<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="true">
  <meta name="msvalidate.01" content="true">
  <meta name="yandex-verification" content="true">
  <meta name="baidu-site-verification" content="true">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blog.lirui.pub","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8990335822972779"
     crossorigin="anonymous"></script>


  <meta name="baidu-site-verification" content="zqFkvU5IKZXfWGBL" />

  <meta name="description" content="1. 卷积层 1. 原理 2. 卷积的作用 3. 一些常见的卷积核 4. 卷积核的参数 5. 几种常见的卷积方式 -TODO 6. 从 pytorch 看一维卷积，二维卷积，三维卷积 参数说明 一维卷积 二维卷积 三维卷积   7. 卷积核的选择   2. 激活层 3. 池化层 — 需要补充 4. 卷积层与池化层比较 5. NLP 与 CV 中使用 CNN 的区别 QA 1. 为什么需要 Pa">
<meta property="og:type" content="article">
<meta property="og:title" content="基本单元-CNN">
<meta property="og:url" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%20-%20CNN/index.html">
<meta property="og:site_name" content="Earyant的技术博客">
<meta property="og:description" content="1. 卷积层 1. 原理 2. 卷积的作用 3. 一些常见的卷积核 4. 卷积核的参数 5. 几种常见的卷积方式 -TODO 6. 从 pytorch 看一维卷积，二维卷积，三维卷积 参数说明 一维卷积 二维卷积 三维卷积   7. 卷积核的选择   2. 激活层 3. 池化层 — 需要补充 4. 卷积层与池化层比较 5. NLP 与 CV 中使用 CNN 的区别 QA 1. 为什么需要 Pa">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/1.gif">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/cat.jpg">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/cat-edgeDetect.jpg">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/cat-edgeDetect-2.jpg">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/cat-sharpen.jpg">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/cat-boxblur.jpg">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/cat-blur-gaussian.jpg">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/2dconv.png">
<meta property="og:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/3dconv.png">
<meta property="article:published_time" content="2022-03-12T15:33:22.000Z">
<meta property="article:modified_time" content="2022-03-12T15:33:22.000Z">
<meta property="article:author" content="Earyant">
<meta property="article:tag" content="机器学习知识整理">
<meta property="article:tag" content="深度学习基础">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/img/CNN/1.gif">

<link rel="canonical" href="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%20-%20CNN/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>基本单元-CNN | Earyant的技术博客</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?7b631c63a156a1da87aae10873b41f51";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Earyant的技术博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Earyant的技术博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">欢迎来到Earyant的技术博客，在这里我将与你分享新技术。</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">88</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">19</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">339</span></a>

  </li>
        <li class="menu-item menu-item-相册">

    <a href="/gallery/" rel="section"><i class="fa fa-camera-retro fa-fw"></i>相册</a>

  </li>
        <li class="menu-item menu-item-留言板">

    <a href="/guestbook/" rel="section"><i class="fa fa-comment fa-fw"></i>留言板</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>


        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8990335822972779"
            crossorigin="anonymous"></script>
        <ins class="adsbygoogle"
            style="display:block; text-align:center;"
            data-ad-layout="in-article"
            data-ad-format="fluid"
            data-ad-client="ca-pub-8990335822972779"
            data-ad-slot="3743679245"></ins>
        <script>
            (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      </div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/earyantLe" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://blog.lirui.pub/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%20-%20CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/me/me2.png">
      <meta itemprop="name" content="Earyant">
      <meta itemprop="description" content="个人技术博客，分享开发中遇到的问题，以及想学的新技术，会持续更新，可以订阅rss。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Earyant的技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基本单元-CNN
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-12 23:33:22" itemprop="dateCreated datePublished" datetime="2022-03-12T23:33:22+08:00">2022-03-12</time>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

  
	<div>
      <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8990335822972779"
          crossorigin="anonymous"></script>
      <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-8990335822972779"
          data-ad-slot="3743679245"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
  </div>
  

    
    
    
    <div class="post-body" itemprop="articleBody">

      


        <!-- toc -->
<ul>
<li><a href="#1-卷积层">1. 卷积层</a><ul>
<li><a href="#1-原理">1. 原理</a></li>
<li><a href="#2-卷积的作用">2. 卷积的作用</a></li>
<li><a href="#3-一些常见的卷积核">3. 一些常见的卷积核</a></li>
<li><a href="#4-卷积核的参数">4. 卷积核的参数</a></li>
<li><a href="#5-几种常见的卷积方式-todo">5. 几种常见的卷积方式 -TODO</a></li>
<li><a href="#6-从-pytorch-看一维卷积二维卷积三维卷积">6. 从 pytorch 看一维卷积，二维卷积，三维卷积</a><ul>
<li><a href="#参数说明">参数说明</a></li>
<li><a href="#一维卷积">一维卷积</a></li>
<li><a href="#二维卷积">二维卷积</a></li>
<li><a href="#三维卷积">三维卷积</a></li>
</ul>
</li>
<li><a href="#7-卷积核的选择">7. 卷积核的选择</a></li>
</ul>
</li>
<li><a href="#2-激活层">2. 激活层</a></li>
<li><a href="#3-池化层-需要补充">3. 池化层 — 需要补充</a></li>
<li><a href="#4-卷积层与池化层比较">4. 卷积层与池化层比较</a></li>
<li><a href="#5-nlp-与-cv-中使用-cnn-的区别">5. NLP 与 CV 中使用 CNN 的区别</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-为什么需要-padding">1. 为什么需要 Padding ？</a></li>
<li><a href="#2-为什么卷积核设计尺寸都是奇数">2. 为什么卷积核设计尺寸都是奇数</a></li>
<li><a href="#3-卷积操作的特点">3. 卷积操作的特点</a></li>
<li><a href="#4-你觉得-cnn-有什么不足">4. 你觉得 CNN 有什么不足？</a></li>
<li><a href="#5-cnn-与-rnn-的优劣">5. CNN 与 RNN 的优劣</a></li>
<li><a href="#6-卷积池化的意义">6. 卷积，池化的意义</a></li>
<li><a href="#7-卷积中不同零填充的影响">7. 卷积中不同零填充的影响</a></li>
<li><a href="#8-1-1-卷积的作用">8. 1 * 1 卷积的作用？</a></li>
<li><a href="#9-卷积核是否越大越好">9. 卷积核是否越大越好？</a></li>
<li><a href="#10-如何减少卷积层参数量">10. 如何减少卷积层参数量？</a></li>
<li><a href="#11-cnn-特点">11. CNN 特点</a></li>
<li><a href="#12-为何较大的batch-size-能够提高-cnn-的泛化能力">12. 为何较大的batch size 能够提高 CNN 的泛化能力？</a></li>
<li><a href="#13-same-与-valid-的区别">13. SAME 与 VALID 的区别</a></li>
<li><a href="#14-cnn-优缺点">14. CNN 优缺点</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/aLy2yv65v2fnv-t8IEgMxQ">https://mp.weixin.qq.com/s/aLy2yv65v2fnv-t8IEgMxQ</a></p>
<h2><span id="1-卷积层">1. 卷积层</span></h2><h3><span id="1-原理">1. 原理</span></h3><p><img data-src="../img/CNN/1.gif" alt="1"></p>
<p>卷积操作原理上其实是对两个矩阵进行<strong>点乘求和</strong>的数学操作，其中一个矩阵为<strong>输入的数据矩阵</strong>，另一个矩阵则为<strong>卷积核</strong>（滤波器或特征矩阵），求得的结果表示为原始图像中提取的特定局部特征。</p>
<h3><span id="2-卷积的作用">2. 卷积的作用</span></h3><p>在图像领域中，深层卷积已经证明比浅层卷积更具表征，从图像的特征提取来看， 不同卷积操作提取到的特征类型是不相同的：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">卷积层次</th>
<th style="text-align:center">特征类型</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">浅层卷积</td>
<td style="text-align:center">边缘特征</td>
</tr>
<tr>
<td style="text-align:center">中层卷积</td>
<td style="text-align:center">局部特征</td>
</tr>
<tr>
<td style="text-align:center">深层卷积</td>
<td style="text-align:center">全局特征</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="3-一些常见的卷积核">3. 一些常见的卷积核</span></h3><p>在传统图像领域，已经证明一些特殊的卷积核能够执行边缘检测，锐化，模糊等操作， 如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">卷积作用</th>
<th style="text-align:center">卷积核</th>
<th style="text-align:center">卷积后图像</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">输出原图</td>
<td style="text-align:center">$\begin{bmatrix} 0 &amp; 0 &amp; 0 \ 0 &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 0 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat.jpg" alt="origin_img"></td>
</tr>
<tr>
<td style="text-align:center">边缘检测（突出边缘差异）</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 0 &amp; -1 \ 0 &amp; 0 &amp; 0 \ -1 &amp; 0 &amp; 1 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-edgeDetect.jpg" alt="edgeDetect-1"></td>
</tr>
<tr>
<td style="text-align:center">边缘检测（突出中间值）</td>
<td style="text-align:center">$\begin{bmatrix} -1 &amp; -1 &amp; -1 \ -1 &amp; 8 &amp; -1 \ -1 &amp; -1 &amp; -1 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-edgeDetect-2.jpg" alt="edgeDetect-2"></td>
</tr>
<tr>
<td style="text-align:center">图像锐化</td>
<td style="text-align:center">$\begin{bmatrix} 0 &amp; -1 &amp; 0 \ -1 &amp; 5 &amp; -1 \ 0 &amp; -1 &amp; 0 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-sharpen.jpg" alt="sharpen_img"></td>
</tr>
<tr>
<td style="text-align:center">方块模糊</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 \end{bmatrix} \times \frac{1}{9}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-boxblur.jpg" alt="box_blur"></td>
</tr>
<tr>
<td style="text-align:center">高斯模糊</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 2 &amp; 1 \ 2 &amp; 4 &amp; 2 \ 1 &amp; 2 &amp; 1 \end{bmatrix} \times \frac{1}{16}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-blur-gaussian.jpg" alt="gaussian_blur"></td>
</tr>
</tbody>
</table>
</div>
<h3><span id="4-卷积核的参数">4. 卷积核的参数</span></h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">参数名</th>
<th style="text-align:left">作用</th>
<th style="text-align:left">常见设置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Kernel Size</td>
<td style="text-align:left">卷积核的大小</td>
<td style="text-align:left">在过去常设为5，如LeNet-5；现在多设为3，通过堆叠$3\times3$的卷积核来达到更大的感受域</td>
</tr>
<tr>
<td style="text-align:center">Stride</td>
<td style="text-align:left">卷积步长</td>
<td style="text-align:left">常见设置为1，表示滑窗距离为1，可以覆盖所有相邻位置特征的组合；当设置为更大值时相当于对特征组合降采样</td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:left">填充策略</td>
<td style="text-align:left"><code>SAME</code>： 表示对不足卷积核大小的边界位置进行某种填充（通常零填充）以保证卷积输出维度与与输入维度一致；<code>VALID</code>时则对不足卷积尺寸的部分进行舍弃，输出维度就无法保证与输入维度一致</td>
</tr>
<tr>
<td style="text-align:center">In Channels</td>
<td style="text-align:left">卷积核的深度</td>
<td style="text-align:left">默认与输入的特征矩阵通道数（深度）一致；在某些压缩模型中会采用通道分离的卷积方式</td>
</tr>
<tr>
<td style="text-align:center">Out Channels</td>
<td style="text-align:left">卷积核的个数</td>
<td style="text-align:left">若设置为与输入通道数一样的大小，可以保持输入输出维度的一致性；若采用比输入通道数更小的值，则可以减少整体网络的参数量</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="5-几种常见的卷积方式-todo">5. 几种常见的卷积方式 -TODO</span></h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28186857">https://zhuanlan.zhihu.com/p/28186857</a></p>
<h3><span id="6-从-pytorch-看一维卷积二维卷积三维卷积">6. 从 pytorch 看一维卷积，二维卷积，三维卷积</span></h3><h4><span id="参数说明">参数说明</span></h4><p>卷积操作常用的有一维卷积，二维卷积与三维卷积，其中，三维卷积用到就比较少了， 三个类在 Pytorch 中的参数都是一样的，只是输入输出维度有所差别罢了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">in_channels: 输入数据的通道数</span><br><span class="line">out_channels: 卷积操作产生的输出通道数</span><br><span class="line">kernels: 卷积核的大小， int 或 tuple， 卷积核的大小设置是需要反复实验测试的。</span><br><span class="line">stride: 卷积步伐，stride 太小，会导致重复计算较多，计算量大； 而太大，有可能会造成特征遗漏。</span><br><span class="line">padding: 输入数据的每一条边填充0的层数， int 或 tuple, 默认为0</span><br><span class="line">padding_mode： 填充方式， zeros： 以0为填充数据</span><br><span class="line">dilation: 卷积核中元素之间的间距， 默认为 1</span><br><span class="line">groups: 从输入通道到输出通道的阻塞连接数， 默认为1</span><br><span class="line">bias: 是否添加 bias， 默认为True</span><br></pre></td></tr></table></figure>
<h4><span id="一维卷积">一维卷积</span></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class torch.nn.Conv1d:</span><br><span class="line"></span><br><span class="line">-- 输入输出数据：</span><br><span class="line">	Input: [N, C_in, L_in]: [batch_size, in_channels, input_len]</span><br><span class="line">    Output: [N, C_out, L_out]: [batch_size, out_channels, output_len]</span><br><span class="line"></span><br><span class="line">-- 参数：</span><br><span class="line">	权重参数： [out_channels, in_channels/groups, kernel_size], 默认初始化为均匀分布 </span><br><span class="line">	Bias参数： [out_channels], 默认初始化为均匀分布</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
L_{out} = \frac{L_{in} + 2 * padding - dilation * (kernel\_size - 1)-1}{stride} + 1</script><p>一维卷积在NLP中常用于 Embedding 部分来提取特征，如在TextCNN中就有使用， 此时可以将词向量维度理解为通道数<code>C_in</code>， 输入序列的长度为 <code>L_in</code>。</p>
<p>注意一点的是，在一维卷积中，卷积核的大小是一维的， 即如 果指定为 n， 则卷积核的大小为 <code>[n, 1, 1]</code>。 </p>
<h4><span id="二维卷积">二维卷积</span></h4><p><img data-src="../img/CNN/2dconv.png" alt="2dconv"></p>
<ul>
<li>单通道：若输入卷积核尺寸为 $(k_h,k_w,1)$，卷积核在输入图像的空间维度上进行滑窗操作，每次滑窗和  $(k_h, k_w)$窗口内的值进行卷积操作，得到输出图像中的一个值。</li>
<li>多通道：输入图像特征通道数为3，卷积核尺寸为 $(k_h,k_w ,3)$ ,每次滑窗与3个通道上的 $(k_h , k_w) $窗口内的所有值进行卷积操作，得到输出图像中的一个值。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class torch.nn.Conv2d:</span><br><span class="line"></span><br><span class="line">-- 输入输出数据：</span><br><span class="line">	Input: [N, C_in, H_in, L_in]: [batch_size, in_channels, input_len]</span><br><span class="line">    Output: [N, C_out, H_out, L_out]: [batch_size, out_channels, output_len]</span><br><span class="line"></span><br><span class="line">-- 参数：</span><br><span class="line">	权重参数： [out_channels, in_channels/groups, kernel_size], 默认初始化为均匀分布 </span><br><span class="line">	Bias参数： [out_channels], 默认初始化为均匀分布</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
H_{out} = \frac{H_{in} + 2 \times padding[0] - dilation[0] \times (kernel\_size[0] -1) - 1}{stride[0]} + 1 \\
W_{out} = \frac{W_{in} + 2 \times padding[1] - dilation[1] \times (kernel\_size[1] -1) - 1}{stride[1]} + 1</script><h4><span id="三维卷积">三维卷积</span></h4><p><img data-src="../img/CNN/3dconv.png" alt="3dconv"></p>
<h3><span id="7-卷积核的选择">7. 卷积核的选择</span></h3><p>大卷积核虽然可以获取更大的感受域，但是大卷积核反而会导致计算量大幅增加，不利于训练更深层的模型，相应的计算能力也会降低。</p>
<p>堆叠2个 <strong>3×3</strong> 卷积核（二通道）可以获得与 <strong>5×5卷积核</strong> 相同的感受视野，同时参数量会更少（3×3×2+1&lt;5×5×1+1）,这也是 <strong>3×3卷积</strong> 应用更广泛的原因，在大多数情况下通过堆叠较小的卷积核比直接采用单个更大的卷积核会更加有效。</p>
<h2><span id="2-激活层">2. 激活层</span></h2><p>激活层本质就是采用激活函数对卷积出的特征做一个非线性变换。</p>
<ul>
<li>首选 Relu， 然后试试 Relu 变体 Leaky Relu 和 Maxout。</li>
<li>某些情况下 tanh 也能获得不错结果。</li>
</ul>
<h2><span id="3-池化层-需要补充">3. 池化层 — 需要补充</span></h2><p>池化层的<strong>作用</strong>是对感受域内的特征进行筛选，提取区域内最具代表性的特征，能够有效地降低特征尺度，进而减少模型所需要的参数量，此外还可以防止过拟合现象。</p>
<p>池化操作的本质是<strong>降采样</strong>。其除了能显著降低参数数量外，还能保持对平移，伸缩，旋转操作的不变性。</p>
<ul>
<li><p>常见的池化操作：选择指导 (Boureau et al., 2010)</p>
<blockquote>
<ul>
<li>最大池化： Max Pooling</li>
<li>平均值池化： Mean Pooling</li>
</ul>
</blockquote>
</li>
</ul>
<p>无论max pooling还是mean pooling,都没有需要学习的参数。因此，在<strong>卷积神经网络</strong>的训练中，Pooling层需要做的仅仅是将<strong>误差层</strong>传递到上一层，<strong>而没有梯度的计算。</strong></p>
<p>对于max Pooling，下一层的误差项的值会原封不动的传递到上一层对应区块中的最大值所对应的神经元，而其他神经元的误差项都是0。</p>
<p>对于 mean Pooling， 下一层的误差项会均匀划分到该层的所有的神经元上。</p>
<h2><span id="4-卷积层与池化层比较">4. 卷积层与池化层比较</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">卷积层</th>
<th style="text-align:center">池化层</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">结构</td>
<td style="text-align:center">零填充时输出维度不变，而通道数改变</td>
<td style="text-align:center">通常特征维度会降低，通道数不变</td>
</tr>
<tr>
<td style="text-align:center">稳定性</td>
<td style="text-align:center">输入特征发生细微改变时，输出结果会改变</td>
<td style="text-align:center">感受域内的细微变化不影响输出结果</td>
</tr>
<tr>
<td style="text-align:center">作用</td>
<td style="text-align:center">感受域内提取局部关联特征</td>
<td style="text-align:center">感受域内提取泛化特征，降低维度</td>
</tr>
<tr>
<td style="text-align:center">参数量</td>
<td style="text-align:center">与卷积核尺寸、卷积核个数相关</td>
<td style="text-align:center">不引入额外参数</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="5-nlp-与-cv-中使用-cnn-的区别">5. NLP 与 CV 中使用 CNN 的区别</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>NLP</th>
<th>CV</th>
</tr>
</thead>
<tbody>
<tr>
<td>卷积核</td>
<td>多为一维卷积， 通常都是由较为浅层的卷积层组成</td>
<td>对二维信号做卷积，一般设为叠加的3×3卷积核</td>
</tr>
<tr>
<td>Pooling</td>
<td>一般采用 Max-Pooling</td>
<td></td>
</tr>
<tr>
<td>全连接层</td>
<td>一般常采用LN + dropout</td>
<td>一般常采用BN + dropout</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-为什么需要-padding">1. 为什么需要 Padding ？</span></h3><p>图像是 <code>5 × 5</code>的矩阵，我们的卷积核是 <code>3 × 3</code>的，最终我们得出的feature map是 <code>3 × 3</code>的矩阵（<code>n -f + 1</code>) 。</p>
<p>这样会带来两个问题：</p>
<blockquote>
<ul>
<li><p>每一次做卷积操作时，你的图像就会缩小，如果这种情况发生多次，你的图像就会变得很小。</p>
</li>
<li><p>边缘的像素点所受到的关注点比中心的关注点少很多。比如上图的 <code>1 * 1</code> 的像素点只进行了一次卷积计算，而中心点 <code>3 * 3</code> 却进行了9次卷积计算，这明显是不公平的。这意味着图像边缘的信息大多都丢失了。</p>
</li>
</ul>
</blockquote>
<p>如果加上 paddding 之后，我们的 feature-map 就变为 <code>(n + 2p - f + 1) × (n + 2p - f + 1)</code>的矩阵。</p>
<p>Padding存在的意义在于：</p>
<blockquote>
<ul>
<li><p>为了不丢弃原图信息</p>
</li>
<li><p>为了保持feature map 的大小与原图一致</p>
</li>
<li><p>为了让更深层的layer的 input 依旧保持有足够大的信息量</p>
</li>
<li><p>为了实现上述目的，且不做多余的事情，padding出来的pixel的值都是0，不存在噪音问题。</p>
</li>
</ul>
</blockquote>
<h3><span id="2-为什么卷积核设计尺寸都是奇数">2. 为什么卷积核设计尺寸都是奇数</span></h3><ul>
<li>保证像素点中心位置，避免位置信息偏移</li>
<li>填充边缘时能保证两边都能填充，原矩阵依然对称</li>
</ul>
<h3><span id="3-卷积操作的特点">3. 卷积操作的特点</span></h3><ul>
<li><p><strong>稀疏交互：</strong>卷积神经网络中，卷积核尺度远小于输入的尺度，这样每个输出神经网仅与前一层区域内的神经元存在连接权重，我们称此为稀疏交互。</p>
<blockquote>
<ul>
<li>提高了模型的统计效率：原本一幅图像只能提供少量特征，现在每一块像素区域都可以提供一部分特征</li>
<li>使得参数大量减少，优化的时间复杂度也会减小几个数量级，过拟合情况也得到改善。 </li>
<li>稀疏交互的意义在于，<strong>先从局部的特征入手，再将局部特征组合起来形成更复杂和抽象的特征</strong>。</li>
</ul>
</blockquote>
</li>
<li><p><strong>参数共享：</strong> 参数共享指的是<strong>同一个模型的不同模块中使用相同的参数</strong>。参数共享的意义在于使得卷积层具有<strong>平移等特性</strong>。</p>
<blockquote>
<ul>
<li>权重共享一定程度上能增强参数之间的联系，获得更好的<strong>共性特征</strong>。</li>
<li>很大程度上降低了网络的参数，<strong>节省计算量和计算所需内存</strong>。</li>
<li>权重共享能起到<strong>很好正则的作用</strong>。正则化的目的是为了降低模型复杂度，防止过拟合，而权重共享则正好降低了模型的参数和复杂度。</li>
</ul>
</blockquote>
</li>
<li><p><strong>平移不变性：</strong>（局部）平移不变性是一个很有用的性质，尤其是当我们关心某个特征<strong>是否出现</strong>而不关心它出现的具体位置时。平移不变性是由于<strong>参数共享 和池化</strong> 所带来的。</p>
</li>
</ul>
<h3><span id="4-你觉得-cnn-有什么不足">4. 你觉得 CNN 有什么不足？</span></h3><ul>
<li><p><strong>信息损失问题。</strong> CNN在Pooling的时候会丢失大量的有价值信息，以及忽略局部与整体之间的关联性比如得分最高的特征只出现了一次，而得分第二高的特征出现了很多次，得分第二高的特征可能比最高的特征还要重要，却被丢弃了，自然造成了不小的信息损失</p>
</li>
<li><p><strong>忽略了位置信息</strong>：一个区域有用的特征极有可能和另一个区域的信息有联系，如TextCNN：对于一些粒度较粗的分类问题如话题分类，位置信息可能不大，但对于如情感分析这种粒度较细的分类问题，位置信息不足便会导致一些问题，如”虽然他长的很帅，但是人品不好”和”虽然他人品不好，但他长得帅啊”，在情感倾向上区别还是比较明显的。</p>
</li>
</ul>
<h3><span id="5-cnn-与-rnn-的优劣">5. CNN 与 RNN 的优劣</span></h3><ul>
<li>并行能力， 训练时间很漫长</li>
<li>RNN 容易发生<strong>梯度消失</strong>，包括 LSTM</li>
<li>CNN 的感受视野受限于卷积核，需要深层的 CNN 网络来获得更大的感受视野</li>
</ul>
<h3><span id="6-卷积池化的意义">6. 卷积，池化的意义</span></h3><ul>
<li>卷积和池化可能导致<strong>欠拟合</strong><ul>
<li>如果一项任务涉及到要<strong>对输入中相隔较远的信息进行合并</strong>时，那么卷积可能就不正确了。</li>
<li>如果一项任务依赖于保存<strong>精确的空间信息</strong>，那么在所有的特征上使用池化将会增大训练误差。</li>
</ul>
</li>
<li>当我们比较卷积模型的统计学习表现时，只能以基准中的其他卷积模型作为比较的对象</li>
</ul>
<h3><span id="7-卷积中不同零填充的影响">7. 卷积中不同零填充的影响</span></h3><p>假定 <code>m， k</code> 分别代表图像的宽度和卷积核的宽度：</p>
<ul>
<li><strong>Valid 卷积（有效卷积）</strong>：不使用零填充，卷积核只允许访问那些图像中能够<strong>完全包含整个核</strong>的位置，输出的宽度为 <code>m − k + 1</code><ul>
<li>在这种情况下，输出的所有像素都是输入中相同数量像素的函数，这使得输出像素的表示更加规范。</li>
<li>然而，输出的大小在每一层都会缩减，这限制了网络中能够包含的卷积层的层数。（一般情况下，影响不大，除非是上百层的网络）</li>
</ul>
</li>
<li><strong>Same 卷积（相同卷积）：</strong>只进行足够的零填充来<strong>保持输出和输入具有相同的大小</strong>，即输出的宽度为 <code>m</code>.<ul>
<li>在这种情况下，只要硬件支持，网络就能包含任意多的卷积层。</li>
<li>然而，输入像素中靠近边界的部分相比于中间部分对于输出像素的影响更小。这可能会导致边界像素存在一定程度的欠表示。</li>
</ul>
</li>
<li><strong>Full 卷积（全卷积）：</strong>进行足够多的零填充使得每个像素都能被访问 k 次（非全卷积只有中间的像素能被访问 k 次），最终输出图像的宽度为 <code>m + k − 1</code><ul>
<li>因为 same 卷积可能导致边界像素欠表示，从而出现了 Full 卷积；</li>
<li>但是在这种情况下，输出像素中靠近边界的部分相比于中间部分是更少像素的函数。这将导致<strong>学得的卷积核不能再所有所有位置表现一致</strong>。</li>
<li>事实上，很少使用 Full 卷积</li>
</ul>
</li>
</ul>
<p>通常<strong>零填充的最优数量</strong>处于 “有效卷积”和 “相同卷积” 之间。</p>
<h3><span id="8-1-1-卷积的作用">8. 1 * 1 卷积的作用？</span></h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/40050371">https://zhuanlan.zhihu.com/p/40050371</a></p>
<ul>
<li>实现信息的跨通道交互和整合。</li>
<li>对卷积核通道数进行降维和升维，减小参数量。</li>
</ul>
<h3><span id="9-卷积核是否越大越好">9. 卷积核是否越大越好？</span></h3><p>卷积核越大，参数量越多。 前期无法使用较小卷积核是因为，前期的模型无法做的很深，这样限制了卷积核的感受视野。但其实，通过堆叠2 个 3 <em> 3 卷积核可以获得与 5 </em> 5 卷积核相同的感受视野，同时参数量特更少。 因此，大多数情况下，通过堆叠较小的卷积核比直接采用单个较大的卷积核更加有效。</p>
<p>自然语言中， TextCNN 就采用单层的卷积核，此时选择合适的，较大的卷积核相对比较重要， 而DPCNN 中，因为能够将卷积做的很深，那么就可以采用3 * 3 的卷积核来做了。</p>
<h3><span id="10-如何减少卷积层参数量">10. 如何减少卷积层参数量？</span></h3><ul>
<li>用深层小卷积代替浅层大卷积</li>
<li>使用分离卷积操作：将原本$K\times K\times C$的卷积操作分离为$K\times K\times 1$和$1\times1\times C$的两部分操作</li>
<li>添加 $1 \times 1$ 卷积</li>
<li>在卷积层前使用池化操作</li>
</ul>
<h3><span id="11-cnn-特点">11. CNN 特点</span></h3><ul>
<li><p><strong>区域不变性：</strong> filter 在每层的输入向量(图像)上滑动，检测的是局部信息，然后通过pooling取最大值或均值。pooling这步综合了局部特征，失去了每个特征的位置信息。</p>
<p>这很适合基于图像的任务，比如要判断一幅图里有没有猫这种生物，你可能不会去关心这只猫出现在图像的哪个区域。但是在NLP里，词语在句子或是段落里出现的位置，顺序，都是很重要的信息。</p>
</li>
<li><p><strong>局部组合性：</strong> CNN中，每个滤波器都把较低层的局部特征组合生成较高层的更全局化的特征。</p>
<p>这在CV里很好理解，像素组合成边缘，边缘生成形状，最后把各种形状组合起来得到复杂的物体表达。在语言里，当然也有类似的组合关系，但是远不如图像来的直接。而且在图像里，相邻像素必须是相关的，相邻的词语却未必相关。</p>
</li>
</ul>
<h3><span id="12-为何较大的batch-size-能够提高-cnn-的泛化能力">12. 为何较大的batch size 能够提高 CNN 的泛化能力？</span></h3><p>在相同迭代次数和学习率的条件下，每批次采用更多的数据将有助于模型更好的学习到正确的模式，模型输出结果也会更加稳定</p>
<h3><span id="13-same-与-valid-的区别">13. SAME 与 VALID 的区别</span></h3><ul>
<li>SAME： 宽卷积，通常采用零填充的方式对卷积核不满足整除条件的输入特征进行补全，以使卷积层的输出维度保持与输入特征维度一致。</li>
<li>VALID：窄卷积，不进行任何填充，在输入特征边缘位置若不足以进行卷积操作，则对边缘信息进行舍弃，因此在步长为1的情况下该填充方式的卷积层输出特征维度可能会略小于输入特征的维度。</li>
</ul>
<h3><span id="14-cnn-优缺点">14. CNN 优缺点</span></h3><p><strong>优点：</strong></p>
<ul>
<li>共享卷积核，优化计算量。</li>
<li>无需手动选取特征，训练好权重，即得特征。</li>
<li>深层次的网络抽取图像信息丰富，表达效果好。</li>
<li>保持了层级网络结构。</li>
<li>不同层次有不同形式与功能。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>需要调参，需要大样本量，GPU等硬件依赖。</li>
<li>物理含义不明确。</li>
</ul>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">

  </div>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://www.zhihu.com/people/lirui940403">
            <span class="icon">
              <i class="fab fa-zhihu"></i>
            </span>

            <span class="label">Zhihu</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://github.com/earyantLe">
            <span class="icon">
              <i class="fab fa-github"></i>
            </span>

            <span class="label">Github</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/" rel="tag"># 机器学习知识整理</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" rel="tag"># 深度学习基础</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%20-%20MLP/" rel="prev" title="基本单元-NLP">
      <i class="fa fa-chevron-left"></i> 基本单元-NLP
    </a></div>
      <div class="post-nav-item">
    <a href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0/" rel="next" title="主动学习">
      主动学习 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>

          <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8990335822972779"
              crossorigin="anonymous"></script>
          <ins class="adsbygoogle"
              style="display:block; text-align:center;"
              data-ad-layout="in-article"
              data-ad-format="fluid"
              data-ad-client="ca-pub-8990335822972779"
              data-ad-slot="3743679245"></ins>
          <script>
              (adsbygoogle = window.adsbygoogle || []).push({});
          </script>

          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8990335822972779"
     crossorigin="anonymous"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-8990335822972779"
     data-ad-slot="3743679245"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">1. 卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.1.</span> <span class="nav-text">1. 原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.2.</span> <span class="nav-text">2. 卷积的作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.3.</span> <span class="nav-text">3. 一些常见的卷积核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.4.</span> <span class="nav-text">4. 卷积核的参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.5.</span> <span class="nav-text">5. 几种常见的卷积方式 -TODO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.6.</span> <span class="nav-text">6. 从 pytorch 看一维卷积，二维卷积，三维卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.6.1.</span> <span class="nav-text">参数说明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.6.2.</span> <span class="nav-text">一维卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.6.3.</span> <span class="nav-text">二维卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.6.4.</span> <span class="nav-text">三维卷积</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.7.</span> <span class="nav-text">7. 卷积核的选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">2. 激活层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">3. 池化层 — 需要补充</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">4. 卷积层与池化层比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">5. NLP 与 CV 中使用 CNN 的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">6.</span> <span class="nav-text">QA</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.1.</span> <span class="nav-text">1. 为什么需要 Padding ？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.2.</span> <span class="nav-text">2. 为什么卷积核设计尺寸都是奇数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.3.</span> <span class="nav-text">3. 卷积操作的特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.4.</span> <span class="nav-text">4. 你觉得 CNN 有什么不足？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.5.</span> <span class="nav-text">5. CNN 与 RNN 的优劣</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.6.</span> <span class="nav-text">6. 卷积，池化的意义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.7.</span> <span class="nav-text">7. 卷积中不同零填充的影响</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.8.</span> <span class="nav-text">8. 1 * 1 卷积的作用？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.9.</span> <span class="nav-text">9. 卷积核是否越大越好？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.10.</span> <span class="nav-text">10. 如何减少卷积层参数量？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.11.</span> <span class="nav-text">11. CNN 特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.12.</span> <span class="nav-text">12. 为何较大的batch size 能够提高 CNN 的泛化能力？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.13.</span> <span class="nav-text">13. SAME 与 VALID 的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">6.14.</span> <span class="nav-text">14. CNN 优缺点</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Earyant"
      src="/images/me/me2.png">
  <p class="site-author-name" itemprop="name">Earyant</p>
  <div class="site-description" itemprop="description">个人技术博客，分享开发中遇到的问题，以及想学的新技术，会持续更新，可以订阅rss。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">339</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">88</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button motion-element"><i class="fa fa-comment"></i>
    Chat
  </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/earyantLe" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;earyantLe" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:lirui940403@gmail.com" title="E-Mail → mailto:lirui940403@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/earyant" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;earyant" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/earyantLe" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;earyantLe" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/earyant" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;earyant" rel="noopener" target="_blank"><i class="fab fa-facebook fa-fw"></i>FB Page</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/earyant" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;earyant" rel="noopener" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i>StackOverflow</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/lirui940403" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;lirui940403" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://zhuyuanxiang.github.io/" title="https:&#x2F;&#x2F;zhuyuanxiang.github.io&#x2F;" rel="noopener" target="_blank">zYx.Tom</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://mofanpy.com/" title="https:&#x2F;&#x2F;mofanpy.com&#x2F;" rel="noopener" target="_blank">mofan</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://github.com/timqian/chinese-independent-blogs" title="https:&#x2F;&#x2F;github.com&#x2F;timqian&#x2F;chinese-independent-blogs" rel="noopener" target="_blank">中文独立博客推荐</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.ruanyifeng.com/blog/" title="https:&#x2F;&#x2F;www.ruanyifeng.com&#x2F;blog&#x2F;" rel="noopener" target="_blank">阮一峰</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://space.bilibili.com/1567748478" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;1567748478" rel="noopener" target="_blank">李沐</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://seekbetter.me/" title="https:&#x2F;&#x2F;seekbetter.me&#x2F;" rel="noopener" target="_blank">加菲猫</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.jetli.com.cn/" title="http:&#x2F;&#x2F;www.jetli.com.cn&#x2F;" rel="noopener" target="_blank">优秀博客导航</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Earyant</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">997k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">15:06</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'dc57e777868f7d0d0d6e',
      clientSecret: 'd54ae953e61c3d6fe846828c2765958a001a8654',
      repo        : 'earyant.github.io-comment',
      owner       : 'earyantLe',
      admin       : ['earyantLe'],
      id          : '3df0d75ea5389e4601ad829d358a1abd',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>



</body>
</html>
