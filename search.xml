<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>java知识整理</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#算法和数据结构性能场景">算法和数据结构（性能，场景）：</a><ul>
<li><a href="#数据结构">数据结构：</a></li>
<li><a href="#算法httpsblogcsdnnetgane-chengarticledetails52652705">算法</a></li>
<li><a href="#数据库mysql">数据库(mysql)</a></li>
<li><a href="#nosql">NoSql</a></li>
<li><a href="#设计模式">设计模式</a></li>
<li><a href="#操作系统">操作系统</a></li>
<li><a href="#java">java</a></li>
<li><a href="#脚本语言">脚本语言</a></li>
</ul>
</li>
<li><a href="#架构">架构</a><ul>
<li><a href="#微服务">微服务</a></li>
<li><a href="#分布式">分布式</a></li>
<li><a href="#大数据">大数据</a></li>
<li><a href="#运维-统计-技术支持">运维 &amp; 统计 &amp; 技术支持</a></li>
<li><a href="#测试">测试</a></li>
</ul>
</li>
<li><a href="#书单">书单</a></li>
<li><a href="#实战">实战</a><ul>
<li><a href="#实践一个双十一电商项目">实践一个双十一电商项目</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="算法和数据结构性能场景">算法和数据结构（性能，场景）：</span></h2><h3><span id="数据结构">数据结构：</span></h3><ul>
<li>数组</li>
<li>链表</li>
<li>树<ul>
<li>二叉树<ul>
<li>满二叉树</li>
<li>完美二叉树</li>
<li>完全二叉树</li>
<li>二叉搜索树： 其任何节点中的值都会大于或者等于其做字数中存储的值并小于或者等于其右子树的值。<ul>
<li>时间复杂度：<ul>
<li>索引: O(log(n))</li>
<li>搜索: O(log(n))</li>
<li>插入: O(log(n))</li>
<li>删除: O(log(n))</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>红黑树</li>
<li>AVL树</li>
<li>Hash树</li>
<li>tire树</li>
<li>b-树（读b树，也叫balance树，不读b减树 “-”代表横杠）</li>
<li>b+树</li>
<li>LSM（Log-Structured Merge-Trees）树</li>
<li>Trie 字典树，基数树或者前缀树，能够存储键为字符串的动态集合或者关联数组的搜索树，树中节点没有存储键值，而是在该节点在树中的挂载位置决定了其关联键值，某个节点的所有子节点都拥有相同的前缀，整树根节点则是空字符串</li>
<li>Fenwick Tree：树状数组，又称为 Binary Indexed Tree，其表现形式为树，不过本质上是以数组实现，数组的下标代表着树中的顶点，每个顶点的父节点或者子节点的下标能够通过位运算获得，数组中的每个元素包含了预计算的区间值之和，在整颗数更新的过程中同样会更新这些预计算的值。<ul>
<li>时间复杂度：<ul>
<li>区间求值： O(log(n))</li>
<li>更新： O(log(n))</li>
</ul>
</li>
</ul>
</li>
<li>Segment Tree<ul>
<li>线段树是用于存放间隔或者线段的树形数据结构，它允许快速查找某一个节点在某若干条线段中出现的次数。<ul>
<li>区间查询： O(log(n))</li>
<li>更新: O(log(n))</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>队列</li>
<li>栈</li>
<li>堆<br> 堆是一种特殊的基于树的满足某些特性的数据结构，整个堆中的所有父子节点的键值都会满足相同的排序条件。堆更准确地可以分为最大堆与最小堆，在最大堆中，父节点的键值永远大于或者等于子节点的值，并且整个堆中的最大值存储于根节点；而最小堆中，父节点的键值永远小于或者等于其子节点的键值，并且整个堆中的最小值存储于根节点。</li>
<li>Hashing<ul>
<li>哈希能够将任意长度的数据映射到固定长度的数据，哈希函数返回的即是哈希值，如果两个不同的键得到相同的哈希值，将这种现象称为碰撞。</li>
<li>Hash Map<br> 是一种能够建立起键与值之间关系的数据结构，Hash Map能够使用哈希函数将键转化为桶或者槽中的下标，从而优化对于目标值的搜索速度。</li>
<li>碰撞解决：<ul>
<li>链地址法：<br> 每个桶都是互相独立的，包含一系列索引的列表，搜索操作的时间复杂度即是搜索桶的时间（固定时间）与遍历列表的时间之和。</li>
<li>开地址法：<br> 当插入新值时，会判断该值对应的哈希桶是否存在，如果存在则根据某种算法一次选择下一个可能的位置，知道找到一个尚未被占用的地址，所谓开地址法也是只某个元素的位置并不永远由其哈希值决定。</li>
</ul>
</li>
</ul>
</li>
<li>Graph<br>图是一种数据元素间为多对多关系的数据结构，加上一组基本操作构成的抽象数据类型<ul>
<li>无向图：<br>无向图具有对称的邻接矩阵，因此如果存在某条从节点u到节点v的边，反之从v到u的边也存在。</li>
<li>有向图：<br>有向图的邻接矩阵是非对称的，即如果存在从u到v的表并不意味着存在v到u的边。<h3><span id="算法">：</span></h3></li>
</ul>
</li>
<li><p>查找：</p>
<ul>
<li>二分查找，以及变种二分查找。</li>
<li><a href="https://www.cnblogs.com/0kk470/p/7555033.html">深度优先、广度优先</a></li>
<li><a href="https://www.cnblogs.com/MrSaver/p/8641971.html">贪心算法</a><ul>
<li><a href="https://blog.csdn.net/a345017062/article/details/52443781">参考二</a></li>
</ul>
</li>
<li><a href="https://blog.csdn.net/qfikh/article/details/51960331">回溯算法</a></li>
<li><a href="https://blog.csdn.net/luningcsdn/article/details/50930276">剪枝算法</a></li>
<li><a href="https://www.cnblogs.com/little-YTMM/p/5372680.html">动态规划</a><ul>
<li><a href="https://blog.csdn.net/yao_zi_jie/article/details/54580283">参考二</a></li>
</ul>
</li>
<li><a href="https://blog.csdn.net/amds123/article/details/70173402">朴素贝叶斯</a><ul>
<li><a href="http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html">参考二</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_two.html">参考三</a></li>
</ul>
</li>
<li><a href="http://www.infoq.com/cn/articles/recommendation-algorithm-overview-part01">推荐算法</a></li>
<li><a href="https://www.oschina.net/news/51297/top-10-open-source-recommendation-systems">参考二</a></li>
<li><a href="https://blog.csdn.net/luoshixian099/article/details/51908175">最小生成树算法</a></li>
<li><a href="https://blog.csdn.net/qq_35644234/article/details/60870719">最短路径算法</a></li>
</ul>
</li>
<li><p>排序：</p>
<ul>
<li>7种排序<ul>
<li><a href="https://www.cnblogs.com/shen-hua/p/5424059.html">选择排序</a><blockquote>
<p>每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。</p>
</blockquote>
</li>
<li><a href="https://blog.csdn.net/shuaizai88/article/details/73250615">冒泡排序</a><blockquote>
<p>相邻元素前后交换、把最大的排到最后。<br>时间复杂度 O(n²)</p>
</blockquote>
</li>
<li><a href="https://www.cnblogs.com/hapjin/p/5517667.html">插入排序</a></li>
<li><a href="http://developer.51cto.com/art/201403/430986.htm">快速排序</a><ul>
<li>稳定： 否</li>
<li>时间复杂度：<ul>
<li>最优时间：O(nlog(n))</li>
<li>最坏时间: O(n^2)</li>
<li>平均时间：O(nlog(n))</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://www.cnblogs.com/chengxiao/p/6194356.html">归并排序：</a><ul>
<li>分治算法，不断将某个数组分为两个部分，分别对左子数组与右子数组进行排序，然后将两个数组合并为新的有序数组</li>
<li>稳定：是</li>
<li>时间复杂度<ul>
<li>最优时间： O(nlog(n))</li>
<li>最坏时间： O(nlog(n))</li>
<li>平均时间： O(nlog(n))</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://blog.51cto.com/ahalei/1362789">桶排序：</a><ul>
<li><a href="https://blog.csdn.net/sunjinshengli/article/details/70738527">参考二</a></li>
<li>桶排序将数组分到有限数量的筒子里，每个桶子再个别排序，有可能在使用别的排序算法或者以地柜方式继续使用桶排序。</li>
<li>时间复杂度：<ul>
<li>最优时间： O(n+k)</li>
<li>最坏时间： O(n^2)</li>
<li>平均时间： O(n+k)<br><a href="https://github.com/kdn251/interviews/blob/master/README-zh-cn.md">参考</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://www.cnblogs.com/suvllian/p/5495780.html">计数排序</a></li>
<li>时间、空间复杂度（理解并分析）</li>
<li>动态规划、贪心算法<h3><span id="计算机网络">计算机网络</span></h3></li>
</ul>
</li>
</ul>
</li>
<li>OSI7层协议（TCP四层）<ul>
<li>URL到页面的过程</li>
</ul>
</li>
<li>http&#x3A;<ul>
<li>http/https 1.0、1.1、2.0</li>
<li>get/post 以及幂等性</li>
<li>http相关头协议</li>
</ul>
</li>
<li>网络攻击（CSRF、XSS）</li>
<li>TCP/IP<ul>
<li>三次握手、四次握手</li>
<li>拥塞控制（过程、阙值）</li>
<li>TCP与UDP比较</li>
<li>子网掩码</li>
<li>DDos攻击</li>
</ul>
</li>
<li>BIO、IO、NIO、AIO<ul>
<li>原理</li>
<li>Netty</li>
<li>linux内核的select poll epoll</li>
</ul>
</li>
</ul>
<h3><span id="数据库mysql">数据库(mysql)</span></h3><ul>
<li>索引<ul>
<li>分类<ul>
<li>全文索引</li>
<li>HASH索引</li>
<li>BTree索引</li>
<li>RTree索引</li>
<li>普通索引</li>
<li>唯一索引</li>
<li>主索引</li>
<li>外键索引</li>
<li>复合索引</li>
</ul>
</li>
</ul>
</li>
<li>优化方式<ul>
<li>失效条件</li>
<li>底层结构</li>
</ul>
</li>
<li>sql语法<ul>
<li>join、union、子查询、having、group by</li>
</ul>
</li>
<li>引擎对比<ul>
<li>InnoDB</li>
<li>MyISAM</li>
</ul>
</li>
<li>[锁]{}<ul>
<li>行锁、表锁、页级锁、意向锁、读锁、写锁、悲观锁、乐观锁、以及枷锁的select sql方式</li>
</ul>
</li>
<li>隔离级别<ul>
<li>脏读</li>
<li>不可重复读</li>
<li>幻读</li>
</ul>
</li>
<li>事务的ACID</li>
<li>B树</li>
<li>B+树</li>
<li>优化<ul>
<li>explain</li>
<li>慢查询</li>
<li>show profile</li>
<li>数据库的范式</li>
<li>分库分表</li>
<li>主从复制</li>
<li>读写分离</li>
</ul>
</li>
</ul>
<h3><span id="nosql">NoSql</span></h3><ul>
<li>redis</li>
<li>memcached</li>
<li>mongdb</li>
<li><a href="http://www.runoob.com/Memcached/Memcached-tutorial.html">《Memcached 教程》</a></li>
<li><a href="https://blog.csdn.net/chenleixing/article/details/47035453">《深入理解Memcached原理》</a></li>
<li><a href="https://www.jianshu.com/p/36e5cd400580">《Memcached软件工作原理》</a></li>
<li><a href="http://zhihuzeye.com/archives/2361">《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》</a></li>
<li><a href="https://blog.csdn.net/liu251890347/article/details/37690045">《memcache 中 add 、 set 、replace 的区别》</a></li>
<li><a href="https://pan.baidu.com/s/1qX00Lti?errno=0&amp;errmsg=Auth%20Login%20Sucess&amp;&amp;bduss=&amp;ssnerror=0&amp;traceid=">《memcached全面剖析》</a></li>
</ul>
<h3><span id="设计模式">设计模式</span></h3><ul>
<li><a href="https://blog.csdn.net/q291611265/article/details/48465113">设计模式的六大原则</a><ul>
<li>开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。</li>
<li>里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。</li>
<li>依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。</li>
<li>接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。</li>
<li>迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。</li>
<li>合成复用原则：尽量使用合成/聚合,而不是使用继承。</li>
</ul>
</li>
<li><a href="http://www.runoob.com/design-pattern/design-pattern-tutorial.html">23种常见设计模式</a><ul>
<li><a href="https://www.cnblogs.com/susanws/p/5510229.html">参考二</a></li>
</ul>
</li>
<li><p><a href="http://blog.jobbole.com/62314/">《细数JDK里的设计模式》</a></p>
<ul>
<li><p>结构型模式：</p>
<ul>
<li>适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。</li>
<li>桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC；</li>
<li>组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。</li>
<li>装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。</li>
<li>享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。</li>
<li>代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy</li>
</ul>
</li>
<li><p>创建模式:</p>
<ul>
<li>抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。</li>
<li>建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。</li>
<li>工厂方法：就是 一个返* 回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。</li>
<li>原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。</li>
<li>单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。</li>
</ul>
</li>
<li><p>行为模式：</p>
<ul>
<li>责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。</li>
<li>命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。</li>
<li>解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。</li>
<li>迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。</li>
<li>中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。</li>
<li>空对象模式：如 java.util.Collections#emptyList()。</li>
<li>观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。</li>
<li>模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。</li>
</ul>
</li>
</ul>
</li>
<li><p><a href="https://www.cnblogs.com/hwaggLee/p/4510687.html">《Spring-涉及到的设计模式汇总》</a></p>
</li>
<li><a href="https://blog.csdn.net/u012387062/article/details/54719114">《Mybatis使用的设计模式》</a></li>
</ul>
<h3><span id="操作系统">操作系统</span></h3><ul>
<li>进程通信IPC，与线程区别</li>
<li>OS集中策略、进程调度</li>
<li>互斥与死锁</li>
<li>linux相关命令<ul>
<li>cpu命令</li>
<li>内存</li>
<li>部署</li>
<li>vim<h3><span id="java">java</span></h3></li>
</ul>
</li>
<li>面向对象</li>
<li><p><a href="https://earyant.github.io/2017/09/10/java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/">集合</a></p>
<ul>
<li>map<ul>
<li><a href="https://earyant.github.io/2017/08/09/HashMap%E5%85%A8%E8%A7%A3%E6%9E%90/">Hashmap</a></li>
<li>EnumMap: 枚举类型座位键值的Map，效率要高于HashMap</li>
<li>HashTable：</li>
<li>ConcurrentHashMap：<ul>
<li>get操作全并发访问，put操作可配置并发操作的哈希表，并发级别可以通过构造参数中的concurrentLevel参数设置(默认级别为16).该参数会在Map内部划分一些分区，在put的时候，只有更新的分区是锁住的。</li>
</ul>
</li>
<li>ConcurrentSkipListMap： 基于跳跃表的ConcurrentNavigableMap实现。本质上这种集合可以当做TreeMap的线程安全版本来使用。</li>
<li>IdentityHashMap</li>
<li>LinkedHashMap</li>
<li>TreeMap</li>
<li>WeakHashMap</li>
</ul>
</li>
<li>list<ul>
<li>ArrayList<ul>
<li>内部用一个整形数字或者数组存储了集合的大小。</li>
<li>访问速度稳定；</li>
<li>在尾部添加成本低，在头部添加成本高(线性复杂度)。</li>
</ul>
</li>
<li>LinkedList<ul>
<li>Deque实现，每一个节点都保存着上一个节点和下一个节点的指针。所以数据的存取和更新都具有线性复杂度。<br><a href="https://earyant.github.io/2017/09/10/ArrayList%E5%92%8CLinkedList%E5%AF%B9%E6%AF%94/">ArrayList和LinkedList对比</a></li>
<li>时间复杂度：<ul>
<li>索引:  O(n)</li>
<li>搜索:  O(n)</li>
<li>插入:  O(1)</li>
<li>移除:  O(1)</li>
</ul>
</li>
</ul>
</li>
<li>Vector</li>
</ul>
</li>
<li><p>set</p>
<ul>
<li>HashSet</li>
<li>EnumSet</li>
<li>BitSet</li>
<li>LinkedHashMap</li>
<li>TreeSet</li>
<li>ConcurrentSkipListSet ： 使用ConcurrentSkipListMap来存储线程安全的Set。</li>
<li>CopyOnWriteArraySet： 使用CopyOnWriteArrayList存储的线程安全的Set</li>
</ul>
</li>
<li><p>Queues/Deques</p>
<ul>
<li>ArrayDeQue ： Deque是基于有首尾指针的数组（环形缓冲区）实现的。和LinkedList不同，这个类没有实现List接口，因此，如果没有收尾元素的话，就不能去除任何元素。比LinkedList好一点，产生的垃圾数量较少。</li>
<li><a href="https://www.cnblogs.com/lemon-flm/p/7877898.html">Queue</a><ul>
<li>enqueue： 插入到队列中</li>
<li>dequeue： 将队头移除</li>
<li>时间复杂度：<ul>
<li>索引: O(n)</li>
<li>搜索: O(n)</li>
<li>插入: O(1)</li>
<li>移除: O(1)</li>
</ul>
</li>
</ul>
</li>
<li><p>Stack ：后进先出的队列</p>
<ul>
<li>push： 将元素压入栈</li>
<li>pop：  将栈顶元素移除</li>
<li>时间复杂度：<ul>
<li>索引: O(n)</li>
<li>搜索: O(n)</li>
<li>插入: O(1)</li>
<li>移除: O(1)</li>
</ul>
</li>
</ul>
<p>-- 并发 —</p>
</li>
<li><p>ArrayBlockingQueue： 基于书实现的一个有界阻塞对，大小不能重新定义，试图向一个满的队列添加元素的时候，就会受到阻塞，知道另一个方法从队列中取出元素。</p>
</li>
<li>ConcurrentLinkedDeque、ConcurrentLinkedQueue：基于链表实现的无解队列，添加元素不阻塞。要求消费者的速度至少要比生产一样快，不然内存就会耗尽，严重依赖于CAS操作。</li>
<li>DelayQueue ： 无界的保存Delayed元素的集合，元素只有在延时已经过期的时候才能被取出。队列的第一个元素延期最小(包含负值，延时已经过期)，要实现一个延期任务的队列的时候使用(不要自己手动实现—使用ScheduledThreadPoolExecutor)</li>
<li>LinkedBlockingDeque/LinkedBlockingQueue： 可选择有界或者无界基于链表的实现。在队列为空或者满的情况下使用ReentrantLock</li>
<li>LinkedTransferQueue: 基于链表的无界队列，除了通常的队列操作，还有一系列的transfer方法，可以让生产者直接给等待的消费者传递信息，这样就不用将元素存储到队列中了，这是一个基于CAS的无锁集合</li>
<li>PriorityBlockingQueue：PriorityQueue的无界的版本。</li>
<li>SynchronousQueue：一个有界队列，其中没有任何内存容量。这就意味着任何插入操作必须等到响应的取出操作才能执行，反之亦反。如果不需要Queue接口的话，通过Exchanger类也能完成响应的功能。</li>
</ul>
</li>
<li><p>Lists类</p>
<ul>
<li>CopyOnWriteArrayList ： list的实现每一次都会产生一个新的隐含数组副本，所以这个操作成本很高，适合遍历操作比更新操作多的集合，例如listeners/observers集合</li>
</ul>
</li>
<li>Collections 工具类<ul>
<li>checked* : 检查要添加的元素的类型并返回结果，尝试添加非法类型的变量都会抛出一个ClassCastException<ul>
<li>checkedCollection</li>
<li>checkedList</li>
<li>checkedMap</li>
<li>checkSet</li>
<li>checkedSortedMap</li>
<li>checkedSortedSet</li>
</ul>
</li>
<li>empty* : 返回一个固定的空集合。<ul>
<li>emptyList</li>
<li>emptyMap</li>
<li>emptySet</li>
</ul>
</li>
<li>singleton* : 返回一个只有一个入口的set、list、map集合<ul>
<li>singletonList</li>
<li>singletonMap</li>
</ul>
</li>
<li>synchronized* ： 获得集合的线程安全版本<ul>
<li>synchronizedCollection</li>
<li>synchronizedList</li>
<li>synchronizedMap</li>
<li>synchronizedSet</li>
<li>synchronizedSortedMap</li>
<li>synchronizedSortedSet</li>
</ul>
</li>
<li>unmodifiable* : 返回一个不可变的集合<ul>
<li>unmodifiableCollection</li>
<li>unmodifiableList</li>
<li>unmodifiableMap</li>
<li>unmodifiableSet</li>
<li>unmodifiableSortedMap</li>
<li>unmodifiableSortedSet</li>
</ul>
</li>
<li>addAll : 添加一些元素或者一个数组的内容到集合中</li>
<li>binarySearch ： 和数组的Arrays.binarySearch功能相同</li>
<li>disjoint : 检查两个集合是不是没有相同元素</li>
<li>fill ： 用一个指定的值代替集合中的所有元素</li>
<li>frequency: 集合中有多少元素是和给定元素相同的。</li>
<li>indexOfSubList、lastIndexOfSubList\indexOf\lashIndexOf 找出给定list中第一个出现和最后一个出现的子表</li>
<li>max、min 找出基于自然顺序或者比较器排序的集合、最大或者最小的元素</li>
<li>replaceAll： 替换所有</li>
<li>reverse: 掉到排序元素和集合中的顺序</li>
<li>rotate ： 根据给定的距离旋转元素</li>
<li>shuffle： 随机排放List集合中的节点，而已给定自己的生成器</li>
<li>sort ： 自然排序或者指定的排序器排序</li>
<li>swap 交换集合中的两个元素的位置</li>
</ul>
</li>
<li>Arrays<ul>
<li>Arrays.asList(): 可以将Array转换成List。</li>
<li>Arrays.binarySearch : 在一个已排序的或者其中一段中快速查找</li>
<li>Arrays.copyOf : 如果扩大数组容量又不想改变内容时候用这个方法</li>
<li>Arrays.copyOfRange :  可以复制整个数组或者其中一个部分</li>
<li>Arrays.deepEquals、Arrays.deepHashCode : Arrays.equals、hashCode的高级版本，支持子数据操作。</li>
<li>Arrays.equals : 比较两个数组是否想相等。</li>
<li>Arrays.fill  : 用一个给定的值填充整个数组或者其中一个部分</li>
<li>Arrays.hashCode : 根据数组内容计算器hash值。</li>
<li>Arrays.sort : 对整个数组或者数组一部分进行排序。</li>
<li>Arrays.toString : 打印数组的内容</li>
<li>所有集合都可以用 T[] Collection.toArray(T[] a)方法复制到整个数组：<br>  return coll.toArray(new T[coll.size()]);</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>并发和多线程</p>
<ul>
<li>参考：<ul>
<li><a href="https://github.com/CL0610/Java-concurrency">Java 并发知识合集</a></li>
<li><a href="https://github.com/CL0610/Java-concurrency/blob/master/Java%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1.png">JAVA并发知识图谱</a></li>
<li>java并发编程网</li>
<li><a href="http://www.importnew.com/18459.html">《40个Java多线程问题总结》</a></li>
<li><a href="https://www.cnblogs.com/zhanht/p/5450325.html">《Java并发编程——线程安全及解决机制简介》</a></li>
</ul>
</li>
<li>锁<ul>
<li>ReetrantLock</li>
<li>ReetranReadWriteLock</li>
<li>Condition</li>
</ul>
</li>
<li><p>开发工具类</p>
<ul>
<li>CyclicBarrier</li>
<li>CountDownLatch</li>
<li>Semphere</li>
</ul>
</li>
<li><p>并发集合</p>
<ul>
<li>ConcurrentHashMap</li>
<li>ConcurrentLinkedQueue</li>
</ul>
</li>
<li>线程池<ul>
<li>Excutor</li>
<li>ThreadPoolExcutor</li>
<li>Callable和Future</li>
<li>ScheduledExecutorService</li>
</ul>
</li>
<li>原子操作<ul>
<li>基本类型<ul>
<li>AtomicBoolean</li>
<li>AtomicInteger</li>
<li>AtomicLong</li>
</ul>
</li>
<li>引用类型<ul>
<li>AtomicReference</li>
<li>AtomicReferenceArrayFieldUpdater</li>
</ul>
</li>
<li>数组<ul>
<li>AtomicIntegerArray</li>
<li>AtomicLongArray</li>
<li>AtomicReferenceArray</li>
</ul>
</li>
</ul>
</li>
<li>synchronized<ul>
<li>同步、重量级锁，synchronized原理</li>
<li>锁优化<ul>
<li>自旋锁</li>
<li>轻量级锁</li>
<li>重量级锁</li>
<li>偏向锁</li>
</ul>
</li>
</ul>
</li>
<li>Lock机制</li>
<li>线程通信</li>
<li><a href="https://www.cnblogs.com/dolphin0520/p/3920373.html">volatile</a><ul>
<li>实现机制</li>
<li>内存语义</li>
<li>内存模型</li>
</ul>
</li>
<li>ThreadLocal</li>
<li>Fork\Join</li>
<li>concurrent包</li>
<li>AQS<ul>
<li>AbstractqueuedSynchronized同步器</li>
<li>CLH同步队列</li>
<li>同步状态的获取及释放</li>
<li>线程阻塞和唤醒</li>
</ul>
</li>
<li>CAS<ul>
<li>Compare And Swap缺陷</li>
</ul>
</li>
</ul>
</li>
<li><p>优化调优</p>
<ul>
<li>工具<ul>
<li>MAT</li>
<li>Jmeter</li>
</ul>
</li>
<li>理解性能优化<ul>
<li>性能基准</li>
<li>性能优化到底是什么</li>
<li>衡量维度</li>
</ul>
</li>
<li>JVM调优<ul>
<li>什么是JVM内存模型JMM</li>
<li>各垃圾回收气使用场景</li>
<li>理解GC日志</li>
<li>实战MAT分析DUMP文件</li>
</ul>
</li>
<li>Tomcat调优<ul>
<li>tomcat运行机制</li>
<li>线程模型</li>
<li>系统参数认识及调优</li>
<li>基准测试</li>
</ul>
</li>
<li>MySQL调优<ul>
<li>理解MySQL底层B+树</li>
<li>SQL执行计划详解索引优化详解</li>
<li>SQL语句优化</li>
</ul>
</li>
</ul>
</li>
<li><p>JVM</p>
<blockquote>
<p>《深入理解Java虚拟机：JVM高级特性与最佳实践》</p>
</blockquote>
<ul>
<li>内存模型<ul>
<li>重排序</li>
<li>顺序一致性</li>
<li>happens-hefore</li>
<li>as-if-serial</li>
</ul>
</li>
<li>GC垃圾回收机制</li>
<li>分代算法，GC算法</li>
<li>收集器</li>
<li>类加载、双亲委派</li>
<li>JVM调优<ul>
<li>jvm参数</li>
</ul>
</li>
<li>内存泄露和内存溢出</li>
</ul>
</li>
<li><p>IO和NIO</p>
</li>
<li>反射和代理、异常、java8、序列化</li>
<li>设计模式：<ul>
<li>24中常用的设计模式<ul>
<li>proxy代理模式</li>
<li>Factory工厂模式</li>
<li>Singleton单例模式</li>
<li>Delegate委派模式</li>
<li>Strategy策略模式</li>
<li>prototype原型模式</li>
<li>Adapter适配器模式</li>
</ul>
</li>
<li>java源码中或者spring中用到哪些</li>
</ul>
</li>
<li>web<ul>
<li>servlet</li>
<li>cookie、session</li>
<li>spring<ul>
<li>aop<ul>
<li>AOP设计原理</li>
</ul>
</li>
<li>ioc<ul>
<li>IOC容器设计原理及高级特性</li>
</ul>
</li>
<li>FactoryBean与BeanFactory</li>
<li>mvc</li>
<li><a href="https://earyant.github.io/2017/09/17/Spring%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/">事务</a></li>
<li>基于SpringJDBC手写ORM框架</li>
<li>SpringMVC九大组件</li>
<li>手写实现SpringMVC框架</li>
<li>SpringMVC与Struts2对比分析</li>
<li>Spring5新特性</li>
<li>动态代理</li>
</ul>
</li>
<li>mybatis<ul>
<li>代码自动生成器</li>
<li>关联查询、嵌套 查询</li>
<li>缓存使用场景及选择策略</li>
<li>Spring集成下的SqlSession与Mapper</li>
<li>事务</li>
<li>分析MyBatis的动态代理</li>
<li>手写实现Mini版的MyBatis</li>
</ul>
</li>
<li>tomcat<ul>
<li>参考<ul>
<li><a href="https://www.cnblogs.com/hggen/p/6264475.html">《TOMCAT原理详解及请求过程》</a></li>
<li><a href="https://www.cnblogs.com/crazylqy/p/4706223.html">《Tomcat服务器原理详解》</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/">《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》</a></li>
<li><a href="https://blog.csdn.net/xlgen157387/article/details/79006434">《四张图带你了解Tomcat系统架构》</a></li>
<li><a href="https://www.futurehosting.com/blog/jboss-vs-tomcat-choosing-a-java-application-server/">《JBoss vs. Tomcat: Choosing A Java Application Server》</a><ul>
<li>Tomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Srping。</li>
<li>Jboss 实现全部了JEE特性，软件开源免费、文档收费。</li>
<li><a href="https://www.cnblogs.com/sunfenqing/p/7339058.html">《Tomcat 调优方案》</a></li>
<li>启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）；</li>
<li><a href="http://blog.chinaunix.net/uid-20662363-id-3012760.html">《tomcat http协议与ajp协议》</a></li>
<li><a href="http://dmouse.iteye.com/blog/1354527">《AJP与HTTP比较和分析》</a><ul>
<li>AJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。</li>
<li>并发高时，AJP协议优于HTTP协议。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>类加载机制</li>
</ul>
</li>
<li>Jetty<ul>
<li>参考<ul>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-jetty/">《Jetty 的工作原理以及与 Tomcat 的比较》</a></li>
<li><a href="https://blog.csdn.net/doutao6677/article/details/51957288">《jetty和tomcat优势比较》</a></li>
</ul>
</li>
</ul>
</li>
<li>hibernate</li>
</ul>
</li>
<li>源码</li>
<li>Guava</li>
</ul>
<h3><span id="脚本语言">脚本语言</span></h3><ul>
<li>python</li>
<li>shell</li>
</ul>
<h2><span id="架构">架构</span></h2><h3><span id="微服务">微服务</span></h3><ul>
<li>微框架<ul>
<li>与微服务之间的关系</li>
<li>热部署实战</li>
<li>核心组件Starter\Actuator\AutoConfiguration\Cli</li>
<li>集成Mybatis实现多数据源路由实战</li>
<li>集成Dubbo实战</li>
<li>集成Redis缓存实战</li>
<li>集成Swagger2实战</li>
<li>API管理及测试体系</li>
<li>实现多环境配置动态解析</li>
</ul>
</li>
<li>SpringCloud<ul>
<li>注册中心<ul>
<li>Eureka</li>
<li>Zookeeper</li>
</ul>
</li>
<li>Ribbon集成REST实现负载均衡</li>
<li>Fegion生命是服务调用</li>
<li>Hystrix服务熔断降级方式</li>
<li>Zuul实现微服务网管</li>
<li>Config分布式统一配置中心（与disconf作对比）</li>
<li>Sleuth调用链路跟踪</li>
<li>BUS消息总线</li>
<li>基于Hystrix实现接口降级实战</li>
<li>集成SpringCloud实现统一整合方案</li>
</ul>
</li>
<li><p>Docker虚拟化</p>
<ul>
<li>Docker的镜像、仓库、容器</li>
<li>Docker File文件</li>
<li>Docker Compose</li>
<li>Swarm K8s</li>
</ul>
</li>
<li><p>漫谈微服务架构</p>
<pre><code>\-  SOA架构和微服务架构之间的区别和联系
\- 如何设计微服务及设计原则
\- 全局分析Spring Cloud各个组件所能解决的问题
</code></pre><h3><span id="分布式">分布式</span></h3></li>
<li><p>分布式架构原理</p>
<ul>
<li>分布式架构严谨过程</li>
<li>如何把应用从单机扩展到分布式</li>
<li>CDN加速静态文件访问</li>
<li>系统监控、容灾、存储动态扩容</li>
<li>架构设计及业务驱动划分</li>
<li>CAP原理和BASE理论</li>
</ul>
</li>
<li>分布式架构策略<ul>
<li>分布式架构网络通信原理剖析</li>
<li>通信协议中的序列化和反序列化</li>
<li>基于框架的RPC技术<ul>
<li>WebService、RMI、Hession</li>
</ul>
</li>
<li>深入分析Zookeeper在disconf配置中心的应用</li>
<li>基于Zookeeper实现分布式服务器动态上下线感知</li>
<li>深入分析Zookeeper Zab协议及选举机制源码解读</li>
<li>Dubbo管理中心及监控平台安装部署</li>
<li>基于Dubbo的分布式系统架构实战</li>
<li>Dubbo容错机制及高扩展性分析</li>
</ul>
</li>
<li>分布式架构中间件<ul>
<li>分布式消息通信</li>
<li>ActiveMq\Kafka\RabbitMQ</li>
<li>Redis主从复制原理及无磁盘复制分析</li>
<li>图解Redis中AOF和RDB持久化策略的原理</li>
<li>MongoDb企业级集群解决方案</li>
<li>MongoDb数据分片、转存及恢复策略</li>
<li>基于OpenResty部署应用层Nginx以及Nginx+lua实践</li>
<li>Nginx反向代理服务器及负载均衡服务配置实战</li>
<li>基于Netty实现高性能IM聊天</li>
<li>基于Netty实现Dubbo多协议通信支持</li>
<li>Netty无锁化串行设计及高并发处理机制</li>
</ul>
</li>
<li>分布式架构实战<ul>
<li>分布式全局ID生成方案</li>
<li>Session跨域共享及企业级单点登录解决方案实战</li>
<li>分布式事务解决方案实战</li>
<li>高并发下的服务降级、限流实战</li>
<li>基于分布式架构下的分布式锁的解决方案实战</li>
<li>分布式架构下实现分布式定时调度</li>
</ul>
</li>
<li>NoSql和KV存储(redis,hbase,mongodb,etcd,springcloud)</li>
<li>负载均衡(原理，cdn，一致性hash)</li>
<li>RPC框架<ul>
<li>通信 netty</li>
<li>序列化协议 thrift，protobuff</li>
</ul>
</li>
<li>消息队列<ul>
<li>原理</li>
<li>kafka</li>
<li>activeMQ</li>
<li>rocketMQ</li>
</ul>
</li>
<li>分布式存储系统<ul>
<li>GFS</li>
<li>HDFS</li>
<li>fastDFS</li>
<li>存储模型<ul>
<li>skipList</li>
<li>LSM</li>
</ul>
</li>
</ul>
</li>
<li>分布式事务<ul>
<li>redis分布锁</li>
</ul>
</li>
<li><p>分布式锁</p>
<h3><span id="大数据">大数据</span></h3></li>
<li><p>hadoop生态圈</p>
<ul>
<li>hive</li>
<li>hbase</li>
<li>hdfs</li>
<li>zoopkeeper</li>
<li>storm</li>
<li>kafka</li>
</ul>
</li>
<li>spark</li>
<li>搜索引擎与技术</li>
<li>机器学习与技术</li>
<li>人工智能</li>
</ul>
<h3><span id="运维-amp-统计-amp-技术支持">运维 &amp; 统计 &amp; 技术支持</span></h3><ul>
<li><p>常规监控</p>
<ul>
<li><a href="https://blog.csdn.net/enweitech/article/details/77849205">《腾讯业务系统监控的修炼之路》</a><ul>
<li>监控的方式：主动、被动、旁路(比如舆情监控)</li>
<li>监控类型： 基础监控、服务端监控、客户端监控、 监控、用户端监控</li>
<li>监控的目标：全、块、准</li>
<li>核心指标：请求量、成功率、耗时</li>
</ul>
</li>
<li><p><a href="https://www.oschina.net/news/67525/monitoring-tools">《开源还是商用？十大云运维监控工具横评》</a></p>
<blockquote>
<p>Zabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。</p>
</blockquote>
</li>
<li><p><a href="http://developer.51cto.com/art/201612/525373.htm">《监控报警系统搭建及二次开发经验》</a></p>
</li>
</ul>
</li>
<li><p>命令行监控工具</p>
<ul>
<li><a href="https://coderxing.gitbooks.io/architecture-evolution/di-er-pian-ff1a-feng-kuang-yuan-shi-ren/44-an-quan-yu-yun-wei/445-fu-wu-qi-zhuang-tai-jian-ce/4451-ming-ling-xing-gong-ju.html">《常用命令行监控工具》</a></li>
<li><a href="http://blog.jobbole.com/96846/">《20个命令行工具监控 Linux 系统性能》</a></li>
<li><a href="https://my.oschina.net/feichexia/blog/196575">《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》</a></li>
<li><a href="https://earyant.github.io/2018/05/04/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">日志分析常用命令</a></li>
<li><a href="https://earyant.github.io/2018/05/04/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E8%84%9A%E6%9C%AC/">日志分析脚本</a></li>
</ul>
</li>
<li><p>统计分析</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/25195217">《流量统计的基础：埋点》</a><blockquote>
<p>常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度</p>
</blockquote>
</li>
<li><a href="http://www.25xt.com/company/17066.html">《APP埋点常用的统计工具、埋点目标和埋点内容》</a><blockquote>
<p>第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。</p>
</blockquote>
</li>
<li><a href="https://tech.meituan.com/mt-mobile-analytics-practice.html">《美团点评前端无痕埋点实践》</a><blockquote>
<p>所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>持续集成(CI/CD)</p>
<ul>
<li><a href="http://www.ruanyifeng.com/blog/2015/09/continuous-integration.html">《持续集成是什么？》</a></li>
<li><a href="https://www.testwo.com/article/1170">《8个流行的持续集成工具》</a></li>
<li><a href="https://www.liaoxuefeng.com/article/001463233913442cdb2d1bd1b1b42e3b0b29eb1ba736c5e000">《使用Jenkins进行持续集成》</a></li>
</ul>
</li>
<li>环境分离<ul>
<li><a href="https://my.oschina.net/sancuo/blog/214904">《开发环境、生产环境、测试环境的基本理解和区》</a></li>
</ul>
</li>
</ul>
<h3><span id="测试">测试</span></h3><ul>
<li>TDD 理论<ul>
<li>-<a href="https://www.jianshu.com/p/62f16cd4fef3">《深度解读 - TDD（测试驱动开发）》</a><ul>
<li>基于测试用例编码功能代码，XP（Extreme Programming）的核心实践.</li>
<li>好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈；</li>
</ul>
</li>
</ul>
</li>
<li>单元测试<ul>
<li><a href="https://www.cnblogs.com/happyzm/p/6482886.html">《Java单元测试之JUnit篇》</a></li>
<li><a href="TestNG 覆盖 JUnit 功能，适用于更复杂的场景。">《JUnit 4 与 TestNG 对比》</a></li>
<li><a href="模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。">《单元测试主要的测试功能点》</a></li>
</ul>
</li>
<li>压力测试<ul>
<li><a href="https://blog.csdn.net/blueheart20/article/details/52170790">《Apache ab 测试使用指南》</a></li>
<li><a href="https://www.cnblogs.com/binyue/p/6141088.html">《大型网站压力测试及优化方案》</a></li>
<li><a href="http://news.chinabyte.com/466/14126966.shtml">《10大主流压力/负载/性能测试工具推荐》</a></li>
<li><a href="http://quentinxxz.iteye.com/blog/2249799">《真实流量压测工具 tcpcopy应用浅析》</a></li>
<li><a href="https://www.cnblogs.com/jwentest/p/7136727.html">《nGrinder 简易使用教程》</a></li>
</ul>
</li>
<li>全链路压测<ul>
<li><a href="http://www.infoq.com/cn/articles/jd-618-upgrade-full-link-voltage-test-program-forcebot">《京东618：升级全链路压测方案，打造军演机器人ForceBot》</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/30306892">《饿了么全链路压测的探索与实践》</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28355759">《四大语言，八大框架｜滴滴全链路压测解决之道》</a></li>
<li><a href="https://www.jianshu.com/p/27060fd61f72">《全链路压测经验》</a></li>
</ul>
</li>
<li>A/B 、灰度、蓝绿测试<ul>
<li><a href="https://testerhome.com/topics/11165">《技术干货 | AB 测试和灰度发布探索及实践》</a></li>
<li><a href="http://blog.51cto.com/purplegrape/1403123">《nginx 根据IP 进行灰度发布》</a></li>
<li><a href="https://www.v2ex.com/t/344341">《蓝绿部署、A/B 测试以及灰度发布》</a></li>
</ul>
</li>
</ul>
<h2><span id="书单">书单</span></h2><ul>
<li>算法与数据结构<ul>
<li>数据结构（严蔚敏）/大话数据结构              * 剑指Offer/程序员面试金典/编程珠玑/编程之美/牛客网+leetcode</li>
<li>程序员笔试面试最优解（左程云）/不如直接看左神的笔试面试指南视频</li>
<li>数据结构与算法经典问题解析（Java语言描述）</li>
<li>图解数据结构（使用Java）</li>
</ul>
</li>
<li>计算机网络：<ul>
<li>计算机网络（谢希仁）</li>
<li>TCP/IP 详解</li>
<li>HTTP权威指南</li>
<li>图解TCP/IP</li>
<li>图解HTTP</li>
</ul>
</li>
<li>数据库：//数据库主要是多用，书上主要看索引和性能的部分<ul>
<li>高性能MySQL/深入浅出MySQL</li>
</ul>
</li>
<li>操作系统：<ul>
<li>OS原理：操作系统（课本，黑色的那个）</li>
<li>Linux：<ul>
<li>Linux私房菜 //鸟哥写的，很全，包括bash部分</li>
<li>跟阿铭学Linux //主要偏重于命令和操作，比较浅显</li>
</ul>
</li>
</ul>
</li>
<li>java：<ul>
<li>Java疯狂讲义/Java编程思想/Java核心技术 卷1</li>
<li>深入理解Java虚拟机</li>
<li>并发编程的艺术/多线程编程核心技术</li>
<li>Effective Java</li>
<li>Java程序员面试笔试宝典 //何昊的那本，个人感觉是突击知识点的神器</li>
<li>Java程序性能优化</li>
<li>实战Java高并发程序设计</li>
</ul>
</li>
<li>Java Web：<ul>
<li>Spring实战/轻量级JavaEE 企业应用（红皮，讲SSH的） //主要看最后一部分Spring的就可以</li>
<li>深入JavaWeb技术内幕（阿里 许令波）//这个讲的还是比较深的</li>
<li>SpringBoot实战/深入实践SpringBoot</li>
</ul>
</li>
<li>设计模式：<ul>
<li>大话设计模式 //通俗易懂</li>
<li>各类博客的总结</li>
</ul>
</li>
<li>分布式与大数据：<ul>
<li>分布式服务框架原理与实践</li>
<li>大型网站技术架构</li>
<li>Hadoop实战（hadoop体系包括得很全）</li>
</ul>
</li>
<li>其他：<ul>
<li>Git：<ul>
<li>Git权威指南</li>
<li>Git官方讲解视频（牛客网有带字幕的）</li>
</ul>
</li>
<li>Redis：<ul>
<li>Redis实战</li>
</ul>
</li>
</ul>
</li>
<li>docker</li>
<li>springcloud</li>
</ul>
<h2><span id="实战">实战</span></h2><h3><span id="实践一个双十一电商项目">实践一个双十一电商项目</span></h3><ul>
<li>用户认证<ul>
<li>用户注册</li>
<li>SSO单点登录</li>
<li>第三方登陆</li>
<li>UI界面拦截</li>
<li>业务拦截</li>
</ul>
</li>
<li>店铺、商品<ul>
<li>聚合检索</li>
<li>动静分离</li>
<li>店铺管理</li>
<li>商品管理</li>
</ul>
</li>
<li>订单、支付<ul>
<li>订单号统一生成规则</li>
<li>下单流程管理</li>
<li>库存管理</li>
<li>购物车</li>
<li>优惠券支付</li>
<li>积分支付</li>
<li>第三方支付</li>
</ul>
</li>
<li>数据统计分析<ul>
<li>用户行为分析</li>
<li>行业分析</li>
<li>区域分析</li>
</ul>
</li>
<li>通知推送<ul>
<li>融云推送</li>
<li>消息中间件</li>
<li>用户群聊</li>
<li>点对点聊天</li>
<li>文件断点续传</li>
</ul>
</li>
</ul>
<p>感谢：<br><a href="https://www.nowcoder.com/discuss/29890?hmsr=toutiao.io&amp;source=rss&amp;utm-medium=toutiao.io&amp;utm-source=toutiao.io">这可能不只是一篇面经</a><br><a href="https://github.com/kdn251/interviews/blob/master/README-zh-cn.md">java整理</a><br><a href="https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98">后端架构师技术图谱</a><br><a href="https://github.com/sorenduan/awesome-java-books.git">java书籍推荐</a></p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>java知识整理</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习知识整理</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote>
<p>机器学习相关知识点整理，</p>
</blockquote>
<!-- toc -->
<ul>
<li><a href="#编程语言相关">编程语言相关</a><ul>
<li><a href="#java">java</a></li>
<li><a href="#python">python</a></li>
</ul>
</li>
<li><a href="#数学基础">数学基础</a><ul>
<li><a href="#抽样方法">抽样方法</a><ul>
<li><a href="#1分层抽样的适用范围">1.分层抽样的适用范围？</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#机器学习相关">机器学习相关</a><ul>
<li><a href="#线性回归和lr">线性回归和LR</a></li>
<li><a href="#gbdt-xgboost相关">gbdt、xgboost相关</a></li>
<li><a href="#rf相关">RF相关</a></li>
<li><a href="#kmeans相关">kmeans相关</a></li>
<li><a href="#em-hmm-crf相关">EM HMM CRF相关</a></li>
<li><a href="#决策树相关">决策树相关</a></li>
<li><a href="#svm相关">SVM相关</a></li>
<li><a href="#降维算法相关">降维算法相关</a><ul>
<li><a href="#各种ml模型比较">各种ML模型比较</a></li>
</ul>
</li>
<li><a href="#其他">其他</a></li>
</ul>
</li>
<li><a href="#深度学习相关">深度学习相关</a></li>
<li><a href="#自然语言处理相关">自然语言处理相关</a></li>
<li><a href="#手撕算法场景题">手撕算法&amp;场景题</a></li>
<li><a href="#面经分享">面经分享</a></li>
<li><a href="#一些有用的知识整理">一些有用的知识整理</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="编程语言相关">编程语言相关</span></h1><h2><span id="java">java</span></h2><p>java语言相关请看<a href="/posts/java/java语言基础/java整理/">这里</a></p>
<h2><span id="python">python</span></h2><ul>
<li>python内存机制<ul>
<li>引用计数，垃圾回收，内存池 </li>
<li><a href="https://www.cnblogs.com/geaozhang/p/7111961.html">https://www.cnblogs.com/geaozhang/p/7111961.html</a> </li>
</ul>
</li>
<li>python中dictionary，set的底层原理 <ul>
<li>使用伪随机探测的散列表作为字典的底层数据结构</li>
</ul>
</li>
<li>介绍一下构造函数，析构函数，函数重载(面向对象这一块的知识)<ul>
<li><code>__metaclass__</code> 元类方法，在创建类的时候执行 </li>
<li><code>__new__</code> 是一个静态方法，返回一个创建的实例</li>
<li><code>__init__</code>构造函数，在初始化实例的时候会执行，没有返回</li>
<li><code>__del__</code>析构函数，被python垃圾回收器销毁的时候调用</li>
<li>python中不需要函数重载</li>
</ul>
</li>
<li>解释python元类？<ul>
<li>首先理解python中的类也是对象</li>
<li>元类就是用来创建类的（type()就是python在背后用来创建所有类的元类）</li>
</ul>
</li>
<li>python的静态方法，类方法和实例方法？<ul>
<li>实例方法就是一般的方法，需要先将类实例化后调用，关键字<code>self</code></li>
<li>静态方法(staticmethod)不需要创建类的实例就可以调用，没有关键字</li>
<li>类方法(classmethod)可以使用类和实例调用，关键字<code>cls</code></li>
</ul>
</li>
<li>python自省？<ul>
<li>自省就是运行时能知道对象的类型，比如type(), dir(), getattr(), hasattr(), isinstance()</li>
</ul>
</li>
<li>新式类和旧式类？<ul>
<li><a href="https://www.cnblogs.com/btchenguang/archive/2012/09/17/2689146.html">https://www.cnblogs.com/btchenguang/archive/2012/09/17/2689146.html</a> </li>
</ul>
</li>
<li>python里的拷贝（引用，copy(),deepcopy()）<ul>
<li>引用， <code>b=a</code>，a改变b也改变</li>
<li>copy(), 浅拷贝，拷贝父对象，但不会拷贝对象的内部子对象</li>
<li>deepcopy(), 深拷贝，完全拷贝父对象及其子对象</li>
</ul>
</li>
<li>python的is和=？<ul>
<li><code>is</code>是对比地址</li>
<li><code>=</code>是对比值</li>
</ul>
</li>
<li>python如何实现单例模式?请写出两种实现方式?</li>
<li>python中变量查找顺序？<ul>
<li>LEGB顺序，即<ul>
<li>local， 函数内部作用域</li>
<li>enclosing， 函数内部与内嵌函数之间</li>
<li>global， 全局作用域</li>
<li>build-in， 内置作用域</li>
</ul>
</li>
</ul>
</li>
<li>请描述抽象类和接口类的区别和联系？</li>
<li>python中的进程和线程<ul>
<li>进程：一个运行的程序（代码）就是一个进程，没有运行的代码叫程序，进程是系统资源分配的最小单位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大</li>
<li>线程: cpu调度执行的最小单位，也叫执行路径，不能独立存在，依赖进程存在，一个进程至少有一个线程，叫主线程，而多个线程共享内存（数据共享，共享全局变量),从而极大地提高了程序的运行效率。</li>
<li>协程: 是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操中栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。</li>
</ul>
</li>
</ul>
<h1><span id="数学基础">数学基础</span></h1><h2><span id="抽样方法">抽样方法</span></h2><h3><span id="1分层抽样的适用范围">1.分层抽样的适用范围？</span></h3><p>分层抽样利用事先掌握的信息， 充分考虑了保持样本结构和总体结构的一致性，当总体由差异明显的几部分组成的时候，适合用分层抽样。</p>
<h1><span id="机器学习相关">机器学习相关</span></h1><p>本目录主要按照不同算法整理机器学习相关面试知识点。</p>
<ul>
<li>常见的loss函数：<ul>
<li>平方损失函数（最小二乘法）<ul>
<li>$L(Y, f(X))=(Y-f(X))^{2}$</li>
</ul>
</li>
<li>对数损失函数（方便极大似然估计）<ul>
<li>$J(\theta)=-\frac{1}{m}\left[\sum<em>{i=1}^{m} y^{(i)} \log h</em>{\theta}\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]$`</li>
</ul>
</li>
<li>指数损失函数（Adaboost）<ul>
<li>$L(Y, f(X))=\frac{1}{n} \sum<em>{i=1}^{n} e^{-Y</em>{i} f\left(X_{i}\right)}$</li>
</ul>
</li>
<li>Hinge损失函数（SVM）<ul>
<li>$L(Y)=\max (0,1-t Y)$</li>
</ul>
</li>
<li>0-1损失<ul>
<li>$L(Y, f(X))=\left{\begin{array}{l}{1, Y \neq f(X)} \ {0, Y=f(X)}\end{array}\right.$</li>
</ul>
</li>
</ul>
</li>
<li>常见的优化算法：<ul>
<li><a href="https://blog.csdn.net/Kaiyuan_sjtu/article/details/85126721">https://blog.csdn.net/Kaiyuan_sjtu/article/details/85126721</a> </li>
</ul>
</li>
<li>常见的激活函数：<ul>
<li>sigmoid/tanh/relu/leaky relu/maxout/softmax</li>
</ul>
</li>
<li>常用的评价指标：<ul>
<li>precision（精确性、查准率）： 预测出的正确正样本数比上所有预测为正样本数</li>
<li>recall（召回率、查全率）:预测出的正确正样本数比上所有实际正样本数</li>
<li>F1: precision和recall的调和均值</li>
<li>ROC（Receiver Operating Characteristic）：<ul>
<li>横坐标伪正类率（False Positive Rate），预测为正但实际为负的样本占所有负样本的比例；</li>
<li>纵坐标真正类率（True Positive Rate），预测为正且实际为正的样本占所有正样本的比例；</li>
</ul>
</li>
<li>AUC：ROC曲线下的面积</li>
</ul>
</li>
<li>常用的距离度量方式<ul>
<li>欧式距离：$d<em>{a b}=\sqrt{\left(x</em>{1}-y<em>{1}\right)^{2}+\left(x</em>{2}-y_{2}\right)^{2}}$</li>
<li>曼哈顿距离：$d<em>{a b}=\left|x</em>{1}-y<em>{1}\right|+\left|x</em>{2}-y_{2}\right|$</li>
<li>余弦相似度：$\cos \theta=\frac{a^{<em>} b}{|a|^{</em>}|b|}=\frac{x<em>{1} * y</em>{1}+x<em>{2} * y</em>{2}}{\sqrt{x<em>{1}^{2}+x</em>{2}^{2}} * \sqrt{y<em>{1}^{2}+y</em>{2}^{2}}}$</li>
<li>切比雪夫距离：各对应坐标数值差的最大值，如平面两个向量$a=(x<em>{1}, y</em>{1}), b=(x<em>{2}, y</em>{2})$，其 $d<em>{a b}=\max \left{\left|x</em>{1}-x<em>{2}\right|,\left|y</em>{1}-y_{2}\right|\right}$</li>
<li>汉明距离：字符串对应位置的不同字符个数</li>
<li>编辑距离：两个字符串之间由一个转成另一个所需的最少编辑操作次数</li>
<li>Person相关系数：反应两个变量的线性相关性。</li>
<li>K-L散度：相对熵，$D(P | Q)=\sum_{i=1}^{n} P(i) \log \frac{P(i)}{Q(i)}$</li>
</ul>
</li>
</ul>
<h3><span id="线性回归和lr">线性回归和LR</span></h3><ul>
<li>对于LR模型，特征有<x1,x2,...,xn> 如果手误把第一个特征又加了一次变成了n+1个特征<x1,x2,...,xn,x1>请问会有什么影响？如果是加了一个噪声特征呢？<ul>
<li>冗余特征过多，训练过程越慢</li>
<li>会改变模型参数值，使得模型不稳定。极端假设所有特征均重复，则LR模型参数w会变为原来的1/2</li>
</ul>
</x1,x2,...,xn,x1></x1,x2,...,xn></li>
<li>逻辑回归损失函数为什么用极大似然？<ul>
<li>用最小二乘法目标函数就是平方损失的话是非凸函数，会有很多局部最优点 </li>
<li>用最大似然估计目标函数就是对数似然函数</li>
</ul>
</li>
<li>回归问题的损失函数都有哪些？从哪些角度设计一个合理的损失函数？<ul>
<li>绝对值损失，平方误差损失，huber损失等</li>
<li><a href="https://www.zhihu.com/question/68390722/answer/266034620">https://www.zhihu.com/question/68390722/answer/266034620</a></li>
</ul>
</li>
<li>逻辑回归VS线性回归？<ul>
<li>都属于广义线性模型</li>
<li>一个回归问题一个分类问题</li>
</ul>
</li>
</ul>
<h3><span id="gbdt-xgboost相关">gbdt、xgboost相关</span></h3><ul>
<li>xgboost和GBDT区别：<ul>
<li>基学习模型不同：GBDT使用的是CART，而xgb还支持线性分类器</li>
<li>优化方案不同：gbdt使用一阶导，xgb使用二阶泰勒展开</li>
<li>xgb支持自定义代价函数，但必须二阶可导</li>
<li>xgb加入了正则化项</li>
<li>列采样</li>
<li>xgb支持缺失值的处理，会自动学习出分裂方向</li>
<li>xgb支持并行，不是tree粒度的并行而是特征粒度的并行。提前将数据进行排序存在block结构中，后面迭代直接使用减少计算量。</li>
<li>近似直方图算法，用于高效的生成候选的分割点</li>
<li>xgb支持交叉验证，方便选取合最优参数，early stop</li>
</ul>
</li>
<li>xgb如何缓解过拟合？<ul>
<li>正则化：对树中叶子节点的数目L1正则，对叶子节点分数L2正则</li>
<li>列抽样：即特征抽样</li>
<li>shrinkage：类似学习率，在学习出每一颗树之后对这个树增加一个权重参数，减小其影响力，为后续的树提供空间去优化模型</li>
</ul>
</li>
<li>xgb如何调参？</li>
<li>xgb的特征重要性是怎么计算的？<ul>
<li>某个特征的重要性（feature score），等于它被选中为树节点分裂特征的次数的和</li>
</ul>
</li>
<li>adaboost流程？权重更新公式？<ul>
<li>加法模型+指数损失+前向分布算法的二类分类学习算法 </li>
<li>流程：<ul>
<li>初始化权重分布</li>
<li>计算基分类器在训练集上的分类误差率：$e<em>{m}=P\left(G</em>{m}\left(x<em>{i}\right) \neq y</em>{i}\right)=\sum<em>{i=1}^{N} w</em>{m i} I\left(G<em>{m}\left(x</em>{i}\right) \neq y_{i}\right)$</li>
<li>计算该分类器的对应系数：$\alpha<em>{m}=\frac{1}{2} \log \frac{1-e</em>{m}}{e_{m}}$`</li>
<li>更新训练集的权重分布：$w<em>{m+1, i}=\frac{w</em>{m i}}{Z<em>{m}} \exp \left(-\alpha</em>{m} y<em>{i} G</em>{m}\left(x_{i}\right)\right)$</li>
<li>重复2-4过程直至效果比较好</li>
<li>将所有基分类器加权求和</li>
</ul>
</li>
</ul>
</li>
<li>gbdt流程？<ul>
<li>加法模型+负梯度函数+前向分布算法 </li>
<li>流程：<ul>
<li>初始化基学习器：$f<em>{0}(x)=\arg \min </em>{c} \sum<em>{i=1}^{N} L\left(y</em>{i}, c\right)$</li>
<li>对迭代轮数1,2,…,M:<ul>
<li>对所有样本，计算负梯度：$r<em>{i m}=-\left[\frac{\partial L\left(y</em>{i}, f\left(x<em>{i}\right)\right)}{\partial f\left(x</em>{i}\right)}\right]<em>{f=f</em>{m-1}}$`</li>
<li>对$r<em>{i m}$拟合一个回归树，得到第m棵树的叶节点区域$R</em>{m j}$,  j=1,2,…,J</li>
<li>对j=1,2,…,J：计算$c<em>{m j}=\arg \min </em>{c} \sum<em>{x</em>{i} \in R<em>{m j}} L\left(y</em>{i}, f<em>{m-1}\left(x</em>{i}\right)+c\right)$</li>
<li>更新回归树：$f<em>{m}(x)=f</em>{m-1}(x)+\sum<em>{j=1}^{J} c</em>{m j} I\left(x \in R_{m j}\right)$</li>
</ul>
</li>
<li>得到最终回归树：$\hat{f}(x)=f<em>{M}(x)=\sum</em>{m=1}^{M} \sum<em>{j=1}^{J} c</em>{m j} I\left(x \in R_{m j}\right)$</li>
</ul>
</li>
</ul>
</li>
<li>xgb损失函数？推导？<ul>
<li>$\mathcal{L}(\phi)=\sum<em>{i} l\left(\hat{y}</em>{i}, y<em>{i}\right)+\sum</em>{k} \Omega\left(f_{k}\right)$，其中等式右侧第二项为正则化项：$\Omega(f)=\gamma T+\frac{1}{2} \lambda|w|^{2}$</li>
<li>损失函数的优化：<ul>
<li>$\mathcal{L}^{(t)}=\sum<em>{i=1}^{n} l\left(y</em>{i}, \hat{y}<em>{i}^{(t-1)}+f</em>{t}\left(\mathbf{x}<em>{i}\right)\right)+\Omega\left(f</em>{t}\right)$</li>
<li>$\mathcal{L}^{(t)} \simeq \sum<em>{i=1}^{n}\left[l\left(y</em>{i}, \hat{y}^{(t-1)}\right)+g<em>{i} f</em>{t}\left(\mathbf{x}<em>{i}\right)+\frac{1}{2} h</em>{i} f<em>{t}^{2}\left(\mathbf{x}</em>{i}\right)\right]+\Omega\left(f_{t}\right)$</li>
<li>$\tilde{\mathcal{L}}^{(t)}=\sum<em>{i=1}^{n}\left[g</em>{i} f<em>{t}\left(\mathbf{x}</em>{i}\right)+\frac{1}{2} h<em>{i} f</em>{t}^{2}\left(\mathbf{x}<em>{i}\right)\right]+\gamma T+\frac{1}{2} \lambda \sum</em>{j=1}^{T} w_{j}^{2}$</li>
<li>$w<em>{j}^{*}=-\frac{\sum</em>{i \in I<em>{j}} g</em>{i}}{\sum<em>{i \in I</em>{j}} h_{i}+\lambda}$</li>
</ul>
</li>
</ul>
</li>
<li>xgb节点分裂规则？<ul>
<li>$G=\frac{1}{2}\left[\frac{G<em>{L}^{2}}{H</em>{L}+\lambda}+\frac{G<em>{R}^{2}}{H</em>{R}+\lambda}-\frac{\left(G<em>{L}+G</em>{R}\right)^{2}}{\left(H<em>{L}+H</em>{R}\right)+\lambda}\right]-\gamma$</li>
</ul>
</li>
<li>xgb如何处理稀疏值？<ul>
<li>会分别计算将该样本分到左右子树两种情况的增益，选择增益大的进行分裂。</li>
<li>在测试时，如果出现缺失值，默认右子树</li>
</ul>
</li>
<li>为什么gbdt不适合处理sparse特征？<ul>
<li>对于高维稀疏数据，每棵树在进行分裂时，金辉选取一个特征，大部分特征是不会被选到的</li>
</ul>
</li>
<li>gbdt和lr的区别？<ul>
<li>都是监督学习，判别式模型</li>
<li>一个线性，一个非线性</li>
<li>lr可以选择一阶导数或者二阶优化，gbdt只有一阶</li>
<li>lr适合处理稀疏数据，gbdt适合稠密特征</li>
<li></li>
</ul>
</li>
<li>xgb的VC维？</li>
<li>为什么xgb加了二阶梯度会更好？<ul>
<li><a href="https://www.zhihu.com/question/61374305">xgboost是用二阶泰勒展开的优势在哪？</a></li>
<li>为什么引入二阶泰勒展开？统一损失函数求导的形式以支持自定义损失函数</li>
<li>为什么更好？类比牛顿法和SGD，二阶求导信息量更大，训练过程收敛更快更准确。</li>
</ul>
</li>
<li>lgb对比xgb和原始gbdt的优缺点是什么</li>
<li>xgb和LR关于特征的处理有什么区别？<ul>
<li>LR一般是离散值，而xgb可以连续</li>
<li>LR各个特征独立，xgb可以特征组合</li>
</ul>
</li>
</ul>
<h3><span id="rf相关">RF相关</span></h3><ul>
<li>RF变量重要性排序原理？<ul>
<li>平均不纯度的减少：对于每棵树，按照不纯度（gini/information entropy等)给特征排序，然后整个森林取平均</li>
<li>平均准确率的减少：测量每种特征对模型预测准确率的影响</li>
</ul>
</li>
</ul>
<h3><span id="kmeans相关">kmeans相关</span></h3><ul>
<li>KNN和kmeans的区别？<ul>
<li>KNN是有监督学习（分类/回归），kmeans是无监督学习（聚类）</li>
<li>k的含义：KNN中k表示找到距离样本X最近的k个点；kmeans表示人为定义将数据分为k个类别</li>
</ul>
</li>
<li>kmeans的基本流程：<ul>
<li>选取k个类的初始中心点</li>
<li>对所有点进行计算距离划分到最近的类</li>
<li>重新计算每一类的中心点</li>
<li>重新回到上述2，如果中心点没变则输出类别</li>
</ul>
</li>
<li>k值的选取？<ul>
<li>先验知识</li>
<li>Elbow method</li>
</ul>
</li>
<li>如何选取初始中心点？<ul>
<li><a href="https://www.cnblogs.com/pinard/p/6164214.html">https://www.cnblogs.com/pinard/p/6164214.html</a>   </li>
</ul>
</li>
<li>kmeans时间复杂度和空间复杂度？<ul>
<li>时间：O(NlogN)</li>
<li>空间： O(K*(M+N))</li>
</ul>
</li>
</ul>
<h3><span id="em-hmm-crf相关">EM HMM CRF相关</span></h3><ul>
<li>EM算法推导？jensen不等式确定的下界？<ul>
<li>EM算法就是含有隐变量的概率模型参数的极大似然估计</li>
<li><img data-src="http://ww1.sinaimg.cn/large/afd47e42ly1g26n7hu2r0j20f60pegoo.jpg" alt></li>
<li>Jensen不等式：<ul>
<li>对于凸函数：$E[f(X)] \geq f(E[X])$</li>
<li>对于凹函数：$E[f(X)] \leq f(E[X])$</li>
</ul>
</li>
<li>EM算法是收敛的，但是不能保证收敛到全局最优 </li>
<li>对初始值的选取敏感</li>
</ul>
</li>
<li>HMM和CRF的区别？<a href="https://www.zhihu.com/question/53458773">https://www.zhihu.com/question/53458773</a><ul>
<li>两者都可以用于序列模型</li>
<li>CRF是无向图，HMM是有向图</li>
<li>CRF是判别式模型，HMM是生成式模型</li>
<li>CRF没有假设，HMM有马尔科夫假设</li>
<li>CRF可以全局最优，HMM可能局部最优</li>
</ul>
</li>
<li>CRF模型优化目标，怎么训练的？<ul>
<li>CRF的三个问题以及解决思路</li>
</ul>
</li>
<li>HMM做了哪些独立性假设？<ul>
<li>有限历史假设：即当前状态仅仅与前一个状态有关</li>
<li>输出独立假设：即输出状态仅仅与当前的隐状态有关</li>
<li>齐次性假设：状态与时间无关</li>
</ul>
</li>
<li>viterbi算法原理<ul>
<li>动态规划求最大路径</li>
</ul>
</li>
</ul>
<h3><span id="决策树相关">决策树相关</span></h3><ul>
<li>信息增益、信息增益比、基尼系数的公式和原理<ul>
<li>信息增益：g=H(D)-H(D|A), 在特征选择时偏向于取值较多的特征,对应ID3算法，该算法只有树的生成，容易过拟合；</li>
<li>信息增益率：$g<em>{\mathrm{g}}(D, A)=\frac{g(D, A)}{H</em>{A}(D)} \quad, \quad \mathrm{H}<em>{A}(D)=-\sum</em>{i=1}^{n} \frac{\left|D<em>{\mathrm{i}}\right|}{|D|} \log </em>{2} \frac{\left|D_{\mathrm{i}}\right|}{|D|}$</li>
<li>gini指数：$\operatorname{Gini}(p)=\sum<em>{k=1}^{K} p</em>{k}\left(1-p<em>{k}\right)=1-\sum</em>{k=1}^{K} p_{k}^{2}$</li>
</ul>
</li>
<li>决策树的VC维<ul>
<li>VC维是描述模型复杂度的，模型假设空间越大，vc维越高</li>
<li><a href="http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/">http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/</a></li>
<li>VC = 节点数+1</li>
</ul>
</li>
<li>决策树怎么做特征离散化？<ul>
<li>可以采用二分法对连续属性离散化：$T_{a}=\left{\frac{a^{i}+a^{i+1}}{2} | 1 \leq i \leq n-1\right}$</li>
</ul>
</li>
<li>决策树的缺失值怎么处理？<ul>
<li>对于建树节点分裂过程缺失：对特征计算非缺失样本的熵然后乘上权重（非缺失样本占比）就是该特征最终的熵 </li>
<li>对于建树完成训练时缺失某个特征：将样本分配到每颗分裂出的子树中，然后乘上落入该子树的概率（即该子树中样本比上总样本）</li>
<li>对于预测过程：确定额的划分</li>
</ul>
</li>
<li>CART决策树的剪枝？<ul>
<li><a href="https://www.zhihu.com/question/22697086">https://www.zhihu.com/question/22697086</a></li>
</ul>
</li>
<li>CART回归树是怎么做节点划分的？<ul>
<li>采用启发式的方法 </li>
</ul>
</li>
<li>CART为什么采用gini指数作为特征划分标准？<ul>
<li>信息增益(比)是基于信息论为熵模型的，会涉及大量的对数运算。而基尼系数和熵之半的曲线非常接近，都可以近似代表分类误差率</li>
</ul>
</li>
</ul>
<h3><span id="svm相关">SVM相关</span></h3><ul>
<li>SVM推导</li>
<li>SVM损失函数？<ul>
<li>hinge：$L(y)=\max (0,1-t \cdot y)$</li>
<li>表示当样本点被分类正确且函数间隔大于1时，损失为0；否则损失为$1-t \cdot y$</li>
</ul>
</li>
<li>为什么要使用hinge loss？<ul>
<li>只考虑支持向量的影响</li>
</ul>
</li>
<li>SVR原理</li>
<li>核函数原理、哪些地方引入、如何选择？<ul>
<li>$\mathrm{K}(\mathrm{x}, \mathrm{z})=&lt;\Phi(\mathrm{x}), \Phi(\mathrm{Z})&gt;$</li>
<li><a href="https://www.zhihu.com/question/24627666">https://www.zhihu.com/question/24627666</a></li>
<li>核函数的作用就是一个从低维到高维的映射</li>
<li>线性：$K\left(v<em>{1}, v</em>{2}\right)=<v_{1}, v_{2}>$</v_{1},></li>
<li>多项式：$K\left(v<em>{1}, v</em>{2}\right)=\left(\gamma<v_{1}, v_{2}>+c\right)^{n}$</v_{1},></li>
<li>RBF：$K\left(v<em>{1}, v</em>{2}\right)=\exp \left(-\gamma\left|v<em>{1}-v</em>{2}\right|^{2}\right)$</li>
<li>sigmoid：$K\left(v<em>{1}, v</em>{2}\right)=\tanh \left(\gamma<v_{1}, v_{2}>+c\right)$</v_{1},></li>
<li>如果特征维数很大（跟样本数量差不多），优先选用线性；如果特征数量小，样本数量一般，选用高斯核；如果特征数量小，样本数量很大，手工添加一些feature变成第一种情况。</li>
</ul>
</li>
<li>为什么需要转成对偶形式？<ul>
<li>原问题是一个凸二次规划问题   </li>
<li>优化了复杂度。由求特征向量w转化为求比例系数</li>
<li>可以方便引出核函数</li>
</ul>
</li>
<li>线性回归的梯度下降和牛顿法求解公式的推导</li>
<li>最速下降法和共轭梯度法 wolfe条件 最速下降法和共轭梯度法的收敛速度如何判断<ul>
<li>最速下降法即梯度下降：一阶信</li>
<li>共轭梯度法：介于最速下降和牛顿法之间的一种优化方法，仅需要一阶导数信息（方向限制在初始点的共轭区间内），但收敛速度较快，同时避免了牛顿法求Hessian矩阵的缺点</li>
<li>wolfe条件：跟line search有关</li>
</ul>
</li>
<li>LDA中有哪些分布？定义？什么是共轭分布？<ul>
<li>共轭分布：在贝叶斯统计中，如果先验分布和后验分布属于同一类分布，则成这俩为共轭分布</li>
<li>LDA过程：<ul>
<li>从狄利克雷分布D(a)中采样生成文档的主题分布$\theta_{i}$</li>
<li>从主题$\theta<em>{i}$的多项式分布中采样生成文档第j个词的主题$z</em>{i, j}$</li>
<li>从狄利克雷分布D(b)中采样生成主题$z<em>{i, j}$对应的词语分布$\phi</em>{\tilde{z}_{i, j}}$</li>
<li>从词语的多项式分布中采样生成最终词语$w_{i, j}$</li>
</ul>
</li>
</ul>
</li>
<li>k折交叉验证中k取值？<ul>
<li>从偏差和方差角度回答： <ul>
<li>当k取值很小时，比如k=2，此时模型训练数据较少，不容易拟合正确，所以偏差较高，方差较低</li>
<li>当k取值较大时，比如k=n，此时相当于所有数据都用于训练，容易过拟合，所以偏差低，方差高</li>
</ul>
</li>
<li>论文给出k值参考公式：k=log(N)，N为样本总数</li>
</ul>
</li>
<li>KKT条件？（L为拉格朗日函数，g(x), h(x)为约束函数）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$$\left\&#123;\begin&#123;array&#125;&#123;l&#125;&#123;\nabla_&#123;x&#125; L=0&#125; \\ &#123;\mu g(x)=0&#125; \\ &#123;h(x)=0&#125; \\ &#123;g(x) \leq 0&#125; \\ &#123;\lambda \neq 0&#125; \\ &#123;\mu \geq 0&#125;\end&#123;array&#125;\right.$$</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3><span id="降维算法相关">降维算法相关</span></h3><ul>
<li>常见降维方法：L1，PCA, LDA t-SNE</li>
<li>什么是主成分？</li>
<li>PCA是一种无监督的降维方法，为了让映射后的样本具有最大的发散性（即尽可能少的重叠，保留原有信息）；</li>
<li>LDA是一种有监督的降维方法，为了让映射后的样本具有最好的分类性能（即类内方差最小，类间方差最大）</li>
<li>局部线性嵌入(LLE)是一种非线性降维算法，能够使降维后的数据较好地保持原有流形结构。</li>
</ul>
<h5><span id="各种ml模型比较">各种ML模型比较</span></h5><ul>
<li>逻辑回归VS线性回归？<ul>
<li>都属于广义线性模型</li>
<li>一个回归问题一个分类问题</li>
</ul>
</li>
<li>SVM和LR逻辑回归？<ul>
<li>都属于线性分类算法，判别模型，监督学习</li>
<li>损失函数不同</li>
<li>确定决策边界时考虑的训练点不同</li>
<li>SVM有核函数，LR虽然也可以用但是一般不适用</li>
<li>SVM自带正则项</li>
</ul>
</li>
</ul>
<h3><span id="其他">其他</span></h3><ul>
<li>谈谈牛顿法？牛顿法如何优化的？<ul>
<li>牛顿法迭代公式：$x<em>{k+1}=x</em>{k}-\frac{f^{\prime}\left(x<em>{k}\right)}{f^{\prime \prime}\left(x</em>{k}\right)}$,优点是二阶导收敛速度快，但是需要就算hessian矩阵的逆，计算复杂</li>
<li>优化：拟牛顿法，使用正定矩阵来近似Hessian矩阵的逆</li>
</ul>
</li>
<li>交叉熵损失函数公式？怎么推导得到的？<ul>
<li>公式： $L=\sum_{i=1}^{N} y^{(i)} \log \hat{y}^{(i)}+\left(1-y^{(i)}\right) \log \left(1-\hat{y}^{(i)}\right)$</li>
<li>推导：<ul>
<li>$P(y=1 | x)= \hat{y}$</li>
<li>$P(y=0 | x)=1- \hat{y}$</li>
<li>$P(y|x)=\hat{y}^{y} \cdot(1-\hat{y})^{1-y}$</li>
<li>log化：$\log P(y | x)=\log \left(\hat{y}^{y} \cdot(1-\hat{y})^{1-y}\right)=y \log \hat{y}+(1-y) \log (1-\hat{y})$</li>
<li>求log化的最大值，前面加个负号就是求最小值，就是交叉熵的公式了</li>
</ul>
</li>
</ul>
</li>
<li>mapreduce原理<ul>
<li>map和reduce两个过程：分而治之</li>
</ul>
</li>
<li>共线性的特征会对模型产生怎样的影响？<ul>
<li>LR中特征强相关，不会影响最优性，但是会造成权重的数值解不稳定性（即模型系数每次都不一样）</li>
</ul>
</li>
<li>朴素贝叶斯公式，先验概率，后验概率，条件概率<ul>
<li>贝叶斯公式：$P\left(Y | X\right)=\frac{P\left(X | Y\right) P\left(Y\right)}{ P(Y)}$</li>
</ul>
</li>
<li>各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。<ul>
<li><a href="https://www.zhihu.com/question/26726794">https://www.zhihu.com/question/26726794</a> </li>
</ul>
</li>
<li>如何解决L1不可导问题？<ul>
<li>L1能产生稀疏解，而且稀疏解的泛化能力比较好</li>
<li>subgradient: 绝对值函数只有在零点是不可导的，可以把abs的导数定义成符号函数sgn</li>
<li>proximal gradient：</li>
</ul>
</li>
<li>L0，L1，L2正则化<ul>
<li>L0正则化的值是模型参数中非零参数的个数，L0很难优化求解是NP难问题</li>
<li>L1对应拉普拉斯分布</li>
<li>L2对应高斯分布</li>
</ul>
</li>
<li>哪些常用的分类器是有VC维的，怎么计算？<ul>
<li>线性分类器： d+1</li>
<li>高斯核分类器： 无穷</li>
<li>神经网络：参数数量</li>
<li>决策树：节点数+1</li>
</ul>
</li>
<li>特征选择方法？<ul>
<li>皮尔森相关系数：<ul>
<li>协方差和标准差比值：$\rho<em>{X, Y}=\frac{\operatorname{cov}(X, Y)}{\sigma</em>{X} \sigma_{Y}}$</li>
<li>衡量两个变量之间的线性关系，取值[-1,1]，对非线性有明显缺陷</li>
</ul>
</li>
<li>卡方检验<ul>
<li>表示自变量对应变量的相关性：$\chi^{2}=\sum \frac{(A-E)^{2}}{E}$</li>
</ul>
</li>
<li>互信息<ul>
<li>$I(X ; Y)=\sum<em>{x \in X} \sum</em>{y \in Y} p(x, y) \log \frac{p(x, y)}{p(x) p(y)}$</li>
</ul>
</li>
<li>基于惩罚项的特征选择<ul>
<li>L1正则</li>
</ul>
</li>
<li>基于学习模型的特征排序<ul>
<li>RF，GBDT，xgboost</li>
</ul>
</li>
</ul>
</li>
<li>最大似然估计(MLE)VS最大后验估计(MAP)<ul>
<li>MLE： $\hat{\theta}_{\mathrm{MLE}}=\arg \max P(X |  \theta)$，但由于连乘会造成浮点下溢，通常使用最大化对数形式</li>
<li>MAP: $\hat{\theta}<em>{\mathrm{MAP}}=\underset{\theta}{\operatorname{argmax}} P(\theta | X)=\underset{\theta}{\operatorname{argmax}} \frac{P(X | \theta) P(\theta)}{P(X)} \propto \operatorname{argmax}</em>{\theta} P(X | \theta) P(\theta)$</li>
<li>MLE是频率派的思想，认为参数$\theta$是固定的；而MAP是贝叶斯派的思想，认为参数符合某种概率分布（先验概率）</li>
<li>MLE可以认为是经验风险最小化，MAP可以认为是结构风险最小化</li>
</ul>
</li>
<li>判别式模型 VS 生成式模型？<ul>
<li>判别式，无向图，求解的是条件概率，如LR,SVM,NN,CRF等</li>
<li>生成式，有向图，求解的是联合概率，如HMM,NB,LDA等</li>
<li>由生成式模型可以得到判别式模型，但反之不行</li>
</ul>
</li>
<li>模型融合？原理？怎么选融合的模型？<ul>
<li>模型融合的方法有：voting/averaging/bagging/boosting/stacking等</li>
<li>stacking融合：交叉验证+拼接；<a href="https://blog.csdn.net/u011630575/article/details/81302994">https://blog.csdn.net/u011630575/article/details/81302994</a></li>
<li>融合模型要求： 好而不同。要求模型效果优秀且各模型个体之间尽量不同（如模型类型，模型超参数等）</li>
</ul>
</li>
</ul>
<h1><span id="深度学习相关">深度学习相关</span></h1><p>本目录主要整理深度学习相关面试知识点。</p>
<ul>
<li>深度学习神经网络为什么不用牛顿法而使用梯度下降？<ul>
<li>数据量大： 牛顿法所需统计量（梯度Hessian矩阵等）不可能每一次迭代都使用全部样本</li>
<li>维度高：参数多，导致hessian矩阵巨大</li>
<li>非凸性：牛顿法会受限于鞍点。sgd一定会收敛，但牛顿法不一定会收敛</li>
<li>…</li>
</ul>
</li>
<li>Batch-norm层的作用？<ul>
<li>使网络中每层输入数据的分布相对稳定，加速模型学习速度</li>
<li>使模型对网络中的参数不那么敏感，网络学习更稳定</li>
<li>缓解梯度消失问题</li>
<li>具有一定的正则化效果</li>
<li>…</li>
</ul>
</li>
<li>残差网络的作用？<ul>
<li>解决深度网络的退化问题</li>
<li>解决梯度弥散问题</li>
<li>…</li>
</ul>
</li>
<li>网络初始化有哪些方式，他们的公式 初始化过程？</li>
<li>优化方法 SGD、Adam算法过程 动量算法过程</li>
<li></li>
</ul>
<h1><span id="自然语言处理相关">自然语言处理相关</span></h1><ul>
<li>word2vec原理</li>
<li>glove原理？模型推导？<ul>
<li>思路是将全局词-词共现矩阵进行分解，训练得到词向量</li>
<li>目标函数： $J=\sum<em>{i, j=1}^{V} f\left(X</em>{i j}\right)\left(w<em>{i}^{T} \tilde{w}</em>{j}+b<em>{i}+\tilde{b}</em>{j}-\log X_{i j}\right)^{2}$</li>
<li>$X_{ij}$表示单词j出现在单词i上下文中的次数</li>
</ul>
</li>
<li>fasttext原理<ul>
<li>模型框架类似于Word2vec的CBOW,但是也有区别：<ul>
<li>输入：word2vec用的是上下文单词的one-hot编码；fasttext用的是一个sentence的单词向量同时包括subword, 字符级别n-gran向量</li>
<li>中间层：word2vec使用的是求和；fasttext使用的是平均；</li>
<li>输出：cbow输出目标词汇；fasttext输出文本分类标签</li>
</ul>
</li>
<li>速度快，使用层次softmax，对oov友好 </li>
<li>有监督的文本分裂，无监督的词向量学习</li>
</ul>
</li>
<li>glove和word2vec区别：<ul>
<li>g是基于全局语料的，w是基于滑动窗口局部语料的；因此w可以进行在线学习，而g则需要固定语料信息</li>
<li>目标函数不一样</li>
<li>g更快，对于高频词的处理更有效</li>
</ul>
</li>
<li>LDA的词表示和word2vec的词表示有什么区别？<ul>
<li>LDA出来的词向量不如word2vec的精细，一些任务无法完成</li>
<li>训练过程LDA使用的是狄利克雷先验分布，属于生成式模型；word2vec使用的是语言模型，属于判别式模型</li>
<li></li>
</ul>
</li>
<li>分词的原理<ul>
<li>最大正向匹配，最大逆向匹配，双向匹配</li>
<li>n-gram</li>
<li>BMES模型（HMM，CRF）</li>
</ul>
</li>
<li>字典树的优缺点？手写字典树？<ul>
<li>优点：查询速度快，可以做前缀比较</li>
<li>缺点：内存消耗大</li>
</ul>
</li>
<li>输入补全可以由那种数据结构来做？<ul>
<li>字典树 </li>
</ul>
</li>
<li>为什么正则化处理中bias不需要正则<ul>
<li>bias影响的是结果的偏差，对输入没有放大缩小的作用，而正则化要降低方差（提高模型泛化能力），所以不需要正则化bias</li>
</ul>
</li>
<li>反卷积与反池化<ul>
<li>反卷积：</li>
<li>反池化：</li>
</ul>
</li>
<li>attention机制原理</li>
<li>transformer结构图以及原理</li>
<li>BLEU原理及代码</li>
<li>dropout train和test的区别<ul>
<li>train过程：输出会依一定概率p让输入为0</li>
<li>test过程： 需要乘上概率p</li>
</ul>
</li>
<li>BN  train和test的区别？<ul>
<li>train： 有batch</li>
<li>test：只有单个样本，所以方差和均值使用之前训练阶段每个batch保存下来的平均</li>
</ul>
</li>
<li>正负样本不平衡问题？<ul>
<li>过采样或欠采样</li>
<li>组合/集成方法：</li>
<li>正负样本设置惩罚权重</li>
<li>focal loss</li>
</ul>
</li>
<li>BN前向传播公式，反向求导公式？<ul>
<li>对一批数据进行归一化，沿着特征方向：$B N\left(x<em>{i}\right)=\alpha \times \frac{x</em>{i}-\mu<em>{b}}{\sqrt{\sigma</em>{B}^{2}+\epsilon}}+\beta$</li>
<li>其中两个参数alpha和beta是调节参数，可学习的，防止网络表达能力下降</li>
<li><a href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html">https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html</a></li>
</ul>
</li>
<li>BN为什么不适用与RNN？<ul>
<li>RNN是变长的，基于timestep计算，如果使用BN，需要保存每个timestep下batch的均值和方差，效率很低 </li>
</ul>
</li>
<li>加了dropout后，神经网络的BP阶段有什么改变，求导公式要怎么改<ul>
<li>需要乘上mask向量，因为在前向传播过程中失活的神经元在反向传播时应该也是要不起作用的</li>
</ul>
</li>
<li>试分析为什么不能在循环神经网络中的循环连接上直接应用丢弃法？<ul>
<li>若放在循环链接，则信息将会因循环进行而逐渐丢失</li>
<li>rnn的dropout只能设置在输入输出层上</li>
</ul>
</li>
<li>在LSTM中，隐藏层神经元数量与参数数量之间的关系？<ul>
<li>对照LSTM中gate过程的公式可算出：num=4<em>（O</em>(I+H)+O）</li>
</ul>
</li>
<li>CNN卷积的反向传播过程</li>
<li>胶囊网络？<ul>
<li>CNN对物体之间的空间关系识别能力不强</li>
<li>CNN对物体旋转之后识别能力不强</li>
<li>胶囊是一个包含多个神经元的载体，每个神经元表示了图像中出现的特定实体的各种属性</li>
<li><a href="https://www.tinymind.cn/articles/61">https://www.tinymind.cn/articles/61</a></li>
</ul>
</li>
<li>转置卷积？<ul>
<li>一般卷积：$\mathbf{z}=C \mathbf{x}$</li>
<li>转置卷积: $\mathbf{x}=C^{\mathrm{T}} \mathbf{z}$</li>
</ul>
</li>
<li>微步卷积？<ul>
<li>步长s&lt;1的转置卷积 </li>
<li>如果卷积操作的步长s&gt;1，希望其对应的转置卷积的步长为1/s，需要在输入特征之间插入s-1个0来使得其移动的速度变慢</li>
</ul>
</li>
<li>空洞卷积？存在什么问题？<ul>
<li>通过间隔地对输入进行卷积操作以增加输出单元的感受野</li>
</ul>
</li>
<li>1*1卷积核的作用？<ul>
<li>降维</li>
<li>升维</li>
<li>增加非线性</li>
</ul>
</li>
<li>TensorFlow训练模型的整个流程？</li>
<li>梯度消失是否可以通过增加学习率来缓解？</li>
<li>卷积层神经元数量计算？<ul>
<li>假设卷积层的输入神经元个数为n，卷积大小为m，步长（stride）为s，输入神经元两端各填补p 个零（zero padding），则神经元数量为<script type="math/tex">(n-m+2 p) / s+1</script></li>
</ul>
</li>
<li>CNN的反向传播？</li>
<li>什么样的任务适合用深度学习，什么样的问题不适合？<ul>
<li>不适合：<ul>
<li>小样本</li>
<li>低维数据，大样本量，不如ensemble</li>
<li></li>
</ul>
</li>
</ul>
</li>
<li>NLP中的CNN的max pooling<ul>
<li>能减少模型参数数量，有利于缓解过拟合</li>
<li>可以把变长的输入X整理成固定长度的输入</li>
<li>丢失最大强度特征的位置信息</li>
<li>有时候强特征出现多次</li>
<li>改进：k-max pooling和chunk-max pooling</li>
</ul>
</li>
<li>LSTM中为什么选择tanh？<ul>
<li><a href="https://www.zhihu.com/question/61265076">https://www.zhihu.com/question/61265076</a></li>
</ul>
</li>
<li>算法的错误样例分析方法？（即预测与真实标签不符）</li>
<li>warmup策略为什么有效？<ul>
<li>warmup是指在训练初始阶段使用较小的学习率来启动，接着切换到大学效率而后进行常见的decay训练</li>
<li>有助于缓解模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳</li>
<li>有助于保持模型深层的稳定性</li>
</ul>
</li>
</ul>
<h1><span id="手撕算法amp场景题">手撕算法&amp;场景题</span></h1><ul>
<li>排序啊查找啊  基础</li>
<li>千万向量中找到和单个向量相似的那个  <ul>
<li>先聚类，然后输入向量先与聚类中心比较再与类中的向量比较</li>
<li>update by <a href="https://github.com/ZhengZixiang">ZhengZixiang</a>: 答聚类做法不是太完美，我实习中学到的实现，会做tpo k的近似最近邻。具体说来就是用局部敏感哈希LSH做降维分桶，然后落在同一个哈希桶里的取相似，比如问句匹配就会这么干</li>
</ul>
</li>
<li>海量数据排序（找中位数）<ul>
<li><a href="https://blog.csdn.net/sykpour/article/details/26480217">https://blog.csdn.net/sykpour/article/details/26480217</a></li>
</ul>
</li>
<li>判断是否平衡二叉树<ul>
<li>设置flag，一边遍历一遍记录深度，如果深度差大于1，则flag设置为False </li>
</ul>
</li>
<li>扇形涂色问题。一个圆被分成M个扇形，一共有N种颜色，相邻扇形不同色，一共有几种涂法？</li>
<li>判断二叉树对称</li>
<li>递归和非递归实现求二叉树深度</li>
<li>求字符串中最长的不重复子串的长度（双指针、dp）</li>
<li>大数加法？大数乘法？</li>
<li>给个一个二维矩阵，矩阵中每一位是字符，从任意一个字符出发，不断向上下左右能拼成一个字符串；给定一些字符串，逐个判断是否能在该矩阵中拼出</li>
<li>一棵二叉树，每个节点的值是一个整数，求这个树中路径上数字都相同的路径中最长的一条</li>
<li>求n的m次方根，怎么转换成优化算法然后解</li>
<li>求树两个节点的最低公共祖先</li>
<li>实现一个hashmap，包含put get delete方法</li>
<li>给定数组{a1, a2, a3, … an}，要求挑出一些数，这些数不能相邻，使得加起来的和最大。如果是环怎么处理？</li>
<li>一个四位数abcd，满足abcd*4=dcba,求这个数？</li>
<li>一个链表，奇数位升序，偶数为降序，将其转化成完全升序的链表</li>
<li>求逆序对的数目</li>
<li>求二维矩阵的子矩阵，使得和最大</li>
<li>名人问题，给出最优解？</li>
<li>01矩阵找出由1组成的最大面积的矩阵？</li>
<li>编辑距离</li>
<li>射气球</li>
<li>求二叉树哪一个点到其他所有点的路径总和最小，即树的重心？</li>
<li>设计一个结构存取稀疏矩阵<ul>
<li>只存非零元素，三元组形式：（元素，行，列） </li>
</ul>
</li>
<li>电梯上升只能停一层，大家下电梯再各自步行到自己的楼层，求停在哪一层所有人步行层数总和最少？</li>
<li>给一个环形数组长度为N，数组每个位置都有一种颜色，总共M种颜色，求包含全部颜色的最短长度</li>
<li>有M个有序链表（从大到小），要求取出前K大的元素。<ul>
<li>把M个链表的头结点做成一个大小为M的最大堆，每次取出堆中最大的节点，然后将这个节点的后续节点放进堆中重新排序</li>
<li>时间复杂度$O((k+m)log^{m})$，空间复杂度$O(M)$</li>
</ul>
</li>
<li>求A的长度为L的各个连续子串在B中出现的次数总和<ul>
<li>先预处理一下字符串B，将B中长度为L的子串及其出现次数记录在hashmap里；然后去遍历A中长度为L的子串并查找hashmap；时间复杂度O(N)</li>
</ul>
</li>
<li>N！中0的个数？<ul>
<li>关注5的个数</li>
</ul>
</li>
<li>二叉树中是否存在和为target的路径？<ul>
<li>dfs</li>
</ul>
</li>
<li>B+、 B、 平衡二叉树 、AVL树、红黑树的区别</li>
<li>实现带有求最大值功能的栈，要求时间复杂度为O（1）<ul>
<li>两个栈，一个保存数据，一个保存每次操作后的最大元素 </li>
</ul>
</li>
<li>给出一个n*n数字矩阵，寻找一条最长上升路径，每个位置只能向上下左右四个位置移动。</li>
<li>环形打印二维矩阵？</li>
<li>求二维数组中，任意矩形之和？</li>
</ul>
<h1><span id="面经分享">面经分享</span></h1><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484654&amp;idx=2&amp;sn=2e1b3f0e13be9a793a9ad01cf9dd2538&amp;chksm=97aee23ca0d96b2a10d918ba4957f38c1bec4cd515582aaa37dcf2ae60f227a21229a406d5ee&amp;token=1761549850&amp;lang=zh_CN#rd">字节AI Lab-NLP算法热乎面经</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484614&amp;idx=1&amp;sn=7cc14c23b1fa71f812c37567f7352173&amp;chksm=97aee214a0d96b02297a1b46486c1ddebbc99b249122c117605b46dab5c8158dec8f22618c28&amp;token=1761549850&amp;lang=zh_CN#rd">算法面经分享 | 双非研究生斩获大厂offer</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484614&amp;idx=2&amp;sn=719b7b680c98e266eef6e4a2a81a0537&amp;chksm=97aee214a0d96b026f20702329541f5def04994ea24773d61c7ee0d25edf8f7a1dd306ba7075&amp;token=1761549850&amp;lang=zh_CN#rd">太难啦！面试官盘点NLP近五年招聘动态</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484551&amp;idx=1&amp;sn=74489dfac7b34966bff65bd9bbda3c02&amp;chksm=97aee255a0d96b43bceef1ef00792a8259043625c83c1cadcd86039920940a94bee011f8fb30&amp;token=1761549850&amp;lang=zh_CN#rd">算法面经大乱斗Plus</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484460&amp;idx=2&amp;sn=c55b103ccea3d025cc71e2b52d0894d3&amp;chksm=97aee2fea0d96be84fe2c081a743ce6140c4b3924fbc754689eb702a6532510c2302886c3f3b&amp;token=1761549850&amp;lang=zh_CN#rd">来啦！百度凤巢算法面经</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484410&amp;idx=1&amp;sn=fd9524b12158b80db6596f5b35db83a8&amp;chksm=97aee528a0d96c3eff1d26d7acf314f65824ec98c74cc11cb92ad8e15ec80951f3b940f7efbe&amp;token=1761549850&amp;lang=zh_CN#rd">算法面经大乱斗</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484380&amp;idx=2&amp;sn=5df4641bb323237cc92c7c45b180087b&amp;chksm=97aee50ea0d96c185cc391d39a47b44ed52a694eda3d0290dd1af3fb7e53b2311e5601d403e9&amp;token=1761549850&amp;lang=zh_CN#rd">头条+腾讯 双杀面经（NLP实习）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484306&amp;idx=2&amp;sn=bb19811abf7eaa6978acfcaf313eed49&amp;chksm=97aee540a0d96c562b8692a03c8a6421824c681242a5006c6609583bbe03769bf00447f00611&amp;token=1761549850&amp;lang=zh_CN#rd">字节跳动 算法全四面 详细面经</a></li>
<li><a href="https://mp.weixin.qq.com/s/G6Vibdy2_XGhr4CiV1wx7Q">暑期实习 | 百度NLP算法岗面试复盘</a></li>
<li><a href="https://mp.weixin.qq.com/s/mVVei2NXqOF_xbGQ25dMwg">【社招】1年工作经验，字节跳动算法面经</a></li>
<li><a href="https://mp.weixin.qq.com/s/GK86DAmWJ-DIIa5qSeKqKQ">NLP面试复盘 | 阿里/腾讯/头条/paypal/快手</a></li>
<li><a href="https://mp.weixin.qq.com/s/U3IZ1WTUXIDif4Nv0wUX2Q">字节跳动 | 算法三面复盘</a></li>
<li><a href="https://mp.weixin.qq.com/s/X4OAf1aZo4S9MYwXck62aA">春招面经集合 | 腾讯/字节/华为/东芝/360/Boss</a></li>
<li><a href="https://mp.weixin.qq.com/s/n4H8US5QnFeddmKhmuTAeA">NLP算法岗面经 | 微软/腾讯/字节跳动/快手</a></li>
<li><a href="https://mp.weixin.qq.com/s/6tmllHZ09uVCKYwUXmigvg">字节跳动 | 大数据/数据挖掘面经</a></li>
<li><a href="https://mp.weixin.qq.com/s/FI4AH2E9f5x8Q0ZdNXccTw">蚂蚁金服 | 算法面试复盘</a></li>
<li><a href="https://mp.weixin.qq.com/s/lIV0TNQNw5Uuz8gp5xG-5w">美团+阿里 | 机器学习算法春招面经</a></li>
<li><a href="https://mp.weixin.qq.com/s/Eyiyqa74-rZ7D_-QYGPB8Q">达摩院+华为 | NLP博士的春招历程</a></li>
<li><a href="https://mp.weixin.qq.com/s/Nwg60Ld2QDZW6e9_Mng-Cg">福娃之路 | 五面阿里算法</a></li>
<li><a href="https://mp.weixin.qq.com/s/f5hMbe5rh7GNcWP9TimtqA">豪取BAT！超详细暑期实习算法面经(非科班无论文)</a></li>
<li><a href="https://mp.weixin.qq.com/s/McCPYbr-Kv2xOz_q1mGpwg">字节跳动 | 算法面试复盘</a></li>
<li><a href="https://mp.weixin.qq.com/s/qPlLAevEToMFi26ab-dGKg">超强整理，非科班小硕的进击之路</a></li>
<li><a href="https://mp.weixin.qq.com/s/qq9M8NQv6gQ7wSOr6UQzwg">嘿同学， 你点的面筋</a></li>
<li><a href="https://mp.weixin.qq.com/s/qljmCNybQD-bX7GDaut80w">NLP面经集结 | 达摩院、腾讯、微软、美团、百度</a></li>
<li><a href="https://mp.weixin.qq.com/s/B5mH9-G2SC_IgaX_Z0YKWw">腾讯+头条 算法双杀面经</a></li>
<li><a href="https://mp.weixin.qq.com/s/OYK_ZJ9QK2T1W8GPzeeZJw">来看看offer收割机的烦恼</a></li>
<li><a href="https://mp.weixin.qq.com/s/VPXlrEse1bYRJAelidxVBg">六面！终斩腾讯NLP暑期实习offer</a></li>
<li><a href="https://mp.weixin.qq.com/s/19YTgfG4jNNzC0sKVRCi3g0">字节跳动AI-LAB | 算法三轮技术面分享</a></li>
<li><a href="https://mp.weixin.qq.com/s/psCrq7M3s1NDvk0KokcZJw">超详细！腾讯NLP算法岗面经（已offer）</a></li>
<li><a href="https://mp.weixin.qq.com/s/ZSReDAswMUsRK7Ab83nnMg">阿里机器学习算法面经（已offer）</a></li>
</ul>
<h1><span id="一些有用的知识整理">一些有用的知识整理</span></h1><ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484306&amp;idx=1&amp;sn=b9b996cf512d62a9e41571d134a62636&amp;chksm=97aee540a0d96c561b157737b6d0ffb70bd8130c17d575bc247eb148ab1ce564fc281120d3c4&amp;token=1761549850&amp;lang=zh_CN#rd">关于ELMo，面试官们都怎么问</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484333&amp;idx=1&amp;sn=7e26a0dc657af9373ce384db94b9b1e1&amp;chksm=97aee57fa0d96c69ce36f58c9ef7ca0a9b4f4cfa9816a8d6295a54dcbe55f29a04ca69630eb4&amp;token=1761549850&amp;lang=zh_CN#rd">关于Transformer，面试官们都怎么问</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484380&amp;idx=1&amp;sn=55fccbb2565520bf747fa35359271673&amp;chksm=97aee50ea0d96c180ccf9177c653e78097ee7a9f18a3fb02811c128548cb585b427887d0dc8f&amp;token=1761549850&amp;lang=zh_CN#rd">关于BERT，面试官们都怎么问</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247483759&amp;idx=1&amp;sn=26e3e1139413af63ec4cdc2a29271088&amp;chksm=97aee7bda0d96eab29ebc216486fbee1456a38aaff046e82bdfa08bf96f17bc9dc22f1a96dc7&amp;token=1761549850&amp;lang=zh_CN#rd">Transformers Assemble（PART I）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247483798&amp;idx=1&amp;sn=72d8c9c1870a095bcdd32014fcdcb235&amp;chksm=97aee744a0d96e52512dec76848993df462c87e5f78da6444d2c3793e199a7bb211f460438b0&amp;token=1761549850&amp;lang=zh_CN#rd">Transformers Assemble（PART II）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247483970&amp;idx=1&amp;sn=bf3696f54985e779b5f0f3ccbd923b91&amp;chksm=97aee490a0d96d867586e0196c64a9b36e38e3ca537e7beba1f8af6ab01109ecd746e47d80dd&amp;token=1761549850&amp;lang=zh_CN#rd">Transformers Assemble（PART III）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484067&amp;idx=1&amp;sn=84bd52abaf9b17ac9b41e312ba8d688b&amp;chksm=97aee471a0d96d67c5e9149a53d1eca8222fa65e11dab90348276b9429ebd4781d3e47fa0f9d&amp;token=1761549850&amp;lang=zh_CN#rd">Transformers Assemble（PART IV）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484450&amp;idx=1&amp;sn=038e11feebcc01193ee6fbc1b157411c&amp;chksm=97aee2f0a0d96be6571f984c602b722b1a0bd88f1bbe89c8226f90b32a8469d6ae1591904ec9&amp;token=1761549850&amp;lang=zh_CN#rd">Transformers Assemble（PART V）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484015&amp;idx=1&amp;sn=7e79cf7f2b3abe51b82c4a8beacdf195&amp;chksm=97aee4bda0d96dab57db412e7c9f51e7e9bd5d9d17742f2a522f2dbc881c77fb59183c098d04&amp;token=1761549850&amp;lang=zh_CN#rd">【ICLR2020】Transformer Complex-order：一种新的位置编码方式</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247483778&amp;idx=1&amp;sn=4d5e9c0a80280734d380137cb23b4a55&amp;chksm=97aee750a0d96e464e114b7859d9ab0082ccfeda6a0b402cbbceb99fa49216592dc86dd6756a&amp;token=1761549850&amp;lang=zh_CN#rd">BERT源码分析（PART I）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247483808&amp;idx=1&amp;sn=d533c7fcc8f274f3f3920ee26ae38d17&amp;chksm=97aee772a0d96e64cfc31fba1f47fce8f07386588dc53595a116b06ec6ce0a47e57a857cc134&amp;token=1761549850&amp;lang=zh_CN#rd">BERT源码分析（PART II）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247483828&amp;idx=1&amp;sn=3022bf8631c93b3c8633398b35546726&amp;chksm=97aee766a0d96e70c9627ab54b075b5083a98fc8ee5ed1b2d34d84fffe6c9bcd438e0b427ab3&amp;token=1761549850&amp;lang=zh_CN#rd">BERT源码分析（PART III）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484028&amp;idx=1&amp;sn=f3b0eee66c60100a097a169c05ce8181&amp;chksm=97aee4aea0d96db838f45c63d637c14cbc6dbc8ada083025ff83060230d2cf7aece331b572d4&amp;token=1761549850&amp;lang=zh_CN#rd">【NLP保姆级教程】手把手带你CNN文本分类(附代码)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484040&amp;idx=1&amp;sn=b85f2183c942ede4181c3d89e625bc50&amp;chksm=97aee45aa0d96d4caafbd97e9e019100af8ff5bb9e2f4faa31dcbafe910eab1f55f424687038&amp;token=1761549850&amp;lang=zh_CN#rd">【NLP保姆级教程】手把手带你RNN文本分类(附代码)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484075&amp;idx=2&amp;sn=a1280a4d661848d7d8f9a054c0c4e5b9&amp;chksm=97aee479a0d96d6fde3f2f17695ca8df0ea78538ad484c87da191fc26a80b8af9bd0fb34ed9d&amp;token=1761549850&amp;lang=zh_CN#rd">【NLP保姆级教程】手把手带你fastText文本分类(附代码)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484260&amp;idx=3&amp;sn=e48ffb63e24b82e9c3aac6ed011dcd53&amp;chksm=97aee5b6a0d96ca03c6f435a0b49f215a40804277543f1df32177ea7170abffe95eb4f792723&amp;token=1761549850&amp;lang=zh_CN#rd">【NLP保姆级教程】手把手带你RCNN文本分类(附代码)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484260&amp;idx=1&amp;sn=68d9ccd65a60c31b853dc2882105773e&amp;chksm=97aee5b6a0d96ca00df4f485bd5b1fe4293ebb65c5ba923d72f5498aecb5fb52c4d4ae63a951&amp;token=1761549850&amp;lang=zh_CN#rd">【NLP保姆级教程】手把手带你HAN文本分类(附代码)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484169&amp;idx=1&amp;sn=31007086d6b42517275415ef3d717ef7&amp;chksm=97aee5dba0d96ccdf1804968222432c11fe090736e58b26267ebd584d3c3b94c6591219ec33e&amp;token=1761549850&amp;lang=zh_CN#rd">【情感分析】基于Aspect的情感分析模型总结（PART I）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484214&amp;idx=1&amp;sn=9d31862263657abb00054c7829c320b8&amp;chksm=97aee5e4a0d96cf25550e15816041c15d6707df6cb7d6aaf3b3348b116087c5984928904d6aa&amp;token=1761549850&amp;lang=zh_CN#rd">【情感分析】基于Aspect的情感分析模型总结（PART II）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484335&amp;idx=1&amp;sn=e4bb3e0eee0faf96ed72fbb5ef9a7d4d&amp;chksm=97aee57da0d96c6b0f3866744984e501ab877ea0e957ecbc5ff2cda4b7a57887d33e30d33166&amp;token=1761549850&amp;lang=zh_CN#rd">【情感分析】基于Aspect的情感分析模型总结（PART III）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484533&amp;idx=2&amp;sn=681b4882feb90237dd1762ab064bf254&amp;chksm=97aee2a7a0d96bb1fc5cd4201672204c0fba3378e0ddfb3b1494ef9edb24b97ca8091f76d38a&amp;token=1761549850&amp;lang=zh_CN#rd">【情感分析】基于Aspect的情感分析模型总结（PART IV）</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484460&amp;idx=1&amp;sn=87f3f00e6730bb363d3b77fd092c3e3a&amp;chksm=97aee2fea0d96be8a3c0c07a2891bd802fa78e02cb73026a088dd5b67177ea3507cf0166915d&amp;token=1761549850&amp;lang=zh_CN#rd">预训练模型中的可插拔式知识融入——利用Adapter结构</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484547&amp;idx=1&amp;sn=283f59407b771af588868e96ccb0582b&amp;chksm=97aee251a0d96b4734197b300ab44548315bec4f16f9ae9465588bb7b4113936ae925ed6521a&amp;token=1761549850&amp;lang=zh_CN#rd">详解ERNIE-Baidu进化史及应用场景</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484569&amp;idx=1&amp;sn=c1c6592196179ac2f68f7705eb2d9eb5&amp;chksm=97aee24ba0d96b5d5029720e965b2b71ea840cfc9baec5bd1d4715e5c8380b53687de96bcb9c&amp;token=1761549850&amp;lang=zh_CN#rd">安排！微软UniLM 2.0解读</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484602&amp;idx=1&amp;sn=c1c68bcba3d0261a39947d33d98ac5a4&amp;chksm=97aee268a0d96b7e4f9844c7fe26eb479f7f472b6331f5e79058c9e94dd31c72c41ea2265fdc&amp;token=1761549850&amp;lang=zh_CN#rd">Huggingface出品！NLP论文研讨会</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484633&amp;idx=1&amp;sn=1404ab98e7d87221a9004ab4cb790b6b&amp;chksm=97aee20ba0d96b1df963895fcd0f0a3342fa2b70b3e566b6d64e5744b32a5d196f44cf276915&amp;token=1761549850&amp;lang=zh_CN#rd">业务，工程和算法的互殴现场</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484350&amp;idx=1&amp;sn=dd6a7ec6ca90c421acd6d42847acd7b0&amp;chksm=97aee56ca0d96c7ab78663b2302c7117b761d71625170baef91b3d2a3dfb3c491569d7b78ae4&amp;token=1761549850&amp;lang=zh_CN#rd">我是如何收集信息的</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzkwNjM2NQ==&amp;mid=2247484335&amp;idx=2&amp;sn=e2204e4950e796c31a7f12e82cfc42f0&amp;chksm=97aee57da0d96c6be91f479d75ec1763549f6bd4fbbd421834154dc8938c06237ee580f51a31&amp;token=1761549850&amp;lang=zh_CN#rd">如何优雅地训练大型模型？</a></li>
</ul>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>AL</tag>
      </tags>
  </entry>
  <entry>
    <title>Earyant的百宝箱</title>
    <url>/posts/%E4%B9%A6%E5%8D%95/Earyant%E7%9A%84%E7%99%BE%E5%AE%9D%E7%AE%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>本文章是本人的收藏夹，罗列了各种神奇的工具、文章。</p>
<h1><span id="微信">微信</span></h1><h2><span id="公众号">公众号</span></h2><h3><span id="读书类">读书类</span></h3><ol>
<li><a href="../公众号/阿猫读书">阿猫读书</a></li>
<li><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzUzMjM5MjYwMQ==&amp;action=getalbum&amp;album_id=2648759383936221185#wechat_redirect">每晚一卷书</a></li>
<li><a href="../公众号/十点读书">十点读书</a></li>
<li><a href="../公众号/晚点">晚点LatePost</a></li>
<li>知乎高赞</li>
</ol>
<h3><span id="投资类">投资类</span></h3><ol>
<li>阿猫投资学</li>
</ol>
<h3><span id="认知升级职场商业">认知升级\职场商业</span></h3><ol>
<li>艾菲的理想</li>
<li>笔记侠</li>
<li>曹将</li>
<li>插座APP</li>
<li>得到</li>
<li>洞见</li>
<li>刘润</li>
</ol>
<h3><span id="时事">时事</span></h3><ol>
<li>warfalcon</li>
<li>政事堂</li>
</ol>
<h2><span id="优秀公众号合集">优秀公众号合集</span></h2><p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzIxNTAzNzU0Ng==&amp;action=getalbum&amp;album_id=1458616066929999872&amp;scene=173&amp;from_msgid=2654752758&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">🔥笔记侠 - 思维方式</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5OTA3MjUwMA==&amp;action=getalbum&amp;album_id=1361538843169865729&amp;scene=173&amp;from_msgid=2651214323&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">🔥印象笔记 - 一周排行榜</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5NjAyNjkwMA==&amp;action=getalbum&amp;album_id=1571716752881844225&amp;scene=173&amp;from_msgid=2723968871&amp;from_itemidx=3&amp;count=3&amp;nolastread=1#wechat_redirect">🔥有道云笔记 - 一周排行榜</a><br><a href="https://pan.baidu.com/s/1s8SG3lX1aURJC7s0Hn5WOA?pwd=8888#list/path=%2F">刘润文章合集</a><br><a href="https://mp.weixin.qq.com/s/W90rNoch0YMaYhKJQKgmbw">财富自由书单</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1296553807849144320&amp;scene=173&amp;from_msgid=2247493100&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">理财投资</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1314738114677653506&amp;scene=173&amp;from_msgid=2247489889&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">B站推荐</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&amp;__biz=MzIxNTAzNzU0Ng==&amp;scene=1&amp;album_id=1872860866862170118&amp;count=3#wechat_redirect">笔记侠 - 更新书堂</a><br><a href="https://mp.weixin.qq.com/s/XHWfUbV9yGl_24GdyAugbA">艾菲的理想 - 文章精选</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NTU3NjAwNg==&amp;action=getalbum&amp;album_id=1346886558733090816&amp;scene=173&amp;from_msgid=2650053648&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">艾菲的理想 - 外在成功</a><br><a href="https://www.yuque.com/erudite/gn1k8g/lse9k4">语雀 - 小小哥的 Blog</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3ODIyNjMwMw==&amp;action=getalbum&amp;album_id=1512150289473159169&amp;scene=173&amp;from_msgid=2247486259&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">道长的思维铺子 - 思考方式和思维模型</a></p>
<h2><span id="优秀公众号文章">优秀公众号文章</span></h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzIxNTAzNzU0Ng==&amp;mid=2654752758&amp;idx=1&amp;sn=6e6cea5c09902c6e63185fbe43a3d8e9&amp;chksm=8c568cf3bb2105e52138531af9ce7a17e294a0aa13a536f112db0e7c67dd1dd1628a1cd6680c&amp;scene=21#wechat_redirect">🔥读懂《毛选》的人有多通透</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzIxNTAzNzU0Ng==&amp;mid=2654751710&amp;idx=1&amp;sn=76af1712cbc5379575439215cbf3a260&amp;scene=21#wechat_redirect">比管理时间重要1000倍的，是管理精力</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzIxNTAzNzU0Ng==&amp;mid=2654742981&amp;idx=1&amp;sn=4b7043f396bd0090681bc7486da4dc29&amp;scene=21#wechat_redirect">卡耐基的这100句话，畅销85年，改变了很多人</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzA4MDk2OTM0MA==&amp;mid=2651780573&amp;idx=1&amp;sn=c0bb6cd358071739af9a0a1340b9e591&amp;scene=21#wechat_redirect">阅读新闻的技巧</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzIxNTAzNzU0Ng==&amp;mid=2654741710&amp;idx=1&amp;sn=a79d85ce443bf6eef65f6c4e732f22e0&amp;scene=21#wechat_redirect">看完德鲁克的72条思考，我终于明白他为何这么牛</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzU5MzcyMzc2OQ==&amp;mid=2247597652&amp;idx=1&amp;sn=87787dd37121a6d0e650ad98abed6f2d&amp;scene=21#wechat_redirect">别人送的第一桶金，一文不值</a></p>
<h1><span id="视频">视频</span></h1><p><a href="https://docs.qq.com/sheet/DRU5MWHZCTHFGQnhM?tab=m112fj">🔥b站Up主推荐\书籍推荐</a></p>
<h1><span id="读书">读书</span></h1><p><a href="http://www.xysudu.com/">🔥书籍解说</a><br><a href="http://klib.me/weread/hot/all.html">微信读书热门标注</a></p>
<h1><span id="github">github</span></h1><h2><span id="资料收集">资料收集</span></h2><p><a href="https://github.com/ixinzhi">ixinzhi</a><br><a href="https://github.com/apachecn">apachecn</a><br><a href="https://github.com/it-ebooks-0">it-ebooks</a><br><a href="https://github.com/wizardforcel">wizardforcel</a><br><a href="https://github.com/timqian/chinese-independent-blogs">中文独立博客列表</a></p>
<h2><span id="周刊">周刊</span></h2><p><a href="https://github.com/ruanyf/weekly">科技周刊</a><br><a href="https://hellogithub.com/periodical/volume/82">Hello Github</a></p>
<h1><span id="其他">其他</span></h1><p><a href="/posts/杂类/资料/">其他</a></p>
<h1><span id="ted">TED</span></h1><h1><span id="技术">技术</span></h1><h2><span id="周报">周报</span></h2><p><a href="https://github.com/cbamls/AI_Tutorial">AIQ</a></p>
]]></content>
      <categories>
        <category>百宝箱</category>
      </categories>
      <tags>
        <tag>百宝箱</tag>
      </tags>
  </entry>
  <entry>
    <title>算法面试题</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://zhuanlan.zhihu.com/p/578505706">知乎</a><br><a href="https://zhuanlan.zhihu.com/p/190223015">AI算法工程师面试题6</a></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>1. 为什么要对数值类型的特征做归一化</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E5%81%9A%E5%BD%92%E4%B8%80%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="优点">优点</span></h2><p>归一化是数据预处理的一种常用方法，它将不同尺度的特征转化为统一的尺度，使得数据在同一量纲下进行比较和分析。对于数值类型的特征，归一化的目的是消除不同特征之间的量纲差异，使得模型能够更好地学习特征之间的关系，提高模型的性能。<br>对数值类型的特征进行归一化是为了确保不同特征之间的数值范围一致，从而有助于机器学习模型更好地理解和处理数据。以下是一些常见的原因和好处：</p>
<ol>
<li><strong>梯度下降</strong>：在许多机器学习算法中，如线性回归、支持向量机、神经网络等，都使用梯度下降来最小化损失函数。如果不对特征进行归一化，那些具有较大范围值的特征可能会主导梯度下降的过程，导致收敛速度变慢甚至无法收敛。通过归一化，可以使梯度下降更快速地找到全局最优解。</li>
<li><strong>特征权重的一致性</strong>：在某些模型中，例如线性模型，模型的权重（系数）与特征的数值大小相关。如果特征没有归一化，那么模型可能会赋予值较大的特征更高的权重，导致模型的解释性降低并且难以解释。</li>
<li><strong>K-means 聚类</strong>：K-means 聚类算法是一种基于距离的算法，如果特征的数值范围不一致，会导致聚类结果受到特征数值大小的影响。通过归一化，可以确保各个特征对聚类结果的贡献相对均衡。</li>
<li><strong>正则化</strong>：在正则化线性模型（如岭回归或 Lasso 回归）时，正则化项的惩罚力度可能会受到特征尺度的影响。归一化可以确保正则化对所有特征的影响是一致的。</li>
<li><strong>可视化</strong>：在数据可视化和特征工程阶段，归一化后的数据更容易可视化和理解。例如，绘制散点图或箱线图时，数据的分布更容易比较和解释。</li>
</ol>
<h2><span id="归一化方法">归一化方法</span></h2><ol>
<li><p>Min-Max 归一化（最小-最大归一化）：<br>Min-Max 归一化将数据线性映射到指定的范围，通常是[0, 1]。这种方法适用于大多数情况，特别是当你不知道数据的分布情况时。<br>这个公式将原始数据线性映射到[0, 1]范围内，使得最小值对应0，最大值对应1，中间的值按比例映射到这个范围内。</p>
</li>
<li><p>标准化（Z-score 归一化）：</p>
</li>
</ol>
<p>标准化将数据转换为均值为0，标准差为1的正态分布（标准正态分布）。这种方法适用于数据近似正态分布的情况。<br>这个公式通过减去均值，然后除以标准差，将数据映射到均值为0，标准差为1的分布上。标准化使得数据分布更加对称，并且可以使某些机器学习算法更容易收敛。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>3. 什么是组合特征？如何处理高维组合特征？</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BB%80%E4%B9%88%E6%98%AF%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%EF%BC%9F%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E9%AB%98%E7%BB%B4%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%EF%BC%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>2. 怎样处理类别型特征</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%80%8E%E6%A0%B7%E5%A4%84%E7%90%86%E7%B1%BB%E5%88%AB%E5%9E%8B%E7%89%B9%E5%BE%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>1、如何处理类别型特征<br>类别特征（Categorical Feature）主要是指性别（男、女）、血型（A、B、AB、O）等只在有限选项内取值的特征。类别型特征的原始输入通常是字符串形式，除了决策树等少数模型能直接处理字符串的输入，对于逻辑回归、支持向量机等模型来说，类别型特征必须经过处理转换成数值型才能正确工作。<br>在处理类别型特征，可以通过各种方式的编码来处理。比如序号编码、 独热编码、二进制编码等</p>
<p>2、常用编码方法<br>2.1 序号编码<br>序号编码通常用于处理类别间具有大小关系的数据。例如成绩，一般分为不及格、及格、良好、优秀，并且存在“不及格 &lt; 及格 &lt; 良好 &lt; 优秀”的排序关系。序号编码会按照大小关系对类别型特征赋值一个数值ID，例如不及格表示为0、及格表示为1、良好表示为2、优秀表示为3，转换后依然保留大小关系。</p>
<p>2.2 独热编码<br>独热编码通常用于处理类别间具备大小关系的特征。例如血型，一共有四个取值，独热编码会把血型变成一个四维稀疏矩阵，A型血表示为（1，0，0，0），B血型为（0，1，0，0），AB表示为（0，0，1，0），O型血表示为（0，0，0，1）。</p>
<blockquote>
<p> 对于类别取值较多的情况下使用独热编码需要注意以下问题：</p>
<ol>
<li><p>使用稀疏向量来节省空间    </p>
</li>
<li><p>配合特征选择来降低维度</p>
</li>
</ol>
</blockquote>
<p>2.3 二进制编码<br>二进制编码主要分为两步，先用序号编码给每一个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>血型</th>
<th>类别 ID（序号编码）</th>
<th>独热编码</th>
<th>二进制编码</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>1 0 0 0</td>
<td>0 0 1</td>
</tr>
<tr>
<td>B</td>
<td>2</td>
<td>0 1 0 0</td>
<td>0 1 0</td>
</tr>
<tr>
<td>AB</td>
<td>3</td>
<td>0 0 1 0</td>
<td>0 1 1</td>
</tr>
<tr>
<td>O</td>
<td>4</td>
<td>0 0 0 1</td>
<td>1 0 0</td>
</tr>
</tbody>
</table>
</div>
<p>为什么能使用One-Hot Encoding？<br>使用one-hot编码，将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，也是基于的欧式空间。</p>
<p>将离散型特征使用one-hot编码，可以会让特征之间的距离计算更加合理。比如，有一个离散型特征，代表工作类型，该离散型特征，共有三个取值，不使用one-hot编码，计算出来的特征的距离是不合理。那如果使用one-hot编码，显得更合理。</p>
<p>独热编码优缺点<br>优点：独热编码解决了分类器不好处理属性数据的问题，在一定程度上也起到了扩充特征的作用。它的值只有0和1，不同的类型存储在垂直的空间。</p>
<p>缺点：当类别的数量很多时，特征空间会变得非常大。在这种情况下，一般可以用PCA（主成分分析）来减少维度。而且One-Hot Encoding+PCA这种组合在实际中也非常有用。</p>
<p>One-Hot Encoding的使用场景<br>独热编码用来解决类别型数据的离散值问题。将离散型特征进行one-hot编码的作用，是为了让距离计算更合理，但如果特征是离散的，并且不用one-hot编码就可以很合理的计算出距离，那么就没必要进行one-hot编码，比如，该离散特征共有1000个取值，我们分成两组，分别是400和600,两个小组之间的距离有合适的定义，组内的距离也有合适的定义，那就没必要用one-hot 编码。</p>
<p>基于树的方法是不需要进行特征的归一化，例如随机森林，bagging 和 boosting等。对于决策树来说，one-hot的本质是增加树的深度，决策树是没有特征大小的概念的，只有特征处于他分布的哪一部分的概念。</p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>4. 怎样有效地找到组合特征？</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%80%8E%E6%A0%B7%E6%9C%89%E6%95%88%E5%9C%B0%E6%89%BE%E5%88%B0%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%EF%BC%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote>
<p>决策树是一种用于分类和回归任务的机器学习算法。它们是决策的强大工具，可用于对变量之间的复杂关系进行建模。<br>决策树的主要优点之一是它们易于理解和解释。树形结构可以清晰地可视化决策过程，并且可以轻松评估每个特征的重要性。构建决策树的过程从选择根节点开始，根节点是最好地将数据分为不同类别或目标值的特征。然后根据该特征的值将数据分成子集，并对每个子集重复该过程，直到满足停止标准。停止标准可以基于子集中的样本数量、子集的纯度或树的深度。</p>
</blockquote>
<!-- toc -->
<ul>
<li><a href="#优点">优点</a></li>
<li><a href="#缺点">缺点</a><ul>
<li><a href="#集成学习">集成学习</a></li>
</ul>
</li>
<li><a href="#bagging">bagging</a></li>
<li><a href="#boosting">boosting</a><ul>
<li><a href="#随机森林">随机森林</a></li>
</ul>
</li>
<li><a href="#优点-1">优点</a></li>
<li><a href="#缺点-1">缺点</a></li>
<li><a href="#总结">总结</a></li>
<li><a href="#使用场景">使用场景</a></li>
<li><a href="#问题">问题</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p>决策树的主要缺点之一是它们很容易过度拟合数据，特别是当树很深并且有很多叶子时。当树过于复杂并且适合数据中的噪声而不是底层模式时，就会发生过度拟合。这可能会导致对新的、未见过的数据的泛化性能较差。为了防止过度拟合，可以使用<strong>剪枝、正则化和交叉验证</strong>等技术。决策树的另一个问题是它们对输入特征的<strong>顺序敏感</strong>。不同的特征顺序会导致不同的树结构，最终的树可能不是最优的。为了克服这个问题，可以使用随机森林和梯度提升等技术。</p>
<h2><span id="优点">优点</span></h2><ol>
<li>易于理解和解释：树形结构可以清晰地可视化决策过程，并且可以轻松评估每个特征的重要性。</li>
<li>处理数值和分类数据：决策树可以处理数值和分类数据，使其成为适用于各种应用的多功能工具。</li>
<li>高精度：决策树可以在很多数据集上实现高精度，特别是当树不深时。</li>
<li>对异常值具有鲁棒性：决策树不受异常值的影响，这使得它们适合有噪声的数据集。</li>
<li>既可用于分类任务，又可用于回归任务。</li>
</ol>
<h2><span id="缺点">缺点</span></h2><ol>
<li>过度拟合：决策树很容易对数据过度拟合，特别是当树很深并且有很多叶子时。</li>
<li>对输入特征的顺序敏感：不同的特征顺序会导致不同的树结构，最终的树可能不是最优的。</li>
<li>不稳定：决策树对数据的微小变化很敏感，这会导致不同的树结构和不同的预测。</li>
<li>偏差：决策树可能会偏向于具有更多级别的特征或具有多个级别的分类变量，这可能导致预测不准确。</li>
<li>不适合连续变量：决策树不适合连续变量，如果变量是连续的，则可能导致将变量分成许多级别，这将使树变得复杂并导致过度拟合。</li>
</ol>
<h1><span id="集成学习">集成学习</span></h1><blockquote>
<p>众所周知，三个臭皮匠顶个诸葛亮，人无完人，模型无完模型，永远没有百分百准确率的模型。<br>一个准确率为99.9%的模型，仍可能有0.1%的比例会判断错误，那么如何在上一层楼呢？我们可以通过再训练一个对漏过的数据更精准的模型，在第一个大模型的判断基础上，再次判断。</p>
</blockquote>
<p>用人举个例子：</p>
<ol>
<li>诸葛亮出了主意以后，县令可以在此基础上，再次判断，得到更精准的答案，这就是提升数的基本思想。</li>
<li>所有人一起投票，投票最多的选项，大概率为最佳选项，这就是bagging的基本思想。</li>
</ol>
<h2><span id="bagging">bagging</span></h2><p>举例：随机森林</p>
<h2><span id="boosting">boosting</span></h2><p>举例：GBDT</p>
<p><strong>疑问</strong><br>既然后面的树是在拟合前面树的残差，那提升树可以做预训练模型吗？</p>
<h1><span id="随机森林">随机森林</span></h1><blockquote>
<p>随机森林是一种集成机器学习算法，可用于分类和回归任务。它是多个决策树的组合，其中每棵树都是使用数据的随机子集和特征的随机子集来生长的。最终的预测是通过对森林中所有树木的预测进行平均来做出的。</p>
</blockquote>
<p>使用多个决策树背后的想法是，虽然单个决策树可能容易过度拟合，但决策树的集合或森林可以降低过度拟合的风险并提高模型的整体准确性。构建随机森林的过程首先使用一种称为引导的技术创建多个决策树。Bootstrapping 是一种统计方法，涉及从原始数据集中随机选择数据点并进行替换。这会创建多个数据集，每个数据集都有一组不同的数据点，然后用于训练单个决策树。随机森林的另一个重要方面是为每棵树使用随机的特征子集。这称为随机子空间方法。这减少了森林中树木之间的相关性，进而提高了模型的整体性能。</p>
<h2><span id="优点">优点</span></h2><p>随机森林的主要优点之一是它比单个决策树更不容易过度拟合。多棵树的平均可以消除误差并减少方差。随机森林在高维数据集和具有大量 calcategories 变量的数据集中也表现良好。</p>
<h2><span id="缺点">缺点</span></h2><p>随机森林的缺点是训练和预测的计算成本可能很高。随着森林中树木数量的增加，计算时间也会增加。此外，随机森林比单个决策树的可解释性更差，因为更难理解每个特征对最终预测的贡献。</p>
<h2><span id="总结">总结</span></h2><p>总之，随机森林是一种强大的集成机器学习算法，可以提高决策树的准确性。它不太容易过度拟合，并且在高维和分类数据集中表现良好。然而，与单个决策树相比，它的计算成本较高且可解释性较差。</p>
<h2><span id="使用场景">使用场景</span></h2><p>&gt;</p>
<blockquote>
<p>在什么情况下，会使用决策树呢？</p>
</blockquote>
<ol>
<li>模型可解释性强</li>
</ol>
<h2><span id="问题">问题</span></h2><ol>
<li>为什么每个独立的树不能基于所有数据训练？</li>
<li>等同于第一个问题，训练好几种不同的模型，再共同投票，跟随机森林的差别是什么？</li>
</ol>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>朴素贝叶斯</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote>
<p>该算法通过使用贝叶斯定理来计算给定输入特征值的给定类别的概率。贝叶斯定理指出，给定一些证据（在本例中为特征值）的假设（在本例中为类别）的概率与给定假设的证据的概率乘以假设的先验概率成正比。朴素贝叶斯算法可以使用不同类型的概率分布（例如高斯分布、多项式分布和伯努利分布）来实现。高斯朴素贝叶斯用于连续数据，多项式朴素贝叶斯用于离散数据，伯努利朴素贝叶斯用于二进制数据。</p>
</blockquote>
<h2><span id="优点">优点</span></h2><p>朴素贝叶斯的主要优点之一是它的简单性和效率。它易于实现，并且比其他算法需要更少的训练数据。它在高维数据集上也表现良好，并且可以处理丢失的数据。</p>
<h2><span id="缺点">缺点</span></h2><p>朴素贝叶斯的主要缺点是假设特征之间的独立性，这在现实世界的数据中通常是不正确的。这可能会导致预测不准确，尤其是当特征高度相关时。此外，朴素贝叶斯对数据集中不相关特征的存在很敏感，这可能会降低其性能。</p>
<h2><span id="总结">总结</span></h2><p>综上所述，朴素贝叶斯是一种简单高效的机器学习算法，基于贝叶斯定理，用于分类任务。它在高维数据集上表现良好，并且可以处理丢失的数据，但它的主要缺点是假设特征之间的独立性，如果数据不独立，则可能导致预测不准确。</p>
<h2><span id="使用场景">使用场景</span></h2><p>&gt;</p>
<blockquote>
<p>朴素贝叶斯有如此明显的优点和缺点，那么什么情况下，会使用朴素贝叶斯呢？</p>
</blockquote>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>朴素贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title>舍不得看完的中国史</title>
    <url>/posts/%E5%8E%86%E5%8F%B2/%E8%88%8D%E4%B8%8D%E5%BE%97%E7%9C%8B%E5%AE%8C%E7%9A%84%E4%B8%AD%E5%9B%BD%E5%8F%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>《舍不得看完的中国史》 — 渤海小吏</p>
]]></content>
  </entry>
  <entry>
    <title>金句摘抄</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E9%87%91%E5%8F%A5%E6%91%98%E6%8A%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3><span id="异类">《异类》</span></h3><p>1、成功源自优势的不断积累：你出生在何时何地，你父母的职业以及你成长的环境，这三者相互作用才塑造出这个世界上独特的你。<br>2、有些人的成功当之无愧，有些人则不是；有些人依靠个人实力赚到钱，有些人却只是单凭运气――所有这些对他们知道自己是谁很关键。<br>3、人生的真正差异不在于非凡的天赋，而在于非比寻常的机遇。<br>4、并不是这些人比其他的律师更聪明，只是因为他们工作了几十年之后所磨练出的技巧，突然之间变得很有价值。</p>
<h3><span id="洗脑术">《洗脑术》</span></h3><ol>
<li>洗脑是一个让我们感觉良好的睡前故事，每当我们感到恐惧或迷茫，就把它呼唤出来解释那些令我们紧张的事物。在20世纪50年代和60年代，那是苏联人；70年代，是新兴宗教运动和广告公司；80年代，是重金属。洗脑就像蝙蝠侠，冲破黑夜拯救我们。它对我们说：这不是你们的错，你们无能为力，无需为此负责，你们是受害者。<br>2 在中情局的各种吐实药中，没有一种被证实比古老的“吐实药”更加有效。在对44名受试者实施了132项试验之后，他们发现大麻的药效最强，紧随其后的是酒精和咖啡因――就是啤酒加咖啡。<br>3 在情报界，能迫使他人违背自己利益行事的手段一直极具吸引力，催眠带来了这种可能。战略情报局一度认真地考虑训练一名德国人“在催眠状态下产生难以压抑的冲动，暗杀希特勒”。但精神病学家认为没有成功的希望：如果被催眠的人没有杀人动机，这么做很难；但如果真的找到了这样的人，直接叫他这么做不是简单得多吗？</li>
<li>中情局的专家乐观地相信，大脑是轻易就能胡乱摆弄的器官。然而，实际情况复杂得多。使人情绪失控、失魂落魄都是可以做到的，但是“吐实药”勾起的幻想和套出的真话一样多；LSD每次引发的结果都不同；催眠不可靠；潜意识信息以“无效”画上句号；电击休克法制造健忘症好比用木槌关闭笔记本电脑。</li>
<li>脱胎于冷战虚构文学的洗脑并不意味着它了无一物。干扰大脑的手段确实存在，也的确可以强迫他人改变信仰。使人们远离他们的社会环境能减少遭到严厉指责的几率；剥夺人们的睡眠和食物能摧毁他们的抵抗；让人们恐惧、忙碌，向他们灌输负罪感也能让他们俯首听命。但是说到底，就算把这些都用上，依然无法稳操胜券。神奇而科学的洗脑是不存在的。</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>九型人格</title>
    <url>/posts/%E5%BF%83%E7%90%86%E5%AD%A6/%E4%B9%9D%E5%9E%8B%E4%BA%BA%E6%A0%BC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="简述">简述</span></h2><p>九型人格，又被称为“性格型态学”，它包括活跃程度；规律性；感兴趣的范围；反应的强度；心理的素质；分心程度；专注力范围/持久性。</p>
<blockquote>
<p>九型人格是一个近年来倍受美国斯坦福大学等国际知名大学MBA学员推崇并成为现今最热门的课程之一，近十几年来已风行欧美学术界及工商界。全球500强企业的管理阶层均有研习九型性格，并以此培训员工，建立团队，提高执行力。九型人格作为一个人格心理学理论在当前社会还未被主流心理学界认可。<br>九型人格不仅仅是一种精妙的性格分析工具，更主要的是为个人修养、自我提升和历练提供更深入的洞察力。与当今其它性格分类法不同，九型人格揭示了人们内在最深层的价值观和注意力焦点，它不受表面的外在行为的变化所影响。它可以让人真正地知己知彼；可以帮助人们明白自己的个性，从而完全接纳自己的短处、活出自己的长处；可以让人明白其它不同人的个性类型，从而懂得如何与不同的人交往沟通及融洽相处，与别人建立更真挚、和谐的合作伙伴关系。<br><a href="https://baike.baidu.com/item/%E4%B9%9D%E5%9E%8B%E4%BA%BA%E6%A0%BC/9222652?fr=ge_ala">定义详见百度百科</a></p>
</blockquote>
<p>该性格分法不同于mbti，他更注重内心感知事物的注意力在哪、价值观如何。mbti更注重的是思考的方式，如何获取信息、思考信息、感知信息、产出结论；</p>
<h3><span id="九型人格能够带来什么">九型人格能够带来什么？</span></h3><p>九型人格论是一门讲求实践效益的学科，属人格心理学范畴，是应用心理学中的一种，其应用范围广泛，有助于个人成长、企业管理及人际沟通和关系处理，特别适于企事业单位在人员招聘、组织构建、团队沟通过程中，作为评价人员性格的工具，更扩展至夫妻相处、子女教育及亲子关系等方方面面。九型人格论把人格清晰简洁的分成九种类型，每种类型都有其鲜明的人格特征。九型人格论所描述的九种人格类型，并没有好坏之别，只不过不同类型的人回应世界的方式具有可被辨识的根本差异。九型人格是一张详尽描绘人类性格特征的活地图，是一件与人沟通、有效交流的利器！</p>
<h2><span id="注意力区域划分">注意力区域划分</span></h2><p>凯伦-韦布的区域划分（三大直觉中心）<br>腹中心：8 9 1，或者称为生存（行为模式）中心，以<strong>身体力行</strong>为导向，对生存的问题直觉最强。<br>脑中心：5 6 7，或者称为资讯（思维模式）中心，以<strong>思考和分析</strong>为导向，对现实事物的运动现象直觉最强。<br>心中心：2 3 4，或者称为情感（情绪模式）中心，以<strong>感受和想象</strong>为导向，对人情和环境的气氛直觉最强。</p>
<h2><span id="价值观划分">价值观划分</span></h2><p>九型人格与当今各种性格分类法的最大区别在于，九型性格揭示了人们内在最深层的价值观和注意力焦点，它不受表面的外在行为的变化所影响：</p>
<ul>
<li>深入观察发现“我是谁”</li>
<li>你的思维模式及怎样影响你的决策</li>
<li>你的价值取向及怎样影响你的事业</li>
<li>你的情绪反应及怎样影响你的人际</li>
<li>你的行为方式及怎样影响你成长</li>
<li>你个性的优势与局限</li>
<li>你在事业发展中的个性障碍及突破的方向</li>
<li>你在人际关系中的个性冲突及改善的技巧</li>
<li>你在亲密关系中的个性困扰及解决的方法</li>
</ul>
<h2><span id="障碍种类及表现"><strong>障碍种类及表现</strong></span></h2><div class="table-container">
<table>
<thead>
<tr>
<th>障碍种类</th>
<th>表现</th>
</tr>
</thead>
<tbody>
<tr>
<td>偏执型人格障碍</td>
<td>以猜忌和偏执为主要特点。表现出一般性猜疑，不信赖或者疑惑他人，过分警戒与防守;强烈地意识到自己的主要性，有将四周发生的事件说明为“诡计”、不合乎事实的<a href="https://baike.baidu.com/item/先占观念/53288499?fromModule=lemma_inlink">先占观念</a>;过火自信，以为自己准确，将挫折和失败归罪于他人;容易发生病感性嫉妒;对挫折和谢绝特别敏感，不能体谅别人，长期耿耿于怀，常与人发生争执或沉湎于诉讼，人际关系不良。</td>
</tr>
<tr>
<td>决裂型人格障碍</td>
<td>以观点、外貌和行动独特，人际关联有显明缺点和感情冷漠为重要特色。对喜事缺乏高兴感，对人冷淡，对生涯缺少热忱和兴致，孤单古怪，缺乏知音，刚愎自用，很少与人交往，因而也较少与人产生抵触。</td>
</tr>
<tr>
<td>冲动型人格障碍</td>
<td>又称<a href="https://baike.baidu.com/item/暴发型/53721216?fromModule=lemma_inlink">暴发型</a>或袭击型的<a href="https://baike.baidu.com/item/人格障碍/3169525?fromModule=lemma_inlink">人格障碍</a>。以行为和情绪存在显著的激动性为主要特点。发生不预兆，不考虑成果，不能自控，易与他人发生矛盾。发生之后能意识错误，间歇期普通表现畸形。患者<a href="https://baike.baidu.com/item/心理发育/55475381?fromModule=lemma_inlink">心理发育</a>不成熟，断定剖析能力差,惯用和少用的内感官，轻易被人教唆鼓动，对他人和社会表现出敌意、攻打和损坏行为。</td>
</tr>
<tr>
<td>依赖型人格障碍</td>
<td>又称之为<a href="https://baike.baidu.com/item/艺术型/12612783?fromModule=lemma_inlink">艺术型</a>人格障碍。主要特点是极度依赖他人。他们固然有较好的工作能力，但因为缺乏自信念，缺乏独破能力，遇事没有主意，事事依赖别人。自以为笨拙，对别人的看法从不反驳，对长辈和上级驯如绵羊，对配偶也是唯命是从,理智型的个性特质。生活中的大事，好比抉择职业、<a href="https://baike.baidu.com/item/找对象/4579901?fromModule=lemma_inlink">找对象</a>等，老是依附别人来替他作出决议或指出方向</td>
</tr>
<tr>
<td>癔症型人格障碍</td>
<td>又称<a href="https://baike.baidu.com/item/表演型人格障碍/112521?fromModule=lemma_inlink">表演型人格障碍</a>。好情感用事，名义上显得热情、讨人爱好，但缺乏真挚，易变而成熟。行为特点是大吹大擂，矫揉造作。他们盼望本人的言行能引起别人的关注，<a href="https://baike.baidu.com/item/虚荣心/1436076?fromModule=lemma_inlink">虚荣心</a>强，<a href="https://baike.baidu.com/item/自我核心/22324286?fromModule=lemma_inlink">自我核心</a>，自我放荡，常对小事<a href="https://baike.baidu.com/item/情感反映/3921313?fromModule=lemma_inlink">情感反映</a>过于强烈，有时无故发性格。他们的请求特殊多，依附性强，总愿望得到别人的照料，而很少为别人着想。他们的生活，有时就如戏剧个别，追求刺激，<a href="https://baike.baidu.com/item/暗示性/10576569?fromModule=lemma_inlink">暗示性</a>强。</td>
</tr>
<tr>
<td>逼迫型人格障碍</td>
<td>以要求严厉和完美为主要特点。有以下表现：<strong>1.不断定感</strong>。仿佛觉得所面对的世界不肯定，偶尔和意外的事件太多，应用自己制订的“法则”来加以抗衡，拘泥于情势、规矩、次序，做事安分守己、墨守成规，刻板执拗，不能随机应变，有僵化的特别作风。常喜欢计数，偏好对称，有巫术偏向,和平型，把偶尔的表面景象与自己的利弊相接洽。<strong>2.不保险感</strong>。做事过于细心谨严,重复检讨核查,唯恐忽视和错误，为了平安不惜就义效力跟经济。自我猜忌有无才能、念头是否纯粹等。遇事就心境缓和，总象面临重大考验似的。<strong>3.寻求完善</strong>。追求美中不足，对己斥责求全，求全责备，但又缺乏自负。</td>
</tr>
<tr>
<td>反社会型人格障碍</td>
<td>亦称<a href="https://baike.baidu.com/item/悖德型人格障碍/7230206?fromModule=lemma_inlink">悖德型人格障碍</a>。其最明显的行为特点是疏忽社会<a href="https://baike.baidu.com/item/道德标准/862443?fromModule=lemma_inlink">道德标准</a>、<a href="https://baike.baidu.com/item/行为准则/3986118?fromModule=lemma_inlink">行为准则</a>和任务，没有恻隐同情之心，对他人的感触不闻不问。这种人的智力发育良好但<a href="https://baike.baidu.com/item/易激惹/10456854?fromModule=lemma_inlink">易激惹</a>，常发生冲动<a href="https://baike.baidu.com/item/性行为/1282989?fromModule=lemma_inlink">性行为</a>;即便给别人造成苦楚，也很少感内疚，缺乏罪反感;因此常发生不负义务的行为，甚至是守法乱纪的行为，虽屡受处分，也不易接受教训，屡教不改。<a href="https://baike.baidu.com/item/临床表现/9731119?fromModule=lemma_inlink">临床表现</a>的中心是缺乏自我把持能力。</td>
</tr>
<tr>
<td>自恋型人格障碍</td>
<td>这种人主要表示为过份地自我关怀、自诩自尊。比方自认为是了不起的人物，夸张自己的成绩、能力与外貌。往往异想天开，沉沦于空想之中。平时好出风头，喜欢得到别人的留神和称颂,环境保护的挑战。不能接收别人的倡议和批驳，从不斟酌别人的好处，要求别人都按自己的志愿去做，对人对事不能辩证地看，讨论人时很极端。不能替别人着想，不懂得别人的难处和苦衷。</td>
</tr>
<tr>
<td>躲避型人格障碍</td>
<td>特点是行为退缩、心理自大，面对挑衅多采用回避立场或无能敷衍。不敢深刻到自己心灵的内部去，他们的回避带有强制性、盲目性和非理智性等特点。</td>
</tr>
</tbody>
</table>
</div>
<p><img data-src="./format,f_auto.jpeg" alt="九型人格性格"></p>
<h2><span id="性格演变路线">性格演变路线</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th>美德</th>
<th>原罪</th>
<th>性格惯性</th>
<th>破解</th>
</tr>
</thead>
<tbody>
<tr>
<td>平静</td>
<td>愤怒</td>
<td>批判</td>
<td>耐性</td>
</tr>
<tr>
<td>谦卑</td>
<td>骄傲</td>
<td>服务</td>
<td>爱己如人</td>
</tr>
<tr>
<td>诚实</td>
<td>虚假</td>
<td>修饰</td>
<td>不做作</td>
</tr>
<tr>
<td>自在</td>
<td>嫉妒</td>
<td>幻想</td>
<td>自制力</td>
</tr>
<tr>
<td>放下</td>
<td>贪心</td>
<td>偏执</td>
<td>分享</td>
</tr>
<tr>
<td>勇气</td>
<td>恐惧</td>
<td>怀疑</td>
<td>相信</td>
</tr>
<tr>
<td>节制</td>
<td>贪吃</td>
<td>乐观</td>
<td>承受</td>
</tr>
<tr>
<td>纯真</td>
<td>欲望</td>
<td>政府</td>
<td>同理心</td>
</tr>
<tr>
<td>行动</td>
<td>懒惰</td>
<td>传统</td>
<td>独立</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="预期期望">预期期望</span></h2><p>九型人格中<strong>第一型</strong>会要求<a href="https://baike.baidu.com/item/自我控制/1810124?fromModule=lemma_inlink">自我控制</a>、合理、规律，并且延迟奖励的能力，他们的孩子是一个小成年人。</p>
<p>九型人格中<strong>第二型</strong>会要求宽厚、有思想、有用，并且注意他人，他们的孩子是一个小帮手。</p>
<p>九型人格中<strong>第三型</strong>会要求处事卓越，履行家庭的希望，外型完美，并且非常受欢迎，他们的孩子是一个小的明星。</p>
<p>九型人格中<strong>第四型</strong>会要求敏感、艺术的创造性，情感深度和了解，他们的孩子是一位小治疗师。</p>
<p>九型人格中<strong>第五型</strong>会要求独立、用功、聪颖和有<a href="https://baike.baidu.com/item/求知欲/3240264?fromModule=lemma_inlink">求知欲</a>，他们的孩子是一个小天才。</p>
<p>九型人格中<strong>第六型</strong>会要求可靠、守纪律、坚持不懈并且可信赖，他们的孩子是一位忠于工作信念的人。</p>
<p>九型人格中<strong>第七型</strong>会要求生命力、幽默、韧性和自然，他们的孩子是一位小艺人。</p>
<p>九型人格中<strong>第八型</strong>会要坚强的、自给自足、勇气和自我克制力，他们的孩子是一位小企业家。</p>
<p>九型人格中<strong>第九型</strong>会要求安静、压抑要求、温和并且不要求，他们的孩子是一个小天使。</p>
<p>孩子的求知欲往往使父母惊奇，支持儿童以自己的方式去展开未来。<a href="https://baike.baidu.com/item/亲子关系/17644287?fromModule=lemma_inlink">亲子关系</a>中只有一件事是肯定的，孩子将显现出意想不到的能力和处事方式如果父母设法阻拦儿童自然的开展，孩子将不会成功，仅会成为扭曲的人或<a href="https://baike.baidu.com/item/神经病/183922?fromModule=lemma_inlink">神经病</a>患者。父母必须<a href="https://baike.baidu.com/item/观察儿童/4510870?fromModule=lemma_inlink">观察儿童</a>的类型，并且以儿童所属型号的最佳发展来与他相处，而不是意图去改变他们。</p>
<p><a href="https://baike.baidu.com/item/%E4%B9%9D%E5%9E%8B%E4%BA%BA%E6%A0%BC/9222652?fr=ge_ala#6_3">参考百度百科</a><br><a href="https://zhuanlan.zhihu.com/p/42827329?from=groupmessage">参考知乎</a></p>
]]></content>
  </entry>
  <entry>
    <title>mbti不同人格的历史人物集合</title>
    <url>/posts/%E5%BF%83%E7%90%86%E5%AD%A6/mbti%E4%B8%8D%E5%90%8C%E4%BA%BA%E6%A0%BC%E7%9A%84%E5%8E%86%E5%8F%B2%E4%BA%BA%E7%89%A9%E9%9B%86%E5%90%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="enfp">enfp</span></h1><p>李白、苏轼</p>
<h1><span id="istj">istj</span></h1><p>高适</p>
<blockquote>
<p>Todo：大坑，一点一点填</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>晚点</title>
    <url>/posts/%E4%B9%A6%E5%8D%95/%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%99%9A%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mjk1OTQ0Ng==&amp;action=getalbum&amp;album_id=1480239092163526656#wechat_redirect">长报道集合</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mjk1OTQ0Ng==&amp;action=getalbum&amp;album_id=1897429172814200832#wechat_redirect">对话集合</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mjk1OTQ0Ng==&amp;action=getalbum&amp;album_id=1389415061881683968#wechat_redirect">字节</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mjk1OTQ0Ng==&amp;action=getalbum&amp;album_id=1390313666498854914#wechat_redirect">阿里</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mjk1OTQ0Ng==&amp;action=getalbum&amp;album_id=2006351155009781761#wechat_redirect">大公司最有影响力的人</a></p>
]]></content>
  </entry>
  <entry>
    <title>十点读书</title>
    <url>/posts/%E4%B9%A6%E5%8D%95/%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%8D%81%E7%82%B9%E8%AF%BB%E4%B9%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1568975195799879681#wechat_redirect">1000本好书</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1621012091610398721#wechat_redirect">文学经典</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1620846839975444482#wechat_redirect">影视经典</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1620868945903681538#wechat_redirect">生活智慧</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1620886480426434563#wechat_redirect">人际关系</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1625224812614713345#wechat_redirect">四大名著</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1865762539700027394#wechat_redirect">读三国</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1868676242879610883#wechat_redirect">读名著</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1870418230142369792#wechat_redirect">名人堂</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDMyMzg2MA==&amp;action=getalbum&amp;album_id=1887650822734282758#wechat_redirect">民国风范</a></p>
]]></content>
  </entry>
  <entry>
    <title>阿猫读书</title>
    <url>/posts/%E4%B9%A6%E5%8D%95/%E5%85%AC%E4%BC%97%E5%8F%B7/%E9%98%BF%E7%8C%AB%E8%AF%BB%E4%B9%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1296553807849144320#wechat_redirect">理财投资类</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1319040509263953921#wechat_redirect">思维认知类</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=2030989786773012483#wechat_redirect">买房思考</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1303494635976867842#wechat_redirect">高分好书</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1658471168825212932#wechat_redirect">问答分享</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1314738114677653506#wechat_redirect">B站推荐</a><br><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI0MDc3MTE5Mg==&amp;action=getalbum&amp;album_id=1727874967381327874#wechat_redirect">随心感悟</a></p>
]]></content>
  </entry>
  <entry>
    <title>鬼谷子识人之道</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E9%AC%BC%E8%B0%B7%E5%AD%90%E8%AF%86%E4%BA%BA%E4%B9%8B%E9%81%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>今日，读《鬼谷子》一书，书中有一沟通之道，颇感深奥，仔细思虑良久，记录之。</p>
<blockquote>
<p>一般说来，游说有智谋的人要靠博识多见的言辞，以显示自身的博学，游说博闻多见的人要靠条理明辨的言辞，游说明辨事理的人要依靠言辞中要点明确。游说高贵的人要依靠言辞中有气势，要以高雅潇洒为原则，游说富人要靠我们谈话时豪气冲天，游说贫穷的人要靠言辞中以利引诱，游说低贱的人要靠我们谈话时态度谦恭，游说勇士要靠我们谈话时表情果敢，游说愚蠢的人要靠我们把利害讲得明明白白。这就是游说之术。</p>
</blockquote>
<p>我刚开始也觉得有点抽象，但是我大概在书本上画了画， 其实就是对人的性格进行了归类，这是我的思考。</p>
<p>有智谋的人，一般都比较聪明，会有些小点子，因此他会更钦佩见多识广的人，能扩充他的认知。<br>博学的人，一般爱好广泛，但因精力有限，每一项都不精通，因此他会更佩服见识更深的人，这类人一般条理清晰，更有逻辑。<br>明辨事理的人，一般是s型，喜欢钻研，爱好不需要广泛，他更佩服逻辑清晰，目标清晰，有条理，会抓重点的人，引领他钻对方向。</p>
<p>高贵的人，一般很清高，看不起世俗，一般喜欢往上攀，所以得比他更有权势，或者看透世俗<br>富贵的人，有钱则豪横，如果低声下气，他更看不起。<br>贫穷的人，一般认知较差，而且通常会互相扶持，所以很好忽悠，只要以利引诱，就能瓦解<br>低贱的人，更在意他的出身，或者自身的缺陷，所以更得礼遇<br>勇士，一般会往前冲，不在意逻辑，思考得不够深渊，跟他们要讲气节，<br>愚蠢的人，讲道理他们是不懂的，“民可使由之，不可使知之”，就告诉他们利害关系，不要告诉他们为什么这么做。 让他们自己做出选择，做错了也不会怪你了。</p>
]]></content>
  </entry>
  <entry>
    <title>面对工作不如意我该怎么处理？</title>
    <url>/posts/%E6%80%9D%E8%80%83/%E9%9D%A2%E5%AF%B9%E5%B7%A5%E4%BD%9C%E4%B8%8D%E5%A6%82%E6%84%8F%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>近日又重温了不知道看了多少遍的《大明王朝：1566》，职场如官场，官场比职场恐怖、残酷、邪恶不知多少倍，想在书中学到一些职场生存之道，提升一些自己的认知。<br>今日与同事聊天偶发奇想，现代职场中，如果我们干的不舒服了，不顺心了，尚可跳槽，而古代官员们无法跳槽，他们是如何处理工作不顺心的问题的呢？</p>
<h2><span id="面对工作不如意该如何处理">面对工作不如意该如何处理？</span></h2><p>本文不会系统性得梳理所有情况，也不会沉淀什么方法论，只是想到哪说到哪。</p>
<p>有同事总说，“谁谁怎么能这样？生平第一次见到如此恶心的人。”、“我真是受不了他了，他脑子真是有病”。 我有时也会抱怨，但抱怨过后，好像并不能解决什么。</p>
<p>伟大的政治家们徐阶、张居正，甚至人人喊打的严嵩他们是怎么处理这种情况的呢？<br>面对嘉靖帝“政不由己出”的不作为、甩锅行为，他们难道看不出来吗？看出来为什么不抱怨呢？</p>
<p>事实上，如果他们抱怨的话，可能脑袋早就搬家了，也不会入阁拜相，名留青史了，任何一位皇帝决不允许有人对自己有任何负面意见。<br>于是乎，他们只能认同老板的观点、行为、结论。</p>
<p>所以问题就有变化了：<br>“这个工作环境为什么这么烂？”变为“这个工作环境这么烂我该怎么办？”<br>一味地吐槽没有任何意义，反而会增加祸端；<br>世间不如意者十有八九，你现在所抱怨的问题，换一个环境不一定就解决了。 所以第一宗旨一定是，我该怎么办，而不是吐槽。</p>
<h2><span id="那工作不如意我该怎么办呢">那工作不如意我该怎么办呢？</span></h2><p>身处大环境下，接受不如意，接受不顺心，接受难题！ 这个是问题的根本。<br>当然你可以选择跳槽，换一个环境，这个不在本文的讨论范围内，本文只讨论无法跳出环境的情况下如何解决问题。之前看过一句话“人生要做选择题，要少做证明题”，有机会再展开讲。</p>
<p>首先不要有任何负面情绪，不要只吐槽，那是没有任何意义的，吐槽无法给你带来质的改变，只有可能带来短期的快乐和由于隔墙有耳带来长期的打压、报复，生活会更不如意。</p>
<p>然后再思考，这个环境的好处和坏处是什么？ 好处能给你直接带来什么好处？ 坏处能不能转换一下，间接给你带来好处？<br>这个问题其实很绕，很多人想不明白，或者说，没想透。</p>
<p>我举个例子，如果领导很水，大领导催他，他也只会催你，给你带来无尽的活与痛苦，这个时候如果不抱怨，怎么将坏处转化为好处呢？<br>想清楚问题的根本，坏处是因为他没有判断力和担当能力，所以大领导催他，他就只会催你，那你是不是也可以反过来催他，让他去催大领导呢？<br>这里要讲究方法，比如可以诉苦，老板咱们没人力，没时间，没资源做这件事，如果压缩工期的话，导致做出来的质量很差，很有可能留坑，以后炸了对你影响更大。</p>
<h2><span id="我为什么不能成功">我为什么不能成功</span></h2><p>善用资源，一定要“利用”身边的资源，不好意思麻烦别人，不好意思张口自己研究，终将只有自己的力量，是无法长久的。</p>
<p>未完待续~~</p>
]]></content>
      <categories>
        <category>认知升级</category>
      </categories>
      <tags>
        <tag>认知升级</tag>
      </tags>
  </entry>
  <entry>
    <title>4R原子法</title>
    <url>/posts/%E5%BF%83%E7%90%86%E5%AD%A6/4R%E5%8E%9F%E5%AD%90%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>提示 -&gt; 渴求 -&gt; 反应 -&gt; 激励</p>
]]></content>
  </entry>
  <entry>
    <title>贝尔宾团队角色</title>
    <url>/posts/%E6%80%9D%E8%80%83/%E8%B4%9D%E5%B0%94%E5%AE%BE%E5%9B%A2%E9%98%9F%E8%A7%92%E8%89%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>贝尔宾团队角色共有9种角色，资料来自<a href="https://wiki.mbalib.com/wiki/%E8%B4%9D%E5%B0%94%E5%AE%BE%E5%9B%A2%E9%98%9F%E8%A7%92%E8%89%B2%E7%90%86%E8%AE%BA">智库wiki</a>：</p>
<p>智多星PL（Plant）</p>
<p>　　智多星创造力强，充当创新者和发明者的角色。他们为团队的发展和完善出谋划策。通常他们更倾向于与其他团队成员保持距离，运用自己的想象力独立完成任务，标新立异。他们对于外界的批判和赞扬反应强烈，持保守态度。他们的想法总是很激进，并且可能会忽略实施的可能性。 他们是独立的、聪明的、充满原创思想的，但是他们可能不善于与那些气场不同的人交流。</p>
<p>　　外交家RI（Resource Investigator）</p>
<p>　　外交家是热情的、行动力强的、外向的人。无论公司内外，他们都善于和人打交道。他们与生俱来是谈判的高手，并且善于挖掘新的机遇、发展人际关系。虽然他们并没有很多原创想法，但是在听取和发展别人想法的时候，外交家效率极高。就像他们的名字一样，他们善于发掘那些可以获得并利用的资源。由于他们性格开朗外向，所以无论到哪里都会受到热烈欢迎。 外交家为人随和，好奇心强，乐于在任何新事物中寻找潜在的可能性。然而，如果没有他人的持续激励，他们的热情会很快消退。</p>
<p>　　审议员ME（Monitor Evaluator）</p>
<p>　　审议员是态度严肃的、谨慎理智的人，他们有着与生俱来对过份热情的免疫力。他们倾向于三思而后行，做决定较慢。通常他们非常具有批判性思维。他们善于在考虑周全之后作出明智的决定。具有审议员特征的人所作出的决定，基本上是不会错的。</p>
<p>　　协调者CO（Co-ordinator）</p>
<p>　　协调者最突出的特征就是他们能够凝聚团队的力量向共同的目标努力。成熟、值得信赖并且自信，都是他们的代名词。在人际交往中，他们能够很快识别对方的长处所在，并且通过知人善用来达成团队目标。虽然协调者并不需是团队中最聪明的成员，但是他们拥有远见卓识，并且能够获得团队成员的尊重。</p>
<p>　　鞭策者SH（Shaper）</p>
<p>　　鞭策者是充满干劲的、精力充沛的、渴望成就的人。通常，他们非常有进取心，性格外向，拥有强大驱动力。他们勇于挑战他人，并且关心最终是否胜利。他们喜欢领导并激励他人采取行动。在行动中如遇困难，他们会积极找出解决办法。他们是顽强又自信的，在面对任何失望和挫折时，他们倾向于显示出强烈的情绪反应。鞭策者对人际不敏感，好争辩，可能缺少对人际交往的理解。这些特征决定了他们是团队中最具竞争性的角色。</p>
<p>　　凝聚者TW（Teamworker）</p>
<p>　　凝聚者是在团队中给予最大支持的成员。他们性格温和，擅长人际交往并关心他人。他们灵活性强，适应不同环境和人的能力非常强。凝聚者观察力强，善于交际。作为最佳倾听者的他们通常在团队中倍受欢迎。他们在工作上非常敏感，但是在面对危机时，他们往往优柔寡断。</p>
<p>　　执行者IMP（Implementer）</p>
<p>　　执行者是实用主义者，有强烈的自我控制力及纪律意识。他们偏好努力工作，并系统化地解决问题。广而言之，执行者是典型的将自身利益与忠诚与团队紧密相连、较少关注个人诉求的角色。然而，执行者或许会因缺乏主动而显得一板一眼。</p>
<p>　　完成者CF（Completer Finisher）</p>
<p>　　完成者是坚持不懈的、注重细节的。他们不太会去做他们认为完成不了的任何事。他们由内部焦虑所激励，但表面看起来很从容。一般来说，大多数完成者都性格内向，并不太需要外部的激励或推动。他们无法容忍那些态度随意的人。完成者并不喜欢委派他人，而是更偏好自己来完成所有的任务。</p>
<p>　　专业师SP（Specialist）</p>
<p>　　专业师是专注的，他们会为自己获得专业技能和知识而感到骄傲。他们首要专注于维持自己的专业度以及对专业知识的不断探究之上。然而由于专业师们将绝大多数注意力都集中在自己的领域，因此他们对其他领域所知甚少。最终，他们成为了只对专一领域有贡献的专家。但是很少有人能够一心一意钻研，或有成为一流专家的才能。</p>
<p>我的角色：</p>
<p><img data-src="image-20230223104543825.png" alt="我的角色"></p>
]]></content>
  </entry>
  <entry>
    <title>摄影书单</title>
    <url>/posts/%E4%B9%A6%E5%8D%95/%E6%91%84%E5%BD%B1%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="文章合集">文章合集</span></h2><p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&amp;__biz=MjM5MTY4NjUyOA==&amp;scene=1&amp;album_id=1460145326458994688&amp;count=3#wechat_redirect">摄影科普</a></p>
]]></content>
      <categories>
        <category>书单</category>
        <category>摄影资源</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>摄影资源</tag>
      </tags>
  </entry>
  <entry>
    <title>百望山</title>
    <url>/posts/%E6%95%A3%E6%96%87%E8%AF%97/%E7%99%BE%E6%9C%9B%E5%B1%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>回首百望，荆棘满路，划痕还在，血迹却已经干了。</p>
]]></content>
  </entry>
  <entry>
    <title>如何成为稀缺人才</title>
    <url>/posts/%E6%80%9D%E8%80%83/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E7%A8%80%E7%BC%BA%E4%BA%BA%E6%89%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://mp.weixin.qq.com/s?__biz=MzIxNTAzNzU0Ng==&amp;mid=2654755913&amp;idx=1&amp;sn=27371d3c45bfd6eab5d60fbfb29efc15&amp;chksm=8c569f4cbb21165a63c1b1f1236a5c8aad212c2742ca39c14ee2e1b0ab9f4356d57b00e74553&amp;scene=21#wechat_redirect">笔记侠读后感</a></p>
<p>不是习惯驱动的成功，终将成为过去。</p>
<h3><span id="六个人才档次">六个人才档次</span></h3><blockquote>
<p>“下君尽己之能，中君尽人之力，上君尽人之智。”我建议所有管理人员都好好思考一下这句话。<br>这句话出自《韩非子》，意思是，低水平的人实际上只是依靠自己的能力在苦干；中等水平的人可以运用别人的力量来做事；高水平的人可以激发别人的智慧来实现目标。<br>管理人员应该具备后两种能力，不仅能够激励团队成员积极工作，还能够发挥团队的智慧去突破和创新。</p>
</blockquote>
<p>个人能力再强，也只是个优秀的打工仔。 很多诺贝尔奖颁给的项目，也是多人负责的，很少有独立负责就能获得最高成就的。  想要成功，就要依托团队的力量。<br>在高一点层次的人才，会学会如何利用他人的力量，得到的成果会跃升一个数量级。 但如果只能基于自己的脑力，利用他人的劳动力，那得到的收获只有数量级上的增长，无法得到质量上的突破。<br>第三个层次，学会激发别人的智慧来实现自己的目标，不能仅仅用其蛮力，可用其智创造财富。</p>
<p>员工的价值如何衡量，价值来源于稀缺性和不可替代性。<br>员工的目标是使自己在组织中变得有价值，让自己最终成为不可替代的人。</p>
<p>我们往往会产生一种错觉，把平台的价值当成了自己的价值，而没有思考自己的能力是否真正提升了。</p>
<p>员工价值=能力×价值观×心智模式。</p>
<p>这个公式告诉我们，提升自己有三个大的努力方向：<br>第一，提升个人能力；<br>第二，树立与公司一致的价值观；<br>第三，改善自己的心智模式。</p>
<p>成长最终还是要靠自己，平台仅仅提供推动作用，第一责任人和最受益人都是我们自己。</p>
<h3><span id="精英小团队让组织更健康">精英小团队让组织更健康</span></h3><p>什么是精英小团队？<br>举个例子，我们公司的精英小团队由两到三人组成，最多不超过五人，五人以上就要拆分为两个团队。精英小团队是由精英成员组成的，它的成员要具备以下三个条件。<br>第一是思想精英化，这里所说的思想包括价值观、做事方法和思维方式。<br>第二是专业能力精英化，这里所说的专业能力包括现有能力和学习能力。<br>第三是业绩结果（赋能）精英化，结果导向是对职场人士最基本的要求，结果是一切工作的起点和终点。精英小团队的成员，需要有强烈的结果导向，出色的结果是他们的荣誉。<br>由精英构成的精英小团队，工作效率更高、赋能效果更好、给公司创造的价值也更大。团队成员成长更迅速，他们的收入也会更高。</p>
<h3><span id="精英小团队由什么类型的员工组成呢">精英小团队由什么类型的员工组成呢？</span></h3><p>采用人为分类法，我们可按茎的形态将常见的植物分为四大类：草本植物、藤类植物、灌木和乔木。<br>草本植物，体形一般都很矮小、寿命较短、茎干软弱。<br>藤类植物，一般茎长而不能直立，能倚附他物向上攀升。<br>灌木，是木本植物的一种，没有明显的主干、呈丛生状态、比较矮小，多年生。<br>乔木，也是木本植物的一种，树身高大，由根部生出独立的主干，树干和树冠有明显区分，且主干直立，通常高达六米至数十米，多年生。<br>参照以上的人为分类法，我们将莱绅通灵的员工分为草本型员工、藤类型员工、灌木型员工和乔木型员工。<br>草本型员工，赋能力弱、专业知识差、工作能力一般、缺乏学习力，通常没有自己的愿景和使命。<br>灌木型员工，是行业或者专业里的老兵。他们在某个领域或者行业里工作时间比较久，仿佛什么都知道，但其实并没有掌握相关的核心知识，再加上进取心不够，没办法成为公司栋梁。<br>乔木型员工，有自己的愿景和使命，看问题有格局，做事有担当，也愿意学习，所以他们的成长空间很大，慢慢会成为公司栋梁。<br>能持续给公司带来价值的显然是乔木型员工。要想拥有更多的乔木型员工，一方面需要在公司内部寻找乔木型员工的苗子，重点培养；另一方面要在社会上寻找乔木型员工，把他们请进公司并委以重任。</p>
]]></content>
      <categories>
        <category>认知升级</category>
        <category>职场能力</category>
      </categories>
      <tags>
        <tag>认知升级</tag>
        <tag>职场能力</tag>
      </tags>
  </entry>
  <entry>
    <title>销售思维</title>
    <url>/posts/%E6%80%9D%E8%80%83/%E9%94%80%E5%94%AE%E6%80%9D%E7%BB%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="问题背景">问题背景</span></h2><p>昨日同事问我一个问题：<br>背景比较复杂，简单来说，负责人A（大佬）、B（中佬）、C（农民工）是负责一个业务方向，具体干活的是C， 负责人J（中佬）是负责风险把控横向项目，是个负责人，大约跟同事A、B平级。领导把业务方向的风险把控项目能力交给同事J，但是业务方发现了风险，对线上影响很大，找到了同事A、B，要求解决问题。<br>如果上面关系还是很复杂难懂，可以再简化为： 负责人J有职责对某个技术方向负责，但是宣称没有人力，需要同事C自行实现一些方案解决问题。 同事C问我该怎么办？<br>再抽象一下：同事找到了领导，给我分配了不是自己该负责的方向，自己该怎么拒绝。</p>
<h2><span id="解题思路">解题思路</span></h2><p>面对这种问题，我的第一反应是，不能接，但是也不能推脱。<br>一旦你推脱了，说不想做，那就是态度问题，负责人会觉得你态度有问题，很可能拿“挑活”、“有边界感”、“不配合”、“影响团队合作”等态度问题压你，这些标签一旦给自己扣上，自己很难洗清，要想洗清，就得接手这样的项目来尝试洗清了， 反而在领导心里留下了更不好的印象，自己出力不讨好。<br>一旦你接了，就免费充当了别人的人力，费力不讨好的同时，也模糊了自己的边界感，恐怕以后更会变本加厉，而且如果是好活他们一定不会分出来，既然让你干了，一旦出问题，锅跑不了了。</p>
<p>我当时的解决方案是：<br>先要想明白一个问题， 领导交给你不想做的任务，你有哪些方法可以拒绝，大概想到这几个方法。</p>
<ol>
<li>直接刚，我觉得这个任务不属于我的工作范畴，我不接。</li>
<li>我觉得这个任务有问题，我觉得是个坑，不能接。</li>
<li>没做过类似的项目，怕自己做不好。</li>
<li>这个项目的特质是什么，为什么不适合我。如果我做的话，我担心有*问题。</li>
</ol>
<p>这几个方法分别有什么问题呢？</p>
<ol>
<li>领导安排的任务不干？态度有问题，跟领导对着干，容易被扣帽子。 </li>
<li>你挑活？ 容易被扣帽子。</li>
<li>那你更应该学习学习了，你不想学习？</li>
</ol>
<h2><span id="方案分析">方案分析</span></h2><p>其实对方法进行归类，有以下几类</p>
<ol>
<li>态度原因：<ol>
<li>不是我负责的，我不干；</li>
<li>有坑，我挑活，不干；</li>
</ol>
</li>
<li>性格\专业原因：<ol>
<li>不是我不干，也不是我不想干好，而是我不适合做这个，怕出问题，还不如让适合的人做；</li>
</ol>
</li>
<li>能力原因：<ol>
<li>不是我不干，是我干不好；</li>
</ol>
</li>
</ol>
<ul>
<li>可以看出，态度原因的回答其实是最差的，老板以后肯定不喜欢你了，因此对老板来说，态度永远是第一位的，永远不要表达出有消极的态度。</li>
<li>其次就是能力原因，跟领导说自己能力不行，那以后领导怎么器重你。</li>
<li>最好的方法就是说一个，非硬伤，但是能拒绝的理由。 每个人的性格、专业不同，肯定不能把所有事情都做得完美。 性格\专业出身等原因又不是你的消极态度、能力不足导致的，不会影响你在领导心中的形象；而且一旦后面领导仍然选择让你干，也是领导的决定，出问题了他也有很大责任，用人失误。</li>
</ul>
<h2><span id="方案后遗症">方案后遗症</span></h2><p>本答案其实已经完结了，但同事C确实也按照这个思路跟负责人A和负责人J沟通了。 但是沟通的过程中，没有很好地控制住情绪，负责人们应该看得出抵触的情绪，这个问题我之前也普遍存在，因此昨天思考了很久，想起刘润老师之前的一门课，于是想到一个思维，能解决这个问题。</p>
<h3><span id="不要做情绪的奴隶">不要做情绪的奴隶</span></h3><p>每个人都有情绪，很少有非常非常理智的人， 雍正脾气就很大，但就算当上皇帝以后，仍然需要控制脾气，皇帝的权力很大了吧？为什么还要收着呢？</p>
<h3><span id="销售思维">销售思维</span></h3><p>小时候不是很懂，见过很多笑嘻嘻上门推销的销售、商城门口跟着你喋喋不休的销售、酒桌上把酒换盏的销售。<br>看到他们非常地热情，会有些不适感。 但其实他们也不想这么热情，这么“讨人厌”，就是因为他们的目标很明确，卖出产品、达成交易，从而完成他们的核心目的！<br>无论遇到多讨厌的客户，只要他掏钱，就是金主爸爸，递根烟、陪喝酒都是小事，可以主动出击；</p>
<p>联想到职场上，也是一样的， 我负责一个项目，需要别人协作，那这个团队合作的过程，就是交易的过程， 我的目标就是让他帮我完成okr。如果能达成我的核心问题，能让我的利益最大化，我就需要一些手段维护好人际关系。遇到讨厌的同事、领导，也需要驾驭情绪，完成自己的目标。 而不是被别人激怒，牵着鼻子走。 “他怎么能这样呢？” 这就是一句没用的话，为何古人说“百无一用是书生”？ 就是因为书生很想当然，没有从实际利益出发，从利益角度考虑问题；</p>
<p>这里再提到一本书中讲的观点，《幽微的人性》中有一章讲到<strong>生存式教育</strong>，现代学生在学校学的是<strong>精英式教育</strong>，不是<strong>生存式教育</strong>，什么意思呢？ 每个人需要知道自己的核心目标是什么，是更好地生存，是更好地生存，不仅仅是生存。 所以有时候要放弃“想当然”、“书生气”。什么方案能让我利益最大化，那我就选择什么方案、什么情绪。 让我的情绪、能力成为我的工具，而不是被情绪牵着走。（前提是不能做违法、违反道德的事情）。 我们心中仍有理想、良心，但不能想当然，而是驾驭工具，完成理想，无愧良心（此处向王阳明、徐阶等隐忍的儒士致敬）。</p>
<p>本故事乃现实场景，可能描述不周。仅做记录，如有不同见解，欢迎评论。如有吐槽，请看官手下留情。<br>本人也在逐渐刺破认知气泡升级认知的过程，知尚在山底，行当然也更没跟上。但很庆幸，什么时间认识到问题都不算晚，学无止境。</p>
]]></content>
      <categories>
        <category>认知升级</category>
        <category>职场能力</category>
      </categories>
      <tags>
        <tag>认知升级</tag>
        <tag>职场能力</tag>
      </tags>
  </entry>
  <entry>
    <title>重新思考-知所未知的力量</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E9%87%8D%E6%96%B0%E6%80%9D%E8%80%83-%E7%9F%A5%E6%89%80%E6%9C%AA%E7%9F%A5%E7%9A%84%E5%8A%9B%E9%87%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="个人层面">个人层面</span></h1><h2><span id="1-像科学家一样思考">1. 像科学家一样思考</span></h2><ol>
<li>个人理解：<br>个人更愿意理解为，像“偶像”一样思考，当然这个偶像不是娱乐圈的爱豆，而是成功人士，如“科比”、“乔布斯”、“王阳明”、“孔子”、“曾国藩”等等，之所以这么做，是因为“偶像”本身就是模版，让你遇到问题、选择时，想象出如果是偶像，他会怎么做，自然而然，自己也会成功。<br>不同的偶像有不同的思维方式，此处就无法具体展开介绍。 大致方向是： 深入思考，看清本质，考虑深远；</li>
<li>他人理解：<br>当形成一个观点时，要抵制住诱惑，需要把观点当成一种实验，借鉴他们的做法，保持观点转换的灵活性；</li>
<li>二次理解：<br>刚看到这个“准则”时，以为说的是“偶像”的作用，不要局限于自己的思维，更多的是参考别人的思维。 准则理解有偏差。</li>
</ol>
<h2><span id="2-用价值观而不是观点定义你的身份">2. 用价值观而不是观点定义你的身份</span></h2><ol>
<li><p>个人理解：<br>用观点定义你的身份，更容易让别人对你贴上标签。</p>
</li>
<li><p>他人理解：<br>用观点定义身份，更容易让自己变得“顽固”，会更想让自己做出错误的改变，从而支持自己的观点。</p>
</li>
<li><p>二次理解：<br>用价值观定义身份，本质上是将自己抽立出去了，避免因主观原因导致判断错误；<br>思考问题时，想的不是我应该做什么、怎么做。 而是如果要达成什么目标时，我需要做什么、怎么做。</p>
</li>
</ol>
<h2><span id="3-寻找与你观点相反的信息">3. 寻找与你观点相反的信息</span></h2><ol>
<li><p>个人理解<br>避免思维局限，让自己越来越钻牛角尖，需要跳出来，从正反两个方向考虑观点的正确与否，实行方案可行性。有点像 “测试” 思维</p>
</li>
<li><p>他人理解：<br>要积极了解不同的观点，以此对抗偏差，打破“过滤泡”，逃避“回音室”（这两个词是谁想出来的，真是厉害）。即使不同意他人的观点，也可以先跟随别人的思想考虑问题，为自己提供不同的思路；</p>
</li>
</ol>
<h2><span id="4-不要被困在愚昧之巅">4. 不要被困在愚昧之巅</span></h2><ol>
<li><p>个人理解：<br>不要太自以为是，一定要谦虚，记住人外有人，天外有天；</p>
</li>
<li><p>他人理解：<br>不要把自信和能力混为一谈。达克效应*是一个很好的提醒，你越是认为自己做得好，就越有可能高估自己、停滞不前。为了防止对自身知识过于自信，请反思一下你对某个既定主题的阐释能力。</p>
</li>
</ol>
<h2><span id="5-利用怀疑的好处">5. 利用怀疑的好处</span></h2><ol>
<li>他人理解：<br>当发现自己具备怀疑能力时，可以把它定义为一个成长的机会； <strong>提高专业知识的第一步是，知其未所知</strong>；</li>
</ol>
<h2><span id="6-拥抱犯错的喜悦">6. 拥抱犯错的喜悦</span></h2><ol>
<li><p>个人理解：<br>从小我们就学过，失败乃成功之母，不要畏惧失败，也不要逃避错误，不必为错误感到丢脸，反而从失败中汲取教训，才能避免下一次失败；</p>
</li>
<li><p>他人理解：<br>不要害怕自嘲，将关注点从“自我证明”转向为“自我提高”</p>
</li>
</ol>
<h2><span id="7-从遇到的每个人身上学习新东西">7. 从遇到的每个人身上学习新东西</span></h2><ol>
<li><p>个人理解：<br>三人行必有我师，取其精华去其糟粕；</p>
</li>
<li><p>他人理解：<br>每个人可能都比我更了解一些专业知识，可以多问问最近在重新思考什么问题，或者跟他们讨论过去一年你改变的情况；</p>
</li>
</ol>
<h2><span id="8-除了支持网络还要构成挑战网络">8. 除了支持网络，还要构成挑战网络</span></h2><ol>
<li><p>个人理解：<br>一味地要求别人支持你、顺从你、夸赞你，并不能一定使你成长，反而可能导致骄傲、自满，就算没有到如此地步，也可能无法反思自己，再上一层楼。</p>
</li>
<li><p>有啦啦队队长式的鼓励固然很好，但你也需要来自批评者的挑战</p>
</li>
</ol>
<h2><span id="9-不要回避建设性冲突">9. 不要回避建设性冲突</span></h2><ol>
<li><p>个人理解：<br>冲突可能会使两个人关系破裂，但不要一味地回避冲突，尤其是“建设性”冲突，能让你重新思考问题，发现问题的另一面， 很有可能有了新的启发；</p>
</li>
<li><p>他人理解：<br>试着把观点分歧看成一场辩论，这样人们会倾向于<strong>理智地对待分歧，对事不对人。</strong></p>
</li>
</ol>
<h1><span id="人际层面">人际层面</span></h1><h2><span id="1-练习说服性倾听的艺术">1. 练习说服性倾听的艺术</span></h2><ol>
<li>他人理解：<br>当我们试图打开别人的心扉时，倾听通常比交谈效果更好。在谈话中，如何让对方明确自身观点，并激发他们的兴趣，探索自我改变的原因？一个好的开始方式是增加提问，减少陈述。</li>
</ol>
<h2><span id="2-问对方怎么做而不是原因">2. 问对方怎么做而不是原因</span></h2><ol>
<li><p>个人理解：<br>问其原因，可能会说其主观原因，或者不自觉中描述的方向有偏差。</p>
</li>
<li><p>他人理解：<br>当描述自己为什么会持有极端的观点时，人们往往会强化对观念的承诺并加倍固化其观点。<strong>而当试图解释如何将想法变成现实时，人们往往会意识到自身理解的局限性，并开始调整一些想法。</strong></p>
</li>
</ol>
<h2><span id="3-询问什么证据会改变你的想法">3. 询问“什么证据会改变你的想法”</span></h2><ol>
<li>他人理解：<br>我们不能强迫别人同意我们的意见，通常，询问他们什么能令他们敞开心扉，然后看看能否以他们的方式说服他们，这样会更有效。</li>
</ol>
<h2><span id="4-询问人们的观点最初是怎么形成的">4. 询问人们的观点最初是怎么形成的</span></h2><ol>
<li>个人理解<br>不要听别人怎么判断一件事，而是问他事情的来龙去脉，自己去分析结论。 别人给的观点和结论，都是主观判断的，绝大多数情况都会有偏差；<br>另外，不同环境、身份影响着你对事情的主观判断，有着不同的信息差，对事情的发展和走向，也有不同的预测。 常见的情况就是看古装剧时，不懂当时的情景，也就无法正确理解古人的所作所为；不知道一个人对自己口吃很在意，在其面前说vvvip，他肯定会很生气；</li>
<li>他人理解：<br>如同我们的刻板印象，我们的许多观点都是武断的；我们在没有严谨数据或深入思考的情况下形成了观点。为了帮助他人重新评估自己的想法，我们要问问他们如果出生在不同的时代或地点，他们的观念会有怎样的变化。</li>
</ol>
<h2><span id="5-承认共同点辩论就像舞蹈不是战斗">5. 承认共同点，辩论就像舞蹈，不是战斗</span></h2><ol>
<li>他人理解：<br>承认共性并不会使你变弱，这表明你愿意讨论什么是真相，并促使对方考虑你的观点。</li>
</ol>
<h2><span id="6-记住少就是多">6. 记住，少就是多</span></h2><ol>
<li><p>个人理解：<br>有时候，表面自己的观点，往往说的越少，越精炼，越能表达清楚，说得多了，反而会影响一人的理解；<br>同理，自古以来，醒世格言都是抽象的大道理，不会举例，这些抽象、精简的大道理才会深入刻进思维里，做事的时候才会在潜意识时影响自己；</p>
</li>
<li><p>他人理解：<br>你如果列举了太多不同的论据来支持你的观点，就可能让听众产生防御心理，并可能导致他们用最不起眼的观点反对你的整个论点。与其让太多论据淡化论点，不如先从你的几个最强论点开始阐述。</p>
</li>
</ol>
<h2><span id="7-强化选择理由">7. 强化选择理由</span></h2><ol>
<li>他人理解：<br>有时候，人们拒绝辩论，并不是因为不屑，而是因为他们拒绝接受行为被控制的感觉。因此，你需要提醒人们，他们可以自由选择相信某种观点，从而尊重他人的自主性。</li>
</ol>
<h2><span id="8-就对话的感受进行沟通">8. 就对话的感受进行沟通</span></h2><ol>
<li>他人理解：<br>如果对话过于情绪化，那就尝试着将讨论调回正轨。谈判专家会评价自己的感受，并检验自己对对方感受的理解是否准确。你可以借鉴这种做法，有时可以表达自己的失望或沮丧，并询问对方是否愿意分享自己的感受。</li>
</ol>
<h1><span id="群体层面">群体层面</span></h1><h2><span id="1-使有争议的话题复杂化">1. 使有争议的话题复杂化</span></h2><ol>
<li><p>他人理解：<br>每个故事都不止两面。不要像对待硬币那样对待两极化议题，要用棱镜的多个镜面进行审视。看到问题的灰度能使我们更加开放。</p>
</li>
<li><p>个人理解：<br>个人觉得这个观点表达的有点不正确，貌似要把问题复杂化，让所有人听不懂。 但看了解释，发现不是这个意思，本意是：<strong>多角度思考</strong>；</p>
</li>
</ol>
<h2><span id="2-不要回避警告和意外事件">2. 不要回避警告和意外事件</span></h2><ol>
<li>他人理解：<br>承认有竞争性的观点和冲突性的结果，并不会让利益或信誉受损。这反而是吸引观众的有效方法，还能促使他们保持好奇心。</li>
</ol>
<h2><span id="3-扩大你的情感范围">3. 扩大你的情感范围</span></h2><ol>
<li>他人理解：<br>想要进行富有成效的谈话，不必消除沮丧甚至愤怒的情绪，只需要将更多情绪混合在一起，你可以试着表现出一些好奇，甚至承认困惑或矛盾的心情。</li>
</ol>
<h2><span id="4-每周打破一次迷思的讨论可以在晚餐进行">4. 每周打破一次迷思的讨论，可以在晚餐进行</span></h2><ol>
<li>他人理解：<br>在孩子们很小的时候，揭穿错误的观念会容易得多。这也是教孩子们养成重新思考习惯的好方法。每周选择一个不同的话题（这周可能是恐龙，下周可能是外太空），由家庭成员轮流负责，带领全家讨论这个迷思话题。</li>
</ol>
<h2><span id="5-让孩子们做多版草稿多寻求他人的反馈">5. 让孩子们做多版草稿，多寻求他人的反馈</span></h2><ol>
<li>他人理解：<br>创作不同版本的图画或故事，可以鼓励孩子们学习并理解修改想法的价值。从其他人那里获得反馈信息，也可以帮助孩子们持续完善自己的标准。他们可能学会了接受困惑，并在第一次尝试时不去期待一下子达到完美。</li>
</ol>
<h2><span id="6-不要问孩子们长大了做什么">6. 不要问孩子们长大了做什么</span></h2><ol>
<li>他人理解：<br>孩子们不必用职业来定义自己。单一的身份会关闭替代选择的大门。与其试图缩小孩子们的选择范围，不如帮助他们扩大可能性。这些可能性不必是单一目标，孩子们可以做到很多事情。</li>
<li>个人理解：<br>该观点本意是想，不让孩子太局限于一个事物，一个方向。 但观点描述的，我有点不认同。 还是要给孩子设定一定的目标，只是不要太局限于小目标。  可以设定一个范围目标。 小孩子肯定需要多方位培养，才能挖掘出孩子最擅长、最适合的方向，而且还能多个退路；</li>
</ol>
<h2><span id="7-放弃最佳实践">7. 放弃最佳实践</span></h2><ol>
<li>他人理解：<br>一旦有了最佳实践，那就表明理想的路径已经设定好了。如果想让人们不断重新思考工作方式，那么最好采用过程问责制，促使人们不断追求更好的实践。</li>
</ol>
<h2><span id="8-建立心理安全">8. 建立心理安全</span></h2><ol>
<li>他人理解：<br>在学习型文化*的组织中，人们相信自己可以去质疑和挑战现状，而不会因此受到惩罚。构建这样的心理安全，往往需要领导者做出示范，虚怀若谷。</li>
</ol>
<h2><span id="9-用重新思考积分卡持续记录">9. 用重新思考积分卡持续记录</span></h2><ol>
<li>他人理解：<br>不要只根据结果评估决策的好坏，还要跟踪过程中对不同可选方案的思考深度。浅层的过程带来正面的结果，这只是运气。而一个深层的过程和一个负面的结果，却可能是一个聪明的实验。</li>
</ol>
<h2><span id="10-扔掉十年计划">10. 扔掉十年计划</span></h2><ol>
<li>他人理解：<br>去年你感兴趣的事今年可能会让你厌烦，而昨天让你困惑的事明天可能会变得激动人心。激情不是被发现的，而是被不断培养的。只需要提前一步计划，你就能重新思考。</li>
<li>个人理解：<br>此处仍然不是很认同，一定要有规划，只是说规划一定不能是太狭隘的，一定是一个大方向，可以随时调整的。 但不能说不做规划。</li>
</ol>
<h2><span id="11-重新思考行动改变不是环境转换">11. 重新思考行动改变，不是环境转换</span></h2><ol>
<li>他人理解：<br>追逐幸福可能会把幸福赶跑。换一个新环境并不足以得到幸福。快乐盛衰不定，意义却会历久弥新。采取行动建立使命感，通常可以从提高自身学习能力或者增加对他人的贡献开始。</li>
</ol>
<h2><span id="12-安排一次人生体验">12. 安排一次人生体验</span></h2><ol>
<li>他人理解：<br>人们很容易陷入不断承诺升级却得不到满足的境地。就像安排健康检查一样，每年做一次或两次人生体检是值得的。通过这种方法，你可以评估自己学习了多少新知识，你的观念和目标是如何演变的，下一步计划是否需要重新思考。</li>
</ol>
<h2><span id="13-抽出时间重新思考">13. 抽出时间重新思考</span></h2><ol>
<li>他人理解：<br>当查看自己的日程表时，我发现大部分安排都是要做的事情。我设定了一个目标，每天花一小时思考和学习。现在我决定更进一步：我每周安排一次重新思考和“空杯”的时间。在这个时间里，我要去见挑战网络里的朋友们，了解在他们看来，我应该重新思考哪些想法和意见。最近，我的妻子阿莉森告诉我，我需要重新思考一下“蛋黄酱”这个词的发音。</li>
</ol>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5NjA3OTM0MA==&amp;mid=2655737855&amp;idx=1&amp;sn=2cacba133a0a80b37596df983b8ee53b&amp;chksm=bd51447c8a26cd6a5efb8fb60d91a641087f23fa4a9302e72241ecef4888b91616ab80c5de5f&amp;mpshare=1&amp;srcid=1108ckWXh6YZgcCBLffEHdri&amp;sharer_sharetime=1667861435784&amp;sharer_shareid=318e4741475752490a682acec35633be&amp;scene=21#wechat_redirect">他人理解来自</a></p>
]]></content>
      <categories>
        <category>读书笔记</category>
        <category>认知升级</category>
      </categories>
      <tags>
        <tag>认知升级</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>动机与人格</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%8A%A8%E6%9C%BA%E4%B8%8E%E4%BA%BA%E6%A0%BC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="马斯洛关于人性研究的核心观点">马斯洛关于人性研究的核心观点</span></h1><ol>
<li>人类有趋向于<strong>健康、创造性和自我满足</strong>等更高层次的内在趋势。</li>
<li>神经症可以被认为是对自我实现趋向的一种阻断。</li>
<li>一个有协同作用的社会的演进是一个自然和基本的过程。它是这样一种社会:在其中，所有的个体都可以达到自我发展的高级层次，但又不会妨碍他人的自由。</li>
<li>商业效率和个人成长并不是不相容的。自我实现的过程使每一个个体都趋向于最高的效率水平。</li>
</ol>
<h1><span id="关于动机的17个命题">关于动机的17个命题</span></h1><ol>
<li>作为一个整体的个人<br>个人是一个一体化的、有组织的整体。当我们饿的时候，不是肚子需要食物，而是作为整体的人需要。食物平息的也不是肚子的饥饿感，而是我们个体的饥饿感。</li>
<li>作为动机状态典型的饥饿<br>饥饿驱力是特殊的而不是一般的动机实例。在透彻研究饥饿冲动与全面了解爱的需要相比，我们能够通过后者更多地了解普遍的人类动机。饥饿驱力即食物需要，它比其它动机更孤立、更常见，同时还有一个躯体基础（如肚子产生饥饿的反应. 。因此其不适合作为研究动机的实例。</li>
<li>手段和目的<br>生活中的普通欲望，通常是达到目的的手段而非目的本身。我们需要钱（手段. ，并不是因为钱具有价值，而是因为它能够实现我们的很多心愿（目的. ——如给亲人和自己买礼物、去喜欢的地方旅游等。<br>瓜瓜问：游戏是目的还是手段？（PS.书中第六章有提. </li>
<li>无意识动机<br>一个有意识的欲望与它下面潜藏的最终的无意识目标之间的关系完全不必是直接的。瓜瓜疑惑：无意识目标是啥？是说达成目标已经成为习惯？不需要刻意坚持吗？查了很多网络资料，还是没很懂，请大佬们指教哇。</li>
<li>欲望与文化<br>两种不同的文化可能提供两种不同的方法来满足某一特定的欲望。在原始社会，要满足自尊需要，可能需要通过武力斗争；而在现代，通过脑力劳动来满足自尊需要是很常见的。</li>
<li>复杂多样的动机<br>一般来说，一个行动或有意识的愿望具有多种不同的动机。第3点的手段和目的也很好地论证了这一点，我们赚钱并不仅仅是因为喜欢钱，更重要的是因为钱背后所代表的东西。</li>
<li>促动状态<br>动机是连续不断的、无休止的、起伏的和复杂的。</li>
<li>满足产生新的动机<br>一个欲望满足后，另一个迅速出现并取代它的位置,当这个被满足了，又会有一个站到突出的位置上来。产生新动机的原因之一：当我们对某个事物具有强烈欲望时，我们就会努力；努力与坚持过后，我们将会得到，但往往在即将得到之前，我们对它的欲望却远远没有之前那么强烈，因为努力的过程改变了我们，努力让我们变得更好，而此时更好的自己已经无法和之前的欲望相匹配。换言之，当我们欲望得到满足时，我们对它的在意程度大大降低，因为欲望的满足过程改变了我们的看待事物的方式和角度、充实了我们自己，这也让我们更加有信心，还可能由此产生更高层次的欲望。</li>
<li>不可能列出内驱力一览表<br>内驱力之间不仅没有相互的排斥，它们的相互重叠甚至使我们几乎不可能完全清楚和严格地把一种内驱力同其他内驱力分开。</li>
<li>按照基本目标为动机分类<br>内省地出现在意识中的内驱力、动机行为，甚至被明确追求的目的物，它们没有一个可作为人类动机生活的动力分类的坚实基础。<br>一个正在经历性欲、求爱、完成性行为全部过程的人，也许实际上是在寻求尊重，而不是性的满足。</li>
<li>动物资料不足以说明问题<br>动机理论必须以人为中心，而不是以动物为中心。</li>
<li>环境<br>动机理论不仅包括机体本身，而且应包括环境，包括文化的决定作用。</li>
<li>整合作用<br>正如我们有时同时做好几件事情，机体甚至也可能以非一元化的方式做出反应。<br>当生活轻松顺利时，机体可以同时做许多事情，向许多方向发展。</li>
<li>无动机的行为<br>并非所有行为或者反应都是有动机的。成熟、表现、成长以及自我实现等现象都违背了普遍的动机理论的法则，这些现象是表达性的而不是应对性的。有时，我们的行为并非是为了达到特定的目标，而只是一种漫无目的的情感表达。如本书第2章提到的：“一个健康孩子做出的漫不经心的动作，愉快的人独自一人时脸上露出的笑容…这些都是属于表达性的、非机能性的行为。一个人言行举止的风格，也几乎总是表达性的。”</li>
<li>达到目的的可能性<br>我们有意识地渴望一切实际可能获得的东西。正如现在的瓜瓜不会想去拥有一架私人飞机，但会想努力赚钱买一套房。</li>
<li>现实和无意识<br>弗洛伊德认为，一个本我冲动(id impulse)是一种分离的存在，与世界上任何其他事物都没有内在的联系。<br>杜威认为，成年人的所有冲动，是与现实结合，并且受现实影响的。</li>
<li>健康人的动机<br>任何值得关注的动机理论，除讨论有缺陷者的防御手段外，还必须讨论健康、强健的人的最高能力。在严谨的理论中，不能仅由特殊来推一般。科学研究所选的个体应该全面且具有代表性。</li>
</ol>
<h1><span id="基本需要的层次">基本需要的层次</span></h1><ol>
<li>生理需要</li>
<li>安全需要</li>
<li>归属与爱的需要</li>
<li>自尊需要</li>
<li>自我实现的需要</li>
</ol>
<p><img data-src="./需要层次.jpg" alt="需要层次"></p>
<h1><span id="类本能理论中的基本需要">类本能理论中的基本需要</span></h1><p>从某种意义上说，基本需要在某种可以察觉到的程度上是由体质或遗传决定的。理由如下：</p>
<ol>
<li>独特的人类本能<br>有些本能性的冲动只能在人类身上被发现。</li>
<li>挫折是致病的<br>基本需要必须得到满足，否则我们就要得病。</li>
<li>得到满足是一种健康<br>基本需要的满足会产生有益的、良好的、健康的、自我实现的效应。</li>
<li>必要性<br>基本需要满足物的必需性使它们自身与其他需要的满足物区别开。</li>
<li>心理治疗<br>所有主要的心理治疗方式都培育、促进、巩固了我们称为基本的、类本能的需要，同时削弱或彻底消除所谓神经症的需要。</li>
<li>鼓励本能<br>教育、法律、宗教等至少应起保护、促进、鼓励安全、爱、自尊、自我实现等类本能需要的表达和满足。</li>
<li>两分矛盾的解决<br>基本需要的类本能性质有助于解决生物性与文化、天生与习得、主观与客观、独特性与普遍性之间的矛盾。</li>
</ol>
<h1><span id="应对性行为和表达性行为的区别">应对性行为和表达性行为的区别</span></h1><ol>
<li>应对是有目的、有动机的，而表达没有；</li>
<li>应对需要作出努力，而表达不需要；</li>
<li>应对更多地是由外界环境决定，而表达主要取决于机体本身的状态；</li>
<li>应对通常是后天学习的结果，而表达不是；</li>
<li>应对更容易被控制，而表达往往是不受控制甚至不可控制的；</li>
<li>应对通常是想改变环境，而表达对环境的改变是无意的；</li>
<li>应对是手段，而表达是目的；</li>
<li>行为中的应对成分是有意识的，而表达更可能是无意识的。</li>
</ol>
<h1><span id="表达性行为">表达性行为</span></h1><ol>
<li>存在<br>当人们是自在的自己时，往往会出现表达性行为。</li>
<li>艺术<br>当艺术是在寻求交流、力图激起感情、表现和影响他人时，艺术创造就是相对有动机的，艺术还可以是相对无动机的，这时，它是表达性的而不是交流性的，是个人内部的而不是人与人之间的。</li>
<li>欣赏<br>神秘、敬畏、愉快、惊异、赞赏等体验也都属于这一类被动的丰富的主观审美体验，这些体验涌向机体，像音乐的效果一样，使机体沉浸其中。</li>
<li>游戏<br>游戏可以是应对性的，也可以是表达性的，或两者兼有之。</li>
<li>智力表现<br>思维，如同感知一样，可以是自发的和被动地接受或生产，它们是机体的本性和存在的无动机、不费力、快乐的表现，是让事情自然发生而不是人为地致使它们发生</li>
</ol>
<h1><span id="对自我实现者的总体印象">对自我实现者的总体印象</span></h1><ol>
<li>对现实的感知：更倾向于领悟真实的存在，而不是拘泥于他们自己或他们所属文化群的愿望、希望、恐惧、焦虑以及理论或信仰中。</li>
<li>接受性：能够以一个人在接受大自然的特性时所持的那种毫不怀疑的态度，来接受脆弱、过失、弱点，以及人性的罪恶方面。</li>
<li>自发性：有相对自主的、独特的、不遵从惯例的道德准则。</li>
<li>以问题为中心：他们不以自我为中心。也因此，他们有能力把注意力集中到常人不易达到的程度。</li>
<li>超然独处：可以超然于物外，泰然自若地保持平静，而不受那些在其他人那里会引起骚动的事情影响。</li>
<li>自主性：自我实现者的发展和持续成长依赖于自己的潜力以及潜在的资源。</li>
<li>清新的鉴赏力：具有奇妙的反复欣赏的能力，他们带着敬畏、兴奋、好奇甚至狂喜、清新而又天真无邪地体验生命的基本内涵。</li>
<li>高峰体验：以问题为中心、高度集中，献身行为，强烈的感官体验，对音乐或艺术的忘我、投入的欣赏，等等。</li>
<li>人类亲情：对人类怀有一种很深的认同、同情和爱的感情。</li>
<li>谦逊与尊重：对每个人都会给予一定程度的尊重。</li>
<li>人际关系：比其他成年人具有更深刻和深厚的人际关系。</li>
<li>道德：自我实现者的道德力量很强，有明确的道德标准。</li>
<li>手段与目的：他们更关注目的，手段相当明确地从属于目的。</li>
<li>幽默感：他们的幽默感常常与哲理紧密相关联。</li>
<li>创造性：相对于那些更狭隘的人，他们更具有创造力。</li>
<li>对文化适应性的抵抗：他们全都在某种深刻的、意味深长的意义上抵制文化适应。</li>
<li>不完美性：他们也有罪恶感、焦虑、沮丧、自责、内心的矛盾和冲突。</li>
<li>价值：他们以哲人的态度接受自我、接受人性、接受大部分社会生活、接受自然和客观现实，这为他们的价值系统提供了坚实基础。<blockquote>
<p>瓜瓜总结：自我实现者拥有比常人更敏锐的洞察力、鉴赏力、创造力，他们对坏事物、未知事物社会生活、客观现实等有着更开放的态度。在社会层面，他们会尊重每位社会成员，对人类具有很深的感情，有着深厚的人际关系；但他们并非总是规则的接受者，他们有着非同寻常的道德标准。除此之外，他们还有哲理性幽默、以问题为中心、关注目的等特点。</p>
</blockquote>
</li>
</ol>
<h1><span id="自我实现者的创造性">自我实现者的创造性</span></h1><ol>
<li>感知：他们可以看到新鲜的、天然的、具体的和形象化的事物，也可以看到属类的、抽象的、仪式性的、分门别类了的事物。</li>
<li>表达：他们更具自发性，更富有表达能力。</li>
<li>儿童的纯真：他们的创造性在许多方面类似于天然快乐、无忧忧虑的儿童的创造性。</li>
<li>对未知事物的好奇：他们更不惧怕未知、神秘、令人迷惑的事物，反而经常沉浸其中。<br>总之，自我实现者的创造性首先强调的是人格，而不是成就，因为这些成就是人格的附产物，是从属于人格的。</li>
</ol>
<p>转载自 <a href="https://www.zhihu.com/question/265432037/answer/1106563332">马斯洛的《动机与人格》，没太看明白，哪位心理学大神讲解下？谢谢？ - 王瓜瓜的回答 - 知乎</a></p>
]]></content>
  </entry>
  <entry>
    <title>五级领导力</title>
    <url>/posts/%E7%AE%A1%E7%90%86/%E4%BA%94%E7%BA%A7%E9%A2%86%E5%AF%BC%E5%8A%9B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://zhuanlan.zhihu.com/p/385223061">参考1</a></p>
]]></content>
  </entry>
  <entry>
    <title>什么是战略</title>
    <url>/posts/%E7%AE%A1%E7%90%86/%E4%BB%80%E4%B9%88%E6%98%AF%E6%88%98%E7%95%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>战略分为十大学派：</p>
<ol>
<li>人们看见了<strong>设计派的蜘蛛</strong>，蜘蛛正专心编织自己的网，等待飞虫落进来；</li>
<li>继续往前走，看见了<strong>计划学派的松鼠</strong>，松鼠在树之间跑来跑去，收集资源为未来的日子做打算；</li>
<li>然后人们看见了<strong>定位学派的水牛</strong>，水牛稳稳地躺在水里，它在森林这么多选择中，选择了自己最舒服的位置；</li>
<li>还没有看到大象，树丛中藏着<strong>企业家学派的狼群</strong>，狼群死死盯着目标，绝不放弃；</li>
<li>抬头看到了<strong>认知学派的猫头鹰</strong>，猫头鹰把一切都看在眼里，说你们这些无知的动物，受认知和眼界所限，你们看到的都是幻想；</li>
<li>还没有找到大象，继续往前走，发现一群<strong>学习派的猴子</strong>，猴子们嬉戏玩闹，学习对方的动作，一步一步成长；</li>
<li>继续往前走，看到了<strong>权力学派的狮子</strong>，狮子们在商讨，待会抓到的猎物，应该怎么分呢？</li>
<li>而在狮子不远处，是<strong>文化学派的孔雀</strong>，孔雀与世无争，从来未转移焦点，始终关心自己是不是漂亮；</li>
<li>再往前走，人们发现了<strong>环境学派的鸵鸟</strong>，鸵鸟的心态，是相信世界会选择最合适的动物活下来；</li>
<li>最后，人们看见了<strong>结果学派的变色龙</strong>，变色龙善于变化，能表现出不同的形态；</li>
</ol>
<p>人们穿越了森林，见到了各种各样的动物。却没有找到我，没有找到那头 战略的大象?<br>大象在哪里?<br>森林里面，没有大象。整片森林，就是战略的大象。 每一种动物，每一个学派，都是一种战略的方向。</p>
<blockquote>
<p>摘自刘润的《一文讲透”十大战略“模型》</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>职场思考</title>
    <url>/posts/%E6%80%9D%E8%80%83/%E8%81%8C%E5%9C%BA%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="团队情况">团队情况</span></h2><h2><span id="管理能力">管理能力</span></h2><ol>
<li><p>管理者与自己干活的不同之处？</p>
<blockquote>
<p>为“任务”负责 -&gt; 为“结果”负责</p>
</blockquote>
<ol>
<li>首先自己干活是“个人价值输出”，为“交代给自己的任务”负责，要求的是，将交给自己的任务保质保量完成；</li>
<li>但负责人是“团队能力输出”，为“结果”负责，这个方向现状是什么，有什么问题，该怎么解决问题，该如何拆解问题，怎么让团队保质保量完成； 并且作为负责人，很多时候是没有指导人能事无巨细得指导的，所以需要自己多谋、多定，不能等着别人喂；</li>
</ol>
</li>
</ol>
<ol>
<li><p>遇到哪些认为有挑战性的管理问题？</p>
<ol>
<li><p>资源分配问题</p>
<ol>
<li>多给少</li>
<li>少给多</li>
<li>风险管控（多-&gt;少，少-&gt;多）</li>
</ol>
</li>
<li><p>情绪管理问题</p>
</li>
<li><p><strong>精神/价值同步</strong>（《人类简史》），能干成大事必备的条件！</p>
</li>
</ol>
</li>
</ol>
<pre><code>人类简史是一部**“格局很大”**的书，着重推荐给看到这里的人！！！

这里问大家2个问题：

1. 很多古代人都相信各种“神”， 有管发财的“财神”，有管下雨的“雷神”、“雨神”，有管生死的“阎王”，是不是很可笑？
2. 人类为什么能在众多动物中脱颖而出，站在食物链的顶端？

因为动物们只能将眼前“实体”的事物作为目标，组建20个以内的团体，让这个小团体共同为食物奋斗，从而生存下去；动物的世界里，很少能组建50个以上能战斗的群体；

而人类就是意识到了，能够创建一个虚拟的“天神”，虚拟的“部落”，虚拟的“制度”，约束团队，使大家为同一个目标奋斗；只有人类才能意识到，做坏事是要遭天谴的，才能不做坏事；

自古以来，伟大的领袖们带领的创业团队、公司、国家，无一不是拥有一个“口号”，让大家相信跟着他，跟着这个团队，我们就能实现这个口号；  如“让全国人民富余起来”、“用科技让复杂的世界更简单”。 有了这个口号，团队的成员就会相信，我能做到，这个口号也能是成员们具有自驱力，而不是别人推着走；
</code></pre><ol>
<li><p>如果团队有同学离职，你该怎么处理？</p>
<ol>
<li>先理解他，安抚离职带来的负面情绪；</li>
<li>找出离职关键问题，是个人原因还是公司原因；</li>
<li>如果是成长受到了什么阻碍，个人规划不清晰，可以尝试沟通解决；</li>
</ol>
</li>
<li><p>如何平衡带领同学的资源问题？</p>
<blockquote>
<p>这是一个比较难的问题，也是一个比较涉及范围比较广泛的问题；</p>
<p>同学们的性格、专业能力并不相同，各自有各自的闪光点；所以在不同事情上，侧重的也不太一样。</p>
</blockquote>
<ol>
<li>多资源给少同学时，也就是人手不够时，重点将问题拆解，找出核心要解决的问题，逐一击破；</li>
<li>少资源给多同学时，也就是不知道干什么时，此时需要注意不能让同学们产生没什么产出，迟早会被淘汰的心态，此时多同步部门的“价值观”，给每个人聊个人成长规划，并帮助其制定成长路线，使其有事做！</li>
</ol>
</li>
<li><p>如何为同学制定规划的？</p>
</li>
<li><p>管理者最重要的品质是什么？</p>
</li>
</ol>
<pre><code>1. 最重要的：责任心！
2. 提出问题能力、问题拆解能力、解决问题能力；
3. 核心能力抽象，“能力复制”能力；
</code></pre><ol>
<li><p>是什么样的心理，让你的路线多变，即做过android，又做过后端，又做过算法？</p>
</li>
<li><p>从事过这几个方向，哪个方向更好，有什么不一样的地方？</p>
</li>
<li><p>心理学对团队管理有什么帮助吗？</p>
</li>
</ol>
<h2><span id="其他问题">其他问题</span></h2><ol>
<li>对未来有什么规划？</li>
<li>说说你的优缺点？最大优势是什么？</li>
<li>你是一个怎样性格的人？</li>
<li>平时的爱好？</li>
<li>能给公司带来什么？</li>
<li>为什么离职？为什么不继续这份工作？</li>
<li>为什么选择我们公司？</li>
<li>期望薪资多少？</li>
<li>为什么我们应该选择你？</li>
<li>当你对老板做出的决定有异议时，你会做什么？</li>
<li>你怎么看待转行这个行为？</li>
<li>你觉得你身份转变最大的是哪一年？为什么有这种变化？</li>
<li>请用一个词描述你自己。</li>
<li>请讲述你近期遇到的一件有趣的事情。</li>
<li>你最不能忍受什么？</li>
<li>你如何定义成功？</li>
<li>你认为自己是幸运的吗？</li>
<li>你与上司发生过分歧吗？你是如何处理的？</li>
<li>如果应聘成功，你将如何执行“xxx项目”？</li>
<li>你有哪些失败的经历？你从中学习到了什么？</li>
<li>你认为我们这个行业有哪些改变趋势？我们应该如何应对这些改变呢？</li>
<li>你如何让人记住自己？</li>
<li>当同事在会议上挑战你时，你如何回应？</li>
<li>当你开始一份新工作时，如何适应你的工作环境？</li>
<li>你有什么保持工作与生活平衡的策略?</li>
<li>什么激励了你？</li>
<li>在过去的一年里，你为自己的职业发展做了哪些事情?</li>
<li>如果你发现一位同事正在为他们的工作而苦苦挣扎，你会怎么做？</li>
<li>你最容易被别人误解的地方是什么？</li>
<li>谈谈你的家庭情况？</li>
<li>对这项工作，你有哪些可预见的困难?</li>
<li>你希望与什么样的上级共事?</li>
<li>来的路上还顺利吗？</li>
<li>生活中的你，是如何认识比自己优秀的人？</li>
</ol>
<p><a href="https://business.linkedin.com/zh-cn/talent-solutions/talent-blog/recruitment-faq">参考1</a><br><a href="http://www.dhmhr.com/article/index.php?c=show&amp;id=84">参考2</a><br><a href="http://tmgc.hncu.edu.cn/info/1213/6689.htm">参考3</a></p>
<h2><span id="异常情况">异常情况</span></h2><ol>
<li>迟到了怎么办</li>
<li>遇到自己不会的智力题怎么办？</li>
</ol>
<h2><span id="自我准备">自我准备</span></h2><ol>
<li>如何让自己面试的时候，超长发挥？</li>
<li>如何能在面试中，让别人一下子就记住你？</li>
<li>如何让别人觉得你能胜任？</li>
<li>如何能让别人觉得非你不可？</li>
</ol>
]]></content>
      <categories>
        <category>职场思考</category>
      </categories>
      <tags>
        <tag>职场思考</tag>
      </tags>
  </entry>
  <entry>
    <title>Java书单</title>
    <url>/posts/%E4%B9%A6%E5%8D%95/Java%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="java书单推荐">Java书单推荐</span></h1><h2><span id="入门">入门</span></h2><ol>
<li>Head First Java</li>
<li>Head First 设计模式</li>
<li>java从入门到精通</li>
<li>Java编程思想</li>
<li>Java核心技术 卷1 基础知识</li>
<li>Java开发实战经典</li>
<li>Java程序员修炼之道</li>
<li>Spring源码深度解析</li>
<li>go扩展网站性能的50条原则</li>
<li>阿里巴巴Java开发手册</li>
</ol>
<h2><span id="中级">中级</span></h2><ol>
<li>Effective Java</li>
<li>Java并发变成实战</li>
<li>编写高质量代码：改善Java程序的151个建议</li>
<li>重构 改善既有代码的设计</li>
<li>深入分析Java Web技术内幕</li>
<li>大型网站系统与JAVA中间件实践</li>
</ol>
<h2><span id="高级">高级</span></h2><ol>
<li>深入理解Java虚拟机：JVM高级特性与最佳实践</li>
<li>企业应用架构模式</li>
<li>Java Performance The Definitive Guide</li>
</ol>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>书单</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习书单</title>
    <url>/posts/%E4%B9%A6%E5%8D%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#数据分析">数据分析</a></li>
<li><a href="#机器学习">机器学习</a></li>
<li><a href="#python实践">python实践</a></li>
<li><a href="#深度学习">深度学习</a></li>
<li><a href="#强化学习">强化学习</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="数据分析">数据分析</span></h2><ol>
<li><a href="https://github.com/lyhue1991/eat_pyspark_in_10_days">10天吃掉pyspark</a>   <a href="https://www.heywhale.com/home/column/5fe6aa955e24ed00302304e0">代码运行</a></li>
</ol>
<h2><span id="机器学习">机器学习</span></h2><ol>
<li>《机器学习》 - 周志华</li>
<li>《统计学习方法》 - 李航</li>
<li>《机器学习实战》</li>
<li>《百面机器学习 算法工程师带你去面试》</li>
<li>《机器学习系统设计》</li>
<li>《Spark机器学习【Machine Learning with Spark】》</li>
<li>《python机器学习基础教程》</li>
<li>《机器学习实战：基于Scikit-Learn和TensorFlow》</li>
<li>《优达学城-机器学习入门》</li>
<li>《coursera-机器学习-吴恩达》  <a href="http://www.ai-start.com/ml2014/">笔记</a></li>
<li>《Python机器学习实践指南》</li>
<li>《Python机器学习——预测分析核心算法》</li>
<li>《深入理解XGBoost：高效机器学习算法与进阶》</li>
<li>《分布式机器学习：算法、理论与实践》</li>
<li><a href="https://mp.weixin.qq.com/s/UI0kUS8EtXaDD7MlXTuTcg">机器学习资源汇总</a></li>
</ol>
<h2><span id="python实践">python实践</span></h2><ol>
<li>《流畅的python》</li>
<li>《python数据分析基础》</li>
<li>《利用python进行数据分析》</li>
<li>《python机器学习及实践：从零开始通往Kaggle竞赛之路》</li>
<li><a href="https://www.6aiq.com/article/1550074429084">《美团机器学习实战》</a>  <a href="https://zhuanlan.zhihu.com/p/62625806">笔记</a></li>
</ol>
<h2><span id="深度学习">深度学习</span></h2><ol>
<li>《深度学习》 <a href="https://github.com/topics/deeplearning-ai">笔记</a></li>
<li>《动手学深度学习》</li>
<li>《<a href="https://nndl.github.io/">神经网络与深度学习</a>》</li>
<li>《python神经网络编程》</li>
<li>《深度学习入门-基于python的理论与实现》</li>
<li>《python深度学习》</li>
<li>《deeplearning.ai-深度学习吴恩达》</li>
<li>《TensorFlow技术解析与实战》</li>
<li>《精通Python自然语言处理》</li>
<li>《图神经网络基础前沿与应用》</li>
<li><a href="https://github.com/wagamamaz/tensorflow-tutorial">TensorFlow and Deep Learning Tutorials</a></li>
<li><a href="https://github.com/lyhue1991/eat_tensorflow2_in_30_days?utm_source=gold_browser_extension">30天吃掉TensorFlow</a>  <a href="https://www.heywhale.com/home/column/5d8ef3c3037db3002d3aa3a0">代码运行地址</a></li>
<li><a href="https://github.com/lyhue1991/eat_pytorch_in_20_days">20天吃掉pytorch</a> <a href="https://www.heywhale.com/home/column/5f2ac5d8af3980002cb1bc08">代码运行地址</a></li>
</ol>
<h2><span id="强化学习">强化学习</span></h2><ol>
<li>《深入浅出强化学习：原理入门》</li>
<li>《强化学习精要：核心算法与TensorFlow实现》</li>
<li>《深入浅出强化学习：编程实战》</li>
<li>《白话强化学习与Pytorch》</li>
</ol>
]]></content>
      <categories>
        <category>书单</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>8.高斯分布</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/8.%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="高斯分布">高斯分布</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>7.概率分布</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/7.%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#概率分布">概率分布</a><ul>
<li><a href="#分布一览">分布一览</a></li>
<li><a href="#1-伯努利分布">1. 伯努利分布</a></li>
<li><a href="#2-二项分布">2. 二项分布</a></li>
<li><a href="#3-beta-分布">3. Beta 分布</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="概率分布">概率分布</span></h1><h2><span id="分布一览">分布一览</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th>分布名称</th>
<th>分布公式</th>
<th>期望</th>
<th>方差</th>
</tr>
</thead>
<tbody>
<tr>
<td>伯努利分布</td>
<td>$Bern(x&#124;\mu) = \mu^x (1-\mu)^{1-x}$</td>
<td>$\mu$</td>
<td>$\mu(1-\mu)$</td>
</tr>
<tr>
<td>二项分布</td>
<td>$Bin(m&#124;N,\mu)= \frac{N!}{(N-m)!m!} \mu^m (1-\mu)^{N-m}$</td>
<td>$N\mu$</td>
<td>$N\mu(1-\mu)$</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="1-伯努利分布">1. 伯努利分布</span></h2><ul>
<li>伯努利试验： 随机试验，每次试验都只有两个结果 0 与 1， 则称为伯努利试验。</li>
</ul>
<script type="math/tex; mode=display">
Bern(x|\mu) = \mu^x (1-\mu)^{1-x} \\
E(x) = \mu \\
var(x) = \mu(1-\mu)</script><p>假设存在一个$x$的观测值的数据集$D= {x_1,…x_N}$，假设每次观测都是独立从$Betn(x|\mu)$分布中抽取，那么可以构造关于$\mu$的似然函数：</p>
<script type="math/tex; mode=display">
p(D|\mu) = \prod_{n=1}^N p(x_n|\mu) = \prod_{n=1}^N \mu^{x_n}(1-\mu)^{1-x_n}</script><p>如果采用极大似然的方式来估计$\mu$的值，那么，对应的极大似然函数为：</p>
<script type="math/tex; mode=display">
lnp(D|\mu) = \sum_{n=1}^N ln p(x_n|\mu) = \sum_{n=1}^N \{x_n ln \mu + (1-x_n)ln(1-\mu)\}</script><p>令 $ln p(D|\mu)$ 关于$\mu$的导数等于 0，就得到极大似然的估计值：</p>
<script type="math/tex; mode=display">
\mu_{ML} = \frac{1}{N} \sum_{n=1}^Nx_n</script><h2><span id="2-二项分布">2. 二项分布</span></h2><ul>
<li><p>n重伯努利试验： 将伯努利试验独立重复进行 n 次， 称为 n 重伯努利试验。</p>
</li>
<li><p>n 重伯努利试验中<strong>成功的总次数 X</strong> 服从二项分布：$X \sim B(N,\mu)$</p>
</li>
</ul>
<script type="math/tex; mode=display">
Bin(m|N,\mu)= C_N^m \mu^m (1-\mu)^{N-m} = \frac{N!}{(N-m)!m!} \mu^m (1-\mu)^{N-m} \\
E(m) = \sum_{m=0}^N m Bin(m |N,\mu) = N\mu \\
var(m) = \sum_{m=0}^N(m - E)^2 Bin(m|N,\mu) = N\mu(1-\mu)</script><h2><span id="3-beta-分布">3. Beta 分布</span></h2><script type="math/tex; mode=display">
Beta(\mu|a,b) = \frac{\Gamma (a + b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1} \\
E(\mu) = \frac{a}{a+b} \\
var(\mu) = \frac{ab}{(a+b)^2(a+b+1)}</script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>6.大数据问题</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/6.%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="大数据问题">大数据问题</span></h1><hr>
<!-- toc -->
<ul>
<li><a href="#1-数据流采样">1. 数据流采样</a><ul>
<li><a href="#k-1-时">K = 1 时</a></li>
<li><a href="#k-1-时">K &gt; 1 时</a></li>
</ul>
</li>
<li><a href="#2-基数统计">2. 基数统计</a><ul>
<li><a href="#1-hashset">1. HashSet</a></li>
<li><a href="#2-bitmap">2. bitmap</a></li>
<li><a href="#3-linear-counting">3. Linear Counting</a></li>
<li><a href="#4-loglog-counting">4. Loglog Counting</a></li>
<li><a href="#5-hyperloglog-counting">5. HyperLogLog Counting</a></li>
</ul>
</li>
<li><a href="#3-频率估计">3. 频率估计</a><ul>
<li><a href="#1-hashmap">1. HashMap</a></li>
<li><a href="#2-数据分片-hashmap">2. 数据分片 + HashMap</a></li>
<li><a href="#3-count-min-sketch">3. Count-Min Sketch</a></li>
<li><a href="#4-count-mean-min-sketch">4. Count-Mean-Min Sketch</a></li>
</ul>
</li>
<li><a href="#4-heavy-hitters">4. Heavy Hitters</a><ul>
<li><a href="#1-hashmap-heap">1. HashMap + Heap</a></li>
<li><a href="#2-多机-hashmap-heap">2. 多机 HashMap + Heap</a></li>
<li><a href="#3-count-min-sketch-heap">3. Count-Min Sketch + Heap</a></li>
<li><a href="#4-lossy-counting">4. Lossy Counting</a></li>
<li><a href="#5-spacesaving">5. SpaceSaving</a></li>
</ul>
</li>
<li><a href="#5-范围查询">5. 范围查询</a><ul>
<li><a href="#1-array-of-count-min-sketches">1. Array of Count-Min Sketches</a></li>
</ul>
</li>
<li><a href="#6-成员查询-bloom-filter">6. 成员查询 - Bloom Filter</a></li>
<li><a href="#1-从-n-个数中取-m-个数出来要求概率相等">1. 从 N 个数中取 m 个数出来，要求概率相等</a></li>
<li><a href="#2-top-k-问题">2. Top K 问题</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-数据流采样">1. 数据流采样</span></h2><ul>
<li>问题： 在一个无限的整数数据流，如何从中等概率随机抽取 k 个整数出来？  — 采样问题</li>
</ul>
<h3><span id="k-1-时">K = 1 时</span></h3><p><strong>抽样方法：</strong></p>
<ul>
<li>当第一个整数到达时，保存该整数</li>
<li>当第二个整数到达时，以 $\frac{1}{2}$ 的概率使用该整数替换第一个整数，以 $\frac{1}{2}$ 的概率丢弃该整数</li>
<li>当第 i 个整数到达时，以 $\frac{1}{i}$ 的概率使用第 i 个整数替换被选中的整数， 以 $1 - \frac{1}{i}$ 的概率丢弃 第i个整数</li>
</ul>
<p><strong>归纳法 - 验证分析</strong></p>
<ul>
<li>n = 1 时， 被选中的概率为 100%， 成立</li>
<li>设 $n = m , m \ge 1$ 时，命题成立，即前 m 个数，每一个被选中的概率为 $\frac{1}{m}$</li>
<li>当 $ n = m + 1 $ 时， 第 <code>m + 1</code> 个数被选中的概率为 $\frac{1}{m+1}$， 前 m 个数被选中的概率为 $\frac{1}{m} * (1-\frac{1}{m+1}) = \frac{1}{m+1}$ , 成立。</li>
</ul>
<h3><span id="k-gt-1-时">K &gt; 1 时</span></h3><p><strong>抽样方法</strong></p>
<ul>
<li>前 k 个整数到达时，全部保留</li>
<li>第 i 个整数到达时， 以 $\frac{k}{i}$ 的概率替换 k 个数中的某一个，以 $1-\frac{k}{i} $ 丢弃</li>
</ul>
<p><strong>归纳法 - 验证分析</strong></p>
<ul>
<li><p>$n \le k$ 时， 被选中的概率为100%， 成立</p>
</li>
<li><p>假设 $n = m, m &gt; k$ 时， 你命题成立， 即前m 个数， 每一个被选中的概率为 $\frac{1}{m}$</p>
</li>
<li><p>当 $ n = m + 1 $ 时， 第 m+1 个数被选中的概率为 $\frac{k}{m+1}$， 前 m 个数被选中的概率为：</p>
<script type="math/tex; mode=display">
\frac{1}{m} * [ \frac{k}{m+1} * (1 - \frac{1}{k})  + 1 - \frac{k}{m+1}] = \frac{1}{m+1}</script></li>
</ul>
<h2><span id="2-基数统计">2.  基数统计</span></h2><ul>
<li>题目： 计算一个数据流中不同元素的个数？</li>
</ul>
<h3><span id="1-hashset">1. HashSet</span></h3><p>采用 hashet，不断加入， 最终的hashset大小就是所求答案。 缺点： 单机内存存不下</p>
<h3><span id="2-bitmap">2.  bitmap</span></h3><ul>
<li>前提： 假设已经知道不同元素的个数的上限，假设为 N</li>
</ul>
<p>我们可以建立一个长度为N的 bit 数组， 每个元素与 bit 数组的某一位一一对应， 该位为1，则表示此元素在集合中，为 0 表示不再集合中，最终的答案为 bitmap 中1的个数。</p>
<ul>
<li>缺点： bitmap 与实际情况下不同元素的个数无关，而与不同元素的个数上限有关。</li>
</ul>
<h3><span id="3-linear-counting">3. Linear Counting</span></h3><p><strong>基本思路：</strong></p>
<ul>
<li>选择一个哈希函数 h， 其结果服从均匀分布</li>
<li>开一个长度为 m 的bitmap，初始化为 0</li>
<li>数据流每来一个元素，计算哈希值并对m取模，然后将该位置置1</li>
<li>最后，若 bitmap 中还有 u 个bit 为 0， 则不同元素的总数近似为 $-m log\frac{u}{m}$</li>
</ul>
<p><strong>m的选择</strong></p>
<p>对于 bitmap 长度的选择，主要由两个因素决定：基数大小以及容许的误差。 假设基数大小大约为n， 允许误差大约为 $\epsilon$， 则 m 需要满足如下约束：</p>
<script type="math/tex; mode=display">
m > \frac{\epsilon^t - t - 1}{(\epsilon t)^2}， t= \frac{n}{m}</script><h3><span id="4-loglog-counting">4. Loglog Counting</span></h3><p><strong>基本思路：</strong></p>
<ul>
<li><strong>均匀随机化。</strong> 选择哈希函数 h 的几大条件：<ul>
<li>h 应该尽可能减少冲突</li>
<li>h 的结果是几乎服从均匀分布的。</li>
<li>哈希后的结果是固定长度的。</li>
</ul>
</li>
<li>对于每个元素，计算出哈希值，每个哈希值是等长的，长度为 L</li>
<li></li>
</ul>
<h3><span id="5-hyperloglog-counting">5.  HyperLogLog Counting</span></h3><h2><span id="3-频率估计">3. 频率估计</span></h2><ul>
<li>题目： 计算数据流中任意元素的出现的次数</li>
</ul>
<h3><span id="1-hashmap">1. HashMap</span></h3><ul>
<li>用 HashMap 来记录每个元素出现的次数。</li>
<li>缺点： 占用内存大，单机内存无法存下这个巨大的 HashMap</li>
</ul>
<h3><span id="2-数据分片-hashmap">2. 数据分片 + HashMap</span></h3><p>假设有 n 台机器， 那么每台机器都有一个HashMap， 第 i 台处理 <code>hash(elem) % n == i-1</code>的元素。</p>
<p>查询时， 先计算元素在哪台机器上，然后去那台机器上的HashMap读取。</p>
<h3><span id="3-count-min-sketch">3. Count-Min Sketch</span></h3><ul>
<li>选定 d 个哈希函数， 并建立一个 <code>d * m</code> 的二维整数数组作为哈希表</li>
<li>对于每个元素，分别使用 d 个hash 函数计算相应哈希值，并对 m 取余，然后在对应的位置上增1，二维数组中的每个整数称为 sketch。</li>
<li>对于要查询的元素，取出 d 个sketch， 返回最小的哪一个。（d 个sketch 都是该元素的近似频率，返回任意一个均可）</li>
</ul>
<p>优点： 省内存； </p>
<p>缺点：对于出现次数较少的元素，准确性很差。主要是由于 hash 冲突比较严重</p>
<h3><span id="4-count-mean-min-sketch">4. Count-Mean-Min Sketch</span></h3><p>对 Count-Min Sketch 做了改进。</p>
<ul>
<li>来了一个查询，按照 Count-Min Sketch 的正常流程，取出它的d个sketch</li>
<li>对于每个hash函数，估算一个噪音 = 该行所有整数（除了被查询的这个元素）的平均值</li>
<li>真正的sketch = 该行的sketch  - 该行的噪音</li>
<li>返回 d 个sketch 的中位数</li>
</ul>
<h2><span id="4-heavy-hitters">4. Heavy Hitters</span></h2><ul>
<li>题目： 寻找数据流中出现最频繁的 k 个元素？</li>
</ul>
<h3><span id="1-hashmap-heap">1. HashMap + Heap</span></h3><p><strong>用一个 HashMap存放所有元素出现的次数，用一个小根堆，容量为k，存放目前出现过的最频繁的 k 个元素：</strong></p>
<ul>
<li>元素过来时，更新 HashMap， 并且在堆中查找该元素，如果找到，则+1并调整堆； 如果没有找到，则将该元素次数与堆顶元素比较，如果大于，则把堆顶元素替换为该元素，并调整堆。</li>
<li>时间复杂度为 $O(n (k + logk))$， 空间复杂度为 $O(n)$</li>
</ul>
<h3><span id="2-多机-hashmap-heap">2. 多机 HashMap + Heap</span></h3><ul>
<li>将数据分片， 第 i 台机器只处理  $hash(elem) % n == i-1$ 的元素</li>
<li>每台机器都有一个 HashMap 和 Heap， 格子计算出 top k 元素</li>
<li>将每台机器的 Heap， 通过网络汇总到一台机器上，并将多个Heap合成一个 Heap</li>
</ul>
<h3><span id="3-count-min-sketch-heap">3. Count-Min Sketch + Heap</span></h3><h3><span id="4-lossy-counting">4. Lossy Counting</span></h3><h3><span id="5-spacesaving">5. SpaceSaving</span></h3><h2><span id="5-范围查询">5. 范围查询</span></h2><ul>
<li>题目：给定一个无限的整数数据流，如何查询在某个范围内的元素出现的总次数？</li>
</ul>
<h3><span id="1-array-of-count-min-sketches">1. Array of Count-Min Sketches</span></h3><h2><span id="6-成员查询-bloom-filter">6. 成员查询 - Bloom Filter</span></h2><ul>
<li>题目：给定一个无限的数据流和一个有限集合，如何判断数据流中的元素是否在这个集合中？</li>
</ul>
<p>布隆过滤器本质上是<strong>二进制向量 + 一系列随机映射函数</strong>， 主要用于检测某元素是否在一个集合中。</p>
<ul>
<li>优点： 空间效率和查询时间都远远超过一般的算法</li>
</ul>
<p><strong>布隆过滤器原理</strong></p>
<ul>
<li>加入元素：当一个元素被加入到集合时，通过 K 个哈希函数将这个元素映射成一个位数组中的K个点，把它们置为1。 </li>
<li>检索元素：查看对应的 K 个点是否都为1 ： 如果存在任意一个为 0， 被检元素一定不在； 如果都为1，则很可能存在。</li>
</ul>
<p><strong>布隆过滤器与Bitmap 区别</strong></p>
<p>布隆过滤器使用了 k 个哈希函数，每个元素对应 k 个bit，从而降低了冲突的概率</p>
<p><strong>布隆过滤器缺点</strong></p>
<ul>
<li>存在误判：即可能要查找的元素不在容器内，但 k 个位置上都是 1</li>
<li>删除困难：一旦删除元素，不能简单将对应 k 个位置置为 0</li>
</ul>
<p><strong>布隆过滤器实现</strong></p>
<p>假设要存的数据量为n， 期望的误判率为 fpp，我们需要计算 Bit 数组的大小 m， hash 函数的个数 k，并选择合适的哈希函数。</p>
<ul>
<li>Bit 数组大小选择：<script type="math/tex; mode=display">
m = -\frac{nlnfpp}{(ln2)^2}</script></li>
</ul>
<ul>
<li>哈希函数选择：<script type="math/tex; mode=display">
k = \frac{m}{n}ln2</script></li>
</ul>
<hr>
<h2><span id="1-从-n-个数中取-m-个数出来要求概率相等">1. 从 N 个数中取 m 个数出来，要求概率相等</span></h2><p><a href="https://www.cnblogs.com/TenosDoIt/p/3364139.html">https://www.cnblogs.com/TenosDoIt/p/3364139.html</a></p>
<h2><span id="2-top-k-问题">2. Top K 问题</span></h2><p><a href="http://doc.okbase.net/zyq522376829/archive/169290.html">http://doc.okbase.net/zyq522376829/archive/169290.html</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>5.抽样方法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/5.%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#抽样方法">抽样方法</a><ul>
<li><a href="#简单随机抽样">简单随机抽样</a></li>
<li><a href="#分层采样">分层采样</a></li>
<li><a href="#水塘采样">水塘采样</a></li>
<li><a href="#随机欠采样和过采样">随机欠采样和过采样</a></li>
<li><a href="#使用-imbalanced-learn-进行欠采样和过采样">使用 imbalanced-learn 进行欠采样和过采样</a></li>
</ul>
</li>
<li><a href="#结论">结论</a></li>
<li><a href="#分层抽样的适用范围">分层抽样的适用范围？</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="抽样方法">抽样方法</span></h1><p>采样问题是数据科学中的常见问题，对此，WalmartLabs 的数据科学家 Rahul Agarwal 分享了数据科学家需要了解的 5 种采样方法，编译整理如下。</p>
<p>数据科学实际上是就是研究算法。</p>
<p>我每天都在努力学习许多算法，所以我想列出一些最常见和最常用的算法。</p>
<p>本文介绍了在处理数据时可以使用的一些最常见的采样技术。</p>
<h2><span id="简单随机抽样">简单随机抽样</span></h2><p>假设您要选择一个群体的子集，其中该子集的每个成员被选择的概率都相等。</p>
<p>下面我们从一个数据集中选择 100 个采样点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sample_df = df.sample(<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<h2><span id="分层采样">分层采样</span></h2><p>假设我们需要估计选举中每个候选人的平均票数。现假设该国有 3 个城镇：</p>
<p>A 镇有 100 万工人，</p>
<p>B 镇有 200 万工人，以及</p>
<p>C 镇有 300 万退休人员。</p>
<p>我们可以选择在整个人口中随机抽取一个 60 大小的样本，但在这些城镇中，随机样本可能不太平衡，因此会产生偏差，导致估计误差很大。</p>
<p>相反，如果我们选择从 A、B 和 C 镇分别抽取 10、20 和 30 个随机样本，那么我们可以在总样本大小相同的情况下，产生较小的估计误差。</p>
<p>使用 python 可以很容易地做到这一点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,  test_size=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure>
<h2><span id="水塘采样">水塘采样</span></h2><p>我喜欢这个问题陈述：</p>
<p>假设您有一个项目流，它长度较大且未知以至于我们只能迭代一次。</p>
<p>创建一个算法，从这个流中随机选择一个项目，这样每个项目都有相同的可能被选中。</p>
<p>我们怎么能做到这一点？</p>
<p>假设我们必须从无限大的流中抽取 5 个对象，且每个元素被选中的概率都相等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> randomdef generator(<span class="built_in">max</span>): number = <span class="number">1</span> <span class="keyword">while</span> number &lt; <span class="built_in">max</span>: number += <span class="number">1</span> <span class="keyword">yield</span> number<span class="comment"># Create as stream generatorstream = generator(10000)# Doing Reservoir Sampling from the streamk=5reservoir = []for i, element in enumerate(stream): if i+1&lt;= k: reservoir.append(element) else: probability = k/(i+1) if random.random() &lt; probability: # Select item in stream and remove one of the k items already selected reservoir[random.choice(range(0,k))] = elementprint(reservoir)------------------------------------[1369, 4108, 9986, 828, 5589]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>从数学上可以证明，在样本中，流中每个元素被选中的概率相同。这是为什么呢？</p>
<p>当涉及到数学问题时，从一个小问题开始思考总是有帮助的。</p>
<p>所以，让我们考虑一个只有 3 个项目的流，我们必须保留其中 2 个。</p>
<p>当我们看到第一个项目，我们把它放在清单上，因为我们的水塘有空间。在我们看到第二个项目时，我们把它放在列表中，因为我们的水塘还是有空间。</p>
<p>现在我们看到第三个项目。这里是事情开始变得有趣的地方。我们有 2/3 的概率将第三个项目放在清单中。</p>
<p>现在让我们看看第一个项目被选中的概率：</p>
<p>移除第一个项目的概率是项目 3 被选中的概率乘以项目 1 被随机选为水塘中 2 个要素的替代候选的概率。这个概率是：</p>
<p>2/3*1/2 = 1/3</p>
<p>因此，选择项目 1 的概率为：</p>
<p>1–1/3=2/3</p>
<p>我们可以对第二个项目使用完全相同的参数，并且可以将其扩展到多个项目。</p>
<p>因此，每个项目被选中的概率相同：2/3 或者用一般的公式表示为 K/N</p>
<h2><span id="随机欠采样和过采样">随机欠采样和过采样</span></h2><p>我们经常会遇到不平衡的数据集。</p>
<p>一种广泛采用的处理高度不平衡数据集的技术称为重采样。它包括从多数类（欠采样）中删除样本或向少数类（过采样）中添加更多示例。</p>
<p>让我们先创建一些不平衡数据示例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classificationX, y = make_classification( n_classes=<span class="number">2</span>, class_sep=<span class="number">1.5</span>, weights=[<span class="number">0.9</span>, <span class="number">0.1</span>], n_informative=<span class="number">3</span>, n_redundant=<span class="number">1</span>, flip_y=<span class="number">0</span>, n_features=<span class="number">20</span>, n_clusters_per_class=<span class="number">1</span>, n_samples=<span class="number">100</span>, random_state=<span class="number">10</span>)X = pd.DataFrame(X)X[ target ] = y</span><br></pre></td></tr></table></figure>
<p>我们现在可以使用以下方法进行随机过采样和欠采样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_0 = <span class="built_in">len</span>(X[X[ target ]==<span class="number">0</span>])num_1 = <span class="built_in">len</span>(X[X[ target ]==<span class="number">1</span>])<span class="built_in">print</span>(num_0,num_1)<span class="comment"># random undersampleundersampled_data = pd.concat([ X[X[ target ]==0].sample(num_1) , X[X[ target ]==1] ])print(len(undersampled_data))# random oversampleoversampled_data = pd.concat([ X[X[ target ]==0] , X[X[ target ]==1].sample(num_0, replace=True) ])print(len(oversampled_data))------------------------------------------------------------OUTPUT:90 1020180</span></span><br></pre></td></tr></table></figure>
<h2><span id="使用-imbalanced-learn-进行欠采样和过采样">使用 imbalanced-learn 进行欠采样和过采样</span></h2><p>imbalanced-learn（imblearn）是一个用于解决不平衡数据集问题的 python 包，它提供了多种方法来进行欠采样和过采样。</p>
<p>a. 使用 Tomek Links 进行欠采样：</p>
<p>imbalanced-learn 提供的一种方法叫做 Tomek Links。Tomek Links 是邻近的两个相反类的例子。<br>在这个算法中，我们最终从 Tomek Links 中删除了大多数元素，这为分类器提供了一个更好的决策边界。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> TomekLinks</span><br><span class="line">tl = TomekLinks(return_indices=<span class="literal">True</span>, ratio= majority )X_tl, y_tl, id_tl = tl.fit_sample(X, y)</span><br></pre></td></tr></table></figure>
<p>b. 使用 SMOTE 进行过采样：</p>
<p>在 SMOE（Synthetic Minority Oversampling Technique）中，我们在现有元素附近合并少数类的元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line">smote = SMOTE(ratio= minority )X_sm, y_sm = smote.fit_sample(X, y)</span><br></pre></td></tr></table></figure>
<p>imbLearn 包中还有许多其他方法，可以用于欠采样（Cluster Centroids, NearMiss 等）和过采样（ADASYN 和 bSMOTE）。</p>
<h1><span id="结论">结论</span></h1><p>算法是数据科学的生命线。</p>
<p>抽样是数据科学中的一个重要课题，但我们实际上并没有讨论得足够多。</p>
<p>有时，一个好的抽样策略会大大推进项目的进展。错误的抽样策略可能会给我们带来错误的结果。因此，在选择抽样策略时应该小心。</p>
<p>via：<a href="https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c">https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c</a></p>
<h1><span id="分层抽样的适用范围">分层抽样的适用范围？</span></h1><p>分层抽样利用事先掌握的信息， 充分考虑了保持样本结构和总体结构的一致性，当总体由差异明显的几部分组成的时候，适合用分层抽样。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>4.信息论</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/4.%E4%BF%A1%E6%81%AF%E8%AE%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#基本知识">基本知识</a></li>
<li><a href="#1-自信息-信息熵互信息">1. 自信息 ，信息熵，互信息</a><ul>
<li><a href="#自信息-self-information">自信息 - self-information</a></li>
<li><a href="#信息熵-information-entropy">信息熵 — information-entropy</a></li>
<li><a href="#互信息">互信息</a></li>
</ul>
</li>
<li><a href="#2-相对熵kl散度-与-交叉熵">2. 相对熵（KL散度） 与 交叉熵</a><ul>
<li><a href="#1-相对熵-kl-散度-kullback-leibler-divergence">1. 相对熵 — KL 散度 ： Kullback-Leibler divergence</a></li>
<li><a href="#2-交叉熵-cross-entropy">2. 交叉熵 - cross entropy</a></li>
<li><a href="#3-交叉熵与kl散度的关系">3. 交叉熵与KL散度的关系</a></li>
</ul>
</li>
<li><a href="#3-联合熵与条件熵">3. 联合熵与条件熵</a></li>
<li><a href="#4-互信息">4. 互信息</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="基本知识">基本知识</span></h2><ul>
<li><p>基本思想: 一件不太可能的事情发生, 要比一件非常可能的事情发生提供更多的信息</p>
</li>
<li><p>性质:</p>
<blockquote>
<ul>
<li>非常可能发生的事情信息量较少,并且极端情况下,一定能够发生的事件应该没有信息量</li>
<li>比较不可能发生的事件具有更大的信息量</li>
<li>独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，应该是投掷一次硬币正面朝上的信息量的两倍。</li>
</ul>
</blockquote>
</li>
</ul>
<h2><span id="1-自信息-信息熵互信息">1. 自信息 ，信息熵，互信息</span></h2><h3><span id="自信息-self-information">自信息 - self-information</span></h3><p>如果说概率P是对确定性的度量，信息是对不确定性的度量，这两者是相对的， <strong>事件发生的概率越大，那么事件的信息量就越小， 事件的概率与事件的信息量之间成反比。</strong></p>
<p>举例来说：如果<strong>事件A发生的概率比事件B发生的概率要大</strong>，那么我们就说<strong>事件B的信息量要比事件A的信息量要大</strong>。</p>
<p>信息量能够量化以上性质,定义一个事件x的自信息为：</p>
<script type="math/tex; mode=display">
I(x) = -log(p(x))</script><p>当该对数的底数为自然对数 e 时，单位为奈特（nats）；当以 2 为底数时，单位为比特（bit）或香农（shannons）.</p>
<h3><span id="信息熵-information-entropy">信息熵 — information-entropy</span></h3><p>信息熵是对<strong>平均不确定性</strong>的度量，本质上是<strong>所有事件的信息量的期望</strong>， 对整个概率分布中的不确定性总量进行量化：</p>
<script type="math/tex; mode=display">
H(X) = E_{X}[I(x)]=-\sum_{x \in X} p(x)log(p(x))； \quad X 表示所有事件\\</script><p>信息论中，记 <code>0log0 = 0</code></p>
<ul>
<li>当且仅当某个 $P(X_i)=1$，其余的都等于0时， H(X)= 0。</li>
<li>当且仅当某个$P(X_i)=1/n，i=1， 2，……， n$时，$H(X)$ 有极大值 log n。</li>
</ul>
<p>熵可以表示样本集合的不确定性，<strong>熵越大，样本的不确定性就越大</strong>。</p>
<h3><span id="互信息">互信息</span></h3><script type="math/tex; mode=display">
I(X,Y) = \sum_{y \in Y} \sum_{x \in X} p(x,y) log( \frac{p(x,y)}{p(x)p(y)})</script><p>互信息 $I(X,Y)$ 取值为非负。当X、Y相互独立时，$I(X,Y)$ 最小为0。</p>
<h2><span id="2-相对熵kl散度-与-交叉熵">2. 相对熵（KL散度） 与 交叉熵</span></h2><h3><span id="1-相对熵-kl-散度-kullback-leibler-divergence">1. 相对熵 — KL 散度 ： Kullback-Leibler divergence</span></h3><p>如果对于同一个随机变量 x 有两个单独的概率分布 P(x) 和 Q(x)，我们可以使用 KL 散度来衡量<strong>这两个分布的差异</strong>。</p>
<ul>
<li>定义： P 对 Q 的KL散度为：</li>
</ul>
<script type="math/tex; mode=display">
D_P(Q) =\sum_{x \in X}P(x)log(\frac{P(x)}{Q(x)})</script><ul>
<li><p>含义：在离散型变量的情况下， KL 散度衡量的是：<strong>当我们使用一种被设计成能够使得概率分布 Q 产生的消息的长度最小的编码，发送包含由概率分布 P 产生的符号的消息时，所需要的额外信息量。</strong></p>
</li>
<li><p>性质：</p>
<blockquote>
<ul>
<li><strong>非负: </strong>KL 散度为 0 当且仅当P 和 Q 在离散型变量的情况下是相同的分布，或者在连续型变量的情况下是“几乎处处”相同的.</li>
<li><strong>不对称</strong>：$D_p(q) != D_q(p)$</li>
</ul>
</blockquote>
</li>
</ul>
<h3><span id="2-交叉熵-cross-entropy">2. 交叉熵 - cross entropy</span></h3><ul>
<li>设 $p(x), q(x)$ 为 $X$ 中取值的两个概率分布，则 $p$ 对 $q$ 的交叉熵为：</li>
</ul>
<script type="math/tex; mode=display">
D(p || q) = -\sum_{x \in X}p(x)log\, \frac{p(x)}{q(x)}</script><p>在一定程度上，相对熵可以度量两个随机变量的“距离”。</p>
<h3><span id="3-交叉熵与kl散度的关系">3. 交叉熵与KL散度的关系</span></h3><ul>
<li><p><strong>针对 Q 最小化交叉熵等价于最小化 P 对 Q 的 KL 散度</strong>，因为 Q 并不参与被省略的那一项。</p>
<script type="math/tex; mode=display">
H_P(Q) = H(P) + D_P(Q)最大似然估计中，最小化 KL 散度其实就是在最小化分布之间的交叉熵。</script></li>
<li><p>最大似然估计中，最小化 KL 散度其实就是在最小化分布之间的交叉熵。</p>
</li>
</ul>
<h2><span id="3-联合熵与条件熵">3. 联合熵与条件熵</span></h2><ul>
<li><p>联合熵 $H(X, Y)$：两个随机变量X，Y的联合分布。</p>
</li>
<li><p>条件熵 $H(Y|X) $：在随机变量X发生的前提下，随机变量Y发生所新带来的熵定义为Y的条件熵，用来衡量在已知随机变量X的条件下随机变量Y的不确定性。</p>
</li>
</ul>
<script type="math/tex; mode=display">
H(Y|X) = H(X,Y) - H(X)</script><p>联合熵与条件熵的推导过程如下：</p>
<script type="math/tex; mode=display">
\begin{align}
H(X, Y) - H(X) &= -\sum_{x,y} p(x,y) log \, p(x,y) + \sum_x p(x) log \, p(x) \\
&= -\sum_{x,y} p(x,y) log \, p(x,y) +  \sum_x (\sum_y p(x,y)) \, log \, p(x) \qquad \text{边缘分布 p(x) 等于联合分布 p(x,y) 的和} \\
&= -\sum_{x,y} p(x,y) log \, p(x,y) +  \sum_{x,y} p(x,y) \, log \, p(x) \\ 
&= -\sum_{x,y} p(x,y) log \frac{p(x,y)}{p(x)} \\
&= -\sum_{x,y} p(x,y) log p(y|x)
\end{align}</script><h2><span id="4-互信息">4. 互信息</span></h2><ul>
<li>$I(X, Y)$ ：两个随机变量X，Y的互信息 为<strong>X，Y的联合分布</strong>和<strong>各自独立分布乘积</strong>的<strong>相对熵</strong>。</li>
</ul>
<script type="math/tex; mode=display">
I(X, Y) = \sum_{x,y} p(x,y) log \frac{p(x,y)}{p(x)p(y)} \\
I(X, Y) = D(P(X,Y) || P(X)P(Y))</script><p>推导如下：</p>
<p><a href="https://www.nowcoder.com/ta/review-ml/review?page=59">https://www.nowcoder.com/ta/review-ml/review?page=59</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>3.线性代数</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/3.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-矩阵相乘">1. 矩阵相乘</a></li>
<li><a href="#1-范数">1. 范数</a><ul>
<li><a href="#1-向量的范数">1. 向量的范数</a></li>
<li><a href="#2-矩阵的范数">2. 矩阵的范数</a></li>
</ul>
</li>
<li><a href="#4-特征值分解特征向量">4. 特征值分解，特征向量</a></li>
<li><a href="#6-条件概率">6. 条件概率</a></li>
<li><a href="#7-联合概率与边缘概率">7. 联合概率与边缘概率</a></li>
<li><a href="#8-独立性与条件独立性">8. 独立性与条件独立性</a></li>
<li><a href="#8-期望方差协方差-相关系数">8. 期望，方差，协方差， 相关系数</a><ul>
<li><a href="#1-期望">1. 期望</a></li>
<li><a href="#2-方差">2. 方差</a></li>
<li><a href="#3-协方差">3. 协方差</a></li>
<li><a href="#4-相关系数">4. 相关系数</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-矩阵正定性">1. 矩阵正定性</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-矩阵相乘">1. 矩阵相乘</span></h2><script type="math/tex; mode=display">
c_{ij} = a_{ik} * b_{kj}</script><h2><span id="1-范数">1. 范数</span></h2><h3><span id="1-向量的范数">1. 向量的范数</span></h3><p>任意一组向量设为$\vec{x}=(x_1,x_2,…,x_N)$ 如下：</p>
<ul>
<li>向量的1范数： 向量的各个元素的绝对值之和</li>
</ul>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_1=\sum_{i=1}^N\vert{x_i}\vert</script><ul>
<li>向量的2范数： 向量的每个元素的平方和再开平方根</li>
</ul>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_2=\sqrt{\sum_{i=1}^N{\vert{x_i}\vert}^2}</script><ul>
<li><p>向量的负无穷范数： 向量所有元素的绝对值中最小的</p>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_{-\infty}=\min{|{x_i}|}</script></li>
<li><p>向量的正无穷范数： 向量所有元素的绝对值中最大的</p>
</li>
</ul>
<script type="math/tex; mode=display">
\Vert\vec{x}\Vert_{+\infty}=\max{|{x_i}|}</script><ul>
<li>向量的p范数： 向量元素绝对值的p次方和，然后再开P次方根<script type="math/tex; mode=display">
L_p=\Vert\vec{x}\Vert_p=\sqrt[p]{\sum_{i=1}^{N}|{x_i}|^p}</script></li>
</ul>
<h3><span id="2-矩阵的范数">2. 矩阵的范数</span></h3><p>对于矩阵 $A_{m \times n}$， 举例而说： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A = [</span><br><span class="line">-1, 2, 3;</span><br><span class="line">4, -6, 6;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<ul>
<li><p>矩阵的1范数（列范数）：矩阵的每一列上的元素绝对值先求和，再从中取个最大值</p>
<script type="math/tex; mode=display">
\Vert A\Vert_1=\max_{1\le j\le n}\sum_{i=1}^m|{a_{ij}}| \\
\text{举例}: \Vert A\Vert_1 = max([5,8,9]) = 9</script></li>
<li><p>矩阵的2范数： 矩阵 $A^TA$ 的最大特征值开平方根</p>
<script type="math/tex; mode=display">
\Vert A\Vert_2=\sqrt{\lambda_{max}(A^T A)}</script></li>
</ul>
<h2><span id="4-特征值分解特征向量">4. 特征值分解，特征向量</span></h2><ul>
<li>特征值分解可以得到特征值与特征向量</li>
<li>特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么</li>
</ul>
<p>矩阵A 的特征值与其特征向量$\vec{v}$, 特征值 $\lambda$ 满足：</p>
<script type="math/tex; mode=display">
A\nu = \lambda \nu</script><p>特征值分解是将一个矩阵分解为如下形式：</p>
<script type="math/tex; mode=display">
A=Q\sum Q^{-1} \\
Q: 矩阵A的特征向量组成的矩阵 \\</script><p>$\sum$: 一个对角矩阵，每一个对角元素是一个特征值里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）。 特征值分解表示矩阵$A$的信息可以由其特征值和特征向量表示。</p>
<h2><span id="6-条件概率">6. 条件概率</span></h2><script type="math/tex; mode=display">
P(A|B) = \frac{P(A\cap B)}{P(B)} \\
P(A_1A_2...A_n)=P(A_n|A_1...A_{n-1})...P(A_2|A_1)P(A_1)
=P(A_1)\prod_{i=2}^{n}P(A_i|A_1...A_{i-1})</script><h2><span id="7-联合概率与边缘概率">7. 联合概率与边缘概率</span></h2><ul>
<li>联合概率：联合概率指类似于$P(X=a,Y=b)$这样，包含多个条件，且所有条件同时成立的概率。</li>
<li><p>边缘概率：边缘概率指类似于$P(X=a)$，$P(Y=b)$这样，仅与单个随机变量有关的概率。</p>
</li>
<li><p>区别：联合概率是指在多元的概率分布中多个随机变量分别满足各自条件的概率。而边缘概率是某个事件发生的概率，而与其它事件无关。</p>
</li>
<li><p>联系： 联合分布可求边缘分布，但若只知道边缘分布，无法求得联合分布。  </p>
</li>
</ul>
<h2><span id="8-独立性与条件独立性">8. 独立性与条件独立性</span></h2><ul>
<li>独立性：$P(XY)=P(X)P(Y)$</li>
<li>条件独立： 再条件Z发生时， X， Y 条件独立：<script type="math/tex; mode=display">
X\bot Y|Z \iff P(X,Y|Z) = P(X|Z)P(Y|Z)</script></li>
</ul>
<h2><span id="8-期望方差协方差-相关系数">8. 期望，方差，协方差， 相关系数</span></h2><h3><span id="1-期望">1. 期望</span></h3><script type="math/tex; mode=display">
E(ax+by+c) = aE(x)+bE(y)+c \\
离散函数期望：E(f(x))=\sum_{k=1}^{n}{f(x_k)P(x_k)} \\
连续函数期望：E(f(x))=\int_{-\infty}^{+\infty}{f(x)p(x)dx}</script><p><strong>如果$X$和$Y$相互独立，则$E(xy)=E(x)E(y)$。  </strong></p>
<h3><span id="2-方差">2. 方差</span></h3><script type="math/tex; mode=display">
Var(x) = E((x-\overline{x})^2) \\
Var(x) = E(x^2) -E(x)^2</script><p><strong>如果$X$和$Y$相互独立,$Var(ax+by)=a^2Var(x)+b^2Var(y)$</strong></p>
<h3><span id="3-协方差">3. 协方差</span></h3><p><strong>协方差是衡量两个遍历的总体误差。</strong></p>
<script type="math/tex; mode=display">
Cov(x,y)=E((x-E(x))(y-E(y))) \\
Cov(ax,by) = abCov(x,y) \\
Cov(a+bx, c+dy) = bdCov(x, y)</script><p><strong>独立变量的协方差为0。</strong></p>
<h3><span id="4-相关系数">4. 相关系数</span></h3><script type="math/tex; mode=display">
Corr(x,y) = \frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}}</script><p><strong>值越接近1，说明两个变量正相关性（线性）越强。越接近-1，说明负相关性越强，当为0时，表示两个变量没有相关性</strong></p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-矩阵正定性">1. 矩阵正定性</span></h3><ul>
<li><p>问题：矩阵正定性的判断？ </p>
<blockquote>
<ul>
<li>矩阵中的特征值均不小于 0 ， 则为半正定。</li>
<li>矩阵中的特征值都大于 0， 则为正定。</li>
</ul>
</blockquote>
</li>
<li><p>Hessian矩阵正定性在梯度下降中的应用</p>
<blockquote>
<ul>
<li>在判断优化算法的可行性时Hessian矩阵的正定性起到了很大的作用,若Hessian正定,则函数的二阶偏导恒大于0,函数的变化率处于递增状态,在牛顿法等梯度下降的方法中,Hessian矩阵的正定性可以很容易的判断函数是否可收敛到局部或全局最优解。</li>
</ul>
</blockquote>
</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>2.高数</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/2.%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="qa">QA</span></h2><h3><span id="1-欧拉公式">1. 欧拉公式</span></h3><script type="math/tex; mode=display">
e^{ix} = cosx + isinx</script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>1.概率论</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/1.%E6%A6%82%E7%8E%87%E8%AE%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="contents">Contents</span></h2><!-- toc -->
<ul>
<li><a href="#1-随机事件和概率">1. 随机事件和概率</a><ul>
<li><a href="#1-事件运算规律">1. 事件运算规律</a></li>
<li><a href="#2-条件概率">2. 条件概率</a></li>
<li><a href="#3-事件独立性">3. 事件独立性</a></li>
<li><a href="#4-五大公式">4. 五大公式</a></li>
<li><a href="#5-古典型概率">5. 古典型概率</a></li>
<li><a href="#6-几何型概率">6. 几何型概率</a></li>
<li><a href="#7-n重伯努利试验">7. n重伯努利试验</a></li>
</ul>
</li>
<li><a href="#2-随机变量与分布">2. 随机变量与分布</a><ul>
<li><a href="#1离散型随机变量">1.离散型随机变量</a></li>
<li><a href="#2-连续型随机变量">2. 连续型随机变量</a></li>
<li><a href="#3-常见分布">3. 常见分布</a></li>
<li><a href="#4-todo">4. TODO</a></li>
</ul>
</li>
<li><a href="#4-随机变量的数学特征">4. 随机变量的数学特征</a><ul>
<li><a href="#1-数学期望">1. 数学期望</a></li>
<li><a href="#2-方差">2. 方差</a></li>
<li><a href="#3-常见分布期望与方差-todo">3. 常见分布期望与方差 — TODO</a></li>
<li><a href="#4-协方差">4. 协方差</a></li>
<li><a href="#5-相关系数">5. 相关系数</a></li>
<li><a href="#6-独立与不相关">6. 独立与不相关</a></li>
</ul>
</li>
<li><a href="#5-知识点">5. 知识点</a><ul>
<li><a href="#1-古典概率模型">1. 古典概率模型</a></li>
<li><a href="#2-几何概率">2. 几何概率</a></li>
<li><a href="#3-数学期望">3. 数学期望</a></li>
<li><a href="#4-贝叶斯">4. 贝叶斯</a></li>
</ul>
</li>
<li><a href="#6-贝叶斯定理">6. 贝叶斯定理</a><ul>
<li><a href="#1-基本概率">1. 基本概率</a></li>
<li><a href="#2-两大规则">2. 两大规则</a></li>
<li><a href="#3-实例说明">3. 实例说明</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-简单古典概率">1. 简单古典概率</a></li>
<li><a href="#2-纸牌问题">2. 纸牌问题</a></li>
<li><a href="#3-棍子问题">3. 棍子问题</a></li>
<li><a href="#4-采样问题">4. 采样问题</a></li>
<li><a href="#5-贝叶斯">5. 贝叶斯</a></li>
<li><a href="#6-假期期望">6. 假期期望</a></li>
<li><a href="#7-下雨概率">7. 下雨概率</a></li>
<li><a href="#8-见面概率">8. 见面概率</a></li>
<li><a href="#9-为何推荐使用高斯分布">9. 为何推荐使用高斯分布？</a></li>
<li><a href="#10-玫瑰花">10. 玫瑰花</a></li>
<li><a href="#11-切比雪夫不等式">11. 切比雪夫不等式</a></li>
<li><a href="#12-0~1均匀分布的随机器如何变化成均值为0方差为1的随机器">12. 0~1均匀分布的随机器如何变化成均值为0，方差为1的随机器</a></li>
<li><a href="#13-红蓝球">13. 红蓝球</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a href="https://zhuanlan.zhihu.com/p/42859784">https://zhuanlan.zhihu.com/p/42859784</a></p>
<h2><span id="1-随机事件和概率">1. 随机事件和概率</span></h2><h3><span id="1-事件运算规律">1. 事件运算规律</span></h3><ul>
<li><p>交换律：</p>
<script type="math/tex; mode=display">
A \cup B = B \cup A</script><script type="math/tex; mode=display">
A \cap B = B \cap A</script></li>
<li><p>结合律：</p>
<script type="math/tex; mode=display">
A \cup (B \cup C) = (A \cup B) \cup C</script><script type="math/tex; mode=display">
A \cap (B \cap C) = (A \cap B) \cap C</script></li>
<li><p>分配律：</p>
<script type="math/tex; mode=display">
A \cap (B \cup C) = (A \cap B) \cup (A \cap C)</script><script type="math/tex; mode=display">
A \cup (B \cap C) = (A \cup B) \cap (A \cup C)</script></li>
</ul>
<h3><span id="2-条件概率">2. 条件概率</span></h3><script type="math/tex; mode=display">
P(B|A) = \frac{P(AB)}{P(A)}</script><h3><span id="3-事件独立性">3. 事件独立性</span></h3><script type="math/tex; mode=display">
A,B \, 相互独立  <--> P(AB) = P(A)P(B)</script><ul>
<li>A,B 相互独立的充要条件为 A 与 $\overline{B} $ 或 $\overline{A}$ 与 B 或 $\overline{A}$ 与 $\overline{B}$ 相互独立。</li>
<li>当 0 &lt; P(A) &lt; 1 时， A, B 相互独立 等价于 P(B|A) = P(B) 或 $P(B|A) = P(B|\overline{A})$成立 </li>
<li>n 个事件间相互独立 —&gt; 这n个事件必两两独立； 反之不成立。</li>
</ul>
<h3><span id="4-五大公式">4.  五大公式</span></h3><ul>
<li><p>加法公式：</p>
<script type="math/tex; mode=display">
P(A + B) = P(A) + P(B) - P(AB)</script><script type="math/tex; mode=display">
P(A + B + C) = P(A) + P(B) + P(C) - P(AB) - P(AC) - P(BC) + P(ABC)</script></li>
<li><p>减法公式：</p>
<script type="math/tex; mode=display">
P(A - B) = P(A) - P(AB)</script></li>
<li><p>乘法公式：</p>
<script type="math/tex; mode=display">
P(A) > 0 时， P(AB) = P(A)P(B|A)</script></li>
<li><p>全概率公式：</p>
<script type="math/tex; mode=display">
P(A) = \sum_{i=1}^n P(B_i)P(A|B_i)</script></li>
<li><p>贝叶斯公式：</p>
<script type="math/tex; mode=display">
P(B_j| A) = \frac{P(B_j)P(A|B_j)}{\sum_{i=1}^n P(B_i)P(A|B_i)}</script></li>
</ul>
<h3><span id="5-古典型概率">5. 古典型概率</span></h3><ul>
<li><p>定义： 在样本空间中，有有限 n 个样本点，且每个样本点的发生具有相等的可能性，则称这种有限等可能试验为古典概型。</p>
</li>
<li><p>如果事件 A 由 $n_A$ 个样本点组成，则事件 A 的概率为：</p>
<script type="math/tex; mode=display">
P(A) = \frac{n_A}{n} = \frac{A 中包含的样本点}{样本空间中的样本点总数}</script></li>
</ul>
<h3><span id="6-几何型概率">6. 几何型概率</span></h3><ul>
<li><p>定义：当试验的样本空间是某区域（该区域可以是一维，二维或三维等）， 以 $L(\Omega)$ 表示当前样本空间 $\Omega$ 的几何度量（长度，面积，体积）等。 $L(\Omega)$ 为有限，且试验结果出现在 $\Omega$ 中的任意区域的可能性只与该区域几何度量成正比。</p>
</li>
<li><p>如果事件 A 的样本点表示的区域为 $\Omega_A$ ， 那么事件A的概率为：</p>
<script type="math/tex; mode=display">
P(A) = \frac{L(\Omega_A)}{L(\Omega)} = \frac{\Omega_A 的几何度量}{\Omega 的几何度量}</script></li>
</ul>
<h3><span id="7-n重伯努利试验">7. n重伯努利试验</span></h3><ul>
<li>伯努利试验： 随机试验，每次试验都只有两个结果 $A$ 与 $\overline{A}$， 则称为伯努利试验。</li>
<li>n重伯努利试验： 将伯努利试验独立重复进行 n 次， 称为 n 重伯努利试验。</li>
</ul>
<p>若每次实验中， $P(A)= p$， 那么 n 重伯努利试验中事件 A 发生 k 次的概率为：</p>
<script type="math/tex; mode=display">
二项概率公式：C_n^k p^k(1-p)^{n-k}</script><h2><span id="2-随机变量与分布">2. 随机变量与分布</span></h2><h3><span id="1离散型随机变量">1.离散型随机变量</span></h3><script type="math/tex; mode=display">
概率分布：P\{X=x_k \} = p_k \\
分布函数： F(x) = P(X \leq x) = \sum_{x_k \leq x}p_k  \\</script><h3><span id="2-连续型随机变量">2. 连续型随机变量</span></h3><script type="math/tex; mode=display">
F(x) = \int_{-\infty}^{x} f(t)dt</script><h3><span id="3-常见分布">3. 常见分布</span></h3><ul>
<li><p><strong>几何分布：</strong>n重伯努利试验中， 在第 k 次试验时才首次试验成功的概率服从几何分布。</p>
<script type="math/tex; mode=display">
P\{X = K \} = p (1-p)^{k-1}</script></li>
<li><p><strong>超几何分布：</strong> N 件商品中含有 M 件次品，从中任意一次取出 n 件(或从中一件接一件不放回的取n件)， 令 X = 抽取的n件商品中的次品件数， 则 X 服从参数为 n， N， M 的超几何分布。</p>
<script type="math/tex; mode=display">
P\{ X = k \} = \frac{C_M^kC_{N-M}^{n-k}}{C_N^n}</script></li>
<li><p><strong>泊松分布：</strong>一段时间内电话总机接到的呼叫次数， 候车的旅客数，保险索赔的次数都服从泊松分布。</p>
<script type="math/tex; mode=display">
P\{X = k \} = \frac{\lambda^k}{k!} e^{-\lambda};m \quad X \sim P(\lambda)</script></li>
<li><p><strong>均匀分布：</strong>X 在区间 [a,b] 上服从均匀分布，则 $X \sim U(a,b)$</p>
<script type="math/tex; mode=display">
f(x)= \begin{cases} \frac{1}{b-a}, & a < x <b  \\ 0, & \text{其他} \end{cases}\\
F(x)= \begin{cases} 0, & x < a \\ \frac{x-a}{b-a}, & a \leq x <b  \\ 1, & x \geq b  \end{cases}</script></li>
<li><p>指数分布： $X \sim E(\lambda)$</p>
<script type="math/tex; mode=display">
</script></li>
<li><p>正态分布</p>
</li>
</ul>
<h3><span id="4-todo">4. TODO</span></h3><h2><span id="4-随机变量的数学特征">4. 随机变量的数学特征</span></h2><h3><span id="1-数学期望">1. 数学期望</span></h3><ul>
<li><p>离散型随机变量：</p>
<script type="math/tex; mode=display">
P(x_k) = p_k \\
E(x) = \sum_{k=1}^n x_k p_k</script></li>
<li><p>连续型随机变量：</p>
<script type="math/tex; mode=display">
E(X) = \int_{-\infty}^{+\infty} xf(x)dx</script></li>
<li><p>性质：设 C 为常数, X， Y 为随机变量</p>
<blockquote>
<ul>
<li>$E(C) = C$</li>
<li>$E(CX) = CE(X)$</li>
<li>$E(X \pm Y) = E(X) \pm E(Y)$</li>
<li>$E(XY) = E(X)E(Y)$ 的充要条件为 <strong>X , Y不相关。</strong> </li>
</ul>
</blockquote>
</li>
<li><p>随机变量X的函数 $Y = g(X)$ 的数学期望：</p>
<blockquote>
<ul>
<li>X 为离散随机变量：<script type="math/tex; mode=display">
P(X=x_k) = p_k; \qquad \sum_{k=1}^{n} g(x_k)p_k 绝对收敛时有：  \\
E(Y) = E(g(X)) = \sum_{k=1}^{n} g(x_k)p_k</script></li>
</ul>
<ul>
<li>X 为连续随机变量：<script type="math/tex; mode=display">
X 概率密度为f(x)； \qquad \int_{-\infty}^{+\infty} g(x)f(x)dx 绝对收敛时有：\\
E(Y) = E(g(X)) = \int_{-\infty}^{+\infty} g(x)f(x)dx</script></li>
</ul>
</blockquote>
</li>
<li><p>随机变量 (X, Y) 的函数 $Z = g(X, Y)$ 的数学期望：</p>
<blockquote>
<ul>
<li><p>(X, Y) 为离散随机变量：</p>
<script type="math/tex; mode=display">
P\{X=x_i, Y=y_j\} = p_{ij}; \quad  \sum_{i=1}^n \sum_{i=1}^m g(x_i, y_j)p_{ij} 绝对收敛有： \\
E(Z) = E[g(X,Y)] = \sum_{i=1}^n \sum_{i=1}^m g(x_i, y_j)p_{ij}</script></li>
<li><p>(X,Y) 为连续随机变量：</p>
<script type="math/tex; mode=display">
概率密度：f(x,y); \quad \\
E(Z) = E[g(X,Y)] = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x,y)f(x,y)dxdy</script></li>
</ul>
</blockquote>
</li>
</ul>
<h3><span id="2-方差">2. 方差</span></h3><script type="math/tex; mode=display">
D(X) = E(X^2) - [E(X)]^2</script><ul>
<li>$D(C) = 0$， 但不能从反推出 C 为常数</li>
<li>$D(aX+b) = a^2D(X)$</li>
<li>$D(X \pm Y) = D(X) + D(Y)$  的充要条件是 X 与 Y 不相关。</li>
<li>$D(-X) = D(X)$</li>
</ul>
<h3><span id="3-常见分布期望与方差-todo">3. 常见分布期望与方差 — TODO</span></h3><p><a href="https://blog.csdn.net/Ga4ra/article/details/78935537">https://blog.csdn.net/Ga4ra/article/details/78935537</a></p>
<ul>
<li><p>0-1 分布：</p>
<script type="math/tex; mode=display">
p(X=k) = p^k(1-p)^{1-k}; k = 0, 1\\
E(X) = p; \\ 
D(X) = p(1-p)</script></li>
<li><p>二项分布：$X \sim B(n,p)  $</p>
<script type="math/tex; mode=display">
p(X=k) = C_n^kp^k(1-p)^{n-k} \\
E(X) = np \\
D(X) = np(1-p)</script></li>
<li></li>
</ul>
<h3><span id="4-协方差">4. 协方差</span></h3><ul>
<li><p>定义： 对于随机变量X ,Y ， 如果 $E{[X - E(x)][Y - E(Y)]}$存在，则称之为 X 和 Y 的协方差：</p>
<script type="math/tex; mode=display">
cov(X,Y) = E\{[X - E(x)][Y - E(Y)]\} = E(XY) - E(X)E(Y)</script></li>
<li><p>性质：</p>
<script type="math/tex; mode=display">
cov(X,Y) = E(XY) - E(X)E(Y) \\
D(X \pm Y) = D(X) + D(Y) \pm 2 cov(X,Y) \\
cov(X,Y) = cov(Y, X)\\
cov(aX, bY) = abcov(X, Y); a,b 为常数 \\
cov(X_1+X_2, Y) = cov(X_1, Y) + cov(X_2, Y)</script></li>
</ul>
<h3><span id="5-相关系数">5. 相关系数</span></h3><ul>
<li><p>定义： 对于随机变量 X 和 Y， 如果 $D(X)D(Y) \neq 0$， 则称 $\frac{cov(X,Y)}{\sqrt{D(X)} \sqrt{D(Y)}}$ 为 X 与 Y 的相关系数。</p>
<script type="math/tex; mode=display">
\rho_{XY} = \frac{cov(X,Y)}{\sqrt{D(X)} \sqrt{D(Y)}}</script></li>
<li><p>性质：</p>
<script type="math/tex; mode=display">
|\rho_{XY}| \leq 1 \\
|\rho_{XY}| = 1 的充要条件为存在不全为0的常数 a，b, 使得：\\
P(aX+bY =1) = 1</script></li>
</ul>
<h3><span id="6-独立与不相关">6. 独立与不相关</span></h3><ul>
<li><p>不相关： 如果随机变量 X 与 Y 的相关系数 $\rho_{XY} = 0$， 则称 X 与 Y 不相关。</p>
</li>
<li><p>相互独立一定不相关，不相关不一定相互独立。</p>
</li>
<li>对于二维正态随机变量(X,Y), X 和 Y相互独立的充要条件为 $\rho = 0$</li>
<li>对于二维正态随机变量(X,Y)， X,Y相互独立与不相关等价。</li>
</ul>
<h2><span id="5-知识点">5. 知识点</span></h2><h3><span id="1-古典概率模型">1. 古典概率模型</span></h3><ul>
<li><p>原理： 在一个样本空间 S 中， 若 S 中<strong>每个样本点发生的可能性相同</strong>，那么事件A 发生的概率 $P(A) = \frac{|T|}{|S|}$。（有限等可能试验）</p>
</li>
<li><p>例子： 一个骰子掷到 1 的概率：</p>
</li>
</ul>
<script type="math/tex; mode=display">
S = \{1, 2, 3 ,4, 5, 6\}, T = {1} \Rightarrow P(\frac{|T|}{|S|}) = \frac{1}{6}</script><h3><span id="2-几何概率">2. 几何概率</span></h3><ul>
<li><p>原理： 在一个几何形状 S 中随机抽取一个点，求该点属于子形状 T 的概率$P(\frac{|T|}{|S|})$。（延伸到几何度量上的有限等可能试验）</p>
</li>
<li><p>例子： 在一个边长为 2 的正方形内抽取一个点， 求该点属于其内切单位圆的概率。</p>
<script type="math/tex; mode=display">
p = \frac{\text{圆的面积}}{\text{正方形面积}} = \frac{\pi}{4}</script></li>
</ul>
<h3><span id="3-数学期望">3. 数学期望</span></h3><ul>
<li><p>原理：一个离散随机变量X的数学期望为 $E(x) = \sum_x xp(x)$</p>
</li>
<li><p>举例：以1/2 的概率取1， 以 1/2 的概率取 0，则此时的期望为$E(x) = 0 \times p(0) + 1 \times p(1) = \frac{1}{2}$</p>
</li>
</ul>
<h3><span id="4-贝叶斯">4. 贝叶斯</span></h3><ul>
<li>条件概率：<script type="math/tex; mode=display">
P(A|B) = \frac{P(AB)}{P(B)} = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^c)P(A^c)}</script></li>
</ul>
<h2><span id="6-贝叶斯定理">6. 贝叶斯定理</span></h2><h3><span id="1-基本概率">1. 基本概率</span></h3><ul>
<li>$P(X=x_i)$ ：边缘概率</li>
<li>$P(X=x_i,Y=y_i)$：联合概率</li>
<li>$P(Y=y_i|X=x_i)$：条件概率</li>
</ul>
<h3><span id="2-两大规则">2. 两大规则</span></h3><ul>
<li><p><strong>加和规则（sum rule）：</strong></p>
<script type="math/tex; mode=display">
p(X=x_i) = \sum_{j=1}^L p(X=x_i,Y=y_j)</script></li>
<li><p><strong>乘积规则（product rule）：</strong></p>
<script type="math/tex; mode=display">
p(X=x_i,Y=y_j) = p(Y=y_j|X=x_i)p(X=x_i)</script></li>
</ul>
<ul>
<li><strong>贝叶斯定理：</strong><script type="math/tex; mode=display">
p(Y|X) = \frac{p(X|Y)p(Y)}{p(X)}</script></li>
</ul>
<h3><span id="3-实例说明">3. 实例说明</span></h3><hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-简单古典概率">1.  简单古典概率</span></h3><p>有n个不同的球，每次抽取1个球：</p>
<ul>
<li>有放回的抽取，抽取 m 个排成一列，求不同排列总数。  $n^m$</li>
<li>无放回的抽取，抽取 m 个排成一列，求不同排列总数。  $P_n^m = \frac{n!}{(n-m)!}$</li>
<li>无放回的抽取，抽取m个忽视次序的组成一组，求不停组合总数。 $C_n^m = \frac{n!}{m!(n-m)!}$</li>
<li>将所有球分为 k 个不同的组，忽视每一组中元素的次序，且每组恰好有 $n<em>1, …n_k$ 个球$(n_1 + …+n_k=n)$ ， 求不同分组结果数。 $C_m^{n_1} C</em>{n-n<em>1}^{n_2} … C</em>{n-n<em>1-…-n</em>{k-1}}^{n_k} = \frac{n!}{n_1!n_2!…n_k!}$</li>
</ul>
<h3><span id="2-纸牌问题">2.  纸牌问题</span></h3><ul>
<li><p>问题：54 张牌，分成 6 份， 每份 9 张牌， 大小王在一起的概率？(阿里一面)</p>
</li>
<li><p>答案：</p>
<blockquote>
<ul>
<li>分母： 总样本空间为将54张牌放入 1-54 的方法总数：<script type="math/tex">54!</script></li>
<li>分子： 大小王属于 1-9 的方法总数为 <script type="math/tex">9 * 8 * 52!</script>， 因此大小王在一起的方法总数为 <script type="math/tex">6 * 9 * 8 * 52!</script></li>
<li>概率为： <script type="math/tex">\frac{6 * 9 * 8 52!}{54!} = \frac{8}{53}</script></li>
</ul>
</blockquote>
</li>
</ul>
<h3><span id="3-棍子问题">3.  棍子问题</span></h3><ul>
<li><p>问题：一根棍子折三段能组成三角形的概率？</p>
</li>
<li><p>解答：</p>
<blockquote>
<ul>
<li><p>假设：棍子长度为1，第一段长度为$x$， 第二段长度为 $y$， 第三段长度 $1-x-y$</p>
</li>
<li><p>分母：总样本空间为： 1 * 1 = 1</p>
</li>
<li><p>分子：两边之和大于第三边</p>
<script type="math/tex; mode=display">1 > x > 0</script><script type="math/tex; mode=display">1 > y > 0</script><script type="math/tex; mode=display">1 - x -y > 0;</script><script type="math/tex; mode=display">x+y > 1 - x - y;</script><script type="math/tex; mode=display">1-x-y+y > x;</script><script type="math/tex; mode=display">1-x-y + x > y</script></li>
</ul>
</blockquote>
</li>
</ul>
<p>化简画图最终得到子空间面积为 $\frac{1}{8}$</p>
<h3><span id="4-采样问题">4.  采样问题</span></h3><ul>
<li>问题：从 1，2，…， n 中有放回的均匀采样 m次，问出现过的不同数字的个数 x 的期望为多少？</li>
</ul>
<p>出现的不同数字的个数 X 可以表示为 $X_1 + … + X_n$ ， 其中 $X_i$ 表示 i 是否出现，如果出现， 为1，否则为 0</p>
<script type="math/tex; mode=display">
E(X_i) = P(X_i = 1) = P(i 在 m 次采样中出现过)</script><p>i 没有在 m 次采样中出现过的概率为： $(\frac{n-1}{n})^m$ ，那么，有：</p>
<script type="math/tex; mode=display">
E(X_i) = 1 - (\frac{n-1}{n})^m</script><p>那么期望可加：</p>
<script type="math/tex; mode=display">
E(X) = E(X_1) + ... + E(X_n) = n[1 - (\frac{n-1}{n})^m]</script><h3><span id="5-贝叶斯">5.  贝叶斯</span></h3><ul>
<li>问题：某城市发生一起汽车撞人逃跑事件，该城市只有两种颜色的车，蓝20%绿80%， 事发时现场只有一个目击者，他指正是蓝车，但根据专家分析，当时那种条件下能看正确的可能性是80%，那么肇事的车是蓝车的概率是多少？</li>
</ul>
<p>假设事件 A 为目击者指正蓝车， 事件B为肇事车为蓝车，事件C为肇事车为绿车，那么有：</p>
<script type="math/tex; mode=display">
P(B|A) = \frac{P(B) * P(A|B)}{P(B) * P (A|B) + P(C) * P(A|C)} = \frac{0.2 * 0.8}{0.2 * 0.8 + 0.8 * 0.2} = 0.5</script><h3><span id="6-假期期望">6. 假期期望</span></h3><ul>
<li>问题：某公司有这么一个规定： 只要有1个员工过生日，当天所有员工全部放假一天。但在其余时候，所有员工都没有假期，必须正常上班。这个公司需要雇佣多少员工，才能让公司一年内所有员工的总工作期望值最大？</li>
</ul>
<p>假设有 n 名员工， X表示不放假的天数，则总工作时间为 nX； 假设第 i 天不放假则 $X_i = 1$， 第 i 天放假则 $X_i = 0 $， 那么则有：</p>
<script type="math/tex; mode=display">
X = X_1 + ... + X_{365}  \\
E(X_i) = P(第i天不放假) = P(每个员工都不过生日) = (\frac{364}{365})^n \\
E(nX) = 365n(\frac{364}{365})^n</script><p>$n &lt;= 364$ 时关于 n 增加， $n &gt; 364$ 时，关于n减少。</p>
<h3><span id="7-下雨概率">7. 下雨概率</span></h3><ul>
<li>问题：你有三位好友，他们都在西雅图工作，西雅图是出了名的爱下雨，每天下雨的概率高达 2/3。 假设你的好心能够以 1/3 的概率正确判断是否在下雨。 加入他们中恰好有两位告诉你今天西雅图在下雨，问实际上下雨的概率是多少？</li>
</ul>
<script type="math/tex; mode=display">
P(A说下雨，B,C说不下雨 | 下雨) = P(A 不看错，B,C看错) = \frac{1}{3} \frac{2}{3} \frac{2}{3} \\
P(A说下雨，B,C说不下雨 | 不下雨) = P（A 看错，B，C没看错) = \frac{2}{3} \frac{1}{3} \frac{1}{3}  \\
P(下雨) = \frac{2}{3}</script><h3><span id="8-见面概率">8. 见面概率</span></h3><h3><span id="9-为何推荐使用高斯分布">9. 为何推荐使用高斯分布？</span></h3><p>当我们由于缺乏关于某个实数上分布的先验知识而不知道该选择怎样的形式时，正态分布是默认的比较好的选择，其中有两个原因：</p>
<ol>
<li><p>我们想要建模的很多分布的真实情况是比较接近正态分布的。</p>
<p><strong>中心极限定理</strong>说明很多独立随机变量的和近似服从正态分布。这意味着在实际中，很多复杂系统都可以被成功地建模成正态分布的噪声，即使系统可以被分解成一些更结构化的部分。</p>
</li>
<li><p>第二，在具有相同方差的所有可能的概率分布中，正态分布在实数上具有最大的不确定性。因此，我们可以认为正态分布是对模型加入的先验知识量最少的分布。</p>
</li>
</ol>
<h3><span id="10-玫瑰花">10. 玫瑰花</span></h3><ul>
<li>问题：一个活动,n个女生手里拿着长短不一的玫瑰花,无序的排成一排,一个男生从头走到尾,试图拿更长的玫瑰花,一旦拿了一朵就不能再拿其他的,错过了就不能回头,问最好的策略及其概率?</li>
</ul>
<h3><span id="11-切比雪夫不等式">11. 切比雪夫不等式</span></h3><script type="math/tex; mode=display">
P(|X- \mu| \geq k\sigma) \leq \frac{1}{k^2} \quad k > 0 , \mu 为期望， \sigma 为标准差</script><p>切比雪夫不等式 描述了这样一个事实，事件大多会集中在平均值附近。</p>
<h3><span id="12-0~1均匀分布的随机器如何变化成均值为0方差为1的随机器">12. 0~1均匀分布的随机器如何变化成均值为0，方差为1的随机器</span></h3><p>[0, 1] 均匀分布的随机器的均值为 1/2， 方差为 1/12.， 那么变换为： $\sqrt{12(x-1/2)}$</p>
<h3><span id="13-红蓝球">13. 红蓝球</span></h3><ul>
<li>问题：抽蓝球红球，蓝结束红放回继续，平均结束游戏抽取次数</li>
</ul>
<p>设抽到 蓝球 的概率为 $p$ ， 设抽到红球的概率为 $q$， 那么抽取到的次数为：</p>
<script type="math/tex; mode=display">
1 * p + 2 * p * q + ... + n * p * q^{n-1}; \quad n 为无穷大</script><p>那么就有：</p>
<script type="math/tex; mode=display">
E = p[1 + 2*q + ... +n *q^{n-1} ]</script><p>我们令：</p>
<script type="math/tex; mode=display">
S = 1 + 2*q + ... +n *q^{n-1}</script><p>那么有：</p>
<script type="math/tex; mode=display">
\begin{align}
S - qS &= (1 + 2q + ... + nq^{n-1}) - (q + 2q^2 + ... + nq^n) \\
&= 1 + q + q^2 + ... q^{n-1} - nq^n \\
&= \frac{1 - q^n}{1-q} - nq^n
\end{align}</script><p>那么我们就可以得到：</p>
<script type="math/tex; mode=display">
\begin{align}
E = pS = (1-q) \frac{[\frac{1 - q^n}{1-q} - nq^n]}{1-q}  = \frac{1 - q^n}{1-q} - nq^n
\end{align}</script><p>当 n 趋向于无穷大时次数等于：</p>
<script type="math/tex; mode=display">
E = \frac{1 - 0}{1-q} = \frac{1}{1-q} = \frac{1}{p}</script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>基础数学知识</tag>
      </tags>
  </entry>
  <entry>
    <title>心情篇</title>
    <url>/posts/%E6%97%A5%E8%AE%B0/%E5%BF%83%E6%83%85%E7%AF%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>心情篇集合，心情好了和心情不好了，都来这里逛一逛，看看当时为啥心情不好，回头看看，哪些事情还值不值得。<br><span id="more"></span></p>
<h2><span id="急躁">急躁</span></h2><p>急躁的心情会让心跳加快，呼吸加快，急躁更使人心情不好，对身体不好。</p>
<p>小时候，我就是个急躁的人，遇到不会的题，会急到哭；</p>
<p>急躁的急，着急、急速，有好有坏，对事比较着急，说明能放在心上，积极应对，凡事都能有个交代；但操之过急，往往不能成功，随后又会心情低落，对自己失望过及；</p>
<p>急躁的躁，就不是什么好词了，躁动、烦躁，字典给的解释是：“性急；不冷静。”。 不冷静就会欠思考，就容易冲动，容易犯错事，说错话。</p>
<p>想要改掉急躁的毛病，就要学会心静，让心情平静下来，拿起笔，一笔一划地写上一页“静”字，心情自然而然就会静下来了。</p>
<h2><span id="生气">生气</span></h2><p>自古以来，生气惹出来的祸更不少了，什么“冲冠一怒为红颜”啊</p>
<p>其实本身“气”这个字，本身有“人的精神状态”的含义，比如形容一个人气色足，有精气神。</p>
<iframe height="498" width="510" src="./qingjian.mp4"></iframe>]]></content>
  </entry>
  <entry>
    <title>AI换脸</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/AI%E6%8D%A2%E8%84%B8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="ai换脸">AI换脸</span></h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650785496&amp;idx=3&amp;sn=b6a4c9478e6eb751b976d768d9ae30dd&amp;chksm=871a02a6b06d8bb0dc3f008f3ded2c9698980dcd5a80ee5e14294ddeeeaa7a24541f0e07ebf6&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650785496&amp;idx=3&amp;sn=b6a4c9478e6eb751b976d768d9ae30dd&amp;chksm=871a02a6b06d8bb0dc3f008f3ded2c9698980dcd5a80ee5e14294ddeeeaa7a24541f0e07ebf6&amp;scene=21#wechat_redirect</a></p>
<p><a href="https://github.com/alievk/avatarify">https://github.com/alievk/avatarify</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/34042498">https://zhuanlan.zhihu.com/p/34042498</a></p>
<p><a href="https://github.com/aerophile/awesome-deepfakes">https://github.com/aerophile/awesome-deepfakes</a></p>
<p><a href="https://arxiv.org/pdf/1909.11573.pdf">https://arxiv.org/pdf/1909.11573.pdf</a></p>
<p><a href="https://towardsdatascience.com/realistic-deepfakes-colab-e13ef7b2bba7">https://towardsdatascience.com/realistic-deepfakes-colab-e13ef7b2bba7</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/36414465">https://zhuanlan.zhihu.com/p/36414465</a></p>
<p><a href="https://arxiv.org/pdf/2005.05535.pdf">https://arxiv.org/pdf/2005.05535.pdf</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP大纲</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/NLP%20%E5%A4%A7%E7%BA%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<!-- tocstop -->
<span id="more"></span>
<p><strong>NLP</strong> <strong>大纲</strong></p>
<p>词向量，语言模型，预训练语言模型：NNLM， word2vec， （Glove， Fasttext） ，预训练语言模型深入：ELMO，GPT，GPT1，GPT2，ERINE，ERINE2.0，albert，Robert， xlnet 等变种。</p>
<p>Attention机制 - transorformer：Attention 机制深入： 各种花式Attention</p>
<p>Transformer， transformer vs lstm vs cnn</p>
<p>文本分类：Fattext， TextCNN，TextRNN， HAN， TextRCNN，TextGCN</p>
<p>预训练语言模型入门：BERT， BERT 用于文本分类</p>
<p>文本匹配：BERT用于文本匹配， 孪生网络（Siamese），ESIM， sentence-bert， <a href="https://zhuanlan.zhihu.com/p/87384188">https://zhuanlan.zhihu.com/p/87384188</a></p>
<p>序列标注：BERT用于序列标注， bi-lstm + crf， BERT+crf， Bert+bi-lstm+crf</p>
<p>中英文分词技术演变：BPE, wordpiece，ULM，sentencepiece</p>
<p>自然语言推理：</p>
<p>阅读理解：BiDAF，BERT，以及各种骚操作。</p>
<p>关键词提取： 从 tfidf 开始到SIFRank等</p>
<p>模型压缩与预训练模型压缩：知识蒸馏，DistillBert，tinybert等</p>
<p>预训练模型可解释性：</p>
<p>关系抽取：</p>
<p>机器翻译：从 seq2seq 到 …</p>
<p>任务型对话：</p>
<p>开放域对话：</p>
<p>自然语言生成： 从seq2seq到BART</p>
<p>文本摘要：</p>
<p>文本纠错：</p>
<p>认知图谱构建：GIANT, 阿里巴巴认知图谱</p>
<p>多模态预训练：VideoBERT到最新的ERNIE-ViL</p>
<p>多模态融合：</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
      </tags>
  </entry>
  <entry>
    <title>idea</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E4%B8%80%E4%BA%9Bidea/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="一些idea">一些idea</span></h1><ul>
<li><p>transformer 如何更好的表示图， 解决大规模图神经网络的计算，存储复杂度高</p>
</li>
<li><p>验证bert 做图谱推理时， 其他实体对target 的att 比重</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
      </tags>
  </entry>
  <entry>
    <title>深度合成技术</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E6%B7%B1%E5%BA%A6%E5%90%88%E6%88%90%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="深度合成技术">深度合成技术</span></h1><p><a href="https://book.yunzhan365.com/owjnh/zfjo/mobile/index.html">https://book.yunzhan365.com/owjnh/zfjo/mobile/index.html</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
      </tags>
  </entry>
  <entry>
    <title>算法工程师修炼之道</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#算法工程师-修炼之道">算法工程师 修炼之道</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="算法工程师-修炼之道">算法工程师 修炼之道</span></h1><ol>
<li><p>不要执着于使用最新技术。 不执着于使用最新技术，不代表不关注最新技术。</p>
</li>
<li><p>技术不是职业生涯的全部，尤其是对于做商业产品的算法工程师。</p>
<ul>
<li>用金钱代替技术。</li>
<li>用沟通代替技术。对于算法工程师，如果沟通不充分就直接开工</li>
<li>用管理代替技术。这是区别高阶工程师和普通工程师的重要能力。</li>
<li>好的技术管理人员应该让大家先做价值高的，用眼光替代技术。充分了解现有技术优缺点，知道什么地方应该投入新技术，什么地方应该采用旧技术，什么地方甚至不需要技术。</li>
</ul>
</li>
<li><p>不要只关注自己领域的技术</p>
<p>作为算法工程师，多学习下周边技术，不要仅仅只会调参，看论文。周边技术是指能为你快速实现验证和部署的技术，并非所有技术都要学习。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
      </tags>
  </entry>
  <entry>
    <title>优秀算法博客</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/10-%E8%80%81%E5%AE%8B%E6%B8%A3%E6%B8%A3%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/%E4%B8%80%E4%BA%9B%E4%BC%98%E7%A7%80%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#预训练语言模型">预训练语言模型</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="预训练语言模型">预训练语言模型</span></h2><p>张俊林： <a href="https://zhuanlan.zhihu.com/p/70257427">XLNet:运行机制及和Bert的异同比较</a></p>
<p>张俊林： <a href="https://zhuanlan.zhihu.com/p/54743941">https://zhuanlan.zhihu.com/p/54743941</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>老宋渣渣算法面经</tag>
      </tags>
  </entry>
  <entry>
    <title>提前批NLP面经</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/10-%E8%80%81%E5%AE%8B%E6%B8%A3%E6%B8%A3%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/%E6%8F%90%E5%89%8D%E6%89%B9%20NLP%20%E5%87%89%E7%BB%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#oppo-提前批">OPPO 提前批</a><ul>
<li><a href="#一面">一面</a></li>
<li><a href="#二面-总监部长面">二面 - 总监/部长面</a></li>
<li><a href="#为啥凉-自我分析安慰一波">为啥凉 - 自我分析(安慰)一波</a></li>
</ul>
</li>
<li><a href="#今日头条凉经">今日头条凉经</a><ul>
<li><a href="#1-一面">1. 一面</a></li>
<li><a href="#2-原因分析">2. 原因分析</a></li>
</ul>
</li>
<li><a href="#提前批-阿里大文娱">提前批 - 阿里大文娱</a><ul>
<li><a href="#1-一面">1. 一面</a></li>
<li><a href="#2-二面">2. 二面</a></li>
<li><a href="#自我分析">自我分析</a></li>
</ul>
</li>
<li><a href="#学霸批-拼多多">学霸批 - 拼多多</a><ul>
<li><a href="#1-一面-hr">1. 一面 - hr</a></li>
<li><a href="#2-二面-1">2. 二面</a></li>
<li><a href="#三面">三面</a></li>
<li><a href="#自我分析-1">自我分析</a></li>
</ul>
</li>
<li><a href="#网易-提前批">网易- 提前批</a><ul>
<li><a href="#1-一面-1">1. 一面</a></li>
<li><a href="#二面">二面</a></li>
<li><a href="#总监面">总监面</a></li>
<li><a href="#hr面-15分钟">HR面 - 15分钟</a></li>
</ul>
</li>
<li><a href="#360-垃圾">360 - 垃圾</a><ul>
<li><a href="#一面-10分钟">一面 - 10分钟</a></li>
<li><a href="#二面-10分钟">二面 - 10分钟</a></li>
</ul>
</li>
<li><a href="#小米">小米</a><ul>
<li><a href="#一面-1">一面</a></li>
<li><a href="#二面-1">二面</a></li>
</ul>
</li>
<li><a href="#搜狗">搜狗</a><ul>
<li><a href="#1-一面-2">1. 一面</a></li>
<li><a href="#2-二面-2">2. 二面</a></li>
</ul>
</li>
<li><a href="#猿辅导">猿辅导</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="oppo-提前批">OPPO 提前批</span></h2><h3><span id="一面">一面</span></h3><p>等了将近4个小时，Oppo的效率有点差呀。</p>
<ul>
<li>项目</li>
<li>Transformer 结构， 大致说一下</li>
<li>懂 ELMO 吗？ 谈谈 ELMO 的结构</li>
<li>数据处理的一些手段</li>
<li><strong>BertTextClassification</strong> 都做了啥</li>
<li>语言模型懂得多么？ 简单谈谈</li>
<li>Word2Vec 的 Nagative sample </li>
<li>Bert 没有很深入，简单谈谈</li>
<li>你一般怎么找论文（然后我就说我看论文蛮快的）</li>
<li>一道编程题： [743, 74  2, 54], 组成最大的数为 74743542</li>
<li>你有什么想问我的吗？</li>
</ul>
<h3><span id="二面-总监部长面">二面 - 总监/部长面</span></h3><p>面我的年纪应该不小了，应该是不太懂技术的，感觉不太看得起深度学习。</p>
<ul>
<li>评价一下你的一面面试官（我说，面试官好像没有跟进最新paper，其实可以聊一下， 不过面试官真的很nice）</li>
<li>你的一面面试官是做翻译的，我看你好像偏向搜索，所以谈谈你想做啥？（我就说我想做搜索方面的）</li>
<li>简单聊了一下Github项目，和阅读理解。</li>
<li>你有什么想问我的吗？ 然后我问了俩问题。</li>
</ul>
<p>然后， 凉凉。</p>
<h3><span id="为啥凉-自我分析安慰一波">为啥凉 - 自我分析(安慰)一波</span></h3><ul>
<li>岗位少： 我投的方向只招收5个人，还是机器翻译 + 对话两个方向总共招这么点人。 说实话，感觉 Oppo对NLP并不看重， 对比 CV 就能看的出来。</li>
<li>竞争激烈，神仙打架</li>
</ul>
<h2><span id="今日头条凉经">今日头条凉经</span></h2><h3><span id="1-一面">1.  一面</span></h3><ul>
<li><p>先自我介绍一下，主要说自己的研究方向（阅读理解，balabala）</p>
</li>
<li><p>深挖了一下 Bert 的细节（包括预训练过程细节，损失函数与自己使用的一些经验，在阅读理解与分类问题上)</p>
</li>
<li><p>语言模型相关： AR , AE 模型（我自己扩展的，面试官没打断）</p>
</li>
<li><p>我们来一道有意思的概率题（瞬间心里咯噔一下，概率论早就还给老师了，答的并不好，难受）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一个地区的某个疾病的患病率为 0.01， 一个模型能够预测患病与否，错误率为 0.01， 现在，我已经被检测出来患病了， 求我真正患病的概率。</span><br></pre></td></tr></table></figure>
<p>假设真正患病为事件A， 预测为患病为事件B， 那么我们要求：</p>
<script type="math/tex; mode=display">
P(A|B) = \frac{P(AB)}{P(B)} = \frac{P(B|A) * P(A)}{P(B)} = ?  \qquad \text{俺就答到这，不会算了}</script></li>
<li><p>我们来一道有意思的编程题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">将驼峰命名方式为 abcdAutoDecoder， abcHTTPDecoder 改为下划线命名为 abcd_auto_decoder, abc_http_decoder</span><br></pre></td></tr></table></figure>
<p>一道贪心的题， 比较简单。</p>
</li>
<li><p>又问了一些 Pytorch 的内容，我觉得主要看我对 Pytorch 熟不熟悉</p>
</li>
<li><p>你可以问我一些问题， 然后我就问了俩问题， 就道谢离开。</p>
</li>
</ul>
<h3><span id="2-原因分析">2. 原因分析</span></h3><p>概率论那道题没有答上来，算法写的不是很好，虽然答出来了，但因为题很简单，边界处理的不干净。</p>
<h2><span id="提前批-阿里大文娱">提前批 - 阿里大文娱</span></h2><h3><span id="1-一面">1. 一面</span></h3><ul>
<li>简单介绍一下自己</li>
<li>项目从头到尾问了问</li>
<li>目前主要做什么？</li>
<li>Bert</li>
<li>Transformer</li>
<li>一道概率题，54张牌，分为三份，每份18张，求大小王在一起的概率</li>
<li>写了一道快排</li>
</ul>
<h3><span id="2-二面">2. 二面</span></h3><ul>
<li>介绍一下自己</li>
<li>项目谈了谈</li>
<li>做过 文本聚类 方面的工作吗</li>
<li>会C++吗</li>
<li>会其余一些任务吗，如命名实体识别</li>
<li>来一到编程题。 <strong>给一句话，求里面长度最长的单词</strong>。（写的很快，但有小bug，面试官很不满意）</li>
</ul>
<h3><span id="自我分析">自我分析</span></h3><p>凉的原因在于： </p>
<ul>
<li>c++ ， 很多靠这个卡人的</li>
<li>编程题边界没处理干净</li>
</ul>
<h2><span id="学霸批-拼多多">学霸批 - 拼多多</span></h2><h3><span id="1-一面-hr">1. 一面 - hr</span></h3><ul>
<li>加班能接受吗？ 11， 11， 6</li>
<li>父母都是做什么的？</li>
<li>手里的offer 情况，没有去试试头条吗？</li>
<li>如果手里有百度和拼多多的offer， 你选哪个？</li>
<li>你有什么想问我的吗？</li>
</ul>
<h3><span id="2-二面">2. 二面</span></h3><ul>
<li>聊一聊项目和Bert </li>
<li>一道概率题（忘记是啥了）</li>
<li>一道编程题： 长度为 n-1 的数组中，数字全部都是 1-n 的数，找出那个没有出现的数（当时智障了，居然答的乱七八糟）</li>
</ul>
<h3><span id="三面">三面</span></h3><ul>
<li>Word2Vec  的Skip-Gram模型</li>
<li>多头注意力机制</li>
<li>两道编程题：<ul>
<li>求一棵二叉树的深度</li>
<li>给定一个二维数组， 数组中全是 0 和 1， 求孤岛中所有为 1 的坐标（当时没有现在强，没做出来，面试官急着吃饭）</li>
</ul>
</li>
</ul>
<h3><span id="自我分析">自我分析</span></h3><p>我个人觉得还是编程题部分没有答好，因为题蛮简单的，答成这样的确有挂的风险。 此外，我看到接到offer 的人，很多手上都握着bat，头条至少一家的offer， 感觉十月份会有很多拒的人。</p>
<h2><span id="网易-提前批">网易- 提前批</span></h2><h3><span id="1-一面">1. 一面</span></h3><ul>
<li>自我介绍， 这部分感觉最重要</li>
<li>编程题：编辑距离</li>
<li>编程题：一道链表medium，忘了</li>
<li>聊了 linux命令， git命令， 正则</li>
<li>BERT 简单聊了聊</li>
</ul>
<h3><span id="二面">二面</span></h3><ul>
<li>自我介绍，聊项目</li>
<li>聊语言模型， Bert， XLNet等，我吹了一波</li>
<li>然后聊了聊linux， 给正则匹配</li>
</ul>
<h3><span id="总监面">总监面</span></h3><ul>
<li>自我介绍</li>
<li>总监说，技术方面我不问，我们谈谈落地， 博客写的不错（这个应该加分很大）</li>
<li>我们有道目前布局 AI 教育方面，你是做阅读理解的，你觉得阅读理解能用在我们哪些产品上？ 就这个问题，一直深挖，谈了将近50分钟。</li>
</ul>
<h3><span id="hr面-15分钟">HR面 - 15分钟</span></h3><p>面试官本来以为是现场面，hr这边通知我是 视频面，因此前面很多时间都浪费了，所以只面了15分钟。</p>
<p>我态度很好，面试官觉得很加分。</p>
<ul>
<li>自我介绍一下</li>
<li>你选择工作主要看哪些方面：我说先看团队，再看方向，然后看地点， 工资什么的对我不重要。 最后舔了一波： 如果网易这边要我的话，我就结束秋招了， 面试官听了很开心</li>
<li>你觉得你在别人眼中是什么样子： 我就说我算是技术比较强的一波人，大家有问题都会向我寻求帮助，获得“大神”称号</li>
<li>你觉得你是一个怎么样的人？ 我是一个很开朗的人，很喜欢分享，您看我的博客就知道了，在团队中往往起到一个活跃气氛的作用。</li>
<li>你有什么问题想问我的吗？</li>
</ul>
<h2><span id="360-垃圾">360 - 垃圾</span></h2><p>估计我投的岗不招人</p>
<h3><span id="一面-10分钟">一面 - 10分钟</span></h3><p>聊了聊项目，谈了谈我的几个仓库都在做啥，就过了。  excuse me？？？</p>
<h3><span id="二面-10分钟">二面 - 10分钟</span></h3><p>项目简单说一下，说了一下他们这边在做什么， 然后问你有没有什么问题， 就凉了。 （没有问技术） excuse me？ 不招人就直说， 浪费我时间。</p>
<h2><span id="小米">小米</span></h2><h3><span id="一面">一面</span></h3><ul>
<li>自我介绍</li>
<li>聊项目</li>
<li>聊 Transformer， 包括各个细节， 功能，并用 pytorch 写了一下多头</li>
<li>Layer Normalization 原理，用 pytorch 写一下</li>
<li>一道编程题： 编辑距离</li>
</ul>
<h3><span id="二面">二面</span></h3><p>面试官情商不高，态度优点居高临下， 让我很不舒服。</p>
<ul>
<li>softmax 公式， 会溢出吗？ 怎么解决溢出？ </li>
<li>Word2Vec 的多层softmax 是怎么实现的，思路是怎样的，损失函数变化</li>
<li>阅读理解应用？ 做过问答系统吗？</li>
<li>机器翻译了解吗？</li>
<li>你的博客对我来说一点用都没，我写的一定比你好… </li>
</ul>
<p>技术问题就完了，直言我做的不够深。 然后问我，你有什么想问的吗？</p>
<p>我个人觉得这是很恶心的一点， 因为我是做阅读理解的，你又没问，怎么知道我做的不深？ 还说我数据结构不扎实， 我编辑距离都写出来了，就因为 word2vec 的多层softmax 没有联想到哈夫曼树，就说我不深？</p>
<ul>
<li>反问： 您觉得我有哪些方面不足？ 面试官说了一堆，什么这个不行，那个不行</li>
<li>反问：  在阅读理解领域，您觉得什么叫深？ 面试官说，我不是做这个的，我不知道， excuse me？</li>
</ul>
<h2><span id="搜狗">搜狗</span></h2><h3><span id="1-一面">1. 一面</span></h3><ul>
<li>自我介绍，项目</li>
<li>现在还在搜狗实习吗？</li>
<li>一道概率题： 对于一个超长文本，等概率的从该文本中抽取 m 行</li>
<li>一道编程题： 编辑距离</li>
</ul>
<h3><span id="2-二面">2. 二面</span></h3><ul>
<li>自我介绍</li>
<li>聊 Bert 细节</li>
<li>聊 Transformer 细节，用 pytorch 写了下多头和 layernormlization</li>
<li>编程题：判定二叉树为对称二叉树，很简单</li>
<li>会c++吗？</li>
</ul>
<p>如果挂了，必然是挂在 c++ 上了， 等通知。</p>
<h2><span id="猿辅导">猿辅导</span></h2><p>做题就对了， 一面一道medium， 一道hard。 二面一道hard</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>老宋渣渣算法面经</tag>
      </tags>
  </entry>
  <entry>
    <title>整理简历中的点</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/10-%E8%80%81%E5%AE%8B%E6%B8%A3%E6%B8%A3%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E7%AE%80%E5%8E%86%E4%B8%AD%E7%9A%84%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#整理一下简历中的点">整理一下简历中的点</a><ul>
<li><a href="#模型篇">模型篇</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="整理一下简历中的点">整理一下简历中的点</span></h1><hr>
<h2><span id="模型篇">模型篇</span></h2><ul>
<li>预训练语言模型：GPT GPT2.0 BERT ERNIE ERNIE MASS UNILM</li>
<li>词向量：Skip-Gram CBOW Cove ELMO</li>
<li>文本分类：TextCNN TextRCNN HAN DPCNN </li>
<li>SQUAD 阅读理解： BiDAF， QANet， R-net， AOA等</li>
<li>RACE 阅读理解：DCMN  OCN</li>
<li>文本相似度匹配：</li>
<li>query-response 匹配</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>老宋渣渣算法面经</tag>
      </tags>
  </entry>
  <entry>
    <title>面试套路</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/10-%E8%80%81%E5%AE%8B%E6%B8%A3%E6%B8%A3%E7%AE%97%E6%B3%95%E9%9D%A2%E7%BB%8F/%E9%9D%A2%E8%AF%95%E5%A5%97%E8%B7%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-自我介绍">1. 自我介绍</a></li>
<li><a href="#2-看了这么多论文有什么idea吗快手第一问">2. 看了这么多论文，有什么idea吗？（快手第一问）</a><ul>
<li><a href="#1-简单idea-文本分类在做ing">1. 简单idea — 文本分类（在做ing）</a></li>
<li><a href="#2-复杂一点的idea-阅读理解">2. 复杂一点的idea — 阅读理解</a></li>
<li><a href="#3-多维向量融合-多种数据集">3. 多维向量融合 — 多种数据集</a></li>
<li><a href="#4-探索-attention-在语义匹配机制中的选择">4. 探索 Attention 在语义匹配机制中的选择</a></li>
<li><a href="#3-关于预训练语言模型-知识图谱-雏形做不了没资源">3. 关于预训练语言模型 + 知识图谱  - 雏形（做不了，没资源）</a></li>
<li><a href="#4-预训练语言模型-自然语言生成-下一个爆点雏形">4. 预训练语言模型 + 自然语言生成 — 下一个爆点（雏形）</a></li>
<li><a href="#5-信息融合-受到-char-word-embdding-启发">5. 信息融合 - 受到 char + word embdding 启发、</a></li>
</ul>
</li>
<li><a href="#3-你有什么想问的吗">3. 你有什么想问的吗</a></li>
<li><a href="#4-hr-的提问">4. HR 的提问</a></li>
<li><a href="#5-部门领导的提问">5. 部门领导的提问</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-自我介绍">1. 自我介绍</span></h2><p>您好，我是北京科技大学的计算机研究生，本科毕业于北京化工大学。 本科期间做过一段时间的Android 和嵌入式。 研究生期间主要研究方向是自然语言处理中的阅读理解。 </p>
<ul>
<li>研一上半学期主要是学习机器学习，深度学习方面的基础， 研一下主要是阅读自然语言方面的论文和确定自己的研究方向，4月中旬决定要做<strong>高考阅读理解</strong>这个方向，开始阅读阅读理解领域的相关论文。后来，考虑到数据方面的因素，暑假去爱奇艺实习了一段时间，主要做爬虫和数据方面的工作。 </li>
<li>研二上学期主要是做阅读理解相关的实验与跟进最新的论文，前期主要探索能不能参考 SQUAD 数据集上的模型对 RACE 数据集上现有的 Attention 机制进行改进。 后来预训练语言模型爆发，直接拉高 benchmark， 因此研二下主要是看看，能不能在 Bert 之上(如 Attention）做一些文章。后来，觉得自己方向做的太窄了， 因此，慢慢扩展到文本分类，文本相似度这些方向。</li>
</ul>
<p>此外，我知乎专栏写的还不错， 可以看看。 我自己也很喜欢跟别人分享知识，我在搜狗实习，每周五都会分享一些最新的论文和技术。</p>
<p>我觉得我现在是处于 <strong>论文量足够大</strong>， <strong>读论文也很快</strong>（差不多3个小时精读一篇），也能很快实现， 看论文也能产生一些idea， 但大多数创新点都不够顶会的级别， 没有资源和时间去做了， 毕竟马上就要毕业了。</p>
<h2><span id="2-看了这么多论文有什么idea吗快手第一问">2. 看了这么多论文，有什么idea吗？（快手第一问）</span></h2><h3><span id="1-简单idea-文本分类在做ing">1. 简单idea — 文本分类（在做ing）</span></h3><ul>
<li>文本长度对 Bert 在文本分类任务上微调的影响</li>
<li>如何将长文本信息融合</li>
<li>探索在 Bert 之上做文本分类的效果， 比如将经典的一些网络融进去，看看有没有提升，并分析对不同的数据集为何会有这种提升。</li>
</ul>
<h3><span id="2-复杂一点的idea-阅读理解">2. 复杂一点的idea — 阅读理解</span></h3><p>RACE 数据集本身其文本长度在 2000 左右，而 Bert 的限制在 512， 因此，如何融入这种长文本信息。 </p>
<ul>
<li>加 x 层 Transformer： 先分别对段落进行 embedding， 然后采用 Transformer 进行信息融合 — 效果有所提升</li>
<li>设计精巧的 Attention 机制： 比如article 与 question 之间的匹配方式等， 目前正在尝试。</li>
</ul>
<h3><span id="3-多维向量融合-多种数据集">3. 多维向量融合 — 多种数据集</span></h3><p>对于高维向量， 预训练语言模型向量的融合， 加一层 cnn， lstm， transformer 向量的融合。</p>
<h3><span id="4-探索-attention-在语义匹配机制中的选择">4. 探索 Attention 在语义匹配机制中的选择</span></h3><h3><span id="3-关于预训练语言模型-知识图谱-雏形做不了没资源">3. 关于预训练语言模型 + 知识图谱  - 雏形（做不了，没资源）</span></h3><p>idea 来源于 百度的 ERNIE 与 清华的 ERNIE ， 这两篇文章采用了不同的方式融合知识图谱信息。 </p>
<ul>
<li>百度的方式能否融入 实体与实体之间的关系？ 如何验证？</li>
<li>如果不能， 那么如何更好的融入 实体与实体之间 的关系。（思路：设计一个类似 NP 的预训练网络，跟语言模型一起训）</li>
</ul>
<p>百度的文章对比清华的文章，虽然创新度有所不足，但更看好百度的方向，毕竟大道至简， 清华的那篇文章着实复杂了些， 太多中间过程可能反而引入了很多噪声。</p>
<h3><span id="4-预训练语言模型-自然语言生成-下一个爆点雏形">4. 预训练语言模型 + 自然语言生成 — 下一个爆点（雏形）</span></h3><p>这点还需要看生成方面的诸多论文。</p>
<h3><span id="5-信息融合-受到-char-word-embdding-启发">5. 信息融合 - 受到 char + word embdding 启发、</span></h3><h2><span id="3-你有什么想问的吗">3. 你有什么想问的吗</span></h2><ul>
<li>请问在贵部门，算法工程师主要负责哪些事情？</li>
<li>您怎么看目前预训练语言模型在NLP中的发展？</li>
<li>您觉得算法工程师的核心技能是什么？</li>
</ul>
<h2><span id="4-hr-的提问">4. HR 的提问</span></h2><ul>
<li>您觉得， 我需要加强哪些方面的知识？</li>
<li>你对我接下来的学习有什么建议吗？</li>
<li>能谈谈对我此次表现的评价吗？</li>
</ul>
<h2><span id="5-部门领导的提问">5. 部门领导的提问</span></h2><ul>
<li>您怎么看到预训练语言模型，它会一统江湖吗？</li>
<li>您觉得，我在刚开始工作1-3年内，如何提升专业技术？</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>老宋渣渣算法面经</tag>
      </tags>
  </entry>
  <entry>
    <title>Bert-Pytorch</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/11-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Bert-pytorch/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="bert-pytorch">Bert-pytorch</span></h1><p><a href="https://zhuanlan.zhihu.com/p/76936436">https://zhuanlan.zhihu.com/p/76936436</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch-Transformer</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/11-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Pytorch-Transformer/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#pytorch-transformer">Pytorch-Transformer</a><ul>
<li><a href="#bert">BERT</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="pytorch-transformer">Pytorch-Transformer</span></h1><hr>
<h2><span id="bert">BERT</span></h2><ul>
<li>配置类： BertConfig</li>
<li>Layer Normalization：BertLayerNorm = torch.nn.LayerNorm</li>
<li>Bert 输入： BertEmbeddings</li>
<li>多头注意力机制/自注意力机制： BertSelfAttention</li>
<li>Bert 一层的输出： BertSelfOutput 依赖于 BertLayerNorm</li>
<li>Bert 一层： BertAttention 依赖于 BertSelfAttention， BertSelfOutput</li>
<li>BertIntermediate ： 无依赖</li>
<li>Bert 最终输出： BertOutput， 依赖于 BertLayerNorm</li>
<li>Bert一层 ： BertLayer 依赖于 BertAttention， BertIntermediate， BertOutput</li>
<li>Bert 的Encoder： BertEncoder， 依赖于 BertLayer</li>
<li>BertPooler： Bert [CLS] 输出</li>
<li>BertPredictionHeadTransform：依赖于 BertLayerNorm</li>
<li>BertLMPredictionHead： 依赖于 BertPredictionHeadTransform</li>
<li>BertOnlyMLMHead： 依赖于 BertLMPredictionHead</li>
<li>BertOnlyNSPHead： </li>
<li>BertPreTrainingHeads： 依赖于 BertLMPredictionHead</li>
<li>BertPreTrainedModel： 继承于 PreTrainedModel</li>
<li>BertModel:  依赖于 BertEmbedding  BertEncoder， BertPooler</li>
<li>BertForPreTraining： 继承于 BertPreTrainedModel， 依赖于 BertModel， BertPreTrainingHeads</li>
<li>BertForMaskedLM： 依赖于 BertModel， BertOnlyMLMHead</li>
<li>BertForNextSentencePrediction： 依赖于 BertModel， BertOnlyNSPHead</li>
</ul>
<hr>
<ul>
<li><p>BertForSequenceClassification： 用于分类</p>
</li>
<li><p>BertForMultipleChoice：用于多选</p>
</li>
<li><p>BertForTokenClassification： 用于命名实体识别</p>
</li>
<li><p>BertForQuestionAnswering： 用于 QA</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>事件知识图谱</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E4%BA%8B%E4%BB%B6%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="事件知识图谱">事件知识图谱</span></h1><h2><span id="refernece">Refernece</span></h2><p>[1] What is Event Knowledge Graph: A Survey</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>关系抽取</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%20-%20%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="知识图谱-关系抽取">知识图谱 - 关系抽取</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>实体识别</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%20-%20%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="知识图谱-实体识别">知识图谱 - 实体识别</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>实体连接</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%20-%20%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="知识图谱-实体链接">知识图谱 - 实体链接</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>知识表示</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%20-%20%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#知识图谱-知识表示">知识图谱 - 知识表示</a><ul>
<li><a href="#1-两大表示形式">1. 两大表示形式</a><ul>
<li><a href="#1-基于符号逻辑的知识表示">1. 基于符号逻辑的知识表示</a></li>
<li><a href="#2-基于向量的知识表示学习">2. 基于向量的知识表示学习</a></li>
</ul>
</li>
<li><a href="#2-知识表示的挑战">2. 知识表示的挑战</a><ul>
<li><a href="#1-复杂关系建模">1. 复杂关系建模</a></li>
<li><a href="#2-多源信息融合">2. 多源信息融合</a></li>
<li><a href="#3-关系路径建模">3. 关系路径建模</a></li>
</ul>
</li>
<li><a href="#2-知识表示学习">2. 知识表示学习</a><ul>
<li><a href="#1-距离模型-se">1. 距离模型 - SE</a></li>
<li><a href="#2-单层神经网络模型-slm">2. 单层神经网络模型 - SLM</a></li>
<li><a href="#3-能量模型-sme">3. 能量模型 - SME</a></li>
<li><a href="#4-隐变量模型-lfm">4. 隐变量模型 - LFM</a></li>
<li><a href="#5-张量神经网络模型-ntn">5. 张量神经网络模型 - NTN</a></li>
<li><a href="#6-矩阵分解模型-resacl-模型">6. 矩阵分解模型 - RESACL 模型</a></li>
<li><a href="#7-翻译模型-transe">7. 翻译模型 - TransE</a></li>
</ul>
</li>
<li><a href="#3-知识表示学习的主要挑战">3. 知识表示学习的主要挑战</a><ul>
<li><a href="#1-复杂关系建模-1">1. 复杂关系建模</a></li>
<li><a href="#2-多源信息融合-1">2. 多源信息融合</a></li>
<li><a href="#3-关系路径建模">3. 关系路径建模</a></li>
</ul>
</li>
<li><a href="#3-发展趋势">3. 发展趋势</a><ul>
<li><a href="#1-符号-向量">1. 符号 + 向量</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="知识图谱-知识表示">知识图谱 - 知识表示</span></h1><hr>
<h2><span id="1-两大表示形式">1. 两大表示形式</span></h2><p>知识表示分为两大类： 基于符号逻辑的知识表示 与 基于向量的知识表示。近年来，知识图谱的知识表示方法已经发生了很大的变化，主要受到以下两个方面的影响：</p>
<ul>
<li><strong>数据规模大。</strong>现代知识图谱往往规模十分大，因此采用以三元组为基础的较为简单实用的知识表示方法，并弱化了对强逻辑表示的要求；</li>
<li><strong>深度学习技术。</strong>由于知识图谱是很多搜索、问答和大数据分析系统的重要数据基础，基于向量的知识图谱表示使得这些数据更加易于与深度学习模型集成，使得基于向量空间的知识图谱表示得到越来越多的重视。</li>
</ul>
<h3><span id="1-基于符号逻辑的知识表示">1. 基于符号逻辑的知识表示</span></h3><ul>
<li><p>优点：基于显性知识表示，因而表示能力强，能处理较为复杂的知识结构，具有可解释性，并支持复杂的推理。</p>
</li>
<li><p>缺点：<strong>计算效率问题</strong>与<strong>数据稀疏问题</strong>。</p>
</li>
</ul>
<h3><span id="2-基于向量的知识表示学习">2. 基于向量的知识表示学习</span></h3><ul>
<li>优点：易于捕获隐性知识， 并易于与深度学习模型集成；显著提升计算效率；有效缓解数据稀疏；实现异质信息融合。</li>
<li>缺点：对复杂知识结构的支持不够，可解释性差， 不能支持复杂推理。</li>
</ul>
<h2><span id="2-知识表示的挑战">2. 知识表示的挑战</span></h2><h3><span id="1-复杂关系建模">1. 复杂关系建模</span></h3><p>知识图谱中关系可划分为： </p>
<ul>
<li>1-1： 1个头实体对应1个尾实体</li>
<li>1-N：1个头实体对应多个尾实体</li>
<li>N-1： 1个尾实体对应多个头实体</li>
<li>N-N：N 个尾实体对应多个头实体</li>
</ul>
<p>其中， 1-N， N-1， N-N 称为复杂关系。</p>
<h3><span id="2-多源信息融合">2. 多源信息融合</span></h3><p>知识图谱中依旧有大量与知识有关的其他信息没有被有效利用：</p>
<ul>
<li>知识图谱中的其他信息， 如实体和关系的描述信息，类别信息等</li>
<li>知识图谱外的海量信息，如互联网文本包含大量与知识库实体和关系有关的信息。</li>
</ul>
<h3><span id="3-关系路径建模">3. 关系路径建模</span></h3><p>知识图谱中，多步的关系路径能够反映实体之间的语义信息。如何突破知识表示学习孤立学习每个三元组的局限性，充分考虑关系路径信息是知识表示学习的关键问题。</p>
<h2><span id="2-知识表示学习">2. 知识表示学习</span></h2><p>知识表示学习是面向知识库中的实体和关系进行表示学习。该技术可以在低维空间中高效计算实体和关系的语义联系，有效解决数据稀疏问题，使知识获取，融合和推理的性能得到显著提升。</p>
<p>在进行详细方法介绍前，我们将知识库表示为：</p>
<script type="math/tex; mode=display">
G = (E,R,S)</script><ul>
<li>$E = { e<em>1, …, e</em>{|E|} }$ ： 表示知识库的实体集合，其中包含 $|E|$ 种不同实体。</li>
<li>$E = { r<em>1,…r</em>{|R|} }$：表示知识库的关系集合，其中包含 $|R|$ 种不同关系。</li>
<li>$S  \subseteq E \times R \times E$ ： 表示知识库中三元组集合</li>
<li>$(h, r, t)$：单一的三元组的表示， $h$ 表示头实体， $t$ 表示尾实体， $r$ 表示 $h$ 与 $r$ 的关系。</li>
</ul>
<p>从表示方法上看，几个代表模型可分为： 距离模型，单层神经网络模型，能量模型，双线性模型，张量神经网络模型，矩阵分解模型和翻译模型等。</p>
<h3><span id="1-距离模型-se">1. 距离模型 - SE</span></h3><p>结构表示(structured embedding，SE)中，每个实体用 $d$ 维向量表示，所有实体在同一个向量空间。并为每个关系 $r$  定义两个矩阵 $M<em>{r,l}, M</em>{r,2} \in R^{d \times d}$，用于三元组中头实体和尾实体的投影操作。</p>
<p>损失函数定义为：</p>
<script type="math/tex; mode=display">
f_r(h,t) = |M_{r,l} l_h - M_{r,2}l_t|_{L_1}</script><p>SE 通过两个矩阵将头实体与尾实体分别投影到关系 $r$ 的对应空间中，然后再该空间中计算两投影向的距离。 该距离表示 2 个实体在关系 $r$ 下的语义相似度，它们的距离越小，说明二者存在关系 $r$。</p>
<p>重要缺陷： 它对头，尾实体使用 2 个不同的矩阵进行投影，协同性较差，往往无法精确刻画两实体与关系之间的语义联系。</p>
<h3><span id="2-单层神经网络模型-slm">2. 单层神经网络模型 - SLM</span></h3><p>单层神经网络模型尝试是采用单层神经网络的非线性操作来减轻 SE 无法协同精确刻画实体与关系的语义联系的问题。</p>
<p>损失函数定义为：</p>
<script type="math/tex; mode=display">
f_r(h,t) = u_r^T g(M_{r,1}l_h + M_{r,2}l_t)</script><ul>
<li>$M<em>{r,1}, M</em>{r,2} \in R^{d \times k}$： 投影矩阵</li>
<li>$g()$： tanh 函数</li>
<li>$u_r^T \in R^k$ ： 关系$r$ 的向量表示</li>
</ul>
<p>SLM 的非线性操作仅提供了实体与关系之间比较微弱的联系，却引入了更高的计算复杂度。</p>
<h3><span id="3-能量模型-sme">3. 能量模型 - SME</span></h3><p>SME 定义了两种损失函数：</p>
<script type="math/tex; mode=display">
f_r(h,t) = (M_1l_h + M_2l_r + b_1)^T(M_3l_t  + M_4l_r + b_2) \\
f_r(h,t) = (M_1l_h \otimes M_2l_r + b_1)^T(M_3l_t \otimes M_4l_r + b_2)</script><ul>
<li>$M_1, M_2, M_3, M_4 \in R^{d \times k}$ ：投影矩阵</li>
<li>$\otimes$： 按位乘</li>
</ul>
<h3><span id="4-隐变量模型-lfm">4. 隐变量模型 - LFM</span></h3><p>LFM 定义损失函数为：</p>
<script type="math/tex; mode=display">
f_r(h,t) = l_h^TM_rl_t</script><ul>
<li>$M_r \in R^{d \times d}$ ： 关系 $r$ 所对应的双线性变换矩阵。</li>
</ul>
<p>LFM 通过基于关系 $r$ 的双线性变换，刻画了实体和关系的语义联系，协同性较好，计算复杂度低。</p>
<p>扩展： DISTMULT 模型</p>
<h3><span id="5-张量神经网络模型-ntn">5. 张量神经网络模型 - NTN</span></h3><p>基本思想： 用双线性张量取代传统神经网络中的线性变换层， 在不同维度下将头，尾实体向量联系起来。</p>
<p>损失函数定义如下：</p>
<script type="math/tex; mode=display">
f_r(h,t) = u_r^Tg(l_hM_rl_t + M_{r,1}l_h + M_{r,2}l_t + b_r)</script><ul>
<li>$u_r^T$： 一个与关系相关的线性层</li>
<li>$g()$： tanh 函数</li>
<li>$M<em>r \in R^{d \times d \times k}$， $M</em>{r,1}, M_{r,2} \in R^{d \times k }$</li>
</ul>
<p>注意： NTN 中的实体向量是该实体中所有单词向量的平均值，这样可以充分利用单词向量构建实体表示，降低实体表示学习的稀疏性，增强不同实体的语义联系。</p>
<p>缺点是由于计算复杂度较高，因此需要更多的三元组数据才能充分学习，实验表明，NTN的确在大规模稀疏知识图谱上效果较差。</p>
<h3><span id="6-矩阵分解模型-resacl-模型">6.  矩阵分解模型 - RESACL 模型</span></h3><h3><span id="7-翻译模型-transe">7. 翻译模型 - TransE</span></h3><p>TransE认为，对于三元组 $(h,r,t)$ ， 应该具有以下的关系：</p>
<script type="math/tex; mode=display">
l_h + l_r \approx l_t</script><p>TransE 模型定义的损失函数为：</p>
<script type="math/tex; mode=display">
f_r(h,t) = |l_h + l_r - l_t|_{L_1/L_2}</script><p>在实际训练中，为了增强知识表示的区分能力，TransE 采用最大间隔方法，定义了如下优化目标函数：</p>
<script type="math/tex; mode=display">
L = \sum_{(h,r,t) \in S} \sum_{(h',r',t') \in S'} max(0, f_r(h,t) + \gamma - f_{r'}(h', t') )</script><ul>
<li>S： 合法三元组的集合</li>
<li>S‘： 错误三元组的集合，TransE 将 S 中每个三元组的头实体，关系，尾实体其中之一随机替换为其他实体或关系来得到 S’</li>
<li>$\gamma$： 合法三元组得分与错误三元组得分之间的间隔距离</li>
</ul>
<p>优点：参数少，计算复杂度低，却能直接建立实体和关系之间的复杂语义联系。</p>
<p>实验表明，TransE 的性能较以往模型有显著提升。特别是在大规模稀疏知识图谱上，TransE 的性能尤其惊人。</p>
<h2><span id="3-知识表示学习的主要挑战">3. 知识表示学习的主要挑战</span></h2><h3><span id="1-复杂关系建模">1. 复杂关系建模</span></h3><h3><span id="2-多源信息融合">2. 多源信息融合</span></h3><h3><span id="3-关系路径建模">3.  关系路径建模</span></h3><h2><span id="3-发展趋势">3. 发展趋势</span></h2><h3><span id="1-符号-向量">1. 符号 + 向量</span></h3><p>一个新的趋势是把符号逻辑与表示学习结合起来研究更加鲁棒、易于捕获隐含知识、易于与深度学习集成、并适应大规模知识图谱应用的新型表示框架。这需要较好的平衡符号逻辑的表示能力和表示学习模型的复杂性。一方面要能处理结构多样性、捕获表达构件的语义和支持较为复杂的推理，另一方面又要求学习模型的复杂性较低。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>知识表示学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%20-%20%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="知识图谱-知识表示学习">知识图谱 - 知识表示学习</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>融合算法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%20--%20%E8%9E%8D%E5%90%88%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="知识图谱-融合算法">知识图谱 — 融合算法</span></h1><h2><span id="reference">Reference</span></h2><p>[1] <a href="https://zhuanlan.zhihu.com/p/105203565">https://zhuanlan.zhihu.com/p/105203565</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱+NLP</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1+nlp/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="知识图谱nlp">知识图谱+nlp</span></h1><h2><span id="reference">Reference</span></h2><p>[1] <a href="https://www.zhihu.com/question/351260481/answers/updated">https://www.zhihu.com/question/351260481/answers/updated</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱值得研究的问题</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%80%BC%E5%BE%97%E7%A0%94%E7%A9%B6%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#知识图谱值得研究的问题">知识图谱值得研究的问题</a><ul>
<li><a href="#工业问题">工业问题</a></li>
<li><a href="#学术问题">学术问题</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="知识图谱值得研究的问题">知识图谱值得研究的问题</span></h1><h2><span id="工业问题">工业问题</span></h2><ul>
<li>如何从非结构化文本中挖掘不同粒度的标签，进而实现行业知识图谱的快速构建</li>
<li>如何构建行业的领域标签，不同粒度的</li>
</ul>
<h2><span id="学术问题">学术问题</span></h2><ul>
<li>比向量化，图卷积更有效的知识表示是否存在</li>
<li>多模态的知识融合如何实现</li>
<li>基于图谱的知识推理</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>只是图片综述</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#知识图谱综述">知识图谱综述</a><ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#2-overview">2. Overview</a><ul>
<li><a href="#21-a-brief-history-of-knowledge-bases">2.1 A Brief History of Knowledge Bases</a></li>
</ul>
</li>
<li><a href="#22-definitions-and-notations">2.2 Definitions and Notations</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="知识图谱综述">知识图谱综述</span></h1><p><a href="https://segmentfault.com/a/1190000016522687">https://segmentfault.com/a/1190000016522687</a></p>
<h2><span id="abstract">Abstract</span></h2><ul>
<li>knowledge graph representation learning：知识表示学习</li>
<li>knowledge acquisition and completion：知识获取与补全</li>
<li><p>temporal knowledge graph：时序知识图谱</p>
</li>
<li><p>knowledge-aware applications：知识图谱应用</p>
</li>
<li>summarize recent breakthroughs and perspective directions to facilitate future research</li>
</ul>
<h2><span id="introduction">Introduction</span></h2><p>知识图谱包含： </p>
<ul>
<li>entities，can be real-world objects and abstract concepts</li>
<li>relationship，represent the relation between entities</li>
<li>semantic descriptions：semantic descriptions of entities and their relationships contain types and properties with a well-defined meaning.</li>
</ul>
<p>本文内容：</p>
<ul>
<li><p><strong>Comprehensive review.</strong> We conduct a comprehensive review on the origin of knowledge graph and modern techniques for relational learning on knowledge graphs. Major neural architectures of knowledge graph representation learning and reasoning are introduced and compared. Moreover, we provide a complete overview of many applications on different domains.</p>
</li>
<li><p><strong>Full-view categorization and new taxonomies.</strong> A full-view categorization of research on knowledge graph, together with fine-grained new taxonomies are presented. </p>
<p>Specifically, in the high-level we review knowledge graph in three aspects: KRL, knowledge acquisition, and knowledge-aware application. </p>
<ul>
<li>For KRL approaches, we further propose fine-grained taxonomies into four views including representa tion space, scoring function, encoding models, and auxiliary information. </li>
<li>For knowledge acquisition, KGC is reviewed under embedding-based ranking, relational path reasoning, logical rule reasoning and meta relational learning; entity-relation acquisition tasks are divided into entity recognition, typing, disambiguation, and alignment; and relation extraction is discussed according to the neural paradigms.</li>
</ul>
</li>
<li><p><strong>Wide coverage on emerging advances.</strong> This survey provides a wide coverage on emerging topics including transformer-based knowledge encoding, graph neural network (GNN) based knowledge prop- agation, reinforcement learning based path reasoning, and meta relational learning.</p>
</li>
<li><p><strong>Summary and outlook on future directions.</strong> This survey provides a summary on each category and highlights promising future research directions.</p>
</li>
</ul>
<h2><span id="2-overview">2. Overview</span></h2><h3><span id="21-a-brief-history-of-knowledge-bases">2.1 A Brief History of Knowledge Bases</span></h3><p><img data-src="image/006gOeiSly1gic36zxip5j30w308qt9y.jpg" alt="屏幕快照 2020-09-02 上午10.15.19.png"></p>
<h2><span id="22-definitions-and-notations">2.2 Definitions and Notations</span></h2><h2><span id="reference">Reference</span></h2><p>[1] A Survey on Knowledge Graphs: Representation, Acquisition and Applications</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>行业知识图谱</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E8%A1%8C%E4%B8%9A%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://zhuanlan.zhihu.com/p/333285965">https://zhuanlan.zhihu.com/p/333285965</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>认知知识图谱</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/12-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/%E8%AE%A4%E7%9F%A5%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="认知知识图谱">认知知识图谱</span></h1><p><a href="https://www.zhihu.com/question/330503177/answers/updated">https://www.zhihu.com/question/330503177/answers/updated</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>迁移学习基础</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/13-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="迁移学习">迁移学习</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>认知神经科学</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/14-%E8%AE%A4%E7%9F%A5%E7%A5%9E%E7%BB%8F%E7%A7%91%E5%AD%A6/%E8%AE%A4%E7%9F%A5%E7%A5%9E%E7%BB%8F%E7%A7%91%E5%AD%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#认知神经科学">认知神经科学</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="认知神经科学">认知神经科学</span></h1><p><a href="https://neu-reality.com/2018/06/speech-brain-waves/">https://neu-reality.com/2018/06/speech-brain-waves/</a></p>
<p><a href="http://brain.bnu.edu.cn/cn/ke/keyanjinzhan/2017/1218/1145.html">http://brain.bnu.edu.cn/cn/ke/keyanjinzhan/2017/1218/1145.html</a></p>
<p><a href="https://www.jiqizhixin.com/articles/2020-03-11-4">https://www.jiqizhixin.com/articles/2020-03-11-4</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/79373989">https://zhuanlan.zhihu.com/p/79373989</a></p>
<p><a href="https://www.zhihu.com/question/20176552">https://www.zhihu.com/question/20176552</a></p>
<p>综述： What happened to cognitive science?</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>认知神经科学</tag>
      </tags>
  </entry>
  <entry>
    <title>clip比你想的更重要</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/clip%20-%20%E6%AF%94%E4%BD%A0%E6%83%B3%E7%9A%84%E8%A6%81%E9%87%8D%E8%A6%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#clip-比你想的要重要">clip: 比你想的要重要</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#多模态预训练模型">多模态预训练模型</a><ul>
<li><a href="#单流模型">单流模型</a></li>
<li><a href="#双流模型">双流模型</a></li>
</ul>
</li>
<li><a href="#clip-是什么">CLIP 是什么？</a></li>
<li><a href="#clip-告诉了我们什么">CLIP 告诉了我们什么？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="clip-比你想的要重要">clip: 比你想的要重要</span></h1><h2><span id="前言">前言</span></h2><p>自去年开始就开始关注多模态领域，一方面工作场景内容的需要；一方面的确是非常感兴趣。大致从多模态预训练和多模态融合两个角度去研究。 从目前的趋势来看，接下来不出意外应该是多模态领域尤其是多模态预训练领域的主场。这就引出我今天想讲的内容： <strong>CLIP，一个被远远低估的预训练模型。</strong></p>
<h2><span id="多模态预训练模型">多模态预训练模型</span></h2><p>多模态预训练一直是一个比较热门的话题，从 image-text 的角度来看，目前的多模态预训练模型可以大致分为两种：<strong>单流模型</strong>与<strong>双流模型</strong>。这里先挖一个坑，后续会对多模态预训练模型进行一个详细的综述，不过真玩意还真是不好写。</p>
<h3><span id="单流模型">单流模型</span></h3><h3><span id="双流模型">双流模型</span></h3><h2><span id="clip-是什么">CLIP 是什么？</span></h2><h2><span id="clip-告诉了我们什么">CLIP 告诉了我们什么？</span></h2>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>language+speech与训练模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/language%20+%20speech%20%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#language-speech">language + speech</a><ul>
<li><a href="#speechbert">SpeechBERT</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="language-speech">language + speech</span></h1><h2><span id="speechbert">SpeechBERT</span></h2><p><img data-src="image/speechbert.png" alt></p>
<h2><span id="reference">Reference</span></h2><p>SpeechBERT: An Audio-and-text Jointly Learned Language Model for End-to-end Spoken Question Answering   2020-8</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>language+vision预训练模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/language+vision%20%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#languagevision-预训练模型">language+vision 预训练模型</a><ul>
<li><a href="#idea-多模态融合">idea — 多模态融合</a></li>
<li><a href="#单流模型与双流模型">单流模型与双流模型</a><ul>
<li><a href="#单流模型">单流模型</a></li>
<li><a href="#双流模型">双流模型</a></li>
</ul>
</li>
<li><a href="#1-image-based-单流模型">1. Image-based 单流模型</a><ul>
<li><a href="#visualbert">VisualBERT</a></li>
<li><a href="#vl-bert">Vl-BERT</a></li>
<li><a href="#unicoder-vl">Unicoder-VL</a></li>
<li><a href="#oscar">OSCAR</a></li>
</ul>
</li>
<li><a href="#2-image-based-双流模型">2. Image-based 双流模型</a><ul>
<li><a href="#vil-bert">Vil-Bert</a></li>
<li><a href="#lxmert">LXMERT</a></li>
<li><a href="#welan">Welan</a></li>
</ul>
</li>
<li><a href="#3-video-based-单流模型">3. Video-based 单流模型</a><ul>
<li><a href="#videobert">VideoBERT</a><ul>
<li><a href="#1-输入格式">1. 输入格式</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4-video-based-双流模型">4. Video-based 双流模型</a><ul>
<li><a href="#cbt">CBT</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="languagevision-预训练模型">language+vision 预训练模型</span></h1><h2><span id="idea-多模态融合">idea — 多模态融合</span></h2><ul>
<li>如何将图片特征与语言特征进行有效融合</li>
</ul>
<h2><span id="单流模型与双流模型">单流模型与双流模型</span></h2><h3><span id="单流模型">单流模型</span></h3><p>单流模型： 训练开始前融合多模态数据，只用一个 Transformer</p>
<h3><span id="双流模型">双流模型</span></h3><p><img data-src="image/LXMERT_1.png" alt></p>
<p>双流模型： 先对多模态数据进行独立编码，再进行融合。需要三个 Transformer 各自分工协作。 典型如LXMERT， ViLBERT。</p>
<h2><span id="1-image-based-单流模型">1. Image-based 单流模型</span></h2><h3><span id="visualbert">VisualBERT</span></h3><p><img data-src="image/VisualBERT.png" alt></p>
<h3><span id="vl-bert">Vl-BERT</span></h3><p><img data-src="image/Vl-BERT.png" alt></p>
<h3><span id="unicoder-vl">Unicoder-VL</span></h3><p><img data-src="image/Unicoder-VL.png" alt></p>
<h3><span id="oscar">OSCAR</span></h3><p><img data-src="image/OSCAR_1.png" alt></p>
<p><img data-src="image/OSCAR_2.png" alt></p>
<p><img data-src="image/OSCAR_3.png" alt></p>
<h2><span id="2-image-based-双流模型">2. Image-based 双流模型</span></h2><h3><span id="vil-bert">Vil-Bert</span></h3><h3><span id="lxmert">LXMERT</span></h3><p><img data-src="image/LXMERT_1.png" alt></p>
<p><img data-src="image/LXMERT_2.png" alt></p>
<h3><span id="welan">Welan</span></h3><h2><span id="3-video-based-单流模型">3. Video-based 单流模型</span></h2><h3><span id="videobert">VideoBERT</span></h3><p><img data-src="image/VideoBERT.png" alt></p>
<h4><span id="1-输入格式">1. 输入格式</span></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2><span id="4-video-based-双流模型">4. Video-based 双流模型</span></h2><h3><span id="cbt">CBT</span></h3><p><img data-src="image/CBT.png" alt></p>
<h2><span id="reference">Reference</span></h2><p><strong>综述</strong></p>
<p>[1] VLP: A Survey on Vision-Language Pre-training</p>
<p><strong>Image-based 单流模型：</strong></p>
<p>[1] Visualbert: A simple and performant baseline for vision and language  2019-8</p>
<p>[2] VL-bert: Pre-training of generic visual-linguistic representations  2019-8</p>
<p>[3 ]Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training  2019-12</p>
<p>[4] B2T2：Fusion of detected objects in text for visual question answering.</p>
<p>[5] UNITER: Learning universal image-text representations   2019-9</p>
<p>[6] VLP: Unified Vision-Language Pre-Training for Image Captioning and VQA   2019-12</p>
<p>[7] FashionBERT- Text and Image Matching with Adaptive Loss for Cross-modal Retrieval   2020-5</p>
<p>[8] Imagebert: Cross-modal pre-training with large-scale weak-supervised image-text data  2020-1</p>
<p>[9] Pixel-bert: Aligning image pixels with text by deep multi-modal transformers  2020-4</p>
<p>[10] Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks   - 2020-6</p>
<p>[11] M6: A Chinese Multimodal Pretrainer 2021-5</p>
<p><strong>Image-based 双流模型：</strong></p>
<p>[1] ViL-BERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks  2019-8</p>
<p>[2] Lxmert: Learning cross-modality encoder representations from transformers. 2019-8</p>
<p>[3] ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph  - 2020-6</p>
<p>[4] WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training 2021-5</p>
<p><strong>Video-based 单流模型：</strong></p>
<p>[1] VideoBERT: A Joint Model for Video and Language Representation Learning  2019-9</p>
<p><strong>Video-based 双流模型：</strong></p>
<p>[1] CBT: Learning Video Representations Using Contrastive Bidirectional Transformer 2019-9</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>language+vision</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/language+vision/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#languagevision">language+vision</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="languagevision">language+vision</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&amp;mid=2247496394&amp;idx=1&amp;sn=22197341f2a5104b70ec9a6acee3d360&amp;source=41#wechat_redirect">从 Vision 到 Language 再到 Action，万字漫谈三年跨域信息融合研究</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/111814136">一文纵览 Vision-and-Language 领域最新研究与进展</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>一文缕清多模态与训练</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/%E4%B8%80%E6%96%87%E6%BB%A4%E6%B8%85%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%84%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="一文滤清多模态预训练">一文滤清多模态预训练</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态综述</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#多模态综述">多模态综述</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="多模态综述">多模态综述</span></h1><h2><span id="reference">Reference</span></h2><p>[1] Multimodal Machine Learning: A Survey and Taxonomy</p>
<p><a href="https://blog.csdn.net/a2352159950/article/details/103152516">https://blog.csdn.net/a2352159950/article/details/103152516</a></p>
<p><a href="https://www.w3xue.com/exp/article/201810/3125.html">https://www.w3xue.com/exp/article/201810/3125.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/149248482">https://zhuanlan.zhihu.com/p/149248482</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态融合</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="多模态融合">多模态融合</span></h1><p><a href="https://zhuanlan.zhihu.com/p/152234745">https://zhuanlan.zhihu.com/p/152234745</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态训练方面paper</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/15-%E5%A4%9A%E6%A8%A1%E6%80%81/%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%96%B9%E9%9D%A2%E7%9A%84paper/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="多模态预训练对比学习">多模态预训练+对比学习</span></h1><p>CLIP - Learning Transferable Visual Models From Natural Language Supervision</p>
<p>WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training 2021-5</p>
<p>UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning</p>
<p><a href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a></p>
<p><a href="https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb#scrollTo=0BpdJkdBssk9">https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb#scrollTo=0BpdJkdBssk9</a></p>
<p><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>2021算法岗，灰飞烟灭？</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/16-%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0/2021%E7%AE%97%E6%B3%95%E5%B2%97%EF%BC%8C%E7%81%B0%E9%A3%9E%E7%83%9F%E7%81%AD%EF%BC%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#2021算法岗灰飞烟灭">2021算法岗，灰飞烟灭？</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#今年为什么这么难呢">今年为什么这么难呢？</a></li>
<li><a href="#bar-在哪里">Bar 在哪里？</a><ul>
<li><a href="#1-论文">1. 论文</a></li>
</ul>
</li>
<li><a href="#2-实习">2. 实习</a><ul>
<li><a href="#3-学校">3. 学校</a></li>
</ul>
</li>
<li><a href="#算法的未来会怎样呢">算法的未来会怎样呢</a></li>
<li><a href="#应该怎么办呢">应该怎么办呢？</a></li>
<li><a href="#最后">最后</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="2021算法岗灰飞烟灭">2021算法岗，灰飞烟灭？</span></h1><h2><span id="前言">前言</span></h2><p>老宋我是去年参加秋招的，当时的情况已经算是直转而下了，虽然个人没有做出什么突出性的工作，但是，基础还算扎实，对多个领域有着自己的理解，幸运的来到了百度，也算是上岸了。 </p>
<p>我从去年就开始相继劝退我身边的朋友，并且在知乎上写了这样一篇文章：<a href="https://zhuanlan.zhihu.com/p/87895563">2021 校招算法岗， 劝退还是继续</a>， 可以看到，我整体是持劝退的态度的，这篇文章阅读量还可以，听从我建议的朋友应该顺利脱坑了，我也算是做了一件善事。 <strong>听我建议退坑的同学点个赞不过分吧。</strong></p>
<h2><span id="今年为什么这么难呢">今年为什么这么难呢？</span></h2><p>没想到今年秋招刚开始，算法岗之难就上了我的知乎推荐：<a href="https://www.zhihu.com/question/406974583/answer/1343041027">如何看待2021年秋招算法岗灰飞烟灭？</a> ，略微浏览了一下，为今年的头铁少年们感到惋惜，明明可以轻松去开发岗拿个小sp， 非要累死累活的去算法岗拿白菜。</p>
<p>今年为什么会这么难呢？ </p>
<p>一方面是疫情的原因，另一方面就是学的人太tm的多了， 啥专业都转算法，啥玩意都玩ai。  先来吐槽一下我国**的科研现状， 国内很多导师水平不用我过多描述，大家都懂， 为了发论文， 疯狂的涌入ai领域，完全不考虑自己实验室的硬件设备，传承积累（其实很多实验室没有传承，只有9117），进而导致，自己的学生貌似看了很多前沿论文， 却并没有什么鸟用，发不了顶会都是扯淡。 </p>
<p>还有就是，我国大多数学生的一个特性： <strong>只管埋头走路，从不抬头看天</strong>。 意思就是，很多同学，从来不做职业规划，从来不去分析行业现状， 不信， 你可以从你身边调研看看，你身边的大神，是不是都是很清楚自己要什么的人呢？ 那些普通学生，是不是都很浑浑噩噩，老师说什么就是什么呢。 我把从<strong>埋头走路</strong>到<strong>抬头看天</strong>的这一过程叫做<strong>觉醒。</strong> 那么，同学，你觉醒了吗？</p>
<h2><span id="bar-在哪里">Bar 在哪里？</span></h2><p>众所周知，今年算法岗的Bar一定是比去年要高的，那么今年的 bar 在哪里呢？我依旧从几个方面来答，这里主要指的是NLP的情况。 </p>
<h3><span id="1-论文">1. 论文</span></h3><p>毫无疑问的是，今年论文的重要性在下降，我觉得主要有两方面的原因。一方面是水文比例的急剧飙升，各大顶会动不动几千的录用以及现在成规模的讲故事套路，让顶会在业界人中的含金量下降迅速，这就得单独去看每个应聘者的论文了。 其实水不水，大家都是做 NLP 的，玩什么聊斋阿。另一方面 ，我认为原因在于，算法的红利消失了，即现有的论文无法带来业务上的提升或者说提升很少了，比如说， 你用GCN跑了个<em>*</em>，的确蛮有创新性的，一看效果，他喵的比 BERT 还差，那请问，我要这玩意干啥呢？现在有能在 bert 之上提高很大(4%以上)的模型或方法吗？ 如果有，那你放心，你offer绝对不会少。</p>
<p>总得来说，论文从看顶会名字到看论文内容的阶段，如果内容不够硬，那么你这篇文章反而会给你带来反作用。</p>
<h2><span id="2-实习">2. 实习</span></h2><p>今年实习的重要性在急剧提升，去年我就不断强调实习的重要性，也不知道有多少人听进去呢？现在各个大厂十分需要有业务 sense 的面试者，即给定你一个业务，你能够快速拆解业务，制定方案，且要求后续迭代慢慢的融合进一些前沿 paper 的一些思想，能做到这一点，我觉得给个sp不过分。 其实很多人实习期间很难做出有创新性的东西，一般都是跟着leader走，但是虽然做不出来，但是一定要尝试创新，不能上个bert完事。</p>
<h3><span id="3-学校">3. 学校</span></h3><p>今年学校的bar 应该和去年差不多，双非除了大神，真的别刚算法了，炮灰都不剩。</p>
<h2><span id="算法的未来会怎样呢">算法的未来会怎样呢</span></h2><p>其实，本质上，就是问：你看不看好人工智能的未来呢？  我先来说我的观点，我是持续看好的，但是风险很大。 现在各大公司都在现有的算法技术上探索落地，但是实际上，收效不大，也就是我说的算法红利消失了。 </p>
<p>接下来，可以仔细捋一捋现在无论是 cv 也好， nlp也好，语音也好，它们的进一步突破在哪里，首先，是技术层面的突破，其实这三个领域都度过了突飞猛进的时代，现在都进入了平稳发展，未来几年会不会出现bert那样的大爆发呢？ 更近一步，即使爆发了，会再次实现结果的大幅提高吗？ 相信每个人都有答案。 然后，就是数据问题，其实现在业界很多问题不是不能解决，而是没有形成数据闭环，那么如何建立这种数据闭环是接下来很重要的事情。 最后，就是减少不确定性，这对于cv来说尤其重要。举例来说，政府提出的新基建，如何解决运输最后一公里的问题，能不能专门留出一条通道给重卡无人车，这样既能够减轻车祸问题，又能够解决运输问题。这个层面需要政府去发力，而由于投入太大，政府可能并不太会去做这种事情。</p>
<p>总得来说，我认为AI 还有很大的空间，但是，短时间内的技术红利已经被吃掉了，剩下的都是一些精细化的工作，仅仅依靠技术是解决不了的。 那么有没有一种可能技术突然爆发带来大规模的应用呢？ 我只能说可能性太小了。</p>
<h2><span id="应该怎么办呢">应该怎么办呢？</span></h2><p>还是那句话： <strong>实习，实习，还是实习</strong>。 什么？ 你连实习都找不到， 那你真的该转岗了。工程+算法，两条腿走路，稳健，你没看见我手里拿着《Go语言从入门到放弃》吗？</p>
<h2><span id="最后">最后</span></h2><p>觉得有帮助的同学，点个赞吧</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>博客文章</tag>
      </tags>
  </entry>
  <entry>
    <title>关于付费咨询发现的有意思的现象</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/16-%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0/%E5%85%B3%E4%BA%8E%E4%BB%98%E8%B4%B9%E5%92%A8%E8%AF%A2%E5%8F%91%E7%8E%B0%E7%9A%84%E5%BE%88%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E7%8E%B0%E8%B1%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#关于付费咨询发现的很有意思的现象">关于付费咨询发现的很有意思的现象</a><ul>
<li><a href="#背景">背景</a></li>
<li><a href="#我的初衷">我的初衷</a></li>
<li><a href="#咨询现象">咨询现象</a></li>
<li><a href="#研究生期间发生的一件事情">研究生期间发生的一件事情</a></li>
<li><a href="#最近发生的一件事情">最近发生的一件事情</a></li>
<li><a href="#总结">总结</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="关于付费咨询发现的很有意思的现象">关于付费咨询发现的很有意思的现象</span></h1><h2><span id="背景">背景</span></h2><p>几个月前，发现还是有蛮多同学有咨询需求的，无论是技术方面，方向方面的内容。可以知乎上的咨询来说，十分不划算，只能回复5个消息， 我觉得很多问题是讲不清楚的，因此我在个人首页写下了这样的消息：</p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1ghzcgl4de2j30hm02yjrp.jpg" alt="屏幕快照 2020-08-22 上午9.43.48.png"></p>
<p>对于每个来咨询的同学， 我都是尽可能把时间拉到<strong>一个小时</strong>左右，<strong>收费20</strong>，了解计算机薪资的人都应该知道，这可以说是很良心了。综合这几个月接受的咨询，发现了一些很有意思的现象，我觉得值得深思一下。 </p>
<p>咨询这件事情可能坚持不了太久了， 且行且珍惜。</p>
<h2><span id="我的初衷">我的初衷</span></h2><p>我个人的初衷是希望能够帮助更多的人，这主要是从我个人的经历出发，因为我的整个学习生涯都是自己摸索成长的，除了大学舍友对我的入门有些帮助，除此之外，我实在是想不到有哪个人对我的个人方向， 技术路线等做出一些指导性意见。</p>
<p>在我最迷茫的时候， 我是十分希望能够有人能够对我的职业道路做出针对性的意见， 我也能够少走一些弯路，然而事实并没有。 最后我也悟出了一个道理： <strong>方向比努力更重要</strong>。</p>
<p>从我个人的出发点来看， 如果说在我大学期间甚至研一研二的时候有人能够指导我的职业方向，相信现在的我会强更多，所以说， 为了不像更多人像我当初那么迷茫且无助， 我做了这样一件事情，<strong>这也是我的初衷</strong>。</p>
<p>说实话， 20块钱一次这玩意跟我的工资比起来，真的是九牛一毛，如果是当初的我，别说20， 只要能对我的职业生涯有较大帮助，只要不过千我都能接受。 咱也不说做慈善，就是趁着自己还有热情的时候，能够帮助更多的人，说实话，我也不知道能够保持多久，<strong>且行且珍惜吧。</strong> </p>
<p>有些人可能说， 那你为啥要付费呢，免费不就好了， 我只能说， 白嫖党真的太多了，这种人我是不屑帮助的。</p>
<h2><span id="咨询现象">咨询现象</span></h2><p>最近的咨询发现很有意思的一点， 来微信咨询的朋友， 都是学校很好，很有自己想法的朋友， 大多数都是985硕士，没有看到有本科生或者双非的研究生，这就很有意思了。 </p>
<p>从我的角度出发， 我的初衷是希望能够帮助本科生，我觉得本科生更加需要这样一件事情来帮助他指明方向，大多数985硕士其实并不一定需要我来提供建议，他的师兄师姐，周围朋友就能给他提供很多建议，反而这些对于本科生来说是十分稀缺的。</p>
<p>然而事实反而是很多很强的朋友来咨询了， 我自己也从这些朋友身上学习到了很多东西。思考一下这个现象其实很有意思，我觉得这就是<strong>强者恒强</strong>的原因了。从中我分析出以下几个结论：</p>
<p><strong>第一点</strong>：<strong>大多数本科生都没有觉醒</strong>。不知道自己要什么，对真正对自己专业方向有帮助的人视而不见， 反而去追半佛这种自媒体，对于这种，我只能说，社会毒打。</p>
<p><strong>第二点：强者恒强， 给机会就会抓住。</strong> 对于985 计算机硕士来说， 20块钱真的太小了， 所以他们对这些钱不是很care，且他们有很清晰的目标，问题问的很深入， 打电话聊的时候，反而是我从这些朋友身上学到了一些东西，真的蛮有意思。 </p>
<h2><span id="研究生期间发生的一件事情">研究生期间发生的一件事情</span></h2><p>研究生期间的一个事情佐证了我的观点：</p>
<blockquote>
<p>在研二的时候，学校要求老师带本科生了解实验室，这是一件很好的事情，老师把这部分学生丢给了我， 我当初可比现在还更有热情，因此，我又是做PPT，又是分析需要， 又是问他们有什么问题想了解的吗？ 发生的情况真的是恶心到我了。</p>
<p>第一次开会， 6个人，来了3个， 那当然还是好好讲了， 本着负责的态度，我从现有的互联网职业，介绍了各个职业的技术栈，并让他们确定自己对哪些方面感兴趣，可以先尝试着学一下。 大概讲了有1个小时吧。</p>
<p>准备第二次开会，我在群里问了他们有什么要了解的吗？ 有个同学提出了一个蛮智障的问题：</p>
<ul>
<li>学长， 可以教一下高数吗？</li>
</ul>
<p>我看到这个，热情一下就扑灭了， <strong>不是所有人都像当初的我一样</strong>，渴求指导。</p>
<p>第二次开会，6个人，来了3个，有一个要<strong>睡午觉</strong>。 之后你们也能想到， 既然你们是混，那随意，我也不讲了，爱咋咋地，就没有第三次开会了。 </p>
</blockquote>
<h2><span id="最近发生的一件事情">最近发生的一件事情</span></h2><p>最近在我们的高中群也发生了一件类似的事情， 我个人对宏观经济，理财方面还算有所了解，在6月10号左右， 我在我们的高中群里说：</p>
<blockquote>
<ul>
<li>预计牛市要启动了， 准备上车</li>
</ul>
</blockquote>
<p>依据其实很简单，国家防水 + 疫情修复 + 创业板小牛行情等多重因素叠加， 其实我认识的几个高学历的对理财宏观经济有研究的都能判断牛市可能要来了。 当时，上证指数 2800多点，处于绝对安全区域。当然是肯定没人听了呀，这波行情，以我买的上证50指数为例，到最高点 3587 点的时候，浮盈 20 点以上， 我在浮盈16个点的时候卖出了。 问题在于， 一个月， 16个点， 确定性又足够高， 然而依旧是没有人去做，真的是验证了那个观点： <strong>每个人只能赚自己认知内的钱。</strong></p>
<p>上周推荐来咨询的一位北大朋友，聊到股票的时候顺手推荐了中国国航，逻辑很简单，疫情修复，航空股必涨。 买入时机6.9，当前价格 7.30，本周最高7.54， 一周时间，这个收益很稳健吧。 这个朋友还是信了我的，买了几千块，而反观我的高中同学， 真的是对比明显。</p>
<p>我的炒股技能并不高，只做逻辑清晰，跟宏观经济连接紧密的票子，千万别咨询这方面。</p>
<h2><span id="总结">总结</span></h2><p>说了这么多，其实还是想到哪里说哪里， 其实想表达的就是， 给了机会就要抓住，机会给你了，你自己不中用呀， 人生有多少次机会值得浪费， 诸位共勉。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>博客文章</tag>
      </tags>
  </entry>
  <entry>
    <title>go命令</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/17%20-%20go%E8%AF%AD%E8%A8%80/go%20%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="go-命令">go 命令</span></h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">go run **.go   # 运行</span><br><span class="line">go build **.go  # 编译</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title>go语言基础</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/17%20-%20go%E8%AF%AD%E8%A8%80/go%20%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#go-语言基础">go 语言基础</a><ul>
<li><a href="#关键词与预定义">关键词与预定义</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="go-语言基础">go 语言基础</span></h1><h2><span id="关键词与预定义">关键词与预定义</span></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">break case chan const continue default defer </span><br><span class="line">else fallthrough for func go goto if import inference map package</span><br><span class="line">range return select struct switch type var</span><br><span class="line"></span><br><span class="line">内建常量： true false iota nil</span><br><span class="line">内建类型： int int8 int16 int32, int64 </span><br><span class="line">					uint uint8 uint16 uint32 uint64 uintpr</span><br><span class="line">					float float64 conplex128 complex64</span><br><span class="line">					bool byte rune string error</span><br><span class="line">内建函数：</span><br><span class="line">				make len cap new append copy close delete</span><br><span class="line">				complex real imag panic recover</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title>Graph embedding</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/18%20-%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Graph%20embedding/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#graph-embedding">Graph embedding</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="graph-embedding">Graph embedding</span></h1><h2><span id="reference">Reference</span></h2><p>node2vec: Scalable Feature Learning for Networks</p>
<p>DeepWalk: Online Learning of Social Representations</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2650995211&amp;idx=1&amp;sn=8e32b5590b8e8bff8a5bd8bfb2ceaa7a&amp;chksm=bdbf02588ac88b4e32ea5320e10c7a2e5ac762ea580e7fce8320b6d5c74a273c13410f5475cf&amp;mpshare=1&amp;scene=1&amp;srcid=0113PKe7MsUK1uHM3FkOpV46#rd">当机器学习遇上复杂网络：解析微信朋友圈 Lookalike 算法</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer与图神经网络</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/18%20-%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Transformer%20%E4%B8%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#transformer-与图神经网络">Transformer 与图神经网络</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="transformer-与图神经网络">Transformer 与图神经网络</span></h1><h2><span id="reference">Reference</span></h2><p>Graph Transformer Networks</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>图神经网络</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/18%20-%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="图神经网络">图神经网络</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/363075386">图网络究竟在研究什么？从15篇研究综述看图神经网络GNN的最新研究进展</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch内部机制</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/19-Pytorch/Pytorch%20%E5%86%85%E9%83%A8%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="pytorch-内部机制">Pytorch 内部机制</span></h1><p><a href="https://zhuanlan.zhihu.com/p/338256656">https://zhuanlan.zhihu.com/p/338256656</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch转ONNX</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/19-Pytorch/Pytorch%20%E8%BD%AC%20ONNX/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="pytorch-转-onnx">Pytorch 转 ONNX</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/272767300">Pytorch转ONNX-理论篇</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>python面试题</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/2-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/Python%20%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-垃圾回收机制">1. 垃圾回收机制</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h3><span id="1-垃圾回收机制">1. 垃圾回收机制</span></h3><p><strong>引用计数为主，分代收集为辅。</strong>在 python 中，如果一个对象的引用数为 0， python 虚拟机就会回收这个对象的内存。</p>
<ul>
<li><p>导致引用计数 +1 的情况：</p>
<blockquote>
<ul>
<li>对象被创建： a = classname()</li>
<li>对象被引用： b = a</li>
<li>对象被作为参数，传入到一个函数中： func(a)</li>
<li>对象作为一个元素，存储在容器内： list_name = [a, a]</li>
</ul>
</blockquote>
</li>
<li><p>导致引用计数 -1 的情况：</p>
<blockquote>
<ul>
<li>对象的别名被显式销毁， 如： del a </li>
<li>对象的别名被赋予新的对象，如：a = other_class()</li>
<li>一个对象离开它的作用域，如函数执行完毕时，func 函数中的局部变量</li>
<li>对象所在的容器被销毁，或从容器中删除对象</li>
</ul>
</blockquote>
</li>
</ul>
<p><strong>循环引用导致内存泄漏</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">c1=ClassA() # 内存 1 引用计数 +1 = 1</span><br><span class="line">c2=ClassA() # 内存 2 引用计数 +1 = 1</span><br><span class="line">c1.t=c2  #  内存 2 引用计数 +1 = 2</span><br><span class="line">c2.t=c1  #  内存 1 引用计数 +1 = 2</span><br><span class="line">del c1  # 内存 1 引用计数 -1 = 1</span><br><span class="line">del c2  # 内存 2 引用计数 -1 = 1</span><br></pre></td></tr></table></figure>
<p>如上文描述，由于<strong>循环引用</strong>，导致垃圾回收器都不会回收它们，所以就会导致内存泄露。</p>
<p><strong>垃圾回收机制模块： gc</strong></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>编程语言基础</tag>
      </tags>
  </entry>
  <entry>
    <title>python多线程</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/2-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/Python%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#为什么说python线程是伪线程">为什么说python线程是伪线程？</a></li>
<li><a href="#什么是守护线程">什么是守护线程</a></li>
<li><a href="#python中的多线程">python中的多线程</a></li>
<li><a href="#threadingthread类">Threading.Thread类</a><ul>
<li><a href="#thread类的属性">Thread类的属性</a></li>
<li><a href="#1-name">1. name</a></li>
<li><a href="#2-ident">2. ident</a></li>
<li><a href="#3-daemon">3. daemon</a></li>
<li><a href="#thread类方法">Thread类方法</a></li>
<li><a href="#1-start">1. start()</a></li>
<li><a href="#2-run">2. run()</a></li>
<li><a href="#3-join">3. join()</a></li>
<li><a href="#4-is_alive">4. is_alive()</a></li>
</ul>
</li>
<li><a href="#创建线程的几种方法">创建线程的几种方法</a><ul>
<li><a href="#1-第一种-派生thread的子类并创建子类的实例推荐">1. 第一种： 派生Thread的子类，并创建子类的实例（推荐）</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="为什么说python线程是伪线程">为什么说python线程是伪线程？</span></h2><p>但是在python中，<strong>python虚拟机要求在主循环中同时只能有一个控制线程在运行，这也就意味着即使python解释器中可以运行多个线程，但是在任意时刻只有一个线程会被python解释器执行。</strong></p>
<p>而这正是由<strong>GIL（全局解释器锁）</strong>来控制的，它保证了同一时刻只能有一个线程运行，而在python多线程环境下，python虚拟机按照下面的 方式运行：</p>
<ol>
<li><p>设置GIL</p>
</li>
<li><p>切换进一个线程取运行</p>
</li>
<li><p>执行下面操作之一：</p>
<blockquote>
<ul>
<li>执行指定数量的字节码指令</li>
<li>线程主动让出控制权（time.sleep())</li>
</ul>
</blockquote>
</li>
<li><p>把线程设置会睡眠状态（切换出线程）</p>
</li>
<li><p>解锁GIL</p>
</li>
<li><p>重复以上步骤</p>
</li>
</ol>
<p>这也就是为什么说python的多线程适合于IO密集型，而不适合计算密集型任务。</p>
<h2><span id="什么是守护线程">什么是守护线程</span></h2><p>守护线程可以视为其余非守护线程的保姆，只有所有非守护线程都退出了，守护线程才会终止。</p>
<p>threading模块支持守护线程，其工作方式是:守护线程一般是一个等待客户端请求服务的服务器。如果没有客户端请求,守护线程就是空闲的。</p>
<h2><span id="python中的多线程">python中的多线程</span></h2><p>python中提供了很方便的库来提供多线程，该库就是Threading库。</p>
<h2><span id="threadingthread类">Threading.Thread类</span></h2><p>首先我们先来介绍一下它的初始化函数，再来介绍它的相关属性，最后，我们介绍它常用的一些方法。</p>
<h3><span id="__init__"><code>__init__</code></span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class threading.Thread(group=None, target=None, name=None, args=(), kwargs=&#123;&#125;, *, daemon=None)</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>group: 预留参数，用于扩展</li>
<li>target： run()方法所调用的函数，默认为None。 </li>
<li>name： 线程名字，默认为” Thread-<em>N</em>“ </li>
<li>args： 调用target时的参数列表</li>
<li>kwargs： 调用target时的关键字列表</li>
<li>daemon: 为True，表示启动后台线程（对于需要长时间运行的线程或者需要一直运行的后台任务，你应该考虑使用后台线程）</li>
</ul>
</blockquote>
<h3><span id="thread类的属性">Thread类的属性</span></h3><h3><span id="1-name">1. name</span></h3><blockquote>
<p>获取和设置线程的名字，可更改。</p>
</blockquote>
<h3><span id="2-ident">2. ident</span></h3><blockquote>
<p>获取线程的标识符。线程标识符是一个非零整数，只有在调用了start()方法之后该属性才有效，否则它只返回None。</p>
</blockquote>
<h3><span id="3-daemon">3. daemon</span></h3><blockquote>
<p>一个 boolean 值表示该进程是不是后台进程(守护进程）。True： 后台进程   Flase： 非后台线程，可更改。</p>
</blockquote>
<h3><span id="thread类方法">Thread类方法</span></h3><h3><span id="1-start">1. start()</span></h3><blockquote>
<p>启动线程活动</p>
</blockquote>
<p>每个线程对象必须调用最多一次start()函数，</p>
<h3><span id="2-run">2. run()</span></h3><p>定义线程功能的方法（通常在子类中被应用开发者重写</p>
<h3><span id="3-join">3. join()</span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">join(timeout=None)</span><br></pre></td></tr></table></figure>
<p>设置主线程是否同步阻塞自己来待此线程执行完毕。如果不设置的话则主进程会继续执行自己的，在结束时根据 setDaemon 有无注册为守护模式的子进程，有的话将其回收，没有的话就结束自己，某些子线程可以仍在执行</p>
<p> 主线程启动若干个子线程后，可以继续执行主线程的代码，也可以等待所有的子线程执行完毕后继续执行主线程，这里需要用到的就是 join 方法，子线程通过调用 join 可以告诉主线程，你必须等着我，我完事了你才可以再往下执行。</p>
<h3><span id="4-is_alive">4. is_alive()</span></h3><blockquote>
<p>判断线程是否alive</p>
<p>True: alive      False： not alive</p>
</blockquote>
<h2><span id="创建线程的几种方法">创建线程的几种方法</span></h2><h3><span id="1-第一种-派生thread的子类并创建子类的实例推荐">1. 第一种： 派生Thread的子类，并创建子类的实例（推荐）</span></h3><blockquote>
<ul>
<li>第一步：创建一个线程子类，该类继承<code>threading.Thread</code>类</li>
<li>第二步：复写该子类中的run方法</li>
<li>第三步：写该子线程要执行的功能函数模块</li>
<li>第四步：创建Thread子类实例，运行该线程</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExampleThread</span>(<span class="params">threading.Thread</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, func, args, name=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.name = name</span><br><span class="line">        self.func = func   <span class="comment"># 传入的函数（python中允许向函数中传递函数）</span></span><br><span class="line">        self.args = args   <span class="comment"># 表示要传递到函数的参数信息</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.func(*self.args)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example</span>(<span class="params">参数列表</span>):</span></span><br><span class="line">    <span class="comment"># 子线程要执行的功能实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main&quot;</span>:</span><br><span class="line">    t = ExampleThread(example, 参数列表, example.__name__)</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure>
<h3><span id="第二种-创建thread实例传递给它一个函数">第二种： 创建Thread实例，传递给它一个函数</span></h3><p>该方法是最简单的方法，但是不推荐你使用，因为其不符合面向对象的思想。</p>
<blockquote>
<ul>
<li>第一步：创建一个子线程要执行的功能函数模块</li>
<li>第二步：创建Thread实例，运行该线程</li>
</ul>
</blockquote>
<p>我们看到，该方法与上面的方法相比，更为简洁，这两种方法选一个就好，我个人偏向第一种。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">example</span>(<span class="params">参数列表</span>):</span></span><br><span class="line">    <span class="comment"># 子线程要执行的功能实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main&quot;</span>:</span><br><span class="line">    t = threading.Thread(target=example, args=参数列表)</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>编程语言基础</tag>
      </tags>
  </entry>
  <entry>
    <title>python导入</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/2-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/python%E5%AF%BC%E5%85%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#常见的导入方式">常见的导入方式</a></li>
<li><a href="#from-__future__-import"><code>from __future__ import *</code></a></li>
<li><a href="#from-__future__-import-absolute_import"><code>from __future__ import absolute_import</code></a></li>
<li><a href="#python-库搜索路径">python 库搜索路径</a></li>
<li><a href="#包内导入">包内导入</a></li>
<li><a href="#绝对导入与相对导入">绝对导入与相对导入</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a href="http://kuanghy.github.io/2016/07/21/python-import-relative-and-absolute">Python 相对导入与绝对导入</a></p>
<p><a href="http://codingpy.com/article/python-import-101/">Python导入模块的几种姿势</a></p>
<h2><span id="常见的导入方式">常见的导入方式</span></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import sys     # 导入整个模块</span><br><span class="line">import sys as system  # 导入整个模块并命名</span><br><span class="line">from sys import ...   # 导入sys模块中的子模块</span><br><span class="line">from os import *  # 不推荐，导入该模块下所有的包</span><br></pre></td></tr></table></figure>
<h2><span id="from-__future__-import"><code>from __future__ import *</code></span></h2><blockquote>
<p><code>__future__</code> 模块由 <a href="https://link.jianshu.com?t=https://www.python.org/dev/peps/pep-0236/">PEP 236</a> 提出并加入到 Python 2.1，其存在的主要原因是 Python 的版本升级经常会增加一些新的特性，而 <code>__future__</code> 模块将一些新版本中将会增加的新的特性进行声明，同时使得旧版本可以使用这些新的语法特性。</p>
</blockquote>
<p>这也就是说，如果你要想在低版本中使用高版本的特性，那么<code>from __future__ import ...</code>可以很好的帮你实现，这也意味着如果你在你的代码中使用<code>from __future__ import ...</code>， 会提高你代码的向下兼容性。</p>
<p>需要注意的是：</p>
<blockquote>
<ul>
<li>如果你用的是 Python 2.1 以前的版本，是没办法使用 <code>__future__</code> 的。</li>
<li><code>__future__</code> 模块的导入一定要放在最上方，也就是在所有其它模块之前导入。</li>
</ul>
</blockquote>
<h2><span id="from-__future__-import-absolute_import"><code>from __future__ import absolute_import</code></span></h2><blockquote>
<p>这句话的意思是将所有导入视为绝对导入，指的是禁用<code>implicit relative import</code>（隐式相对导入）, 但并不会禁掉 <code>explicit relative import</code>（显示相对导入）。</p>
</blockquote>
<h2><span id="python-库搜索路径">python 库搜索路径</span></h2><p>当你导入时，会按照以下路径按顺序来搜索你要导入的文件，python的搜索路径构成了<code>sys.path</code>。：</p>
<ol>
<li>在当前目录下搜索该模块</li>
<li>在环境变量 PYTHONPATH 中指定的路径列表中依次搜索</li>
<li>在 Python 安装路径的 lib 库中搜索</li>
<li>也许会用到<code>.pth</code> 文件，但一般不用</li>
</ol>
<p>python 所有加载的模块信息都存放在 <code>sys.modules</code> 结构中，当 import 一个模块时，会按如下步骤来进行</p>
<ul>
<li>如果是 <code>import A</code>，检查 sys.modules 中是否已经有 A，如果有则不加载，如果没有则为 A 创建 module 对象，并加载 A</li>
<li>如果是 <code>from A import B</code>，先为 A 创建 module 对象，再解析A，从中寻找B并填充到 A 的 <code>__dict__</code>中</li>
</ul>
<h2><span id="包内导入">包内导入</span></h2><p>包内导入就是<strong>包内的模块导入包内部的模块</strong>。举个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">example</span><br><span class="line">   --- main</span><br><span class="line">       --- test.py</span><br><span class="line">   --- model</span><br><span class="line">       --- view.py</span><br></pre></td></tr></table></figure>
<p>这是常见的一个结构，将项目的不同模块区分开，那么此时的包内导入如何就是在<code>test.py</code> 中导入<code>view.py</code> 。</p>
<h2><span id="绝对导入与相对导入">绝对导入与相对导入</span></h2><p>首先，注意一点，绝对导入与相对导入是针对<strong>包内导入</strong>而言的。其中：</p>
<blockquote>
<ul>
<li>绝对导入的格式为： <code>import A.B</code> 或<code>from A import B</code></li>
<li>相对导入的格式为：<code>from .. import B</code>, <code>.</code>代表当前模块，<code>..</code>代表上层模块，<code>...</code>代表上上层模块，依次类推。</li>
</ul>
</blockquote>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>编程语言基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer in CV</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/21-%20%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/Transformer%20in%20CV/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="transformer-in-cv">Transformer in CV</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/363370678">Vision Transformer 超详细解读</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/3-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="操作系统">操作系统</span></h1><hr>
<!-- toc -->
<ul>
<li><a href="#1-进程与线程">1. 进程与线程</a><ul>
<li><a href="#1-进程与线程的区别">1. 进程与线程的区别</a></li>
<li><a href="#2-进程间通信的方式">2. 进程间通信的方式</a></li>
<li><a href="#3-线程间的通信方式">3. 线程间的通信方式</a></li>
<li><a href="#4">4.</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-进程与线程">1. 进程与线程</span></h2><h3><span id="1-进程与线程的区别">1. 进程与线程的区别</span></h3><h3><span id="2-进程间通信的方式">2. 进程间通信的方式</span></h3><h3><span id="3-线程间的通信方式">3. 线程间的通信方式</span></h3><h3><span id="4">4.</span></h3>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/3-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="计算机网络">计算机网络</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title>分类模型1-逻辑回归</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B1%20-%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#logistic回归简介">logistic回归简介</a></li>
<li><a href="#logistic-回归的数学表达">Logistic 回归的数学表达</a></li>
<li><a href="#如何求解最优的-theta">如何求解最优的 $\theta$</a></li>
<li><a href="#常见问题">常见问题</a><ul>
<li><a href="#1-逻辑回归与线性回归">1. 逻辑回归与线性回归</a></li>
<li><a href="#2-推导一下-lr">2. 推导一下 LR</a></li>
<li><a href="#3-lr-如何实现多分类">3. LR 如何实现多分类？</a></li>
<li><a href="#4-lr-为何要对特征进行离散化">4. LR 为何要对特征进行离散化</a></li>
<li><a href="#5-逻辑回归中增大-l1-正则化会是什么结果">5. 逻辑回归中，增大 L1 正则化会是什么结果</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="logistic回归简介">logistic回归简介</span></h2><p>logistic回归用于解决的是分类问题，<strong>其基本思想是：根据现有数据对分类边界线建立回归公式,以此进行分类。</strong>也就是说，logistic 回归不是对所有数据点进行拟合，而是要对<strong>数据之间的分界线</strong>进行拟合。</p>
<ul>
<li>逻辑回归的本质： 极大似然估计</li>
<li>逻辑回归的激活函数：Sigmoid</li>
<li>逻辑回归的代价函数：交叉熵</li>
</ul>
<h2><span id="logistic-回归的数学表达">Logistic 回归的数学表达</span></h2><script type="math/tex; mode=display">
h_\theta(x) = sigmoid(\theta^T X)  = \frac{1}{1 + e^{-\theta^T X}}</script><h2><span id="如何求解最优的-theta">如何求解最优的 $\theta$</span></h2><p>首先，我们依旧是要找到一个合适的损失函数，在Logistic回归中的损失函数为：</p>
<script type="math/tex; mode=display">
Cost(h_{\theta}(x),y) = 
\begin{cases} -log(h_{\theta(x)}) & if \, y = 1\\
-log(1-h_{\theta(x)}) & if \, y = 0
\end{cases}</script><script type="math/tex; mode=display">
J(\theta) =    - \frac{1}{m}   \left[  \sum_{i=1}^m y^{(i)}log(h_\theta(x^{(i)}))   + (1-y^{(i)}) log(1 - h_\theta(x^{(i)}))             \right]</script><p>我们最终给它加一个正则化项：</p>
<script type="math/tex; mode=display">
J(\theta) =    - \frac{1}{m}   \left[  \sum_{i=1}^m y^{(i)}log(h_\theta(x^{(i)}))   + (1-y^{(i)}) log(1 - h_\theta(x^{(i)}))             \right] + \frac{\lambda}{2m} \sum_{j=1}^{m}\theta_j^2</script><p>最后，我们要求最优参数的话，依旧是使用梯度下降算法来获取$J(\theta)$ 的最小值时对应的参数。</p>
<hr>
<h2><span id="常见问题">常见问题</span></h2><h3><span id="1-逻辑回归与线性回归">1. 逻辑回归与线性回归</span></h3><ul>
<li><p>逻辑回归处理分类问题，线性回归处理回归问题</p>
</li>
<li><p>线性回归的拟合函数本质上是对 <strong>输出变量 y 的拟合</strong>， 而逻辑回归的拟合函数是对 <strong>label 为1的样本的概率的拟合</strong>。</p>
<script type="math/tex; mode=display">
线性回归：f(x)=\theta ^{T}x \\
逻辑回归：f(x)=P(y=1|x;\theta )=g(\theta ^{T}x)， \quad g(z)=\frac{1}{1+e^{-z}}</script></li>
<li><p>线性回归其参数计算方式为<strong>最小二乘法</strong>， 逻辑回归其参数更新方式为<strong>极大似然估计</strong>。</p>
</li>
<li><p>线性回归更容易受到异常值的影响， 而LR对异常值有较好的稳定性。</p>
</li>
</ul>
<h3><span id="2-推导一下-lr">2. 推导一下 LR</span></h3><ul>
<li><p>sigmoid :</p>
<script type="math/tex; mode=display">
g(z) = \frac{1}{1+e^{-z}} \\
g'(z) = g(z)(1-g(z))</script></li>
<li><p>LR 的定义：</p>
<script type="math/tex; mode=display">
h_{\theta}(x) = g(\theta^Tx) = \frac{1}{1 + e^{-\theta^Tx}}</script></li>
<li><p>LR 满足<strong>伯努利分布：</strong></p>
<script type="math/tex; mode=display">
P(Y=1|x; \theta) = h_{\theta}(x) \\
P(Y=0|x; \theta)  = 1 - h_{\theta}(x) \\
p(y|x; \theta) = (h_{\theta}(x))^y (1-h_{\theta}(x))^{1-y}</script></li>
<li><p><strong>损失函数（极大似然）:</strong>  对于训练数据集，特征数据 $x={x_1, …x_m}$ 和其对应的分类标签 $y = {y_1,…y_m}$ ， 假设 m 个样本是相互独立的，那么极大似然函数为： </p>
<script type="math/tex; mode=display">
\begin{align}
L(\theta) &= \prod_{i=1}^m p(y^{(i)}|x(i);\theta) \\ 
&= \prod_{i=1}^m  (h_{\theta}(x^{(i)}))^{y^{(i)}} (1-h_{\theta}(x^{(i)}))^{1-y^{(i)}}\\
\end{align}</script><p>那么它的 log 似然为：</p>
<script type="math/tex; mode=display">
\begin{align}
L(\theta) &= log L(\theta ) \\
&= \sum_{i=1}^m y^{(i)} log h(x^{(i)}) + (1-y^{(i)}) log (1-h(x^{(i)}))
\end{align}</script></li>
<li><p>参数优化（梯度上升）</p>
<script type="math/tex; mode=display">
\begin{align}
\frac{\partial L(\theta)}{\partial \theta_j} &= (y \frac{1}{g(\theta^Tx)} - (1-y) \frac{1}{1 -g(\theta^Tx)}) \frac{\delta g(\theta^Tx)}{\delta \theta_j} \\
&= (y \frac{1}{g(\theta^Tx)} - (1-y)\frac{1}{1 -g(\theta^Tx)} ) g(\theta^Tx)(1-g(\theta^Tx)) \frac{\delta \theta^Tx}{\theta_j} \\
&= (y (1 - g(\theta^Tx)) - (1-y) g(\theta^Tx)) x_j \\
&= [y - h_{\theta} (x)]x_j \\
\end{align}</script></li>
</ul>
<script type="math/tex; mode=display">
\begin{align}
\theta_j &= \theta_j + \alpha \frac{\partial L(\theta)}{\partial \theta} \\
&= \theta_j + \alpha [y^{(i)} - h_{\theta} (x^{(i)})]x_j^{(i)}   
\end{align}</script><ul>
<li>损失函数：<script type="math/tex; mode=display">
J(\theta) = - \frac{1}{m}   \left[  \sum_{i=1}^m y^{(i)}log(h_\theta(x^{(i)}))   + (1-y^{(i)}) log(1 - h_\theta(x^{(i)}))             \right]</script></li>
</ul>
<h3><span id="3-lr-如何实现多分类">3. LR 如何实现多分类？</span></h3><ul>
<li><strong>方式1：</strong> 修改逻辑回归的损失函数，使用softmax函数构造模型解决多分类问题，softmax分类模型会有相同于类别数的输出，输出的值为对于样本属于各个类别的概率，最后对于样本进行预测的类型为概率值最高的那个类别。</li>
<li><strong>方式2：</strong> 根据每个类别都建立一个二分类器，本类别的样本标签定义为0，其它分类样本标签定义为1，则有多少个类别就构造多少个逻辑回归分类器。</li>
</ul>
<p>若所有类别之间有明显的互斥则使用softmax分类器，若所有类别不互斥有交叉的情况则构造相应类别个数的逻辑回归分类器。</p>
<h3><span id="4-lr-为何要对特征进行离散化">4. LR 为何要对特征进行离散化</span></h3><ul>
<li><strong>非线性。</strong> 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合； 离散特征的增加和减少都很容易，易于模型的快速迭代； </li>
<li><strong>速度快。</strong> 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展</li>
<li><strong>鲁棒性。</strong> 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li><strong>方便交叉与特征组合</strong>： 离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力。</li>
<li><strong>稳定性：</strong> 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问。</li>
<li><strong>简化模型：</strong> 特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。</li>
</ul>
<h3><span id="5-逻辑回归中增大-l1-正则化会是什么结果">5. 逻辑回归中，增大 L1 正则化会是什么结果</span></h3><p>所有参数 w 都会变成 0。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>分类模型1-决策树</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B2%20-%20%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#简介">简介</a></li>
<li><a href="#决策树三要素">决策树三要素</a></li>
<li><a href="#1-特征的选择">1. 特征的选择</a><ul>
<li><a href="#1-id3">1. ID3</a></li>
<li><a href="#2-c45">2. C4.5</a></li>
<li><a href="#3-cart">3. CART</a></li>
</ul>
</li>
<li><a href="#2-剪枝处理">2. 剪枝处理</a><ul>
<li><a href="#0-剪枝的作用">0. 剪枝的作用</a></li>
<li><a href="#1-预剪枝">1. 预剪枝</a></li>
<li><a href="#2-后剪枝">2. 后剪枝</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-id3-c45-cart-这三种决策树的区别">1. ID3, C4.5, CART 这三种决策树的区别</a></li>
<li><a href="#2-树形结构为何不需要归一化">2. 树形结构为何不需要归一化？</a></li>
<li><a href="#3-分类决策树与回归决策树的区别">3. 分类决策树与回归决策树的区别</a></li>
<li><a href="#4-为何信息增益会偏向多取值特征">4. 为何信息增益会偏向多取值特征？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>划分标准</th>
</tr>
</thead>
<tbody>
<tr>
<td>ID3</td>
<td>信息增益</td>
</tr>
<tr>
<td>C4.5</td>
<td>信息增益率</td>
</tr>
<tr>
<td>CART</td>
<td>基尼系数</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="简介">简介</span></h2><p>决策树是一个分而治之的递归过程。 </p>
<ul>
<li>开始，构建根节点，将所有训练数据都放在根节点。</li>
<li>然后，<strong>选择一个最优特征</strong>，按照这一特征将训练数据集分割成子集，使得各个子集有一个在当前条件下最好的分类。</li>
<li>如果子集未分类完毕，则在子集中选择一个最优特征，继续进行划分，直到所有训练数据子集都被正确分类或没有合适的特征为止。</li>
</ul>
<h2><span id="决策树三要素">决策树三要素</span></h2><ul>
<li><strong>特征选择：</strong> 从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准标准，从而衍生出不同的决策树算法。 </li>
<li><strong>决策树生成：</strong>根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止生长。</li>
<li><strong>决策树的修剪：</strong>决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合。剪枝技术有预剪枝和后剪枝两种。</li>
</ul>
<h2><span id="1-特征的选择">1. 特征的选择</span></h2><p>有三种方法进行特征选择：ID3: 信息增益，C4.5: 信息增益比，CART: 基尼系数</p>
<h3><span id="1-id3">1. ID3</span></h3><p><strong>思想：</strong> 计算所有特征划分数据集D，得到多个特征划分数据集D的信息增益，从这些信息增益中选择最大的，因而当前结点的划分特征便是使信息增益最大的划分所使用的特征。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.对当前例子集合，计算各属性的信息增益；</span><br><span class="line">2.选择信息增益最大的属性Ak；</span><br><span class="line">3.把在Ak处取值相同的例子归于同一子集，Ak取几个值就得几个子集；</span><br><span class="line">4.对既含正例又含反例的子集，递归调用建树算法；</span><br><span class="line">5.若子集仅含正例或反例，对应分枝标上P或N，返回调用处。</span><br></pre></td></tr></table></figure>
<p><strong>信息增益：</strong> 度量以<strong>某特征划分数据集前后的信息熵的差值</strong>。 信息熵能够表示样本集合的不确定性，因此我们能够通过前后集合信息熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏。</p>
<p>假设划分前样本集合D的熵为 $H(D)$。使用某个特征A划分数据集D，计算划分后的数据子集的熵为 $H(D|A)$ 。</p>
<script type="math/tex; mode=display">
信息熵：H(D) = - \sum_{k=1}^k \frac{|C_k|}{|D|} log_2 \frac{|C_k|}{|D|} \\
条件熵： H(D|A) = \sum_{i=1}^n \frac{|D_i|}{|D|} H(D_i) \\
信息增益： g(D,A)=H(D)-H(D|A)</script><p><strong>注意：</strong> 在决策树构建中，我们总是希望集合往最快到达<strong>纯度更高</strong> 的子集合发展，因此我们总是选择是的<strong>信息增益最大的特征</strong>来划分当前集合。</p>
<ul>
<li>缺点：信息增益对<strong>分支较多的属性</strong>有所偏好，因此有人提出采用<strong>信息增益比</strong>来划分特征。</li>
</ul>
<h3><span id="2-c45">2. C4.5</span></h3><p><strong>信息增益比本质：</strong>在信息增益的基础之上乘上一个惩罚参数。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。</p>
<script type="math/tex; mode=display">
信息增益比 = 惩罚参数 \times 信息增益 \\
信息增益比：g_R(D,A) = \frac{g(D,A)}{H(D)}</script><p><strong>信息增益比对可取值数目较少的属性有所偏好。C4.5 先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择信息增益比最高的。</strong></p>
<p>相对于 ID3 算法的改进：用<strong>信息增益比</strong>来选择属性，克服了用信息增益选择属性<strong>偏向选择多值属性的不足</strong></p>
<h3><span id="3-cart">3. CART</span></h3><p>CART 既可以用于分类，也可以用于回归。</p>
<p>基尼系数 $Gini(D)$ 表示集合 D 的不确定性，基尼系数 $Gini(D, A=a)$ 表示集合 D 经过 A = a 分割后的不确定性。 基尼系数越小，样本的不确定性越小。</p>
<p>分类问题中，假设有 K 个类，样本点属于第 k 类的概率为 $p_k$， 则概率分布的基尼系数定义为</p>
<script type="math/tex; mode=display">
Gini(D) = \sum_{k=1}^{|K|}p_k(1-p_k)= 1 - \sum_{k=1}^{K} p_k^2</script><p>如果样本集合 $D$ 根据特征 $A$ 是否取一可能值 $a$ 被分割成 $D_1$ 和 $D_2$ 两部分， 那么在特征 A 的条件下， 集合 D 的基尼系数定义为：</p>
<script type="math/tex; mode=display">
Gini(D, A=a) = \frac{D_1}{D}Gini(D_1) + \frac{D_2}{d} Gini(D_2)</script><ul>
<li><p>从根节点开始，对节点计算现有特征的基尼系数，对于每一个特征，根据 “是” 与 “否” 划分为两个部分，根据上式计算划分过后的基尼系数。</p>
</li>
<li><p>在所有可能的特征 A 以及<strong>该特征所有的可能取值aa中</strong>，选择<strong>基尼指数最小</strong>的特征及其对应的取值作为最优特征和最优切分点。然后根据最优特征和最优切分点，将本节点的数据集二分，生成两个子节点。</p>
</li>
<li><p>对两个字节点递归地调用上述步骤，直至节点中的样本个数小于阈值，或者样本集的基尼指数小于阈值，或者没有更多特征后停止。</p>
</li>
</ul>
<h2><span id="2-剪枝处理">2. 剪枝处理</span></h2><h3><span id="0-剪枝的作用">0. 剪枝的作用</span></h3><p>剪枝处理是决策树学习算法用来<strong>解决过拟合</strong>的一种办法。</p>
<p>在决策树算法中，为了尽可能正确分类训练样本， 节点划分过程不断重复， 有时候会造成决策树分支过多，以至于将训练样本集自身特点当作泛化特点， 而导致过拟合。 因此可以采用剪枝处理来去掉一些分支来降低过拟合的风险。 </p>
<h3><span id="1-预剪枝">1. 预剪枝</span></h3><p>在决策树生成过程中，在每个节点划分前先估计其划分后的泛化性能， 如果不能提升，则停止划分，将当前节点标记为叶结点。 </p>
<h3><span id="2-后剪枝">2. 后剪枝</span></h3><p>生成决策树以后，再自下而上对非叶结点进行考察， 若将此节点标记为叶结点可以带来泛化性能提升，则修改之。</p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-id3-c45-cart-这三种决策树的区别">1. ID3, C4.5, CART 这三种决策树的区别</span></h3><ul>
<li>ID3 决策树优先选择<strong>信息增益大</strong>的属性来对样本进行划分， 但是这样的划分方法有一个很大的缺点： 当一个<strong>属性可取值数目较多时</strong>， 可能在这个属性对应值下的样本<strong>只有一个或者很少个</strong>， 此时它的信息增益将很高， ID3会认为这个属性很适合划分。</li>
<li>C4.5树：不采用信息增益作为划分依据，而是采用<strong>信息增益率</strong>作为划分依据。但是仍不能完全解决以上问题,而是有所改善。</li>
<li>CART树：它使用<strong>gini系数</strong>作为节点的分裂依据。</li>
</ul>
<h3><span id="2-树形结构为何不需要归一化">2. 树形结构为何不需要归一化？</span></h3><p>因为数值缩放不影响分裂点位置，对树模型的结构不造成影响。<br>按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。而且，树模型是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化。</p>
<h3><span id="3-分类决策树与回归决策树的区别">3. 分类决策树与回归决策树的区别</span></h3><h3><span id="4-为何信息增益会偏向多取值特征">4. 为何信息增益会偏向多取值特征？</span></h3><p>从直观的理解上来说，当特征取值较多时， 根据此特征划分得到的子集纯度有更大的可能性会更高（对比取值较少的特征）， 因此划分之后的熵会更低，而又由于划分之前的熵是一定的，因此信息增益更大。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>分类模型1-感知机</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B3%20-%20%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="模型-感知机">模型 - 感知机</span></h1><hr>
<!-- toc -->
<ul>
<li><a href="#感知机模型">感知机模型</a></li>
<li><a href="#感知器的训练">感知器的训练</a><ul>
<li><a href="#1-如何判断一个点被正确分类">1. 如何判断一个点被正确分类？</a></li>
<li><a href="#2-损失函数">2. 损失函数</a></li>
<li><a href="#3-求取w-b">3. 求取w， b</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="感知机模型">感知机模型</span></h2><p>感知机可以拟合任何线性函数，这也就意味着任何<strong>线性分类</strong>或<strong>线性回归</strong>问题都可以用感知器来解决。</p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g1gj9rt5fsj307s03ut8i.jpg" alt></p>
<script type="math/tex; mode=display">
f(x) = sign(w^Tx) \\
sign(a) = \begin{cases} +1, & a \ge 0 \\ -1, & a < 0 \end{cases}</script><h2><span id="感知器的训练">感知器的训练</span></h2><p>感知器的训练主要包含两大问题：</p>
<ul>
<li><p>如何判断一个样本是不是被正确分类？</p>
</li>
<li><p>如何定义损失函数？</p>
</li>
</ul>
<h3><span id="1-如何判断一个点被正确分类">1. 如何判断一个点被正确分类？</span></h3><p>误分类分为以下两种情况：</p>
<ul>
<li>当$w^T  x_i   &gt; 0 $ 时，得出$y_i = -1 $ ， 此时出现误分类</li>
<li>当$w^Tx_i  &lt; 0 $ 时，得出$ y_i = 1$ ，此时也出现误分类</li>
</ul>
<p>那么，我们分析，对于误分类的数据$(x_i,y_i) $ 来说，必有：</p>
<script type="math/tex; mode=display">
- y_iw^T x_i > 0</script><p>那么，我们得出，我们可以通过  $- y_iw^Tx_i &gt; 0$ 来得出一个点是不是误分类点。</p>
<h3><span id="2-损失函数">2.  损失函数</span></h3><p>感知机中采用的损失函数是<strong>误分类点到超平面S的总距离。</strong></p>
<p>输入样本中的任意一点到超平面S的距离：</p>
<script type="math/tex; mode=display">
L = \frac{1}{||w||}|w^T x_i|  , \qquad  ||w||是w的L_2范数</script><p>那么误分类点到超平面 S 的距离为：</p>
<script type="math/tex; mode=display">
- \frac{1}{||w||}y_i(w^T x_i)</script><p>$\frac{1}{||w||}$ 是一个固定值，可以不用考虑，这样我们也可以得出我们的<strong>损失函数</strong>如下：</p>
<script type="math/tex; mode=display">
L(w,b) = - \sum_{x_i \in M  }{y_i w^Tx_i }</script><h3><span id="3-求取w-b">3. 求取w， b</span></h3><p>损失函数对于 $w$ 方向上的梯度为：</p>
<script type="math/tex; mode=display">
\frac{\partial {L}}{\partial{w}} = - \sum_{x_i \in M} y_i x_i</script><p>那么随便给定一个误分类点$(x_i, y_i)$， 对w，b的更新如下：</p>
<script type="math/tex; mode=display">
w \leftarrow  w + \eta y_i x_i</script><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>分类模型1-朴素贝叶斯</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B4%20-%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-基本概念">1. 基本概念</a><ul>
<li><a href="#1-条件概率">1. 条件概率</a></li>
<li><a href="#2-先验概率">2. 先验概率</a></li>
<li><a href="#3-后验概率">3. 后验概率</a></li>
</ul>
</li>
<li><a href="#2-贝叶斯公式">2. 贝叶斯公式</a></li>
<li><a href="#3-条件独立假设">3. 条件独立假设</a></li>
<li><a href="#4-从机器学习视角理解朴素贝叶斯">4. 从机器学习视角理解朴素贝叶斯</a></li>
<li><a href="#朴素贝叶斯中的三种模型">朴素贝叶斯中的三种模型</a><ul>
<li><a href="#1-多项式模型">1. 多项式模型</a></li>
<li><a href="#2-高斯模型">2. 高斯模型</a></li>
<li><a href="#3-伯努利模型">3. 伯努利模型</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-朴素贝叶斯为何朴素">1. 朴素贝叶斯为何朴素？</a></li>
<li><a href="#2-朴素贝叶斯分类中某个类别的概率为0怎么办">2. 朴素贝叶斯分类中某个类别的概率为0怎么办？</a></li>
<li><a href="#3-朴素贝叶斯的要求是什么">3. 朴素贝叶斯的要求是什么？</a></li>
<li><a href="#4-朴素贝叶斯的优缺点">4. 朴素贝叶斯的优缺点？</a></li>
<li><a href="#5-朴素贝叶斯与-lr-区别">5. 朴素贝叶斯与 LR 区别？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-基本概念">1. 基本概念</span></h2><h3><span id="1-条件概率">1. 条件概率</span></h3><script type="math/tex; mode=display">
P(X|Y) =  \frac{P(X,Y)}{P(Y)}</script><ul>
<li>$P(X|Y)$含义： 表示 y 发生的条件下 x 发生的概率。</li>
</ul>
<h3><span id="2-先验概率">2. 先验概率</span></h3><ul>
<li>含义： <strong>表示事件发生前的预判概率。</strong>这个可以是基于历史数据统计，也可以由背景常识得出，也可以是主观观点得出。一般都是单独事件发生的概率，如 P(A)</li>
</ul>
<h3><span id="3-后验概率">3. 后验概率</span></h3><ul>
<li>基于先验概率求得的<strong>反向条件概率</strong>，形式上与条件概率相同（若 <code>P(X|Y)</code> 为正向，则 <code>P(Y|X)</code> 为反向）</li>
</ul>
<h2><span id="2-贝叶斯公式">2. 贝叶斯公式</span></h2><p>贝叶斯公式如下：</p>
<script type="math/tex; mode=display">
P(Y|X) = \frac{P(X|Y) P(Y)}{P(X)}  \\</script><blockquote>
<ul>
<li>P(Y) 叫做<strong>先验概率</strong>，意思是事件X发生之前，我们对事件Y发生的一个概率的判断</li>
<li>P(Y|X) 叫做<strong>后验概率</strong>，意思是时间X发生之后，我们对事件Y发生的一个概率的重新评估</li>
<li>P(Y,X) 叫做<strong>联合概率</strong>， 意思是事件X与事件Y同时发生的概率。</li>
</ul>
</blockquote>
<h2><span id="3-条件独立假设">3. 条件独立假设</span></h2><script type="math/tex; mode=display">
P(x|c) = p(x_1, x_2,  \cdots x_n | c) = \prod_{i=1}^Np(x_i | c)</script><p>朴素贝叶斯采用条件独立假设的动机在于： <strong>简化运算。</strong></p>
<h2><span id="4-从机器学习视角理解朴素贝叶斯">4. 从机器学习视角理解朴素贝叶斯</span></h2><p><strong>朴素贝叶斯 = 贝叶斯方法 + 条件独立假设。</strong></p>
<p>在机器学习中，我们可以将 X 理解为“具有某特征”， 而 Y 理解为“类别标签”，于是有：</p>
<script type="math/tex; mode=display">
P("属于某类“ \, \, | \, \, "具有某特征" ) = \frac{P("具有某特征" | "属于某类") P("属于某类")}{P("具有某特征" )}</script><p>而贝叶斯派目的是要对 Y 进行优化：</p>
<script type="math/tex; mode=display">
\begin{align}
Y_{MAP} &= argmax_y P(Y|X)  \\
&= argmax_y \frac{P(X,Y)}{P(X)} \\
&= argmax_y P(Y) P(X|Y)
\end{align}</script><h2><span id="朴素贝叶斯中的三种模型">朴素贝叶斯中的三种模型</span></h2><h3><span id="1-多项式模型">1.  多项式模型</span></h3><p>多项式模型适用于离散特征情况，在文本领域应用广泛， 其基本思想是：<strong>我们将重复的词语视为其出现多次</strong>。</p>
<h3><span id="2-高斯模型">2. 高斯模型</span></h3><p><a href="https://blog.csdn.net/u012162613/article/details/48323777">https://blog.csdn.net/u012162613/article/details/48323777</a></p>
<p><a href="http://www.letiantian.me/2014-10-12-three-models-of-naive-nayes/">http://www.letiantian.me/2014-10-12-three-models-of-naive-nayes/</a></p>
<p>高斯模型适合<strong>连续特征情况</strong>， 我们先给出高斯公式：</p>
<script type="math/tex; mode=display">
P(x_{i}|y_{k}) = \frac{1}{\sqrt{2\pi\sigma_{y_{k}}^{2}}}exp( -\frac{(x_{i}-\mu_{y_{k}})^2}  {2\sigma_{y_{k}}^{2}}   )</script><h3><span id="3-伯努利模型">3. 伯努利模型</span></h3><blockquote>
<p>伯努利模型适用于离散特征情况，它将重复的词语都视为只出现一次。</p>
<script type="math/tex; mode=display">
P( " 代开“， ”发票“， ”发票“， ”我“ | S) = P("代开" | S)   P( ”发票“ | S) P("我" | S)</script><p>我们看到，”发票“出现了两次，但是我们只将其算作一次。</p>
</blockquote>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-朴素贝叶斯为何朴素">1. 朴素贝叶斯为何朴素？</span></h3><p>朴素贝叶斯的朴素性体现在该算法基于一个简单的假设： <strong>所有的变量都是相互独立的</strong>，用贝叶斯公式表达如下：</p>
<script type="math/tex; mode=display">
P(Y|X_1, X_2) = \frac{P(X_1|Y) P(X_2|Y) P(Y)}{P(X_1)P(X_2)}</script><p><strong>而在很多情况下，所有变量几乎不可能满足两两之间的条件。</strong></p>
<h3><span id="2-朴素贝叶斯分类中某个类别的概率为0怎么办">2. 朴素贝叶斯分类中某个类别的概率为0怎么办？</span></h3><p><strong>问题：</strong> 如下，A1,A2,A3是三个特征，Y是分类结果。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">A1</th>
<th style="text-align:center">A2</th>
<th style="text-align:center">A3</th>
<th style="text-align:center">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">P(Y=0) = 3/5</span><br><span class="line">P(Y=1) = 2/5</span><br><span class="line">P(Y=0|A1=1,A2=0,A3=0) = 3/5 * 1/3 * 2/3 * 1/3 = 2/45</span><br><span class="line">P(Y=1|A1=1,A2=0,A3=0) = 2/5 * 1/2 * 1/4 * 1/2 = 1/40</span><br></pre></td></tr></table></figure>
<p>答案是 <strong>拉普拉斯平滑</strong>。</p>
<h3><span id="3-朴素贝叶斯的要求是什么">3. 朴素贝叶斯的要求是什么？</span></h3><ul>
<li>贝叶斯定理</li>
<li>特征条件独立假设</li>
</ul>
<h3><span id="4-朴素贝叶斯的优缺点">4. 朴素贝叶斯的优缺点？</span></h3><ul>
<li>优点： 对小规模数据表现很好，适合多分类任务，适合增量式训练。</li>
<li>缺点：对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）。</li>
</ul>
<h3><span id="5-朴素贝叶斯与-lr-区别">5. 朴素贝叶斯与 LR 区别？</span></h3><ul>
<li>朴素贝叶斯是生成模型，根据已有样本进行贝叶斯估计学习出先验概率 P(Y) 和条件概率 P(X|Y)，进而求出联合分布概率 P(XY)，最后利用贝叶斯定理求解P(Y|X)， 而LR是判别模型，根据极大化对数似然函数直接求出条件概率 P(Y|X)</li>
<li>朴素贝叶斯是基于很强的<strong>条件独立假设</strong>（在已知分类Y的条件下，各个特征变量取值是相互独立的），而 LR 则对此没有要求</li>
<li>朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>分类模型1-随机森林</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B5%20-%20%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="随机森林">随机森林</span></h1><hr>
<!-- toc -->
<ul>
<li><a href="#1-bagging">1. Bagging</a></li>
<li><a href="#2-随机森林">2. 随机森林</a><ul>
<li><a href="#1-原理">1. 原理</a></li>
<li><a href="#2-影响因素">2. 影响因素</a></li>
<li><a href="#3-特征-m-的选择">3. 特征 m 的选择</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-随机森林的过拟合如何解决">1. 随机森林的过拟合如何解决？</a></li>
<li><a href="#2-随机怎了如何处理缺失值">2. 随机怎了如何处理缺失值？</a></li>
<li><a href="#3-什么是-oob">3. 什么是 OOB？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-bagging">1. Bagging</span></h2><ul>
<li>思想：总体样本当中随机取一部分样本进行训练，通过多次这样的结果，进行投票获取平均值作为结果输出，这就极大可能的避免了不好的样本数据，从而提高准确度。因为有些是不好的样本，相当于噪声，模型学入噪声后会使准确度不高。</li>
<li>举例：假设有1000个样本，如果按照以前的思维，是直接把这1000个样本拿来训练，但现在不一样，先抽取800个样本来进行训练，假如噪声点是这800个样本以外的样本点，就很有效的避开了。重复以上操作，提高模型输出的平均值。</li>
</ul>
<h2><span id="2-随机森林">2. 随机森林</span></h2><h3><span id="1-原理">1. 原理</span></h3><p>随机森立是 Bagging 的优化版本。其包含的思想在于： <strong>随机选择样本数建立多个训练集并随机选取特征集合，根据多个训练集与特征集合来建立多颗决策树，然后进行投票决策。</strong></p>
<p>随机森林的最终目的是建立 m 颗决策树，而每颗决策树的建立过程如下：</p>
<ul>
<li>如果训练集大小为N，对于每棵树而言，<strong>随机</strong>且有放回地从训练集中的抽取N个训练样本，作为该树的训练集。</li>
<li>如果每个样本的特征维度为M，指定一个常数m&lt;&lt;M，<strong>随机</strong>地从M个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的</li>
<li>每棵树都尽最大程度的生长，并且没有剪枝过程。</li>
</ul>
<p>随机森林中的随性性指的是：<strong>数据采样的随机性与特征采用的随机性。</strong> 这两个随机性的引入对随机森林的分类性能直观重要，它们使得随机森林不容易陷入过拟合，且具有很好的抗噪能力。</p>
<h3><span id="2-影响因素">2. 影响因素</span></h3><ul>
<li>森林中任意两棵树的相关性： 相关性越大，错误率越大</li>
<li>森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。</li>
</ul>
<h3><span id="3-特征-m-的选择">3. 特征 m 的选择</span></h3><p>m 是随机森林中唯一的一个参数。</p>
<ul>
<li>减小特征选择个数m，树的相关性和分类能力也会相应的降低</li>
<li>增大m，两者也会随之增大。</li>
</ul>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-随机森林的过拟合如何解决">1. 随机森林的过拟合如何解决？</span></h3><p>通过交叉验证来调整树的数量。</p>
<h3><span id="2-随机怎了如何处理缺失值">2. 随机怎了如何处理缺失值？</span></h3><ul>
<li>首先，给缺失值预设一些估计值， 如平均数，中位数等</li>
<li>然后，根据估计的数值，建立随机森林，把所有的数据放进随机森林里面跑一遍。记录每一组数据在决策树中一步一步分类的路径.</li>
<li>判断哪组数据和缺失数据路径最相似，引入一个相似度矩阵，来记录数据之间的相似度，比如有N组数据，相似度矩阵大小就是N*N</li>
<li>如果缺失值是类别变量，通过权重投票得到新估计值，如果是数值型变量，通过加权平均得到新的估计值，如此迭代，直到得到稳定的估计值。</li>
</ul>
<h3><span id="3-什么是-oob">3. 什么是 OOB？</span></h3><p>OOB 即 out-of-bag ， 又称袋外数据。 这是由于 Bagging 方法会采用 Boostrap 进行抽样， 每次约有 $\frac{1}{3}$ 的样本不会出现在抽样后的样本集合中，那么就把这 $\frac{1}{3}$ 的样本称为袋外数据 oob(out-of-bag)。由于 oob 没有用于训练决策树，因此可用于后续对该决策树的泛化能力评估。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>分类模型1-SVM</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B6%20-%20SVM/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#简介">简介</a></li>
<li><a href="#基础准备">基础准备</a><ul>
<li><a href="#1-线性可分">1. 线性可分</a></li>
<li><a href="#2-最大间隔超平面">2. 最大间隔超平面</a></li>
<li><a href="#3-什么是支持向量">3. 什么是支持向量？</a></li>
<li><a href="#4-svm-能解决哪些问题">4. SVM 能解决哪些问题？</a></li>
<li><a href="#5-支持向量机的分类">5. 支持向量机的分类</a></li>
</ul>
</li>
<li><a href="#硬间隔-svm">硬间隔 SVM</a><ul>
<li><a href="#0-几何间隔与函数间隔">0. 几何间隔与函数间隔</a></li>
<li><a href="#1-svm-最优化问题">1. SVM 最优化问题</a></li>
<li><a href="#2-对偶问题">2. 对偶问题</a><ul>
<li><a href="#1-拉格朗日乘数法-等式约束优化问题">1. 拉格朗日乘数法 - 等式约束优化问题</a></li>
<li><a href="#2-拉格朗日乘数法-不等式约束优化问题">2. 拉格朗日乘数法 - 不等式约束优化问题</a></li>
</ul>
</li>
<li><a href="#3-引入对偶问题-todo">3. 引入对偶问题 — TODO</a></li>
<li><a href="#4-svm-优化">4. SVM 优化</a></li>
<li><a href="#2-软间隔svm">2. 软间隔SVM</a></li>
</ul>
</li>
<li><a href="#3-kernel-svm">3. Kernel SVM</a><ul>
<li><a href="#1-思想">1. 思想</a></li>
<li><a href="#2-核函数的作用">2. 核函数的作用</a></li>
<li><a href="#2-常见核函数">2. 常见核函数</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-svm-中的支持向量是什么意思">1. SVM 中的支持向量是什么意思？</a></li>
<li><a href="#2-什么是svm">2. 什么是SVM ？</a></li>
<li><a href="#3-svm-为何采用间隔最大化">3. SVM 为何采用间隔最大化？</a></li>
<li><a href="#4-为何要讲求解-svm-的原始问题转换为其对偶问题">4. 为何要讲求解 SVM 的原始问题转换为其对偶问题？</a></li>
<li><a href="#5-svm-与-lr-的区别">5. SVM 与 LR 的区别</a></li>
<li><a href="#6-svm如何处理多分类问题">6. SVM如何处理多分类问题？</a></li>
<li><a href="#5-svm-软间隔与硬间隔表达式">5. SVM 软间隔与硬间隔表达式</a></li>
<li><a href="#11-核函数的种类和应用场景">11. 核函数的种类和应用场景</a></li>
<li><a href="#12-svm-损失函数是什么">12. SVM 损失函数是什么？</a></li>
<li><a href="#13-核函数的作用是啥">13. 核函数的作用是啥？</a></li>
<li><a href="#14-svm-为何能用对偶函数求解">14. SVM 为何能用对偶函数求解？</a></li>
<li><a href="#15-svm-和全部数据有关还是和局部数据有关">15. SVM 和全部数据有关还是和局部数据有关?</a></li>
<li><a href="#16-为什么高斯核能够拟合无穷维度">16. 为什么高斯核能够拟合无穷维度？</a></li>
<li><a href="#17-lr-与-svm-的区别">17. LR 与 SVM 的区别？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="简介">简介</span></h2><p><a href="https://zhuanlan.zhihu.com/p/77750026">https://zhuanlan.zhihu.com/p/77750026</a></p>
<p>SVM 三宝： <strong>间隔，对偶，核技巧</strong>。它属于<strong>判别模型</strong>。Support Vector Machine</p>
<ul>
<li><strong>支持向量：</strong>在求解的过程中，会发现只根据部分数据就可以确定分类器，这些数据称为支持向量。</li>
<li><strong>支持向量机（SVM）</strong>：其含义是通过<strong>支持向量</strong>运算的分类器。</li>
</ul>
<p>SVM 是一种<strong>二分类模型</strong>， 它的目的是寻找一个超平面来对样本进行分割，分割的依据是<strong>间隔最大化</strong>，最终转化为一个<strong>凸二次规划问题</strong>来求解。</p>
<h2><span id="基础准备">基础准备</span></h2><h3><span id="1-线性可分">1. 线性可分</span></h3><p>$D_0$ 和 $D_1$ 是 n 维空间中的两个点集， 如果存在 n 维向量 $w$ 和实数 $b$ ， 使得：</p>
<script type="math/tex; mode=display">
wx_i +b > 0; \quad x_i \in D_0 \\
wx_j + b < 0; \quad x_j \in D_1</script><p>则称 $D_0$ 与 $D_1$ 线性可分。</p>
<h3><span id="2-最大间隔超平面">2. 最大间隔超平面</span></h3><p>能够将 $D_0$  与 $D_1$ 完全正确分开的 $wx+b = 0$ 就成了一个超平面。</p>
<p>为了使得这个超平面更具鲁棒性，我们会去找最佳超平面，以最大间隔把两类样本分开的超平面，也称之为<strong>最大间隔超平面</strong>。</p>
<ul>
<li>两类样本分别分割在该超平面的两侧</li>
<li>两侧距离超平面最近的样本点到超平面的距离被最大化了</li>
</ul>
<h3><span id="3-什么是支持向量">3. 什么是支持向量？</span></h3><p><strong>训练数据集中与分离超平面距离最近的样本点成为支持向量</strong></p>
<p><img data-src="..\img\SVM\1.jpg" alt="1"></p>
<h3><span id="4-svm-能解决哪些问题">4. SVM 能解决哪些问题？</span></h3><ul>
<li><p><strong>线性分类：</strong>对于n维数据，SVM 的目标是找到一个 n-1 维的最佳超平面来将数据分成两部分。 </p>
<p>通过增加一个约束条件： <strong>要求这个超平面到每边最近数据点的距离是最大的。</strong></p>
</li>
<li><p><strong>非线性分类：</strong> SVM通过结合使用<strong>拉格朗日乘子法</strong>和KTT条件，以及<strong>核函数</strong>可以生产线性分类器</p>
</li>
</ul>
<h3><span id="5-支持向量机的分类">5. 支持向量机的分类</span></h3><ul>
<li><strong>硬间隔SVM（线性可分SVM)</strong>： 当训练数据可分时，通过间隔最大化，学习一个线性表分类器。</li>
<li><strong>软间隔SVM(线性SVM)</strong>：当训练数据接近线性可分时，通过软间隔最大化，学习一个线性分类器。</li>
<li><strong>Kernel SVM</strong>： 当训练数据线性不可分时，通过使用<strong>核技巧及软间隔最大化</strong>，学习非线性SVM。</li>
</ul>
<p>必会：硬间隔最大化 —&gt; 学习的对偶问题 —&gt; 软间隔最大化 —&gt; 非线性支持向量机（核技巧）</p>
<h2><span id="硬间隔-svm">硬间隔 SVM</span></h2><h3><span id="0-几何间隔与函数间隔">0. 几何间隔与函数间隔</span></h3><h3><span id="1-svm-最优化问题">1. SVM 最优化问题</span></h3><p>任意分离超平面可定义为：</p>
<script type="math/tex; mode=display">
w^Tx + b = 0</script><p>二维空间中点 $(x,y)$ 到直线 $Ax + By + C=0$ 的距离公式为：</p>
<script type="math/tex; mode=display">
\frac{|Ax+ By + C}{\sqrt{A^2 + B^2}}</script><p>扩展到n维空间中，任意点 $x$  到超平面$w^Tx + b = 0$ 的距离为：</p>
<script type="math/tex; mode=display">
\frac{|w^Tx + b|}{||w||} \\
||w|| = \sqrt{w_1^2 + ... + w_n^2}</script><p>假设，支持向量到超平面的距离为 $d$ ，那么就有：</p>
<script type="math/tex; mode=display">
\begin{cases} \frac{w^Tx_i + b}{||w||} \geq d, & y_i = +1 \\ \frac{w^Tx_i + b}{||w||} \leq -d, & y_i = -1 \end{cases}</script><p>稍作转化可得到：</p>
<script type="math/tex; mode=display">
\begin{cases} \frac{w^Tx_i + b}{||w||d} \geq 1, & y_i = +1 \\ \frac{w^Tx_i + b}{||w||d} \leq -1, & y_i = -1 \end{cases}</script><p>考虑到 $||w||d$ 为正数，我们暂且令它为 1（之所以令它等于 1，是为了方便推导和优化，且这样做对目标函数的优化没有影响）：</p>
<script type="math/tex; mode=display">
\begin{cases} w^Tx_i + b >= +1, & y_i = +1 \\ w^Tx_i + b <= -1, & y_i = -1 \end{cases}</script><p>两个方程合并，则有：</p>
<script type="math/tex; mode=display">
y_i (w^Tx_i + b) \geq 1</script><p>那么我们就得到了最大间隔超平面的上下两个超平面：</p>
<p><img data-src="..\img\SVM\2.jpg" alt="2"></p>
<p>两个异类超平面的公式分别为：</p>
<script type="math/tex; mode=display">
\begin{cases} w^Tx_i + b = +1, & y_i = +1 \\ w^Tx_i + b = -1, & y_i = -1 \end{cases}</script><p>那么两个异类超平面之间的间隔为：</p>
<script type="math/tex; mode=display">
\frac{2}{||w||}</script><p>我们的目的是最大化这种间隔：</p>
<script type="math/tex; mode=display">
\begin{align}
max \quad \frac{2}{||w||} &:= min \quad \frac{1}{2} ||w|| \\
&:= min \quad \frac{1}{2} ||w||^2
\end{align}</script><p>那么我们的最优化问题为：</p>
<script type="math/tex; mode=display">
min \quad \frac{1}{2} ||w||^2 \quad \\ st. y_i(w^Tx_i + b) \geq 1</script><h3><span id="2-对偶问题">2. 对偶问题</span></h3><h4><span id="1-拉格朗日乘数法-等式约束优化问题">1. 拉格朗日乘数法 - 等式约束优化问题</span></h4><p>高等数学中，其等式约束优化问题为：</p>
<script type="math/tex; mode=display">
min \, f(x_1, ..., x_n) \quad  st. \quad h_k(x_1, ... , x_n) = 0</script><p>那么令：</p>
<script type="math/tex; mode=display">
L(x, \lambda) = f(x) + \sum_{k=1}^l \lambda_k h_k(x)</script><ul>
<li>$L(x, \lambda)$ ： Lagrange 函数</li>
<li>$\lambda$ ： Lagrange 乘子，没有非负要求</li>
</ul>
<p>利用必要条件找到可能的极值点，我们得到如下的方程组：</p>
<script type="math/tex; mode=display">
\begin{cases} 
\frac{\delta L}{ \delta x_i} = 0, & i=1,2,...,n \\ 
\frac{\delta L}{ \delta \lambda_k} = 0, & k=1,2,...,l
\end{cases}</script><p>等式约束下的Lagrange 乘数法引入了 $l$ 个 Lagrange 乘子，我们将 $x_i$ 与 $\lambda_k$ 一视同仁，将$\lambda_k$ 也看做优化变量，那么共有 $(n+l)$ 个优化变量。</p>
<h4><span id="2-拉格朗日乘数法-不等式约束优化问题">2. 拉格朗日乘数法 - 不等式约束优化问题</span></h4><p>对于不等式约束优化问题，其主要思想在于<strong>将不等式约束条件转变为等式约束条件，引入松弛变量，将松弛变量也是为优化变量。</strong></p>
<p><img data-src="..\img\SVM\3.jpg" alt="3"></p>
<p>对于我们的问题：</p>
<script type="math/tex; mode=display">
min \quad \frac{1}{2} ||w||^2 \quad \\ st. \quad  g_i(w) = 1- y_i(w^Tx_i + b) \leq 0</script><p>引入松弛变量 $a_i^2$ 得到：</p>
<script type="math/tex; mode=display">
f(w) =  \frac{1}{2} ||w||^2 \\
g_i(w) = 1- y_i(w^Tx_i + b)  \\
h_i(w, a_i) = g_i(w) + a_i^2 = 0</script><p>这里加平方主要为了不再引入新的约束条件，如果只引入 $a_i$ 那我们必须要保证 $a_i \geq 0$ 才能保证 $h_i(w, a_i)$ ，这不符合我们的意愿。</p>
<p>此时，我们就将不等式约束转化为等式约束，并得到 Lagrange 函数：</p>
<script type="math/tex; mode=display">
\begin{align}
L(w, \lambda, a) &= \frac{1}{2} f(w) + \sum_{i=1}^n \lambda_i h_i(w) \\
&= \frac{1}{2} f(w) + \sum_{i=1}^n \lambda_i [g_i(w) + a_i^2] \quad \lambda_i \geq 0
\end{align}</script><p>那么我们得到方程组有：</p>
<script type="math/tex; mode=display">
\begin{cases} 
\frac{\delta L}{ \delta w_i} =\frac{\delta f}{\delta w_i} + \sum_{i=1}^n \lambda_i \frac{\delta g_i}{\delta w_i} =0 \\ 
\frac{\delta L}{ \delta a_i} = 2 \lambda_i a_i =0 \\
\frac{\delta L}{ \delta \lambda_i}=g_i(w) + a_i^2 = 0 \\
\lambda_i \geq 0  \qquad ？ 需要看一看
\end{cases}</script><p>针对 $\lambda_i a_i = 0$ 有两种情况：</p>
<ul>
<li><p>$\lambda_i = 0, a_i \neq 0$：此时约束条件 $g_i(w)$ 不起作用且 $g_i(w) &lt; 0$ </p>
</li>
<li><p>$\lambda_i \neq 0, a_i = 0$： 此时 $g_i(w)=0, \lambda_i &gt; 0$， 可以理解为约束条件 $g_i(w)$ 起作用了， 且$g_i(w) = 0$</p>
</li>
</ul>
<p>综合可得：$\lambda_ig_i(w) = 0$， 且在约束条件起作用时 $\lambda_i &gt; 0, g_i(w) = 0 $； 约束不起作用时， $\lambda_i = 0, g_i(w) &lt; 0 $。</p>
<p>此时，方程组转化为：</p>
<script type="math/tex; mode=display">
\begin{cases} 
\frac{\delta L}{ \delta w_i} =\frac{\delta f}{\delta w_i} + \sum_{i=j}^n \lambda_j \frac{\delta g_i}{\delta w_i} =0 \\ 
\lambda_ig_i(w) = 0 \\
g_i(w) \leq 0 \\
\lambda_i \geq 0
\end{cases}</script><p>以上便是不等式约束优化优化问题的 <strong>KKT(Karush-Kuhn-Tucker) 条件</strong>， $\lambda_i$ 称为 KKT 乘子。</p>
<p>KTT 条件中，对于不同样本点来说</p>
<ul>
<li>支持向量 $g_i(w) = 0$， 此时 $\lambda_i &gt; 0$ 即可</li>
<li>其余向量 $g_i(w) &lt; 0$， 此时 $\lambda_i = 0$</li>
</ul>
<p>回到原优化问题中：</p>
<script type="math/tex; mode=display">
\begin{align}
L(w, \lambda, a) &= \frac{1}{2} f(w) + \sum_{i=1}^n \lambda_i h_i(w) \\
&= \frac{1}{2} f(w) + \sum_{i=1}^n \lambda_i [g_i(w) + a_i^2] \\
&= \frac{1}{2} f(w) + \sum_{i=1}^n \lambda_i g_i(w) + \sum_{i=1}^n \lambda_i a_i^2
\end{align}</script><p>由于 $\sum_{i=1}^n \lambda_ia_i^2 \geq 0$， 那么问题可以转化为：</p>
<script type="math/tex; mode=display">
\begin{align}
L(w, \lambda) &=  \frac{1}{2} f(w) + \sum_{i=1}^n \lambda_i g_i(w) \\
&=  \frac{1}{2} ||w||^2 + \sum_{i=1}^n \lambda_i (1- y_i(w^Tx_i + b) )
\end{align}</script><p>假设我们找到了最佳的参数 $w$ 使得 $\frac{1}{2} ||w||^2 = p$ ，又因为 $\sum_{i=1}^n \lambda_i (1- y_i(w^Tx + b) ) \leq 0$， 因此有 $L(w, \lambda) \leq p$， 我们需要找到最佳的参数 $\lambda$， 使得 $L(w, \lambda)$ 接近 p， 此时问题转化为：</p>
<script type="math/tex; mode=display">
min_wmax_{\lambda} \, L(w, \lambda) \quad \\ s.t. \quad \lambda_i \geq 0</script><h3><span id="3-引入对偶问题-todo">3. 引入对偶问题 — TODO</span></h3><ul>
<li><p>弱对偶性： 最大的里面挑出来的最小的也要比最小的里面挑出来的最大的要大</p>
<script type="math/tex; mode=display">
min \, max \, f \geq max \, min \, f</script></li>
<li><p>强对偶性：KKT 条件是强对偶性的充要条件。</p>
</li>
</ul>
<h3><span id="4-svm-优化">4. SVM 优化</span></h3><ul>
<li>SVM 的优化问题为：<script type="math/tex; mode=display">
min \quad \frac{1}{2} ||w||^2 \quad \\ st. \quad  g_i(w) = 1- y_i(w^Tx_i + b) \leq 0</script></li>
</ul>
<ul>
<li><p>构造拉格朗日函数：</p>
<script type="math/tex; mode=display">
min_{w,b}max_{\lambda} L(w, b, \lambda) = \frac{1}{2} ||w||^2 + \sum_{i=1}^n \lambda_i (1- y_i(w^Tx_i + b) ) \\
s.t. \lambda_i \geq 0</script></li>
<li><p>利用强对偶性转化：</p>
<script type="math/tex; mode=display">
max_{\lambda}min_{w,b} \, L(w, b, \lambda)</script><p>对参数 $w, b$ 求偏导有：</p>
<script type="math/tex; mode=display">
\frac{\delta L}{\delta w} = w - \sum_{i=1}^n \lambda_i x_i y_i = 0 \\
\frac{\delta L}{\delta b} = \sum_{i=1}^n \lambda_i y_i = 0</script><p>得到：</p>
<script type="math/tex; mode=display">
w =  \sum_{i=1}^n \lambda_i x_i y_i \\
\sum_{i=1}^n \lambda_i y_i = 0</script><p>将两式带入到 $L(w, b, \lambda)$ 中有：</p>
<script type="math/tex; mode=display">
\begin{align}
min_{w,b} \, L(w, b, \lambda) &=\sum_{j=1}^n \lambda_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \lambda_i \lambda_j y_i y_j x_i^Tx_j
\end{align}</script></li>
<li><p>求解模型：</p>
</li>
</ul>
<h3><span id="2-软间隔svm">2. 软间隔SVM</span></h3><p>软间隔允许部分样本点不满足约束条件：</p>
<script type="math/tex; mode=display">
1 - y_i (w^Tx_i + b) \leq 0</script><h2><span id="3-kernel-svm">3. Kernel SVM</span></h2><h3><span id="1-思想">1. 思想</span></h3><p><strong>对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。</strong></p>
<p>用 x 表示原来的样本点，用 $\phi(x)$ 表示 x 映射到新特征空间后的新向量。那么分割超平面可以表示为：</p>
<script type="math/tex; mode=display">
f(x) = w \phi (x) + b</script><p>此时，非线性 SVM 的对偶问题转化为：</p>
<script type="math/tex; mode=display">
min_{\lambda} [\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^n  ]</script><h3><span id="2-核函数的作用">2. 核函数的作用</span></h3><ul>
<li>目的： 将原坐标系中线性不可分数据通过核函数映射到另一空间，尽量使数据在新的空间里线性可分。</li>
</ul>
<h3><span id="2-常见核函数">2. 常见核函数</span></h3><ul>
<li>线性核函数：<script type="math/tex; mode=display">
K(x_i, x_j)</script></li>
</ul>
<h2><span id="qa">QA</span></h2><h3><span id="1-svm-中的支持向量是什么意思">1. SVM 中的支持向量是什么意思？</span></h3><p><img data-src="..\img\10.svm.png" alt="10.svm"></p>
<p> 如上图所示，我们在获得分离超平面时，并非所有的点都对分离超平面的位置起决定作用。</p>
<p>其实在特别远的区域，哪怕你增加10000个样本点，对于超平面的位置，也是没有作用的，因为分割线是由几个关键点决定的（图上三个），这几个关键点支撑起了一个分离超平面，所以这些关键点，就是<strong>支持向量</strong>。</p>
<h3><span id="2-什么是svm">2.  什么是SVM ？</span></h3><p>SVM 是一种二类分类模型。它的基本思想是在特征空间中寻找间隔最大的分离超平面使数据得到高效的二分类， 主要分三种情况：</p>
<ul>
<li>当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；</li>
<li>当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机</li>
<li>当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。</li>
</ul>
<h3><span id="3-svm-为何采用间隔最大化">3. SVM 为何采用间隔最大化？</span></h3><p>当训练数据线性可分时，存在无穷个分离超平面可以将两类数据正确分开。</p>
<ul>
<li>感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。</li>
<li>线性可分支持向量机利用间隔最大化求得最优分离超平面，这时，解是唯一的。</li>
</ul>
<p>SVM 求得的分隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。</p>
<h3><span id="4-为何要讲求解-svm-的原始问题转换为其对偶问题">4. 为何要讲求解 SVM 的原始问题转换为其对偶问题？</span></h3><ul>
<li><p>对偶问题往往更易求解</p>
<p>当我们寻找约束存在时的最优点的时候，约束的存在虽然减小了需要搜寻的范围，但是却使问题变得更加复杂。为了使问题变得易于处理，我们的方法是把目标函数和约束全部融入一个新的函数，即拉格朗日函数，再通过这个函数来寻找最优点。</p>
</li>
<li><p>自然引入核函数，进而推广到非线性分类问题</p>
</li>
</ul>
<h3><span id="5-svm-与-lr-的区别">5. SVM 与 LR 的区别</span></h3><ul>
<li>LR是参数模型，SVM为非参数模型。</li>
<li>LR采用的损失函数为logisticalloss，而SVM采用的是hingeloss。</li>
<li>在学习分类器的时候，SVM只考虑与分类最相关的少数支持向量点。</li>
<li>LR的模型相对简单，在进行大规模线性分类时比较方便。</li>
</ul>
<h3><span id="6-svm如何处理多分类问题">6. SVM如何处理多分类问题？</span></h3><ul>
<li>直接法：直接在目标函数上修改，将多个分类面的参数求解合并到一个最优化问题里面。看似简单但是计算量却非常的大。</li>
<li>间接法：对训练器进行组合。其中比较典型的有一对一，和一对多。</li>
</ul>
<p>一对多： 对每个类都训练出一个分类器，由svm是二分类，所以将此而分类器的两类设定为目标类为一类，其余类为另外一类。这样针对k个类可以训练出k个分类器，当有一个新的样本来的时候，用这k个分类器来测试，那个分类器的概率高，那么这个样本就属于哪一类。这种方法效果不太好，bias 比较高。</p>
<p>一对一： 针对任意两个类训练出一个分类器，如果有 k 类，一共训练出 $C_k^2$ 个分类器，这样当有一个新的样本要来的时候，用这 $C_k^2$ 个分类器来测试，每当被判定属于某一类的时候，该类就加一，最后票数最多的类别被认定为该样本的类。</p>
<h3><span id="5-svm-软间隔与硬间隔表达式">5. SVM 软间隔与硬间隔表达式</span></h3><ul>
<li><p>硬间隔：</p>
<script type="math/tex; mode=display">
min_{w,b} \frac{1}{2} ||w||^2 \qquad st. \quad y^{(i)}(w^Tx^{(i)} + b) \geq 1</script></li>
<li><p>软间隔：</p>
<script type="math/tex; mode=display">
min_{w,b} \frac{1}{2} ||w||^2 + C \sum_{i=1}^m \xi_i  \qquad st. \quad y^{(i)}(w^Tx^{(i)} + b) \geq 1 \quad \xi_i \geq 0</script></li>
</ul>
<h3><span id="11-核函数的种类和应用场景">11. 核函数的种类和应用场景</span></h3><ul>
<li>线性核函数：主要用于线性可分的情形。参数少，速度快。</li>
<li>多项式核函数：</li>
<li>高斯核函数：主要用于线性不可分的情形。参数多，分类结果非常依赖于参数。</li>
<li>sigmoid 核函数：</li>
<li>拉普拉斯核函数：</li>
</ul>
<p>如果feature数量很大，跟样本数量差不多，建议使用LR或者 Linear kernel 的SVM。<br>如果 feature 数量较少，样本数量一般，建议使用 Gaussian Kernel 的SVM。</p>
<h3><span id="12-svm-损失函数是什么">12. SVM 损失函数是什么？</span></h3><script type="math/tex; mode=display">
J(\theta) = \frac{1}{2} ||\theta||^2 + C \sum_i max(0, 1-y_i(\theta^Tx_i + b))</script><h3><span id="13-核函数的作用是啥">13. 核函数的作用是啥？</span></h3><p>核函数能够将特征从低维空间映射到高维空间， 这个映射可以把低维空间中不可分的两类点变成线性可分的。</p>
<h3><span id="14-svm-为何能用对偶函数求解">14. SVM 为何能用对偶函数求解？</span></h3><p>对偶将原始问题中的约束转为了对偶问题中的等式约束， 而且更加方便了核函数的引入， 同时也改变了问题的复杂度， 在原始问题下， 求解问题的复杂度只与样本的维度有关， 在对偶问题下， 只与样本的数量有关。</p>
<h3><span id="15-svm-和全部数据有关还是和局部数据有关">15. SVM 和全部数据有关还是和局部数据有关?</span></h3><p>SVM 只和分类界限上的支持向量点有关， 换而言之只和局部数据有关。</p>
<h3><span id="16-为什么高斯核能够拟合无穷维度">16. 为什么高斯核能够拟合无穷维度？</span></h3><p>因为将泰勒展开式代入高斯核，将会得到一个无穷维度的映射。</p>
<h3><span id="17-lr-与-svm-的区别">17. LR 与 SVM 的区别？</span></h3><ul>
<li>LR是参数模型，SVM是非参数模型</li>
<li>从目标函数来看，区别在于逻辑回归采用的是logistical loss，SVM采用的是hinge loss。这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。</li>
<li>SVM的处理方法是只考虑支持向量，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过<strong>非线性映射</strong>，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。</li>
<li>逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后，分类只需要计算与少数几个支持向量的距离，这个在进行复杂核函数计算时优势很明显，能够大大简化模型和计算。</li>
<li>logic 能做的 svm能做，但可能在准确率上有问题，svm能做的logic有的做不了。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>回归模型1-线性回归</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B1%20-%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-线性回归">1. 线性回归</a><ul>
<li><a href="#1-简介">1. 简介</a></li>
<li><a href="#2-线性回归如何训练">2. 线性回归如何训练？</a><ul>
<li><a href="#1-损失函数">1. 损失函数</a></li>
<li><a href="#2-正规方程">2. 正规方程</a></li>
<li><a href="#3-梯度下降法">3. 梯度下降法</a></li>
<li><a href="#4-两种方法的比较">4. 两种方法的比较</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2-岭回归">2. 岭回归</a><ul>
<li><a href="#岭回归与线性回归">岭回归与线性回归</a></li>
</ul>
</li>
<li><a href="#3-lasso-回归">3. Lasso 回归</a></li>
<li><a href="#4-elasticnet-回归">4. ElasticNet 回归</a></li>
<li><a href="#lwr-局部加权回归">LWR - 局部加权回归</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-最小二乘法估计">1. 最小二乘法估计</a></li>
<li><a href="#2-最小二乘法的几何解释">2. 最小二乘法的几何解释</a></li>
<li><a href="#3-从概率角度看最小二乘法">3. 从概率角度看最小二乘法</a></li>
<li><a href="#4-推一下线性回归的反向传播">4. 推一下线性回归的反向传播</a></li>
<li><a href="#5-从贝叶斯角度看线性回归">5. 从贝叶斯角度看线性回归</a></li>
<li><a href="#6-什么时候使用岭回归">6. 什么时候使用岭回归 ？</a></li>
<li><a href="#7-什么时候使用-l1-正则化">7. 什么时候使用 L1 正则化？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-线性回归">1. 线性回归</span></h2><h3><span id="1-简介">1. 简介</span></h3><p>简单来说，线性回归算法就是<strong>找到一条直线（一元线性回归）或一个平面（多元线性回归）能够根据输入的特征向量来更好的预测输出y的值。</strong></p>
<p>其本质含义在于 X 与 Y 是线性相关的。</p>
<script type="math/tex; mode=display">
y = \theta_0 + \theta_1x_1 + \cdots  + \theta_px_p  = \theta^Tx</script><h3><span id="2-线性回归如何训练">2. 线性回归如何训练？</span></h3><p>在线性回归中， 我们可以通过两种方法来求取参数 $\theta$ ， 一种是采用<strong>正规方程</strong>， 一种是采用<strong>梯度下降方法</strong>。 </p>
<h4><span id="1-损失函数">1. 损失函数</span></h4><script type="math/tex; mode=display">
J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2, \qquad  \\ 或 \\ 矩阵表示: J(\theta) = \frac{1}{2m} (X\theta-y)^T(X\theta - y)</script><h4><span id="2-正规方程">2. 正规方程</span></h4><p>我们使用 $J(\theta) $对 $\theta$ 求导， 得到：</p>
<script type="math/tex; mode=display">
\frac{\delta J(\theta)}{\delta \theta} = 2 X^T(X\theta - y)</script><p>令上式为0，我们可以得到 $ \theta$  的值为：</p>
<script type="math/tex; mode=display">
\theta = (X^TX)^{-1}X^Ty</script><p>我们可以直接通过矩阵运算来求出参数 $\theta$  的解。 而上式我们发现其涉及到了矩阵的可逆问题，<strong>如果 $(X^TX)^{-1} $可逆，那么参数 $\theta$ 的解唯一</strong>。 <strong>如果不可逆， 则此时就无法使用正规方程的方法来解。</strong> </p>
<h4><span id="3-梯度下降法">3. 梯度下降法</span></h4><p>我们可以采用批量梯度下降算法， 此时有：</p>
<script type="math/tex; mode=display">
\theta_j = \theta_j - \alpha \frac{\delta}{\delta \theta_j} J(\theta) \\ 带入J(\theta) 得： \theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}  \\ 或矩阵表达：\theta_j = \theta_j + \alpha \frac{1}{m}(y-X\theta)^Tx_j</script><h4><span id="4-两种方法的比较">4. 两种方法的比较</span></h4><ul>
<li>梯度下降中需要选择适当的学习率 $\alpha $</li>
<li>梯度下降法中需要多次进行迭代，而正规方程只需要使用矩阵运算就可以完成</li>
<li>梯度下降算法对多特征适应性较好，能在特征数量很多时仍然工作良好， 而正规方程算法复杂度为 $O(n^3) $，所以<strong>如果特征维度太高（特别是超过 10000 维），那么不宜再考虑该方法。</strong></li>
<li>正规方程中矩阵需要可逆。</li>
</ul>
<h2><span id="2-岭回归">2. 岭回归</span></h2><p>岭回归本质上是 <strong>线性回归 + L2 正则化</strong>。</p>
<script type="math/tex; mode=display">
\hat{h}_{\theta}(x) = h_{\theta}(x) + \lambda \sum_i w_i^2</script><h3><span id="岭回归与线性回归">岭回归与线性回归</span></h3><p>线性回归中通过正规方程得到的 w 的估计：</p>
<script type="math/tex; mode=display">
\hat{w} = (X^TX)^{-1}X^Ty</script><p>但是，当我们有 N 个样本，每个样本有 $x_i \in R^p$， 当 N &lt; p 时， $X^TX$ 不可逆， 无法通过正规方程计算，容易造成过拟合。</p>
<p>岭回归通过在矩阵 $X^TX$ 上加一个 $\lambda I$ 来使得矩阵可逆， 此时的 w 的估计：</p>
<script type="math/tex; mode=display">
\hat{w} = (X^TX + \lambda I)^{-1}X^Ty</script><p>而岭回归本质上是对 $L(w)$  进行 L2 正则化， 此时的 $J(w)$ 表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
J(w) &= \sum_{i=1}^N ||w^Tx_i - y_i ||^2 + \lambda w^Tw \\
&= (w^TX^T - Y^T)(Xw - Y) + \lambda w^Tw \\
&= w^TX^TXw - 2w^TX^TY  + Y^TY + \lambda w^Tw \\
&= w^T(X^TX + \lambda I)w - 2w^TX^TY + Y^TY
\end{align}</script><p>那么对 $w$ 的极大似然估计有：</p>
<script type="math/tex; mode=display">
\hat{w} = argmax \, J(w) \\
\frac{\delta J(w)}{\delta w} = 2(X^TX + \lambda I)w - 2 X^TY = 0</script><p>那么我们就解得：</p>
<script type="math/tex; mode=display">
\hat{w} = (X^TX + \lambda I)^{-1}X^Ty</script><p>因此说， 岭回归本质上是 <strong>线性回归 + L2 正则化</strong>， 从而达到抑制过拟合的效果。</p>
<h2><span id="3-lasso-回归">3. Lasso 回归</span></h2><p>Lasso 回归的本质是 <strong>线性回归 + L1 正则化</strong>。</p>
<script type="math/tex; mode=display">
\hat{h}_{\theta}(x) = h_{\theta}(x) + \lambda \sum_i |w_i|</script><h2><span id="4-elasticnet-回归">4. ElasticNet 回归</span></h2><p>ElasticNet 回归 本质上是线性回归 + L1正则化 + L2 正则化。</p>
<h2><span id="lwr-局部加权回归">LWR - 局部加权回归</span></h2><p>在线性回归中， 由于最终拟合出来的曲线是一条直线，其拟合能力极为有限（也可以解释为线性回归所求的是具有最小均方误差的无偏估计），因此很容易造成欠拟合现象， 而针对这个问题，有人提出了局部线性回归(LWR)。</p>
<p>局部加权回归其思想很简单： 我们对一个输入 w 进行预测时，赋予了 x 周围点不同的权值，距离 x 越近，权重越高。整个学习过程中误差将会取决于 x 周围的误差，而不是整体的误差，这也就是局部一词的由来。</p>
<p>在LWR中， 其损失函数为：</p>
<script type="math/tex; mode=display">
J(\theta) = \frac{1}{2m} \sum_{i=1}^m w^{(i)} (h_\theta(x^{(i)}) - y^{(i)})^2 \\ 矩阵表示: J(\theta) = \frac{1}{2m} (X\theta-y)^TW(X\theta - y)</script><p>此时，使用回归方程求得：</p>
<script type="math/tex; mode=display">
\theta = (X^TWX)^{-1}X^TWy</script><p>而通常， $w^{(i)} $ 服从高斯分布， 在x周围指数型衰减;</p>
<script type="math/tex; mode=display">
w^{(i)} = e^{- \frac{|x^{(i)} - x|}{2 k^2 }}</script><p>其中， <strong>k 值越小，则靠近预测点的权重越大，而远离预测点的权重越小</strong>。所以参数k的值决定了权重的大小。 </p>
<blockquote>
<ul>
<li>k越大权重的差距就越小，k越小权重的差距就很大，仅有局部的点参与进回归系数的求取，其他距离较远的权重都趋近于零。</li>
<li>如果k去进入无穷大，所有的权重都趋近于1，W也就近似等于单位矩阵，局部加权线性回归变成标准的无偏差线性回归，会造成欠拟合的现象；</li>
<li>当k很小的时候，距离较远的样本点无法参与回归参数的求取，会造成过拟合的现象。</li>
</ul>
</blockquote>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-最小二乘法估计">1. 最小二乘法估计</span></h3><script type="math/tex; mode=display">
X = (x_1,  ..., x_N)^T \\
Y = (y_1, ..., y_N)^T</script><script type="math/tex; mode=display">
\begin{align}
L(w) &= \sum_{i=1}^N ||w^Tx_i - y_i ||^2 \\
&= \sum_{i=1}^N (w^Tx_i - y_i)^2 \\
&= \begin{pmatrix} w^Tx_1 - y_1 & ... & w^Tx_N - y_N  \end{pmatrix} \begin{pmatrix} w^Tx_1 - y_1 \\ ... \\ w^Tx_N - y_N  \end{pmatrix}
\end{align}</script><p>其中有：</p>
<script type="math/tex; mode=display">
\begin{align}
\begin{pmatrix} w^Tx_1 - y_1 & ... & w^Tx_N - y_N  \end{pmatrix} = w^T \begin{pmatrix} x_1  & ... & x_N  \end{pmatrix} - \begin{pmatrix} y_1  & ... & y_N  \end{pmatrix} &=  w^TX^T - Y^T
\end{align}</script><script type="math/tex; mode=display">
\begin{align}
\begin{pmatrix} w^Tx_1 - y_1 \\ ... \\ w^Tx_N - y_N  \end{pmatrix} = \begin{pmatrix} x_1 \\ ... \\ x_N  \end{pmatrix}w - \begin{pmatrix}  y_1 \\ ... \\  y_N  \end{pmatrix}  = Xw-Y
\end{align}</script><p>那 么，最终就得到：</p>
<script type="math/tex; mode=display">
\begin{align}
L(w) &=  (w^TX^T - Y^T)(Xw + Y) \\
&= w^TX^TXw - w^TX^TY - Y^TXw - Y^TY
\end{align}</script><p>考虑到 $w^TX^TY$ 与 $Y^TXw$ 的结果其实都是一维实数且二者为转置，因此，二者的值相等， 那么就有：</p>
<script type="math/tex; mode=display">
L(w) = w^TX^TXw - 2w^TX^TY - Y^TY</script><p>那么就有：</p>
<script type="math/tex; mode=display">
\hat{w} = argmin \, L(w) \\
\frac{\delta L(w)}{\delta w} = 2X^TXw - 2X^TY = 0</script><p>从而就得到：</p>
<script type="math/tex; mode=display">
w = (X^TX)^{-1}X^TY</script><h3><span id="2-最小二乘法的几何解释">2. 最小二乘法的几何解释</span></h3><h3><span id="3-从概率角度看最小二乘法">3. 从概率角度看最小二乘法</span></h3><p>最小二乘法隐藏的一个条件是： <strong>误差服从正态分布。</strong></p>
<p>我们假设起始条件：</p>
<script type="math/tex; mode=display">
X = (x_1, \cdots, x_N)^T \\
Y = (Y_1, \cdots, y_N)^T</script><p>假设误差服从正态分布，那么则有：</p>
<script type="math/tex; mode=display">
\varepsilon \sim N(0, \sigma^2) \\</script><p>那么当噪声服从正态分布时，输出值也服从正态分布：</p>
<script type="math/tex; mode=display">
y = f(w) + \varepsilon = w^Tx + \varepsilon</script><script type="math/tex; mode=display">
y | (x;w) \sim N(w^Tx, \sigma^2); \\
P(y|x;w) = \frac{1}{\sqrt{2\pi\sigma}} e^{-\frac{(y-w^Tx)^2}{2 \sigma^2}} \\</script><p>极大似然过程推导：</p>
<script type="math/tex; mode=display">
\begin{align}
L(w) &= log P(Y|X;w)  \\
&= log \prod_{i=1}^N P(y_i|x_i; w) \\
&= \sum_{i=1}^N log P(y_i | x_i; w) \\
&= \sum_{i=1}^N (log \frac{1}{\sqrt{2 \pi \sigma}} + log \, e^{-\frac{(y_i-w^Tx_i)^2}{2 \sigma^2}}) \\
&= \sum_{i=1}^N (log \frac{1}{\sqrt{2 \pi \sigma}}  -\frac{(y_i-w^Tx_i)^2}{2 \sigma^2}) \\
&:= \sum_{i=1}^N ( -(y_i-w^Tx_i)^2) \\
&= - \sum_{i=1}^N (y_i-w^Tx_i)^2
\end{align}</script><p>我们最终是要用极大似然估计 $w$：</p>
<script type="math/tex; mode=display">
\begin{align}
\hat{w} &= argmax_w L(w) \\
&= argmax_w - \sum_{i=1}^N (y_i-w^Tx_i)^2
\end{align}</script><h3><span id="4-推一下线性回归的反向传播">4. 推一下线性回归的反向传播</span></h3><script type="math/tex; mode=display">
J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 \\
\theta_j = \theta_j - \alpha \frac{\delta}{\delta \theta_j} J(\theta) \\ 带入J(\theta) 得： \theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}  \\ 或矩阵表达：\theta_j = \theta_j + \alpha \frac{1}{m}(y-X\theta)^Tx_j</script><h3><span id="5-从贝叶斯角度看线性回归">5. 从贝叶斯角度看线性回归</span></h3><p><a href="https://www.bilibili.com/video/av31989606/?p=4">https://www.bilibili.com/video/av31989606/?p=4</a></p>
<h3><span id="6-什么时候使用岭回归">6. 什么时候使用岭回归 ？</span></h3><p>如果样本数据过少导致线性回归拟合较差，则考虑采用岭回归。如何输入特征的维度很高,而且是稀疏线性关系的话， 岭回归就不太合适,考虑使用Lasso回归。</p>
<h3><span id="7-什么时候使用-l1-正则化">7. 什么时候使用 L1 正则化？</span></h3><p><strong>L1正则化(Lasso回归)可以使得一些特征的系数变小,甚至还使一些绝对值较小的系数直接变为0</strong>，从而增强模型的泛化能力 。对于高的特征数据,尤其是线性关系是稀疏的，就采用L1正则化(Lasso回归),或者是要在一堆特征里面找出主要的特征，那么L1正则化(Lasso回归)更是首选了。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>回归模型2-岭回归</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B2%20-%20%E5%B2%AD%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#岭回归">岭回归</a><ul>
<li><a href="#简介">简介</a></li>
<li><a href="#岭回归与线性回归">岭回归与线性回归</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-什么时候使用岭回归">1. 什么时候使用岭回归 ？</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="岭回归">岭回归</span></h1><h2><span id="简介">简介</span></h2><p>岭回归本质上是 <strong>线性回归 + L2 正则化</strong>。</p>
<h2><span id="岭回归与线性回归">岭回归与线性回归</span></h2><p>线性回归中通过正规方程得到的 w 的估计：</p>
<script type="math/tex; mode=display">
\hat{w} = (X^TX)^{-1}X^Ty</script><p>但是，当我们有 N 个样本，每个样本有 $x_i \in R^p$， 当 N &lt; p 时， $X^TX$ 不可逆， 无法通过正规方程计算，容易造成过拟合。</p>
<p>岭回归通过在矩阵 $X^TX$ 上加一个 $\lambda I$ 来使得矩阵可逆， 此时的 w 的估计：</p>
<script type="math/tex; mode=display">
\hat{w} = (X^TX + \lambda I)^{-1}X^Ty</script><p>而岭回归本质上是对 $L(w)$  进行 L2 正则化， 此时的 $J(w)$ 表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
J(w) &= \sum_{i=1}^N ||w^Tx_i - y_i ||^2 + \lambda w^Tw \\
&= (w^TX^T - Y^T)(Xw - Y) + \lambda w^Tw \\
&= w^TX^TXw - 2w^TX^TY  + Y^TY + \lambda w^Tw \\
&= w^T(X^TX + \lambda I)w - 2w^TX^TY + Y^TY
\end{align}</script><p>那么对 $w$ 的极大似然估计有：</p>
<script type="math/tex; mode=display">
\hat{w} = argmax \, J(w) \\
\frac{\delta J(w)}{\delta w} = 2(X^TX + \lambda I)w - 2 X^TY = 0</script><p>那么我们就解得：</p>
<script type="math/tex; mode=display">
\hat{w} = (X^TX + \lambda I)^{-1}X^Ty</script><p>因此说， 岭回归本质上是 <strong>线性回归 + L2 正则化</strong>， 从而达到抑制过拟合的效果。</p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-什么时候使用岭回归">1. 什么时候使用岭回归 ？</span></h3><p>如果样本数据过少导致线性回归拟合较差，则考虑采用岭回归。如何输入特征的维度很高,而且是稀疏线性关系的话， 岭回归就不太合适,考虑使用Lasso回归。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-SVM核方法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20SVM%20%E6%A0%B8%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#基础理论-svm-核方法">基础理论 - SVM 核方法</a><ul>
<li><a href="#核方法作用">核方法作用</a></li>
<li><a href="#正定核">正定核</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="基础理论-svm-核方法">基础理论 - SVM 核方法</span></h1><hr>
<h2><span id="核方法作用">核方法作用</span></h2><ul>
<li>从模型角度：非线性带来高维转换</li>
<li>从优化角度：对偶表示带来内积</li>
</ul>
<h2><span id="正定核">正定核</span></h2>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-判别模型 VS 生成模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B%20vs%20%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#监督学习模型">监督学习模型</a></li>
<li><a href="#1-判别模型">1. 判别模型</a></li>
<li><a href="#2-生成模型">2. 生成模型</a></li>
<li><a href="#3-判别模型-vs-生成模型">3. 判别模型 vs 生成模型</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-生成模型和判别模型基本形式有哪些">1. 生成模型和判别模型基本形式，有哪些？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="监督学习模型">监督学习模型</span></h2><p>监督学习的任务是学习一个模型，对给定的输入预测相应的输出，这个模型的一般形式维一个<strong>决策函数</strong>或一个<strong>条件概率分布</strong>。</p>
<ul>
<li><p><strong>决策函数：</strong>输入 X 返回 Y；其中 Y 与一个<strong>阈值</strong>比较，然后根据比较结果判定 X 的类别</p>
<script type="math/tex; mode=display">
Y = f(X)</script></li>
<li><p><strong>条件概率分布</strong>：输入 X 返回 <strong>X 属于每个类别的概率</strong>；将其中概率最大的作为 X 所属的类别</p>
<script type="math/tex; mode=display">
P = (Y|X)</script></li>
</ul>
<h2><span id="1-判别模型">1. 判别模型</span></h2><ul>
<li>代表：K 近邻、感知机（神经网络）、决策树、逻辑斯蒂回归、<strong>最大熵模型</strong>、SVM、提升方法、<strong>条件随机场</strong></li>
<li>思想： 由<strong>数据</strong>直接学习<strong>决策函数 $Y=f(X)$</strong> 或<strong>条件概率分布 $P(Y|X)$</strong> 作为预测的模型。</li>
<li>理解： 直观的说，判别模型学习的是<strong>类别之间的最优分隔面</strong>，反映的是不同类数据之间的差异</li>
<li>举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。</li>
</ul>
<h2><span id="2-生成模型">2. 生成模型</span></h2><ul>
<li><p>代表：朴素贝叶斯、隐马尔可夫模型、混合高斯模型、贝叶斯网络、马尔可夫随机场</p>
</li>
<li><p>思想：由数据学习得到<strong>联合概率密度分布</strong> $P(X,Y)$， 然后求出<strong>条件概率分布</strong> $P(Y|X)$ 作为预测的模型：</p>
<script type="math/tex; mode=display">
P(Y|X) = \frac{P(X,Y)}{P(X)}</script></li>
<li><p>举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率多少，放到绵羊模型中看概率多少，哪个大就是哪个。</p>
</li>
</ul>
<h2><span id="3-判别模型-vs-生成模型">3. 判别模型 vs 生成模型</span></h2><ul>
<li><p>由生成模型能够得到判别模型，但由判别模型得不到生成模型</p>
</li>
<li><p>当存在“<strong>隐变量</strong>”时，只能使用<strong>生成模型</strong></p>
</li>
</ul>
<blockquote>
<p>隐变量：当我们找不到引起某一现象的原因时，就把这个在起作用，但无法确定的因素，叫“隐变量”</p>
</blockquote>
<ul>
<li><p>判别方法的特点：</p>
<blockquote>
<ul>
<li>缺点：不能反映训练数据本身的特性。</li>
<li>优点：它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。</li>
<li>优点：直接面对预测，往往学习的准确率更高。</li>
<li>优点：由于直接学习P(Y|X)或P(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。</li>
</ul>
</blockquote>
</li>
<li><p>生成方法的特点：</p>
<blockquote>
<ul>
<li>优点： 可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度**。但它不关心到底划分各类的那个分类边界在哪。</li>
<li>优点：生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型。</li>
<li>优点：当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。</li>
<li>缺点：学习和计算过程比较复杂</li>
</ul>
</blockquote>
</li>
</ul>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-生成模型和判别模型基本形式有哪些">1. 生成模型和判别模型基本形式，有哪些？</span></h3><ul>
<li>生成模型： 朴素贝叶斯、HMM、混合高斯模型、马尔科夫随机场</li>
<li>判别模型： LR，SVM，神经网络，CRF，Boosting</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-机器学习项目流程</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-抽象成数学问题">1. 抽象成数学问题</a></li>
<li><a href="#2-获取数据">2. 获取数据</a></li>
<li><a href="#3-特征预处理与特征选择">3. 特征预处理与特征选择</a></li>
<li><a href="#4-训练模型与调优">4. 训练模型与调优</a></li>
<li><a href="#5-模型诊断">5. 模型诊断</a></li>
<li><a href="#6-模型融合">6. 模型融合</a></li>
<li><a href="#7-上线运行">7. 上线运行</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-如果给你一些数据集你会如何分类">1. 如果给你一些数据集，你会如何分类?</a></li>
<li><a href="#2-分类算法列一些有多少种">2. 分类算法列一些有多少种？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-抽象成数学问题">1. 抽象成数学问题</span></h2><p><strong>明确问题</strong>是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。</p>
<p>这里的抽象成数学问题，指的我们明确<strong>我们可以获得什么样的数据</strong>，目标是<strong>一个分类还是回归或者是聚类的问题</strong>。</p>
<h2><span id="2-获取数据">2. 获取数据</span></h2><p>数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。</p>
<ul>
<li>数据要有代表性，否则必然会过拟合。</li>
<li>分类问题要考虑到样本均衡问题，不同类别的数据数量不要有数个数量级的差距。</li>
<li>对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些<strong>降维</strong>的技巧了。如果数据量实在太大，那就要考虑分布式了。</li>
</ul>
<h2><span id="3-特征预处理与特征选择">3. 特征预处理与特征选择</span></h2><ul>
<li><p>特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。</p>
<blockquote>
<p>归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。</p>
</blockquote>
</li>
<li><p>特征选择：</p>
<blockquote>
<p>筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如 <strong>相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。</strong></p>
</blockquote>
</li>
</ul>
<h2><span id="4-训练模型与调优">4. 训练模型与调优</span></h2><p>模型选择与超参数调优。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。</p>
<h2><span id="5-模型诊断">5. 模型诊断</span></h2><p>通过模型诊断来确定模型调优的方向与思路。</p>
<ul>
<li><strong>过拟合、欠拟合</strong> 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。</li>
<li><strong>误差分析</strong> 也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因：是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题 ？</li>
</ul>
<p>这个过程需要反复迭代，调优-诊断-调优</p>
<h2><span id="6-模型融合">6. 模型融合</span></h2><p>一般来说，模型融合后都能使得效果有一定提升。而且效果很好。<br>工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。</p>
<h2><span id="7-上线运行">7. 上线运行</span></h2><p>模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。</p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-如果给你一些数据集你会如何分类">1. 如果给你一些数据集，你会如何分类?</span></h3><p>根据数据类型选择不同的模型，如LR或者SVM，决策树。</p>
<ul>
<li>假如特征维数较多，可以选择SVM模型，如果样本数量较大可以选择LR模型，但是LR模型需要进行数据预处理</li>
<li><p>假如缺失值较多可以选择决策树</p>
</li>
<li><p>还可以在考虑正负样例比比，通过上下采样平衡正负样例比。</p>
</li>
</ul>
<h3><span id="2-分类算法列一些有多少种">2. 分类算法列一些有多少种？</span></h3><ul>
<li>单一分类方法： LR， SVM， 决策树， 朴素贝叶斯，神经网络， KNN</li>
<li>集成学习算法：基于 Bagging 和 Boosting 算法思想，随机森林，GBDT，Adaboost，XGboost。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-距离度量方法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="基础理论-距离度量方法">基础理论 - 距离度量方法</span></h1><hr>
<!-- toc -->
<!-- tocstop -->
<span id="more"></span>
<script type="math/tex; mode=display">
欧式距离 = \sqrt{\sum_{l=1}^n (x_i^{(l)} - x_j^{(l)})^2}\\
曼哈顿距离 = \sum_{l=1}^n |x_i^{(l)} - x_j^{(l)}| \\</script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-集成学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#集成学习一览">集成学习一览</a></li>
<li><a href="#1-bagging">1. Bagging</a></li>
<li><a href="#2-boosting">2. Boosting</a></li>
<li><a href="#3-stacking">3. Stacking</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#0-boosting-与-bagging-区别">0. Boosting 与 Bagging 区别</a></li>
<li><a href="#1-boosting-bagging-与偏差方差">1. Boosting, Bagging 与偏差，方差</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a href="https://www.jiqizhixin.com/articles/2018-07-28-3">https://www.jiqizhixin.com/articles/2018-07-28-3</a></p>
<h2><span id="集成学习一览">集成学习一览</span></h2><p><strong>组合多个弱监督模型以得到一个更好更全面的强监督模型，其思想在于：即便某一个弱分类器得到了错误的预测，其他的弱分类器也可以将错误纠正回来。</strong></p>
<p>集成方法奏效的原因是不同的模型<strong>通常不会</strong>在测试集上产生相同的误差。集成模型能至少与它的任一成员表现得一样好。<strong>如果成员的误差是独立的</strong>，集成将显著提升模型的性能。</p>
<p>学习策略推荐：</p>
<blockquote>
<ul>
<li>数据集大： 划分成多个小数据集，学习多个模型进行组合。</li>
<li>数据集小： 利用 Bootstrap 方法进行抽样，得到多个数据集，分别训练多个模型再进行组合。</li>
</ul>
</blockquote>
<h2><span id="1-bagging">1. Bagging</span></h2><p>代表模型： <strong>随机森林， Bagging meta-estimator</strong></p>
<p>先通过采样构造 k 个不同的数据集，学习得到k 个基学习器， 基学习器之间不存在依赖关系，可同时生成。    </p>
<p>更具体的，如果采样所得的训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 <code>2/3</code> 的实例</p>
<ul>
<li><p><strong>Bootstrap：</strong>  一种有放回的抽样方法，目的是为了得到统计量的分布以及置信空间。</p>
<blockquote>
<ol>
<li>采用有放回抽样方法从原始样本中抽取一定数量的样本</li>
<li>根据抽出的样本计算想要得到的统计量T</li>
<li>重复上述N次（一般大于1000），得到N个统计量T</li>
<li>根据这N个统计量，即可计算出统计量的置信区间</li>
</ol>
</blockquote>
</li>
<li><p><strong>Bagging 的基本思路：</strong></p>
<blockquote>
<ol>
<li>利用<strong>Bootstrap</strong>对训练集随机采样，重复进行 <code>T</code> 次</li>
<li>基于每个采样集训练一个弱学习器，得到 T 个弱学习器</li>
<li>预测时，分类问题采用投票方式， 回归问题采用 N 个模型预测平均方式。</li>
</ol>
</blockquote>
</li>
</ul>
<h2><span id="2-boosting">2.  Boosting</span></h2><p>代表模型：<strong>AdaBoost， XGBoost， GBDT， Light GBM， CatBoost</strong></p>
<p>学习一系列弱学习器，然后组合成一个强学习器。基于<strong>串行策略</strong>：弱学习器之间存在依赖关系，新的学习器需要根据上一个学习器生成。</p>
<ul>
<li><p>Boosting基本思路：</p>
<blockquote>
<ol>
<li><p>先从初始训练集训练一个弱学习器，初始训练集各个样本权重相同</p>
</li>
<li><p>根据上一个弱学习器的表现，调整样本权重，是的分类错误的样本得到更多关注</p>
</li>
<li>基于调整后的样本分布，训练下一个弱学习器、</li>
<li>测试时，对各基学习器<strong>加权</strong>得到最终结果</li>
</ol>
</blockquote>
</li>
</ul>
<h2><span id="3-stacking">3. Stacking</span></h2><p>训练一个模型用于组合其他各个模型。首先我们先训练多个不同的模型，然后把之前训练的各个模型的输出为输入来训练一个模型，以得到一个最终的输出。</p>
<ul>
<li><p>Stacking 基本思路：首先我们先训练多个不同的模型，然后把之前训练的各个模型的输出为输入来训练一个模型，以得到一个最终的输出。</p>
<blockquote>
<ul>
<li>先从初始训练集训练 <code>T</code> 个<strong>不同的初级学习器</strong>;</li>
<li>利用每个初级学习器的<strong>输出</strong>构建一个<strong>次级数据集</strong>，该数据集依然使用初始数据集的标签；</li>
<li>根据新的数据集训练<strong>次级学习器</strong>；</li>
<li><strong>多级学习器</strong>的构建过程类似。</li>
</ul>
</blockquote>
</li>
</ul>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="0-boosting-与-bagging-区别">0. Boosting 与 Bagging 区别</span></h3><ul>
<li>Bagging中每个训练集互不相关，也就是每个基分类器互不相关，而Boosting中训练集要在上一轮的结果上进行调整，也使得其不能并行计算</li>
<li>Bagging中预测函数是均匀平等的，但在Boosting中预测函数是加权的</li>
</ul>
<h3><span id="1-boosting-bagging-与偏差方差">1. Boosting, Bagging 与偏差，方差</span></h3><p><strong>Boosting</strong> 能提升弱分类器性能的原因是降低了<strong>偏差</strong>；<strong>Bagging</strong> 则是降低了<strong>方差</strong>；</p>
<ul>
<li><p>Boosting：</p>
<blockquote>
<ul>
<li>Boosting 的<strong>基本思路</strong>就是在不断减小模型的<strong>训练误差</strong>（拟合残差或者加大错类的权重），加强模型的学习能力，从而减小偏差；</li>
<li>但 Boosting 不会显著降低方差，因为其训练过程中各基学习器是强相关的，缺少独立性。</li>
</ul>
</blockquote>
</li>
<li><p>Bagging：</p>
<blockquote>
<ul>
<li>对 <code>n</code> 个<strong>独立不相关的模型</strong>预测结果取平均，方差是原来的 <code>1/n</code>；</li>
<li>假设所有基分类器出错的概率是独立的，<strong>超过半数</strong>基分类器出错的概率会随着基分类器的数量增加而下降。</li>
</ul>
</blockquote>
</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-概率派 VS 贝叶斯派</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E9%A2%91%E7%8E%87%E6%B4%BE%20vs%20%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B4%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><img data-src="..\img\贝叶斯\贝叶斯.png" alt="贝叶斯"></p>
<!-- toc -->
<ul>
<li><a href="#1-频率派-vs-贝叶斯派">1. 频率派 vs 贝叶斯派</a><ul>
<li><a href="#频率派">频率派</a></li>
<li><a href="#贝叶斯派">贝叶斯派</a></li>
</ul>
</li>
<li><a href="#2-极大似然估计-vs-最大后验估计">2. 极大似然估计 vs 最大后验估计</a><ul>
<li><a href="#1-极大似然估计-mle">1. 极大似然估计 - MLE</a></li>
<li><a href="#2-最大后验估计-map">2. 最大后验估计 - MAP</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-极大似然估计与最大后验概率的区别">1. 极大似然估计与最大后验概率的区别？</a></li>
<li><a href="#2-概率与似然的区别">2. 概率与似然的区别</a></li>
<li><a href="#3-贝叶斯派与频率学派的区别">3. 贝叶斯派与频率学派的区别</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-频率派-vs-贝叶斯派">1. 频率派 vs 贝叶斯派</span></h2><p>对于有 n 个样本的样本集 $X = (x_1, …, x_n)$ 以及参数 $\theta$， 那么有 $X$ 服从概率分布 $ P(x|\theta)$ </p>
<h3><span id="频率派">频率派</span></h3><p><strong>频率派</strong>认为 $\theta$ 是一个未知的常量， 数据 $X$ 是一个随机变量，其服从一定的概率分布， 目的是通过极大似然估计 + 随机变量 $X$ 来估计出未知参数 $\theta$ 。 </p>
<script type="math/tex; mode=display">
\theta_{MLE} = argmax_{\theta} \,\, log P(X|\theta)</script><h3><span id="贝叶斯派">贝叶斯派</span></h3><p>贝叶斯派认为 $\theta$ 是一个随机变量，其服从一定的概率分布 $p(\theta)$。其采用最大后验估计来计算 $P(\theta|X)$。</p>
<script type="math/tex; mode=display">
P(\theta|X) = \frac{P(X | \theta) P(\theta)}{P(X)}</script><ul>
<li>先验： $P(\theta)$ ， 似然： $P(X|\theta)$ ， 后验：$P(\theta|X)$</li>
</ul>
<script type="math/tex; mode=display">
\theta_{MAP} = argmax_{\theta} \,  \, P(\theta | X) = argmax_{\theta} P(X|\theta)P(\theta)</script><h2><span id="2-极大似然估计-vs-最大后验估计">2. 极大似然估计 vs 最大后验估计</span></h2><h3><span id="1-极大似然估计-mle">1.  极大似然估计 - MLE</span></h3><ul>
<li><p>原理：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。</p>
</li>
<li><p>极大似然估计提供了一种给定观察数据来评估模型参数的方法：<strong>模型已定，参数未知</strong>。经过若干次实验，观察结果，利用实验结果得到某个参数值能够使得样本出现的概率为最大，称为极大似然估计。</p>
</li>
<li><p>离散情况下参数 $\theta$ 的似然函数：</p>
<blockquote>
<script type="math/tex; mode=display">
L(\theta) = L(X_1, X_2, \cdots, X_n; \theta) = \prod_{i=1}^n p(X_i| \theta)</script></blockquote>
</li>
<li><p><strong>极大似然估计：</strong> 对于给定的样本值$(x_1, x_2, \cdots, x_n)$ 有：</p>
<script type="math/tex; mode=display">
\hat{\vec\theta}= \mathop {\arg \max}_{\vec\theta} L(\vec\theta )</script></li>
<li><p>使得似然函数 $L(x_1, x_2, \cdots, x_n; \theta)$达到最大值的参数值 $\hat{\theta} = \hat{\theta} (x_1, \cdots, x_n)$ 称为未知数 $\theta$ 的最大似然估计值。</p>
</li>
</ul>
<h3><span id="2-最大后验估计-map">2. 最大后验估计 - MAP</span></h3><p>MAP 的基础是贝叶斯公式：</p>
<script type="math/tex; mode=display">
贝叶斯估计：P(\theta|X) = \frac{P(X | \theta) P(\theta)}{P(X)}= \frac{P(X | \theta) P(\theta)}{\int_{\theta} P(X|\theta)P(\theta)d{\theta}} \\
贝叶斯预测：p(\hat{x} | X) = \int_{\theta} p(\hat{x},\theta|X) d{\theta} = \int_{\theta} p(\hat{x}|\theta) p(\theta|X)d{\theta}</script><p>MAP 优化的就是后验概率， 目的是通过观测值使得后验概率最大：</p>
<script type="math/tex; mode=display">
\theta_{MAP} = argmax_{\theta} \,  \, P(\theta | X) = argmax_{\theta} P(X|\theta)P(\theta)</script><hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-极大似然估计与最大后验概率的区别">1. 极大似然估计与最大后验概率的区别？</span></h3><ul>
<li>最大似然估计提供了一种给定观察数据来评估模型参数的方法， 最大似然估计中的采样满足<strong>所有采样都是独立同分布的假设。</strong></li>
<li>最大后验概率是根据经验数据获难以观察量的点估计,与最大似然估计最大的不同是最大后验概率融入了要估计量的先验分布在其中，所以最大后验概率可以看做规则化的最大似然估计。</li>
</ul>
<h3><span id="2-概率与似然的区别">2. 概率与似然的区别</span></h3><ul>
<li>概率是指在给定参数$\theta$的情况下,样本的随机向量 $X=x$ 的可能性。</li>
<li>似然表示的是在给定样本 $X=x$ 的情况下,参数 $\theta$ 为真实值的可能性。</li>
</ul>
<p>一般情况,对随机变量的取值用概率表示。而在非贝叶斯统计的情况下,参数为一个实数而不是随机变量,一般用似然来表示。</p>
<h3><span id="3-贝叶斯派与频率学派的区别">3. 贝叶斯派与频率学派的区别</span></h3><ul>
<li>频率派认为抽样是无限的,在无限的抽样中,对于决策的规则可以很精确。贝叶斯派认为世界无时无刻不在改变,未知的变量和事件都有一定的概率,即后验概率是先验概率的修正。</li>
<li>频率派认为模型参数是固定的,一个模型在无数次抽样后,参数是不变的。而贝叶斯学派认为数据才是固定的而参数并不是。</li>
<li>频率派认为模型不存在先验而贝叶斯派认为模型存在先验。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>概率图模型-HMM</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%20-%20HMM/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="概率图模型-hmm">概率图模型 - HMM</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>模型-KNN</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%A8%A1%E5%9E%8B%20-%20KNN/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="模型-knn">模型 - KNN</span></h1><hr>
<!-- toc -->
<ul>
<li><a href="#简介">简介</a></li>
<li><a href="#算法步骤">算法步骤</a></li>
<li><a href="#k-的选择">K 的选择</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-knn-中为何采用欧式距离而不采用曼哈顿距离">1. KNN 中为何采用欧式距离而不采用曼哈顿距离？</a></li>
<li><a href="#2">2.</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="简介">简介</span></h2><p>KNN算法是分类算法的一种，也属于监督学习算法，其基本思想为：</p>
<ul>
<li><p>当输入一个新的样本时，将新数据的每个特征与样本集中每个样本数据的特征进行比较。</p>
</li>
<li><p>从样本集中选取最<strong>相近</strong>的 K 个样本，然后依据某种决策原则（少数服从多数）来判定这个新样本的 label。</p>
</li>
</ul>
<p>在KNN算法中，有三个主要要素：距离度量，K 的取值，分类决策规则。</p>
<h2><span id="算法步骤">算法步骤</span></h2><ul>
<li>计算新数据与数据集中所有样本之间的距离， 距离度量公式可以选择多种，如欧式距离，曼哈顿距离等。可以参见：<a href="./基础理论 - 距离度量方法.md">基础理论 - 距离度量方法</a></li>
<li><p>按照距离，将样本按照距离值进行排序</p>
</li>
<li><p>选取与当前数据距离最小的 K 个点。</p>
</li>
<li>返回这 K 个点的 label， 依据某种决策原则来判定这个新数据的 label 。</li>
</ul>
<h2><span id="k-的选择">K 的选择</span></h2><ul>
<li>如果 K 较小，预测结果会对邻近的点十分敏感，如果邻近点恰好是噪声，则很容易预测错误。 换个角度说说， <strong>K的减小意味着模型变得复杂，容易发生过拟合。</strong></li>
<li>如果K 较大， 此时不相似的样本也会对预测产生作用，使得预测发生错误。换个角度说，<strong>K的增大意味着模型变得简单，容易发生欠拟合。</strong></li>
</ul>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-knn-中为何采用欧式距离而不采用曼哈顿距离">1. KNN 中为何采用欧式距离而不采用曼哈顿距离？</span></h3><p>我们不用曼哈顿距离，因为它只计算水平或垂直距离，有维度的限制。另一方面，欧式距离可用于任何空间的距离计算问题。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。例如：想象一下国际象棋棋盘，象或车所做的移动是由曼哈顿距离计算的，因为它们是在各自的水平和垂直方向的运动。</p>
<h3><span id="2">2.</span></h3>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>模型-LDA</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%A8%A1%E5%9E%8B%20-%20LDA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="模型-lda">模型 - LDA</span></h1><hr>
<h2><span id="简介">简介</span></h2><p>LDA 叫做线性判别分析，又叫做Fisher 线性判别函数， 其是一种有监督的降维技术，其思想为：<strong>投影后类内方差最小，类间方差最大。</strong></p>
<p>简单来说，我们将数据向低维超平面上投影时， 投影后希望每一种类别数据的投影点尽可能的接近，而不同类别的数据的类别中心点的距离尽可能的大。</p>
<p>​</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>模型-树回归</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%A8%A1%E5%9E%8B%20-%20%E6%A0%91%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="模型-回归树">模型 - 回归树</span></h1><hr>
<h2><span id="cart-用于回归">CART 用于回归</span></h2><p><a href="https://blog.csdn.net/weixin_36586536/article/details/80468426">https://blog.csdn.net/weixin_36586536/article/details/80468426</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>模型-聚类算法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%A8%A1%E5%9E%8B%20-%20%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="聚类算法">聚类算法</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>模型-谱聚类</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%A8%A1%E5%9E%8B%20-%20%E8%B0%B1%E8%81%9A%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="模型-谱聚类">模型 - 谱聚类</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>降维度-PCA</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%99%8D%E7%BB%B4%20-%20PCA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="降维-pca">降维 - PCA</span></h1><h2><span id="qa">QA</span></h2><h3><span id="1-pca-中第一主成分是第一的原因">1. PCA  中第一主成分是第一的原因？</span></h3><p><a href="https://www.nowcoder.com/questionTerminal/7e9febebe3d3467ca5ea17e013d416f0">https://www.nowcoder.com/questionTerminal/7e9febebe3d3467ca5ea17e013d416f0</a></p>
<h3><span id="2-讲一下-pca">2. 讲一下 PCA</span></h3><p>PCA是比较常见的线性降维方法，通过线性投影将高维数据映射到低维数据中。 所期望的是在投影的维度上，新特征自身的方差尽量大，方差越大特征越有效，尽量使产生的新特征间的相关性越小。</p>
<p>PCA算法的具体操作为<strong>对所有的样本进行中心化操作</strong>，计算样本的协方差矩阵，然后对协方差矩阵做特征值分解，取最大的n个特征值对应的特征向量构造投影矩阵。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习-GBDT</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%20-%20GBDT/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="集成学习-gbdt">集成学习 - GBDT</span></h1><hr>
<!-- toc -->
<ul>
<li><a href="#1-boosting-思想">1. Boosting 思想</a></li>
<li><a href="#2-gbdt">2. GBDT</a><ul>
<li><a href="#1-gbdt-思想">1. GBDT 思想</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-boosting-思想">1. Boosting 思想</span></h2><p>Boosting 基于串行策略， 各个基分类器之间有依赖。</p>
<ol>
<li>先从初始训练集训练一个弱学习器，初始训练集各个样本权重相同</li>
<li>根据上一个弱学习器的表现，调整样本权重，是的分类错误的样本得到更多关注</li>
<li>基于调整后的样本分布，训练下一个弱学习器、</li>
<li>测试时，对各基学习器<strong>加权</strong>得到最终结果</li>
</ol>
<h2><span id="2-gbdt">2. GBDT</span></h2><p>GBDT ， Gradient Boosting  Decision Tree， 叫 梯度提升决策树。</p>
<h3><span id="1-gbdt-思想">1. GBDT 思想</span></h3>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习-LightGBM</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%20-%20LightGBM/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="集成学习-lightgbm">集成学习 - LightGBM</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习-XGBoost</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%20-%20XGBoost/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="集成学习-xgboost">集成学习 - XGBoost</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程-数据预处理</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A2%84%E5%A4%84%E7%90%86%20-%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-数据清洗">1. 数据清洗</a><ul>
<li><a href="#1-样本采样">1. 样本采样</a></li>
<li><a href="#2-样本过滤">2. 样本过滤</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-数据清洗">1. 数据清洗</span></h2><p>数据清洗主要包括<strong>数据采样</strong>和<strong>样本过滤</strong>。</p>
<h3><span id="1-样本采样">1. 样本采样</span></h3><ul>
<li>分类问题： 需要注意样本均衡问题，合适选择正负比例。</li>
<li>回归问题： 需要采集数据。</li>
<li>对于采样得到的样本，根据需要，需要设定样本权重。</li>
<li>当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。</li>
</ul>
<h3><span id="2-样本过滤">2. 样本过滤</span></h3><ul>
<li><p>结合业务情况进行数据的过滤</p>
</li>
<li><p><strong>异常点检测</strong>：</p>
<blockquote>
<ul>
<li>偏差检测，例如聚类，最近邻等。</li>
<li>基于统计的异常点检测算法<br>例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。</li>
<li>基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。</li>
<li>基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法</li>
</ul>
</blockquote>
</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程-特征工程</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E9%A2%84%E5%A4%84%E7%90%86%20-%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-如何处理数据中的缺失值">1. 如何处理数据中的缺失值</a><ul>
<li><a href="#1-缺失值较多">1. 缺失值较多</a></li>
<li><a href="#2-缺失值较少">2. 缺失值较少</a></li>
</ul>
</li>
<li><a href="#2-特征常见处理手段">2. 特征常见处理手段</a><ul>
<li><a href="#1数值归一化">1.数值归一化</a></li>
<li><a href="#2-离散化">2. 离散化</a></li>
</ul>
</li>
<li><a href="#3-共线性问题-todo">3. 共线性问题  — TODO</a><ul>
<li><a href="#1-如何判定共线性问题">1. 如何判定共线性问题？</a></li>
<li><a href="#2-如何消除共线性问题">2. 如何消除共线性问题？</a></li>
</ul>
</li>
<li><a href="#4-如何进行特征选择">4. 如何进行特征选择？</a><ul>
<li><a href="#1-特征分类">1. 特征分类</a></li>
<li><a href="#2-如何考虑特征选择">2. 如何考虑特征选择</a></li>
<li><a href="#3-特征选择方法分类">3. 特征选择方法分类</a></li>
<li><a href="#4-特征选择目的">4. 特征选择目的</a></li>
</ul>
</li>
<li><a href="#5-关联规则">5. 关联规则</a><ul>
<li><a href="#1-简介">1. 简介</a></li>
<li><a href="#关联规则的三个度">关联规则的三个度</a><ul>
<li><a href="#1-支持度">1. 支持度</a></li>
<li><a href="#2-置信度">2. 置信度</a></li>
<li><a href="#3-提升度">3. 提升度</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-判断规则的有效性">1. 判断规则的有效性</a></li>
<li><a href="#2-如果数据有问题怎么处理">2. 如果数据有问题，怎么处理?</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><img data-src="..\img\8.数据清洗与特征处理.jpg" alt="8.数据清洗与特征处理"></p>
<h2><span id="1-如何处理数据中的缺失值">1. 如何处理数据中的缺失值</span></h2><p>有些特征可能因为无法采样或者没有观测值而缺失，此时需要对这些缺失的特征值进行特殊处理。</p>
<h3><span id="1-缺失值较多">1. 缺失值较多</span></h3><p>如果该特征中的缺失值较多，则应该直接舍弃，否则反而可能引入较大噪声，造成反效果。</p>
<h3><span id="2-缺失值较少">2. 缺失值较少</span></h3><p>即当缺失值在 10% 以内时，我们可以采用多种方式处理：</p>
<ul>
<li><p>将缺失值当一个特征处理，用 一个异常值表示， 如0</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data_train.fillna(0) </span><br></pre></td></tr></table></figure>
</li>
<li><p>用均值填充</p>
<p>通常一个策略是取相同 label 的数据的均值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data_train.fillna(data_train.mean()) </span><br></pre></td></tr></table></figure>
</li>
<li><p>以上下数据填充</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data_train.fillna(method=&#x27;pad&#x27;)  # 上一个数据填充</span><br><span class="line">data_train.fillna(method=&#x27;bfill&#x27;)  # 下一个数据填充</span><br></pre></td></tr></table></figure>
</li>
<li><p>插值法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data_train.interpolate() # 即估计中间点的值</span><br></pre></td></tr></table></figure>
</li>
<li><p>用随机森林等算法拟合</p>
<blockquote>
<p>将数据分为有值和缺失值2份，对有值的数据采用随机森林拟合，然后对有缺失值的数据进行预测，用预测的值来填充。</p>
</blockquote>
</li>
</ul>
<h2><span id="2-特征常见处理手段">2.  特征常见处理手段</span></h2><h3><span id="1数值归一化">1.数值归一化</span></h3><p>归一化的目的是将所有的特征都统一到一个大致相同的数值区间中。</p>
<p>从梯度下降的角度来看，对于两个特征x1，x2， x1的范围远远大于x2，在学习率相同的情况下，x1的更新速度会大于x2，需要较多的迭代才能得到最优解。</p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g0r7bxl5kfj30ie0a840y.jpg" alt></p>
<ul>
<li>函数归一化： min-max 归一化， 零均值归一化（参考 <strong>Normalization</strong> 一节）</li>
<li>分维度归一化</li>
<li>排序归一化</li>
</ul>
<h3><span id="2-离散化">2. 离散化</span></h3><p>连续值的离散化：</p>
<ul>
<li><strong>等值划分：</strong>将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，…，[9，10)。</li>
<li>等量划分是根据样本总数进行均分，每段等量个样本划分为1段。</li>
</ul>
<p>区别：例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。</p>
<h2><span id="3-共线性问题-todo">3. 共线性问题  — TODO</span></h2><p>对于回归算法而言， 其首先假设回归模型的解释变量之间不存在线性关系， 即解释变量X1，X2，……，Xk中的任何一个都不能是其他解释变量的线性组合。如果违背这一假定，即线性回归模型中某一个解释变量与其他解释变量间存在线性关系，就称线性回归模型中存在多重共线性。</p>
<p>多重共线性违背了解释变量间不相关的古典假设，将给普通最小二乘法带来严重后果。</p>
<p>其实，简单来说，就是特征冗余，容易导致过拟合。</p>
<h3><span id="1-如何判定共线性问题">1. 如何判定共线性问题？</span></h3><ul>
<li>相关性分析。当相关性系数高于0.8，表明存在多重共线性；但相关系数低，并不能表示不存在多重共线性</li>
<li>方差膨胀因子VIF。当VIF大于5或10时，代表模型存在严重的共线性问题；</li>
<li>条件系数检验。 当条件数大于100、1000时，代表模型存在严重的共线性问题。</li>
</ul>
<h3><span id="2-如何消除共线性问题">2. 如何消除共线性问题？</span></h3><p>通常可通过PCA降维、逐步回归法和LASSO回归等方法消除共线性。</p>
<h2><span id="4-如何进行特征选择">4. 如何进行特征选择？</span></h2><h3><span id="1-特征分类">1. 特征分类</span></h3><ul>
<li>相关特征： 对于特定的任务和场景有一定帮助的属性，这些属性能有效提升算法性能。</li>
<li>无关特征：在特定的任务和场景下完全无用的属性，这些属性对对象在本目标环境下完全无用。</li>
<li>冗余特征：同样是在特定的任务和场景下具有一定帮助的属性，但这类属性已过多的存在，不具有产生任何新的信息的能力。</li>
</ul>
<h3><span id="2-如何考虑特征选择">2. 如何考虑特征选择</span></h3><p>可以从以下两个方面来选择特征：</p>
<ul>
<li>特征是否具有发散性：某个特征若在所有样本上的都是一样的或者接近一致，即方差非常小。 也就是说所有样本的都具有一致的表现，那这些就不具有任何信息。</li>
<li>特征与目标的相关性：与目标相关性高的特征，应当优选选择。</li>
</ul>
<h3><span id="3-特征选择方法分类">3. 特征选择方法分类</span></h3><ul>
<li>过滤法：按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。  </li>
<li>包装法：根据目标函数(通常是预测效果评分)，每次选择若干特征，或者排除若干特征。  </li>
<li>嵌入法：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。</li>
</ul>
<h3><span id="4-特征选择目的">4. 特征选择目的</span></h3><ul>
<li>减少特征维度，使模型泛化能力更强，减少过拟合;  </li>
<li>降低任务目标的学习难度；</li>
<li>一组优秀的特征通常能有效的降低模型复杂度，提升模型效率 </li>
</ul>
<h2><span id="5-关联规则">5. 关联规则</span></h2><p><a href="https://www.jianshu.com/p/7d459ace31ab">https://www.jianshu.com/p/7d459ace31ab</a></p>
<h3><span id="1-简介">1. 简介</span></h3><p>关联规则挖掘是一种基于规则的机器学习算法，该算法可以在大数据库中发现感兴趣的关系。它的目的是利用一些度量指标来分辨数据库中存在的强规则。也即是说关联规则挖掘是用于知识发现，而非预测，所以是属于<strong>无监督</strong>的机器学习方法。</p>
<p>从所有可能规则的集合中选择感兴趣的规则需要利用一些度量方法来筛选和过滤，下面的三种方法。</p>
<h3><span id="关联规则的三个度">关联规则的三个度</span></h3><h4><span id="1-支持度">1. 支持度</span></h4><script type="math/tex; mode=display">
Support(X→Y) = P(X,Y) / P(I) = P(X∪Y) / P(I) = num(XUY) / num(I)</script><p>支持度表示 item-set {X,Y} 在总 item-set 里出现的概率。其中， $I$ 表示总事务集， num()表示事务集里特定 item-set 出现的次数。比如：$num(I)$ 表示总事务集的个数，$num(X∪Y)$ 表示含有 {X,Y} 的事务集的个数（个数也叫次数）。</p>
<h4><span id="2-置信度">2. 置信度</span></h4><script type="math/tex; mode=display">
Confidence(X→Y) = P(Y|X)  = P(X,Y) / P(X) = P(XUY) / P(X)</script><p>置信度表示在先决条件X发生的情况下，由关联规则”X→Y“推出Y的概率。即在含有X的项集中，含有Y的可能性。</p>
<h4><span id="3-提升度">3. 提升度</span></h4><script type="math/tex; mode=display">
Lift(X→Y) = P(Y|X) / P(Y)</script><p>提升度表示含有X的条件下，同时含有Y的概率，与Y总体发生的概率之比。</p>
<p>满足最小支持度和最小置信度的规则，叫做“强关联规则”。</p>
<ul>
<li>$Lift(X→Y)&gt;1$，“X→Y”是有效的强关联规则。</li>
<li>$Lift(X→Y) &lt;=1$，“X→Y”是无效的强关联规则。</li>
<li>特别地，$Lift(X→Y) =1$，X与Y相互独立。</li>
</ul>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-判断规则的有效性">1. 判断规则的有效性</span></h3><p>题目：已知有1000名顾客买年货，分为甲乙两组，每组各500人，其中甲组有500人买了茶叶，同时又有450人买了咖啡；乙组有450人买了咖啡，如表所示，<strong>题目：茶叶→咖啡是一条有效的关联规则吗？</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>组次</th>
<th>买茶叶的人数</th>
<th>买咖啡的人数</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>甲组(500人)</td>
<td>500</td>
<td>450</td>
<td></td>
</tr>
<tr>
<td>已组(500人)</td>
<td>0</td>
<td>450</td>
</tr>
</tbody>
</table>
</div>
<p><strong>解答：</strong></p>
<ul>
<li>茶叶—&gt; 咖啡的支持度为： $Support(X—&gt;Y)  = 450/500 = 90\%$</li>
<li>茶叶—&gt;咖啡的置信度为： $Confidence(X—&gt;Y) = 450/500 = 90\%$</li>
<li>茶叶—&gt;咖啡的提升度为：$Lift(X—&gt;Y) = Confidence(X—&gt;Y) / P(Y) = 90\% / ((450+450) / 1000) = 1$</li>
</ul>
<p>由于提升度Lift(X→Y) =1，表示X与Y相互独立，即是否有X，对于Y的出现无影响。也就是说，是否购买咖啡，与有没有购买茶叶无关联。即规则”茶叶→咖啡“不成立，或者说关联性很小，几乎没有，虽然它的支持度和置信度都高达90%，但它不是一条有效的关联规则。</p>
<h3><span id="2-如果数据有问题怎么处理">2. 如果数据有问题，怎么处理?</span></h3><ul>
<li>上下采样平衡正负样例比</li>
<li>考虑缺失值</li>
<li>数据归一化</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>机器学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Trick-Dropout</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Trick%20-%20Dropout/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#trick-dropout">Trick - Dropout</a><ul>
<li><a href="#思想">思想</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-为何-dropout-能够解决过拟合">1. 为何 Dropout 能够解决过拟合？</a></li>
<li><a href="#2-drpout-与-bagging-有何不同">2. Drpout 与 Bagging 有何不同？</a></li>
<li><a href="#3-dropout-有什么缺陷">3. Dropout 有什么缺陷？</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="trick-dropout">Trick - Dropout</span></h1><hr>
<h2><span id="思想">思想</span></h2><ul>
<li><p><strong>思想：</strong> 在每次训练过程中随机地忽略一些神经元。这些神经元被随机地“抛弃”了。也就是说它们在正向传播过程中对于下游神经元的贡献效果暂时消失了，反向传播时该神经元也不会有任何权重的更新。</p>
</li>
<li><p><strong>注意：</strong>每次迭代的过程中，我们删除的神经单元是随机的，本次删除的与上次删除神经元是不一样的</p>
</li>
</ul>
<p>简单来说，Dropout 通过<strong>参数共享</strong>提供了一种廉价的 Bagging 集成近似—— Dropout 策略相当于集成了包括所有从基础网络除去部分单元后形成的子网络。</p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-为何-dropout-能够解决过拟合">1. 为何 Dropout 能够解决过拟合？</span></h3><ul>
<li><p><strong>取平均的作用：</strong>  先回到正常的模型（没有dropout），我们用相同的训练数据去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用 “5个结果取均值”或者“多数取胜的投票策略”去决定最终结果。这种“综合起来取平均”的策略通常可以有效防止过拟合问题。因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。</p>
<p>dropout 掉不同的隐藏神经元就类似在训练不同的网络（随机删掉一半隐藏神经元导致网络结构已经不同)，整个dropout过程就相当于 对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</p>
</li>
<li><p><strong>减少神经元之间复杂的共适应关系：</strong> 因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。（这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况）。 迫使网络去学习更加鲁棒的特征 （这些特征在其它的神经元的随机子集中也存在）。</p>
<p>换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的模式（鲁棒性）。（这个角度看 dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高）</p>
</li>
</ul>
<h3><span id="2-drpout-与-bagging-有何不同">2. Drpout 与 Bagging 有何不同？</span></h3><ul>
<li>在 Bagging 的情况下，所有模型都是独立的；而在 Dropout 的情况下，所有模型<strong>共享参数</strong>，其中每个模型继承父神经网络参数的不同子集。</li>
<li>在 Bagging 的情况下，每一个模型都会在其相应训练集上训练到收敛。而在 Dropout 的情况下，通常大部分模型都没有显式地被训练；取而代之的是，在单个步骤中我们训练一小部分的子网络，参数共享会使得剩余的子网络也能有好的参数设定。</li>
</ul>
<h3><span id="3-dropout-有什么缺陷">3. Dropout 有什么缺陷？</span></h3><p>dropout一大缺点就是代价函数J不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数J每次迭代后都会下降，因为我们所优化的代价函数J实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。</p>
<p>我通常会关闭dropout函数，将keep-prob的值设为1，运行代码，确保J函数单调递减。然后打开dropout函数，希望在dropout过程中，代码并未引入bug。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与dropout方法一起使用。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Trick-normalization</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Trick%20-%20Normalization/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#0-归一化">0 . 归一化</a><ul>
<li><a href="#1-归一化手段">1. 归一化手段</a></li>
<li><a href="#2-min-max-与-zero-mean-区别">2. Min-max 与 Zero-mean 区别</a></li>
<li><a href="#3-为何归一化为何如此优秀">3. 为何归一化为何如此优秀？</a></li>
</ul>
</li>
<li><a href="#1-batch-normalization">1. Batch Normalization</a></li>
<li><a href="#2-layer-normalization">2. Layer Normalization</a></li>
<li><a href="#3-weight-normalization-todo">3. Weight Normalization — TODO</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#0-什么是-ics">0. 什么是 ICS？</a></li>
<li><a href="#0-ics-会导致什么问题">0. ICS 会导致什么问题？</a></li>
<li><a href="#1-bn-到底解决了什么问题">1. BN 到底解决了什么问题？</a></li>
<li><a href="#2-bn-的优点与缺点">2. BN 的优点与缺点</a></li>
<li><a href="#3-为何训练时不采用移动平均">3. 为何训练时不采用移动平均？</a></li>
<li><a href="#4-bn-与-ln-的区别是什么">4. BN 与 LN 的区别是什么？</a></li>
<li><a href="#5-什么时候使用-bn-或-ln">5. 什么时候使用 BN 或 LN？</a></li>
<li><a href="#6-bn-在何处做">6. BN 在何处做？</a></li>
<li><a href="#7-为什么要归一化">7. 为什么要归一化？</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="0-归一化">0 . 归一化</span></h2><h3><span id="1-归一化手段">1. 归一化手段</span></h3><ul>
<li><p><strong>Min-max 归一化：</strong>当有新数据加入时， 可能导致max和min的变化， 需要重新定义。</p>
<script type="math/tex; mode=display">
 x^* = \frac{x -min } {max - min}</script></li>
<li><p><strong>Zero-mean 归一化：</strong>均值为0，标准差为1的标准正态分布。 z-score标准化方法适用于属性A的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。该种标准化方式要求原始数据的分布可以近似为高斯分布，否则效果会变得很糟糕。</p>
<script type="math/tex; mode=display">
x^* = \frac{x- \mu }{\sigma}</script></li>
</ul>
<h3><span id="2-min-max-与-zero-mean-区别">2. Min-max 与 Zero-mean 区别</span></h3><ul>
<li>对于输出结果范围有要求， 使用Min-max normalization </li>
<li>数据较为稳定， 不存在极端最大值，最小值， 用归一化</li>
<li>如果数据存在异常值或较多噪音， 使用标准化。</li>
</ul>
<h3><span id="3-为何归一化为何如此优秀">3. 为何归一化为何如此优秀？</span></h3><p>归一化的本质就是<strong>线性变换</strong>。 线性变化的诸多良好性质，决定了为什么对数据进行改变后不会造成“失效”，还能提高数据的表现。</p>
<p><strong>归一化加快了梯度下降求最优解的速度。</strong></p>
<p>假定一个预测房价的例子，两个特征： 面积与房间数，那么则有： $y = \theta_1 x_1 + \theta_2x_2$， $x_1$ 表房间数，$x_2$ 表面积 ， 现实中，面积范围往往在 $1-1000$， 而房间通常为 $1-10$， 那么面积对模型的影响要更大一些，此时寻求最优解的过程为：</p>
<p><img data-src="..\img\Normalization\1.jpg" alt="1"></p>
<p>归一化后，寻求最优解的过程为：</p>
<p><img data-src="D:\Github\NLPer-Interview\img\Normalization\2.jpg" alt="2"></p>
<p>在未归一化的时候， 由于 $\theta_1$ 的更新幅度要比  $\theta_2$ 小， 因此  $\theta_2$ 的应该要比  $\theta_1$ 要大，但是在实际中，我们使用常规梯度下降法时，我们各个的学习率都是一样的，这也就造成了 $\theta_2$ 的更新会比较慢，结果就是寻求最优解的过程会走很多弯路导致模型收敛速度缓慢。</p>
<p>我们来实际举例， 假设在未归一化的时候， 我们的损失函数为：</p>
<script type="math/tex; mode=display">
J = (3 \theta_1 + 600 \theta_2 - \hat{y})^2</script><p>那么经过归一化后，我们的损失函数可能就变为：</p>
<script type="math/tex; mode=display">
J = (0.5 \theta_1 + 0.55 \theta_2 - \hat{y})^2</script><p>很明显可以看到，数据归一化后， 最优解的寻找过程会很平缓，更容易正确收敛到最优解。</p>
<p>其次，还有一些博客中提到，<strong>归一化有可能提高精度</strong>， 这在涉及到一些距离计算的算法时效果显著。</p>
<h2><span id="1-batch-normalization">1. Batch Normalization</span></h2><p>假设一个 batch 为 m 个输入 $B = {x_{1, \cdots, m}}$ , BN 在这 m 个数据之间做 Normalization， 并学习参数 $\gamma , \beta$：</p>
<script type="math/tex; mode=display">
\mu_B \leftarrow \frac{1}{m} \sum_{i=1}^{m} x_i    \\
\sigma_B^2 \leftarrow \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2  \\
\hat{x}_i  \leftarrow \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} \\
y_i \leftarrow \gamma \hat{x}_i + \beta \equiv BN_{\gamma, \beta}{(x_i)}</script><h2><span id="2-layer-normalization">2. Layer Normalization</span></h2><p>LN 不同于 BN， 其在层内进行 Normalization， 即直接对隐层单元的输出做 Normalization。最大的好处是不再依赖 batch size。 </p>
<script type="math/tex; mode=display">
u^l = \frac{1}{H} \sum_{i=1}^H a_i^l \\
\sigma^l = \sqrt{\frac{1}{H}\sum_{i=1}^H(a_i^l - u^l)^2} \\
\hat{a}_i^l  \leftarrow \frac{a_i^l - \mu^l}{\sqrt{\sigma_l^2 + \epsilon}} \\
y_i^l \leftarrow \gamma \, \hat{a}_i^l + \beta \equiv LN_{\gamma, \beta}{(a_i^l)}</script><ul>
<li>H： 某层中的隐层单元数</li>
</ul>
<h2><span id="3-weight-normalization-todo">3. Weight Normalization — TODO</span></h2><hr>
<h2><span id="qa">QA</span></h2><h3><span id="0-什么是-ics">0. 什么是 ICS？</span></h3><p>ICS 指的是在训练过程中由于网络参数的变化而导致各层网络的输入分布发生了变化， 而深层网络通过层层叠加，高层的输入分布变化会非常剧烈，这就需要高层不断去重新适应底层的参数更新。而为了训好模型，我们需要非常谨慎的去设定学习率， 初始化权重等。</p>
<p>从数学角度来看，它指的是源空间与目标空间的条件概率是一致的，但是其边缘概率不同。 即对所有 $x \in X, P_s(Y|X=x) = P_t(Y|X=x)$ ， 但是 $P_s(X) \neq P_t(X)$ 。</p>
<p>其实，通俗理解来说，就是对于神经网络的各层输出，由于经过了一系列的隐层操作，其分布显然与各层对应的输入数据分布不同，且这种差距会随着网络深度的增加而加大。而在训练过程中， 网络参数的变化会使得各层网络的输入分布发生变化，越深的网络，变化可能越大。</p>
<h3><span id="0-ics-会导致什么问题">0. ICS 会导致什么问题？</span></h3><ul>
<li>上层参数需要不断适应新的输入数据分布，降低学习速度</li>
<li>下层输入的变化可能趋向于变大或变小，导致上层落入饱和区，使得学习过早停止。</li>
<li>每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。</li>
</ul>
<h3><span id="1-bn-到底解决了什么问题">1. BN 到底解决了什么问题？</span></h3><ul>
<li><p>解释1： 原论文说 BN 解决了 ICS 问题，但后续有论文推翻了这个结论，参见：《How Does Batch Normalization Help Optimization》</p>
</li>
<li><p>解释2： 为了防止梯度消失，这也很好理解， BN 将激活函数的输入数据压缩在 N(0,1) 空间内，的确能够很大程度上减轻梯度消失问题。</p>
</li>
<li><p>解释3： 来源于《How Does Batch Normalization Help Optimization》 ， BN 使得优化空间更加平滑，具体来说，BN实际上是改变了损失函数的 lipschitz 性质， 使得梯度的改变变得很轻微，这使得我们可以采用更大的步长且仍然能够保持对实际梯度方向的精确估计。</p>
<p>通俗来讲， 不进行BN， 损失函数不仅仅非凸且趋向于坑洼，平坦区域和极小值，这使得优化算法极不稳定，使得模型对学习率的选择和初始化方式极为敏感，而BN大大减少了这几种情况发生。</p>
</li>
</ul>
<p>我个人更倾向于第三种解释。</p>
<h3><span id="2-bn-的优点与缺点">2. BN 的优点与缺点</span></h3><ul>
<li><p>BN 的优点：</p>
<blockquote>
<ul>
<li>加速网络训练（缓解梯度消失，支持更大的学习率）</li>
<li>抑制过拟合</li>
<li>降低了<strong>参数初始化</strong>的要求。</li>
</ul>
</blockquote>
</li>
<li><p>BN 的缺点：</p>
<blockquote>
<ul>
<li><strong>对 batch size的要求较高</strong>。这是因为如果 batch size 过小，无法估计出全局的样本分布</li>
<li><strong>训练和预测时有些差别。</strong>训练时一个 batch 之间进行 Normalization， 预测时需要依靠训练时获得的 均值和方差来进行预测。</li>
</ul>
</blockquote>
</li>
</ul>
<h3><span id="3-为何训练时不采用移动平均">3. 为何训练时不采用移动平均？</span></h3><p>参见： 《Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models》</p>
<ul>
<li>使用 BN 的目的就是为了保证每批数据的分布稳定，使用全局统计量反而违背了这个初衷；</li>
<li>BN 的作者认为在训练时采用移动平均可能会与梯度优化存在冲突；</li>
</ul>
<h3><span id="4-bn-与-ln-的区别是什么">4. BN 与 LN 的区别是什么？</span></h3><p>LN 对层进行 Normalization ， BN 对 batch 进行 Normalization。 LN 拜托了对 batch size 的依赖， 在 NLP 领域，使用极为广泛， 基本不用 BN。 </p>
<p>我个人的认为是， BN 是对batch进行操作，然而， 语言的复杂度使得 一个 batch 的数据对于全局的数据分布估计极为不准，这使得 BN 的效果变得很差。</p>
<h3><span id="5-什么时候使用-bn-或-ln">5. 什么时候使用 BN 或 LN？</span></h3><ul>
<li>一般只在深层网络中使用， 比如在深层的 Transformer 中， LN 就起到了很关键的作用。 </li>
<li>BN 与 LN 应用在非线性映射前效果更佳。</li>
<li>当你发现你的网络训练速度慢，梯度消失，爆炸等问题时， 不妨考虑加入 BN 或 LN 来试试。</li>
<li>使用 BN 时， 对 batch size 要求较高， 且在训练前需要对数据进行 shuffle。</li>
</ul>
<h3><span id="6-bn-在何处做">6. BN 在何处做？</span></h3><p>BN 可以对<strong>第 L 层激活函数输出值</strong>或<strong>对第 L层激活函数的输入值</strong>进行 Normalization， 对于两个不同的位置，不少研究已经表明：<strong>放在第 L 层激活函数输出值会更好</strong>。</p>
<h3><span id="7-为什么要归一化">7. 为什么要归一化？</span></h3><ul>
<li>归一化的确可以避免一些不必要的数值问题。</li>
<li>为了程序运行时收敛加快。 </li>
<li>统一量纲。样本数据的评价标准不一样，需要对其量纲化，统一评价标准。这算是应用层面的需求。</li>
<li>避免神经元饱和。啥意思？就是当神经元的激活在接近 0 或者 1 时会饱和，在这些区域，梯度几乎为 0，这样，在反向传播过程中，局部梯度就会接近 0，这会有效地“杀死”梯度。</li>
<li>保证输出数据中数值小的不被吞食。 </li>
</ul>
<h2><span id="reference">Reference</span></h2><p>[1] Batch Normalization</p>
<p>[2] Layer Normalization</p>
<p>[3] How Does Batch Normalization Help Optimization</p>
<p>[4]  Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models</p>
<p><a href="https://www.zhihu.com/question/38102762/answer/85238569">深度学习中 Batch Normalization为什么效果好？</a> - 知乎 </p>
<p><a href="http://www.cvmart.net/community/article/detail/368">深度学习中的Normalization模型</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Trick-学习率衰减</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Trick%20-%20%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#为什么要进行学习率衰减">为什么要进行学习率衰减？</a></li>
<li><a href="#学习率衰减策略">学习率衰减策略</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="为什么要进行学习率衰减">为什么要进行学习率衰减？</span></h2><p>随着训练的加深，当模型训练到一定程度后，损失将不再减少，这个时候模型的一阶梯度接近于0， 对应的 Hessian 矩阵通常是两种情况：</p>
<ul>
<li>正定，即所有特征值均为正，此时通常可以得到一个局部极小值，若这个局部极小值接近全局最小则模型已经能得到不错  的性能了，但若差距很大，则模型性能还有待于提升，通常情况下后者在训练初最常见。</li>
<li>特征值有正有负，此时模型很可能陷入了鞍点，若陷入鞍点，模型性能表现就很差。</li>
</ul>
<p>以上两种情况在训练初期以及中期，此时若仍然以固定的学习率，会使模型陷入左右来回的震荡或者鞍点，无法继续优化。所以，学习率衰减或者增大能帮助模型有效的减少震荡或者逃离鞍点。</p>
<h2><span id="学习率衰减策略">学习率衰减策略</span></h2><p>参见 500 questions 第14 章</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Trick-提前终止</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Trick%20-%20%E6%8F%90%E5%89%8D%E7%BB%88%E6%AD%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#early-stop-but-when-1">Early Stop, but when? [1]</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p>前期对该Trick的重视度不够， 想着，不就是过拟合吗？ 我只要保存 验证集 loss 最低点的模型， 你过拟合管我什么事情， 然而， 上了 Bert + 中大规模数据集之后， 我才发现什么叫做噩梦 — 训练时间太 bb 长了吧。 </p>
<p>那还能咋地， 你总不能把 epoch 数量设置的太小吧， 10 是比较基本的吧（看数据集)，但这样跑也能跑个一天一夜，枯了。 这个时候这个Trick 就很有用了，大大节省模型训练时间。</p>
<p>提前终止指的是<strong>当验证集的误差连续 <code>n</code>次递增时停止训练</strong>。 一般情况下， 我会先将<code>n</code>设置为一个较大的数， 跑一个较大的 epoch（如20）， 然后根据 loss 曲线来选择合适的 epoch 数量和 <code>n</code>， 接下来就欢快的嘿嘿嘿了。</p>
<p>需要注意的是，提前终止有其他很多策略，上面提到的只是很常用的一种，至于什么时候选择什么样的提前终止策略也是一个经验活， 还好， [1] 中为我们提供了一些参考， 值得一看。 由于本人经验时间优先，没有深入探讨，希望有大佬帮忙解惑。下面我简单提一下[1] 中是如何建议的。</p>
<h2><span id="early-stop-but-when-1">Early Stop, but when? [1]</span></h2><p>首先，思考一个问题： 如果我们以验证集loss最小值来作为保存模型的依据，那么这会不会对模型的泛化能力产生影响？我个人认为是<strong>不会</strong>，具体需要看Loss曲线图。一般而言，第一次跑的时候，我往往会设置一个很大的 epoch， 这样能够直观的从Loss曲线上看到很多信息，从而帮助我来选择更佳合适 epoch数量， 我个人一般取开始过拟合之后两个epoch作为epoch的最终数量。</p>
<p>我自己做实验发现，在验证集loss最低点不一定能够获得在测试集上最好的效果，有时候，最低点附近的一些点反而在测试集上表现更佳，但差别不大，这也是我认为不会影响模型泛化能力的一个依据， 而实际落地中，这点差别其实真的没有啥鸟用。</p>
<p>回到Trick， 文章谈到， 何时提前停止是对训练时间和泛化误差之间的权衡， 而如果我采用在验证集loss最低点存储模型的方式，那么何时提前停止就不再是对泛化误差的权衡了， 其变成了，如何选择何种的策略来对<strong>训练时间</strong>以及<strong>获取验证集loss全局最低点</strong>来做权衡，使得我们能够找到该点并保存模型，而不至于陷入一些困境[2]。</p>
<p>最后谈谈 Early Stop 策略， 选择合适的策略能够使得我们在合适的时间终止整个训练，从而节省时间。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Trick-正则化</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Trick%20-%20%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#正则化">正则化</a><ul>
<li><a href="#1-l1-正则化-稀疏正则化">1. L1 正则化 - 稀疏正则化</a></li>
<li><a href="#2-l2-正则化-权重衰减">2. L2 正则化 — 权重衰减</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-为何只对权重进行正则惩罚而不针对偏置">1. 为何只对权重进行正则惩罚，而不针对偏置</a></li>
<li><a href="#2-权重衰减的目的">2. 权重衰减的目的</a></li>
<li><a href="#3-l1-与-l2-的异同">3. L1 与 L2 的异同</a></li>
<li><a href="#4为什么-l1-正则化-可以产生稀疏值而-l2-不会">4.为什么 L1 正则化 可以产生稀疏值，而 L2 不会？</a></li>
<li><a href="#5-为何-l1-和-l2-正则化可以防止过拟合">5. 为何 L1 和 L2 正则化可以防止过拟合？</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="正则化">正则化</span></h1><hr>
<p><a href="https://blog.csdn.net/jinping_shi/article/details/52433975">https://blog.csdn.net/jinping_shi/article/details/52433975</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/38709373">https://zhuanlan.zhihu.com/p/38709373</a></p>
<p><a href="https://blog.csdn.net/heyongluoyao8/article/details/49429629">https://blog.csdn.net/heyongluoyao8/article/details/49429629</a></p>
<h2><span id="1-l1-正则化-稀疏正则化">1. L1 正则化 - 稀疏正则化</span></h2><p>1-范数: 表示向量元素的绝对值之和。</p>
<script type="math/tex; mode=display">
||x|| =\sum_{i=1}^N |x_i|</script><script type="math/tex; mode=display">
正则化项： \Omega(\theta) = ||w||_1 =  \sum_i |w_i| \\
目标函数： \tilde{J}(w;X,y) = \alpha ||w||_1  + J(w;X,y)  \\
梯度： \nabla_w \tilde{J}(w;X,y) = \alpha sign(w) + \nabla_w J(w;X,y) \\</script><p>不同于L2，L1 正则化使得权重值可能被减少到0。 因此，L1对于压缩模型很有用。</p>
<p>稀疏向量通常会有许多维度，如果再加上使用特征组合会导致包含更多的维度的。由于使用此类高维度特征向量，因此模型可能会非常庞大，并且需要大量的 RAM。</p>
<p>在高维度稀疏矢量中，最好尽可能使权重正好降至 <code>0</code>。正好为 0 的权重基本上会使相应特征从模型中移除。 将特征设为 0 可节省 RAM 空间，且可以减少模型中的噪点。</p>
<h2><span id="2-l2-正则化-权重衰减">2. L2 正则化 — 权重衰减</span></h2><p>2-范数： 表示向量元素绝对值的平方和再开方。</p>
<script type="math/tex; mode=display">
||x|| = \sqrt{\sum_{i=1}^N x_i^2}</script><script type="math/tex; mode=display">
正则化项： \Omega(\theta) = \frac{1}{2} ||w||_2^2  = \frac{1}{2}w^Tw \\
目标函数： \tilde{J}(w;X,y) = \frac{\alpha}{2}w^Tw  + J(w;X,y)  \\
梯度： \nabla_w \tilde{J}(w;X,y) = \alpha w + \nabla_w J(w;X,y) \\
梯度更新 ： w \leftarrow (1- \epsilon \alpha) w - \epsilon \nabla_w J(w;X,y)</script><p>L2正则化又称权重衰减。因为其导致权重<strong>趋向于0</strong>（但不全是0）。</p>
<p>执行 L2 正则化对模型具有以下影响：</p>
<ul>
<li>使权重值接近于 0（但并非正好为 0）</li>
<li>使权重的平均值接近于 0，且呈正态分布。</li>
</ul>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-为何只对权重进行正则惩罚而不针对偏置">1. 为何只对权重进行正则惩罚，而不针对偏置</span></h3><p>在神经网络中，参数包括每一层仿射变换的<strong>权重</strong>和<strong>偏置</strong>，我们通常只对权重做惩罚而不对偏置做正则惩罚。</p>
<p>精确拟合偏置所需的数据通常比拟合权重少得多。每个权重会指定两个变量如何相互作用。我们需要在各种条件下观察这两个变量才能良好地拟合权重。而每个偏置仅控制一个单变量。这意味着，我们不对其进行正则化也不会导致太大的方差。另外，正则化偏置参数可能会导致明显的欠拟合。</p>
<h3><span id="2-权重衰减的目的">2. 权重衰减的目的</span></h3><p>限制模型的学习能力，通过限制参数 θ 的规模（主要是权重 w 的规模，偏置 b 不参与惩罚），使模型偏好于权值较小的目标函数，防止过拟合。</p>
<h3><span id="3-l1-与-l2-的异同">3. L1 与 L2 的异同</span></h3><ul>
<li><p>相同点：限制模型的学习能力，通过限制参数的规模，使模型偏好于权值较小的目标函数，防止过拟合。</p>
</li>
<li><p>不同点：</p>
<blockquote>
<ul>
<li>L1是模型各个参数的绝对值之和；L2为各个参数平方和的开方值。</li>
<li>L1 正则化可以产生<strong>稀疏权值矩阵</strong>，即产生一个稀疏模型，可以用于特征选择；L2 会趋向于生成一个参数值很小的矩阵。</li>
<li>L1 适用于特征之间有关联的情况； L2 适用于特征之间没有关联的情况</li>
</ul>
</blockquote>
</li>
</ul>
<h3><span id="4为什么-l1-正则化-可以产生稀疏值而-l2-不会">4.为什么 L1 正则化 可以产生稀疏值，而 L2 不会？</span></h3><p>添加 L1 正则化，相当于在 L1范数的约束下求目标函数 J 的最小值，下图展示了二维的情况：</p>
<p><img data-src="..\img\正则化\L1.png" alt="L1"></p>
<p>图中 J 与 L 首次相交的点就是最优解。L1 在和每个坐标轴相交的地方都会有“角”出现（多维的情况下，这些角会更多），在角的位置就会产生稀疏的解。而 J 与这些“角”相交的机会远大于其他点，因此 L1 正则化会产生稀疏的权值。</p>
<p>对于 L2 正则化来说，其二维平面下的图形为：</p>
<p><img data-src="..\img\正则化\L2.png" alt="L2"></p>
<p>如上图所示， 相比于 L1 正则化， L2 不会产生 “角”， 因此 J 与 L2 相交的点具有稀疏性的概率就会变得非常小。</p>
<h3><span id="5-为何-l1-和-l2-正则化可以防止过拟合">5. 为何 L1 和 L2 正则化可以防止过拟合？</span></h3><p>L1 &amp; L2 正则化会使模型偏好于更小的权值。</p>
<p>简单来说，更小的权值意味着更低的模型复杂度，也就是对训练数据的拟合刚刚好，不会过分拟合训练数据（比如异常点，噪声），以提高模型的泛化能力。</p>
<p>此外，添加正则化相当于为模型添加了某种限制，规定了参数的分布，从而降低了模型的复杂度。模型的复杂度降低，意味着模型对于噪声与异常点的抗干扰性的能力增强，从而提高模型的泛化能力。 — <strong>奥卡姆剃刀原理</strong></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Trick - 融合训练集，验证集，测试集</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/Trick%20-%20%E8%9E%8D%E5%90%88%E8%AE%AD%E7%BB%83%E9%9B%86%EF%BC%8C%E9%AA%8C%E8%AF%81%E9%9B%86%EF%BC%8C%E6%B5%8B%E8%AF%95%E9%9B%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="trick-融合训练集验证集测试集">Trick - 融合训练集，验证集，测试集</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>continual learning</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/continual%20learning/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="continual-learning">continual learning</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>主动学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#主动学习">主动学习</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="主动学习">主动学习</span></h1><p>思路：通过机器学习的方法获取到那些比较难分类的样本数据，让人工再次确认和审核，然后将人工标注得到的数据再次使用有监督学习模型或半监督学习模型进行训练，逐步提升模型效果，将人工姜妍融入机器学习的模型中。</p>
<p>主动学习的流程：</p>
<ol>
<li>机器学习模型：包括机器学习模型的训练和预测两部分；</li>
</ol>
<p><a href="https://zhuanlan.zhihu.com/p/301117945">https://zhuanlan.zhihu.com/p/301117945</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基本单元-CNN</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%20-%20CNN/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-卷积层">1. 卷积层</a><ul>
<li><a href="#1-原理">1. 原理</a></li>
<li><a href="#2-卷积的作用">2. 卷积的作用</a></li>
<li><a href="#3-一些常见的卷积核">3. 一些常见的卷积核</a></li>
<li><a href="#4-卷积核的参数">4. 卷积核的参数</a></li>
<li><a href="#5-几种常见的卷积方式-todo">5. 几种常见的卷积方式 -TODO</a></li>
<li><a href="#6-从-pytorch-看一维卷积二维卷积三维卷积">6. 从 pytorch 看一维卷积，二维卷积，三维卷积</a><ul>
<li><a href="#参数说明">参数说明</a></li>
<li><a href="#一维卷积">一维卷积</a></li>
<li><a href="#二维卷积">二维卷积</a></li>
<li><a href="#三维卷积">三维卷积</a></li>
</ul>
</li>
<li><a href="#7-卷积核的选择">7. 卷积核的选择</a></li>
</ul>
</li>
<li><a href="#2-激活层">2. 激活层</a></li>
<li><a href="#3-池化层-需要补充">3. 池化层 — 需要补充</a></li>
<li><a href="#4-卷积层与池化层比较">4. 卷积层与池化层比较</a></li>
<li><a href="#5-nlp-与-cv-中使用-cnn-的区别">5. NLP 与 CV 中使用 CNN 的区别</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-为什么需要-padding">1. 为什么需要 Padding ？</a></li>
<li><a href="#2-为什么卷积核设计尺寸都是奇数">2. 为什么卷积核设计尺寸都是奇数</a></li>
<li><a href="#3-卷积操作的特点">3. 卷积操作的特点</a></li>
<li><a href="#4-你觉得-cnn-有什么不足">4. 你觉得 CNN 有什么不足？</a></li>
<li><a href="#5-cnn-与-rnn-的优劣">5. CNN 与 RNN 的优劣</a></li>
<li><a href="#6-卷积池化的意义">6. 卷积，池化的意义</a></li>
<li><a href="#7-卷积中不同零填充的影响">7. 卷积中不同零填充的影响</a></li>
<li><a href="#8-1-1-卷积的作用">8. 1 * 1 卷积的作用？</a></li>
<li><a href="#9-卷积核是否越大越好">9. 卷积核是否越大越好？</a></li>
<li><a href="#10-如何减少卷积层参数量">10. 如何减少卷积层参数量？</a></li>
<li><a href="#11-cnn-特点">11. CNN 特点</a></li>
<li><a href="#12-为何较大的batch-size-能够提高-cnn-的泛化能力">12. 为何较大的batch size 能够提高 CNN 的泛化能力？</a></li>
<li><a href="#13-same-与-valid-的区别">13. SAME 与 VALID 的区别</a></li>
<li><a href="#14-cnn-优缺点">14. CNN 优缺点</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a href="https://mp.weixin.qq.com/s/aLy2yv65v2fnv-t8IEgMxQ">https://mp.weixin.qq.com/s/aLy2yv65v2fnv-t8IEgMxQ</a></p>
<h2><span id="1-卷积层">1. 卷积层</span></h2><h3><span id="1-原理">1. 原理</span></h3><p><img data-src="../img/CNN/1.gif" alt="1"></p>
<p>卷积操作原理上其实是对两个矩阵进行<strong>点乘求和</strong>的数学操作，其中一个矩阵为<strong>输入的数据矩阵</strong>，另一个矩阵则为<strong>卷积核</strong>（滤波器或特征矩阵），求得的结果表示为原始图像中提取的特定局部特征。</p>
<h3><span id="2-卷积的作用">2. 卷积的作用</span></h3><p>在图像领域中，深层卷积已经证明比浅层卷积更具表征，从图像的特征提取来看， 不同卷积操作提取到的特征类型是不相同的：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">卷积层次</th>
<th style="text-align:center">特征类型</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">浅层卷积</td>
<td style="text-align:center">边缘特征</td>
</tr>
<tr>
<td style="text-align:center">中层卷积</td>
<td style="text-align:center">局部特征</td>
</tr>
<tr>
<td style="text-align:center">深层卷积</td>
<td style="text-align:center">全局特征</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="3-一些常见的卷积核">3. 一些常见的卷积核</span></h3><p>在传统图像领域，已经证明一些特殊的卷积核能够执行边缘检测，锐化，模糊等操作， 如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">卷积作用</th>
<th style="text-align:center">卷积核</th>
<th style="text-align:center">卷积后图像</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">输出原图</td>
<td style="text-align:center">$\begin{bmatrix} 0 &amp; 0 &amp; 0 \ 0 &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 0 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat.jpg" alt="origin_img"></td>
</tr>
<tr>
<td style="text-align:center">边缘检测（突出边缘差异）</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 0 &amp; -1 \ 0 &amp; 0 &amp; 0 \ -1 &amp; 0 &amp; 1 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-edgeDetect.jpg" alt="edgeDetect-1"></td>
</tr>
<tr>
<td style="text-align:center">边缘检测（突出中间值）</td>
<td style="text-align:center">$\begin{bmatrix} -1 &amp; -1 &amp; -1 \ -1 &amp; 8 &amp; -1 \ -1 &amp; -1 &amp; -1 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-edgeDetect-2.jpg" alt="edgeDetect-2"></td>
</tr>
<tr>
<td style="text-align:center">图像锐化</td>
<td style="text-align:center">$\begin{bmatrix} 0 &amp; -1 &amp; 0 \ -1 &amp; 5 &amp; -1 \ 0 &amp; -1 &amp; 0 \end{bmatrix}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-sharpen.jpg" alt="sharpen_img"></td>
</tr>
<tr>
<td style="text-align:center">方块模糊</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 \end{bmatrix} \times \frac{1}{9}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-boxblur.jpg" alt="box_blur"></td>
</tr>
<tr>
<td style="text-align:center">高斯模糊</td>
<td style="text-align:center">$\begin{bmatrix} 1 &amp; 2 &amp; 1 \ 2 &amp; 4 &amp; 2 \ 1 &amp; 2 &amp; 1 \end{bmatrix} \times \frac{1}{16}$</td>
<td style="text-align:center"><img data-src="../img/CNN/cat-blur-gaussian.jpg" alt="gaussian_blur"></td>
</tr>
</tbody>
</table>
</div>
<h3><span id="4-卷积核的参数">4. 卷积核的参数</span></h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">参数名</th>
<th style="text-align:left">作用</th>
<th style="text-align:left">常见设置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Kernel Size</td>
<td style="text-align:left">卷积核的大小</td>
<td style="text-align:left">在过去常设为5，如LeNet-5；现在多设为3，通过堆叠$3\times3$的卷积核来达到更大的感受域</td>
</tr>
<tr>
<td style="text-align:center">Stride</td>
<td style="text-align:left">卷积步长</td>
<td style="text-align:left">常见设置为1，表示滑窗距离为1，可以覆盖所有相邻位置特征的组合；当设置为更大值时相当于对特征组合降采样</td>
</tr>
<tr>
<td style="text-align:center">Padding</td>
<td style="text-align:left">填充策略</td>
<td style="text-align:left"><code>SAME</code>： 表示对不足卷积核大小的边界位置进行某种填充（通常零填充）以保证卷积输出维度与与输入维度一致；<code>VALID</code>时则对不足卷积尺寸的部分进行舍弃，输出维度就无法保证与输入维度一致</td>
</tr>
<tr>
<td style="text-align:center">In Channels</td>
<td style="text-align:left">卷积核的深度</td>
<td style="text-align:left">默认与输入的特征矩阵通道数（深度）一致；在某些压缩模型中会采用通道分离的卷积方式</td>
</tr>
<tr>
<td style="text-align:center">Out Channels</td>
<td style="text-align:left">卷积核的个数</td>
<td style="text-align:left">若设置为与输入通道数一样的大小，可以保持输入输出维度的一致性；若采用比输入通道数更小的值，则可以减少整体网络的参数量</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="5-几种常见的卷积方式-todo">5. 几种常见的卷积方式 -TODO</span></h3><p><a href="https://zhuanlan.zhihu.com/p/28186857">https://zhuanlan.zhihu.com/p/28186857</a></p>
<h3><span id="6-从-pytorch-看一维卷积二维卷积三维卷积">6. 从 pytorch 看一维卷积，二维卷积，三维卷积</span></h3><h4><span id="参数说明">参数说明</span></h4><p>卷积操作常用的有一维卷积，二维卷积与三维卷积，其中，三维卷积用到就比较少了， 三个类在 Pytorch 中的参数都是一样的，只是输入输出维度有所差别罢了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">in_channels: 输入数据的通道数</span><br><span class="line">out_channels: 卷积操作产生的输出通道数</span><br><span class="line">kernels: 卷积核的大小， int 或 tuple， 卷积核的大小设置是需要反复实验测试的。</span><br><span class="line">stride: 卷积步伐，stride 太小，会导致重复计算较多，计算量大； 而太大，有可能会造成特征遗漏。</span><br><span class="line">padding: 输入数据的每一条边填充0的层数， int 或 tuple, 默认为0</span><br><span class="line">padding_mode： 填充方式， zeros： 以0为填充数据</span><br><span class="line">dilation: 卷积核中元素之间的间距， 默认为 1</span><br><span class="line">groups: 从输入通道到输出通道的阻塞连接数， 默认为1</span><br><span class="line">bias: 是否添加 bias， 默认为True</span><br></pre></td></tr></table></figure>
<h4><span id="一维卷积">一维卷积</span></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class torch.nn.Conv1d:</span><br><span class="line"></span><br><span class="line">-- 输入输出数据：</span><br><span class="line">	Input: [N, C_in, L_in]: [batch_size, in_channels, input_len]</span><br><span class="line">    Output: [N, C_out, L_out]: [batch_size, out_channels, output_len]</span><br><span class="line"></span><br><span class="line">-- 参数：</span><br><span class="line">	权重参数： [out_channels, in_channels/groups, kernel_size], 默认初始化为均匀分布 </span><br><span class="line">	Bias参数： [out_channels], 默认初始化为均匀分布</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
L_{out} = \frac{L_{in} + 2 * padding - dilation * (kernel\_size - 1)-1}{stride} + 1</script><p>一维卷积在NLP中常用于 Embedding 部分来提取特征，如在TextCNN中就有使用， 此时可以将词向量维度理解为通道数<code>C_in</code>， 输入序列的长度为 <code>L_in</code>。</p>
<p>注意一点的是，在一维卷积中，卷积核的大小是一维的， 即如 果指定为 n， 则卷积核的大小为 <code>[n, 1, 1]</code>。 </p>
<h4><span id="二维卷积">二维卷积</span></h4><p><img data-src="../img/CNN/2dconv.png" alt="2dconv"></p>
<ul>
<li>单通道：若输入卷积核尺寸为 $(k_h,k_w,1)$，卷积核在输入图像的空间维度上进行滑窗操作，每次滑窗和  $(k_h, k_w)$窗口内的值进行卷积操作，得到输出图像中的一个值。</li>
<li>多通道：输入图像特征通道数为3，卷积核尺寸为 $(k_h,k_w ,3)$ ,每次滑窗与3个通道上的 $(k_h , k_w) $窗口内的所有值进行卷积操作，得到输出图像中的一个值。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class torch.nn.Conv2d:</span><br><span class="line"></span><br><span class="line">-- 输入输出数据：</span><br><span class="line">	Input: [N, C_in, H_in, L_in]: [batch_size, in_channels, input_len]</span><br><span class="line">    Output: [N, C_out, H_out, L_out]: [batch_size, out_channels, output_len]</span><br><span class="line"></span><br><span class="line">-- 参数：</span><br><span class="line">	权重参数： [out_channels, in_channels/groups, kernel_size], 默认初始化为均匀分布 </span><br><span class="line">	Bias参数： [out_channels], 默认初始化为均匀分布</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
H_{out} = \frac{H_{in} + 2 \times padding[0] - dilation[0] \times (kernel\_size[0] -1) - 1}{stride[0]} + 1 \\
W_{out} = \frac{W_{in} + 2 \times padding[1] - dilation[1] \times (kernel\_size[1] -1) - 1}{stride[1]} + 1</script><h4><span id="三维卷积">三维卷积</span></h4><p><img data-src="../img/CNN/3dconv.png" alt="3dconv"></p>
<h3><span id="7-卷积核的选择">7. 卷积核的选择</span></h3><p>大卷积核虽然可以获取更大的感受域，但是大卷积核反而会导致计算量大幅增加，不利于训练更深层的模型，相应的计算能力也会降低。</p>
<p>堆叠2个 <strong>3×3</strong> 卷积核（二通道）可以获得与 <strong>5×5卷积核</strong> 相同的感受视野，同时参数量会更少（3×3×2+1&lt;5×5×1+1）,这也是 <strong>3×3卷积</strong> 应用更广泛的原因，在大多数情况下通过堆叠较小的卷积核比直接采用单个更大的卷积核会更加有效。</p>
<h2><span id="2-激活层">2. 激活层</span></h2><p>激活层本质就是采用激活函数对卷积出的特征做一个非线性变换。</p>
<ul>
<li>首选 Relu， 然后试试 Relu 变体 Leaky Relu 和 Maxout。</li>
<li>某些情况下 tanh 也能获得不错结果。</li>
</ul>
<h2><span id="3-池化层-需要补充">3. 池化层 — 需要补充</span></h2><p>池化层的<strong>作用</strong>是对感受域内的特征进行筛选，提取区域内最具代表性的特征，能够有效地降低特征尺度，进而减少模型所需要的参数量，此外还可以防止过拟合现象。</p>
<p>池化操作的本质是<strong>降采样</strong>。其除了能显著降低参数数量外，还能保持对平移，伸缩，旋转操作的不变性。</p>
<ul>
<li><p>常见的池化操作：选择指导 (Boureau et al., 2010)</p>
<blockquote>
<ul>
<li>最大池化： Max Pooling</li>
<li>平均值池化： Mean Pooling</li>
</ul>
</blockquote>
</li>
</ul>
<p>无论max pooling还是mean pooling,都没有需要学习的参数。因此，在<strong>卷积神经网络</strong>的训练中，Pooling层需要做的仅仅是将<strong>误差层</strong>传递到上一层，<strong>而没有梯度的计算。</strong></p>
<p>对于max Pooling，下一层的误差项的值会原封不动的传递到上一层对应区块中的最大值所对应的神经元，而其他神经元的误差项都是0。</p>
<p>对于 mean Pooling， 下一层的误差项会均匀划分到该层的所有的神经元上。</p>
<h2><span id="4-卷积层与池化层比较">4. 卷积层与池化层比较</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">卷积层</th>
<th style="text-align:center">池化层</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">结构</td>
<td style="text-align:center">零填充时输出维度不变，而通道数改变</td>
<td style="text-align:center">通常特征维度会降低，通道数不变</td>
</tr>
<tr>
<td style="text-align:center">稳定性</td>
<td style="text-align:center">输入特征发生细微改变时，输出结果会改变</td>
<td style="text-align:center">感受域内的细微变化不影响输出结果</td>
</tr>
<tr>
<td style="text-align:center">作用</td>
<td style="text-align:center">感受域内提取局部关联特征</td>
<td style="text-align:center">感受域内提取泛化特征，降低维度</td>
</tr>
<tr>
<td style="text-align:center">参数量</td>
<td style="text-align:center">与卷积核尺寸、卷积核个数相关</td>
<td style="text-align:center">不引入额外参数</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="5-nlp-与-cv-中使用-cnn-的区别">5. NLP 与 CV 中使用 CNN 的区别</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>NLP</th>
<th>CV</th>
</tr>
</thead>
<tbody>
<tr>
<td>卷积核</td>
<td>多为一维卷积， 通常都是由较为浅层的卷积层组成</td>
<td>对二维信号做卷积，一般设为叠加的3×3卷积核</td>
</tr>
<tr>
<td>Pooling</td>
<td>一般采用 Max-Pooling</td>
<td></td>
</tr>
<tr>
<td>全连接层</td>
<td>一般常采用LN + dropout</td>
<td>一般常采用BN + dropout</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-为什么需要-padding">1. 为什么需要 Padding ？</span></h3><p>图像是 <code>5 × 5</code>的矩阵，我们的卷积核是 <code>3 × 3</code>的，最终我们得出的feature map是 <code>3 × 3</code>的矩阵（<code>n -f + 1</code>) 。</p>
<p>这样会带来两个问题：</p>
<blockquote>
<ul>
<li><p>每一次做卷积操作时，你的图像就会缩小，如果这种情况发生多次，你的图像就会变得很小。</p>
</li>
<li><p>边缘的像素点所受到的关注点比中心的关注点少很多。比如上图的 <code>1 * 1</code> 的像素点只进行了一次卷积计算，而中心点 <code>3 * 3</code> 却进行了9次卷积计算，这明显是不公平的。这意味着图像边缘的信息大多都丢失了。</p>
</li>
</ul>
</blockquote>
<p>如果加上 paddding 之后，我们的 feature-map 就变为 <code>(n + 2p - f + 1) × (n + 2p - f + 1)</code>的矩阵。</p>
<p>Padding存在的意义在于：</p>
<blockquote>
<ul>
<li><p>为了不丢弃原图信息</p>
</li>
<li><p>为了保持feature map 的大小与原图一致</p>
</li>
<li><p>为了让更深层的layer的 input 依旧保持有足够大的信息量</p>
</li>
<li><p>为了实现上述目的，且不做多余的事情，padding出来的pixel的值都是0，不存在噪音问题。</p>
</li>
</ul>
</blockquote>
<h3><span id="2-为什么卷积核设计尺寸都是奇数">2. 为什么卷积核设计尺寸都是奇数</span></h3><ul>
<li>保证像素点中心位置，避免位置信息偏移</li>
<li>填充边缘时能保证两边都能填充，原矩阵依然对称</li>
</ul>
<h3><span id="3-卷积操作的特点">3. 卷积操作的特点</span></h3><ul>
<li><p><strong>稀疏交互：</strong>卷积神经网络中，卷积核尺度远小于输入的尺度，这样每个输出神经网仅与前一层区域内的神经元存在连接权重，我们称此为稀疏交互。</p>
<blockquote>
<ul>
<li>提高了模型的统计效率：原本一幅图像只能提供少量特征，现在每一块像素区域都可以提供一部分特征</li>
<li>使得参数大量减少，优化的时间复杂度也会减小几个数量级，过拟合情况也得到改善。 </li>
<li>稀疏交互的意义在于，<strong>先从局部的特征入手，再将局部特征组合起来形成更复杂和抽象的特征</strong>。</li>
</ul>
</blockquote>
</li>
<li><p><strong>参数共享：</strong> 参数共享指的是<strong>同一个模型的不同模块中使用相同的参数</strong>。参数共享的意义在于使得卷积层具有<strong>平移等特性</strong>。</p>
<blockquote>
<ul>
<li>权重共享一定程度上能增强参数之间的联系，获得更好的<strong>共性特征</strong>。</li>
<li>很大程度上降低了网络的参数，<strong>节省计算量和计算所需内存</strong>。</li>
<li>权重共享能起到<strong>很好正则的作用</strong>。正则化的目的是为了降低模型复杂度，防止过拟合，而权重共享则正好降低了模型的参数和复杂度。</li>
</ul>
</blockquote>
</li>
<li><p><strong>平移不变性：</strong>（局部）平移不变性是一个很有用的性质，尤其是当我们关心某个特征<strong>是否出现</strong>而不关心它出现的具体位置时。平移不变性是由于<strong>参数共享 和池化</strong> 所带来的。</p>
</li>
</ul>
<h3><span id="4-你觉得-cnn-有什么不足">4. 你觉得 CNN 有什么不足？</span></h3><ul>
<li><p><strong>信息损失问题。</strong> CNN在Pooling的时候会丢失大量的有价值信息，以及忽略局部与整体之间的关联性比如得分最高的特征只出现了一次，而得分第二高的特征出现了很多次，得分第二高的特征可能比最高的特征还要重要，却被丢弃了，自然造成了不小的信息损失</p>
</li>
<li><p><strong>忽略了位置信息</strong>：一个区域有用的特征极有可能和另一个区域的信息有联系，如TextCNN：对于一些粒度较粗的分类问题如话题分类，位置信息可能不大，但对于如情感分析这种粒度较细的分类问题，位置信息不足便会导致一些问题，如”虽然他长的很帅，但是人品不好”和”虽然他人品不好，但他长得帅啊”，在情感倾向上区别还是比较明显的。</p>
</li>
</ul>
<h3><span id="5-cnn-与-rnn-的优劣">5. CNN 与 RNN 的优劣</span></h3><ul>
<li>并行能力， 训练时间很漫长</li>
<li>RNN 容易发生<strong>梯度消失</strong>，包括 LSTM</li>
<li>CNN 的感受视野受限于卷积核，需要深层的 CNN 网络来获得更大的感受视野</li>
</ul>
<h3><span id="6-卷积池化的意义">6. 卷积，池化的意义</span></h3><ul>
<li>卷积和池化可能导致<strong>欠拟合</strong><ul>
<li>如果一项任务涉及到要<strong>对输入中相隔较远的信息进行合并</strong>时，那么卷积可能就不正确了。</li>
<li>如果一项任务依赖于保存<strong>精确的空间信息</strong>，那么在所有的特征上使用池化将会增大训练误差。</li>
</ul>
</li>
<li>当我们比较卷积模型的统计学习表现时，只能以基准中的其他卷积模型作为比较的对象</li>
</ul>
<h3><span id="7-卷积中不同零填充的影响">7. 卷积中不同零填充的影响</span></h3><p>假定 <code>m， k</code> 分别代表图像的宽度和卷积核的宽度：</p>
<ul>
<li><strong>Valid 卷积（有效卷积）</strong>：不使用零填充，卷积核只允许访问那些图像中能够<strong>完全包含整个核</strong>的位置，输出的宽度为 <code>m − k + 1</code><ul>
<li>在这种情况下，输出的所有像素都是输入中相同数量像素的函数，这使得输出像素的表示更加规范。</li>
<li>然而，输出的大小在每一层都会缩减，这限制了网络中能够包含的卷积层的层数。（一般情况下，影响不大，除非是上百层的网络）</li>
</ul>
</li>
<li><strong>Same 卷积（相同卷积）：</strong>只进行足够的零填充来<strong>保持输出和输入具有相同的大小</strong>，即输出的宽度为 <code>m</code>.<ul>
<li>在这种情况下，只要硬件支持，网络就能包含任意多的卷积层。</li>
<li>然而，输入像素中靠近边界的部分相比于中间部分对于输出像素的影响更小。这可能会导致边界像素存在一定程度的欠表示。</li>
</ul>
</li>
<li><strong>Full 卷积（全卷积）：</strong>进行足够多的零填充使得每个像素都能被访问 k 次（非全卷积只有中间的像素能被访问 k 次），最终输出图像的宽度为 <code>m + k − 1</code><ul>
<li>因为 same 卷积可能导致边界像素欠表示，从而出现了 Full 卷积；</li>
<li>但是在这种情况下，输出像素中靠近边界的部分相比于中间部分是更少像素的函数。这将导致<strong>学得的卷积核不能再所有所有位置表现一致</strong>。</li>
<li>事实上，很少使用 Full 卷积</li>
</ul>
</li>
</ul>
<p>通常<strong>零填充的最优数量</strong>处于 “有效卷积”和 “相同卷积” 之间。</p>
<h3><span id="8-1-1-卷积的作用">8. 1 * 1 卷积的作用？</span></h3><p><a href="https://zhuanlan.zhihu.com/p/40050371">https://zhuanlan.zhihu.com/p/40050371</a></p>
<ul>
<li>实现信息的跨通道交互和整合。</li>
<li>对卷积核通道数进行降维和升维，减小参数量。</li>
</ul>
<h3><span id="9-卷积核是否越大越好">9. 卷积核是否越大越好？</span></h3><p>卷积核越大，参数量越多。 前期无法使用较小卷积核是因为，前期的模型无法做的很深，这样限制了卷积核的感受视野。但其实，通过堆叠2 个 3 <em> 3 卷积核可以获得与 5 </em> 5 卷积核相同的感受视野，同时参数量特更少。 因此，大多数情况下，通过堆叠较小的卷积核比直接采用单个较大的卷积核更加有效。</p>
<p>自然语言中， TextCNN 就采用单层的卷积核，此时选择合适的，较大的卷积核相对比较重要， 而DPCNN 中，因为能够将卷积做的很深，那么就可以采用3 * 3 的卷积核来做了。</p>
<h3><span id="10-如何减少卷积层参数量">10. 如何减少卷积层参数量？</span></h3><ul>
<li>用深层小卷积代替浅层大卷积</li>
<li>使用分离卷积操作：将原本$K\times K\times C$的卷积操作分离为$K\times K\times 1$和$1\times1\times C$的两部分操作</li>
<li>添加 $1 \times 1$ 卷积</li>
<li>在卷积层前使用池化操作</li>
</ul>
<h3><span id="11-cnn-特点">11. CNN 特点</span></h3><ul>
<li><p><strong>区域不变性：</strong> filter 在每层的输入向量(图像)上滑动，检测的是局部信息，然后通过pooling取最大值或均值。pooling这步综合了局部特征，失去了每个特征的位置信息。</p>
<p>这很适合基于图像的任务，比如要判断一幅图里有没有猫这种生物，你可能不会去关心这只猫出现在图像的哪个区域。但是在NLP里，词语在句子或是段落里出现的位置，顺序，都是很重要的信息。</p>
</li>
<li><p><strong>局部组合性：</strong> CNN中，每个滤波器都把较低层的局部特征组合生成较高层的更全局化的特征。</p>
<p>这在CV里很好理解，像素组合成边缘，边缘生成形状，最后把各种形状组合起来得到复杂的物体表达。在语言里，当然也有类似的组合关系，但是远不如图像来的直接。而且在图像里，相邻像素必须是相关的，相邻的词语却未必相关。</p>
</li>
</ul>
<h3><span id="12-为何较大的batch-size-能够提高-cnn-的泛化能力">12. 为何较大的batch size 能够提高 CNN 的泛化能力？</span></h3><p>在相同迭代次数和学习率的条件下，每批次采用更多的数据将有助于模型更好的学习到正确的模式，模型输出结果也会更加稳定</p>
<h3><span id="13-same-与-valid-的区别">13. SAME 与 VALID 的区别</span></h3><ul>
<li>SAME： 宽卷积，通常采用零填充的方式对卷积核不满足整除条件的输入特征进行补全，以使卷积层的输出维度保持与输入特征维度一致。</li>
<li>VALID：窄卷积，不进行任何填充，在输入特征边缘位置若不足以进行卷积操作，则对边缘信息进行舍弃，因此在步长为1的情况下该填充方式的卷积层输出特征维度可能会略小于输入特征的维度。</li>
</ul>
<h3><span id="14-cnn-优缺点">14. CNN 优缺点</span></h3><p><strong>优点：</strong></p>
<ul>
<li>共享卷积核，优化计算量。</li>
<li>无需手动选取特征，训练好权重，即得特征。</li>
<li>深层次的网络抽取图像信息丰富，表达效果好。</li>
<li>保持了层级网络结构。</li>
<li>不同层次有不同形式与功能。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>需要调参，需要大样本量，GPU等硬件依赖。</li>
<li>物理含义不明确。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基本单元-NLP</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%20-%20MLP/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#mlp">MLP</a><ul>
<li><a href="#1-万能近似定理">1. 万能近似定理</a></li>
<li><a href="#2在深度神经网络中非线性单元放弃了训练问题的凸性其意义何在">2.在深度神经网络中，非线性单元，放弃了训练问题的凸性，其意义何在？</a></li>
<li><a href="#3-如何解决非线性问题">3. 如何解决非线性问题</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="mlp">MLP</span></h1><hr>
<p><img data-src="..\img\deep-learning.PNG" alt="deep-learning"></p>
<p><img data-src="..\img\感知机.PNG" alt="感知机"></p>
<h2><span id="1-万能近似定理">1. 万能近似定理</span></h2><p>一个前馈神经网络如果具有至少一个非线性输出层，那么只要给予网络足够数量的隐藏单元，它就可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的函数。</p>
<p><strong>万能近似定理</strong>表明一个单层的网络就足以表达任意函数，但是该层的维数可能非常大，且几乎没有泛化能力；此时，使用更深的模型能够减少所需的单元数，同时增强泛化能力（减少泛化误差）。参数数量相同的情况下，浅层网络比深层网络更容易过拟合。</p>
<h2><span id="2在深度神经网络中非线性单元放弃了训练问题的凸性其意义何在">2.在深度神经网络中，非线性单元，放弃了训练问题的凸性，其意义何在？</span></h2><p>放弃训练问题的凸性，简单来说，就是放弃寻求问题的最优解。</p>
<p><strong>非线性单元</strong>的加入，使训练问题不再是一个<strong>凸优化</strong>问题。这意味着神经网络很难得到最优解，即使一个只有两层和三个节点的简单神经网络，其训练优化问题仍然是 NP-hard 问题 (Blum &amp; Rivest, 1993).</p>
<p>但即使如此，使用神经网络也是利大于弊的：</p>
<ul>
<li>人类设计者只需要寻找正确的<strong>函数族</strong>即可，而不需要去寻找精确的函数。</li>
<li>使用简单的梯度下降优化方法就可以高效地找到足够好的局部最小值</li>
<li>增强了模型的学习/拟合能力，如原书中所说“ maxout 单元可以以任意精度近似任何凸函数”。至于放弃凸性后的优化问题可以在结合工程实践来不断改进。 “似乎传统的优化理论结果是残酷的，但我们可以通过<strong>工程方法</strong>和<strong>数学技巧</strong>来尽量规避这些问题，例如启发式方法、增加更多的机器和使用新的硬件（如GPU）。”</li>
</ul>
<h2><span id="3-如何解决非线性问题">3. 如何解决非线性问题</span></h2><ul>
<li>手动去设计一个非线性转换</li>
<li>核方法：其实内部本质也是非线性变换</li>
<li>神经网络：依据激活函数来提供非线性</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基本单元-RNN</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%20-%20RNN/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#基础相关">基础相关</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-rnn-中为何会出现梯度消失梯度爆炸问题">1. RNN 中为何会出现梯度消失，梯度爆炸问题</a></li>
<li><a href="#2-relu-能否作为rnn的激活函数">2. Relu 能否作为RNN的激活函数</a></li>
<li><a href="#3-推导-lstm">3. 推导 LSTM</a></li>
<li><a href="#4-lstm-长短记忆机制">4. LSTM 长短记忆机制</a></li>
<li><a href="#5-lstm的门机制为何选择-sigmoid-作为激活函数">5. LSTM的门机制为何选择 sigmoid 作为激活函数？</a></li>
<li><a href="#6-融合信息时为何选择-tanh">6. 融合信息时为何选择 tanh？</a></li>
<li><a href="#7-计算资源有限的情况下有没有什么优化方法">7. 计算资源有限的情况下有没有什么优化方法？</a></li>
<li><a href="#8-推导一下-gru">8. 推导一下 GRU</a></li>
<li><a href="#9-lstm-与-gru-之间的关系">9. LSTM 与 GRU 之间的关系</a></li>
<li><a href="#10-为何rnn-会有梯度消失现象推一下">10 为何RNN 会有梯度消失现象，推一下？</a></li>
<li><a href="#11-lstm-与-gru-区别">11. LSTM 与 GRU 区别</a></li>
<li><a href="#12-为何-rnn-训练时-loss-波动很大">12. 为何 RNN 训练时 loss 波动很大</a></li>
<li><a href="#13-lstm-中的激活函数选择">13. LSTM 中的激活函数选择</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="基础相关">基础相关</span></h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/44106750">RNN ： NLP中最常见的神经网络单元</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/44124492">LSTM：RNN最常用的变体</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/44163528">RNN 的梯度消失问题</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/55386469">RNN vs LSTM vs GRU — 该选哪个？</a></li>
</ul>
<h2><span id="qa">QA</span></h2><h3><span id="1-rnn-中为何会出现梯度消失梯度爆炸问题">1. RNN 中为何会出现梯度消失，梯度爆炸问题</span></h3><p><a href="https://zhuanlan.zhihu.com/p/44163528">RNN 的梯度消失问题</a></p>
<p>因此， RNN 的梯度消失，梯度爆炸问题在于： </p>
<script type="math/tex; mode=display">
\prod_{j=k+1}^t \frac{\delta S_j}{\delta S_{j-1}} = \prod_{j=k+1}^t tanh' W_s</script><h3><span id="2-relu-能否作为rnn的激活函数">2. Relu 能否作为RNN的激活函数</span></h3><p>答案是可以，但会产生一些问题：</p>
<blockquote>
<ul>
<li>换成 Relu 可能使得输出值变得特别大，从而产生溢出</li>
<li>换成Relu 也不能解决梯度消失，梯度爆炸问题，因为还有 $W_s$ 连乘的存在（如1中公式）</li>
</ul>
</blockquote>
<p>为什么 CNN 和前馈神经网络采用Relu 就能解决梯度消失，梯度爆炸问题？</p>
<blockquote>
<p>因为CNN 或 FNN 中各层的 W 并不相同， 且初始化时是独立同分布的，一定程度熵可以抵消。</p>
<p>而 RNN 中各层矩阵 $W_s$ 是一样的。</p>
</blockquote>
<h3><span id="3-推导-lstm">3. 推导 LSTM</span></h3><p>关键在于三个门， 三个状态。 其中三个门的公式基本一样</p>
<ul>
<li>遗忘门： 决定上一时刻的 $c_{t-1}$ 多少保留到当前时刻 $c_t$：</li>
</ul>
<script type="math/tex; mode=display">
f_t = \sigma{(W_f \cdot [h_{t-1},x_t] + b_f)}</script><ul>
<li><p>输入门：决定当前时刻输入 $x_t$ 有多少保存到当前时刻 $c_t$：</p>
<script type="math/tex; mode=display">
 i_t=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)</script></li>
<li><p>输出门：控制当前时刻的 $c_t$ 有多少信息作为当前时刻的 $h_t$:</p>
<script type="math/tex; mode=display">
 o_t=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)</script></li>
<li><p>当前输入的状态 $\tilde{c<em>t}$： 将上一时刻的 $h</em>{t-1}$ 与当前时刻的 $x_t$ 融合：</p>
<script type="math/tex; mode=display">
\tilde{c}_t=\tanh(W_c\cdot[h_{t-1},x_t]+b_c)</script></li>
<li><p>当前时刻的状态 $c<em>t$： 将 $x_t$ ， $\tilde{c_t}$ , $h</em>{t-1}$ 融合：</p>
<script type="math/tex; mode=display">
 c_t=f_t \circ c_{t-1}+i_t \circ \tilde{c}_t</script></li>
<li><p>当前时刻的输出 $h_t$：从 $c_t$ 中分出一部分信息：</p>
<script type="math/tex; mode=display">
h_t=o_t\circ \tanh(c_t)</script></li>
</ul>
<h3><span id="4-lstm-长短记忆机制">4. LSTM 长短记忆机制</span></h3><p>长短记忆机制主要通过 <strong>输入门</strong> 与 <strong>遗忘门</strong> 来实现：</p>
<ul>
<li>如果当前信息$x_t$不重要， 则<strong>输入门</strong>相应维度接近于 0， 当前的信息就几乎不融入进入 $\tilde{c_t}$ 。反之， 输入门相应维度接近于 1， 当前信息实现很好的融入。</li>
<li>如果之前的信息 $c_{t-1}$ 不重要，则遗忘门相应维度接近于 0， 过去的信息就几乎不融入进  $c_t$。 反之，亦然。</li>
</ul>
<h3><span id="5-lstm的门机制为何选择-sigmoid-作为激活函数">5. LSTM的门机制为何选择 sigmoid 作为激活函数？</span></h3><p>值得一提的是， 目前几乎所有主流的门控机制中，门控单元的选择均使用 sigmoid 。</p>
<ul>
<li>sigmoid 的饱和性： 十分符合 门控 的效果</li>
<li>值域在 (0,1)， 当输入较大或较小时，输出会接近1 或 0， 从而保证门的开或关。</li>
</ul>
<h3><span id="6-融合信息时为何选择-tanh">6.  融合信息时为何选择 tanh？</span></h3><ul>
<li><p>值域为 (-1, 1)， 这样会带来两个好处：</p>
<blockquote>
<ul>
<li>与大多数情景下特征分布以 0 为中心相吻合。（激活函数一章中有提到这点特性的重要性）</li>
<li>可以避免前向传播时的数值溢出问题(主要是上溢)</li>
</ul>
</blockquote>
</li>
<li><p>tanh 在 0 附近有较大的梯度，模型收敛更快</p>
</li>
</ul>
<h3><span id="7-计算资源有限的情况下有没有什么优化方法">7. 计算资源有限的情况下有没有什么优化方法？</span></h3><ul>
<li>采用 Hard gate</li>
<li>采用 GRU</li>
</ul>
<h3><span id="8-推导一下-gru">8. 推导一下 GRU</span></h3><p>两个门，两个状态</p>
<ul>
<li><p>更新门：控制前一时刻状态信息与当前输入融合</p>
<script type="math/tex; mode=display">
z_t = \sigma (W_z x_t + U_z h_{t-1})</script></li>
<li><p>重置门：控制前一时刻状态信息</p>
<script type="math/tex; mode=display">
r_t = \sigma(W_r x_t + U_r h_{t-1})</script></li>
<li><p>当前输入的信息融入 $h_t’$： </p>
<script type="math/tex; mode=display">
h_t' = tanh(Wx_t + r_t \odot Uh_{t-1}) \\</script></li>
<li><p>当前时刻的状态：</p>
<script type="math/tex; mode=display">
h_t = z_t \odot h_{t-1} + (1-z_t) \odot h_{t-1}'</script></li>
</ul>
<h3><span id="9-lstm-与-gru-之间的关系">9. LSTM 与 GRU 之间的关系</span></h3><ul>
<li>GRU 认为<strong>遗忘门</strong>与<strong>输入门</strong>功能有一定的的重合，认为之前的信息 与 当前的输入信息是此消彼长的关系，因此将二者合并成一个门： 更新门。</li>
<li>合并了记忆状态 c 与隐藏状态 h</li>
<li>采用<strong>重置门</strong>代替了<strong>输出门</strong></li>
</ul>
<h3><span id="10-为何rnn-会有梯度消失现象推一下">10 为何RNN 会有梯度消失现象，推一下？</span></h3><p><a href="https://zhuanlan.zhihu.com/p/44163528">RNN 的梯度消失问题</a></p>
<h3><span id="11-lstm-与-gru-区别">11. LSTM 与 GRU 区别</span></h3><ul>
<li>LSTM 中的单元状态 c 与 GRU 中的 h 类似，但 GRU 去掉了 h 这个状态，即最后的输出不再进行调节，那么也就不需要输出门了</li>
<li>在产生新的全局状态时， LSTM 采用 输入门+遗忘门 的方式， 而 GRU 只采用更新门来控制</li>
<li>更新门起到了遗忘门的作用， 重置门起到了输入门的作用。</li>
</ul>
<h3><span id="12-为何-rnn-训练时-loss-波动很大">12. 为何 RNN 训练时 loss 波动很大</span></h3><p>由于RNN特有的memory会影响后期其他的RNN的特点，梯度时大时小，learning rate没法个性化的调整，导致RNN在train的过程中，Loss会震荡起伏。</p>
<p>为了解决RNN的这个问题，在训练的时候，可以设置临界值，当梯度大于某个临界值，直接截断，用这个临界值作为梯度的大小，防止大幅震荡。</p>
<h3><span id="13-lstm-中的激活函数选择">13. LSTM 中的激活函数选择</span></h3><p>LSTM， 门的激活函数选择 Sigmoid， 而在生成 c 时采用 tanh。</p>
<ul>
<li>Sigmoid函数的输出在0～1之间，符合门控的物理定义。且当输入较大或较小时，其输出会非常接近1或0，从而保证该门开或关。</li>
<li>在生成候选记忆时，使用Tanh函数，是因为其输出在−1～1之间，这与大多数场景下特征分布是0中心的吻合。此外，Tanh函数在输入为0附近相比Sigmoid函数有更大的梯度，通常使模型收敛更快。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-AUC计算</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20AUC%20%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="基础理论-auc-计算">基础理论 - AUC 计算</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-SoftMax</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20Softmax/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#基础理论-softmax">基础理论 - Softmax</a><ul>
<li><a href="#1-softmax-定义">1. Softmax 定义</a></li>
<li><a href="#2-softmax-损失">2. Softmax 损失</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-为何一般选择-softmax-为多分类的输出层">1. 为何一般选择 softmax 为多分类的输出层</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="基础理论-softmax">基础理论 - Softmax</span></h1><hr>
<p><a href="https://zhuanlan.zhihu.com/p/79585726">https://zhuanlan.zhihu.com/p/79585726</a></p>
<h2><span id="1-softmax-定义">1. Softmax 定义</span></h2><script type="math/tex; mode=display">
P(i) = \frac{e^{a_i}}{\sum_{k=1}^T e^{a_k}} \in [0,1]</script><h2><span id="2-softmax-损失">2. Softmax 损失</span></h2><script type="math/tex; mode=display">
L = - \sum_{j=1}^T y_j \, log \, s_j  \\</script><hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-为何一般选择-softmax-为多分类的输出层">1. 为何一般选择 softmax 为多分类的输出层</span></h3><p>虽然能够将输出范围概率限制在 [0,1]之间的方法有很多，但 Softmax 的好处在于， 它使得输出两极化：正样本的结果趋近于 1， 负样本的结果趋近于 0。 可以说， Softmax 是 logistic 的一种泛化。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-偏差 VS 方差、欠拟合 VS 过拟合</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E5%81%8F%E5%B7%AE%20vs%20%E6%96%B9%E5%B7%AE%EF%BC%8C%E6%AC%A0%E6%8B%9F%E5%90%88%20vs%20%E8%BF%87%E6%8B%9F%E5%90%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#定义">定义</a></li>
<li><a href="#理解概念">理解概念</a></li>
<li><a href="#四种情况">四种情况</a></li>
<li><a href="#偏差与欠拟合方差与过拟合">偏差与欠拟合，方差与过拟合</a></li>
<li><a href="#如何降低偏差欠拟合">如何降低偏差（欠拟合）</a></li>
<li><a href="#如何降低方差过拟合">如何降低方差（过拟合）</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p>参考： <a href="https://zhuanlan.zhihu.com/p/48257326">偏差与方差， 欠拟合与过拟合</a></p>
<h2><span id="定义">定义</span></h2><ul>
<li><p>记在<strong>训练集 D</strong> 上学得的模型为</p>
<script type="math/tex; mode=display">
f(x;D)</script></li>
</ul>
<p>  模型的<strong>期望预测</strong>为</p>
<script type="math/tex; mode=display">
  \hat{f}(x) = E_D [f(x;D)]</script><ul>
<li><p><strong>偏差</strong>（Bias）</p>
<script type="math/tex; mode=display">
bias^2(x) = (\hat{f}(x) - y)^2</script><blockquote>
<p><strong>偏差</strong>度量了学习算法的<strong>期望预测</strong>与<strong>真实结果</strong>的偏离程度，即刻画了学习算法本身的拟合能力；</p>
</blockquote>
</li>
<li><p><strong>方差</strong>（Variance）</p>
<script type="math/tex; mode=display">
var(x) = E_D[(f(x;D) - \hat{f}(x))^2]</script></li>
</ul>
<blockquote>
<p><strong>方差</strong>度量了同样大小的<strong>训练集的变动</strong>所导致的学习性能的变化，即刻画了<strong>数据扰动所造成的影响（模型的稳定性</strong>）；</p>
</blockquote>
<script type="math/tex; mode=display">
  \varepsilon^2 = E_D[(y_D-y)^2]</script><ul>
<li><p><strong>噪声</strong>则表达了<strong>在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</strong></p>
</li>
<li><p>“<strong>偏差-方差分解</strong>”表明模型的泛化能力是由算法的能力、数据的充分性、任务本身的难度共同决定的。</p>
</li>
</ul>
<h2><span id="理解概念">理解概念</span></h2><ul>
<li>偏差： 表示模型在训练集上的表现，与<strong>训练误差</strong>成线性关系， 用于描述模型的拟合能力</li>
<li>方差： 表示模型在（开发集或测试集）与<strong>测试误差-训练误差</strong>成线性关系，用于描述模型的泛化能力。</li>
</ul>
<h2><span id="四种情况">四种情况</span></h2><ol>
<li>偏差很低，方差很高： 意味着训练误差很低，测试误差很高，此时发生了过拟合现象。</li>
<li>偏差很高，方差很低： 意味着训练误差，测试误差都很高，此时发生了欠拟合现在。</li>
<li>偏差，方差都很高： 意味着此时同时发生了欠拟合和过拟合现象。</li>
<li>偏差很低，方差很低： 意味着训练误差很低，测试误差也很低，表示我们的模型训练的结果很好。</li>
</ol>
<h2><span id="偏差与欠拟合方差与过拟合">偏差与欠拟合，方差与过拟合</span></h2><ul>
<li>偏差通常是由于我们定义的模型不合适或模型复杂度不够，所造成的现象为欠拟合。</li>
<li>方差主要是由于模型复杂度过高造成的， 所造成的现象是过拟合。</li>
</ul>
<h2><span id="如何降低偏差欠拟合">如何降低偏差（欠拟合）</span></h2><ol>
<li><p>加大模型规模（更换其余机器学习算法，神经网络可以增加每层神经元/神经网络层数）：</p>
<blockquote>
<p>偏差很高很有可能是因为模型的拟合能力差，对于传统机器学习算法，各个方法的拟合能力不同，选择一个拟合能力更好的算法往往能够得出很好的结果。 对于神经网络（拟合能力最强）而言，通过增加网络层数或增加每层单元数就能够很好的提高模型的拟合能力[3][4][5]。</p>
</blockquote>
</li>
<li><p>根据误差分析结果来修改特征： </p>
<blockquote>
<p>我们需要将错误样本分类，判断可能是由于什么原因导致样本失败，在针对分析结果，增加或减少一些特征。</p>
</blockquote>
</li>
<li><p>减少或去除正则化： 这可以避免偏差，但会增大方差。</p>
</li>
<li><p>修改模型结构，以适应你的问题：对于不同的问题，不同的模型结构会产生更好的结果，比如在CV中常用CNN，而在NLP领域常用LSTM。</p>
</li>
</ol>
<h2><span id="如何降低方差过拟合">如何降低方差（过拟合）</span></h2><ol>
<li><p>重新分析，清洗数据。 </p>
<blockquote>
<p>有时候，造成方差很大的原因往往是由于数据不良造成的，对于深度学习来说，有一个大规模，高质量的数据集是极为重要的。</p>
</blockquote>
</li>
<li><p>添加更多的训练数据。</p>
<blockquote>
<p>增大训练数据能够往往能够提高模型的泛化能力。可以采用数据增强技术。</p>
</blockquote>
</li>
<li><p>加入正则化。</p>
</li>
<li><p>加入提前终止。</p>
<blockquote>
<p>意思就是在训练误差变化很慢甚至不变的时候可以停止训练，这项技术可以降低方差，但有可能增大了偏差。 提前终止有助于我们能够在到达最佳拟合附近，避免进入过拟合状态。</p>
</blockquote>
</li>
<li><p>通过特征选择减少输入特征的数量和种类。 </p>
<blockquote>
<p>显著减少特征数量能够提高模型的泛化能力，但模型的拟合能力会降低，这意味着，该技术可以减小方差，但可能会增大偏差。 不过在深度学习中，我们往往直接将所有特征放入神经网络中，交给算法来选择取舍。</p>
</blockquote>
</li>
<li><p>减少模型规模，降低模型复杂度（每层神经元个数/神经网络层数）： <strong>谨慎使用。</strong> </p>
<blockquote>
<p>一般情况下，对于复杂问题如CV或NLP等问题不会降低模型复杂度，而对于简单问题，采用简单模型往往训练速度更快，效果很好。</p>
</blockquote>
</li>
<li><p>根据误差分析结果修改输入特征。</p>
</li>
<li><p>修改模型架构，使之更适合你的问题。 一般可以选择简单模型的情况下，不选择复杂模型。</p>
</li>
<li><p>集成学习。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-分类问题评估指标</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#几个定义混淆矩阵">几个定义：混淆矩阵</a></li>
<li><a href="#几个常规的指标">几个常规的指标</a></li>
<li><a href="#f1-score">F1-Score</a></li>
<li><a href="#mcc-马修斯相关系数">MCC ： 马修斯相关系数</a></li>
<li><a href="#roc-曲线">ROC 曲线</a></li>
<li><a href="#aucarea-under-curve">AUC：Area under Curve</a></li>
<li><a href="#p-r-曲线">P-R 曲线</a></li>
<li><a href="#最后">最后</a></li>
<li><a href="#reference">Reference</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-训练集中类别不平衡哪个参数最不准确">1. 训练集中类别不平衡，哪个参数最不准确？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="几个定义混淆矩阵">几个定义：混淆矩阵</span></h2><ul>
<li>TP： True Positives， 表示<strong>实际为正例</strong>且被分类器<strong>判定为正例</strong>的样本数</li>
<li>FP： False Positives， 表示<strong>实际为负例</strong>且被分类器<strong>判定为正例</strong>的样本数</li>
<li>FN： False Negatives， 表示<strong>实际为正例</strong>但被分类器<strong>判定为负例</strong>的样本数</li>
<li>TN： True Negatives， 表示<strong>实际为负例</strong>且被分类器<strong>判定为负例</strong>的样本数</li>
</ul>
<p><strong>一个小技巧， 第一个字母表示划分正确与否， T 表示判定正确（判定正确）， F表示判定错误(False)； 第二个字母表示分类器判定结果， P表示判定为正例， N表示判定为负例。</strong></p>
<h2><span id="几个常规的指标">几个常规的指标</span></h2><p><strong>Accuracy：</strong></p>
<script type="math/tex; mode=display">
accuracy  = \frac{TP + TN}{TP + FP + FN + TN}= \frac{正确预测的样本数}{所有的样本数} \\</script><p>Accuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy  并不能很好的反映模型的整体情况。</p>
<p><strong>Precision：</strong></p>
<script type="math/tex; mode=display">
Precision = \frac{TP}{TP + FP} \\
Precision = \frac{\sum_{l=1}^{L}TP_l}{\sum_{l=1}^LTP_l + FP_l} = \frac{\text{label 预测为 l 且预测正确的样本个数}}{\text{label 预测为 l 样本个数}} \\</script><p><strong>Recall：</strong></p>
<script type="math/tex; mode=display">
Recall =  \frac{TP}{TP + FN} \\
Recall = \frac{\sum_{l=1}^L TP_l}{ \sum_{l=1}^LTP_l + FN_l} = \frac{\text{label 预测为 l 且预测正确的样本个数}}{\text{真实样本中所有 label 为 l 的样本个数}}</script><p><strong>Precision 与 Recall 的权衡</strong></p>
<p>精确率高，意味着分类器要尽量在 <strong>“更有把握”</strong> 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。</p>
<p>召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强。</p>
<p>从上面的分析可以看出，精确率与召回率是此消彼长的关系， 如果分类器只把可能性大的样本预测为正样本，那么会漏掉很多可能性相对不大但依旧满足的正样本，从而导致召回率降低。</p>
<h2><span id="f1-score">F1-Score</span></h2><p>F1-Score 能够很好的评估模型，其主要用于二分类问题， 计算如下：</p>
<script type="math/tex; mode=display">
\text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}</script><p>而 更一般的有 $F_{\beta}$  ：</p>
<script type="math/tex; mode=display">
F_{\beta} = \frac{(1 + \beta^2) \cdot \text{Precision} \cdot \text{Recall}}{ \beta^2 \times \text{Precision} + \text{Recall}}</script><p>其实， $\beta$ 本质上是Recall， Precision 权重比， 当 $\beta=2$ 时， $F<em>2$ 表明 Recall 的权重要比Precision高，其影响更大， ； 当 $\beta=0.5$ 时， $F</em>{0.5}$ 表明 Recall 的权重要比Precision低， 对应的影响更小； </p>
<p>前面提到 F1 针对的是二分类，而更一般的是，对于多分类问题来说， F1 的计算有多种方式，可以参见 Scikit-Learn 中的评价指标，我们来分别介绍一下。</p>
<p>对于一个多分类问题，假设，对于分类 $i$ 而言有：$TP_i, FP_i, TN_i, FN_i$， 那么各种 F1 的值计算如下。 </p>
<p><strong>Macro F1</strong>： 宏平均</p>
<p>Macro 算法在计算 Precision 与 Recall 时是先分别计算每个类别的Precision 与 Recall， 然后再进行平均。</p>
<script type="math/tex; mode=display">
\text{Precision}_i = \frac{TP_i}{TP_i + FP_i}</script><script type="math/tex; mode=display">
\text{Precision}_{macro} = \frac{\sum_{i=1}^L \text{Precision}_i}{|L|}</script><script type="math/tex; mode=display">
\text{Recall}_i = \frac{TP_i}{TP_i + FN_i} \\
\text{Recall}_{macro} = \frac{\sum_{i=1}^L \text{Recall}_i}{|L|}</script><p>那么我们就得到最终的 Macro F1 的计算为：</p>
<script type="math/tex; mode=display">
\text{Macro F1} = \frac{2 \cdot \text{Precision}_{macro} \cdot \text{Recall}_{macro}}{\text{Precision}_{macro} + \text{Recall}_{macro}}</script><p>我们看到， Macro F1 本质上是所有类别的统计指标的算术平均值来求得的，这样单纯的平均忽略了样本之间分布可能存在极大不平衡的情况</p>
<p><strong>Micro F1</strong> ：微平均</p>
<p>Micro 算法在计算 Precision 与 Recall 时会将所有类直接放到一起来计算。</p>
<script type="math/tex; mode=display">
\text{Precision}_{micro} = \frac{\sum_{i=1}^L TP}{\sum_{i=1}^L TP + \sum_{i=1}^L FP}</script><script type="math/tex; mode=display">
\text{Recall}_{micro} = \frac{\sum_{i=1}^L TP}{\sum_{i=1}^L TP + \sum_{i=1}^L FN}</script><script type="math/tex; mode=display">
\text{Micro F1} = \frac{2 \cdot \text{Precision}_{micro} \cdot \text{Recall}_{micro}}{\text{Precision}_{micro} + \text{Recall}_{micro}}</script><p><strong>Macro vs Micro</strong> [1]</p>
<p>Macro 相对 Micro 而言，小类别起到的作用更大，举个例子而言，对于一个四分类问题有：</p>
<ul>
<li>class A： 1 TP， 1 FP</li>
<li>class B： 10 TP ， 90 FP</li>
<li>class C： 1 TP， 1 FP</li>
<li>class D： 1 TP， 1 FP</li>
</ul>
<p>那么对于 Precision 的计算有： </p>
<script type="math/tex; mode=display">
P_A = P_C = P_D = 0.5, P_B = 0.1 \\
P_{macro} = \frac{0.5 + 0.1 + 0.5 + 0.5}{4} = 0.4 \\
P_{micro} = \frac{1 + 10 + 1 + 1}{2 + 100 + 2 + 2} = 0.123</script><p>我们看到，对于 Macro 来说， 小类别相当程度上拉高了 Precision 的值，而实际上， 并没有那么多样本被正确分类，考虑到实际的环境中，真实样本分布和训练样本分布相同的情况下，这种指标明显是有问题的， 小类别起到的作用太大，以至于大样本的分类情况不佳。 而对于 Micro 来说，其考虑到了这种样本不均衡的问题， 因此在这种情况下相对较佳。</p>
<p>总的来说， 如果你的类别比较均衡，则随便； 如果你认为大样本的类别应该占据更重要的位置， 使用Micro； 如果你认为小样本也应该占据重要的位置，则使用 Macro； 如果 Micro &lt;&lt; Macro ， 则意味着在大样本类别中出现了严重的分类错误； 如果 Macro &lt;&lt; Micro ， 则意味着小样本类别中出现了严重的分类错误。</p>
<p>为了解决 Macro 无法衡量样本均衡问题，一个很好的方法是求加权的 Macro， 因此 Weighed F1 出现了。</p>
<p><strong>Weight F1</strong></p>
<p>Weighted 算法算术 Macro 算法的改良版，是为了解决Macro中没有考虑样本不均衡的原因， 在计算 Precision与Recall 时候，各个类别的 Precision 与 Recall要乘以该类在总样本中的占比来求和：</p>
<script type="math/tex; mode=display">
\text{Precision}_i = \frac{TP_i}{TP_i + FP_i}</script><script type="math/tex; mode=display">
\text{Precision}_{macro} = \frac{\sum_{i=1}^L \text{Precision}_i \times w_i}{|L|}</script><script type="math/tex; mode=display">
\text{Recall}_i = \frac{TP_i}{TP_i + FN_i} \\
\text{Recall}_{macro} = \frac{\sum_{i=1}^L \text{Recall}_i \times w_i}{|L|}</script><p>那么我们就得到最终的 Macro F1 的计算为：</p>
<script type="math/tex; mode=display">
\text{Macro weighted F1} = \frac{2 \cdot \text{Precision}_{macro} \cdot \text{Recall}_{macro}}{\text{Precision}_{macro} + \text{Recall}_{macro}}</script><h2><span id="mcc-马修斯相关系数">MCC ： 马修斯相关系数</span></h2><p>MCC 主要用于衡量二分类问题，其综合考虑了 TP TN, FP , FN， 是一个比较均衡的指标， 对于样本不均衡情况下也可以使用。MCC的取值范围在 <strong>[-1, 1]</strong>， 取值为1 表示预测与实际完全一致， 取值为0表示预测的结果还不如随机预测的结果， -1 表示预测结果与实际的结果完全不一致。因此我们看到， MCC 本质上描述了预测结果与实际结果之间的相关系数。</p>
<script type="math/tex; mode=display">
MCC = \frac{TP \times TN - TP \times FN}{\sqrt{(TP + FP) \times (TP + FN) \times (TN + FP) \times (TN + FN)}}</script><p>值得注意的是，对于两个分类器而言，可能其中一个分类器的 F1 值较高，而其 MCC 值较低， 这表示单一的指标是无法衡量分类器的所有优点与缺点的。</p>
<h2><span id="roc-曲线">ROC 曲线</span></h2><p>在分类任务中，测试部分通常是获得一个概率表示当前样本属于正例的概率， 我们往往会采取一个阈值，大于该阈值的为正例， 小于该阈值的为负例。 如果我们减小这个阈值， 那么会有更多的样本被识别为正类，这会提高正类的识别率，但同时会降低负类的识别率。 </p>
<p>为了形象的描述上述的这种变化， 引入ROC曲线来评价一个分类器的好坏。 ROC 曲线主要关注两个指标：</p>
<script type="math/tex; mode=display">
\text{横坐标}: FPR = \frac{FP}{FP + FN} \\
\text{纵坐标}: TPR = \frac{TP}{TP + FN}</script><p>其中， FPR 代表将负例错分为正例的概率， TPR 表示能将正例分对的概率， 如果我们增大阈值， 则 TPR 会增加，而对应的FPR也会增大， 而绘制ROC曲线能够帮助我们找到二者的均衡点，下图很清晰的描述了ROC 曲线关系：</p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g40frg58cjj30jg08kgns.jpg" alt></p>
<p>在 ROC 曲线中， 有：</p>
<ul>
<li>FPR = 0, TPR = 0： 表示将每一个实例都预测为负类</li>
<li>FPR = 1, TPR = 1：表示将每一个实例都预测为正例</li>
<li>FPR = 0, TPR = 1：为最优分类点</li>
<li>分类器对应的ROC曲线应该尽可能靠近坐标轴的左上角， 而对角线的位置意味着分类器的效果和随机猜测一样的差。</li>
</ul>
<p><strong>ROC曲线在测试集中的样本分布发生变化的时候能够保持不变。</strong>但遗憾的是，很多时候， ROC 曲线并不能清晰的说明哪个分类器的效果更好， 而 AUC 恰恰能够对分类器做出直观的评价。</p>
<h2><span id="aucarea-under-curve">AUC：Area under Curve</span></h2><p>AUC 为ROC 曲线下的面积， 这个面积的数值介于0到1之间， 能够直观的评价出分类器的好坏， AUC的值越大， 分类器效果越好。</p>
<ul>
<li>AUC = 1： 完美分类器， 采用该模型，不管设定什么阈值都能得出完美预测（绝大多数时候不存在）</li>
<li>0.5 &lt; AUC &lt; 1： 优于随机猜测，分类器好好设定阈值的话，有预测价值</li>
<li>AUC = 0.5： 跟随机猜测一样，模型没有预测价值</li>
<li>AUC &lt; 0.5 ：比随机猜测还差，但是如果反着预测，就优于随机猜测。</li>
</ul>
<p><strong>值得一提的是，两个模型的AUC 相等并不代表模型的效果相同， 比如这样：</strong></p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g40goqhuzvj308808d747.jpg" alt></p>
<p><strong>实际场景中， AUC 的确是非常常用的一种指标。</strong></p>
<p><strong>需要注意的是， 在多分类场景下的 ROC 曲线以及 AUC 值， 此时 ROC 曲线应该有多个， 而AUC 的计算如下：</strong></p>
<script type="math/tex; mode=display">
AUC = \frac{2}{|C|(|C|-1)} \sum_{i=1}^{|C|} AUC_i, \quad C \, 表示类别数量</script><h2><span id="p-r-曲线">P-R 曲线</span></h2><p>P-R 曲线其横坐标为 Recall， 纵坐标为 Precision， 其能帮助我们很好的做出权衡</p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g40gyog0e8j30av09rgn9.jpg" alt></p>
<p>在上图中，我们发现， A 完全包住了C， 着意味着A 的Precision 与 Recall 都高于C， A优于C。 而对比 A,B， 二者存在交叉的情况，此时采用曲线下面积大小衡量性能，面积越大，性能越好，此处的A优于B。</p>
<h2><span id="最后">最后</span></h2><p>对于最终分类指标的选择， 在不同数据集，不同场景，不同时间下都会有不同的选择，但往往最好选出一个指标来做优化，对于二分类问题，我目前用 AUC 比较多一些， 多分类我还是看 F1 值。</p>
<h2><span id="reference">Reference</span></h2><p>[1] <a href="https://stats.stackexchange.com/questions/156923/should-i-make-decisions-based-on-micro-averaged-or-macro-averaged-evaluation-mea">Should I make decisions based on micro-averaged or macro-averaged evaluation measures?</a></p>
<p>[2] <a href="https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin">Micro Average vs Macro average Performance in a Multiclass classification setting</a>&gt;</p>
<p>[3 <a href="http://dingby.site/2018/03/07/机器学习性能评估指标/">机器学习性能评估指标</a></p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-训练集中类别不平衡哪个参数最不准确">1. 训练集中类别不平衡，哪个参数最不准确？</span></h3><p>Accuracy</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-指数甲醛平均</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#原理">原理</a></li>
<li><a href="#偏差修正">偏差修正</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="原理">原理</span></h2><p><strong>指数加权平均本质上是一种近似求取平均值的方法。</strong></p>
<script type="math/tex; mode=display">
V_t = \beta V_{t-1} + (1-\beta)\theta_t</script><p>我们也以吴恩达课上的例子举例， 假设</p>
<ul>
<li>$V_t$  表示从第0天到第 $t$ 天的平均温度值。</li>
<li>$\theta_t$ 表示第 t 点的温度值。</li>
</ul>
<p>我们具体展开来说， 假设时间  $t = 100$ ，加权参数 $\beta = 0.9$ ， 那么则有：</p>
<script type="math/tex; mode=display">
V_{100} = 0.9V_{99} + 0.1\theta_{100}  \\ V_{99} = 0.9V_{98} + 0.1\theta_{99}   \\ V_{98} = 0.9V_{97} + 0.1\theta_{98}</script><p>我们将上式带入化简有：</p>
<script type="math/tex; mode=display">
V_{100} = 0.1 \theta_{100} + 0.1 * 0.9  \theta_{99} + 0.1 * 0.9^2 \theta_{98} + \cdots + 0.1 * 0.9^{99}  \theta_1 + 0.1 * 0.9^{100}\theta</script><p>观察上式我们发现， 指数加权平均实质上就是<strong>以指数式加权递减的移动平均。 各数值的加权而随时间而指数式递减，越近期的数据加权越重，但较旧的数据也给予一定的加权。</strong></p>
<p>但有一点需要注意的是， 我们观察上式，在最后一项中它的系数为 $0.99^{100}$ , 这个数已经很接近于0了， 这就意味着，在 $t = 0$ 时刻对加权平均值所起到的作用微乎其微， 继而引出一个问题： <strong>我们加权平均所得到的值到底平均了多少天？</strong> </p>
<p>答案是 $\frac{1}{1-\beta}$  天。这是因为当 $\beta = 0.9$ 时， 有 $0.9^{10} = 0.3486…$ ， 当 $\beta = 0.8$  时， 有 $0.8^5  = 0.3276…$ ， 也就是说当权重下降到 $\frac{1}{3}$（或者说$\frac{1}{e}$） 以下时就被忽略不计了。</p>
<p>前面说到指数平均的本质依旧是<strong>计算平均值</strong>，那么在深度学习中为什么不使用我们常用的平均值求法，而要搞得这么复杂呢？ 答案是<strong>效率以及内存问题。</strong></p>
<p>在深度学习中，数据量经常是非常庞大的， 如果我们使用传统方法来计算平均值，无论是从内存还是从计算量上， 对计算机的压力是很大的， 而对比对数加权平均方法， 我们每次只需要保存上一时刻的值，无论是内存开销还是计算量都小的可怜。 </p>
<h2><span id="偏差修正">偏差修正</span></h2><p>当我们还有指数加权平均来计算平均值时， 一开始的指数加权平均值会很小， 不能代表平均值， 所以需要使用偏差修正：</p>
<script type="math/tex; mode=display">
V_t = \frac{V_t}{1 - \beta^t}</script><p>但是一般机器学习并不关心一开始的指数加权平均值，所以可以不用偏差修正来修正。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-数据角度看深度学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E6%95%B0%E6%8D%AE%E8%A7%92%E5%BA%A6%E7%9C%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-数据集定义">1. 数据集定义</a></li>
<li><a href="#2-数据集划分">2. 数据集划分</a><ul>
<li><a href="#划分原则">划分原则</a></li>
<li><a href="#划分建议">划分建议</a></li>
<li><a href="#数据时分布">数据时分布</a></li>
</ul>
</li>
<li><a href="#3-数据不匹配问题">3. 数据不匹配问题</a><ul>
<li><a href="#1-如何定位数据不匹配">1 如何定位数据不匹配?</a></li>
<li><a href="#2-举例常见几个数据不匹配的场景">2 举例常见几个数据不匹配的场景?</a></li>
<li><a href="#3-如何解决数据不匹配问题">3 如何解决数据不匹配问题?</a></li>
<li><a href="#4-如何提高深度学习系统的性能">4 如何提高深度学习系统的性能</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-数据为何要-shuffle">1. 数据为何要 shuffle ？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-数据集定义">1. 数据集定义</span></h2><ul>
<li><strong>训练集：</strong> 训练集用来训练你的模型，来确定模型的参数而非超参数，这些参数往往称为学习参数， 如权重参数W， 偏置参数b。</li>
<li><strong>验证集：</strong>交叉验证集用于验证模型的performance，从而对模型进行超参数调整以及确定最终模型，这些超参数包括：学习率，网络结构等 。有时也称为交叉验证集。</li>
<li><strong>测试集：</strong>测试集用于对算法进行评估，不会改变学习算法和参数。</li>
</ul>
<h2><span id="2-数据集划分">2. 数据集划分</span></h2><h3><span id="划分原则">划分原则</span></h3><ul>
<li>验证集的规模应该尽可能大，至少能够区分出你所尝试的不同算法之间的性能差异。一般来说，验证集的规模应该在 1000 - 10000 之间。</li>
<li>测试集的规模应该大到使你能够对模型的性能进行一个高度可信的评估即可。当数据规模一般时(100-10000)时，采用数据的10%-30%来作为测试集；在数据规模很大时(10w级别)，采用1%作为1%甚至更小。总的来说，只要能够很好的评估模型性能即可。</li>
<li>验证集与测试集的规模并不是越大越好，但如果数据丰富，可以适当选择较大的验证集与测试集。</li>
</ul>
<h3><span id="划分建议">划分建议</span></h3><ul>
<li>在样本量有限的情况下，有时候会把验证集和测试集合并。实际中，若划分为三类，那么训练集：验证集：测试集=6:2:2；若是两类，则训练集：验证集=7:3。</li>
<li>在海量样本的情况下，这种情况在目前深度学习中会比较常见。此时由于数据量巨大，我们不需要将过多的数据用于验证和测试集。例如拥有1百万样本时，我们按训练集：验证集：测试集=98:1:1的比例划分，1%的验证和1%的测试集都已经拥有了1万个样本，这已足够验证模型性能了。</li>
</ul>
<h3><span id="数据时分布">数据时分布</span></h3><ul>
<li><p>训练集的分布不需要与实际数据分布一致，而应该更多的考虑如何均衡样本分布。</p>
</li>
<li><p>验证集与测试集应该服从同一分布，且该分布能够很好的反应实际数据的分布。二者分布相同有助于定位问题：</p>
<ul>
<li><p>如果模型在验证集上表现良好，却在测试集上表现不佳，那么问题可以定位为：算法在验证集上过拟合了</p>
</li>
<li><p>如果二者分布不同时，发生此情况，问题就有很多了如：</p>
<blockquote>
<ul>
<li>算法在验证集上过拟合了。</li>
<li>测试集比验证集更难进行预测，尽管算法做得足够好了，却很难有进一步的提升空间。</li>
<li>测试集不一定更难预测，但它与开发集性质并不相同（分布不同）。</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>训练集分布于验证集，测试集分布没必要一致。训练集更多的考虑模型的performance，而测试集与验证集是与真实数据相关的，更多考虑的是泛化能力。</p>
</li>
</ul>
<h2><span id="3-数据不匹配问题">3. 数据不匹配问题</span></h2><h3><span id="1-如何定位数据不匹配">1 如何定位数据不匹配?</span></h3><p>​    数据不匹配问题是个不容易定位和解决的问题。这个问题出现总会和模型过拟合表现很相似,即在训练集上能体现非常不错的性能,但在测试集上表现总是差强人意但区别在于如果遇到是数据不匹配的问题,通常在用一批和训<br>练集有看相同或者相似分布的数据上仍然能取得不错的结果。但很多时候,当测试集上结果表现很差时,很多初学<br>者可能会直接将问题定位在模型过拟合上,最后对模型尝试各种方法后,性能却始终不能得到有效提升。当遇到这<br>种情况时,建议先定位出是否存在数据不匹配的问题。最简单的验证方式就是可以从训练集中挑选出一部分数据作<br>为验证集,重新划分后训练和验证模型表现。</p>
<h3><span id="2-举例常见几个数据不匹配的场景">2 举例常见几个数据不匹配的场景?</span></h3><p>​    例如设计款识别物体的app时,实际场景的图片均来自于手机拍摄,而训练集确是来自于网上各类抓取下来的图<br>片。例如在图像去噪、去模糊、去雾、超分辨率等图像处理场景时,由于大量数据的难以获取,因此都会采用人为<br>假设合成的图像进行训练,这时候应用到实际场景中也容易出现不匹配的问题</p>
<h3><span id="3-如何解决数据不匹配问题">3 如何解决数据不匹配问题?</span></h3><p>数据不匹配是个很难有固定方法来解决的问题。这里提供几条供参考的途径：<br>​    1、收集更多符合实际场最需要的数据。这似乎是最简单但也最难方式<br>​    2、对结果做错误分析。找出数据集中出错的数据和正确数据之间的特点和区别,这对你无论是进行后续模型的分析或者是数据的处理提供非常有效的思路。注意,这里的数据集包括训练集和测试集<br>​    3、数据集增强。数据集增强并不意味看数据集越大越好,其目的是丰富数据的分布以适应更多的变化当遇到数<br>据不匹配时,对数据处理般可以有两种方式。其一,合成或处理更多接近需要的数据特点。其二,对所有数据包<br>括实际场景数据都进行处理,将所有数据都统一到另一个分布上,统一出一种新的特点。</p>
<h3><span id="4-如何提高深度学习系统的性能">4 如何提高深度学习系统的性能</span></h3><p>当我们要试图提高深度学习系统的性能时，目前我们大致可以从三方面考虑：</p>
<p>​    1、提高模型的结构，比如增加神经网络的层数，或者将简单的神经元单位换成复杂的 LSTM 神经元，比如在自然语言处理领域内，利用 LSTM 模型挖掘语法分析的优势。</p>
<p>​    2、改进模型的初始化方式，保证早期梯度具有某些有益的性质，或者具备大量的稀疏性，或者利用线性代数原理的优势。  </p>
<p>​    3、选择更强大的学习算法，比如对度梯度更新的方式，也可以是采用除以先前梯度 L2 范数来更新所有参数，甚至还可以选用计算代价较大的二阶算法。</p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-数据为何要-shuffle">1. 数据为何要 shuffle ？</span></h3><p>shuffle 的意思是洗牌或弄乱，即打乱数据集中样本的排列顺序。这样带来一个直接的好处就是样本的分布变得均匀了。</p>
<p>在优化中有一个原则是：网络从意料之外的样本中学习最快，所以说，如果为了加速学习，我们要求每次喂入的数据和前一份数据相关性较低。</p>
<p>总的来说，shuffle的意义在于加速模型学习。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-梯度消失、梯度爆炸</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%EF%BC%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-梯度消失梯度爆炸产生原因">1. 梯度消失，梯度爆炸产生原因</a></li>
<li><a href="#2-解决方案">2. 解决方案</a><ul>
<li><a href="#1-采用-relu-系激活函数">1. 采用 Relu 系激活函数</a></li>
<li><a href="#2-合适的权重初始化">2. 合适的权重初始化</a></li>
<li><a href="#3-残差结构">3. 残差结构</a></li>
<li><a href="#4-batch-normalization-layer-normalization">4. Batch Normalization， Layer Normalization</a></li>
<li><a href="#5-lstm">5. LSTM</a></li>
<li><a href="#6-梯度裁剪-梯度爆炸">6. 梯度裁剪 - 梯度爆炸</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-梯度消失梯度爆炸产生原因">1. 梯度消失，梯度爆炸产生原因</span></h2><p>请看我的这篇文章： <a href="https://zhuanlan.zhihu.com/p/44163528">RNN 的梯度消失问题</a>， 讲的已经很清楚了。</p>
<p>总的来说，梯度消失，梯度爆炸问题本质上是由于随着深度的加深，受到权重信息，激活函数的影响，连乘机制所引发的一系列问题。</p>
<h2><span id="2-解决方案">2. 解决方案</span></h2><p>解决梯度消失，梯度爆炸问题，最终的目的是解决如何在深层网络上的优化问题，当然深层网络所带来的问题远不止梯度消失，爆炸问题。</p>
<h3><span id="1-采用-relu-系激活函数">1. 采用 Relu 系激活函数</span></h3><p>参考：<a href="./激活函数">激活函数</a></p>
<h3><span id="2-合适的权重初始化">2. 合适的权重初始化</span></h3><p>参考：<a href="./权重初始化方案">权重初始化</a></p>
<h3><span id="3-残差结构">3.  残差结构</span></h3><p>残差的方式，能使得深层的网络梯度通过跳级连接路径直接返回到浅层部分，使得网络无论多深都能将梯度进行有效的回传。</p>
<h3><span id="4-batch-normalization-layer-normalization">4. Batch Normalization， Layer Normalization</span></h3><p>参考：<a href="./Normalization">Normalization</a></p>
<h3><span id="5-lstm">5. LSTM</span></h3><p>参考：<a href="https://zhuanlan.zhihu.com/p/44163528">RNN 的梯度消失问题</a>， 讲的很清楚了。</p>
<h3><span id="6-梯度裁剪-梯度爆炸">6. 梯度裁剪 - 梯度爆炸</span></h3><p>如果梯度超过某个阈值，就对其进行限制。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-目标函数、损失函数、代价函数</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%8C%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-经验风险与结构风险">1. 经验风险与结构风险</a></li>
<li><a href="#2-损失函数代价函数目标函数">2. 损失函数，代价函数，目标函数</a></li>
<li><a href="#3-常用的损失函数">3. 常用的损失函数</a><ul>
<li><a href="#1-0-1-损失函数">1 . 0-1 损失函数</a></li>
<li><a href="#2-绝对值损失函数">2. <strong>绝对值损失函数</strong></a></li>
<li><a href="#3-平方损失函数">3. <strong>平方损失函数</strong></a></li>
<li><a href="#4-对数损失函数">4. <strong>对数损失函数</strong></a></li>
<li><a href="#5-指数损失函数">5. <strong>指数损失函数</strong></a></li>
<li><a href="#6-hinge损失函数">6. <strong>Hinge损失函数</strong></a></li>
</ul>
</li>
<li><a href="#4-常用的代价函数">4. 常用的代价函数</a><ul>
<li><a href="#1-二次代价函数">1. 二次代价函数</a></li>
<li><a href="#2-交叉熵代价函数">2. 交叉熵代价函数</a></li>
<li><a href="#3-对数似然函数代价函数">3. 对数似然函数代价函数</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-sigmoid-为何与交叉熵搭配二不用二次方代价函数">1. Sigmoid 为何与交叉熵搭配二不用二次方代价函数</a></li>
<li><a href="#2-sigmoid-为何要与交叉熵搭配">2. sigmoid 为何要与交叉熵搭配</a></li>
<li><a href="#1-logistic-回归为何要使用对数损失函数">1. Logistic 回归为何要使用对数损失函数？</a></li>
<li><a href="#4为什么交叉熵损失相比均方误差损失能提高以-sigmoid-和-softmax-作为激活函数的层的性能">4.为什么交叉熵损失相比均方误差损失能提高以 sigmoid 和 softmax 作为激活函数的层的性能？</a></li>
<li><a href="#5-损失函数有哪些-怎么用">5. 损失函数有哪些？ 怎么用？</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-经验风险与结构风险">1. 经验风险与结构风险</span></h2><ul>
<li>经验风险指的是模型对数据的拟合程度，拟合程度越高，经验风险越小。（其实对应的就是代价函数）</li>
<li>结构风险指的是对模型复杂度的评估，模型越复杂，结构风险越大。（其实对应的就是目标函数）</li>
</ul>
<p>只考虑将经验风险最小化，会出现过拟合现象。</p>
<h2><span id="2-损失函数代价函数目标函数">2. 损失函数，代价函数，目标函数</span></h2><p>其实在很多论文和博客中都用的很随意，其实三者之间是有着细微的区别的：</p>
<ul>
<li><p>损失函数（Loss Function）：一般针对单个样本的描述。其用来衡量模型预测值与真实值不一致的程度，是一个非负实值函数，通常使用 $L(Y, f(x))$ 表示。 损失函数越小，模型的鲁棒性就越好。</p>
</li>
<li><p>代价函数（Cost Function）：一般是针对总体。我们需要通过训练代价函数来获得最优参数，最常见的如平方差代价函数：</p>
<script type="math/tex; mode=display">
J(\theta) = \frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2</script></li>
<li><p>目标函数（Object Function）：等价于 <strong>代价函数 + 正则化项</strong>， 其往往也是我们模型中要优化求解的函数 — 目标函数。</p>
</li>
</ul>
<h2><span id="3-常用的损失函数">3. 常用的损失函数</span></h2><h3><span id="1-0-1-损失函数">1 . 0-1 损失函数</span></h3><script type="math/tex; mode=display">
L(Y, f(x)) =
\begin{cases}
1,& Y\ne f(x)\\
0,& Y = f(x)
\end{cases}</script><p>相等为 0 ， 不相等为1。一般的在实际使用中，相等的条件过于严格，可适当放宽条件：</p>
<script type="math/tex; mode=display">
L(Y, f(x)) =
\begin{cases}
1,& |Y-f(x)|\geqslant T\\
0,& |Y-f(x)|< T
\end{cases}</script><h3><span id="2-绝对值损失函数">2. <strong>绝对值损失函数</strong></span></h3><script type="math/tex; mode=display">
L(Y, f(x)) = |Y-f(x)|​</script><h3><span id="3-平方损失函数">3. <strong>平方损失函数</strong></span></h3><script type="math/tex; mode=display">
L(Y|f(x)) = \sum_N {(Y-f(x))}^2</script><h3><span id="4-对数损失函数">4. <strong>对数损失函数</strong></span></h3><script type="math/tex; mode=display">
L(Y, P(Y|X)) = -\log{P(Y|X)}</script><p>常见的逻辑回归使用的就是对数损失函数。<strong>逻辑回归它假设样本服从伯努利分布（0-1分布），进而求得满足该分布的似然函数，接着取对数求极值等</strong>。</p>
<h3><span id="5-指数损失函数">5. <strong>指数损失函数</strong></span></h3><p>指数损失函数的标准形式为：</p>
<script type="math/tex; mode=display">
L(Y|f(x)) = \exp(-Yf(x))</script><p>例如<strong>AdaBoost就是以指数损失函数为损失函数。</strong></p>
<h3><span id="6-hinge损失函数">6. <strong>Hinge损失函数</strong></span></h3><script type="math/tex; mode=display">
L(y) = \max{(0, 1-ty)}</script><p>其中 $y$ 是预测值，范围为 $(-1,1)$ ，$t$ 为目标值，其为$-1$ 或 $1$。</p>
<p>在<strong>线性支持向量机</strong>中，最优化问题可等价于</p>
<script type="math/tex; mode=display">
\underset{w,b}{\min}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w\Vert ^2</script><p>上式相似于下式</p>
<script type="math/tex; mode=display">
\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w\Vert ^2</script><p>其中$l(wx_i+by_i)$是Hinge损失函数，$\Vert w\Vert ^2$可看做为正则化项。</p>
<h2><span id="4-常用的代价函数">4. 常用的代价函数</span></h2><p><strong>二次代价函数适合输出神经元是线性的情况，交叉熵代价函数适合输出神经元是S型函数的情况。</strong></p>
<h3><span id="1-二次代价函数">1. 二次代价函数</span></h3><script type="math/tex; mode=display">
J = \frac{1}{2n}\sum_x\Vert y(x)-a^L(x)\Vert^2 \\
单样本：\frac{\partial J}{\partial w}=(a-y)\sigma'(z)x \\
单样本：\frac{\partial J}{\partial b}=(a-y)\sigma'(z)</script><h3><span id="2-交叉熵代价函数">2. 交叉熵代价函数</span></h3><script type="math/tex; mode=display">
J = -\frac{1}{n}\sum_x[y\ln a + (1-y)\ln{(1-a)}] \\
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，\\
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)</script><ul>
<li>它是⾮负的， J &gt; 0。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。</li>
<li>如果对于所有的训练输⼊ x，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。</li>
</ul>
<h3><span id="3-对数似然函数代价函数">3. 对数似然函数代价函数</span></h3><p>交叉熵一般与 sigmoid 结合，而对数似然代价函数一般与 softmax 结合。 对数似然代价函数在二分类时可以化简为交叉熵代价函数的形式。</p>
<h2><span id="qa">QA</span></h2><h3><span id="1-sigmoid-为何与交叉熵搭配二不用二次方代价函数">1. Sigmoid 为何与交叉熵搭配二不用二次方代价函数</span></h3><p>如果使用二次方代价函数，根据权值$w$ 和 $b$ 的偏导：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w}=(a-y)\sigma'(z)x, \\
\frac{\partial J}{\partial b}=(a-y)\sigma'(z)</script><p>考虑到 sigmoid 函数倒数在输出接近 0 和 1 时非常小， 会导致一些样本在刚开始训练时学习的非常慢。</p>
<h3><span id="2-sigmoid-为何要与交叉熵搭配">2. sigmoid 为何要与交叉熵搭配</span></h3><p>交叉熵函数权值$w$和偏置$b$的梯度推导为：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)</script><p>由以上公式可知，权重学习的速度受到$\sigma{(z)}-y$影响，更大的误差，就有更快的学习速度，避免了二次代价函数方程中因$\sigma’{(z)}$导致的学习缓慢的情况。</p>
<h3><span id="1-logistic-回归为何要使用对数损失函数">1. Logistic 回归为何要使用对数损失函数？</span></h3><p>逻辑回归它假设样本服从<strong>伯努利分布（0-1分布）</strong>，进而求得满足该分布的似然函数，接着取对数求极值等。整个过程如下：</p>
<ul>
<li><p>Logistic 回归模型为：</p>
<script type="math/tex; mode=display">
P(y=1|x;\theta)=\frac{1}{1+e^{-\theta^{T}x}}</script></li>
<li><p>Logistic 回归的概率分布为伯努利分布，其概率函数为：</p>
<script type="math/tex; mode=display">
P(X=n)=
\begin{cases}
1-p, n=0\\
 p,n=1
\end{cases}</script></li>
<li><p>其似然函数为：</p>
<script type="math/tex; mode=display">
L(\theta)=\prod_{i=1}^{m}
P(y=1|x_i)^{y_i}P(y=0|x_i)^{1-y_i}</script></li>
<li><p>对应的对数似然函数为：</p>
<script type="math/tex; mode=display">
\ln L(\theta)=\sum_{i=1}^{m}[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln{P(y=0|x_i)}]\\
  =\sum_{i=1}^m[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln(1-P(y=1|x_i))]</script></li>
</ul>
<p>将对数似然函数与上文提到的对数损失函数对比，发现，二者的本质是相同的，所以Logistic 直接采用对数损失函数。</p>
<h3><span id="4为什么交叉熵损失相比均方误差损失能提高以-sigmoid-和-softmax-作为激活函数的层的性能">4.为什么交叉熵损失相比均方误差损失能提高以 sigmoid 和 softmax 作为激活函数的层的性能？</span></h3><p>简单来说，就是使用均方误差（MSE）作为损失函数时，会导致大部分情况下<strong>梯度偏小</strong>，其结果就是权重的更新很慢，且容易造成“梯度消失”现象。而交叉熵损失克服了这个缺点，当误差大的时候，权重更新就快，当误差小的时候，权重的更新才慢。</p>
<p>推导过程： <a href="https://blog.csdn.net/guoyunfei20/article/details/78247263">https://blog.csdn.net/guoyunfei20/article/details/78247263</a></p>
<h3><span id="5-损失函数有哪些-怎么用">5.  损失函数有哪些？ 怎么用？</span></h3><ul>
<li>平方损失 — 预测问题</li>
<li>交叉熵 — 分类问题</li>
<li>Hinge 损失 — SVM</li>
<li>CART 回归树的残差损失</li>
</ul>
<h2><span id="reference">Reference</span></h2><p>[1] DeepLearning-500-questions</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-维数灾难问题</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E7%BB%B4%E6%95%B0%E7%81%BE%E9%9A%BE%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#维数灾难问题">维数灾难问题</a><ul>
<li><a href="#引言">引言</a></li>
<li><a href="#1-维度再难会带来哪些问题">1. 维度再难会带来哪些问题？</a></li>
<li><a href="#2-如何解决维数灾难问题">2. 如何解决维数灾难问题？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="维数灾难问题">维数灾难问题</span></h1><hr>
<h2><span id="引言">引言</span></h2><p>先思考一个问题： <strong>数据的维度越高越好吗？</strong> 恐怕不是吧，不然为什么机器学习中特征工程如此的重要，简单来说， 当数据维度过高时，会为学习带来一些困难。 </p>
<p>其实，任何的机器学习算法，其性能与特征数量的关系往往是这样的：</p>
<p><img data-src="..\img\深度学习\1.jpg" alt="1"></p>
<h2><span id="1-维度再难会带来哪些问题">1. 维度再难会带来哪些问题？</span></h2><ul>
<li><p><strong>数据稀疏：</strong>  这很好理解， 因为维数增多，样本密度必然减少， 举例而言：假设我们现在有10个样本， 而每一维的宽度为5个单位， 这样样本密度为 $\frac{10}{5} = 2$ ； 那么在二维空间下， 样本密度为： $\frac{10}{5*5} = 0.4$， 我们看到样本密度成倍数减少，最终造成了数据稀疏。</p>
</li>
<li><p><strong>样本分布不均匀：</strong>准确的来说，处于中心位置的训练样本比边缘训练样本更加稀疏。</p>
<p>这点可以通过数学定理来解释：N个点在p维单位球内随机分布，则随着p的增大，这些点会越来越远离单位球的中心，转而往外缘分散。而各点距单位球中心距离的计算公式为：</p>
<script type="math/tex; mode=display">
d(p,N) = (1 - \frac{1}{2}^{\frac{1}{N}})^{\frac{1}{p}}</script><p>从另一个角度来看，对于D维空间，位于半径 $r = 1- \epsilon$ 和半径 $r = 1$ 之间的部分占球总体积的百分比是多少？</p>
<p>答案是，随着D的增加，这个比率接近为1 ， 这也就解释了为什么在高维空间中，球体的大部分体积都聚集在表面附近的薄球壳上。</p>
<script type="math/tex; mode=display">
V_{外} = k * 1 ^ p = k \\
V_环  = V_外 - V_内 = K - K (1-\epsilon)^p  \\
\frac{V_环}{V_外} = 1 - (1-\epsilon)^p</script></li>
<li><p><strong>过拟合问题：</strong>可以肯定的一点是，样本在高维数据上更容易分类，但是，在高维中训练得到的分类器其实相当于低维空间上的一个复杂非线性分类器，而了解过拟合的同学都应该知道， 模型过于复杂往往是造成过拟合的直接原因。</p>
</li>
</ul>
<h2><span id="2-如何解决维数灾难问题">2. 如何解决维数灾难问题？</span></h2><ul>
<li>对于数据稀疏与分布不均的问题，只有通过增加训练样本和降维的方式来解决。</li>
<li>对于过拟合问题，可以添加针对过拟合的一些操作来解决。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-距离度量方法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-欧式距离">1. 欧式距离</a></li>
<li><a href="#2-曼哈顿距离">2. 曼哈顿距离</a></li>
<li><a href="#3-余弦距离">3. 余弦距离</a></li>
<li><a href="#4-切比雪夫距离">4. 切比雪夫距离</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-余弦相似度-与-欧式距离的区别与联系">1. 余弦相似度 与 欧式距离的区别与联系</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-欧式距离">1. 欧式距离</span></h2><p>衡量点之间的直线距离</p>
<script type="math/tex; mode=display">
二 维： d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2} \\
n 维： d = \sqrt{(x_1 - y_1)^2 + ... + (x_n - y_n)^2}</script><h2><span id="2-曼哈顿距离">2. 曼哈顿距离</span></h2><script type="math/tex; mode=display">
二 维： d = |x_1 - x_2| + |y_1 - y_2| \\
n 维：d = |x_1 - y_1| + ... + |x_n - y_n|</script><h2><span id="3-余弦距离">3. 余弦距离</span></h2><p>将两个点看做是空间中的两个向量，通过衡量两向量之间的相似性来衡量样本之间的相似性。</p>
<script type="math/tex; mode=display">
二维：cos \, \theta = \frac{x_1 * x_2 + y_1 * y_2}{\sqrt{(x_1^2 + y_1^2)} * \sqrt{x_2^2 + y_2^2}} \quad 或 \quad cos \, \theta = \frac{a * b}{|a| * |b|} \\
n 维： cos \, \theta = \frac{x_1 * y_1 + ... + x_n * y_n}{\sqrt{x_1^2 + ... + x_n^2} * \sqrt{y_1^2 + ... + y_n^2}}</script><h2><span id="4-切比雪夫距离">4. 切比雪夫距离</span></h2><p>各对应坐标数值差的最大值。</p>
<script type="math/tex; mode=display">
二维： d = max(|x_1 - x_2|, |y_1 - y_2|) \\
n 维： d = max(|x_1 - y_1|, ... ,|x_n - y_n|)</script><hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-余弦相似度-与-欧式距离的区别与联系">1. 余弦相似度 与 欧式距离的区别与联系</span></h3><ul>
<li><p>区别：</p>
<p>欧式距离和余弦相似度都能度量2个向量之间的相似度，但是欧式距离从2点之间的距离去考量，余弦相似从2个向量之间的夹角去考量。举例如下：</p>
<blockquote>
<p>假设 2人对三部电影的评分分别是 <code>A = [3, 3, 3]</code> 和 <code>B = [5, 5, 5]</code></p>
<p>那么2人的欧式距离是 根号12 = 3.46， A、B的余弦相似度是1（方向完全一致）。</p>
</blockquote>
<p>从上例可以发出，2人对三部电影的评价趋势是一致的，但是欧式距离并不能反映出这一点，余弦相似则能够很好地反应。余弦相似可以很好地规避指标刻度的差异，最常见的应用是计算 <strong>文本的相似度</strong> 。</p>
</li>
<li><p>联系：</p>
<p><strong>归一化后计算的欧式距离是关于余弦相似的单调函数</strong>，可以认为归一化后，余弦相似与欧式距离效果是一致的（欧式距离越小等价于余弦相似度越大）。</p>
<p>因此可以将 <strong>求余弦相似转为求欧式距离</strong> ，余弦相似的计算复杂度过高，转为求欧式距离后，可以借助<code>KDTree</code>（KNN算法用到）或者<code>BallTree</code>（对高维向量友好）来降低复杂度。</p>
</li>
</ul>
<p><img data-src="..\img\1.cosine.png" alt="1.cosine"></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-迁移学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%20-%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="基础理论-迁移学习">基础理论 - 迁移学习</span></h1><hr>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>基础理论-局部最小值，鞍点</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA-%20%E5%B1%80%E9%83%A8%E6%9C%80%E5%B0%8F%E5%80%BC%EF%BC%8C%E9%9E%8D%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#局部最小值鞍点">局部最小值，鞍点</a><ul>
<li><a href="#基础原理">基础原理</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-如何避免陷入局部最小值与鞍点">1. 如何避免陷入局部最小值与鞍点？</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="局部最小值鞍点">局部最小值，鞍点</span></h1><hr>
<h2><span id="基础原理">基础原理</span></h2><p><a href="https://zhuanlan.zhihu.com/p/48737640">神经网络最终收敛何处？</a></p>
<h2><span id="qa">QA</span></h2><hr>
<h3><span id="1-如何避免陷入局部最小值与鞍点">1. 如何避免陷入局部最小值与鞍点？</span></h3><ul>
<li>SGD 或 Mini-batch：SGD 与 Mini-batch 引入了随机性，每次以部分样本来计算梯度，能够相当程度上避免陷入局部最小值。</li>
<li>动量： 引入动量，相当于引入惯性。一些常见情况时，如上次梯度过大，导致进入局部最小点时，下一次更新能很容易借助上次的大梯度跳出局部最小点。</li>
<li>自适应学习率：通过学习率来控制梯度是一个很棒的思想， 自适应学习率算法能够基于历史的累计梯度去计算一个当前较优的学习率。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>多任务学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="多任务学习">多任务学习</span></h1><p>浅谈多任务学习（Multi-task Learning）： <a href="https://zhuanlan.zhihu.com/p/348873723">https://zhuanlan.zhihu.com/p/348873723</a></p>
<h2><span id="refernence">Refernence</span></h2><p>An Overview of Multi-Task Learning in Deep Neural Networks</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>对比学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="对比学习">对比学习</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/346686467">对比学习（Contrastive Learning）综述</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/141141365">对比学习（Contrastive Learning）相关进展梳理</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>损失函数</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#损失函数">损失函数</a><ul>
<li><a href="#focal-loss">Focal loss</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="损失函数">损失函数</span></h1><h2><span id="focal-loss">Focal loss</span></h2>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型压缩</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%20-%20%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#深度学习模型压缩-综述">深度学习模型压缩 - 综述</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="深度学习模型压缩-综述">深度学习模型压缩 - 综述</span></h1><hr>
<p><a href="https://zhuanlan.zhihu.com/p/67871864">https://zhuanlan.zhihu.com/p/67871864</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/36051603">https://zhuanlan.zhihu.com/p/36051603</a></p>
<p><a href="https://blog.csdn.net/wspba/article/details/75671573">https://blog.csdn.net/wspba/article/details/75671573</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习项目流程</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-定义问题">1. 定义问题</a></li>
<li><a href="#2-探索和清洗数据">2. 探索和清洗数据</a></li>
<li><a href="#3-选择模型并探索模型结果">3. 选择模型并探索模型结果</a></li>
<li><a href="#4-监控训练和验证误差">4. 监控训练和验证误差</a></li>
<li><a href="#模型提升策略">模型提升策略</a><ul>
<li><a href="#1-数据角度">1. 数据角度</a></li>
<li><a href="#2-模型角度">2. 模型角度</a></li>
<li><a href="#3-调参角度">3. 调参角度</a></li>
<li><a href="#4-训练角度">4. 训练角度</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-定义问题">1.  定义问题</span></h2><p>确定是分类问题还是回归问题，还是无监督问题。</p>
<h2><span id="2-探索和清洗数据">2. 探索和清洗数据</span></h2><p><strong>探索和进一步清洗数据集一直都是深度学习中最重要的一步。</strong></p>
<h2><span id="3-选择模型并探索模型结果">3. 选择模型并探索模型结果</span></h2><p>探索模型的结果，通常是需要对模型在验证集上的性能进行进一步的分析，这是如何进一步提升模型性能很重要的步骤。将模型在训练集和验证集都进行结果的验证和可视化，可直观的分析出模型是否存在较大偏差以及结果的正确性。</p>
<h2><span id="4-监控训练和验证误差">4. 监控训练和验证误差</span></h2><p>首先很多情况下，我们忽略代码的<strong>规范性和算法</strong>撰写正确性验证，这点上容易产生致命的影响。</p>
<p>在训练和验证都存在问题时，首先请<strong>确认自己的代码是否正确</strong>。其次，<strong>根据训练和验证误差进一步追踪模型的拟合状态</strong>。若训练数据集很小，此时监控误差则显得格外重要。确定了模型的拟合状态对进一步调整学习率的策略的选择或者其他有效超参数的选择则会更得心应手。</p>
<hr>
<h2><span id="模型提升策略">模型提升策略</span></h2><h3><span id="1-数据角度">1. 数据角度</span></h3><p>数据增强。 扩充数据集。</p>
<h3><span id="2-模型角度">2. 模型角度</span></h3><p>提高模型复杂度，更改模型结构。</p>
<h3><span id="3-调参角度">3. 调参角度</span></h3><h3><span id="4-训练角度">4. 训练角度</span></h3>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>网络模型-CNN经典网络</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%20-%20CNN%20%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="reference">Reference</span></h2><p>[1] LeNet： Gradient-based learning applied to document recognition</p>
<p>[2] AlexNet：ImageNet Classification with Deep Convolutional Neural Networks</p>
<p>[3] VGGNet：Very Deep Convolutional Networks for Large-Scale Image Recognition, ICLR 2015.</p>
<p>[4] GoogleNet：Going Deeper with Convolutions </p>
<p>[5] Resnet： Deep Residual Learning for Image Recognition, CVPR 2016.</p>
<p>[6] DenseNet：Densely Connected Convolutional Networks, CVPR 2017.</p>
<p><a href="https://pytorch.org/docs/master/torchvision/models.html#classification">https://pytorch.org/docs/master/torchvision/models.html#classification</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>自监督学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#自监督学习">自监督学习</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="自监督学习">自监督学习</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>调参-优化算法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B0%83%E5%8F%82%20-%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#简介">简介</a></li>
<li><a href="#超参数设置-遵循原论文">超参数设置 — 遵循原论文</a></li>
<li><a href="#1-三大基本算法">1. 三大基本算法</a><ul>
<li><a href="#1-随机梯度下降">1. 随机梯度下降</a></li>
<li><a href="#2-标准梯度下降">2. 标准梯度下降</a></li>
<li><a href="#3-mini-batch-梯度下降">3. mini-batch 梯度下降</a></li>
<li><a href="#三者比较">三者比较</a></li>
</ul>
</li>
<li><a href="#2-梯度下降算法的一点改进">2. 梯度下降算法的一点改进</a><ul>
<li><a href="#1-动量梯度下降法">1. 动量梯度下降法</a></li>
<li><a href="#2-nesterov-accelerated-gradient">2. Nesterov Accelerated Gradient</a></li>
</ul>
</li>
<li><a href="#3-自适应学习率优化算法">3. 自适应学习率优化算法</a><ul>
<li><a href="#0-为何要自适应学习率">0. 为何要自适应学习率？</a></li>
<li><a href="#1-adagrad">1. Adagrad</a></li>
<li><a href="#2-adadelta">2. Adadelta</a></li>
<li><a href="#3-rmsprop">3. RMSprop</a></li>
<li><a href="#4-adam">4. Adam</a></li>
<li><a href="#5-adamax">5. AdaMax</a></li>
<li><a href="#6-nadam">6. Nadam</a></li>
</ul>
</li>
<li><a href="#如何选择优化算法">如何选择优化算法？</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-在mini-batch-中-batch-size-会带来怎样的影响">1. 在mini-batch 中， batch size 会带来怎样的影响？</a></li>
<li><a href="#2-深度学习为什么不用二阶优化">2. 深度学习为什么不用二阶优化？</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="简介">简介</span></h2><p>优化算法在深度学习中也是十分重要的，虽然一般情况下无脑 Adam 即可，但有时采用其余的优化算法反而能够获得更好的结果，这点很有意思。同时，理解优化算法的原理对于选择和面试还是很有帮助的。</p>
<h2><span id="超参数设置-遵循原论文">超参数设置 — 遵循原论文</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th>优化算法</th>
<th>超参数</th>
</tr>
</thead>
<tbody>
<tr>
<td>SGD</td>
<td></td>
</tr>
<tr>
<td>Momentum</td>
<td>$\gamma: 0.9$</td>
</tr>
<tr>
<td>Adagrad</td>
<td>$\gamma: 0.9$</td>
</tr>
<tr>
<td>RMSprop/ Adadelta</td>
<td></td>
</tr>
<tr>
<td>Adam</td>
<td>$\beta_1: 0.9, \quad \beta_2: 0.999, \quad \epsilon: 1e-8$</td>
</tr>
<tr>
<td>Adamax</td>
<td></td>
</tr>
<tr>
<td>Nadam</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="1-三大基本算法">1. 三大基本算法</span></h2><h3><span id="1-随机梯度下降">1. 随机梯度下降</span></h3><script type="math/tex; mode=display">
\theta = \theta + \eta \cdot  \nabla_\theta J(\theta; x^{(i)}; y^{(i)}) \,\,\, \eta 为学习率</script><h3><span id="2-标准梯度下降">2. 标准梯度下降</span></h3><script type="math/tex; mode=display">
\theta = \theta + \eta \cdot  \nabla_\theta J(\theta)</script><h3><span id="3-mini-batch-梯度下降">3. mini-batch 梯度下降</span></h3><script type="math/tex; mode=display">
\theta = \theta + \eta \cdot  \nabla_\theta J(\theta; x^{(i:i+n)}; y^{(i:i+n)})</script><h3><span id="三者比较">三者比较</span></h3><ul>
<li><strong>随机梯度下降：</strong> 每次更新的方向并不向全局最优解的方向前进，最终的收敛结果也往往在全局最优解附近，但并不能达到最优解。迭代过程不可测。不容易陷入局部最小值。</li>
<li><strong>标准梯度下降：</strong> 更新速度很慢，每次都要计算全部样本的梯度。且由于梯度方向过于稳定一致（没有随机因素）且更新次数过少，很容易陷入鞍点或局部最小值。</li>
<li><strong>mini-batch 梯度下降：</strong> 二者折中，batch size 的设置是一个艺术。</li>
</ul>
<h2><span id="2-梯度下降算法的一点改进">2. 梯度下降算法的一点改进</span></h2><h3><span id="1-动量梯度下降法">1. 动量梯度下降法</span></h3><p>在使用梯度下降算法中，很容易产生一种“震荡现象”（相邻前后梯度正负相反），这种震荡现象减慢了梯度下降法的速度，这也导致你无法使用更大的学习率， 如果你使用较大的学习率， 可能导致震荡更大， 收敛更慢。</p>
<p><strong>Momentum的核心思想： 通过计算梯度的指数加权平均值，并利用该平均值来更新你的权重，这样梯度的变化就没有那么快了。</strong>其本质是通过增加动量来减少随机，增加梯度的稳定性。</p>
<script type="math/tex; mode=display">
v_t = \gamma v_{t-1} + \eta \nabla_\theta J(\theta)  \\ \theta = \theta - v_t \\
\gamma: \text{加权系数，常取值为0.9}</script><p>举个例子， 假如这里有个碗状的峡谷， 峡谷中坑坑洼洼，有许多小坡， 如果我们从峡谷上推下一个球， 根据物理现象，由于加速度，小球的速度在下降的过程中越来越快， 即使路上遇到小坡，也能够轻松跨越（跨不过去，就是局部最小点了）， 直至到达谷底。</p>
<p>引申到动量法的参数变化中： 对于在梯度点处具有相同的方向的维度，表明加速度为正，那么速度自然加快；对于在梯度点处改变方向的维度， 加速度为负， 速度减缓。 这样，我们可以得到更快的收敛速度， 同时可以减少摇摆。</p>
<h3><span id="2-nesterov-accelerated-gradient">2. Nesterov Accelerated Gradient</span></h3><p><img data-src="..\img\momentum.png" alt="momentum"></p>
<script type="math/tex; mode=display">
v_t = \gamma v_{t-1} + \eta \nabla_\theta J(\theta_{t-1} - \gamma v_{t-1})  \\ \theta_t = \theta_{t-1} - v_t</script><ul>
<li><p>思想： 在动量法中， 小球总是以一种盲目的方式滚动， 这会造成一个问题， 在临近最优点的附近时控制不住速度，于是会造成我们在最优点附近摇啊摇，最终收敛。</p>
<p>我们希望小球足够聪明，它能够预判后面的地形， 如果后面是下坡路就加速下降， 如果后面是上坡路，说明我们已经到了最优点附近， 该减速了。</p>
</li>
<li><p>实现方式：Nesterov就利用这一思想，它将 $J(\theta - \gamma v_{t-1})$ 假定为下一位置， 通过计算它的梯度，就可以得到我们接下来是加速还是刹车了，的确很聪明。 </p>
</li>
<li><p>优点：Nesterov Accelerated Gradient 相比Momentum， 能显著的提升了优化效果，收敛速度要快很多。</p>
</li>
</ul>
<p>我们来从数学角度分析一下， 相对 momentum， 到底发生了什么变化：</p>
<script type="math/tex; mode=display">
\begin{align}
\theta_i -\gamma v_i &= \theta_{i-1} - v_i - \gamma v_i \\
&= \theta_{i-1} - (\gamma + 1)v_i \\
&= \theta_{i-1} - (\gamma + 1)[\gamma v_{i-1} + \eta \nabla_\theta J(\theta_{t-1} - \gamma v_{t-1}) ] \\
&= \theta_{i-1} - \gamma^2v_{i-1} - \gamma v_{i-1} - (\gamma + 1)\eta \nabla_\theta J(\theta_{t-1} - \gamma v_{t-1})
\end{align}</script><p>具体推论需要再次参考  <a href="https://zhuanlan.zhihu.com/p/22810533">比Momentum更快：揭开Nesterov Accelerated Gradient的真面目</a></p>
<h2><span id="3-自适应学习率优化算法">3. 自适应学习率优化算法</span></h2><h3><span id="0-为何要自适应学习率">0. 为何要自适应学习率？</span></h3><p>在梯度下降的过程中，每个参数更新的频率与幅度是不同的，到了训练中后期，对于某些变量，也许已经到达了极小值附近，而有些变量仍然在初始位置不远处。 此时，如果我们采用不同的学习率会导致一个问题： 如果学习率偏小，则那些更新不多的参数会收敛的很慢，如果学习率偏大，那么对于处于极小值附近的参数，很容易产生不稳定现象。</p>
<p>为了解决这个问题，我们需要针对不同的参数设置不同的学习率， 但参数是无穷尽的， 不可能去人为的设置每一个参数的学习率，因此，自适应学习率就显得很有必要了。</p>
<h3><span id="1-adagrad">1. Adagrad</span></h3><script type="math/tex; mode=display">
G_{i,t} = G_{i, t-1} + g^2_{i,t-1} \\
g_{t,i} = \nabla_\theta J(\theta_t, i)  \\ \theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{i,t} + \epsilon}} \cdot g_{t,i} \\
\epsilon 是一个极小值，防止分母为 0，一般设置为 1e-8</script><ul>
<li><p>$G_{i,t}$ 是一个对角矩阵， $G[i][i]$ 上的元素表示在第 t 步更新时， 历史上 $\theta$ 梯度的积累。</p>
</li>
<li><p><strong>思想：</strong>对每个参数用不同的学习率，这个学习率在一开始比较大，用于快速梯度下降。随着优化过程的进行，对于已经下降很多的参数，则减缓学习率，对于还没怎么下降的参数，则保持一个较大的学习率。</p>
</li>
<li><p><strong>方法：</strong> 通过维护一个对角矩阵来累积历史梯度来实现学习率的变化， 其中对角线上的每个元素表示某个参数历史梯度的累积。</p>
<p>如果某参数历史梯度较大，那么说明该参数优化的快，更有可能到达最优点附近， 而此时它在对角矩阵上对应的累积梯度也大， 从而使得对应的学习率较小，最终实现不同参数有着不同的学习率。</p>
</li>
<li><p><strong>优点：</strong> 十分适合处理稀疏数据。消除了需要手动调整学习率的问题。</p>
</li>
<li><p><strong>缺陷：</strong> 分母项的积累： 由于每个附加项都是正数，因此累积总和在训练期间不断增长。这反过来导致学习速率缩小并最终变得无限小，此时算法不再进行优化。</p>
</li>
</ul>
<h3><span id="2-adadelta">2. Adadelta</span></h3><script type="math/tex; mode=display">
g_t = \nabla_\theta J(\theta_t)  \\
E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma) g_t^2 \\
\Delta \theta_t = - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t \\ \theta_{t+1} = \theta_t + \Delta \theta_t</script><ul>
<li>$E[g^2]_t$ 表示 t 时刻的<strong>平方梯度对数平均值</strong>， 本质的思想用了对数平均的思路。</li>
<li><strong>改进：</strong> 改进 Adagrad 中学习率最终无限小的问题。</li>
<li><strong>思想：</strong> 通过设定一个窗口大小 w ， 来求最近 w 个平方梯度的对数平均值（对数平均的思想），采用求平均值而非求和的方式可以有效的避免学习率无限低问题。</li>
</ul>
<h3><span id="3-rmsprop">3. RMSprop</span></h3><script type="math/tex; mode=display">
g_t = \nabla_\theta J(\theta_t)  \\
E[g^2]_t = 0.9 E[g^2]_{t-1} + 0.1 g_t^2 \\
\Delta \theta_t = - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t \\ \theta_{t+1} = \theta_t + \Delta \theta_t</script><p>比较 RMSprop 与 Adadelta 二者公式可以发现，在 Adadelta 取 $\gamma = 0.9$ 就是RMSprop了。</p>
<h3><span id="4-adam">4. Adam</span></h3><script type="math/tex; mode=display">
g_t = \nabla_\theta J(\theta_t)  \\
m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t \\ v_t = \beta_2 v_{t-1} +(1-\beta_2) g_t^2 \\ \hat{m}_t = \frac{m_t}{1 - \beta_1^t} \\ \hat{v}_t = \frac{v_t}{1 - \beta_2^t}  \\ \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t }+ \epsilon} \hat{m}_t</script><ul>
<li>$m_t$ 是<strong>历史梯度</strong>的<strong>对数平均估计</strong>， $v_t$ 是<strong>历史梯度平方</strong>的<strong>对数平均估计</strong>，其实就是求取的$E[g_t], E[g_t^2]$ 的近似。</li>
<li>$\hat{m_t}, \hat{v_t}$ 是对 $m_t, v_t$ 的校正，可以近似为对 $E[g_t], E[g_t^2]$ 的无偏估计。</li>
</ul>
<p>我们结合 Momentum 与 RMSProp 算法来看， Adam算法本质上就是将二者结合，同时考虑到梯度与梯度平方， 通过历史梯度来加速收敛， 通过历史梯度平方来修正学习率。</p>
<ul>
<li><p>优点： 高效的计算，收敛非常快。适合解决大规模数据和参数优化问题。</p>
</li>
<li><p>为何要进行偏差修正：</p>
<blockquote>
<p>因为初始化的 $m_t$ 与 $v_t$ 为 0 向量，在通过指数平均计算均值时会偏差向 0， 尤其是在初始时间步中和 $\beta_1， \beta_2$ 非常小的情况下（接近于1），尤其如此。 </p>
</blockquote>
</li>
</ul>
<p>更复杂的分析，推荐： <a href="https://juejin.im/entry/5983115f6fb9a03c50227fd4">深度学习最常用的算法:Adam优化算法</a></p>
<h3><span id="5-adamax">5. AdaMax</span></h3><h3><span id="6-nadam">6. Nadam</span></h3><h2><span id="如何选择优化算法">如何选择优化算法？</span></h2><p>我个人一般选择 Adam， 优点是，收敛快，这样模型迭代起来也快， 如果是轻量级模型的话， 需要好好选择优化算法调参， 而如果是重量级的模型， 无脑 Adam 是一个相当不错的选择。</p>
<h2><span id="qa">QA</span></h2><hr>
<h3><span id="1-在mini-batch-中-batch-size-会带来怎样的影响">1. 在mini-batch 中， batch size 会带来怎样的影响？</span></h3><p>batch size 的大小往往是由多个因素决定的：</p>
<ul>
<li><strong>较大的批能得到更精确的梯度估计</strong>。</li>
<li><strong>较小的批能带来更好的泛化误差</strong>，泛化误差通常在批大小为 1 时最好。但是，因为梯度估计的高方差，小批量训练时需要<strong>较小的学习率</strong>以保持稳定性，这意味着<strong>更长的训练时间</strong>。</li>
<li>batch size 与所需显存息息相关，可参见：<a href="https://zhuanlan.zhihu.com/p/65002487">GPU 显存不足怎么办？</a></li>
<li>在 GPU 上， 请采用 2 的幂数作为 batch size， 一般取值在 32 - 256。</li>
<li>小批量更容易利用<strong>多核架构</strong>，但是太小的批并不会减少计算时间，这促使我们使用一些<strong>绝对最小批量</strong></li>
</ul>
<h3><span id="2-深度学习为什么不用二阶优化">2. 深度学习为什么不用二阶优化？</span></h3><p>目前深度学习中，反向传播主要是依靠一阶梯度。二阶梯度在理论和实际上都是可以应用都网络中的，但相比于一阶梯度，二阶优化会存在以下一些主要问题：</p>
<ul>
<li>计算量大，训练非常慢。</li>
<li>二阶方法能够更快地求得更高精度的解，这在浅层模型是有益的。而在神经网络这类深层模型中对参数的精度要求不高，甚至不高的精度对模型还有益处，能够提高模型的泛化能力。</li>
<li>稳定性：二阶方法能更快求高精度的解，同样对数据本身要的精度也会相应的变高，这就会导致稳定性上的问题。</li>
</ul>
<h2><span id="reference">Reference</span></h2><p>[1] An overview of gradient descent optimization algorithms</p>
<p><a href="https://zhuanlan.zhihu.com/p/21486826"> 路遥知马力——Momentum</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/22810533">比Momentum更快：揭开Nesterov Accelerated Gradient的真面目</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>调参-权重初始化</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B0%83%E5%8F%82%20-%20%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#前言">前言</a></li>
<li><a href="#权重初始化为何如此重要">权重初始化为何如此重要？</a></li>
<li><a href="#xavier-初始化">Xavier 初始化</a></li>
<li><a href="#kaiming-初始化">Kaiming 初始化</a></li>
<li><a href="#初始化方案">初始化方案</a><ul>
<li><a href="#1-常量初始化">1. 常量初始化</a></li>
<li><a href="#2-随机初始化">2. 随机初始化</a></li>
<li><a href="#2-均匀分布初始化-uab">2. 均匀分布初始化 - U(a,b)</a></li>
<li><a href="#3-高斯分布-nmean-std">3. 高斯分布 - N(mean, std)</a></li>
<li><a href="#4-单位矩阵初始化">4. 单位矩阵初始化</a></li>
<li><a href="#5-xavier-初始化">5. Xavier  初始化</a></li>
<li><a href="#6-kaiming-初始化msra初始化">6. Kaiming 初始化（MSRA初始化）</a></li>
<li><a href="#7-正交初始化">7. 正交初始化</a></li>
<li><a href="#8-稀疏初始化">8. 稀疏初始化</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-推导一下-xavier-的过程">1. 推导一下 Xavier 的过程</a><ul>
<li><a href="#单层网络">单层网络</a></li>
<li><a href="#前向传播">前向传播</a></li>
<li><a href="#反向传播">反向传播</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#适用范围">适用范围</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="前言">前言</span></h2><p>本节先对一些常见的初始化方案进行描述，然后依托于 Pytorch ， 论述 Pytorch 中提供的几个初始化方案，最后提出一些使用建议。</p>
<h2><span id="权重初始化为何如此重要">权重初始化为何如此重要？</span></h2><p>虽然 Batch Normalization， Layer Normalization 等 Trick 大大减轻了我们需要精选权重初始化方案的需要，但对于大多数情况下， 选择合适的初始化方案依旧有利于加速我们模型的收敛。</p>
<p>从根本上看，选择合适的初始化方案能够使得我们的损失函数便于优化（有些优化面坑坑洼洼，有些优化面比较光滑）； 从另一个角度来说， 合适的权重初始化有利于减轻梯度消失，梯度爆炸问题（参考公式推导）。</p>
<h2><span id="xavier-初始化">Xavier 初始化</span></h2><script type="math/tex; mode=display">
W \, \sim U [ -\frac{\sqrt{6}}{\sqrt{n_i+ n_{i + 1}}}, \frac{\sqrt{6}}{\sqrt{n_i + n_{i + 1}}} ]，  n_i 表示第 i 层神经元的个数</script><ul>
<li>目的： 减轻梯度消失问题。</li>
</ul>
<p>在对梯度的研究中，  发现反向梯度从输出层到输入层逐渐减小， 同时反向梯度的方差随网络反向也逐渐减小，针对这种现象，提出了Xavier initialization。</p>
<p>其的基本思想为：<strong>保持每一层输入的方差,反向梯度的方差一致</strong>。通过方差可以控制输入输出分布以及分布密度之间不要相差太大， 这可以使得信息在网络中能够更平滑的传播。</p>
<h2><span id="kaiming-初始化">Kaiming 初始化</span></h2><p>kaiming初始化的出现是因为xavier存在一个不成立的假设。xavier在推导中假设激活函数都是线性的，而在深度学习中常用的ReLu等都是非线性的激活函数。而kaiming初始化本质上是高斯分布初始化，与上述高斯分布初始化有所不同，其是个满足均值为0，方差为2/n的高斯分布：</p>
<script type="math/tex; mode=display">
[0,\sqrt{\frac{2}{n}}]</script><ul>
<li>n  为所在曾的输入维度</li>
</ul>
<h2><span id="初始化方案">初始化方案</span></h2><h3><span id="1-常量初始化">1. 常量初始化</span></h3><ul>
<li><p>初始化为 0： 当我们在初始化的时候，最容易想到的就是初始化为0，但是，将W初始化为0， 那么在前向计算的时候，我们的<strong>所有神经元的输出均为相同</strong>， 然后在反向传播中， <strong>梯度相同</strong>， <strong>权重更新相同</strong>，这明显是不可行的。</p>
<p>所以， <strong>千万不要初始化为0。</strong></p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.constant_(tensor, val)</span><br></pre></td></tr></table></figure>
<h3><span id="2-随机初始化">2. 随机初始化</span></h3><p>如果我们采用随机初始化，因为我们不知道我们的参数会初始化为多少， 如果初始化不合理， 造成梯度消失的可能性是相当之大，另一方面，如果初始化在优化面坑坑洼洼的那一面，我们的优化过程将变得异常曲折，局部最小值，鞍点以及大的平坦区会造成优化的噩梦。 </p>
<h3><span id="2-均匀分布初始化-uab">2. 均匀分布初始化 - U(a,b)</span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.uniform_(tensor, a=0.0, b=1.0)</span><br></pre></td></tr></table></figure>
<h3><span id="3-高斯分布-nmean-std">3. 高斯分布 - N(mean, std)</span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.normal_(tensor, mean=0.0, std=1.0)</span><br></pre></td></tr></table></figure>
<h3><span id="4-单位矩阵初始化">4.  单位矩阵初始化</span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.eye_(tensor)</span><br></pre></td></tr></table></figure>
<h3><span id="5-xavier-初始化">5. Xavier  初始化</span></h3><ul>
<li><p>Xavier 均匀分布</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.xavier_uniform_(tensor, gain=1.0)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Xavier 正态分布</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.xavier_normal_(tensor, gain=1.0)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3><span id="6-kaiming-初始化msra初始化">6. Kaiming 初始化（MSRA初始化）</span></h3><ul>
<li><p>Kaiming 均匀分布</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.kaiming_uniform_(tensor, a=0, mode=&#x27;fan_in&#x27;, nonlinearity=&#x27;leaky_relu&#x27;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Kaiming 正态分布</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.kaiming_normal_(tensor, a=0, mode=&#x27;fan_in&#x27;, nonlinearity=&#x27;leaky_relu&#x27;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3><span id="7-正交初始化">7. 正交初始化</span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.orthogonal_(tensor, gain=1)</span><br></pre></td></tr></table></figure>
<h3><span id="8-稀疏初始化">8. 稀疏初始化</span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.init.sparse_(tensor, sparsity, std=0.01)</span><br></pre></td></tr></table></figure>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-推导一下-xavier-的过程">1. 推导一下 Xavier 的过程</span></h3><h4><span id="单层网络">单层网络</span></h4><p>假设我们使用线性激活函数 $f(x)$，那么对于一层网络来说有：</p>
<script type="math/tex; mode=display">
y = f(x) = \sum_i^n w_ix_i + b, \,\,\, i = i\cdots n</script><p>根据方差展开式有：</p>
<script type="math/tex; mode=display">
Var(w_ix_i) = E[w_i]^2Var(x_i) + E[x_i]^2 Var(w_i) + Var(w_i) Var(x_i)</script><p>那么，当 $E(x_i) = E(w_i) = 0, \,\,\,\, i = 1\cdots n$ 时， 输出 y 的方差为：</p>
<script type="math/tex; mode=display">
Var(y) = \sum_i^n Var(w_ix_i) =  \sum_i^n Var(w_i) Var(x_i)</script><p>如果 $w_1, \cdots, w_n $ 独立同分布， $x_1, \cdots, x_n$ 也独立同分布， 那么有：</p>
<script type="math/tex; mode=display">
Var(w_1) = \cdots = Var(w_n)  \\ Var(x_1) = \cdots = Var(x_n)</script><p> 那么，我们就可以得出：</p>
<script type="math/tex; mode=display">
Var(y) = n_i Var(w_i) Var(x_i)</script><p>于是，为了保证方差的一致性，则应该有：</p>
<script type="math/tex; mode=display">
Var(w_i) = \frac{1}{n_i}</script><p>现在我们延伸到多层网络中，我们假设 $z^i$ 是第 $i$ 层激活函数的输出向量， $s^i$ 是第 $i$ 层激活函数的输入向量。</p>
<h4><span id="前向传播">前向传播</span></h4><script type="math/tex; mode=display">
s^i = z^iW^i + b^i \\ z^{i+1} = f(s^i)</script><p>那么在前向传播中， 第 $i$ 层的方差可以累积表达为：</p>
<script type="math/tex; mode=display">
Var[z^i] = Var[x] \prod_{j=0}^{i-1} n_j Var[W^j]</script><h4><span id="反向传播">反向传播</span></h4><p>而在反向传播公式中， 损失函数对于 $s^i$ 梯度公式为：</p>
<script type="math/tex; mode=display">
\frac{\delta Cost}{\delta s_k^i} = f'(s^i_k) W_k^{i+1} \frac{\delta Cost}{\delta s^{i+1}}  \\</script><p>那么在d层网络中，第 $i$ 层梯度的累计方差为：</p>
<script type="math/tex; mode=display">
Var[\frac{\delta Cost}{ \delta s^i}] = Var[\frac{\delta Cost}{\delta s^d}] \prod_{j=i}^d n_{j+1} Var[W^j] \\</script><p>我们的目的是，要求各层输入方差一致且各层梯度的方差也一致，这也就意味着：</p>
<script type="math/tex; mode=display">
Var[z^i] = Var[z^{i-1}]= \cdots = Var[x] \\ Var[\frac{\delta Cost}{\delta s^i}] =  = \cdots = Var[\frac{\delta Cost}{\delta s^{d}}]</script><p>那么必须有：</p>
<script type="math/tex; mode=display">
前向传播： \forall i ,  n_i Var[W^i] = 1 \\ 反向传播： \forall  i, n_{i+1} Var[W^i] = 1</script><p>我们的W需要同时满足以上两个条件， 因此作为折中，有：</p>
<script type="math/tex; mode=display">
\forall i, Var[W^i] = \frac{2}{n_i + n_{i+1}}</script><p>如果我们假设 W 服从均匀分布，则W在区间[a,b]内均匀分布的方差为：</p>
<script type="math/tex; mode=display">
Var = \frac{(b-a)^2}{12}</script><p>那么带入就可以得到W的分布：</p>
<script type="math/tex; mode=display">
W \, \sim U [ -\frac{\sqrt{6}}{\sqrt{n_i+ n_{i + 1}}}, \frac{\sqrt{6}}{\sqrt{n_i + n_{i + 1}}} ]</script><h2><span id="适用范围">适用范围</span></h2><h2><span id="reference">Reference</span></h2><p>[1]  Xavier Glorot et al., Understanding the Difficult of Training Deep Feedforward Neural Networks</p>
<p>[2]  Kaiming He et al., Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classfication</p>
<p><a href="https://zhuanlan.zhihu.com/p/25110150">聊一聊深度学习的weight initialization</a></p>
<p><a href="http://www.zhuanzhi.ai/document/b5620e285c10477c1490566d8eeea207">吴恩达团队：神经网络如何正确初始化？</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>调参-激活函数</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B0%83%E5%8F%82%20-%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#前言">前言</a></li>
<li><a href="#1-激活函数的性质">1. 激活函数的性质</a></li>
<li><a href="#2-激活函数一览-todo">2. 激活函数一览 — TODO</a><ul>
<li><a href="#1-sigmoid">1. sigmoid</a></li>
<li><a href="#2-tanh">2. tanh</a></li>
<li><a href="#3-relu">3. Relu</a></li>
</ul>
</li>
<li><a href="#3-如何选择激活函数">3. 如何选择激活函数</a></li>
<li><a href="#relu-的优点">Relu 的优点</a></li>
<li><a href="#激活函数的稀疏激活性">激活函数的稀疏激活性</a></li>
<li><a href="#qa">QA</a></li>
<li><a href="#0-dead-relu-问题">0. Dead Relu 问题</a><ul>
<li><a href="#1-relu-vs-sigmoid-vs-tanh">1. Relu VS Sigmoid VS tanh</a></li>
<li><a href="#2-为什么relu-不是全程可微也能用于基于梯度的学习">2. 为什么Relu 不是全程可微也能用于基于梯度的学习？</a></li>
<li><a href="#3-为何加入非线性因素能够加强网络的表示能力">3. 为何加入非线性因素能够加强网络的表示能力？</a></li>
<li><a href="#4-为何-tanh-比-sigmoid-收敛快">4. 为何 tanh 比 sigmoid 收敛快？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a href="https://zhuanlan.zhihu.com/p/352668984">https://zhuanlan.zhihu.com/p/352668984</a></p>
<h2><span id="前言">前言</span></h2><p>本文先对激活函数的特性，常见的激活函数以及如何选择合适的激活函数。</p>
<p><strong>需要注意的是，激活函数是来向神经网络中引入非线性因素的，通过激活函数，神经网络就可以拟合各种曲线。</strong>可参考：<a href="https://zhuanlan.zhihu.com/p/44398148">激活函数，你真的懂了吗？</a></p>
<h2><span id="1-激活函数的性质">1. 激活函数的性质</span></h2><ul>
<li><p><strong>非线性：</strong>为模型引入非线性因素</p>
</li>
<li><p><strong>几乎处处可微：</strong>有限的不可微点有左右导数（左右导数可能不同，如Relu）。 便于反向传播，利于优化</p>
</li>
<li><p><strong>计算简单：</strong>激活函数在神经网络前向的计算次数与神经元的个数成正比，因此简单的非线性函数自然更适合用作激活函数。这也是ReLU之流比其它使用Exp等操作的激活函数更受欢迎的其中一个原因。</p>
</li>
<li><p><strong>非饱和性：</strong>饱和指的是在某些区间梯度接近于零（即梯度消失），使得参数无法继续更新的问题。</p>
</li>
<li><p><strong>单调性：</strong>当激活函数是单调的时候，单层网络能够保证是凸函数；</p>
</li>
<li><p>$ f(x)≈x $： 当激活函数满足这个性质的时候，如果参数的初始化是随机的较小值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要详细地去设置初始值。 </p>
<p>由于这个条件与非线性有点矛盾，因此激活函数基本只是部分满足这个条件，如 relu 只再 x&gt;0 时为线性。</p>
</li>
<li><p><strong>输出值的范围有限：</strong> 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；但这导致了前面提到的梯度消失问题，而且强行让每一层的输出限制到固定范围会限制其表达能力。</p>
<p>当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的 Learning Rate。</p>
</li>
<li><p><strong>参数少：</strong> 大部分激活函数都是没有参数的。</p>
</li>
<li><p><strong>归一化：</strong> 主要思想是使样本分布自动归一化到零均值、单位方差的分布，从而稳定训练。</p>
</li>
</ul>
<h2><span id="2-激活函数一览-todo">2. 激活函数一览 — TODO</span></h2><h4><span id="1-sigmoid">1. sigmoid</span></h4><h4><span id="2-tanh">2. tanh</span></h4><p>tanh 本质上是 sigmoid 向下平移和伸缩后的结果。</p>
<h4><span id="3-relu">3. Relu</span></h4><h2><span id="3-如何选择激活函数">3. 如何选择激活函数</span></h2><ul>
<li>如果是二分类问题， 输出层是sigmoid，其余层是Relu</li>
<li>一般隐层采用Relu， 有时也要试试 tanh， 这两大函数的变体都有必要试试</li>
</ul>
<h2><span id="relu-的优点">Relu 的优点</span></h2><ul>
<li>Relu 不耗费资源，且导数为1， 学习起来较快</li>
<li>sigmoid， tanh 的导数在正负饱和区的梯度都会接近于0， 这会造成梯度消失。</li>
<li>Relu 有Dead Relu 问题，此时试试其变体， 如Leaky Relu</li>
</ul>
<h2><span id="激活函数的稀疏激活性">激活函数的稀疏激活性</span></h2><p>从信号方面来看，即神经元同时只对输入信号的少部分选择性响应，大量信号被刻意的屏蔽了，这样可以提高学习的精度，更好更快地提取稀疏特征。当 $ x<0 $ 时，relu 硬饱和，而当 x>0 $ 时，则不存在饱和问题。ReLU 能够在 $ x&gt;0 $ 时保持梯度不衰减，从而缓解梯度消失问题。</0></p>
<hr>
<h2><span id="qa">QA</span></h2><h2><span id="0-dead-relu-问题">0. Dead Relu 问题</span></h2><p>某些神经元可能永远不会被激活， 导致其相应的参数永远不能被更新。其本质是<strong>由于Relu在的小于0时其梯度为0所导致的。</strong></p>
<p>首先我们假设Relu的输入是一个低方差中心在+0.1的正态分布， 此时假设现在大多数Relu的输入是正数，那么大多数输入经过Relu函数能得到一个正值， 因此此时大多数输入能够反向传播通过Relu得到一个梯度， 于是我们的Relu的输入就完成了更新。</p>
<p>假设在随机反向传播中， 有一个巨大的梯度经过了Relu且此时Relu的输入为正（Relu是打开的）， 那么该梯度会引起Relu输入X的巨大变化， 假设此时输入X的分布变成了一个中心在-0.1 的正态分布。此时的情况如下：</p>
<blockquote>
<p>首先， 大多数Relu的输入变为负数， 输入经过Relu函数就能得到一个0， 这也意味着大多数输入不能反向传播通过Relu得到一个梯度，导致这部分输入无法通过更新。</p>
</blockquote>
<h3><span id="1-relu-vs-sigmoid-vs-tanh">1. Relu VS Sigmoid VS tanh</span></h3><ul>
<li><p>sigmoid 缺陷：</p>
<blockquote>
<ul>
<li>极容易导致梯度消失问题</li>
<li>计算费时</li>
<li><strong>sigmoid 函数不是关于原点中心对称的</strong></li>
</ul>
</blockquote>
</li>
<li><p>tanh 缺陷： 无法解决梯度消失问题</p>
</li>
<li><p>Relu 优点：</p>
<blockquote>
<ul>
<li><strong>一定程度上缓解了梯度问题：</strong> 其导数始终为一个常数</li>
<li><strong>计算速度非常快：</strong> 求导不涉及浮点运算，所以速度更快</li>
<li><strong>减缓过拟合：</strong> <code>ReLU</code> 在负半区的输出为 0。一旦神经元的激活值进入负半区，那么该激活值就不会产生梯度/不会被训练，造成了网络的稀疏性——<strong>稀疏激活</strong>， 这有助于减少参数的相互依赖，缓解过拟合问题的发生</li>
</ul>
</blockquote>
</li>
</ul>
<h3><span id="2-为什么relu-不是全程可微也能用于基于梯度的学习">2. 为什么Relu 不是全程可微也能用于基于梯度的学习？</span></h3><p>虽然 ReLU 在 0 点不可导，但是它依然存在<strong>左导数和右导数</strong>，只是它们不相等（相等的话就可导了），于是在实现时通常会返回左导数或右导数的其中一个，而不是报告一个导数不存在的错误。</p>
<h3><span id="3-为何加入非线性因素能够加强网络的表示能力">3. 为何加入非线性因素能够加强网络的表示能力？</span></h3><ul>
<li>神经网络的万能近似定理：神经网络只要具有至少一个非线性隐藏层，那么只要给予网络足够数量的隐藏单元，它就可以以任意的精度来近似任何<strong>从一个有限维空间到另一个有限维空间</strong>的函数。</li>
<li>如果不使用非线性激活函数，那么每一层输出都是上层输入的<strong>线性组合</strong>；此时无论网络有多少层，其整体也将是线性的，这会导致失去万能近似的性质</li>
<li>但仅<strong>部分层是纯线性</strong>是可以接受的，这有助于<strong>减少网络中的参数</strong>。</li>
</ul>
<h3><span id="4-为何-tanh-比-sigmoid-收敛快">4. 为何 tanh 比 sigmoid 收敛快？</span></h3><script type="math/tex; mode=display">
tanh^{'}(x)=1-tanh(x)^{2}\in (0,1) \\
sigmoid^{'}(x)=sigmoid(x)*(1-sigmoid(x))\in (0,\frac{1}{4}]</script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>调参-超参数调优</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%B0%83%E5%8F%82%20-%20%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-超参数一览">1. 超参数一览</a><ul>
<li><a href="#1-超参数是什么">1. 超参数是什么？</a></li>
<li><a href="#2-网络结构参数">2. 网络结构参数</a></li>
<li><a href="#2-优化参数">2. 优化参数</a></li>
<li><a href="#3-trick-参数">3. Trick 参数</a></li>
</ul>
</li>
<li><a href="#2-几个重要的超参数">2. 几个重要的超参数</a><ul>
<li><a href="#1-学习率-最重要的超参数">1. 学习率 — 最重要的超参数</a></li>
<li><a href="#2-batch-size">2. batch size</a></li>
<li><a href="#3-dropout">3. dropout</a></li>
<li><a href="#4-优化器参数">4. 优化器参数</a></li>
</ul>
</li>
<li><a href="#超参数调优策略">超参数调优策略</a><ul>
<li><a href="#1-网格搜索">1. 网格搜索</a></li>
<li><a href="#2-随机搜索">2. 随机搜索</a></li>
<li><a href="#3-贝叶斯优化">3. 贝叶斯优化</a></li>
</ul>
</li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-为何学习率那么重要">1. 为何学习率那么重要？</a></li>
<li><a href="#2-卷积核尺寸为何都是奇数">2. 卷积核尺寸为何都是奇数？</a></li>
<li><a href="#3-深层网络为何难以训练">3. 深层网络为何难以训练</a></li>
<li><a href="#4-神经网络为何要做深">4. 神经网络为何要做深？</a></li>
<li><a href="#5-调节-batch_size-对训练效果影响如何">5. 调节 batch_size 对训练效果影响如何？</a></li>
<li><a href="#6-合理增加-batch-size-有何好处">6. 合理增加 batch size 有何好处？</a></li>
<li><a href="#7-盲目增大-batch_size-有何坏处">7. 盲目增大 Batch_Size 有何坏处？</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a href="https://zhuanlan.zhihu.com/p/29247151">https://zhuanlan.zhihu.com/p/29247151</a></p>
<h2><span id="1-超参数一览">1. 超参数一览</span></h2><h3><span id="1-超参数是什么">1. 超参数是什么？</span></h3><ul>
<li>参数： 需要训练，指的是模型训练中的权重参数和 bias 参数。</li>
<li>超参数： 不需要训练，需要在训练前进行指定，并不断调整。</li>
</ul>
<p>其实就很多超参数来说，调整的意义并不大，毕竟往往网络的超参数多达几十个，要是都精调的话，那岂不是得 gg， 因此往往是对重要参数精调，对次要参数粗调。</p>
<p>此外，很多 Trick 往往需要一些其他的超参数，对于这部分参数，往往我会遵循原论文，适当的调一调就行。毕竟，Trick 无穷尽呀。</p>
<h3><span id="2-网络结构参数">2. 网络结构参数</span></h3><p>网络参数指的是你自己构建网络结构时的相关参数，如卷积核数量，网络层数等</p>
<ul>
<li><p>CNN 网络参数</p>
<p>| 超参数      | 说明          | 推荐值                                         |<br>| —————- | ——————- | ——————————————————————— |<br>| kernel size | 卷积核的 size | 一般为奇数：[7 <em> 7], [5 </em> 5], [3 <em> 3], [1 </em> 1] |<br>| kernel num  | 卷积核的数量  | 一般在 [100, 600] 间探索                       |<br>|             |               |                                                |</p>
</li>
<li><p>RNN 网络参数</p>
<p>| 超参数 | 说明 | 推荐值 |<br>| ——— | —— | ——— |<br>|        |      |        |<br>|        |      |        |<br>|        |      |        |</p>
</li>
<li><p>Transformer 参数</p>
<p>| 超参数 | 说明 | 推荐值 |<br>| ——— | —— | ——— |<br>|        |      |        |<br>|        |      |        |<br>|        |      |        |</p>
</li>
</ul>
<h3><span id="2-优化参数">2. 优化参数</span></h3><p>优化参数指的是反向传播中所涉及到的参数，主要包括：学习率， batch_size， 对应优化器参数， 损失函数参数等。</p>
<ul>
<li>常见参数</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>超参数</th>
<th>说明</th>
<th>推荐值</th>
</tr>
</thead>
<tbody>
<tr>
<td>learning rate</td>
<td>最重要的参数，需要精调</td>
<td>下文有推荐</td>
</tr>
<tr>
<td>batch size</td>
<td>次要重要参数，需要精调</td>
<td>[1: 1024]</td>
</tr>
<tr>
<td>dropout</td>
<td>解决过拟合的重要参数，需要精调</td>
<td>[0: 0.5]</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>优化器相关参数：</p>
<p>| 优化器 | 参数说明 | 推荐值 |<br>| ——— | ———— | ——— |<br>| Adam   |          |        |<br>|        |          |        |<br>|        |          |        |</p>
</li>
<li><p>正则化参数：</p>
<p>| 超参            | 说明 | 推荐值    |<br>| ———————- | —— | ————- |<br>| L2 权重衰减系数 |      | [0, 1e-4] |<br>|                 |      |           |<br>|                 |      |           |</p>
</li>
</ul>
<h3><span id="3-trick-参数">3. Trick 参数</span></h3><div class="table-container">
<table>
<thead>
<tr>
<th>超参数</th>
<th>说明</th>
<th>推荐值</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2><span id="2-几个重要的超参数">2. 几个重要的超参数</span></h2><h3><span id="1-学习率-最重要的超参数">1. 学习率 — 最重要的超参数</span></h3><p>学习率直接控制着梯度更新时的量级，从而直接影响模型的优化与最终的有效容量。 幸运的是，对于学习率的设置，已经有一套行之可效的指导方案了， 针对不同的优化器，有不同的设置区间。 </p>
<p>如果是微调，那么学习率要降低两个数量级左右（参考 Bert 的 adam 学习率)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>优化器</th>
<th>设置范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>SGD</td>
<td>[1e-2 ,1e-1]</td>
</tr>
<tr>
<td>Momentum</td>
<td>[1e-3, 1e-2]</td>
</tr>
<tr>
<td>Adagrad</td>
<td>[1e-3, 1e-2]</td>
</tr>
<tr>
<td>Adadelta</td>
<td>[1e-2, 1e-1]</td>
</tr>
<tr>
<td>RMSprop</td>
<td>[1e-3, 1e-2]</td>
</tr>
<tr>
<td>Adam</td>
<td>[1e-3, 1e-2]</td>
</tr>
<tr>
<td>Nadam</td>
<td>[1e-3, 1e-2]</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="2-batch-size">2. batch size</span></h3><p>一般情况下，  batch size 我往往会以 128 为起点，上下调整，注意，batch size 要设置为 2 的幂次方， 范围在 [1, 1024] 之间。</p>
<p>此外，需要一提的是 Batch Normalization 与 batch size 息息相关，如果你使用了 Batch Normalization， 那么 batch size 就不能设的太小， 这点我在 Normalization 那一节中有详细解释。</p>
<h3><span id="3-dropout">3. dropout</span></h3><p>dropout 我往往会设置先为 0.5， 然后在 [0.0, 0.5] 范围内精调。</p>
<p>Dropout 往往会在卷积层和全连接层之间是有来防止过拟合。 使用 Dropout 需要注意两点：</p>
<ul>
<li>在RNN中，如果直接放在memory cell中,循环会放大噪声，扰乱学习。一般会建议放在输入和输出层；</li>
<li>不建议dropout后直接跟上batchnorm，dropout很可能影响batchnorm计算统计量，导致方差偏移，这种情况下会使得推理阶段出现模型完全垮掉的极端情况；</li>
</ul>
<h3><span id="4-优化器参数">4. 优化器参数</span></h3><p>对于优化器的一些参数，我往往会采取默认值，这是因为，默认值都是论文最初的设置，一般都能够获得不错的表现，我个人一般不做很精细的调试，也不建议这样去做。</p>
<h2><span id="超参数调优策略">超参数调优策略</span></h2><p><strong>采用2的幂次方作为 batch_size 的值，并在对数尺度上对学习率进行采样。</strong></p>
<h3><span id="1-网格搜索">1. 网格搜索</span></h3><ul>
<li>定义一个 n 维的网格，每一格都有一个超参数。</li>
<li>对于每个维度，定义可能的取值范围</li>
<li>搜索所有可能的配置并获得最佳结果</li>
</ul>
<p>我个人一般还是用 Markdown 表格来做记录， 如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>优化算法</th>
<th>学习率</th>
<th>batch_size</th>
</tr>
</thead>
<tbody>
<tr>
<td>adam</td>
<td>1e-5</td>
<td>128</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><strong>缺点：</strong>该方法痛点真的很痛，那就是：<strong>维数灾难</strong>。 随着要精调的超参数的增加，搜索在时间复杂度上也会增加的越多（指数级别），最终使得该策略不可行。</li>
<li><strong>优点：</strong> 如果采用较大的搜索范围以及较小步长，该方法有很大概率能找到全局最优值</li>
</ul>
<p>因此， 我一般尽可能少的去调节次要超参数，比如优化算法默认 Adam 等。此外， 先进行粗调来寻找全局最优值可能的位置，然后采用精调的策略寻找更精确的最优值。</p>
<p>一般只有超参数在 4 个以内才使用网格搜索，不然太费时间了。</p>
<h3><span id="2-随机搜索">2. 随机搜索</span></h3><p>随机搜索在搜索范围内随机选取样本点，它认为如果样本点集足够大，那么通过随机采样也能大概率的找到全局最优值或其近似值。</p>
<ul>
<li>优点： 比网格搜索要快</li>
<li>缺点：结果无法保证，很依靠调参经验。</li>
</ul>
<p>我一般都是以推荐超参数设置方案来作为第一次的设置，然后围绕这个设置点上下浮动。</p>
<h3><span id="3-贝叶斯优化">3. 贝叶斯优化</span></h3><p>网格搜索与随机搜索都是独立于之前的训练的，</p>
<p><a href="https://zhuanlan.zhihu.com/p/29779000">https://zhuanlan.zhihu.com/p/29779000</a></p>
<p>贝叶斯则是利用历史的搜索结果进行优化搜索。其主要有四部分组成，</p>
<ul>
<li>目标函数，大部分情况下就是模型验证集上的损失。</li>
<li>搜索空间，即各类待搜索的超参数。</li>
<li>优化策略，建立的概率模型和选择超参数的方式。</li>
<li>历史的搜索结果。</li>
</ul>
<p>首先对搜索空间进行一个先验性的假设猜想，即假设一种选择超参的方式，然后不断的优化更新概率模型，最终的目标是找到验证集上误差最小的一组超参数。</p>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-为何学习率那么重要">1. 为何学习率那么重要？</span></h3><p>当模型训练到一定程度后， 损失将不再减少，这个时候模型的一阶梯度接近于0，此时的Hessian 矩阵通常是两种情况：</p>
<ul>
<li>正定，即所有特征值均为正，此时通常可以得到一个局部极小值，若这个局部极小值接近全局最小则模型已经能得到不错  的性能了，但若差距很大，则模型性能还有待于提升，通常情况下后者在训练初最常见。</li>
<li>特征值有正有负，此时模型很可能陷入了鞍点，若陷入鞍点，模型性能表现就很差。</li>
</ul>
<h3><span id="2-卷积核尺寸为何都是奇数">2. 卷积核尺寸为何都是奇数？</span></h3><ul>
<li>保证像素点中心位置，避免位置信息偏移</li>
<li>填充边缘时能保证两边都能填充，原矩阵依然对称</li>
</ul>
<h3><span id="3-深层网络为何难以训练">3. 深层网络为何难以训练</span></h3><ul>
<li>梯度消失， 梯度爆炸问题</li>
</ul>
<h3><span id="4-神经网络为何要做深">4. 神经网络为何要做深？</span></h3><ul>
<li>神经元数量相同的情况下，深层网络比浅层网络具有更大容量和表达空间。</li>
<li>隐藏层增加意味着由激活函数带来的非线性变换的嵌套层数更多，就能构造更复杂的映射关系。</li>
</ul>
<h3><span id="5-调节-batch_size-对训练效果影响如何">5. 调节 batch_size 对训练效果影响如何？</span></h3><ul>
<li>Batch_size 太小，模型表现效果极其糟糕(error )</li>
</ul>
<h3><span id="6-合理增加-batch-size-有何好处">6. 合理增加 batch size 有何好处？</span></h3><ul>
<li>内存</li>
<li>利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次 epoch 所需的迭代次数减少，对于相同数据量的处理速度进一步加快。</li>
<li>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</li>
</ul>
<h3><span id="7-盲目增大-batch_size-有何坏处">7. 盲目增大 Batch_Size 有何坏处？</span></h3><ul>
<li>内存，显存容量可能撑不住</li>
<li>跑完一次 epoch 所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。</li>
<li>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>迁移学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#迁移学习">迁移学习</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="迁移学习">迁移学习</span></h1><p><img data-src="./image/trans_learning_1.jpeg" alt></p>
<h2><span id="reference">Reference</span></h2><p><a href="https://www.infoq.cn/article/zD5QkcIzF9253friWPVd">一文看懂自然语言处理中迁移学习的现状</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习基础</tag>
      </tags>
  </entry>
  <entry>
    <title>CRF</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/CRF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#crf-条件随机场">CRF — 条件随机场</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="crf-条件随机场">CRF — 条件随机场</span></h1><ul>
<li>白板推导系列</li>
<li>数学基础</li>
<li>线性回归</li>
<li>线性分类</li>
<li>降维</li>
<li>支持向量机</li>
<li>核方法</li>
<li>指数族分布</li>
<li>概率图模型</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>jieba分词</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/Jieba%20%E5%88%86%E8%AF%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="jieba-分词">Jieba 分词</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>TF-IDF</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/TF-IDF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="tf-idf">TF-IDF</span></h1><hr>
<!-- toc -->
<ul>
<li><a href="#什么是tf-idf">什么是TF-IDF？</a></li>
<li><a href="#tf-idf">TF-IDF</a></li>
<li><a href="#举例说明">举例说明</a></li>
<li><a href="#优缺点">优缺点</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="什么是tf-idf">什么是TF-IDF？</span></h2><p>TF-IDF是一种用于信息检索与数据挖掘的常用加权技术，常用于挖掘文章中的关键词，而且算法简单高效，常被工业用于最开始的文本数据清洗。</p>
<h2><span id="tf-idf">TF-IDF</span></h2><p><strong>一个词语在一篇文章中出现次数越多, 同时在所有文档中出现次数越少, 越能够代表该文章.</strong></p>
<ul>
<li><p><strong>TF:</strong> Term Frequency, 表示词频。 一个给定的词在该文章中出现的次数。</p>
<script type="math/tex; mode=display">
TF = \frac{\text{某个词在文章中的出现次数}}{\text{文章的总词数}}  \\</script></li>
<li><p><strong>IDF:</strong> Inverse Document Frequency, 表示逆文档频率。如果包含词条 t 的文档越少, IDF越大，则说明词条具有很好的类别区分能力。</p>
</li>
</ul>
<script type="math/tex; mode=display">
IDF = log(\frac{语料库的文档总数}{包含该词的文档数+1})  \\</script><ul>
<li><strong>TF-IDF：</strong>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语<script type="math/tex; mode=display">
\text{TF-IDF} = TF \times IDF</script></li>
</ul>
<h2><span id="举例说明">举例说明</span></h2><p>假设现在有一篇文章， 文章中包含 10000 个词组， 其中，”贵州” 出现100次，”的” 出现500次，那么我们可以计算得到这几个词的 TF(词频) 值：</p>
<script type="math/tex; mode=display">
TF(贵州) = 100 / 10000 = 0.01 \\
TF(的) = 500 / 10000 = 0.05</script><p>现在语料库中有 1000 篇文章， 其中，包含 “贵州” 的有 99 篇， 包含 “的” 的有 899 篇， 则它们的 IDF 值计算为：</p>
<script type="math/tex; mode=display">
IDF(贵州) = log(1000 / (99+1)) = 1.000 \\
IDF(的) = log(1000 / (899+1)) = 0.046</script><h2><span id="优缺点">优缺点</span></h2><ul>
<li>优点简单快速，而且容易理解。</li>
<li>缺点是有时候用词频来衡量文章中的一个词的重要性不够全面，有时候重要的词出现的可能不够多，而且这种计算无法体现位置信息，无法体现词在上下文的重要性。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>个人书单</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%AA%E4%BA%BA%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#人工智能顶会">人工智能顶会</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="人工智能顶会">人工智能顶会</span></h1><ul>
<li>IJCAI (1+): AI最好的综合性会议，难度很大</li>
<li>AAAI (1): 美国人工智能学会AAAI的年会.</li>
<li>COLT (1): 这是计算学习理论最好的会议,</li>
<li>CVPR (1): 计算机视觉和模式识别方面最好的会议之一</li>
<li>ICCV (1): 介绍CVPR的时候说过了, 计算机视觉方面最好的会之一.</li>
<li>ICML (1): 机器学习方面最好的会议之一</li>
<li>NIPS (1): 神经计算方面最好的会议之一</li>
<li>ACL (1-): 计算语言学/自然语言处理方面最好的会议</li>
<li>KR (1-): 知识表示和推理方面最好的会议之一, </li>
<li>SIGIR (1-): 信息检索方面最好的会议, ACM主办</li>
<li>SIGKDD (1-): 数据挖掘方面最好的会议</li>
<li>ECCV (2+): 计算机视觉方面仅次于ICCV的会议</li>
<li>ECML (2+): 机器学习方面仅次于ICML的会议</li>
<li>ICDM (2+): 数据挖掘方面仅次于SIGKDD的会议, 目前和SDM相当</li>
<li>SDM (2+): 数据挖掘方面仅次于SIGKDD的会议, 目前和ICDM相当</li>
<li>COLLING (2): 计算语言学/自然语言处理方面仅次于ACL的会, 但与ACL的差距比<br>ICCV-ECCV和ICML-ECML大得多.</li>
<li>ECAI (2): 欧洲的人工智能综合型会议, 历史很久, 但因为有IJCAI/AAAI压着,<br>很难往上升.</li>
<li>EMNLP (2-): 计算语言学/自然语言处理方面一个不错的会. 有些人认为与COLLING<br>相当, 但我觉得它还是要弱一点.</li>
<li>PKDD (2-): 欧洲的数据挖掘会议, 目前在数据挖掘会议里面排第4</li>
<li>ACCV (3+): 亚洲的计算机视觉会议</li>
<li>ECIR (3+): 欧洲的信息检索会议</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>主题模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="主题模型">主题模型</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>概率图模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="概率图模型">概率图模型</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>统计语言模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理综述</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#自然语言处理综述">自然语言处理综述</a><ul>
<li><a href="#1-任务概览">1. 任务概览</a></li>
<li><a href="#2-自然语言处理的几个层次">2. 自然语言处理的几个层次</a></li>
<li><a href="#3-自然语言处理中的困难">3. 自然语言处理中的困难</a></li>
<li><a href="#4-基本方法">4. 基本方法</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="自然语言处理综述">自然语言处理综述</span></h1><p><a href="https://zhuanlan.zhihu.com/p/40760991">https://zhuanlan.zhihu.com/p/40760991</a></p>
<h2><span id="1-任务概览">1. 任务概览</span></h2><ul>
<li>机器翻译</li>
<li>自动文摘</li>
<li>信息检索</li>
<li>文档分类</li>
<li>问答系统</li>
<li>信息过滤</li>
<li>信息抽取</li>
<li>文本挖掘</li>
<li>舆情分析</li>
<li>文字编辑和自动校对</li>
<li>作文自动评分</li>
<li>OCR</li>
<li><strong>语音识别</strong></li>
<li><strong>语音合成</strong></li>
<li><strong>说话人识别</strong></li>
</ul>
<h2><span id="2-自然语言处理的几个层次">2. 自然语言处理的几个层次</span></h2><ul>
<li>形态学：研究词的内部结构，包括屈折变化和构词法两个部分。</li>
<li>语法学：研究句子结构成分之间的相互关系和组成句子序列的规则。</li>
<li>语义学：语言的各级单位：词素，词，词组，句子，句子群，整段整篇的话语和文章的意义。</li>
<li>语用学：从使用者的角度研究语言。</li>
</ul>
<h2><span id="3-自然语言处理中的困难">3. 自然语言处理中的困难</span></h2><p>两大基本问题： <strong>歧义消解问题</strong>（词，句） 以及 <strong>未知语言现象问题</strong>（未知词汇，未知结构）。</p>
<h2><span id="4-基本方法">4. 基本方法</span></h2><ul>
<li>经验主义：主张通过建立特定的数学模型来学习复杂的，广泛的语言结构，然后利用统计学，模式识别和机器学习等方法来训练模型参数。</li>
<li>理性主义：主张建立符号处理系统，由人工整理和编写初始的语言知识表示体系（规则）来构造相应的推理程序。最常见的如词法解析器，句法分析器。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>词袋模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/6-%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="词袋模型">词袋模型</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>统计自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP中的迁移学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/NLP%20%E4%B8%AD%E7%9A%84%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#nlp中的迁移学习">NLP中的迁移学习</a><ul>
<li><a href="#1-为何nlp中要引入迁移学习">1. 为何NLP中要引入迁移学习</a></li>
<li><a href="#2-迁移学习的类型">2. 迁移学习的类型</a></li>
<li><a href="#3-sequential-transfer-learning">3. Sequential transfer learning</a><ul>
<li><a href="#1-为何选择语言模型作为预训练阶段的任务">1. 为何选择语言模型作为预训练阶段的任务？</a></li>
<li><a href="#2-nlp中迁移学习演变">2. NLP中迁移学习演变</a></li>
<li><a href="#3-为何语言模型表现极佳">3. 为何语言模型表现极佳</a></li>
<li><a href="#4-数据越多模型越大越好吗">4. 数据越多，模型越大越好吗</a></li>
<li><a href="#5-跨语言预训练语言模型">5. 跨语言预训练语言模型</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="nlp中的迁移学习">NLP中的迁移学习</span></h1><p>tags：笔记</p>
<hr>
<h2><span id="1-为何nlp中要引入迁移学习">1. 为何NLP中要引入迁移学习</span></h2><ul>
<li>大多数NLP任务都共享语言信息</li>
<li>标注数据很稀少</li>
<li>经验上，迁移学习能帮助许多NLP任务获得SOTA效果</li>
</ul>
<h2><span id="2-迁移学习的类型">2. 迁移学习的类型</span></h2><p><img data-src="..\img\迁移学习\1.png" alt="1"></p>
<h2><span id="3-sequential-transfer-learning">3. Sequential transfer learning</span></h2><p>Learn on one task / dataset, then transfer to another task / dataset</p>
<h3><span id="1-为何选择语言模型作为预训练阶段的任务">1. 为何选择语言模型作为预训练阶段的任务？</span></h3><p>对于预训练阶段的任务来说，要求一点：数据量大且质量高。对比图像而言，图像中具有十分庞大的分类图像数据集ImageNet，而对于自然语言领域来说，缺乏大规模的有监督学习数据，这是选择语言模型作为预训练阶段的任务的重要因素。此外，分布式假设：You shall know a word by the company it keeps， 为语言模型作为预训练阶段任务奠定了理论基础。</p>
<p>总的来说，语言模型有三大优势：</p>
<ul>
<li>不需要人类打标签</li>
<li>大多数语言都有着大量的文本内容来训练模型</li>
<li>能够学习到句子的表示与单词的表示</li>
</ul>
<h3><span id="2-nlp中迁移学习演变">2. NLP中迁移学习演变</span></h3><p>迁移学习最初在NLP中是以词向量的方式出现的，它将NLP带入到分布式表示时代，而词向量有一个很大的缺陷：它无法解决词的多多义性问题。于是研究人员开始研究，如何采用句子级别的向量来解决这种多义性问题。直至现在，无论是ELMO还是BERT都通过深层模型解决了这一问题，即词在上下文中向量的表示。至此，预训练语言模型真正成为主流。</p>
<p>在解决多义性问题上，迁移学习的演变本质上是采用深度模型来取代浅层模型的过程。</p>
<h3><span id="3-为何语言模型表现极佳">3. 为何语言模型表现极佳</span></h3><ul>
<li>对于人类来说，语言模型是一个十分困难的任务</li>
<li>Language models are expected to compress any possible context into a vector that generalizes over possible<br>completions.</li>
<li>To have any chance at solving this task, a model is forced to learn syntax, semantics, encode facts about the world, etc.</li>
<li>Given enough data, a huge model,and enough compute, can do a reasonable job!</li>
<li>Empirically works better than translation, autoencoding: “Language Modeling Teaches You More Syntax than<br>Translation Does” </li>
</ul>
<h3><span id="4-数据越多模型越大越好吗">4. 数据越多，模型越大越好吗</span></h3><h3><span id="5-跨语言预训练语言模型">5. 跨语言预训练语言模型</span></h3><ul>
<li>核心思想：Share vocabulary and representations across languages by training one model on many languages</li>
<li>优点：: Easy to implement, enables cross-lingual pretraining by itself</li>
<li>缺点：Leads to under-representation of low-resource languages</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>一文缕清对比学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%80%E6%96%87%E6%BB%A4%E6%B8%85%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#一文滤清对比学习">一文滤清对比学习</a><ul>
<li><a href="#什么是对比学习">什么是对比学习</a></li>
<li><a href="#对比学习最重要的事情搞数据">对比学习最重要的事情：搞数据</a><ul>
<li><a href="#自监督">自监督</a></li>
<li><a href="#监督">监督</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="一文滤清对比学习">一文滤清对比学习</span></h1><h2><span id="什么是对比学习">什么是对比学习</span></h2><h2><span id="对比学习最重要的事情搞数据">对比学习最重要的事情：搞数据</span></h2><h3><span id="自监督">自监督</span></h3><h3><span id="监督">监督</span></h3>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>文本纠错</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#文本纠错">文本纠错</a><ul>
<li><a href="#1-百度开放平台纠错">1. 百度开放平台纠错</a></li>
<li><a href="#2-给予深度学习的中文纠错">2. 给予深度学习的中文纠错</a></li>
<li><a href="#3-其他纠错方案">3. 其他纠错方案</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="文本纠错">文本纠错</span></h1><p><a href="https://zhuanlan.zhihu.com/p/82807092">https://zhuanlan.zhihu.com/p/82807092</a></p>
<p><a href="https://mp.weixin.qq.com/s/JyXN9eukS-5XKvcJORTobg">https://mp.weixin.qq.com/s/JyXN9eukS-5XKvcJORTobg</a></p>
<h2><span id="1-百度开放平台纠错">1.  百度开放平台纠错</span></h2><p><a href="https://ai.baidu.com/tech/nlp_apply/text_corrector">https://ai.baidu.com/tech/nlp_apply/text_corrector</a></p>
<h2><span id="2-给予深度学习的中文纠错">2. 给予深度学习的中文纠错</span></h2><ul>
<li>kenlm：kenlm统计语言模型工具</li>
<li>rnn_lm：TensorFlow、PaddlePaddle均有实现栈式双向LSTM的语言模型</li>
<li>rnn_attention模型：参考Stanford University的nlc模型，该模型是参加2014英文文本纠错比赛并取得第一名的方法</li>
<li>rnn_crf模型：参考阿里巴巴2016参赛中文语法纠错比赛CGED2018并取得第一名的方法</li>
<li>seq2seq_attention模型：在seq2seq模型加上attention机制，对于长文本效果更好，模型更容易收敛，但容易过拟合</li>
<li>transformer模型：全attention的结构代替了lstm用于解决sequence to sequence问题，语义特征提取效果更好</li>
<li>bert模型：中文fine-tuned模型，使用MASK特征纠正错字</li>
<li>conv_seq2seq模型：基于Facebook出品的fairseq，北京语言大学团队改进ConvS2S模型用于中文纠错，在NLPCC-2018的中文语法纠错比赛中，是唯一使用单模型并取得第三名的成绩</li>
</ul>
<p>基于深度学习（如bert模型）进行纠正，对于句子级别的纠错有效。但是对于单词纠错，效果较差。</p>
<h2><span id="3-其他纠错方案">3. 其他纠错方案</span></h2><p>1.工具利用的是pycorrector，对同音字纠正，效果较好。同形不行</p>
<p>2.基于编辑距离来纠正，对于同音字纠正，效果较好。同形不行</p>
<p>3.基于字形编码对于同形字进行纠正，需要有详细的字形编码库.建立近形字库。</p>
<p>4.基于通用词库来完成纠正。目前基于已有的词库（800多万个词条），进行纠正。效果还行，但是不一定能覆盖专有名称，特别是商品名称。</p>
<p>5.利用商品名称库来完成纠正。对于购物小票，效果较好，其他票据目前效果不好。</p>
<p>6.金额纠正，将金额进行加总比对，以此对金额进行纠错。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>信息抽取</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>模型可视化</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#模型可视化">模型可视化</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="模型可视化">模型可视化</span></h1><p><a href="https://github.com/shobrook/communities">https://github.com/shobrook/communities</a></p>
<p><a href="https://github.com/bhoov/exbert">https://github.com/bhoov/exbert</a></p>
<p><a href="https://github.com/jessevig/bertviz">https://github.com/jessevig/bertviz</a></p>
<p><a href="https://www.jianshu.com/p/df7906a2a28e">https://www.jianshu.com/p/df7906a2a28e</a></p>
<p><a href="https://jalammar.github.io/">https://jalammar.github.io/</a></p>
<p><a href="https://github.com/jalammar/ecco">https://github.com/jalammar/ecco</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>模型可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>那些年我看过的综述文章</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E9%82%A3%E4%BA%9B%E5%B9%B4%E6%88%91%E7%9C%8B%E8%BF%87%E7%9A%84%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#那些年我看过的综述文章">那些年我看过的综述文章</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="那些年我看过的综述文章">那些年我看过的综述文章</span></h1><p><strong>A Survey of Transformers</strong></p>
<p><strong>The NLP Cookbook: Modern Recipes for Transformer based Deep Learning Architectures</strong></p>
<p><strong>Pretrained Language Models for Text Generation: A Survey</strong></p>
<p><strong>A Practical Survey on Faster and Lighter Transformers</strong></p>
<p><strong>Efficient Transformers: A Survey</strong></p>
<p><strong>A Survey on Visual Transformer</strong></p>
<p><strong>A Comprehensive Survey on Graph Neural Networks</strong></p>
<p><strong>Graph Neural Networks for Natural Language Processing: A Survey</strong></p>
<p><strong>A Survey of Data Augmentation Approaches for NLP</strong></p>
<p><strong>An Overview of Multi-Task Learning in Deep Neural Networks</strong></p>
<p><strong>Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better</strong></p>
<p><strong>Requirement Engineering Challenges for AI-intense Systems Development</strong></p>
<p><strong>Technology Readiness Levels for Machine Learning Systems</strong></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐类文章</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/8-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%A8%E8%8D%90%E7%B1%BB%E6%96%87%E7%AB%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#推荐类文章">推荐类文章</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="推荐类文章">推荐类文章</span></h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247506213&amp;idx=3&amp;sn=c11d20bf5d2fbd2c2acf17c50ac039b7&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247506213&amp;idx=3&amp;sn=c11d20bf5d2fbd2c2acf17c50ac039b7&amp;scene=21#wechat_redirect</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1476164">https://cloud.tencent.com/developer/article/1476164</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>tiny-dnn整体结构</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/11-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/tiny-dnn/tiny-dnn%20%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="参考">参考</span></h2><p><a href="https://blog.csdn.net/u013088062/column/info/tiny-cnn">https://blog.csdn.net/u013088062/column/info/tiny-cnn</a></p>
<p><a href="https://blog.csdn.net/luoluonuoyasuolong/article/details/79237708">https://blog.csdn.net/luoluonuoyasuolong/article/details/79237708</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>Bert是如何分成的</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/11-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/transformers/%E8%A7%A3%E8%AF%BB%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%20-%20BERT%20%E6%98%AF%E5%A6%82%E4%BD%95%E5%88%86%E8%AF%8D%E7%9A%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="解读源码系列-bert-是如何分词的">解读源码系列 - BERT 是如何分词的</span></h1><p><a href="https://alanlee.fun/2019/10/16/bert-tokenizer/">https://alanlee.fun/2019/10/16/bert-tokenizer/</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP数据增强方法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/0-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/NLP%20%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#nlp-数据增强方法">NLP 数据增强方法</a><ul>
<li><a href="#文本替代">文本替代</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="nlp-数据增强方法">NLP 数据增强方法</span></h1><p><a href="https://zhuanlan.zhihu.com/p/75207641">https://zhuanlan.zhihu.com/p/75207641</a></p>
<p><a href="https://www.qbitai.com/2020/06/16103.html">https://www.qbitai.com/2020/06/16103.html</a></p>
<p><a href="https://www.dataapplab.com/enhance-nlp-what-are-the-easiest-use-augmentation-techniques/">https://www.dataapplab.com/enhance-nlp-what-are-the-easiest-use-augmentation-techniques/</a></p>
<h2><span id="文本替代">文本替代</span></h2><ul>
<li>同义词替代：</li>
<li>词嵌入替换： 采用嵌入空间中最近的邻接词作为句子中某些单词的替换</li>
<li>掩码语言模型：通过bert等这种MLM模型来预测被mask掉的词来做替换，需要注意的是决定哪一个单词被mask是比较重要的</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>数据预处理</tag>
      </tags>
  </entry>
  <entry>
    <title>文本数据预处理</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/0-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#文本数据预处理">文本数据预处理</a><ul>
<li><a href="#1-oov-out-of-vocabulary-words">1. OOV  - out of vocabulary words</a></li>
<li><a href="#2-数据增强">2. 数据增强</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="文本数据预处理">文本数据预处理</span></h1><hr>
<h2><span id="1-oov-out-of-vocabulary-words">1. OOV  - out of vocabulary words</span></h2><ul>
<li>采用细粒度的表示 +  粗粒度的表示融合：彻底消灭所有 OOV </li>
<li>Wordpiece Model： 无法彻底解决OOV</li>
<li><code>&lt;UNK&gt;</code>处理</li>
<li>扩大词表</li>
</ul>
<h2><span id="2-数据增强">2. 数据增强</span></h2>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>数据预处理</tag>
      </tags>
  </entry>
  <entry>
    <title>词向量</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/1-%E8%AF%8D%E5%90%91%E9%87%8F/%E8%AF%8D%E5%90%91%E9%87%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="词向量">词向量</span></h1><hr>
<p><a href="https://zhuanlan.zhihu.com/p/29364112">https://zhuanlan.zhihu.com/p/29364112</a></p>
<h2><span id="word2vec3">Word2Vec[3]</span></h2><p>Word2Vec是Google发布的一个工具， 用于训练词向量，其提供了两种语言模型来供选择， 且Google 基于大规模语料集上训练出了预训练词向量来供开发者或研究者使用。 一般情况下，我们是没有必要自己去训练词向量的，但如果要求特殊，且语料集庞大，自己训练也是可以的。</p>
<p>在Word2Vec中，实现了两个模型：<strong>CBOW</strong> 与 <strong>Skip-Gram</strong>。</p>
<h3><span id="1-cbow模型">1. CBOW模型</span></h3><p>CBOW，全称Continuous Bag-of-Word，中文叫做连续词袋模型：<strong>以上下文来预测当前词</strong> $w_t$ 。</p>
<p><img data-src="https://pic4.zhimg.com/v2-27f3e577618f84c0026968d273d823ef_b.jpg" alt="img"></p>
<p>如上图是一个两层的神经网络，其实在训练语言模型的过程中考虑到效率等问题，常常采用浅层的神经网络来训练，并取第一层的参数如上图就是 $W_{V \times N}$ 来作为最终的词向量矩阵（参考 <a href="https://zhuanlan.zhihu.com/p/43453548">语言模型：从n元模型到NNLM</a>）。</p>
<p>CBOW模型的目的是预测 $P(w<em>t| w</em>{t-k}, \cdots, w<em>{t-1}, w</em>{t+1}, \cdots, w_{t+k}) $，我们先来走一遍CBOW的前向传播过程 。</p>
<h4><span id="1-前向传播过程">1. 前向传播过程</span></h4><ul>
<li><p>输入层: 输入C个单词： $x<em>{1k}, \cdots, x</em>{Ck} $，并且每个 $x$ 都是用 One-hot 编码表示，每一个 $x$ 的维度为 V（词表长度）。</p>
</li>
<li><p>输入层到隐层:  共享矩阵为 $W_{V \times N}$ ，V表示词表长度，W的每一行表示的就是一个N维的向量（训练结束后，W的每一行就表示一个词的词向量）。在隐藏层中，我们的所有输入的词转化为对应词向量，然后取平均值，这样我们就得到了隐层输出值 ( 注意，隐层中无激活函数，也就是说这里是线性组合)。 其中，隐层输出 $h$ 是一个N维的向量 。</p>
<script type="math/tex; mode=display">
h = \frac{1}{C} W^T(x_1 + x_2 + \cdots + x_c)</script></li>
<li><p>隐层到输出层：隐层的输出为N维向量 $h$ ， 隐层到输出层的权重矩阵为  $W’_{N \times V}$ 。然后，通过矩阵运算我们得到一个 $V \times 1 $ 维向量</p>
<script type="math/tex; mode=display">
u = W'^{T} * h</script></li>
</ul>
<p>其中，向量 $u$  的第 $i$  行表示词汇表中第 $i$  个词的可能性，然后我们的目的就是取可能性最高的那个词。因此，在最后的输出层是一个softmax 层获取分数最高的词，那么就有我们的最终输出：</p>
<script type="math/tex; mode=display">
P(w_j| context)  =y_i =  \frac{exp({u_j})}{\sum_{k \in V} exp({u_k})}</script><h4><span id="2-损失函数">2. 损失函数</span></h4><p>我们假定 $j^*$ 是真实单词在词汇表中的下标，那么根据极大似然法，则目标函数定义如下：</p>
<script type="math/tex; mode=display">
E = -log \, p(W_O |W_I) = -log \, \frac{exp({u_j})}{\sum_{k \in V} exp({u_k})} =  log  \, \sum_{k \in V} exp(u_{k})  -u_j</script><h3><span id="2-skip-gram模型">2. Skip-gram模型</span></h3><p>Skip-Gram的基本思想是：已知当前词 $w<em>t$ 的前提下，预测其上下文 $w</em>{t-i}, \cdots , w_{t+i}$ ，模型如下图所示：</p>
<p><img data-src="https://pic2.zhimg.com/v2-42ef75691c18a03cfda4fa85a8409e19_b.jpg" alt="img"></p>
<h4><span id="1-前向传播过程">1. 前向传播过程：</span></h4><ul>
<li>输入层：   输入的是一个单词，其表示形式为 <strong>One-hot</strong> ，我们将其表示为V维向量 $x<em>k$ ，其中 $V$ 为词表大小。然后，通过词向量矩阵 $W</em>{V \times N}$ 我们得到一个N维向量  <script type="math/tex; mode=display">
h = W^T * x_k = v^{T}_{w_I}</script></li>
</ul>
<ul>
<li><p>隐层： 而隐层中没有激活函数，也就是说输入=输出，因此隐藏的输出也是 $h$ 。</p>
</li>
<li><p>隐层到输出层：</p>
<blockquote>
<ul>
<li>首先，因为要输出C个单词，因此我们此时的输出有C个分布： $y_1, \cdots y_C $，且每个分布都是独立的，我们需要单独计算， 其中 $y_i$  表示窗口的第 $i$  个单词的分布。 </li>
<li>其次， 因为矩阵 $W’<em>{N \times V}$ 是共享的，因此我们得到的 $V \times 1$ 维向量 $u$ 其实是相同的，也就是有 $u</em>{c,j} = u_j$ ，这里 $u$ 的每一行同 CBOW 中一样，表示的也是评分。</li>
<li>最后，每个分布都经过一个 softmax 层，不同于 CBOW，我们此处产生的是第 $i$ 个单词的分布（共有C个单词），如下：</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
  P(w_{i,j}| context)  =y_i =  \frac{exp({u_j})}{\sum_{k \in V} exp({u_k})}</script></li>
</ul>
<h4><span id="2-损失函数">2. 损失函数</span></h4><p>假设 $j^*$ 是真实单词在词汇表中的下标，那么根据极大似然法，则目标函数定义如下：</p>
<script type="math/tex; mode=display">
\begin{split} E &= - log \, p(w_1, w_2, \cdots, w_C | w_I)   \\ &= - log \prod_{c=1}^C P(w_c|w_i) \\ &= - log  \prod_{c=1}^{C} \frac{exp(u_{c, j})}{\sum_{k=1}^{V} exp(u_{c,k}) } \\ &= - \sum_{c=1}^C u_{j^*_c} + C \cdot log \sum_{k=1}^{V} exp(u_k) \end{split}</script><h3><span id="3-模型复杂度">3. 模型复杂度</span></h3><p>本节中我们来分析一下模型训练时的复杂度，无论是在CBOW还是Skip-Gram模型中，都需要学习两个词向量矩阵： $W, W’$ 。</p>
<p>对于矩阵 $W$ ， 从前向传播中可以看到， 可以看到对于每一个样本(或mini-batch)，CBOW更新 $W$  的 C 行（h与C个x相关）， 而Skip-Gram 更新W中的其中一行（h与1个x相关），这点训练量并不算大。</p>
<p>对于 $W’$  而言， 无论是 CBOW 还是 Skip-Gram 模型，每个训练样本(mini-batch)都更新 $W’$ 的所有 $V \times N$ 个元素。</p>
<p>在现实中，用于语言模型训练的数据集通常都很大，此外词表也是巨大的，这就导致对于 $W’$ 的更新所花费的计算成本是很大的，真的是验证了一个道理：穷逼必要搞语言模型。</p>
<p>为了解决优化起来速度太慢的问题， Word2Vec 中提供了两种策略来对这方面进行优化。</p>
<h3><span id="4-hierarchical-softmax">4. Hierarchical Softmax</span></h3><p>HS 基于哈夫曼树将计算量大的部分转化为一种二分类问题。</p>
<p><img data-src="image\hs.png" alt="hs"></p>
<p>原先的模型中，模型再隐层之后通过 $W’$ 连接输出层，现在 HS 则去掉了 $W’$ , 隐层向量 <strong>h</strong> 直接与上图的二叉树的 root 节点相连， 图中的每一个分支都代表一个选择。 上图中白色的叶子节点表示词表中所有的$|V|$个词， 黑色节点表示非叶子节点， 每一个叶子节点（单词）都对应一条从 root 节点出发的路径，而问题就转化为了使得 $w=w_o$ 这条路径的概率最大， 即：$P(w=w+O|w_I)$ 最大。</p>
<p>用 $n(w,j)$ 表示从 root 到叶子节点 w 的路径上的第 j 个非叶子节点, 并且每个非叶子节点都对应一个向量$v_{n(w,j)}′$, 维度与h 相同, 然后使用一个sigmod函数: $σ(x)=\frac{1}{1+exp(−x)}∈[0,1]$ ，结合向量的内积, 来判断该向左还是向右，那么第 n 个节点向左以及向右的概率分别为：</p>
<script type="math/tex; mode=display">
P(n,left) = \sigma(v_w' \cdot h) \\
P(n, right) = 1 - \sigma(v_w' \cdot h)</script><p>那么就有：</p>
<script type="math/tex; mode=display">
P(w=w_O|W_I) = \prod_{j=1}^{L(w)-1} P(\sigma(I(n(w, j+1 == left) v_w' \cdot h))</script><ul>
<li>$I()$ ：指示函数，条件成立值为1， 反之为 -1</li>
<li>$L(w)$ ：表示整条路径的长度</li>
</ul>
<p>这样我们就能够通过训练来更新每个非叶子节点的参数 $v_w’$了。举例来说，图上加黑的黑色路径： $(n(w_2,1),n(w_2,2),n(w_2,3),w2$， 对于一个训练样本，我们要使得 $P(w_O=w_2|w_I)$  概率最大：</p>
<script type="math/tex; mode=display">
P(w_2=w_O) = P(n(w_2, 1), left) \cdot P(n(w_2, 2), left) \cdot P(n(w_2, 3), right)</script><p>且需要注意的时，再一个非叶子节点处， 向左向右的概率和为1， 因此一直分裂下去，最后的和肯定还是1， 因此可以得出：</p>
<script type="math/tex; mode=display">
\sum_{j=1}^V P(w_j = w_O) = 1</script><p>损失函数同样为最大似然：</p>
<script type="math/tex; mode=display">
E = -log P(w = w_O | w_I) = -\sum_{j=1}^{L(w) -1} log \sigma([I] v_j'^Th)</script><p>通过 HS， 隐层到输出层的计算量从 $O(V)$ 降到了 $O(logV)$。</p>
<h3><span id="2-negative-sampling-负采样">2. Negative Sampling — 负采样</span></h3><p>在 Word2Vec 中， 对于输出层来说，我每一个输出节点都要预测词表中所有词在当前位置的概率，在动辄几万甚至几十万大的词表中，用softmax 计算真的十分困难。 </p>
<p>但我们的目的不在于训练一个精准的语言模型，而只是为了训练得到语言模型的副产物-词向量，那么我们可不可以把输出压缩呢，将几万的输出压缩到几十程度，这计算量是成几何倍数的下降。</p>
<p>负采样的思路很简单，<strong>不直接让模型从整个词表中找最可能的词，而是直接给定这个词（正例）和几个随机采样的噪声词（负例），然后模型能够从这几个词中找到正确的词，就算达到目的了。</strong></p>
<p>那么如何对负例进行采样呢？作者直接使用<strong>基于词频的权重分布</strong>来获得概率分布进行抽样：</p>
<script type="math/tex; mode=display">
weight(w) = \frac{count(w)^{0.75}}{\sum_u count(w)^{0.75}}</script><p>相比于直接使用频次作为权重， 取0.75幂的好处可以减弱不同频次差异过大带来的影响，使得小频次的单词被采样的概率变大。</p>
<p>此时的损失函数为：</p>
<script type="math/tex; mode=display">
E = - log \sigma(v_{w_O}' h) - \sum_{w_j \in W_{neg}} log \sigma(-v_{w_j}'h)</script><h2><span id="glove">Glove []</span></h2><h2><span id="questions">Questions</span></h2><h2><span id="reference-papers">Reference Papers</span></h2><p>[1] Mikolov, T.(2013). Distributed Representations of Words and Phrases and their Compositionality.</p>
<p>[2] Mikolov, T.(2013). Efficient Estimation of Word Representations in Vector Space.</p>
<p>[3] Rong, X. (2014). word2vec Parameter Learning Explained.</p>
<p>[4] GloVe: Global Vectors for Word Representation</p>
<p>[5] Enriching Word Vectors with Subword Information</p>
<p>[6] Bag of Tricks for Efficient Text Classification</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>词向量</tag>
      </tags>
  </entry>
  <entry>
    <title>词向量与语言模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/1-%E8%AF%8D%E5%90%91%E9%87%8F/%E8%AF%8D%E5%90%91%E9%87%8F%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="词向量与语言模型">词向量与语言模型</span></h1><h2><span id="1-语言模型基础与词向量">1. 语言模型基础与词向量</span></h2><p>语言模型可以简单理解为<strong>一个句子 s 在所有句子中出现的概率分布 P(s)</strong>。比如一个语料库中有100 个句子，『OK』这个句子出现了5次， 那么 $p(OK) = 5\%$。</p>
<p>那么，如何学习到这种概率分布呢？ 最简单的方法是建立一个无比庞大的语料库，该语料库中包含了人类成百上千年间可能讲过的所有的话，那么我们不就可以算出这句话出现的概率了吗。可惜此方法不现实。 </p>
<p>那么，能不能通过数学的方法进行表示呢？答案是可以滴，因为 S 是一个序列 $w_1, w_2 , \cdots ,w_n$，那么$p(s)$可以展开为：</p>
<script type="math/tex; mode=display">
p(s) = P(w_1, w_2, \cdots, w_n) = P(w_1) \cdot P(w_2|w_1) \cdot P(w_3|w_1,w_2) \cdots P(w_n|w_1, w_2, \cdots, w_{n-1})</script><p>那么现在的问题就变成了我们如何计算 $P(w_1, w_2, \cdots, w_n) $</p>
<h3><span id="统计方法-n元模型">统计方法 - n元模型</span></h3><p>回忆概率论：</p>
<script type="math/tex; mode=display">
P(A|B) = \frac{AB}{B}</script><p>我们观察上式，会发现， $P(w<em>1)$ 比较好算， $P(w_2|w_1) = \frac{w_1w_2}{w_1}$  也还ok， $P(w_3|w_1,w_2)$ 就比较有难度了，随着n的增大，计算会越来越难， $P(w_n|w_1, w_2, \cdots, w</em>{n-1})$ 几乎根本不可能估算出来。怎么办？</p>
<p><strong>马尔可夫假设：</strong>假设任意一个词 $w<em>i$  出现的概率只同它前面的n个词 $(w</em>{i-1}, \cdots, w_{i-n})$ 有关。由此，那么就有：</p>
<script type="math/tex; mode=display">
一元模型：  P(S) = \prod_{i=1}^{l} P(w_i)   \\
二元模型：P(S) = \prod_{i=1}^{l} P(w_i|w_{i-1})</script><p>缺陷： </p>
<ol>
<li>无法建模更远的关系，语料的不足使得无法训练更高阶的语言模型。</li>
<li>无法建模出词之间的相似度。</li>
<li>训练语料里面有些 n 元组没有出现过,其对应的条件概率就是 0,导致计算一整句话的概率为 0。解决这个问题有两种常用方法： 平滑法和回退法。</li>
</ol>
<h3><span id="深度学习方法-神经网络语言模型1">深度学习方法 - 神经网络语言模型[1]</span></h3><p>首先，我们回到问题本身，我们为什么要计算 $p(s)$， 我们的目的是为了通过大规模语料库学习到语言内部的概率分布。那么有没有办法通过深度学习的方式来学习到这种概率分布呢？</p>
<p><img data-src="https://pic3.zhimg.com/v2-a58e75cd7fcca491713d8601924d3d46_b.png" alt></p>
<p> 观察上图，假设有一组词序列： $w_1, w_2, \cdots, w_t$ ，其中 $w_i \in V$ ， $V$ 是所有单词的集合。我们的输入是一个词序列，而我们的输出是一个概率值，表示根据context预测出下一个词是 $i$ 的概率。用数学来表示，我们最终是要训练一个模型： </p>
<script type="math/tex; mode=display">{s}
P(s) = P(w_t | w_1^{t-1})</script><ul>
<li>$w<em>t $表示这个词序列中的第 $t$ 个单词， $w</em>{t-n+1}$ 表示输入长度为n的词序列中的第一个单词</li>
<li>$w_1^{t-1}$ 表示从第1个单词到第 $t-1$ 个单词组成的子序列</li>
</ul>
<p>因此我们发现，该模型的每个样本其实计算的是：$p(w<em>n|w_1, \cdots, w</em>{n-1})$</p>
<h3><span id="词向量-表示语言的方式">词向量 - 表示语言的方式</span></h3><p>前面我们通过 NNLM 可以知道，通过语言模型的训练，模型可以学习到语言的概率分布，那么如何将学习到的信息应用到下游任务呢？ 这就是词向量产生的背景，如何用向量来表示语言信息，这里我们简单介绍下 Word2vec[4]。</p>
<p>首先明确一点的是， <strong>词向量是语言模型的副产物</strong>。 怎么理解呢，意思是说，词向量是语言模型训练完成后产生的。</p>
<p>这里我们以word2vec 的 CBOW 训练模型为例：</p>
<p><img data-src="https://pic4.zhimg.com/v2-27f3e577618f84c0026968d273d823ef_b.jpg" alt="img"></p>
<script type="math/tex; mode=display">
h = \frac{1}{C} W^T(x_1 + x_2 + \cdots + x_c) \\
u = W'^{T} * h  \\
P(w_j| context)  =y_i =  \frac{exp({u_j})}{\sum_{k \in V} exp({u_k})}</script><p>通过这样训练完成后，把 $W_{V\times N}$ 保存下来，我们就得到了词向量。</p>
<h2><span id="2-预训练语言模型-用模型表示语言">2. 预训练语言模型 - 用模型表示语言</span></h2><p>前面提到，我们的最终目的还是<strong>通过语言模型来获得某种语言的表示</strong>，但是我们看到，上面那种训练方式，似乎不太合适，那个最后$W_{N\times V}$ 消失不见了，并且模型没有做深。</p>
<p>我们此处总结一下word2vec的弱点：</p>
<ul>
<li>模型无法做深，词向量的表征能力有限，词向量的抽象程度不高</li>
<li>词向量获得的是上下文无关的，难以解决歧义问题上</li>
<li>OV 词无法解决</li>
</ul>
<p>很有意思的是， 相差几个月的时间， ELMO ，GPT， BERT 相继诞生了，都非常具有代表性。 下面会进行分别介绍。</p>
<h3><span id="0-nlp-特点">0. NLP 特点</span></h3><p>在进入预训练语言模型之前，我们先来看看对于NLP来说，最重要的是什么。 </p>
<p>首先是 NLP 的特点：</p>
<ol>
<li><p>输入是一个一维线性序列</p>
</li>
<li><p>输入是不定长的，这点对于模型处理起来会比较麻烦</p>
</li>
<li><p>单词位置与句子位置的相对位置很重要，互换可能导致完全不同的意思</p>
</li>
<li><p>句子中的长距离特征对于理解语义也非常关键。</p>
</li>
</ol>
<p>其次是，NLP 中的几大常见的任务：</p>
<ol>
<li><strong>序列**</strong>标注：** 分词，词性标注，命名实体识别等。 特点是句子中每个单词要求模型根据上下文都要给出一个分类类别</li>
<li><strong>分类任务：</strong> 文本分类， 情感分析。 特点是不管文章有多长，总体给出一个分类类别即可。</li>
<li><strong>句子关系推断：</strong> QA， 自然语言推理。 特点是给定两个句子，模型判断出两个句子是否具备某种语义关系。</li>
<li><strong>生成式任务：</strong>机器翻译， 文本摘要。特点是输入文本内容后，需要自主生成另外一段文字。</li>
</ol>
<p>最后，我们来聊聊三大基本单元： CNN，LSTM，Transformer。</p>
<p>首先先看简单回顾下 Transformer的self-attention 机制，该机制在预训练语言模型中起到了至关重要的作用。我们看到，对于 Transformer 来说，通过self-attention 机制，词与词之间的关系一目了然，并且不会受到文本长度的限制。 然后注意，在 Attention is all you need 这篇文章中，Transformer 是 Encoder-decoder 架构的，这与后面BERT 所用的有所不同，后面BERT 所用的只是 transformer_block。</p>
<p>于是我们总结一下这三个基本单元的优缺点：</p>
<p><strong>RNN：</strong></p>
<ul>
<li>优点：天生的具有时序结构，十分适合解决NLP问题</li>
<li>缺点：<ol>
<li>反向传播时所存在的优化困难问题， 即梯度消失，梯度爆炸问题，进而导致对超长距离依赖的解决不佳</li>
<li>并行能力，进而导致难以做深</li>
</ol>
</li>
</ul>
<p><strong>CNN：</strong></p>
<ul>
<li>优点：<ol>
<li>可以并行，可以做的非常深</li>
<li>能够很好的捕捉 n-gram 特征</li>
</ol>
</li>
<li>缺点：<ol>
<li>无法解决长距离依赖问题</li>
<li>对于位置信息不敏感</li>
</ol>
</li>
</ul>
<p>Transformer：</p>
<ul>
<li>优点：<ol>
<li>self-attention 天生的就解决了长距离依赖问题</li>
<li>可以并行，可以做的非常深</li>
<li>位置信息通过 position embedding 很好的补充了</li>
</ol>
</li>
<li>缺点：<ol>
<li>对于超长文本，会导致非常大的计算复杂度</li>
<li>位置信息依赖于 position embedding</li>
</ol>
</li>
</ul>
<h3><span id="1-elmo">1. ELMO</span></h3><p><img data-src="https://pic4.zhimg.com/v2-78ee0e1d4b79b5e190f4241e2f0d9577_r.jpg" alt></p>
<p>elmo 是通过 L 层的双向LSTM语言模型来学习上下文信息的，这就解决了上文提到的前两个问题，而针对 OV词， ELMO 采用了 char-level 来生成词向量进而进行训练。而对于ELMO 的不同层而言，不同层的 LSTM 能够把握不同粒度和层级的信息，比如浅层的 LSTM 把握的是单词特征， 中层的 LSTM 把握 句法 特征，深层的 LSTM 把握语义特征。</p>
<script type="math/tex; mode=display">
前向语言模型：p(t_1, t_2, \cdots, t_N) = \prod_{k=1}^N p(t_k|t_1, t_2, \cdots, t_{k-1})   \\
后向语言模型：p(t_1, t_2, \cdots, t_N) = \prod_{k=1}^N p(t_k|t_{k+1}, t_{k+2}, \cdots, t_{N})</script><p>但， ELMO 的缺点也十分明显：</p>
<ul>
<li><strong>LSTM 特征抽取能力远弱于 Transformer ， 并行性差</strong></li>
<li><strong>拼接方式双向融合特征融合能力偏弱</strong></li>
<li>层数浅，只有2层</li>
</ul>
<h3><span id="2-bert">2. BERT</span></h3><p>语言模型：</p>
<script type="math/tex; mode=display">
P(s) = P(x_{mask} | context)</script><p>我们先来看模型架构， BERT-base 采用12 层的 Transformer，这里简单提一下，BERT 的架构相当于 Transformer 的Encoder-decoder 架构中的Encoder。</p>
<p>再然后，我们看下，输入的组成部分，输入包含三个部分，分别是 </p>
<ul>
<li>token embedding：词向量，第一个单词是CLS标志，可以用于之后的分类任务</li>
<li>Segment Embeddings：区别两种句子，因为预训练不光做LM还要做以两个句子为输入的分类任务</li>
<li>Position Embeddings：<strong>和之前文章中的Transformer不一样，不是三角函数而是学习出来的</strong></li>
</ul>
<p>最后，我们看下预训练训练任务部分。</p>
<p>首先是 Masked LM：随机遮蔽输入 token 的15%，然后预测被遮住的 token。这样会带来一个问题，即训练与微调阶段的不一致性，因为训练阶段采用了 [MASK] 而 fine-tune 阶段并没有。为了减轻该问题， we do not always replace “masked” words with the actual [MASK] token. 具体做法如下：</p>
<blockquote>
<p> 假如我们有一句话， my dog is hairy ， 被选中的词为hairy，数据生成器并不总是将hairy替换为[MASK]，此时的过程如下：</p>
<ul>
<li>80% 情况下： 用[MASK] 替换 hairy</li>
<li>10% 情况下： 随机选一个词如apple 来替换hairy</li>
<li>10%: 不改变这句话</li>
</ul>
</blockquote>
<p>然后是 NSP，即Next Sentence Prediction，选定一个句子A，B作为预训练样本，B有50%的可能是A的下一句，也有50%的可能是语料库的随机句子。</p>
<h3><span id="2-gpt-10">2. GPT 1.0</span></h3><p>其实GPT 1.0 要比 BERT 出来的早，但是吃了不会宣传的亏啊。首先来看语言模型：</p>
<script type="math/tex; mode=display">
P(s) = P（w_i |w_{i-k}, \cdots, w_{i-1} ）\\
L_1(U) = \sum_i log P(u_i| u_{i-k}, \cdots, u_{i-1}; \Theta); \, \, \text{k为窗口大小}</script><p>跟bert 有很明显的差别，但是符合原来语言模型的的定义。</p>
<p>其次， 模型结构采用单向Transformer， 这是由于语言模型决定的。</p>
<p>第三个是， embedding 不包含 NSP 这种 segment embedding。</p>
<p>说到这里，我们就说完了基础的三个预训练语言模型，接下来我们探讨下如何更好的使用预训练语言模型。</p>
<h2><span id="3-如何使用预训练语言模型">3. 如何使用预训练语言模型</span></h2><h3><span id="1-是否要进行微调1">1. 是否要进行微调[1]</span></h3><p>我们是直接采用训练好的向量还是用预训练语言模型进行微调呢？</p>
<p>『冰』表示freeze， 『火』表示微调的结果。</p>
<p>实际上，对于大多数的任务， BERT 进行微调的方式总是比提取向量再训练的方式能够获得更佳的效果。因此，在条件允许的情况下，推荐采用微调的方式。</p>
<h3><span id="2-是否要进行再次预训练2">2. 是否要进行再次预训练[2]</span></h3><p>答案是需要。</p>
<p>我们知道现在的预训练语料采用的都是百科，书籍等比较规范的数据，而实际业务中的数据千差万别，可以这么理解，预训练本身获得的是语料库中文本的分布，而如果预训练数据分布与业务数据分布偏差较大，会带来一些负面影响。 </p>
<p>因此，针对一些业务，如果数据与百科数据差别非常大，先进行预训练，然后再进行微调是一种比较合适的方式。</p>
<p>我们这里简单介绍下[2] 中的结论</p>
<ol>
<li>在目标领域的数据集上继续预训练（DAPT）可以提升效果；目标领域与语言模型的原始预训练语料越不相关，DAPT效果则提升更明显。</li>
<li>在具体任务的数据集上继续预训练（TAPT）可以十分“廉价”地提升效果。</li>
<li>结合二者（先进行DAPT，再进行TAPT）可以进一步提升效果。</li>
<li>如果能获取更多的、任务相关的无标注数据继续预训练（Curated-TAPT），效果则最佳。</li>
</ol>
<h3><span id="3-bert-向量-vs-glove-向量">3. BERT 向量 vs Glove 向量</span></h3><p>接下来我们分析下 ， BERT 相对于 Glove 向量，到底强在哪里。 首先是训练数据规模的影响，</p>
<ul>
<li>随着数据规模的扩大，Glove 向量的表现与 BERT 向量的表现差距越来越小，我们看到当训练数据足够多的时候，Glove 在一些任务上能够获得略差于BERT的影响，但是在绝大多数情况下依旧比BERT 向量差很多，这说明 BERT 对于小数据集的优越性。</li>
<li>在简单任务上，随着数据量的增加， Glove 能达到 BERT 十分接近的效果</li>
</ul>
<p>然后是语言特征：</p>
<ul>
<li><strong>the complexity of text structure：</strong>句子结构的复杂性</li>
<li><strong>Ambiguity in word usage</strong>: 单词的歧义性。</li>
<li><strong>Prevalence of unseen words</strong>：未登录词出现的概率</li>
</ul>
<p>上图我们可以得出以 BERT 为代表的 Contextual embeddings 在解决一些文本结构复杂度高和单词歧义性方面有显著的效果。</p>
<h2><span id="4-预训练语言模型-后时代">4. 预训练语言模型 - 后时代</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1gdb1uomc8vj30m70re79a.jpg" alt></p>
<p>首先，我们来分析一下这张图，从上往下：</p>
<ul>
<li><strong>Contextual：</strong> 谈论 静态 embedding 与 上下文 embedding，被做烂了，pass。</li>
<li><strong>Architectures：</strong> 模型整体架构，这部分还有的探讨，可以参见上面 T5 的Model Architecture 部分。 目前业界还没有统一的标准说应该选择哪种架构，不过从 T5 的效果来看， Transformer+Encoder+Decoder 的效果是最好的，但参数量也上去了。其实就目前来看，研究的意义不是很大了，除非说能出现一个大的突破。</li>
<li><strong>Task Types：</strong> 谈论了两件事： <strong>语言模型的选择</strong>以及<strong>Contrastive Learning</strong>，其实这两个应该分开讨论。</li>
<li><strong>Multi-Lingual：</strong>  从多国语言的角度出发，这方面不太懂，也不感兴趣，觉得用处不会太大。</li>
<li><strong>Multi-Modal：</strong> 多模角度，我个人认为这对于工业界是十分有意义的。</li>
<li><strong>Knowledge Enriched：</strong> 知识 + 预训练语言模型，我觉得这是一个很值得研究的方向，无论是在工业界和学术界。</li>
<li><strong>Domain Specific：</strong> 特定领域 + 预训练语言模型，我觉得这方面很有搞头，毕竟很多专有领域跟公共领域还是很不同的，比如医学，生物，法学等。由于每看过相关文章，无法说上面的模型与 bert在同样语料上预训练后哪个效果好，但还是有一定参考价值的。</li>
<li><strong>Language-Specific：</strong> 这块我觉得还是很有研究价值的，毕竟我们中文跟英文从各个方面来说差距还是蛮大的，如果能对语言有深入了解，感觉还有搞头。</li>
<li><strong>Model Compression：</strong> 模型压缩，这个在工业界用处很大，十分建议研究，需求也很大，一些蒸馏方法所需要的资源门槛也比较低，如果有资源，有idea，建议入坑。</li>
</ul>
<p>考虑到涉及到的内容太多，我这里抽取四个部分讨论，分别是： Architectures， Task Types， Knowledge Enriched 以及 language generation。 </p>
<h3><span id="1-ae-vs-ar">1. AE vs AR</span></h3><p>AR 语言模型：自回归语言模型，指的是，依据前面（或后面）出现的 tokens 来预测当前时刻的 token， 代表有 ELMO， GPT 等。</p>
<script type="math/tex; mode=display">
forward: p(x) = \prod_{t=1}^T p(x_t | x_{<t}) \\ backward: p(x) = \prod_{t=T}^1 p(x_t | x_{>t})</script><p>AE 语言模型：通过<strong>上下文信息</strong>来预测被 mask 的 token， 代表有 BERT , Word2Vec(CBOW)  。</p>
<script type="math/tex; mode=display">
p(x) = \prod_{x\in Mask} p(x|context)</script><p><strong>AR 语言模型：</strong></p>
<ul>
<li><strong>缺点：</strong>它只能利用单向语义而不能同时利用上下文信息。 ELMO 通过双向都做AR 模型，然后进行拼接，但从结果来看，效果并不是太好。</li>
<li><strong>优点：</strong> 对生成模型友好，天然符合生成式任务的生成过程。这也是为什么 GPT 能够编故事的原因。</li>
</ul>
<p><strong>AE 语言模型：</strong></p>
<ul>
<li><strong>缺点：</strong> 由于训练中采用了 [MASK] 标记，导致预训练与微调阶段不一致的问题。 此外对于生成式问题， AE 模型也显得捉襟见肘，这也是目前 BERT 为数不多实现大的突破的领域。</li>
<li><strong>优点：</strong> 能够很好的编码上下文语义信息， 在自然语言理解相关的下游任务上表现突出。</li>
</ul>
<h2><span id="2-gpt-系列">2. GPT 系列</span></h2><h3><span id="1-gpt-20">1. GPT 2.0</span></h3><p>GPT 2.0 验证了数据的重要性，即使单纯的从数据角度入手，效果就可以获得巨大的提升。GPT 2.0 采用800w 互联网网页数据，这样训练出来的语言模型，能够覆盖几乎所有领域的内容。</p>
<p>第二个意义在于，GPT 2.0 开始探索了预训练语言模型在 zero-shot 下的表现。这方面在GPT 3.0 中体现的淋漓尽致。</p>
<ul>
<li>预训练数据与网络深度的重要性，目前也没有到极限。</li>
<li>GPT 2.0 的生成效果非常惊艳，至少语法，流畅度等方面是没有问题的，就是没有灵魂</li>
<li>zero-flot 也不是不可以</li>
</ul>
<h3><span id="20-gpt-30">2.0 GPT 3.0</span></h3><p>先来介绍一下几个概念：</p>
<ul>
<li>FT，fine-tuning：就是微调啦</li>
<li>FS，few-shot：允许输入数条范例和一则任务说明</li>
<li>One-shot：只允许输入一条范例和一则任务说明</li>
<li>Zero-shot：不允许输入任何范例，只允许输入一则任务说明</li>
</ul>
<p>GPT 3.0 本质上是探索超大型预训练语言模型在 few-shot，one-shot，zero-shot 上的可能性，这是延续之前 GPT 2.0 的研究，整体上，GPT 3.0 在 zero-shot 下能获得相当不错的结果。</p>
<h2><span id="3-bert-系列">3. BERT 系列</span></h2><h3><span id="1-roberta">1. Roberta</span></h3><p>roberta 是bert 的一个完善版，相对于模型架构之类的都没有改变，改变的只是三个方面：</p>
<ol>
<li>预训练数据：<ul>
<li>BERT采用了BOOKCORPUS 和英文维基百科， 总共16GB。而 RoBERTa采用了BOOKCORPUS + 英文维基百科+ CC-NEWS+OPENWEBTEXT+STORIES， 总共160GB。</li>
<li>Roberta 于bert 都采用 512 个token 作为序列长度，但与bert不同的是， robert 不会随机掺杂一些短句，这意味着 roberta 采用的都是长句。</li>
</ul>
</li>
<li><p>动态mask vs 静态 mask：</p>
<ul>
<li><strong>静态mask：</strong>Bert 在准备训练数据时，每个样本只会进行一次随机mask，每个epoch都重复使用，后续的每个训练步都采用相同的mask。</li>
<li><strong>修改版静态mask：</strong> 在预处理时将数据集拷贝10次，每份数据采用不同的mask。</li>
<li><strong>动态mask</strong>：不在预处理时进行mask，而是在每次向模型输入时动态生成mask</li>
</ul>
</li>
<li><p>数据格式与NSP：</p>
<ul>
<li><strong>Segment-pair + NSP：</strong>与bert一样。输入包含两个 segment，这两个segment可能会来自同一个文档或不同文档，两个segment 的token 数均小于 512，预训练任务包含 MLM 与 NSP。</li>
<li><strong>Sentence+pair + NSP：</strong>输入包含两个 sentence，两个句子可能来自同一文档或不同文档，两个句子 token 数均少于 512。预训练任务包含 MLM 与 NSP。</li>
<li><strong>Full-sentences：</strong>输入只有一部分，来自同一个文档或不同文档的连续句子，token总数不超过512。输入可能跨越文档边界，如果跨文档，则在上一个文档末尾添加文档边界token。不包含NSP任务。</li>
<li><strong>Doc-sentences：</strong>输入只有一部分，输入来自同一个文档的连续句子，token总数不超过512。预训练不包含 NSP 任务。</li>
</ul>
<p>通过四个对比实验我们发现：</p>
<ul>
<li>Segment-pair 较好于 sentence-pair，可能是因为 segment 能够学习到长距离依赖关系。</li>
<li>Doc-sentences 几乎在所有任务中表现最佳，这意味着 NSP 任务没有什么用</li>
<li>Doc-sentences 略好于 Full-sentences。</li>
</ul>
</li>
</ol>
<h3><span id="2-t5">2. T5</span></h3><h2><span id="4-预训练语言模型与自然语言生成">4. 预训练语言模型与自然语言生成</span></h2><p>这里我们先来回顾一下BERT和GPT， 前面提到， BERT 本质上相当于 Transformer 中的 Encoder， 而GPT 相当于 Transformer 中的 Decoder。既然我们已经验证了 Transformer 在文本生成领域的成功，尤其是机器翻译领域， 那么当我们想用于生成问题的时候，很自然的想到有没有办法把二者结合起来呢？</p>
<p>MASS 就是基于这样的思想。</p>
<h3><span id="1-mass">1. MASS</span></h3><p>MASS 的思想很简单， 对于输入序列 x，  mask 该句从 u 到 v 位置上的token，记为 $x^{\u:v}$， 而对应的， 从 u 到 v 位置上的 token 片段记为 $x^{u:v}$ 。 k = v - u + 1 表示 mask 的窗口大小 ， 表示一句话中多少个 token 被 mask 。 对于 MASS 的语言模型来说， 其输入为 mask 后的序列 $x^{\u:v}$ ， 输出为被 mask 后的序列 $x^{u:v}$。</p>
<p><strong>为何 MASS 适合生成</strong></p>
<p><strong>首先，</strong> 通过 Seq2Seq 框架来预测被 mask 的tokens 使得 Encoder 去学习没有被 mask 的 token 的信息， 而Decoder 去学习如何从 Encoder 中提取有效的信息。</p>
<p><strong>然后，</strong> 与预测离散的 tokens相比，Decoder 通过预测连续的 tokens， 其能够建立很好的语言生成能力。</p>
<p><strong>最后，</strong> 通过输入与输出的 mask 匹配， 使得 Decoder 能够从Encoder 中提取到有意义的信息，而不是利用之前的信息。 </p>
<p>MASS 总结来说有以下几点重新：</p>
<ul>
<li>引入了 Seq2Seq 来训练预训练模型。</li>
<li><strong>mask 掉的是一段连续的tokens而不是离散的 mask， 有助于模型生成语言的能力。</strong></li>
<li>Encoder 中是 mask 掉的序列，而 Decoder 中是对应被mask的 tokens。</li>
</ul>
<h3><span id="2-unilm">2. UNILM</span></h3><p>UNILM 同样想融合bert与gpt ，然而走了与 MASS 完全不同的路子，它想通过多任务学习的方式来解决。UNILM 这篇文章，厉害在同时使用多个预训练语言模型训练这个思想，在预训练任务中包含了三种语言模型：</p>
<ul>
<li><p><strong>Bidirectional</strong> <strong>LM</strong> <strong>：</strong> BERT 的 mask LM</p>
</li>
<li><p><strong>Unidirectional LM</strong>：GPT 的 语言模型，包括 left-to-right 到 right-to-left</p>
</li>
<li><p><strong>Seq2Seq LM</strong>： 句子间LM。输入两个句子，第一个句子采用双向LM方式，第二个采用单向LM 方式。</p>
</li>
</ul>
<h3><span id="3-bart">3. BART</span></h3><p>BART 与 MASS 的基本思想一致，都是受到 Transformer 在机器翻译领域的成功，尝试将 Transformer架构跟预训练结合起来。</p>
<p>但是与 MASS 不同的是，他们输入的数据格式有很大的差别，Decoder 也有较大的差别。与MASS 相比， BART 完全延续 Transformer 原来的架构方式。</p>
<p><strong>训练数据：</strong></p>
<ul>
<li><strong>Token Masking</strong> 和BERT一样，随机选择<strong>token</strong>用[MASK] 代替。</li>
<li><strong>Token Deletion</strong> 随机删除<strong>token</strong>，模型必须确定哪些<strong>位置</strong>缺少输入。</li>
<li><strong>Text Filling</strong> 屏蔽一个<strong>文段</strong>，文段长度服从泊松分布（λ=3）。每个文段被<strong>一个[MASK]</strong>标记替换。如果文段长度为0，意味插入一个[MASK]标记（灵感来自Span-BERT）。</li>
<li><strong>Sentence Permutation</strong> 以句号作为分割符，将一篇文章分成多个<strong>句子</strong>，并随机打乱。</li>
<li><strong>Document Rotation</strong> 随机均匀地选择一个<strong>token</strong>，以这个token为中心，旋转文档，选中的这个token作为新的开头，此任务训练模型以识别文档的开头。</li>
</ul>
<h2><span id="5-预训练语言模型融入知识">5. 预训练语言模型融入知识</span></h2><h3><span id="1-ernie">1. ERNIE</span></h3><p>ERINE 的网络架构，语言模型等与 BERT 完全相同，与BERT 不同的主要有两点：</p>
<ul>
<li>数据的mask</li>
<li>NSP 任务 与 DLM</li>
</ul>
<p>首先我们来看 mask 方式，ERNIE 的 mask 包括三部分：</p>
<ol>
<li><p>BERT 的 basic-level mask 预训练</p>
</li>
<li><p>Phrase-level 预训练</p>
</li>
<li><p>Entity-level 预训练</p>
</li>
</ol>
<p>但是我们反过来看这篇文章，它融入知识了吗？ 我觉得没有，对于知识图谱来说，实体本身的含义很重要，但是实体的关系同样非常重要，而这篇文章并没有融入任何的关系信息。</p>
<h3><span id="2-ernie-清华">2. ERNIE (清华)</span></h3><p>这篇文章最核心的点在于，将BERT的信息与TransE 的信息进行融合</p>
<p>我们看到，上述整个模型可以整体分为两部分：</p>
<ul>
<li>T-Encoder： 与 Bert 的预训练过程完全相同，是一个多层的双向 Transformer encoder， 用来捕捉词汇和语法信息。</li>
<li>K-Encoder： 本文创新点，描述如何将知识图谱融入到预训练模型。</li>
</ul>
<h3><span id="3-k-bert">3. K-BERT</span></h3><h2><span id="reference">Reference</span></h2><p><strong>语言模型基础与词向量：</strong></p>
<p>[1] A Neural Probabilistic Language Model</p>
<p>[2] Mikolov, T.(2013). Distributed Representations of Words and Phrases and their Compositionality.</p>
<p>[3] Mikolov, T.(2013). Efficient Estimation of Word Representations in Vector Space.</p>
<p>[4] Rong, X. (2014). word2vec Parameter Learning Explained.</p>
<p><strong>预训练语言模型：</strong></p>
<p>[1] ELMO: Deep contextualized word representations</p>
<p>[2]  BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</p>
<p>[3] GPT 1.0: Improving Language Understanding by Generative Pre-Training</p>
<p>[4] GPT 2.0: Language Models are Unsupervised Multitask Learners</p>
<p>[5] GPT 3.0: Language Models are Few-Shot Learners</p>
<p><strong>应用预训练语言模型：</strong></p>
<p>[1]  To tune or not to tune? adapting pretrained representations to diverse tasks. </p>
<p>[2]  Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks</p>
<p><strong>预训练语言模型 - 后时代：</strong></p>
<p>[2]  ERNIE - Enhanced Language Representation with Informative Entities</p>
<p>[3]  ERNIE - Enhanced Representation through Knowledge Integration</p>
<p>[4]  ERNIE 2.0 - A Continual Pre-training Framework for Language Understanding</p>
<p>[5]  MASS - Masked Sequence to Sequence Pre-training for Language Generation</p>
<p>[6] UNILM - Unified Language Model Pre-training for Natural Language Understanding and Generation</p>
<p>[7]  XLNet - Generalized Autoregressive Pretraining for Language Understanding</p>
<p>[8]  RoBERTa - A Robustly Optimized BERT Pretraining Approach</p>
<p>[9] TransformerXL: Attentive Language Models Beyond a Fixed-Length Context</p>
<p><strong>如何预训练一个好的预训练语言模型：</strong></p>
<p>[1] Pre-trained Models for Natural Language Processing: A Survey</p>
<p>[2] T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Bag of Tricks for Efficient Text Classification</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>词向量</tag>
      </tags>
  </entry>
  <entry>
    <title>语言模型与词向量基础</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/1-%E8%AF%8D%E5%90%91%E9%87%8F/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="语言模型与词向量基础">语言模型与词向量基础</span></h1><h2><span id="1-语言模型基础与词向量">1. 语言模型基础与词向量</span></h2><p>语言模型可以简单理解为一个句子 s 在所有句子中出现的概率分布 P(s)。比如一个语料库中有100 个句子，『OK』这个句子出现了5次， 那么 $p(OK) = 5\%$。</p>
<p>那么，如何学习到这种概率分布呢？ 最简单的方法是建立一个无比庞大的语料库，该语料库中包含了人类成百上千年间可能讲过的所有的话，那么我们不就可以算出这句话出现的概率了吗。可惜此方法不现实。 </p>
<p>那么，能不能通过数学的方法进行表示呢？答案是可以滴，因为 S 是一个序列 $w_1, w_2 , \cdots ,w_n$，那么$p(s)$可以展开为：</p>
<script type="math/tex; mode=display">
p(s) = P(w_1, w_2, \cdots, w_n) = P(w_1) \cdot P(w_2|w_1) \cdot P(w_3|w_1,w_2) \cdots P(w_n|w_1, w_2, \cdots, w_{n-1})</script><p>那么现在的问题就变成了我们如何计算 $P(w_1, w_2, \cdots, w_n) $</p>
<h2><span id="2-统计方法-n元模型">2. 统计方法 - n元模型</span></h2><p>我们观察上式，会发现， $P(w<em>1)$ 比较好算， $P(w_2|w_1)$  也还ok， $P(w_3|w_1,w_2)$ 就比较有难度了，随着n的增大，计算会越来越难， $P(w_n|w_1, w_2, \cdots, w</em>{n-1})$ 几乎根本不可能估算出来。怎么办？</p>
<p>马尔可夫假设：假设任意一个词 $w<em>i$  出现的概率只同它前面的n个词 $(w</em>{i-1}, \cdots, w_{i-n})$ 有关。由此，那么就有：</p>
<script type="math/tex; mode=display">
一元模型：  P(S) = \prod_{i=1}^{l} P(w_i)   \\
二元模型：P(S) = \prod_{i=1}^{l} P(w_i|w_{i-1})</script><p>缺陷： </p>
<ol>
<li>无法建模更远的关系，语料的不足使得无法训练更高阶的语言模型。</li>
<li>无法建模出词之间的相似度。</li>
<li>训练语料里面有些 n 元组没有出现过,其对应的条件概率就是 0,导致计算一整句话的概率为 0。解决这个问题有两种常用方法： 平滑法和回退法。</li>
</ol>
<h2><span id="3-深度学习方法-神经网络语言模型1">3. 深度学习方法 - 神经网络语言模型[1]</span></h2><p>首先，我们回到问题本身，我们为什么要计算 $p(s)$， 我们的目的是为了通过大规模语料库学习到语言内部的概率分布。那么有没有办法通过深度学习的方式来学习到这种概率分布呢？</p>
<p><img data-src="https://pic3.zhimg.com/v2-a58e75cd7fcca491713d8601924d3d46_b.png" alt></p>
<p> 观察上图，假设有一组词序列： $w_1, w_2, \cdots, w_t$ ，其中 $w_i \in V$ ， $V$ 是所有单词的集合。我们的输入是一个词序列，而我们的输出是一个概率值，表示根据context预测出下一个词是 $i$ 的概率。用数学来表示，我们最终是要训练一个模型： </p>
<script type="math/tex; mode=display">
P(w_t = i | context) = P(w_t | w_1^{t-1})</script><ul>
<li>$w<em>t $表示这个词序列中的第 $t$ 个单词， $w</em>{t-n+1}$ 表示输入长度为n的词序列中的第一个单词</li>
<li>$w_1^{t-1}$ 表示从第1个单词到第 $t-1$ 个单词组成的子序列</li>
</ul>
<p>因此我们发现，该模型的每个样本其实计算的是：$</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>词向量</tag>
      </tags>
  </entry>
  <entry>
    <title>实体链接</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/10-%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#实体链接">实体链接</a><ul>
<li><a href="#refernece">Refernece</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="实体链接">实体链接</span></h1><h2><span id="refernece">Refernece</span></h2><p><a href="https://mp.weixin.qq.com/s/AIHsI3L57WLqR0D5y-_BTQ">Facebook提出生成式实体链接、文档检索，大幅刷新SOTA！</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>实体连接</tag>
      </tags>
  </entry>
  <entry>
    <title>抽取式摘要</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/11-%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/%E6%8A%BD%E5%8F%96%E5%BC%8F%E6%91%98%E8%A6%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#抽取式摘要">抽取式摘要</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="抽取式摘要">抽取式摘要</span></h1><p><a href="https://zhuanlan.zhihu.com/p/79223454">https://zhuanlan.zhihu.com/p/79223454</a></p>
<p>Fine-tune BERT for Extractive Summarization</p>
<p><a href="https://github.com/nlpyang/BertSum">https://github.com/nlpyang/BertSum</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>文本摘要</tag>
      </tags>
  </entry>
  <entry>
    <title>文本生成最新进展</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/12-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E7%9A%84%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#文本生成的最新进展">文本生成的最新进展</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="文本生成的最新进展">文本生成的最新进展</span></h1><p><a href="https://zhuanlan.zhihu.com/p/104383357">https://zhuanlan.zhihu.com/p/104383357</a></p>
<p><a href="https://www.jiqizhixin.com/articles/2020-04-14">https://www.jiqizhixin.com/articles/2020-04-14</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/334374764">https://zhuanlan.zhihu.com/p/334374764</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>文本生成</tag>
      </tags>
  </entry>
  <entry>
    <title>BERT-KPE</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13-%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/BERT-KPE%20%20Joint%20Keyphrase%20Chunking%20and%20Salience%20Ranking%20with%20BERT/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#bert-kpe-joint-keyphrase-chunking-and-salience-ranking-with-bert">BERT-KPE - Joint Keyphrase Chunking and Salience Ranking with BERT</a><ul>
<li><a href="#methodology">Methodology</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="bert-kpe-joint-keyphrase-chunking-and-salience-ranking-with-bert">BERT-KPE - Joint Keyphrase Chunking and Salience Ranking with BERT</span></h1><h2><span id="methodology">Methodology</span></h2><script type="math/tex; mode=display">
文档： D = \{w_1, \cdots, w_i, \cdots, w_n\} \\
BERT表示文档： H = BERT(D) = \{h_1, \cdots, h_i, \cdots, h_n \} \\
ngram \,的 \, phrase : c_i^k = w_{i:i+k-1}  \\
CNN \,表示 \, ngram: g_i^k = CNN^k \{h_i, \cdots, h_{i+k-1} \}</script><ul>
<li>a chunking network： 识别出有意义的n-grams， 直接采用全连接接网络+softmax判断该n-gram $c_i^k$ 是否为合适的chunk</li>
</ul>
<script type="math/tex; mode=display">
p(c_i^k=y_i^k) = softmax(Linear(g_i^k))</script><ul>
<li>a ranking network：为 phrase 评分<script type="math/tex; mode=display">
f(c_i^k, D) = Linear(g_i^k)</script></li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>关键词抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>KeyPhrase Extraction</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13-%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/KeyPhrase%20Extraction/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#keyphrase-extraction">KeyPhrase Extraction</a><ul>
<li><a href="#ske-span-keyphrase-extraction">SKE： Span Keyphrase Extraction</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="keyphrase-extraction">KeyPhrase Extraction</span></h1><h2><span id="ske-span-keyphrase-extraction">SKE： Span Keyphrase Extraction</span></h2><h2><span id="reference">Reference</span></h2><p>[1] Keyphrase Extraction with Span-based Feature Representations</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>关键词抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>NP chunking</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13-%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/NP%20chunking/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#np-chunking">NP chunking</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="np-chunking">NP chunking</span></h1><p><a href="https://superangevil.wordpress.com/2009/11/20/nltk7_2/">https://superangevil.wordpress.com/2009/11/20/nltk7_2/</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>关键词抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>SIFRank</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13-%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/SIFRank%20-%20A%20New%20Baseline%20for%20Unsupervised%20Keyphrase%20Extraction%20Based%20on%20Pre-trained%20Language%20Model/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#sifrank-a-new-baseline-for-unsupervised-keyphrase-extraction-based-on-pre-trained-language-model">SIFRank: A New Baseline for Unsupervised Keyphrase Extraction Based on Pre-trained Language Model</a><ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#model-overview">Model Overview</a><ul>
<li><a href="#overall-structure">Overall Structure</a></li>
<li><a href="#sif">SIF</a></li>
<li><a href="#sifrank">SIFRank</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="sifrank-a-new-baseline-for-unsupervised-keyphrase-extraction-based-on-pre-trained-language-model">SIFRank: A New Baseline for Unsupervised Keyphrase Extraction Based on Pre-trained Language Model</span></h1><h2><span id="abstract">Abstract</span></h2><h2><span id="model-overview">Model Overview</span></h2><h3><span id="overall-structure">Overall Structure</span></h3><ul>
<li>首先先分词，并标注词性</li>
<li>采用 NP-chunker（用正则编写） 提取句子中的 NPs </li>
<li>用预训练语言模型获取每个 token 的表示</li>
<li>分别将document 与 NPs 表示成向量</li>
<li>计算NPs embedding 与 document的 cos距离， 选择topk</li>
</ul>
<h3><span id="sif">SIF</span></h3><p>通过SIF 来分别获得 NPs 与 document 的 embedding 。</p>
<p>引入了两个平滑项，来解释（1）有些词是在上下文之外出现（2）某些高频词如『the』是没有语境限制的：</p>
<ul>
<li>$\alpha f_w$：$\alpha$ 是标量， $p(w)$ 是整个语料库中单词 $w$ 的词频。</li>
</ul>
<script type="math/tex; mode=display">
Pr(s|c_d) = \prod_{w \in s} Pr(w|c_d) = \prod_{w \in s} \alpha f_w + (1-\alpha) \frac{exp(<v_w, \widetilde{c}_d>)}{Z_{\widetilde{c}_d}} \\
Z_{\widetilde{c}_d} = \sum_{w \in V} exp(<\widetilde{c}_d, v_w>) \\
\widetilde{c}_d = \beta c_0 + (1-\beta)c_d, c_0 \bot c_d \\</script><h3><span id="sifrank">SIFRank</span></h3><ul>
<li>document d 的embedding 为$v_d$</li>
<li>候选NP的embedding 为 $v_{NP}$</li>
</ul>
<script type="math/tex; mode=display">
SIFRank(v_{NP_i}, v_d) = Sim(v_{NP_i}, v_d) = cos(v_{NP_i}, v_d) = \frac{\overrightarrow{v_{NP_i}} \cdot \overrightarrow{v_d} }{||\overrightarrow{v_{NP_i}}||\,||\overrightarrow{v_d}||}</script>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>关键词抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>SIF</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/13-%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96/SIF%EF%BC%9Aa%20simple%20but%20tough%20to%20beat%20baseline%20for%20sentence%20embeddings/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#sifa-simple-but-tough-to-beat-baseline-for-sentence-embeddings">SIF：a simple but tough to beat baseline for sentence embeddings</a><ul>
<li><a href="#模型解释">模型解释</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="sifa-simple-but-tough-to-beat-baseline-for-sentence-embeddings">SIF：a simple but tough to beat baseline for sentence embeddings</span></h1><p><a href="https://zhuanlan.zhihu.com/p/44534561">https://zhuanlan.zhihu.com/p/44534561</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/111710604">https://zhuanlan.zhihu.com/p/111710604</a></p>
<p><a href="https://blog.csdn.net/qq_42491242/article/details/105381771">https://blog.csdn.net/qq_42491242/article/details/105381771</a></p>
<p>核心思想：</p>
<ul>
<li><strong>词频加权：</strong> 对组成句子的词进行线性加权，其中每个词的权重为 $\alpha/(\alpha + p_w)$ ，其中$p_w$ 是词频， $\alpha$ 是超参数。</li>
<li><strong>语义无关向量去除：</strong>句子向量的生成要去除文本中与语义无关的向量。具体做法是从数据集中抽样一些句子，然后计算这些句子向量对应的最大的奇异值向量，这样的向量被认为代表了文本中的语法或停用词这些和语义无关的内容。将这些向量去除可以增强文本对语义本身的表达能力。</li>
</ul>
<h2><span id="模型解释">模型解释</span></h2><p>在潜变量生成模型(latent variable generative model)中，语料的生成是一个动态过程，也就是说每个时刻生成一个单词。这个动态过程是由一个话语向量 $c_t$ (discourse vector)的随机游走来控制的。这里的话语向量代表着当前句子正在表达的意思(what is being talked about)代表着句子的状态或者一种潜在的语义信息。而单词的词向量 $v_w$ 和 $c_t$ 的内积则表示了单词和句子的联系。</p>
<p>两个问题：</p>
<ul>
<li>有些在单词上下文之外的词对句向量也是有影响的</li>
<li>有些频繁出现的高频词(和，的，and，the等)是对话语本身没有贡献的</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>关键词抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>任务型对话</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/14-%E5%AF%B9%E8%AF%9D/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="reference">Reference</span></h2><p>综述 — <a href="https://time.geekbang.org/special/AI-voice">https://time.geekbang.org/special/AI-voice</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>对话</tag>
      </tags>
  </entry>
  <entry>
    <title>开防阈对话</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/14-%E5%AF%B9%E8%AF%9D/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E5%BC%80%E6%94%BE%E5%9F%9F%E5%AF%B9%E8%AF%9D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<p><a href="https://zhuanlan.zhihu.com/p/360572095">https://zhuanlan.zhihu.com/p/360572095</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/75009749">https://zhuanlan.zhihu.com/p/75009749</a></p>
<p><a href="https://mp.weixin.qq.com/s/_QY2EhB-TiBcb5q0379McQ">https://mp.weixin.qq.com/s/_QY2EhB-TiBcb5q0379McQ</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/360575335">https://zhuanlan.zhihu.com/p/360575335</a></p>
<h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/355521452">2021年了，对话系统凉透了吗？</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/365950515">一文带你入门知识图谱多跳问答</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>对话</tag>
      </tags>
  </entry>
  <entry>
    <title>模型蒸馏</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/16-%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%20-%20%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#知识蒸馏">知识蒸馏</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="知识蒸馏">知识蒸馏</span></h1><h2><span id="reference">Reference</span></h2><p>[1] <a href="https://zhuanlan.zhihu.com/p/161930307">https://zhuanlan.zhihu.com/p/161930307</a></p>
<p>[2] knowledge Distillation: A survey</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>Subword分词方法</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/17-%E4%B8%AD%E8%8B%B1%E6%96%87%E5%88%86%E8%AF%8D/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%20-%20Subword%20%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#subword-你值得拥有">Subword ，你值得拥有</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#bpe-2">BPE [2]</a></li>
<li><a href="#中文分词-bert-wwm">中文分词 - BERT-wwm</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="subword-你值得拥有">Subword ，你值得拥有</span></h1><hr>
<h2><span id="前言">前言</span></h2><p> 在进入预训练语言模型时代，Subword方法就已经开始大行其道了，虽然目前在英文领域应用广泛，但似乎还没有在中文领域中出现很重量级的 Subword 方法，我个人觉得可以适当探讨一下。因此，我就把最近看过的所有的预训练语言模型中所用的 Subword 方法提取出来，分析了一波，感兴趣的可以看看。</p>
<p>目前来看，方法大致可以分为三种，分别是 BPE[2]，WordPiece[1][4]，以及SentencePiece[3]。本文先对这三大算法进行论述，然后谈谈中文方向的分词方法发展，最后，在Github上维护一个实现仓库来帮助各位更好的理解。</p>
<h2><span id="bpe-2">BPE [2]</span></h2><h2><span id="中文分词-bert-wwm">中文分词 - BERT-wwm</span></h2><p>其实，早在之前就有写文章谈到我个人对于中文分词的看法：<a href="https://zhuanlan.zhihu.com/p/66155616">深度学习时代，分词真的有必要吗</a>，最近看Subword方法时，又想到中文分词的问题，于是我提了一个小问题：<a href="https://www.zhihu.com/question/357757060">预训练语言模型时代，还需要做分词吗？</a>，希望各位大佬能够分享看法。</p>
<p>BERT-wwm其实从另一个角度阐述了分词的问题，其实其与百度的那篇ERNIE差不多，都是通过 mask 词而非字来实现的。具体的是，<strong>如果词中的某个字被mask掉，那么该词需要被完全mask。</strong>且相同的是，BERT-wwm与ERNIE都是在BERT已训练好的基础上进行再训练的，其实本质上是<strong>词的粒度信息与字的粒度信息的融合</strong>，而这似乎是一种很不错的方式。 而这结果再次验证了：<strong>不同粒度的信息对于预训练语言模型的提升是有用的。</strong></p>
<p>从 Mask 这种操作来看，分词似乎已经完全没有必要了，当然，如果你想去训练一个中文预训练语言模型的话，那么词粒度的信息似乎是要被考虑进去的。</p>
<h2><span id="reference">Reference</span></h2><p>[1] BERT，RoBERTa，UNILM：Google’s Neural Machine Translation System:Bridging the Gap Between Human and Machine Translation</p>
<p>[2] GPT 1.0，GPT 2,.0，MASS，XLMs：Neural machine translation of rare words with subword units.</p>
<p>[3] XLNet，ALBERT：Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing.</p>
<p>[4] Subword regularization: Improving neural network translation models with multiple subword candidates.</p>
<p>[5] BERT-WWM：Pre-Training with Whole Word Masking for Chinese BERT</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>中英文分词</tag>
      </tags>
  </entry>
  <entry>
    <title>模型压缩-综述</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/16-%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%20-%20%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#模型压缩-综述">模型压缩 - 综述</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="模型压缩-综述">模型压缩 - 综述</span></h1><h2><span id="reference">Reference</span></h2><p>[1] A Survey of Methods for Model Compression in NLP</p>
<p>[2] A Survey of Model Compression and Acceleration for Deep Neural Networks</p>
<p>[3] A Survey of Methods for Low-Power Deep Leaning and Computer Vision</p>
<p>[4] Recent Advances in Efficient Computation of Deep Convolutional Neural Networks</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>中英文分词</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/17-%E4%B8%AD%E8%8B%B1%E6%96%87%E5%88%86%E8%AF%8D/%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%20-%20%E4%B8%AD%E8%8B%B1%E6%96%87%E5%88%86%E8%AF%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#分词">分词</a><ul>
<li><a href="#1-英文分词">1. 英文分词</a></li>
<li><a href="#2-中文分词">2. 中文分词</a></li>
<li><a href="#3-中英文混杂">3. 中英文混杂</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="分词">分词</span></h1><h3><span id="1-英文分词">1. 英文分词</span></h3><ul>
<li>BPE</li>
<li>WordPiece</li>
<li></li>
</ul>
<h3><span id="2-中文分词">2. 中文分词</span></h3><h3><span id="3-中英文混杂">3. 中英文混杂</span></h3>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>中英文分词</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention 机制 - 解释性</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2-Attention%E6%9C%BA%E5%88%B6/Attention%20%E6%9C%BA%E5%88%B6%20-%20%E8%A7%A3%E9%87%8A%E6%80%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#attention-机制-解释性">Attention 机制 - 解释性</a><ul>
<li><a href="#refernece">Refernece</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="attention-机制-解释性">Attention 机制 - 解释性</span></h1><h2><span id="refernece">Refernece</span></h2><p><a href="https://zhuanlan.zhihu.com/p/188271413">Attention模型：我的注意力跟你们人类不一样</a></p>
<p>Do People and Neural Networks Pay Attention to the Same Words? Studying Eye-tracking Data for Non-factoid QA Evaluation</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>Attention机制</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention 机制 -- Transformer</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2-Attention%E6%9C%BA%E5%88%B6/Attention%20%E6%9C%BA%E5%88%B6%20--%20Transformer/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#attention-机制-transformer">Attention 机制 — Transformer</a><ul>
<li><a href="#推荐先看">推荐先看</a></li>
<li><a href="#1-scaled-dot-product-attention">1. Scaled Dot-product Attention</a></li>
<li><a href="#2-muti-head-attention">2. Muti-head Attention</a></li>
<li><a href="#3-残差网络normalization与feed-forward-network">3. 残差网络，Normalization与feed-forward network</a></li>
<li><a href="#4-transformer-中如何使用-multi-head-attention">4. Transformer 中如何使用 Multi-head Attention</a></li>
<li><a href="#5-positional-encoding">5. Positional encoding</a></li>
<li><a href="#6-最后的-linear-与-softmax">6. 最后的 Linear 与 Softmax</a></li>
<li><a href="#回归到整体">回归到整体</a></li>
<li><a href="#qa">QA</a><ul>
<li><a href="#1-mask-三连问">1. Mask 三连问</a><ul>
<li><a href="#mask-操作是什么">mask 操作是什么？</a></li>
<li><a href="#它是怎么做的">它是怎么做的？</a></li>
<li><a href="#为什么要-mask">为什么要 mask ？</a></li>
</ul>
</li>
<li><a href="#2-scaled-dot-product-attention-中的scaled-是啥有啥用">2. Scaled Dot-product Attention 中的Scaled 是啥，有啥用？</a></li>
<li><a href="#3-为什么-position-embddding-采用正余弦函数">3. 为什么 Position embddding 采用正余弦函数 ？</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="attention-机制-transformer">Attention 机制 — Transformer</span></h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247513060&amp;idx=1&amp;sn=8d96a41ed097c9c4acf1b3d54af271ba&amp;chksm=970f9b32a0781224fe7a450ed7428b9943839bacdb1874098469a4946234dfd8aea4ed8caf4b&amp;scene=21&amp;cur_album_id=1350016038754385921#wechat_redirect</span><br><span class="line">https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247503650&amp;idx=1&amp;sn=c2030b24daa7bf0f227379dcb639930f&amp;scene=21#wechat_redirect</span><br></pre></td></tr></table></figure>
<h2><span id="推荐先看">推荐先看</span></h2><p><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></p>
<p>代码： <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</a></p>
<p>此外，代码十分推荐看 <code>Bert-pytorch</code> 里面的实现，代码比上述的要更加清晰，可以看完上述代码与 bert 之后再看。</p>
<h2><span id="1-scaled-dot-product-attention">1.  Scaled Dot-product Attention</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1fyhq0qrab9j30av0apt8w.jpg" alt></p>
<ul>
<li>首先， Q 与 K 进行了一个点积操作，这个就是我在 Attention 讲到的score操作； </li>
<li>然后经过 Scale 操作，其实就是为了防止结果过大，除以一个尺度标度 $\sqrt{d_k}$， 其中 $d_k$ 是 Q 中一个向量的维度；</li>
<li>再然后， 经过一个Mask操作； 考虑到Q，K都是矩阵，且由于句子的长度是不定的，因此Q，K中必然会有一个补齐的操作，为了避免补齐的数据会影响我们Attention的计算，因此需要将补齐的数据设置为负无穷，这样经过后面的Softmax后就接近于 0，这样就不会对结果产生影响了。</li>
<li>最后经过一个 Softmax 层， 然后计算Attention Value。</li>
</ul>
<p>我们可以看到，这个依旧沿袭的是 Attention 的经典思想，不过在其中添加了一些操作如Scale， Mask，这意味着，对于Attention 而言， 其只要核心思想不变，适当的调整数据能够获得更好的结果。其公式如下：</p>
<script type="math/tex; mode=display">
Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V</script><p>这里解释一下 Scaled Dot-product Attention 在本文中的应用，也是称为 Self-Attenion 的原因所在，这里的Q，K， V 都是同源的，意思就是说，这里是句子对句子自己进行Attention来查找句子中词之间的关系，这是一件很厉害的事情，回想LSTM是怎么做的，再比较 Self-Attention， 直观的感觉，Self-Attention更能把握住词与词的语义特征，而LSTM对长依赖的句子，往往毫无办法，表征极差，这一点会单独讨论。</p>
<h2><span id="2-muti-head-attention">2. Muti-head Attention</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g0u01y18qbj30b10bqt95.jpg" alt></p>
<p>这里多头的含义其实就是<strong>采用多个Attention来从多个维度来把握词的信息</strong>，我们从图中看到，这里有 h=8 个Attention，每个Attention输出一种 Self-Attention 的结果，然后 Concat 起来。</p>
<ul>
<li>首先，Q，K， V 进过了一个线性变换，然后再传入到 Scaled Dot-Product Attention 中， 注意一点，对于不同的 Scaled Dot-Product Attention 而言， 变换矩阵是不一样的，且这些变换矩阵都参与训练。 </li>
<li>然后，将每个 Attention 的输出 Concat。</li>
<li>最后，进过一个线性变换输出，这个线性变化矩阵也是可训练的。</li>
</ul>
<script type="math/tex; mode=display">
head_i = Attention( QW_i^Q, KW_i^K, VW_i^V) \\
MultiHead(Q,K,V) = Concat(head_1, \cdots, head_n)W^O</script><h2><span id="3-残差网络normalization与feed-forward-network">3. 残差网络，Normalization与feed-forward network</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g0z7p03m8fj30fl0krmyq.jpg" alt></p>
<ul>
<li>首先，Encoder 与Decoder中都有着很明显的残差连接，这种残差结构能够很好的消除层数加深所带来的信息损失问题。这也是一篇很值得看的文章。</li>
<li>其次，有一个Layer Normalization过程，这在神经网络中其实也是很常见的手段，也是很经典的一篇文章。</li>
<li>然后，数据经过了一个前馈神经网络， 该前馈神经网络采用了两个线性变换，激活函数为Relu，公式如下：</li>
</ul>
<script type="math/tex; mode=display">
FFN(x) =    Relu(0, xW_1 + b_1) W_2 + b_2</script><h2><span id="4-transformer-中如何使用-multi-head-attention">4. Transformer 中如何使用 Multi-head Attention</span></h2><p>Transformer 中使用 Multi-head Attention要注意以下几点：</p>
<ul>
<li>在 Encoder 与 Decoder 中的黑色框中，采用的都是是 Self-Attention ，Q，K，V 同源。</li>
<li>需要注意的是<strong>只有在 Decoder 中的 Muti-head 中才有 Mask 操作</strong>，而在Encoder中却没有，这是因为<strong>我们在预测第 t个词时，需要将 t 时刻及以后的词遮住，只对前面的词进行 self-attention</strong>，这点不理解的话可以回想一下Sequence-to-Sequence那篇文章中对机器翻译的训练过程 。</li>
<li>在黄色框中，  Q 来自Decoder层， 而 K， V来自Encoder的输出 。</li>
</ul>
<h2><span id="5-positional-encoding">5. Positional encoding</span></h2><p>由于 Self-Attention 自己是把握不到句子的顺序信息的，因此，Transformer 需要采用 Positional encoding 来获取序列的顺序信息，论文中采用了正余弦函数的方式。 </p>
<p>本质上的核心思想是： 在<strong>偶数位置，使用正弦编码，在奇数位置，使用余弦编码</strong></p>
<script type="math/tex; mode=display">
PE(pos, 2i) = sin(pos / 10000^{2i/d_{model}}) \\
PE(pos, 2i+1) = cos(pos / 10000^{2i/d_{model}})</script><p>通过上式，我们可以得出：</p>
<script type="math/tex; mode=display">
sin(\alpha + \beta) = sin \alpha cos \beta + cos \alpha sin \beta \\
cos(\alpha + \beta) = cos \alpha cos \beta - sin \alpha sin \beta \\
PE(pos + k) = PE(pos) + PE(k)</script><h2><span id="6-最后的-linear-与-softmax">6. 最后的 Linear 与 Softmax</span></h2><p>这个其实没什么好说的，一般都会在最后一层加一个前馈神经网络来增加泛化能力，最后用一个 softmax 来进行预测。</p>
<h2><span id="回归到整体">回归到整体</span></h2><p>前面已经将所有的细节都讲的很清楚了，这里回到整体的情况下来简要谈一下论文中的Encoder与Decoder。</p>
<ul>
<li>Encoder 是由一个Stack组成， Stack中有6个相同的Layer， 每个Layer的结构如3图中所示</li>
<li>Decoder 同样由一个Stack组成， Stack中也有6个相同的Layer， 与 Encoder中的Layer有所差别， 主要是多了一个将Encoder输出引入的Muti-Head机制，这点在3图中也能很明白的看出来。 </li>
</ul>
<hr>
<h2><span id="qa">QA</span></h2><h3><span id="1-mask-三连问">1. Mask 三连问</span></h3><h4><span id="mask-操作是什么">mask 操作是什么？</span></h4><p>mask 操作是对某些值进行掩盖，使得其再参数更新时不产生效果。</p>
<h4><span id="它是怎么做的">它是怎么做的？</span></h4><p>通过将需要被mask的位置设置为负无穷，这样在后面的Softmax后，这些位置的概率就接近于 0，这样就不会对结果产生影响了。</p>
<h4><span id="为什么要-mask">为什么要 mask ？</span></h4><p>Transformer 本身的 mask 操作分为两部分： padding mask 与 sequence mask。</p>
<ul>
<li><p><strong>Padding mask：</strong> 考虑到每个批次中输入序列的长度是不一样的，而往往我们要先进行对其，对不足长度的文本进行 padding， 而这些padding 的词其实是没有意义的， 因此我们在做 Self-attention 的时候应该忽略它。</p>
</li>
<li><p><strong>Sequence Mask：</strong> 在Decoder 中，其不应该看见未来的信息，即对一个序列，当 <code>time_step=t</code> 时， 我们Decoder 的输出应该只依赖于 t 时刻之前的输入，而不应该依赖于 t 时刻之后的输入。</p>
<p>具体的做法是，产生一个上三角矩阵，上三角的值全为 1，下三角的值权威0，对角线也是 0。</p>
</li>
</ul>
<h3><span id="2-scaled-dot-product-attention-中的scaled-是啥有啥用">2. Scaled Dot-product Attention 中的Scaled 是啥，有啥用？</span></h3><p>Scaled 就是缩放数据。</p>
<ul>
<li>比较大的输入会使得 softmax 的梯度变得很小，当数量级较大时， softmax 将几乎全部的概率分布都分配给了最大值对应的标签， 此时梯度消失为 0， 参数更新会变得困难。</li>
<li>假设 Q， K 的各个分量是相互独立的随机变量，均值为 0， 方差为1，那么点积 $Q \cdot K$ 的均值为 0， 方差为 $d_k$ 。 方差越大，说明点积的数量级越大，通过除以 $\sqrt{d_k}$ 将方差稳定到 1， 可以有效的控制前面提到的梯度消失问题。</li>
</ul>
<h3><span id="3-为什么-position-embddding-采用正余弦函数">3. 为什么 Position embddding 采用正余弦函数 ？</span></h3><p>因为有：</p>
<script type="math/tex; mode=display">
PE(pos + k) = PE(pos) + PE(k)</script><p>这样使得模型能够记住相对位置信息。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>Attention机制</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention 机制 -- 基础篇</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2-Attention%E6%9C%BA%E5%88%B6/Attention%20%E6%9C%BA%E5%88%B6%20--%20%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#attention-机制-基础篇">Attention 机制 — 基础篇</a><ul>
<li><a href="#hard-vs-soft-1">Hard vs Soft [1]</a></li>
<li><a href="#global-vs-local-2">Global vs Local [2]</a></li>
<li><a href="#attention的本质思想-5-6">Attention的本质思想 [5]  [6]</a></li>
<li><a href="#score-函数的选择-6-2">Score 函数的选择 [6]  [2]</a></li>
<li><a href="#query-key-value-的定义">Query, Key, Value 的定义</a></li>
<li><a href="#self-attention-5">Self-Attention [5]</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="attention-机制-基础篇">Attention 机制 — 基础篇</span></h1><h2><span id="hard-vs-soft-1">Hard vs Soft [1]</span></h2><p>Attention首先分为两大类：<strong>Hard Attention 与 Soft Attention</strong>， 两者的区别在于 Hard Attention 关注一个很小的区域，而soft Attention 关注的相对要发散。 举个机器翻译方面的例子：</p>
<blockquote>
<p>我是小明   —&gt;  I am XiaoMing</p>
</blockquote>
<ul>
<li>对于 Hard Attention而言，在第1时刻翻译时，只关注“我”这个词，我们翻译得到“I”，在第2时刻翻译时，关注“是”这个词，翻译结果为“am”，以此直到 t 时刻结束。 它是采用one-hot编码的方式对位置进行标记，比如第1时刻，编号信息就是[1,0,0…]， 第二时刻，编码信息就是 [0, 1, 0, …]， 以此类推。这样会带来一个缺点：<strong>无法采用常规优化方法来进行优化，具体的训练细节很复杂，不推荐深入了解。</strong></li>
<li>而对于soft attention 而言，在第一时刻翻译时， “我是小明” 都对 “I” 做出了贡献，只不过贡献有大小之分，也就是说，虽然“我”这个词很重要，但是我们也不能放过其他词所带来的信息。</li>
</ul>
<p>比较二者而言，很显然，soft attention有很大的优势，因此，对于NLP领域而言，目前大多数的研究都基于 soft Attention 进行扩展。</p>
<p>虽然 [1] 具有很强的开创意义，但其毕竟是关于CV领域的，不推荐精读，因此我没有写任何公式，个人十分推荐下面这篇文章来作为 Attention 的第一篇精读论文。</p>
<h2><span id="global-vs-local-2">Global vs Local [2]</span></h2><p>在 soft attention阵营中，很快又划分为两大阵营： <strong>Glocal attention</strong> 与 <strong>Local attention</strong>， <strong>二者的区别在于关注的范围大小不同</strong>， 其中，Global attention 关注<strong>全部的文字序列</strong>，而 Local attention 关注的是<strong>固定的窗口中的所有文字序列</strong>。</p>
<p>比较二者， Global attention 的计算量要比 Local Attention 要大，尤其是对于长句子而言，效率变得很低； 而 Local Attention 只与窗口内的文字相关，因此窗口的大小就显得至关重要了，且在local attention 中多了一个<strong>预测中心词 $p_t$ 的过程</strong>，这有可能会忽略一些重要的词， 但同时，如果选择适当，那么 local attention 理应会降低无关词的干扰，当然，所带来的收益并不大。 而对于窗口的设置，论文中采用<strong>高斯分布</strong>来实现，如下：</p>
<script type="math/tex; mode=display">
\hat{a}_{i,j} = a_{i,j} \, e^{- \frac{(s - p_t)^2}{2 \sigma^2}}, \sigma = \frac{D}{2}</script><p>另一方面，由于Global Attention考虑的信息较多，因此从原理上讲要更好一些，毕竟local attention 可能会忽略对当前输出很重要的词，且 Local Attention 的表现与窗口的大小密切相关，如果设置小了，可能会导致效果变得很差。 </p>
<p>而考虑到NLP中问题的复杂性（如句子长短不一，句子之间可能有很强的相关性），因此<strong>后来的很多论文[3][4]中很少考虑采用 Local Attention 方法</strong>，且我自己在做阅读理解任务时，也基本不会考虑Local Attention， 毕竟窗口大小的设置实在太考验人了。</p>
<ul>
<li>Global Attention</li>
</ul>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g0tereh268j30zk0k00te.jpg" alt="Global Attention"></p>
<ul>
<li>local attention</li>
</ul>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g0terwkhqmj30zk0k0wf1.jpg" alt="Local Attention"></p>
<h2><span id="attention的本质思想-5-6">Attention的本质思想 [5]  [6]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g0tf397umyj30kn08uq34.jpg" alt></p>
<p>在上图中，Query 表示我们的问题信息，在阅读理解问题中，其对应的就是 question，而在机器翻译中，常常采用上一时刻的输出信息 $S_{i-1}$ 作为 Query；</p>
<p>对于 { key:value }而言，大多数情况下key与value是相同的，一般指的是第 j 个词的表示, 比如在机器翻译中， key 与 value 通常采用词的隐层输出 $h<em>j$  。我们通过计算 Query 与各个 key 之间的相似性或相关性来获得 $a</em>{i,j}$，然后对各个进行加权求和：</p>
<script type="math/tex; mode=display">
\alpha_{i,j} = \frac{e^{score(Query, Key(j))}}{\sum_{k=1}^t e^{score(Query, Key(k))}} \\
c_i= \sum_{i=1}^n = \alpha_{i,j} h_j</script><p>由上式可以看到，对于Attention机制的整个计算过程，可以总结为以下三个过程：</p>
<ul>
<li><strong>socre 函数：</strong> 根据 Query 与 Key 计算两者之间的相似性或相关性， 即 socre 的计算。</li>
<li><strong>注意力权重计算：</strong>通过一个softmax来对值进行归一化处理获得注意力权重值， 即$a_{i,j}$ 的计算。</li>
<li><strong>加权求和生成注意力值：</strong>通过注意力权重值对value进行加权求和， 即 $c_i$ 的计算。</li>
</ul>
<p>总的来说，Attention 无论如何变化，总是万变不离其宗。 对于大多数 Attention 的文章来说，其变化主要在于 Query， Key， Value 的定义以及第一阶段 Score 的计算方法，下面我们来详细讨论一下。</p>
<h2><span id="score-函数的选择-6-2">Score 函数的选择 [6]  [2]</span></h2><p>Score 函数本质的思想就是度量两个向量的相似度。</p>
<p>常见的方式主要有以下三种：</p>
<ul>
<li>求点积：学习快，适合向量再同一空间中，如 Transformer 。</li>
</ul>
<script type="math/tex; mode=display">
score(Query, Key(j)) = Query \cdot Key(j)</script><ul>
<li>Cosine 相似性</li>
</ul>
<script type="math/tex; mode=display">
score(Query, Key(j)) = \frac{Query \cdot Key(j)}{||Query|| \cdot ||Key(j)||}</script><ul>
<li>MLP网络</li>
</ul>
<script type="math/tex; mode=display">
score(Query, Key(j)) = MLP(Query,  Key(j)) \\
general: score(Query, Key(j)) = Query \, W \, Key(j) \\
concat: score(Query, key(j)) = W \, [Query;Key(j) ]</script><p>一般情况下，采用MLP网络更加灵活一些，且可以适当的扩展层以及改变网络结构，这对于一些任务来说是很有帮助的。</p>
<h2><span id="query-key-value-的定义">Query, Key, Value 的定义</span></h2><p>对于一个 Attention 机制而言，定义好 Query， Key， Value 是至关重要的，这一点我个人认为是一个经验工程，看的多了，自然就懂了。 我这里简单举阅读理解与机器翻译的例子：</p>
<ul>
<li>对于机器翻译而言，常见的是： Query 就是上一时刻 Decoder 的输出 $S_{i-1}$， 而Key，Value 是一样的，指的是 Encoder 中每个单词的上下文表示。</li>
<li>对于英语高考阅读理解而言， Query 可以是<strong>问题的表示</strong>，也可以是<strong>问题+选项的表示</strong>， 而对于Key， Value而言，往往也都是一样的，都指的是<strong>文章</strong>。而此时Attention的目的就是找出<strong>文章</strong>中与<strong>问题</strong>或<strong>问题+选项</strong>的相关片段，以此来判断我们的问题是否为正确的选项。</li>
</ul>
<p>由此我们可以看出， Attention 中 Query， Key， Value 的定义都是很灵活的，不同的定义可能产生不一样的化学效果，比如 <strong>Self-Attention</strong> ，下面我就好好探讨探讨这一牛逼思想。</p>
<h2><span id="self-attention-5">Self-Attention [5]</span></h2><p>Self-Attention 可以说是最火的 Attention 模型了，其在最近很火的 Bert 中也起到了重要的作用，最关键的是，<strong>其可与 LSTM 一较高低</strong>。 </p>
<p>这篇文章是十分值得精读，反复看的，因为其真正的将 Attention 用到了另一个新的高度，膜拜 Google。鉴于篇幅所限，本文就不赘述其中详细原理了，而是简述一下其核心思想。</p>
<p>Self-Attention 的本质就是<strong>自己注意自己</strong>， 粗暴点来说，就是，Q，K，V是一样的，即：</p>
<script type="math/tex; mode=display">
Attention \, value = Attention(W_QX,W_KX,W_VX)</script><p>它的内部含义是对序列本身做 Attention，来获得序列内部的联系，如下图所示 [7]。 </p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g0u0j6zj7hg30go0er1kx.gif" alt></p>
<p>这其实是有点类似于我们在 Embedding 层的时候采用 LSTM 来获得输入序列的上下文表示，但与 LSTM 不同之处在于<strong>Self - Attention 更能够把握句子中词与词的句法特征或语义特征</strong>，但另一方面其对于<strong>序列的位置信息</strong>不能很好的表示，这也是为什么会采用 Postition Embedding 来对位置信息做一个补充，但对于一些对位置信息敏感的任务，position  Embedding 所带来的信息可能会不够。</p>
<p>之所以说这篇文章具有开创意义，是因为其将Attention用到了一个基础单元上， 为取代LSTM提供了一种可能。</p>
<h2><span id="reference">Reference</span></h2><p>[1]  Show, Attend and Tell: Neural Image Caption Generation with Visual Attention — 不推荐</p>
<p>[2]  Effective Approaches to Attention-based Neural Machine Translation</p>
<p>[3] Neural Machine Translation by Jointly Learning to Align and Translate</p>
<p>[4] Neural Responding Machine for Short-Text Conversation</p>
<p>[5] Attention is all you need</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>Attention机制</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer 的位置编码</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2-Attention%E6%9C%BA%E5%88%B6/Transformer%20%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#transformer-的位置编码">Transformer 的位置编码</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="transformer-的位置编码">Transformer 的位置编码</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/352898810">让研究人员绞尽脑汁的Transformer位置编码</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>Attention机制</tag>
      </tags>
  </entry>
  <entry>
    <title>文本分类</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/3-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/Tricks%20-%20%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#tricks-文本分类">Tricks - 文本分类</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="tricks-文本分类">Tricks - 文本分类</span></h1><hr>
<h2><span id="reference">Reference</span></h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247485033&amp;idx=1&amp;sn=1f43019d702607d7dfc47ddfc7f84090&amp;chksm=970c2ebfa07ba7a948965596237d2d6cce3447c71233dc74f0c17de7a38e198b9c2092793ded&amp;scene=21#wechat_redirect">文本分类有哪些论文中很少提及却对性能有重要影响的tricks？</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>文本分类</tag>
      </tags>
  </entry>
  <entry>
    <title>文本分类</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/3-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-textcnn1">1. TextCNN[1]</a></li>
<li><a href="#2-对textcnn-的分析-3">2. 对TextCNN 的分析 [3]</a></li>
<li><a href="#3-textrnn">3. TextRNN</a></li>
<li><a href="#4-textrcnn-4">4. TextRCNN [4]</a></li>
<li><a href="#5-han-5">5. HAN [5]</a></li>
<li><a href="#dpcnn">DPCNN</a></li>
<li><a href="#最后">最后</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-textcnn1">1. TextCNN[1]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g2iksw5rx2j30o70b0js1.jpg" alt></p>
<p> $x<em>i \in R^k$ 表示一个第$i$ 个词其 $k$ 维的词向量表示， 对于一个长度为 $n$ 的句子，有：$X = {x_1, \cdots, x_n} \in R^{n \times k}$， 我们通过对向量矩阵 $X$ 进行卷积操作来提取特征， 其中， $x</em>{i:i+j}$ 表示第 $i$ 个词到第 $i+j$ 个词，共 $j+1$ 个词。</p>
<p>对于一个窗口大小为 $h$ 的卷积核， 其 shape 为 $w \in R^{h \times k}$ ， 其提取特征的过程为：</p>
<script type="math/tex; mode=display">
c_i = f(w \cdot x_{i:i+h-1} + b); \quad b \in R， c_i \in R</script><p>1个卷积核对 $X$ 一次卷积的过程需要对 ${x<em>{1:h}, x</em>{2:h+1}, \cdots, x_{n-h+1:n}  }$ 分别进行卷积操作， 我们得到最终的特征表示： </p>
<script type="math/tex; mode=display">
c = [c_1, c_2, \cdots, c_{n-h+1}]  ; \quad c \in R^{n-h+1}</script><p>然后，文章对特征向量 $c$ 采用最大池化操作来提取最重要特征：</p>
<script type="math/tex; mode=display">
\hat{c} = Maxpool(c); \quad \hat{c} \in R</script><p>上述的过程描述的是一个卷积核对$X$ 提取特征的过程，而实际中，我们往往要采用多种窗口大小的卷积核，且每种窗口的卷积核有很多个，这里假设卷积核的窗口大小为 3， 4， 5， 卷积核的shape分别为 $3 \times k , 4 \times k, 5 \times k $， 其对应的卷积核数量为 $m_1, m_2, m_3$ 。</p>
<p>对于窗口大小为 3 的卷积核， 我们在一次卷积过后获得一个$C = (n-h+1) \times 1 \times m_1$的矩阵， 然后对该矩阵进行最大池化得到一个 $ 1 \times 1 \times m_1$  的向量， 该向量就是窗口为3 的卷积核所提取的全部特征。</p>
<p>同样的道理，窗口为 4 的卷积核所提取的特征为一个 $1 \times 1 \times m_2$ 的向量， 窗口为 5 的卷积核所提取的特征为一个 $1 \times 1 \times m_3$ 的向量。</p>
<p>最后我们将这三个向量拼接起来形成一个 $z \in R^{1 \times (m_1 + m_2 + m_3) }$ 的向量， 然后将该向量送入输出层：</p>
<script type="math/tex; mode=display">
y = w \cdot (z \circ r) + b; \quad r \in R^{m_1+m_2+m_3} \quad \text{r为 dropout}</script><h2><span id="2-对textcnn-的分析-3">2. 对TextCNN 的分析 [3]</span></h2><p>文章 [3] 对CNN 用于文本分类时的超参进行分析，这些超参包括： 词向量的选择，Filter 的大小， 卷积核的数量， 激活函数的选择， Pooling 策略， 正则化方法。</p>
<p><strong>Word Embedding</strong>  </p>
<p>文章比较了三种情况： Word2vec， Glove， Word2vec + Glove， 而实际上，三者的性能相差无几， 具体的依旧要看任务数据集，并没有定论，因此在实际的开发中，分别采用不同的预训练词向量来帮助我们更好的选择。</p>
<p><strong>Filter Size</strong></p>
<p>不同的数据集有其适合的 Filter Size， 文章建议区域大小为 <strong>1-10</strong> 内进行线性搜索， 但如果数据集中的句子长度较大(100+)， 那么可以考虑设置较大的 Filter Size。</p>
<p>不同size的 Filter 进行结合会对结果产生影响，当把与<strong>最优 Filter size 相近的Filter 结合时</strong>会提升效果，但如果与较远的Filter 结合会损害性能。因此，文章建议最初采用一个 Filter ， 调节 size 来找到最优的 Filter size， 然后探索最优Filter size的周围的各种 size 的组合。</p>
<p><strong>卷积核数量</strong></p>
<p>对于不同的数据集而言，卷积核的设置也有所不同，最好不要超过600，超过600可能会导致过拟合， 推荐范围为100-600。同时，卷积核数量增多，训练时间会变长，因此需要对训练效率做一个权衡。</p>
<p><strong>激活函数</strong></p>
<p>尽量多尝试激活函数， 实验表明，Relu， tanh 表现较佳。</p>
<p><strong>Pooling 策略</strong></p>
<p>实验分析得出， 1-max pooling 始终优于其他池化策略，这可能是因为在分类任务中，上下文的位置并不重要，且句子中的 n-granms 信息可能要比整个句子更具预测性。</p>
<p><strong>正则化方法</strong></p>
<p>实验表明，在输出层加上L2正则化并没有改善性能，dropout是有用的，虽然作用不明显，这可能是因为参数量很少，难以过拟合的原因所致。文章建议不要轻易的去掉正则化项，可以将 dropout 设置为一个较小值 (0-0.5)，推荐0.5 ， 对于L2， 使用一个相对较大的约束。 当我们增加卷积核数量时，可能会导致过拟合，此时就要考虑添加适当的正则项了。</p>
<h2><span id="3-textrnn">3. TextRNN</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g2k36w52s9j30cz0ap0t9.jpg" alt></p>
<p>以双向LSTM 或GRU来获取句子的信息表征， 以最后一时刻的 h 作为句子特征输入到 softmax 中进行预测， 很简单的模型，就不详细介绍了。</p>
<h2><span id="4-textrcnn-4">4. TextRCNN [4]</span></h2><p>说实话，这篇论文写的真乱，一个很简单的思想，看起来比 Transformer 还复杂，真的是有点醉， 不推荐看原论文，写的真的很冗余。 </p>
<p>文章的思想很简单：</p>
<ul>
<li>首先，对于单词 $w_i$ ， 获得其词向量表示 $e(w_i)$</li>
<li>然后， 采用双向 GRU 来获取每个词的上下文向量表示 $c_l(w_i), c_r(w_i)$ </li>
<li>为了更好的表示词的信息，文章将原始词向量 $e(w_i)$， 上下文表示$c_l(w_i), c_r(w_i)$  结合起来，形成词的新的向量表示，这里作者采用一个全连接网络来聚合这些信息：</li>
</ul>
<script type="math/tex; mode=display">
x_i = [c_l(w_i); e(w_i); c_r(w_i)] \\
y^{(2)} = tanh(W^{(2)} x_i + b^{(2)})</script><ul>
<li><p>采用最大池化来获取句子的最终表示：</p>
<script type="math/tex; mode=display">
y^{(3)} = max_{i=1}^n y_i^{(2)}</script></li>
<li><p>最后，采用一个softmax 来做分类：</p>
</li>
</ul>
<script type="math/tex; mode=display">
y^{(4)} = W^{(4)} y^{(3)} + b^{(4)} \\
p_i = \frac{exp(y_i^{(4)})}{\sum_{k=1}^n exp (y_k^{(4)})}</script><h2><span id="5-han-5">5. HAN [5]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g2ipy7d8q6j30bo0dyq3f.jpg" alt></p>
<p><strong>问题定义</strong></p>
<p>HAN 主要针对 document-level 的分类， 假定document 中有L个句子：${s<em>1, … s_L}$， 对于句子 $s_i$， 其包含有 $T_i$ 个单词：${ w</em>{i1}, \cdots, w<em>{it}, \cdots w</em>{iT}}$  。</p>
<p><strong>Word Encoder</strong></p>
<p>对于一个句子$s_i$ ，文章采用词向量矩阵将其做 Embedding， 然后采用双向 GRU 来获得该句子的上下文表示， 以第 $i$ 个句子中的第 $t$ 个单词为例：</p>
<script type="math/tex; mode=display">
x_{it} = W_e w_{it}, t \in [1,T] \\
\overrightarrow{h}_{it} = \overrightarrow{GRU}_{(x_{it})},  t \in [1,T] \\
\overleftarrow{h}_{it} = \overleftarrow{GRU}_{(x_{it})},  t \in [T,1] \\
h_{it} = [\overrightarrow{h}_{it}, \overleftarrow{h}_{it}]</script><p><strong>Word Attention</strong></p>
<p>考虑到在每个句子中，各个词对句子信息的贡献不同，因此此处引入一个注意力机制来提取语义信息，更好的获得句子的表示。</p>
<script type="math/tex; mode=display">
u_{it} = tanh(W_w h_{it} + b_w) \\
\alpha_{it} = \frac{exp(u_{it}^Tu_w)}{\sum_t exp(u_{it}^Tu_w)}; \quad  u_w \text{是随机初始化的，并参与训练} \\
s_i = \sum_t \alpha_{it}h_{it}</script><p><strong>Sentence Encoder</strong></p>
<p>一个 document 中有L个句子，我们需要对这L个句子的信息进行整合，但很明显，句子之间的信息是由关联的，因此文章采用双向GRU对句子信息进行综合来获得每个句子新的表示：</p>
<script type="math/tex; mode=display">
\overrightarrow{h}_{i} = \overrightarrow{GRU}_{(s_i)}, i \in [1, L] \\
\overleftarrow{h}_{i} = \overleftarrow{GRU}_{(s_i)}, i \in [L, 1] \\
h_i = [\overrightarrow{h}_i, \overleftarrow{h}_i]</script><p><strong>Sentence Attention</strong></p>
<p>考虑到在一个document中，各个句子的重要程度并不同，因此采用一个Attention 来对句子信息进行整合最终形成 document 的最终信息：</p>
<script type="math/tex; mode=display">
u_i = tanh(W_sh_i + b_s) \\
\alpha_i = \frac{exp(u_i^T u_s)}{\sum_i exp(u_i^T u_s)}; \quad  u_s \text{是随机初始化的，并参与训练} \\
v = \sum_i \alpha_i h_i</script><p><strong>Document Classification</strong></p>
<script type="math/tex; mode=display">
p = softmax(W_c v + b_c) \\
L = -\sum_d log p_{dj}</script><h2><span id="dpcnn">DPCNN</span></h2><h2><span id="最后">最后</span></h2><p>虽然文本分类是最简单的任务，但其在企业中应用最为广泛，十分适合初学者入门学习。</p>
<h2><span id="reference">Reference</span></h2><p>[1] TextCNN： Convolutional Neural Networks for Sentence Classification</p>
<p>[3] A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification</p>
<p>[4] Recurrent Convolutional Neural Network for Text Classification</p>
<p>[5] Hierarchical Attention Networks for Document Classification</p>
<p>[n] Large Scale Multi-label Text Classification With Deep Learning</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&amp;mid=2247485854&amp;idx=1&amp;sn=040d51b0424bdee66f96d63d4ecfbe7e&amp;chksm=9bb980faacce09ec069afa79c903b1e3a5c0d3679c41092e16b2fdd6949aa059883474d0c2af&amp;token=793481651&amp;lang=zh_CN&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&amp;mid=2247485854&amp;idx=1&amp;sn=040d51b0424bdee66f96d63d4ecfbe7e&amp;chksm=9bb980faacce09ec069afa79c903b1e3a5c0d3679c41092e16b2fdd6949aa059883474d0c2af&amp;token=793481651&amp;lang=zh_CN&amp;scene=21#wechat_redirect</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>文本分类</tag>
      </tags>
  </entry>
  <entry>
    <title>命名实体识别</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/4-%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#命名实体识别">命名实体识别</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#ner简介">NER简介</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="命名实体识别">命名实体识别</span></h1><h2><span id="前言">前言</span></h2><p>这篇文章的目的是对命名实体识别领域进行较为全面的综述，包括<strong>数据集，评估指标，传统模型，前沿模型，发展方向，个人思考</strong>等几大块，目的是为初学者提供一个较为前沿且易懂的学习文章。本文篇幅较长，请耐心阅读，别放在收藏内吃灰哦。</p>
<h2><span id="ner简介">NER简介</span></h2><h2><span id="reference">Reference</span></h2><p>[1] A Survey on Deep Learning for Named Entity Recognition</p>
<p>[2] CLUENER2020: FINE-GRAINED NAMED ENTITY RECOGNITION DATASET AND BENCHMARK FOR CHINESE  — 一个2020年最新的中文命名实体识别数据集</p>
<p>[3] LTP: A New Active Learning Strategy for Bert-CRF Based Named Entity Recognition</p>
<p>[4] Few-Shot Named Entity Recognition: A Comprehensive Study</p>
<p>[5] FLAT- Chinese NER Using Flat-Lattice Transformer</p>
<p>[6] Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition</p>
<p>[7] Lex-BERT- Enhancing BERT based NER with lexicons</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>命名实体识别</tag>
      </tags>
  </entry>
  <entry>
    <title>命名实体识别经验</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/4-%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E7%9A%84%E7%BB%8F%E9%AA%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#上游任务-序列标注">上游任务 - 序列标注</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="上游任务-序列标注">上游任务 - 序列标注</span></h1><h2><span id="前言">前言</span></h2><h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/152463745">工业界如何解决NER问题？12个trick，与你分享</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/77868938">nlp中的实体关系抽取方法总结</a></p>
<p><a href="https://mp.weixin.qq.com/s/v2HUU_2-cYgnFPqtXsd5Ug">一人之力，刷爆三路榜单！信息抽取竞赛夺冠经验分享</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/350669317">NER标注数据少，怎么办？</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/347457328">ICLR2021 中唯一录取的NER论文：NER数据存在漏标怎么办？</a></p>
<p><a href="https://www.zhihu.com/people/lou-jie-9/posts">jayjay</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/166496466">流水的NLP铁打的NER：命名实体识别实践与探索</a></p>
<p><a href="https://tech.meituan.com/2020/07/23/ner-in-meituan-nlp.html">美团搜索中NER技术的探索与实践</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>命名实体识别</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态命名实体识别</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/4-%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#多模态命名实体识别">多模态命名实体识别</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="多模态命名实体识别">多模态命名实体识别</span></h1><h2><span id="reference">Reference</span></h2><p>RpBERT: A Text-image Relation Propagation-based BERT Model for Multimodal NER  2021-2</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>命名实体识别</tag>
      </tags>
  </entry>
  <entry>
    <title>文本相似度</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/5-%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#上游任务-文本相似度">上游任务 - 文本相似度</a><ul>
<li><a href="#1-孪生网络12">1. 孪生网络[1][2]</a><ul>
<li><a href="#1-siamese-recurrent-architectures1">1. <strong>Siamese Recurrent Architectures</strong>[1]</a></li>
<li><a href="#2-siamese-recurrent-networks-2">2. Siamese Recurrent Networks [2]</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="上游任务-文本相似度">上游任务 - 文本相似度</span></h1><h2><span id="1-孪生网络12">1. 孪生网络[1][2]</span></h2><h3><span id="1-siamese-recurrent-architectures1">1. <strong>Siamese Recurrent Architectures</strong>[1]</span></h3><h3><span id="2-siamese-recurrent-networks-2">2. Siamese Recurrent Networks [2]</span></h3><h2><span id="reference">Reference</span></h2><p>[1] Siamese Recurrent Architectures for Learning Sentence Similarity</p>
<p>[2] Learning Text Similarity with Siamese Recurrent Networks</p>
<p><a href="https://github.com/nlpyang/BertSum">https://github.com/nlpyang/BertSum</a></p>
<p><a href="https://github.com/google-research/bert/issues/164">https://github.com/google-research/bert/issues/164</a></p>
<p>Using Prior Knowledge to Guide BERT’s Attention in Semantic Textual Matching Tasks  -2021</p>
<p><a href="https://zhuanlan.zhihu.com/p/358260721">https://zhuanlan.zhihu.com/p/358260721</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>文本匹配</tag>
      </tags>
  </entry>
  <entry>
    <title>语义匹配</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/5-%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#文本相似度">文本相似度</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#文本匹配简介">文本匹配简介</a><ul>
<li><a href="#0-问题简介">0. 问题简介</a></li>
<li><a href="#1-文本匹配的挑战">1. 文本匹配的挑战</a></li>
<li><a href="#2-深度学习文本匹配模型3">2. 深度学习文本匹配模型[3]</a></li>
</ul>
</li>
<li><a href="#单粒度语义文本表达">单粒度语义文本表达</a><ul>
<li><a href="#1-dssm2013">1. DSSM,2013</a></li>
<li><a href="#2-csddm-2014">2. CSDDM, 2014</a></li>
</ul>
</li>
<li><a href="#2-多粒度语义文本表达">2. 多粒度语义文本表达</a></li>
<li><a href="#manm">MANM</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="文本相似度">文本相似度</span></h1><p>tags: NLP</p>
<p>500 questions ： 18.5.6 如何做语义匹配？</p>
<hr>
<p>[TOC]</p>
<h2><span id="前言">前言</span></h2><p>文本匹配算是一个基础性的任务，其可以应用到其他上游任务中如：信息检索，问答系统，对话等，这些上游任务本质上还是文本匹配的机制，只不过关注的核心在于，不同的任务需要不同的匹配机制。</p>
<h2><span id="文本匹配简介">文本匹配简介</span></h2><h3><span id="0-问题简介">0. 问题简介</span></h3><p>文本匹配在信息检索，自动问答等任务有着广泛的应用，而随着文本匹配逐渐从传统的文本匹配模型向深度文本匹配模型转移，在不同任务上的应用也有很大的改变。</p>
<p>文本匹配问题可以简述为，一个样本中有两段文本：$s_1, s_2$， 在搜索引擎中，二者分别为查询项和文档；在问答系统中，两者分别为问题和答案， 文本匹配的目的是预测二者之间的匹配程度 $r$。</p>
<p>在实际开发中，问题往往会抽象成一个排序问题，即给定一段文本 $s_1$， 然后给定另一个文本列表，其中包含多个文本段$S_2$， 目标是在这个文本列表中筛选出与给定文本 $s_1$ 匹配的文本。 文本匹配模型回计算 $s_1$ 与 其他文本的相似度。</p>
<p>最关键的是，语义匹配详细可以划分为5个子任务，分别是：</p>
<ul>
<li>相似度计算</li>
<li>问答匹配</li>
<li>对话匹配</li>
<li>自然语言推理</li>
<li>信息检索中的匹配</li>
<li>阅读理解匹配</li>
</ul>
<h3><span id="1-文本匹配的挑战">1. 文本匹配的挑战</span></h3><ul>
<li>词语匹配的多元性： 不同词可以表示同一个语义； 同一个词在不同语境下会有不同的语义。</li>
<li>短语匹配的结构性：中文中这种词非常常见， 如：“机器学习” 与 “学习机器” 是两个不同的概念</li>
<li>文本匹配的层次性：文本是以层次化的方式组织起来的，词语组成短语，短语组成句子，句子形成段落，段落形成篇章，在设计模型时，如何考虑不同层次的匹配信息是十分重要的。</li>
</ul>
<h3><span id="2-深度学习文本匹配模型3">2. 深度学习文本匹配模型[3]</span></h3><p>根据特征提取的不同方式，深度学习在文本匹配模型中的应用大致可分为三类：</p>
<ul>
<li>基于单语义文本表达的深度学习模型： 将单个文本表达成一个稠密向量，然后计算两个向量之间的相似度来作为文本的匹配度[1]   [2]。</li>
<li>基于多语义文本表达的深度学习模型：认为单一粒度的向量来表示一段文本不够精细，需要多语义的简历表达，即分别提取词，短语，句子等不同级别的表达向量，再计算不同粒度向量间的相似度作为文本间的匹配度</li>
<li>直接建模匹配模式的深度学习模型：认为匹配问题需要更惊喜的建模匹配的模式，即需要更早的让两段文本进行交互，然后挖掘文本交互后的模式特征，综合得到文本间的匹配度。</li>
</ul>
<h2><span id="单粒度语义文本表达">单粒度语义文本表达</span></h2><h3><span id="1-dssm2013">1. DSSM,2013</span></h3><h3><span id="2-csddm-2014">2. CSDDM, 2014</span></h3><p>ARC-I — 卷积</p>
<p>CNTN — 卷积</p>
<p>LSTM-RNN</p>
<h2><span id="2-多粒度语义文本表达">2. 多粒度语义文本表达</span></h2><p>MultiGranCNN</p>
<p><a href="https://github.com/NTMC-Community/awesome-neural-models-for-semantic-match">https://github.com/NTMC-Community/awesome-neural-models-for-semantic-match</a></p>
<p><a href="https://github.com/sebastianruder/NLP-progress/blob/master/english/semantic_textual_similarity.md">https://github.com/sebastianruder/NLP-progress/blob/master/english/semantic_textual_similarity.md</a></p>
<h2><span id="manm">MANM</span></h2><h2><span id="reference">Reference</span></h2><p>[1]  Siamese Recurrent Architectures for Learning Sentence Similarity</p>
<p>[2]  Learning Text Similarity with Siamese Recurrent Networks</p>
<p>[3]  深度文本匹配综述</p>
<p>[3]</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>文本匹配</tag>
      </tags>
  </entry>
  <entry>
    <title>无监督文本匹配</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/5-%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#无监督文本匹配">无监督文本匹配</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="无监督文本匹配">无监督文本匹配</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://www.zhihu.com/question/354129879">BERT模型可以使用无监督的方法做文本相似度任务吗？</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>文本匹配</tag>
      </tags>
  </entry>
  <entry>
    <title>BERT可解释性</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/BERT%20%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#bert-可解释性">BERT 可解释性</a><ul>
<li><a href="#syntactic-knowledge">Syntactic knowledge</a></li>
<li><a href="#semantic-knowledge">Semantic Knowledge</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="bert-可解释性">BERT 可解释性</span></h1><h2><span id="syntactic-knowledge">Syntactic knowledge</span></h2><p>Open Sesame: Getting inside BERT’s Linguistic Knowledge</p>
<p>Patient Knowledge Distillation for BERT Model Compression.</p>
<p>Linguistic Knowledge and Transferability of Contextual Representations.</p>
<p>Parsing as pretraining.</p>
<p>Are pre-trained language models aware of phrases? simple but strong baselines for grammar induction.</p>
<p>Inducing syntactic trees from BERT representations</p>
<p>Do attention heads in BERT track syntactic dependencies?</p>
<p> What does BERT learn about the structure of language?</p>
<p>A Structural Probe for Finding Syntax in Word Representations.</p>
<p>Emergent linguistic structure in artificial neural networks trained by self-supervision.</p>
<p>BERT is not a knowledge base (yet): Factual knowledge vs. name-based rea- soning in unsupervised qa</p>
<p>IsSuper- vised Syntactic Parsing Beneficial for Language Understanding? An Empirical Investigation.</p>
<p>What BERT is not: Lessons from a new suite of psy- cholinguistic diagnostics for language models</p>
<h2><span id="semantic-knowledge">Semantic Knowledge</span></h2><p>What BERT is not: Lessons from a new suite of psy- cholinguistic diagnostics for language models</p>
<p>What do you learn from context? Probing for sentence structure in contextualized word representations.</p>
<p>Do NLP Models Know Numbers? Probing Numeracy in Embeddings.</p>
<p> What’s in a Name? Are BERT Named Entity Representations just as Good for any other Name?</p>
<p>BERT Rediscovers the Classical NLP Pipeline.</p>
<p>Investigating Entity Knowledge in BERT with Simple Neural End- To-End Entity Linking</p>
<p>Visualizing and Measuring the Geometry of BERT</p>
<p>BERT Rediscovers the Classical NLP Pipeline</p>
<p>理解BERT每一层都学到了什么</p>
<p><a href="https://www.zhihu.com/search?type=content&amp;q=bert  聚类">https://www.zhihu.com/search?type=content&amp;q=bert%20%20%E8%81%9A%E7%B1%BB</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Recent Advances in Language Model Fine-tuning</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/Recent%20Advances%20in%20Language%20Model%20Fine-tuning/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#recent-advances-in-language-model-fine-tuning">Recent Advances in Language Model Fine-tuning</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="recent-advances-in-language-model-fine-tuning">Recent Advances in Language Model Fine-tuning</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://www.aclweb.org/anthology/P18-1031.pdf">Universal Language Model Fine-tuning for Text Classification</a></p>
<p><a href="https://www.aclweb.org/anthology/2020.acl-main.244.pdf">Pretrained Transformers Improve Out-of-Distribution Robustness</a></p>
<p><a href="https://ruder.io/thesis/neural_transfer_learning_for_nlp.pdf#page=62">Neural Transfer Learning for Natural Language Processing</a></p>
<p><a href="https://www.aclweb.org/anthology/N19-1213.pdf">An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models</a></p>
<p><a href="https://www.aclweb.org/anthology/P19-1335.pdf">Zero-Shot Entity Linking by Reading Entity Descriptions</a></p>
<p><a href="https://www.aclweb.org/anthology/D19-1433.pdf">Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling</a></p>
<p><a href="https://www.aclweb.org/anthology/P19-1373.pdf">Pretraining Methods for Dialog Context Representation Learning</a></p>
<p><a href="https://www.aclweb.org/anthology/2020.acl-main.740.pdf">Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>一文缕清预训练语言模性发展脉络</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E4%B8%80%E6%96%87%E6%BB%A4%E6%B8%85%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E8%84%89%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#一文滤清预训练语言模型发展脉络">一文滤清预训练语言模型发展脉络</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#1-bert-之前">1. BERT 之前</a><ul>
<li><a href="#11-从-word-embedding-到-elmo">1.1 从 Word Embedding 到 ELMO</a></li>
<li><a href="#12-fine-tuning-pretraining-gpt-的诞生">1.2 Fine-tuning pretraining：  GPT 的诞生</a></li>
<li><a href="#4-预训练新时代bert">4. 预训练新时代：BERT</a></li>
</ul>
</li>
<li><a href="#2-bert-之后">2. BERT 之后</a><ul>
<li><a href="#1-预训练-知识图谱">1. 预训练 + 知识图谱</a></li>
<li><a href="#2-预训练-自然语言生成">2. 预训练 +  自然语言生成</a></li>
<li><a href="#3-预训练-多任务学习">3. 预训练 + 多任务学习</a></li>
<li><a href="#4-改进语言模型">4. 改进语言模型</a></li>
<li><a href="#5-预训练-中文领域">5. 预训练 + 中文领域</a></li>
<li><a href="#6-预训练-精细调参">6. 预训练 + 精细调参</a></li>
<li><a href="#7-预训练-基础单元">7. 预训练+ 基础单元</a></li>
</ul>
</li>
<li><a href="#最后">最后</a></li>
<li><a href="#reference">Reference</a><ul>
<li><a href="#1-ar-与-ae-语言模型">1. AR 与 AE 语言模型</a></li>
</ul>
</li>
<li><a href="#bert-诞生之前">BERT 诞生之前</a></li>
<li><a href="#gpt-系列">GPT 系列</a></li>
<li><a href="#bert-系列">BERT 系列</a></li>
<li><a href="#多任务学习">多任务学习</a></li>
<li><a href="#中文领域">中文领域</a></li>
<li><a href="#融入知识">融入知识</a></li>
<li><a href="#多语言">多语言</a></li>
<li><a href="#模型压缩">模型压缩</a></li>
<li><a href="#文本生成">文本生成</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="一文滤清预训练语言模型发展脉络">一文滤清预训练语言模型发展脉络</span></h1><h2><span id="前言">前言</span></h2><p>预训练语言模型的诞生已经3年多了，其衍生的各个子领域可谓是百花齐放，这篇文章对我这几年看过的预训练语言模型方面的 paper 进行一个梳理，对于每个子领域有遗漏的欢迎大家评论补充。</p>
<p>这篇文章会以月为单位更新，拭目以待。</p>
<h2><span id="1-bert-之前">1. BERT 之前</span></h2><h3><span id="11-从-word-embedding-到-elmo">1.1 从 Word Embedding 到 ELMO</span></h3><p>考虑到词向量不能解决词的多义性问题，在 ELMO 之前，我们往往采用双向 LSTM 来减轻这种问题，但这毕竟治标不治本，对于大数据集好说， 深层双向 LSTM 的确能够很好的缓解这种问题，但对于小数据集，往往没啥效果。</p>
<p>为了解决这种多义性问题，ELMO 在训练语言模型时采用双向 LSTM 。 不同层的 LSTM 能够把握不同粒度和层级的信息，比如浅层的 LSTM 把握的是单词特征， 中层的 LSTM 把握 句法 特征， 深层的 LSTM 把握语义特征， 对于不同的任务来说， 不同的特征起到了不同的作用。 </p>
<p>举例来说： 文本分类问题为何 ELMO 与 BERT 所起到的作用与 Word2Vec 相差无几，这就是因为对于分类问题来说， n-gram 信息起到很大的作用，而这本质就是单词特征； 但对于阅读理解领域， ELMO 与 BERT 就能大幅提高模型效果，这也是因为 语法与语义特征对于阅读理解这种深层次问题是十分重要的。</p>
<p>ELMO 在迁移到下游任务时，会将不同层的特征采用<strong>加权求和</strong>的方式来获得每个词的最终表示。</p>
<p>事实证明， ELMO 的确解决了多义性问题， 词性也能对应起来了。</p>
<p>但， ELMO 的缺点也十分明显：</p>
<ul>
<li><strong>LSTM 特征抽取能力远弱于 Transformer ， 并行性差</strong></li>
<li><strong>拼接方式双向融合特征融合能力偏弱</strong></li>
</ul>
<h3><span id="12-fine-tuning-pretraining-gpt-的诞生">1.2 Fine-tuning pretraining：  GPT 的诞生</span></h3><p>GPT 虽然不是第一个预训练语言模型，但它的出现更具<strong>开创意义</strong>。其特点很明显：</p>
<ul>
<li>采用<strong>单向 Transformer</strong> 作为特征抽取器</li>
<li>采用二阶段： 预训练 + 微调  来适配下游任务</li>
</ul>
<p>GPT 1.0 与 GPT 2.0 的出现说明了一下几点：</p>
<ul>
<li>高质量，大规模的预训练数据集是提升性能的根本</li>
<li>深层的 Transformer 模型具有更强的表示能力</li>
</ul>
<p>至少，从目前为止， 业界还没有探索到数据与模型的极限，即仅仅堆数据，加深模型这条路，还没有走完。</p>
<h3><span id="4-预训练新时代bert">4. 预训练新时代：BERT</span></h3><p>GPT 虽然很强，但由于其基于 AR 模型且目前很多排行榜都是基于<strong>自然语言理解</strong>的，因此， GPT 在这方面无法与 BERT 的表现相抗衡。但 GPT 在生成方面是 BERT 无法比拟的， 就问你BERT： 会编故事吗？</p>
<p>BERT 主要分为两大部分： <strong>Masked LM</strong> 与 <strong>NSP</strong> (Next Sentence Prediction)。</p>
<p>BERT 由于其采用 AE 模型，MASK 操作所带来的缺陷依旧存在：</p>
<ul>
<li>预训练与微调阶段不匹配的问题，这点 BERT 提供了一个策略来减轻该问题</li>
<li>Mask 掉的  token 之间关系被忽略的问题</li>
</ul>
<p>此外，由于数据量，模型都十分大，如果每次只 mask 一个token，那么整个训练过程将变得极为漫长， 文章采用 mask 15% 的操作，是一个经验性的选择，是对模型训练效果与训练时长做出了一个权衡。</p>
<p>至于 NSP 任务，事实证明其在句子关系上的确起到了一定的作用，对于某些任务的确有帮助，但也有文章指出，其实用处不大，这点后面会详细讨论。</p>
<h2><span id="2-bert-之后">2. BERT 之后</span></h2><p>BERT 之后，有诸多改进方案，无论是对语言模型进行改进，融合知识图谱进行改进，多任务学习+预训练语言模型等， 这些文章都具有很大的价值，且质量都很高，本节的目的是对最近的这些模型进行一个全面的总结，帮助人们理清思路。对此，我画了一个直观的优化图，如下图所示：</p>
<h3><span id="1-预训练-知识图谱">1. 预训练 + 知识图谱</span></h3><p>预训练诞生之后， 在自然语言理解领域的确获得了很大的提升，尤其是在阅读理解领域，完全超过了人类的表现，虽然这并不表示真正的智能，但依旧意味着，NLP 已经逐渐走向成熟。</p>
<p>随之而来的问题十分明显， 如何表示知识， 有没有一种方式能够利用<strong>大规模语料+预训练语言模型</strong>使得模型能够学习到知识，从而应用到下游任务中。相信这个课题将是接下来一个十分核心的热点， 百度和清华就这方面做出了探讨， 具体可参加： <a href="https://zhuanlan.zhihu.com/p/69941989">Bert 改进： 如何融入知识</a></p>
<p>百度的文章中提出通过 mask 掉实体来获取实体的表示， 可以肯定的是，这样是能够更好的表示实体信息，但对于实体关系的把握，我个人觉得存疑，这是因为 mask 操作往往不仅仅 mask 掉一个实体，那么被 mask 掉的实体之间的关系如何把握？</p>
<p>我个人觉得可以设计一个<strong>精巧的任务</strong>来验证实体之间的关系， 可以通过知识图谱来生成一个语料， 如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">谢霆锋是张柏芝的__。 </span><br></pre></td></tr></table></figure>
<p>我们来预测空白处的位置， 判断其是否为 <code>丈夫</code>， <code>前夫</code> 之类的词， 这点需要根据具体的知识图谱而定。</p>
<p>清华的那篇文章，其先编码实体与实体间关系信息为一个向量， 然后将向量融合如预训练语言模型中进行训练， 而实际的操作更为复杂，俺个人觉得，这条路恐怕不是正确的路，不符合大道至简的原则，且任务太多，反而会引入噪声（个人对知识图谱研究不深，只是直观感觉）。</p>
<p>目前来看，个人觉得百度的路是对的。</p>
<h3><span id="2-预训练-自然语言生成">2. 预训练 +  自然语言生成</span></h3><p>这部分包含两个课题： </p>
<ul>
<li><strong>如何将 BERT 用于生成任务</strong></li>
<li><strong>如何设计一个适合于生成任务的语言模型</strong></li>
</ul>
<p>前面在 AR 与 AE 模型中已经介绍过为何 BERT 不适用于生成任务中， 那么随之而来的问题就是，既然预训练语言模型在自然语言理解中如此成功，那么我们怎么将其迁移到自然语言生成中呢， 这是一个很大的问题，个人觉得还需要1年以上的时间发展才能出现类似 Bert 这样的突破。</p>
<p>我个人前期看了两篇文章，大致提了一下思路：<a href="https://zhuanlan.zhihu.com/p/70663422">Bert 之后：预训练语言模型与自然语言生成</a></p>
<p>首先，对于第一个课题： <strong>如何将 BERT 用于生成任务。</strong> 从技术上来说， Encoder-Decoder 架构应该是首选的框架了， Encoder 输入原句子，Decoder 生成新句子，那么问题在于，Encoder 与 Decoder 如何表示？</p>
<p>对于 Encoder 端来说，我们只需要将 Bert 直接初始化就行；那么对于Decoder 端呢？ 也采用 Bert 初始化吗？ 要知道的是， Decoder 可是用来生成的， 如果你的 embedding 信息是通过 AE 模型训练得到的，那么生成效果估计会诡异的一批。 那么现在的问题就变成了， <strong>如何合理的初始化 Decoder 端的 embedding 信息呢？</strong></p>
<p>然后，我们再来谈谈第二个课题：<strong>如何设计一个适合于生成任务的语言模型。</strong> 目前从我看到的两篇文章中有两个思路：</p>
<ul>
<li>MASS 通过 mask 连续的<strong>一小段</strong>来试图即学习到理解知识，又学习到生成知识， 通过预测一段连续的 tokens 的确有助于提高模型生成方面的能力，但我个人觉得 mask 一小段信息所提升的生成能力十分有限， 且我认为这会影响到模型理解方面的能力。</li>
<li>UULM 就厉害了， 它涉及了一组语言模型： <strong>Unidirectional LM， Masked Bidirectional LM， Seq2Seq LM</strong>， 真的是有钱任性， 但这样直接堆语言模型的方式真的好吗？ 可以肯定的是， 不同语言模型的结合必然是接下来的一大趋势，但你这样直接堆是不是有点暴力啊，我个人感觉一般。</li>
</ul>
<p>那么，怎么去设计一个适合于生成任务的语言模型呢？ 我个人的想法在之前的博客提到了： 就人类而言， <strong>生成是基于理解的，而非独立的， 在大脑中， 理解与生成是两个区域， 先理解后生成，这才是正确的路。</strong> </p>
<p>因此，我个人觉得，接下来的一个思路应该是： <strong>理解的归理解，不断提高预训练语言模型在理解领域的表现， 对于生成，采用 Encoder-Decoder 框架。</strong> 在预训练的角度来说， 基于理解层面训练得到的模型， 然后分别初始化 Encoder-Decoder 端， 然后去预训练 Decoder 端的参数， Freeze/not Freeze Encoder 端的参数， 从而得到词在 Encoder 与 Decoder 的不同 Embedding， 然后再生成任务中的 Encoder-Decoder 中分别使用这两种 embedding。 </p>
<h3><span id="3-预训练-多任务学习">3.  预训练 + 多任务学习</span></h3><p>多任务学习就更好玩了，目前主要有两大代表： MT-DNN 与 ERNIE 2.0。</p>
<ul>
<li><p><strong>MT-DNN</strong> 又叫<strong>联合训练</strong>，其实就是将预训练语言模型用在多个任务中去接着预训练，从而提高模型泛化。具体来说，训练过程就是把所有数据合并在一起，每个batch只有单一任务的数据，同时会带有一个task-type的标志， 然后shuffle 之后进行训练。</p>
</li>
<li><p><strong>ERNIE</strong>  提出一个很好的思路： <strong>Continual Learning</strong>。 这点很有意思，就像人类做题一样， 它不像 MT-DNN 那样训练，而是这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">task1 --&gt; task1,task2 --&gt; task1, task2, task3</span><br></pre></td></tr></table></figure>
<p>即在训练后续任务时，前面的任务依旧要参与训练，主要是希望在学习后续任务时依旧记得前面任务的学习成果。</p>
</li>
</ul>
<p>我个人觉得 ERNIE 更符合我们人类的训练方式，不过具体的两种学习方式的表现还需要对比一下。 </p>
<p>回想我们人类的学习方式，其最初是专题训练，即每个 task 分别训练， 然后再进行总体训练，即所有 task 一起进行训练，然后发现自己的弱点，然后适当加强对某任务的训练，然后又进行总体训练，如此反复， 过程更像是这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(task1 or task 2 or task3)--&gt; (task1, task2), (task1, task3), (task2, task3) --&gt; (task1, task2, task3) --&gt; (task1 or task2 or task3) --&gt; ...</span><br><span class="line">专题训练 --&gt; 组合训练 --&gt; 总体训练 --&gt; 专题训练 --&gt; ...</span><br></pre></td></tr></table></figure>
<p>如果要保证训练新任务时不会过分忘记前面训练所得到的成果，似乎各个任务的训练样本比例以及训练时间更加重要。比如你做了一年的阅读理解，突然让你做单向选择，你答的也不会太好。</p>
<p>因此，我个人觉得， <strong>联合训练 + Continual Learning</strong> 是一个不错的思路。</p>
<p>不过我很疑惑的是，为何 7月份 有段时间 ERNIE 2.0 很火，我感觉它的创新性和各方面也就是 MT-DNN 一级别的啊，难道是宣传问题？ </p>
<h3><span id="4-改进语言模型">4. 改进语言模型</span></h3><p>要说起改进语言模型，当首推 <strong>XLNet</strong>， 毕竟前段时间也是刷了榜的，通过交换 token 位置来解决 mask 所带来的预训练与微调不匹配的问题， 这似乎比 BERT 更加优秀。</p>
<p>但从最近的实验看来，似乎又不是那么回事， XLNet 精巧的语言模型设计有没有超越 BERT， 目前学界还没有一个定论，RoBERTa 的出现似乎验证了在同等数据集下，XLNet 并不占优势， 通过精调模型参数，<strong>RoBERTa</strong> 获得了十分漂亮的结果。</p>
<p>而 XLNet 对此予以回击，又在同等条件下对比了 XLNet 与 BERT 模型， 又说明了 XLNet 效果的确要超过 BERT，emmm， 俺也不知道该相信哪个，反正我都会试试，哪个好用哪个。</p>
<p>XLNet 网上讲的很多了，我就不细说了。</p>
<h3><span id="5-预训练-中文领域">5. 预训练 + 中文领域</span></h3><p>十分推荐： <a href="https://github.com/ymcui/Chinese-BERT-wwm">BERT-WWM</a></p>
<p>对于中文领域，分词还是分字一直是一个问题，那么，到底是选分词，还是分字，这一直是一个大问题。 </p>
<p>BERT 无疑选择了分字这条路， ERNIE 通过融入知识，其实带来了部分分词的效果，那么在预训练语言模型中，分词到底有没有用， BERT-WWM 给出了答案。</p>
<p>通过采用 mask 词的方式， 在原有的 BERT-base 模型上接着进行训练， 这其实有种 词 + 字 级别组合的方式， 我在 <a href="https://zhuanlan.zhihu.com/p/66155616">深度学习时代，分词真的有必要吗</a> 中就有提到 字级别 与 词级别之间的差别， 而预训练语言模型能很好的组织二者，的确是件大喜事。</p>
<p>而事实证明， BERT-WWM 在中文任务上的确有着优势所在，具体就不细说了，至少目前来说，我们的中文预训练语言模型有三大选择了： BERT , ERNIE, BERT-WWM。</p>
<h3><span id="6-预训练-精细调参">6. 预训练 + 精细调参</span></h3><p>通过精细调参， BERT 能够发挥出更大的威力。 RoBERTa 证明了这一点。</p>
<p>此外， RoBERTa 认为 NSP 不仅不能带来下游任务的性能提升，反而会有所损害。 RoBERTa 的出现说明 BERT 本身的还有很多潜力要挖。</p>
<p>总的来说，这篇文章依旧是个苦工活，虽创新度一般，但价值很高。</p>
<h3><span id="7-预训练-基础单元">7. 预训练+ 基础单元</span></h3><p>大多数语言模型都采用 Transformer 来作为预训练的基本单元，那么 Transformer 有没有改进的空间呢？ 必然是有的。</p>
<p>XLNet 采用 Transformerxl 作为基本单元来解决长文本问题，Transformerxl 本质上就是 Transformer + 循环机制， 这样会带来并行性上的损失。</p>
<p>相信后续还会有更多的变体来解决 Transformer 的各种问题， 如果有对 Transformer 研究十分深的同学欢迎补充一下。</p>
<h2><span id="最后">最后</span></h2><p>本来打算再多研读几篇文章再写的，但是限于精力原因（忙于秋招），只能对前段时间看的论文大致总结， 提一些自己的思路，实在是无力去找新的 Paper 了。 </p>
<p>希望9月初会下 offer 雨打我的脸啊！！！</p>
<h2><span id="reference">Reference</span></h2><p>[1]  BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</p>
<p>[2]  ERNIE - Enhanced Language Representation with Informative Entities</p>
<p>[3]  ERNIE - Enhanced Representation through Knowledge Integration</p>
<p>[4]  ERNIE 2.0 - A Continual Pre-training Framework for Language Understanding</p>
<p>[5]  MASS - Masked Sequence to Sequence Pre-training for Language Generation</p>
<p>[6]  RoBERTa - A Robustly Optimized BERT Pretraining Approach</p>
<p>[7]  UNILM - Unified Language Model Pre-training for Natural Language Understanding and Generation</p>
<p>[8]  XLNet - Generalized Autoregressive Pretraining for Language Understanding</p>
<h3><span id="1-ar-与-ae-语言模型">1. AR 与 AE 语言模型</span></h3><p>AR：Autoregressive Language Modeling</p>
<p>AE： Autoencoding Language Modeling</p>
<ul>
<li><p>AR 语言模型：指的是，依据前面（或后面）出现的 tokens 来预测当前时刻的 token， 代表有 ELMO， GPT 等</p>
<script type="math/tex; mode=display">
forward: p(x) = \prod_{t=1}^T p(x_t | x_{<t}) \\
backward: p(x) = \prod_{t=T}^1 p(x_t | x_{>t})</script></li>
<li><p>AE 语言模型：通过<strong>上下文信息</strong>来预测被 mask 的 token， 代表有 BERT , Word2Vec(CBOW)</p>
<script type="math/tex; mode=display">
p(x) = \prod_{x\in Mask} p(x|context)</script></li>
</ul>
<p>二者有着它们各自的优缺点：</p>
<ul>
<li><p>AR 语言模型：</p>
<blockquote>
<ul>
<li><strong>缺点：</strong>它只能利用单向语义而不能同时利用上下文信息。 ELMO 通过双向都做AR 模型，然后进行拼接，但从结果来看，效果并不是太好。</li>
<li><strong>优点：</strong> 对生成模型友好，天然符合生成式任务的生成过程。这也是为什么 GPT 能够编故事的原因。</li>
</ul>
</blockquote>
</li>
<li><p>AE 语言模型：</p>
<blockquote>
<ul>
<li><strong>缺点：</strong> 由于训练中采用了 [MASK] 标记，导致预训练与微调阶段不一致的问题。 此外对于生成式问题， AE 模型也显得捉襟见肘，这也是目前 BERT 为数不多实现大的突破的领域。</li>
<li><strong>优点：</strong> 能够很好的编码上下文语义信息， 在自然语言理解相关的下游任务上表现突出。</li>
</ul>
</blockquote>
</li>
</ul>
<h2><span id="bert-诞生之前">BERT 诞生之前</span></h2><p>NNLM， Word2vec， ELMO， GPT 1.0</p>
<h2><span id="gpt-系列">GPT 系列</span></h2><h2><span id="bert-系列">BERT 系列</span></h2><p>spanBERT, Robert</p>
<h2><span id="多任务学习">多任务学习</span></h2><p>MT-DNN</p>
<h2><span id="中文领域">中文领域</span></h2><p>bert-wwm</p>
<h2><span id="融入知识">融入知识</span></h2><p>ERNIE 系列， ERNIE-THU, LIBERT, SenseBERT， KnowBERT， BERT-MK，K-BERT，BERT-WWM，WKLM，LUKE，SemBERT，sentiLR，SKEP，KG-BERT，KEPLER</p>
<h2><span id="多语言">多语言</span></h2><p>mBERT， XLM， Unicoder，XLM-R</p>
<h2><span id="模型压缩">模型压缩</span></h2><p>ALBERT， MiniLM， DistilBERT， TinyBERT， BERT-PKD， Distilled-BiLSTM</p>
<h2><span id="文本生成">文本生成</span></h2><p>MASS， UNILM，bart</p>
<p>T5， XLNET， TransformerXL</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用预训练模型</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#如何使用预训练模型">如何使用预训练模型</a></li>
<li><a href="#0-基础概念">0. 基础概念</a></li>
<li><a href="#1-是否要进行微调1">1. 是否要进行微调[1]</a></li>
<li><a href="#2-是否要进行再次预训练2">2. 是否要进行再次预训练[2]</a></li>
<li><a href="#3-bert-向量-vs-glove-向量">3. BERT 向量 vs Glove 向量</a><ul>
<li><a href="#1-数据规模">1. 数据规模</a><ul>
<li><a href="#2-语言特性">2. 语言特性</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="如何使用预训练模型">如何使用预训练模型</span></h2><h2><span id="0-基础概念">0. 基础概念</span></h2><ul>
<li><p><strong>预训练：</strong>指的是大公司通过大规模数据，大型网络所训练得出的模型，模型参数量往往很大</p>
</li>
<li><p><strong>训练：</strong> 指的是在预训练语言模型的基础上，再添加一些语料，接着训练语言模型，这对硬件的要求也很高，一般实验室玩不起。</p>
</li>
<li><p><strong>微调：</strong>指的是，不针对语言模型，而是针对特定任务，对上层模型与预训练语言模型进行微调，其实本质上还是对上层模型进行微调，对预训练语言模型进行微调在数据量较小的情况下所起到的作用不大。</p>
</li>
</ul>
<h2><span id="1-是否要进行微调1">1. 是否要进行微调[1]</span></h2><p>我们是直接采用训练好的向量还是用预训练语言模型进行微调呢？</p>
<p><img data-src="image/fine_tune.png" alt></p>
<p>『冰』表示freeze， 『火』表示微调的结果。</p>
<p>实际上，对于大多数的任务， BERT 进行微调的方式总是比提取向量再训练的方式能够获得更佳的效果。因此，在条件允许的情况下，推荐采用微调的方式。</p>
<h2><span id="2-是否要进行再次预训练2">2. 是否要进行再次预训练[2]</span></h2><p>答案是<strong>需要</strong>。</p>
<p>我们知道现在的预训练语料采用的都是百科，书籍等比较规范的数据，而实际业务中的数据千差万别，可以这么理解，预训练本身获得的是语料库中文本的分布，而如果预训练数据分布与业务数据分布偏差较大，会带来一些负面影响。 </p>
<p>因此，针对一些业务，如果数据与百科数据（预训练）差别非常大，先进行预训练，然后再进行微调是一种比较合适的方式。</p>
<p><img data-src="image/pre_train.png" alt></p>
<p>我们这里简单介绍下[2] 中的结论：</p>
<ol>
<li>在目标领域的数据集上继续预训练（DAPT）可以提升效果；目标领域与语言模型的原始预训练语料越不相关，DAPT效果则提升更明显。</li>
<li>在具体任务的数据集上继续预训练（TAPT）可以十分“廉价”地提升效果。</li>
<li>结合二者（先进行DAPT，再进行TAPT）可以进一步提升效果。</li>
<li>如果能获取更多的、任务相关的无标注数据继续预训练（Curated-TAPT），效果则最佳。</li>
</ol>
<h2><span id="3-bert-向量-vs-glove-向量">3. BERT 向量 vs Glove 向量</span></h2><p>这篇文章对比了 BERT ，Glove，random 三种向量， 我们都知道， BERT 相对于其他两种向量，其效果提升非常明显，本文基于此，探讨与传统词向量相比，BERT向量优异在何处呢？</p>
<p> 为了对比不同词向量的在下游任务的表现，本文采用了三个任务： </p>
<ul>
<li>NER： 词汇级别的任务</li>
<li>sentiment analysis：句子级别的任务</li>
<li>GLUE：句子对级别的任务</li>
</ul>
<p>为了更加纯粹对比三种向量，三种词向量在训练时均不微调，如果微调的话，就会难以判断是模型的作用还是词向量本身的作用。</p>
<h4><span id="1-数据规模">1. 数据规模</span></h4><p>实验表明，下游任务的训练数据对于不同的向量影响是十分不同的， 结果如下图所示：</p>
<p><img data-src="image/Context_1.png" alt></p>
<p><img data-src="image/Context_2.png" alt></p>
<p>从上图中我们可以看出</p>
<ul>
<li><p>随着数据规模的扩大，Glove 向量的表现与 BERT 向量的表现差距越来越小，我们看到当训练数据足够多的时候，Glove 在一些任务上能够获得略差于BERT的影响，但是在绝大多数情况下依旧比BERT 向量差很多，这说明 BERT 对于小数据集的优越性。</p>
</li>
<li><p>在简单任务上，随着数据量的增加， Glove 能达到 BERT 十分接近的效果</p>
</li>
</ul>
<h3><span id="2-语言特性">2. 语言特性</span></h3><p>接下来， 文章从三个角度来评测不同的向量：</p>
<ul>
<li><strong>the complexity of text structure：</strong>句子结构的复杂性</li>
<li><strong>Ambiguity in word usage</strong>: 单词的歧义性。</li>
<li><strong>Prevalence of unseen words</strong>：未登录词出现的概率</li>
</ul>
<p><img data-src="image/Context_3.png" alt></p>
<p>从结果来看，以 BERT 为代表的 Contextual embeddings 在解决一些文本结构复杂度高和单词歧义性方面有显著的效果，但是在未登录词方面 GloVe 代表的Non-Contextual embeddings 有不错的效果。</p>
<p>从上面的结论可以看出，</p>
<ul>
<li>在对于拥有大量训练数据和简单任务中，考虑算力和设备等，GloVe 代表的 Non-Contextual embeddings 是个不错的选择。</li>
<li>但是对于文本复杂度高和单词语义歧义比较大的任务，BERT代表的 Contextual embeddings 却有明显的优势。</li>
</ul>
<h2><span id="reference">Reference</span></h2><p>[1] Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks</p>
<p>[2]  To tune or not to tune? adapting pretrained representations to diverse tasks. </p>
<p>[3]  Contextual Embeddings: When Are They Worth It?</p>
<p>[4]  How to fine-tune BERT for Text Classification</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>如何更好的微调预训练语言模性</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%A6%82%E4%BD%95%E6%9B%B4%E5%A5%BD%E7%9A%84%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#如何更好的微调预训练语言模型">如何更好的微调预训练语言模型</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="如何更好的微调预训练语言模型">如何更好的微调预训练语言模型</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://ruder.io/recent-advances-lm-fine-tuning/"></a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>如何更好的与训练一个BERT</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%A6%82%E4%BD%95%E6%9B%B4%E5%A5%BD%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AABERT/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#如何更好的预训练一个bert">如何更好的预训练一个BERT</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="如何更好的预训练一个bert">如何更好的预训练一个BERT</span></h1><h2><span id="reference">Reference</span></h2><p>Train No Evil- Selective Masking for Task-Guided Pre-Training</p>
<p>Don’t Stop Pretraining- Adapt Language Models to Domains and Task</p>
<p><a href="https://ruder.io/recent-advances-lm-fine-tuning/">Recent Advances in Language Model Fine-tuning</a></p>
<p><a href="https://lilianweng.github.io/lil-log/2021/03/21/reducing-toxicity-in-language-models.html">Reducing Toxicity in Language Models</a></p>
<p>[1] BioBERT- a pre-trained biomedical language representation model for biomedical text mining</p>
<p>[2] SciBERT- A Pretrained Language Model for Scientific Text</p>
<p>[3] PatentBERT - Patent Classification by Fine-Tuning BERT Language Model</p>
<p>[4] FinBERT- Financial Sentiment Analysis with Pre-trained Language Models</p>
<p>[5] SentiBERT- A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics</p>
<p>[6] DomBERT- Domain-oriented Language Model for Aspect-based Sentiment Analysis</p>
<p><a href="https://zhuanlan.zhihu.com/p/269158593">熵简科技 AI Lab 开源金融领域中文预训练语言模型 FinBERT</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-BERT系列</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20BERT%20%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#bert-1">BERT [1]</a><ul>
<li><a href="#1-model-architecture">1 Model Architecture</a></li>
<li><a href="#2-input-representation">2 Input Representation</a></li>
<li><a href="#3-pre-training-tasks">3. Pre-training Tasks</a></li>
<li><a href="#4-pre-training-训练细节">4. Pre-training 训练细节</a></li>
<li><a href="#5-bert-结果">5. BERT 结果</a></li>
<li><a href="#6-优点与缺点">6. 优点与缺点</a></li>
</ul>
</li>
<li><a href="#roberta">RoBERTa</a><ul>
<li><a href="#1-训练数据比较">1. 训练数据比较：</a></li>
<li><a href="#2-dynamic-masking-vs-static-mask">2. dynamic masking vs static mask</a></li>
<li><a href="#3-数据格式与nsp">3. 数据格式与NSP</a></li>
<li><a href="#4-batch-size-大大大">4. batch size - 大大大</a></li>
<li><a href="#5-text-encoding">5. Text Encoding</a></li>
<li><a href="#6-训练细节">6. 训练细节</a></li>
</ul>
</li>
<li><a href="#4-t5-4">4. T5 [4]</a><ul>
<li><a href="#1-数据才是正道-c4">1. 数据才是正道 ：C4</a></li>
<li><a href="#2-text-to-text-模型归一">2. Text-to-Text： 模型归一</a></li>
<li><a href="#3-评测模型">3. 评测模型</a></li>
<li><a href="#4-baseline">4. Baseline</a></li>
<li><a href="#5-architectures">5. Architectures</a><ul>
<li><a href="#51-attention-mask-方式">5.1 Attention mask 方式</a></li>
<li><a href="#52-模型结构">5.2 模型结构</a></li>
</ul>
</li>
<li><a href="#6-unsupervised-objectives">6. unsupervised objectives</a><ul>
<li><a href="#61-high-level-approachs">6.1 High-level approachs</a></li>
<li><a href="#2-bert-mask-策略">2. bert Mask 策略</a></li>
</ul>
</li>
<li><a href="#7-pre-training-datasets">7. pre-training datasets</a><ul>
<li><a href="#71-预训练数据集的选择">7.1 预训练数据集的选择</a></li>
<li><a href="#72-预训练数据集的大小">7.2 预训练数据集的大小</a></li>
</ul>
</li>
<li><a href="#8-fine-tune">8. fine-tune</a></li>
<li><a href="#9-multi-task-learning">9. Multi-task learning</a></li>
<li><a href="#10-combining-multi-task-learning-with-fine-tuning">10. Combining multi-task learning with fine-tuning</a></li>
<li><a href="#11-scaling">11. scaling</a></li>
<li><a href="#12-t5-模型-put-it-all-together">12. T5 模型： put it all together</a></li>
</ul>
</li>
<li><a href="#questions">Questions</a><ul>
<li><a href="#1-为什么-bert-结果好于-elmo">1. 为什么 BERT 结果好于 ELMO</a></li>
<li><a href="#2-你觉得bert-有哪些需要改进的地方">2. 你觉得BERT 有哪些需要改进的地方</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="bert-1">BERT [1]</span></h2><h3><span id="1-model-architecture">1 Model Architecture</span></h3><p><img data-src="image/BERT.png" alt></p>
<p>Bert 模型结构上是一个多层，双向 Transformer encoder。</p>
<p>我们假定层数为 L， 隐层size为 H， self-attention heads 数目为A，那么有：</p>
<ul>
<li>$BERT_{BASE}$: L = 12, H=768, A= 12， 参数数量 110M, 即1.1亿</li>
<li>$BERT_{LARGE}$: L = 24, H=1024, A= 16， 参数数量 340M， 即3.4亿</li>
</ul>
<p>$BERT_{BASE}$ 与 OpenAI GPT 模型大小相同，主要是为了二者之间比较。 在下文，我们将双向Transformer称为 “ Transformer encoder”， 将单向（仅左）的Transformer称为 “Transformer decoder”。</p>
<h3><span id="2-input-representation">2 Input Representation</span></h3><p><img data-src="image/BERT_1.png" alt></p>
<ul>
<li><p>Token Embeddings：词向量，第一个单词是CLS标志，可以用于之后的分类任务</p>
</li>
<li><p>Segment Embeddings：区别两种句子，因为预训练不光做LM还要做以两个句子为输入的分类任务</p>
</li>
<li>Position Embeddings：<strong>和之前文章中的Transformer不一样，不是三角函数而是学习出来的</strong></li>
</ul>
<p>我们的 Input Representation 能够清楚的表示单一文本句子或句子对（如[Question, Answer]）。每个给定的token， 它的 input representation 是由 corresponding token， segment， 和 position embeddings 集合而成的。如图2所示。</p>
<p>细节如下：</p>
<ul>
<li>We use <strong>WordPiece embeddings</strong>  with a 30,000 token vocabulary. We denote split word pieces with ##.</li>
<li>We use <strong>learned positional embeddings</strong> with supported sequence lengths up to <strong>512 tokens</strong>.</li>
<li>The first token of every sequence is always the <strong>special classification embedding ([CLS]).</strong> </li>
<li>Sentence pairs are packed together into a single sequence. We differentiate the sentences in two ways.<ul>
<li>First, we separate them with a <strong>special token ([SEP]).</strong> </li>
<li>Second, we add a learned sentence A embedding to every token of the first sentence and a sentence B embedding to every token of the second sentence.</li>
</ul>
</li>
</ul>
<h3><span id="3-pre-training-tasks">3. Pre-training Tasks</span></h3><p>BERT 使用两个新的无监督预测任务来训练。</p>
<p><strong>Task 1. Mased LM  - MLM</strong></p>
<p>为了训练深度双向表征，我们随机遮蔽输入 token 的某些部分，然后预测被遮住的 token。我们将此称为“masked LM”（MLM，类似于我们的完形填空）。在这种情况下，对应于遮蔽 token 的最终隐藏向量会输入到 softmax 函数中，并如标准 LM 中那样预测所有词汇的概率。在所做的所有实验中，我们随机遮住了每个序列中 15% 的 WordPiece token。</p>
<p>虽然该方法能够获得双向预训练模型，但该方法有两个弱点：</p>
<ol>
<li>训练与微调阶段的不一致性，因为训练阶段采用了 [MASK] 而 fine-tune 阶段并没有。 为了减轻该问题， we do not always replace “masked” words with the actual [MASK] token. 具体做法如下：</li>
</ol>
<blockquote>
<p> 假如我们有一句话， my dog is hairy ， 被选中的词为hairy，数据生成器并不总是将hairy替换为[MASK]，此时的过程如下：</p>
<ul>
<li>80% 情况下： 用[MASK] 替换 hairy</li>
<li>10% 情况下： 随机选一个词如apple 来替换hairy</li>
<li>10%: 不改变这句话</li>
</ul>
</blockquote>
<ul>
<li>only 15% of tokens are predicted in each batch,  which suggests that more pre-training steps may be required for the model to converge.</li>
</ul>
<p><strong>Task 2. Next Sentence Prediction - NSP</strong></p>
<p>语言模型不能获取两个句子之间的关系，因此我们预训练了一个  binarized next sentence prediction  task， 该任务可以从任意单语语料库中轻松生成。 </p>
<p>具体来说，我们选定一个句子A，B作为预训练样本，B有50%的可能是A的下一句，也有50%的可能是语料库的随机句子。举例而言：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- Input: [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]</span><br><span class="line">- Label: IsNext</span><br><span class="line"></span><br><span class="line">- Input: [CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]</span><br><span class="line">- Label: NotNext</span><br></pre></td></tr></table></figure>
<h3><span id="4-pre-training-训练细节">4. Pre-training 训练细节</span></h3><p>预训练数据集采用 <strong>BooksCorpus（800M）</strong>和 <strong>English Wikipedia</strong> 语料。</p>
<p>为了生成每个训练输入序列，我们从语料库中抽取两段文本，我们将其称为“句子”，尽管它们通常比单个句子长得多(但也可以短一些)。第一句记做 A embedding，第二句记做 B embedding。 50% 的情况下B是A的真正后一句话， 50%情况下B是一个随机句子。两个句子的总长度 &lt;= 512 个 tokens。</p>
<p>我们设 batch_size = 256 ，则有256 sequences * 512 tokens = 128,000 tokens/batch， 训练步数为1000000步，大约33亿 word corpus 中的40个epoch。优化算法采用 Adam， 学习率设为 1e-4， $\beta_1 = 0.9， \beta_2 = 0.999$，  L2 权重衰减为 0.01。 在所有层使用dropout， 概率为0.1. 我们采用gelu激活函数而非relu。 训练损失为  the sum of the mean masked LM likelihood and mean next sentence prediction likelihood.</p>
<ul>
<li>$BERT_{BASE}$ 在 16个TPU芯片上进行训练</li>
<li>$BERT_{LARGE}$ 在 64个TPU 芯片上进行训练</li>
</ul>
<h3><span id="5-bert-结果">5. BERT 结果</span></h3><p><img data-src="image/BERT_3.png" alt></p>
<h3><span id="6-优点与缺点">6. 优点与缺点</span></h3><p><strong>优点：</strong></p>
<p><strong>缺点：</strong></p>
<ul>
<li>采用 mask 机制，导致预训练与微调阶段的不一致</li>
<li>每个batch只有15%的token被预测，所以BERT收敛得比left-to-right模型要慢</li>
</ul>
<h2><span id="roberta">RoBERTa</span></h2><p>RoEBERTa 其实是对BERT的进一步探索，在同等参数量的情况下，探索了 BERT 关于数据量，模型架构，训练任务等问题，主要包含以下几个方面：</p>
<h3><span id="1-训练数据比较">1. 训练数据比较：</span></h3><p>BERT采用了BOOKCORPUS 和英文维基百科， 总共16GB。而 RoBERTa采用了BOOKCORPUS + 英文维基百科+ CC-NEWS+OPENWEBTEXT+STORIES， 总共160GB。</p>
<p>Roberta 于bert 都采用 512 个token 作为序列长度，但与bert不同的是， robert 不会随机掺杂一些短句，这意味着 roberta 采用的都是长句。</p>
<h3><span id="2-dynamic-masking-vs-static-mask">2. dynamic masking vs static mask</span></h3><p>在同等参数量级（bert-base）情况下，比较动态mask与静态mask的差别。</p>
<ul>
<li><strong>静态mask：</strong>Bert 在准备训练数据时，每个样本只会进行一次随机mask，每个epoch都重复使用，后续的每个训练步都采用相同的mask。</li>
<li><strong>修改版静态mask：</strong> 在预处理时将数据集拷贝10次，每份数据采用不同的mask。</li>
<li><strong>动态mask</strong>：不在预处理时进行mask，而是在每次向模型输入时动态生成mask</li>
</ul>
<p><img data-src="image/roberta_1.png" alt></p>
<p>从上表可以看出，修改版静态mask的确能够略微提升结果，而修改版静态mask结果与动态mask相差无几。</p>
<h3><span id="3-数据格式与nsp">3. 数据格式与NSP</span></h3><p>本节探讨输入训练数据的格式以及NSP任务的必要性。主要通过四个对比实验</p>
<p><img data-src="image/roberta_2.png" alt></p>
<ul>
<li><strong>Segment-pair + NSP：</strong>与bert一样。输入包含两个 segment，这两个segment可能会来自同一个文档或不同文档，两个segment 的token 数均小于 512，预训练任务包含 MLM 与 NSP。</li>
<li><strong>Sentence+pair + NSP：</strong>输入包含两个 sentence，两个句子可能来自同一文档或不同文档，两个句子 token 数均少于 512。预训练任务包含 MLM 与 NSP。</li>
<li><strong>Full-sentences：</strong>输入只有一部分，来自同一个文档或不同文档的连续句子，token总数不超过512。输入可能跨越文档边界，如果跨文档，则在上一个文档末尾添加文档边界token。不包含NSP任务。</li>
<li><strong>Doc-sentences：</strong>输入只有一部分，输入来自同一个文档的连续句子，token总数不超过512。预训练不包含 NSP 任务。</li>
</ul>
<p>通过四个对比实验我们发现：</p>
<ul>
<li>Segment-pair 较好于 sentence-pair，可能是因为 segment 能够学习到长距离依赖关系。</li>
<li>Doc-sentences 几乎在所有任务中表现最佳，这意味着 NSP 任务没有什么用</li>
<li>Doc-sentences 略好于 Full-sentences。</li>
</ul>
<h3><span id="4-batch-size-大大大">4. batch size - 大大大</span></h3><p>以往的神经机器翻译研究表明，采用非常大的mini-batches进行训练时候，搭配适当提高学习率既可以提高优化速度，又可以提高最终任务性能。</p>
<p>Bert 采用 batch-size 256，训练了1M 步。 此处比较了在保证总步数（batch_size * 步数）不变的情况下，增大 batch_size 所带来的变化。</p>
<p><img data-src="image/roberta_3.png" alt></p>
<p>通过上表可以发现，提高 batch_size，在总步数不变的情况下，增大学习率，最终获得的优化效果相差无几。</p>
<h3><span id="5-text-encoding">5. Text Encoding</span></h3><p>BERT 采用 wordpiece 来进行分词</p>
<p>roberta 采用BPE 来分词</p>
<h3><span id="6-训练细节">6. 训练细节</span></h3><p><img data-src="image/roberta_4.png" alt></p>
<p>通过上表我们看到，增加数据量带来的效果是显而易见的，而训练时间越长，获得的结果越好，但训练到一定程度，增益已经非常缓慢了。</p>
<h2><span id="4-t5-4">4. T5 [4]</span></h2><p>T5 本质上就是解决了人们对如何才能训练一个好的 PTM 的疑问。</p>
<h3><span id="1-数据才是正道-c4">1. 数据才是正道 ：C4</span></h3><p><strong>T5再次证明了数据的力量，没有什么是数据搞不定的，如果搞不定，那么再加点。</strong></p>
<p>搞数据一直是一个工作量比较大的事情，在实际业务中也必不可少，C4 的构建过程对实际还是有参考价值的。整个构建过程如下：</p>
<blockquote>
<p><strong>首先，</strong>从Common Crawl 上获取了大量的文本，然后经过清洗后获得了750GB的高质量数据文本。 作为一名算法工程师，清洗数据在所难免，这里强调一下数据清洗的重要性。</p>
</blockquote>
<p>文章中提到的清洗方法值得学习一下：</p>
<ul>
<li>只保留以标点符号结尾的句子，这些表点符号包括句号，感叹号，问号以及引号。</li>
<li>删除任何带有“淫秽，色情，暴力”等词的句子，这些词可以可以从 <a href="https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words">List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words</a> 查到。</li>
<li>删除所有带有JavaScript这一词的行。</li>
<li>包含 “lorem ipsum” 的页面。</li>
<li>删除所有带花括号（编程语言）的页面。</li>
<li>对于连续三句话重复出现的情况，只保留一个。</li>
</ul>
<h3><span id="2-text-to-text-模型归一">2. Text-to-Text： 模型归一</span></h3><p>这部分算是本文真正的创新点之一，即将所有任务归结到一个大的框架下，即：Text-to-Text Transformer，其本质上是一个采用 标准Transformer（Attention is all you need） 来搭建的 Encoder-Decoder 框架，统一框架这就意味着对于所有的NLP任务，都采用一样的模型，一样的损失函数，一样的解码过程。其实本质上还是 Seq2Seq， 换汤不换药。</p>
<p>我们知道，NLP任务中包含多种任务，其实主要是生成任务，分类任务以及回归任务，Text-To-Text 对各种任务提出了统一的框架。</p>
<ul>
<li><p><strong>生成任务：</strong> 直接通过Encoder-Decoder生成句子即可。思路跟传统的Encoder-Decoder一样。</p>
</li>
<li><p><strong>分类任务</strong>： 直接生成对应的标签，如情感分类任务，可以在句子前面加上：”sentiment:”， 那么输出就会是 “negative” 或 “positive”。</p>
</li>
<li><p><strong>回归任务：</strong> 这里的处理感觉就没有大道至简的感觉，它将回归任务转化为了分类任务，比如1-5分，以 0.2 为间隔，划分为25个类，然后预测类别。感觉这里的处理有点为了归一而归一的意思。</p>
<p>举个简单的例子，假如我想要预测北京房价，如果是人类预测，他首先判断，是在千万级别判断，然后得出在1kw以下，然后在百万级别判断，得出在200-300w之间，然后在在十万级别判断，是在20-30w之间，然后在万级别判断，是在5w-6w之间，以此类推，直到一定的精度。</p>
<p>而如果模型要做的话，难道不应该直接生成吗？从[0-9.]中在合适的时间选择，这样才符合回归任务的本质吧。</p>
</li>
</ul>
<p>模型的细节其实也值得探讨一下，主要包含以下几个方面，这些细节完全参照 BERT：</p>
<ul>
<li><strong>Layer Normalization：</strong> 在每个 Block 的输入前使用</li>
<li><strong>残差连接：</strong> 将每个 Block 的输入与输出加起来</li>
<li><strong>Dropout：</strong> 用于 feed-forward 网络， 残差连接， attention weights， 以及整个stack 的输入输出。</li>
<li><strong>Relative Position Embedding：</strong> 与之前采用 <strong>sinusoidal position signal</strong>（attention is all you need 中使用的) 或 <strong>学习的 position embedding</strong>（BERT中使用的）不同， 本文中采用<strong>相对位置编码</strong>。</li>
</ul>
<h3><span id="3-评测模型">3. 评测模型</span></h3><p>为了评估模型在各个任务上的表现， 文章将模型适配到各个主流数据集上，主要包含四大任务： 机器翻译，问答，文本摘要以及文本分类：GLUE， SuperGLUE， CNN/Daily Mail， SQuAD， WMT English to German, French, and Romanian translation。</p>
<p>为了在这些数据集上训练，且采用统一的框架 Text-to-Text， T5 参考了多任务学习时的做法，对每一个数据集都定义了特别的输入。 </p>
<ul>
<li><p>对于翻译，如果是 English-to-German，那么格式为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input: translate English to German: That is good.</span><br><span class="line">output: Das ist gut.</span><br></pre></td></tr></table></figure>
</li>
<li><p>对于分类：如针对 MNLI 数据集，则输入输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input: mnli premise: I hate pigeons. hypothesis: My feelings towards pigeons are filled with animosity.</span><br><span class="line">output: entailment</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>其他几个典型的输入输入输出如下图所示，这部分就不赘述了，其实没啥意思。</p>
<p><img data-src="image/T5_1.png" alt></p>
<h3><span id="4-baseline">4.  Baseline</span></h3><ul>
<li><strong>Model:</strong> 采用标准 Encoder-Decoder Transformer（Attention is all you need），目的是能够在生成效果方面获得一些显著效果。Model size： 模型的 encoder， decoder size 接近，都采用跟 BERT base 一样多的 block（12个）。每个block的前馈神经网络输出纬度为$d<em>{ff}=3072$； attention机制的每个纬度为$d</em>{kv}=64$，采用12个head；sub-layers 与 embedding是的纬度为 $d_{model} = 768$。整个model 有 220 million 参数，是BERT-base的两倍。dropout = 0.1</li>
<li><strong>Training：</strong>损失函数采用标准的极大似然估计；优化器选择 AdaFactor；在test时，采用 greedy decoding；步数：$2^{19}=524288$；sequence length： 512； batch size 128。优化时的学习率衰减，在前 $10^4$采用 0.01 的学习率，在后面采用 $\frac{1}{\sqrt{max(n,k}}$ 对学习率进行衰减；其中 n是当前的 training iteration， k 是 warm-up steps（10^4）。</li>
<li><strong>fine-tune</strong>：步数： $2^{18}=262144$，batch size：128， sequence len：512；learning rate：0.001；每5000 steps 存 checkpoints。</li>
<li>Vocabulary： SentencePiece + WordPiece。</li>
<li><strong>Unsupervised objective</strong>：</li>
</ul>
<h3><span id="5-architectures">5. Architectures</span></h3><p>模型结构中主要涉及两个方面： <strong>模型架构</strong> 与 <strong>Attention mask 方式</strong>。</p>
<h4><span id="51-attention-mask-方式">5.1 Attention mask 方式</span></h4><p>在介绍这三种模型结构时，先来介绍 Attention 中的三种mask方式，mask方式的不同会极大的影响模型的效果，三种mask方式如下图所示：</p>
<p><img data-src="image/T5_2.png" alt></p>
<p>三种mask 方式分别为：</p>
<ul>
<li>Fully-visible： 同时看上下文的信息，典型的就是BERT了。</li>
<li>Causal：很常见的mask机制，分为从左到右，从右到左两种，当前点仅能看到之前的信息，而看不到之后的信息，具体可以参见《Attention is all you need》decoder 的输入部分。 同时， GPT 也是采用的这种方式，一般生成式语言模型都会采用这种方式：<a href="https://zhuanlan.zhihu.com/p/70663422">Bert 之后：预训练语言模型与自然语言生成</a></li>
<li>Causal with prefix：典型的 UNILM 中的 Seq-to-Seq LM 就是这种做法。</li>
</ul>
<h4><span id="52-模型结构">5.2 模型结构</span></h4><p>模型架构中，主要有 <strong>Encoder-Decoder，Language model，Prefix LM</strong> 这三种，如下图所示：</p>
<p><img data-src="image/T5_3.png" alt></p>
<ul>
<li><strong>Encoder-Decoder：</strong>  encoder 采用<strong>fully-visible</strong> attention mask，decoder 中采用 <strong>causal</strong> attention mask。其实本质上与 “attention is all you need” 结构差不多。</li>
<li><strong>Language model：</strong> 该结构相当于上面的 decoder 部分，典型的如 GPT 就是，这里其实就是延续的 GPT  的思路。mask 方式当然是 Causal 了。</li>
<li><strong>Prefix LM：</strong> full-visible 与 causal 都有着各自的缺陷，见：<a href="https://zhuanlan.zhihu.com/p/79371603">就最近看的paper谈谈预训练语言模型发展</a>。Causal with prefix算是二者的均衡。</li>
</ul>
<p><strong>模型结构的最终实验结果如下：</strong></p>
<p><img data-src="image/T5_4.png" alt></p>
<p>对于目标函数的选择，这里比较了 Denoising（BERT式）以及 LM（GPT式）两种方法。从上标中我们可以得出以下结论：</p>
<ul>
<li>Encoder-Decoder + Denoising 效果是最好的。</li>
<li>Encoder 与 Decoder 之间共享参数能够获得相近的最好效果。</li>
<li>Encoder与Decoder层数减半会损害结果。</li>
<li>ALBERT 中发现共享 self-attention 参数能够降低参数量，但并不会带来很大的损害，参见：<a href="https://zhuanlan.zhihu.com/p/92849070">ALBERT 告诉了我们什么？</a></li>
<li>参数共享的Encoder-Decoder performance 优于 decoder-only prefix LM ，这说明 Encoder-Decoder 架构是有益的。</li>
<li>Denoising 效果总是优于 LM 的效果。</li>
</ul>
<h3><span id="6-unsupervised-objectives">6. unsupervised objectives</span></h3><p><img data-src="image/T5_11.png" alt></p>
<p>文章按照上图中的顺序，从左到右依次探讨。</p>
<h4><span id="61-high-level-approachs">6.1   High-level approachs</span></h4><p>首先是 High-level approachs， 此处主要探讨的是，几种常见不同的目标函数的结果，主要包括以下三种，它们的输入输出如上图所示：</p>
<p><img data-src="image/T5_5.png" alt></p>
<p>图中，<code>&lt;M&gt;</code> 表示 <code>[MASK]</code> 标志</p>
<ul>
<li><strong>Prefix language modeling：</strong>该方法将句子分为两截，一部分作为输入到Encoder 中，另一部分作为Decoder的输出。</li>
<li><strong>masked language modeling(MLM)：</strong> 就是BERT那种形式。随机替换15%的token， 其中 90% 替换为[MASK]标志，10% 替换为随机token。</li>
<li><strong>deshuffling objective：</strong> 该方法会shuffle 句子中的token，并要求预测原始的句子。</li>
</ul>
<p><img data-src="image/T5_6.png" alt></p>
<p>三个结果的比较如上图所示， 我们看到， BERT-Style 的结果往往是最好的， prefix language modeling objective 能获得相近的结果。</p>
<h4><span id="2-bert-mask-策略">2. bert Mask 策略</span></h4><p>本节第二部分就是进一步探讨， 在 BERT-Style 内部，哪种方式 mask 方式是最好的呢？</p>
<p><img data-src="image/T5_7.png" alt></p>
<p>首先，第一个探讨的问题就是 mask 策略，如上图所示：</p>
<ul>
<li><strong>mask token：</strong> mask 掉 token，将替换的token 换成 [MASK]（类似 BERT）</li>
<li><strong>replace span：</strong>为了提高计算效率。将句子中span的token替换为其他的token（类似 SpanBERT）</li>
<li><strong>drop tokens：</strong> 直接丢弃掉 tokens。</li>
</ul>
<p><img data-src="image/T5_8.png" alt></p>
<p>这三种方法的结果如上图所示，可以得出， Replace span的方法是最好的。</p>
<p>接下来就探讨，<strong>应该mask 掉多少百分比的文本呢？</strong>如下图所示，最终发现 15% 的效果是最好的。</p>
<p><img data-src="image/T5_9.png" alt></p>
<p>最后， 前面得出要采用 replace span 方法，那么 <strong>span 的长度应该采用多长呢</strong>？结果如上图所示， 最终发现 3 的长度是最好的。</p>
<p><img data-src="image/T5_10.png" alt></p>
<h3><span id="7-pre-training-datasets">7. pre-training datasets</span></h3><p>本节探讨预训练数据集的重要性，主要分为两个部分： <strong>数据集的选择</strong>以及<strong>数据集大小</strong>的选择。</p>
<h4><span id="71-预训练数据集的选择">7.1 预训练数据集的选择</span></h4><p>在数据集的选择中，主要比较了 <strong>C4</strong>， <strong>Unfiltered C4</strong>（未经过过滤的C4文本），<strong>RealNews-like</strong>，<strong>WebText-like</strong>，<strong>Wikipedia</strong>，<strong>Wikipedia + Toronto Books Corpus</strong> 这几个数据集， 其结果如下：</p>
<p><img data-src="image/T5_12.png" alt></p>
<p>上表可以发现：</p>
<ul>
<li>Unfiltered C4 是未经过上述策略过滤的数据，与 C4 比较就可以发现， C4的效果明显提升，这再次验证了一个高质量数据集的重要性。</li>
<li>Wikipedia + TBC 数据集在 SuperGLUE 上的表现要比 C4好，这说明预训练数据集与任务数据集之间的相关性是十分重要的。即 pre-training on in-domain unlabeled data can improve performance on downstream tasks. 但需要注意的是单领域的数据集往往较小，因此可能会产生一些问题。</li>
</ul>
<h4><span id="72-预训练数据集的大小">7.2 预训练数据集的大小</span></h4><p>此处主要探讨两个问题：<strong>数据集的大小</strong>以及<strong>样本重复</strong>所带来的影响。我们选择的 Full Dataset 的大小为 $2^{35} B$ tokens，只是 C4 的一个子集。 实验结果如下：</p>
<p><img data-src="image/T5_13.png" alt></p>
<p><img data-src="image/T5_14.png" alt></p>
<p>从实验结果中我们可以看出：</p>
<ul>
<li>随着数据集 size 的减小， performance 在降低。通过 Training loss 曲线，随着数据集size的减小， training loss，这说明存在一定的过拟合现象，模型对小的数据集存在 memorize 现象。</li>
<li>当样本重复64次时，所带来的影响是有限的，这说明一定程度的预训练数据重复并不会带来损害。</li>
</ul>
<h3><span id="8-fine-tune">8. fine-tune</span></h3><p>本节讨论了用于<strong>如何在 Text-to-Text 上使用微调手段。</strong>主要有三种手段：</p>
<ul>
<li>微调 endocer-decoder 的所有参数。 </li>
<li><strong>adapter layers：</strong> 在decoder 外添加一层 dense-Relu-dense的 前馈网络，微调该前馈网络而不是微调所有参数。 同时， 该前馈网络的维度 d 的选择也十分重要，因此作者比较了多个维度。</li>
<li><strong>gradual unfreezing：</strong> 即随着时间的推移，越来越多的参数参与训练。最开始，只有最后一层开始训练，然后，随着时间推移，慢慢加入前面层的参数，直到所有的参数都参与训练。</li>
</ul>
<p><img data-src="image/T5_15.png" alt></p>
<p>从上图中我们发现：</p>
<ul>
<li>微调所有参数往往能够获得最好的结果</li>
<li>对于 low-resource 的任务如 SQuAD， 即使是小的 d 也能工作的很好</li>
<li>对于 High-resource 任务往往需要更大 的 d</li>
<li>对于微调来说， adapter layers 是一个不错的手段，能够很好的权衡 performance 与 训练性能， 且 d 的选择也颇为重要。</li>
</ul>
<h3><span id="9-multi-task-learning">9. Multi-task learning</span></h3><h3><span id="10-combining-multi-task-learning-with-fine-tuning">10. Combining multi-task learning with fine-tuning</span></h3><h3><span id="11-scaling">11. scaling</span></h3><p><img data-src="image/T5_16.png" alt></p>
<p>本节主要讨论了几个 <strong>Scaling 策略</strong>所带来的影响。主要涉及到的策略有：增大模型size， 增加 training steps， 增大 batch size。需要注意的是，<strong>当增加 trainging steps与 batch size 时，也要相应的增加训练数据。</strong>那其实问题就回到了，增加数据与增大模型所带来的效果增益。</p>
<p>从结果来看，<strong>增加数据与增大模型对performance 都是有影响的</strong>，且增大模型所带来的增益更大，且这两种 scaling 同时使用效果更佳。</p>
<h3><span id="12-t5-模型-put-it-all-together">12.  T5 模型： put it all together</span></h3><h2><span id="questions">Questions</span></h2><h3><span id="1-为什么-bert-结果好于-elmo">1. 为什么 BERT 结果好于 ELMO</span></h3><ol>
<li>Transformer 抽取特征的能力强于 LSTM</li>
<li>ELMO 中采用直接拼接进行多层向量融合的方式偏弱</li>
<li>BERT 参数量远多于 ELMO</li>
</ol>
<h3><span id="2-你觉得bert-有哪些需要改进的地方">2. 你觉得BERT 有哪些需要改进的地方</span></h3><h2><span id="reference">Reference</span></h2><p>[1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</p>
<p>[2] RoBERTa: A Robustly Optimized BERT Pretraining Approach</p>
<p>[4] T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-ERNIE系列</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20ERNIE%20%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#预训练语言模型-ernie-系列">预训练语言模型 - ERNIE 系列</a><ul>
<li><a href="#前言">前言</a></li>
<li><a href="#ernie-10">ERNIE 1.0</a><ul>
<li><a href="#1-双向transformer">1. 双向Transformer</a></li>
<li><a href="#2-不同粒度的信息融合">2. 不同粒度的信息融合</a></li>
<li><a href="#3-basic-level-masking-预训练">3. Basic-Level Masking 预训练</a></li>
<li><a href="#4-phrase-level-masking-预训练">4. Phrase-level Masking 预训练</a></li>
<li><a href="#5-entity-level-masking-预训练">5. Entity-level Masking 预训练</a></li>
<li><a href="#6-多源数据">6. 多源数据</a></li>
<li><a href="#7-dlmdialogue-language-model">7. DLM：Dialogue Language Model</a></li>
</ul>
</li>
<li><a href="#ernie-20">ERNIE 2.0</a><ul>
<li><a href="#1-sequential-multi-task-learning">1. sequential multi-task learning</a></li>
<li><a href="#2-模型架构">2. 模型架构</a></li>
<li><a href="#3-pre-training-任务-word-aware">3. Pre-training 任务:  word-aware</a></li>
<li><a href="#4-pre-training-任务-structure-aware">4. Pre-training 任务:  Structure-aware</a></li>
<li><a href="#5-pre-training-任务-semantic-aware">5. Pre-training 任务:  Semantic-aware</a></li>
</ul>
</li>
<li><a href="#6-实验">6. 实验</a></li>
<li><a href="#ernie-30">ERNIE 3.0</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="预训练语言模型-ernie-系列">预训练语言模型 - ERNIE 系列</span></h1><h2><span id="前言">前言</span></h2><p>最近恰逢百度 ERNIE 3.0 发布，效果也的确还不错，因此，老宋我就想着总结一下百度 ERNIE 系列在预训练语言模型+知识融合方面的探索。虽然ERNIE 3.0 目前无法使用（没错，自己厂内人士都用不了），但是理论角度还是得看看有啥新花样，不然老板心血来潮问起来，咱也不能不会阿。</p>
<h2><span id="ernie-10">ERNIE 1.0</span></h2><p>对于 ERNIE 1.0 来说，其与 BERT 最大的不同就是融入了多级粒度的信息，如实体，短语等，这更加适用于中文这种具有先验信息的词汇，类似于中文中分词的道理一样。</p>
<h3><span id="1-双向transformer">1. 双向Transformer</span></h3><p>ERNIE 同样采用多层的双向Transoformer 来作为特征提取的基本单元，这部分没啥创新，就是简单提一下。 </p>
<h3><span id="2-不同粒度的信息融合">2. 不同粒度的信息融合</span></h3><p>ERNIE 同样采用了多种粒度信息，只不过不同粒度信息的预训练过程与 Bert 不同， 对于一个 token， 其同样由 token embedding + segment embedding + position embedding 组成，与 bert 相同， 每一句话的第一个 token 都为 [CLS]。</p>
<p><img data-src="https://pic2.zhimg.com/v2-68664a317aa9b18bb8d3377a99f4dd4d_b.jpg" alt="img"></p>
<h3><span id="3-basic-level-masking-预训练">3. Basic-Level Masking 预训练</span></h3><p>这个过程与 Bert 中的 MLM 类似，是对于词粒度的预训练。 对于英文而言，粒度为 word， 对于中文而言，粒度为字。</p>
<p>随机 Mask 输入序列中 15% 的 token， 然后预测这些被 mask 掉的 tokens。这点与 Bert 相同， 不同的是，其论文中没有提到十分采用类似 Bert 的那种 Mask 的Trick 来降低预训练与预测的不一致性，这点需要看代码确认一下。</p>
<h3><span id="4-phrase-level-masking-预训练">4. Phrase-level Masking 预训练</span></h3><p>我个人认为短语级别的粒度信息对于中文，英文来说都是有用的。</p>
<p>对于中文来说， 比如 “放你一马”， 这从单单的字粒度信息是学习不到的，且这种信息相当多。而对于英文来说，英文短语也不在少数，就像： pull up, pull down, push up, push down 我觉得word粒度对这种短语信息也是难以捕捉的。</p>
<p>在这部分的预训练过程中，首先采用对应的工具识别出句子中存在的 Phrase， 然后随机 Mask 句子中的一些短语（文章并没有说 mask 多少百分比）， 然后预测 mask 掉的 Phrase 中的 word（字）， 即以 word（字）为预测单元。</p>
<h3><span id="5-entity-level-masking-预训练">5. Entity-level Masking 预训练</span></h3><p>实体信息包括人名，地名，组织名称，产品名称等， 而实体又是一种抽象的概念，且通常包含着一些重要的信息，且实体之间的关系也十分重要。 ERNIE 先用命名实体识别找出句子中的实体，然后与 Phrase-level 一样， mask 其中的一些实体并预测这些mask掉的 word (字)。</p>
<p><img data-src="https://pic1.zhimg.com/v2-c09fc9150ac135c0b26d24f2d0332860_b.jpg" alt="img"></p>
<p>对此，Entity-level Masking 预训练能够捕捉到实体的语义信息，这点是毋庸置疑的，但对于实体间关系的抽取，从模型上来看并不突出，希望有大佬解释一下（论文中是提到可以学习到实体间关系，只是我对此存疑）。</p>
<h3><span id="6-多源数据">6. 多源数据</span></h3><p>ERNIE 在预训练时采用了多源数据，包括：中文维基百科，百度百科，百度新闻，百度贴吧。其中，百度贴吧由于其社区的特性，里面的内容是对话形式的，而 ERNIE 中对于 Segement Embedding 预训练与 Bert 的 NSP 不同的是，其采用 DLM 来获得这种句子粒度级别的信息，而这对于句子语义的把握更佳准确。</p>
<h3><span id="7-dlmdialogue-language-model">7. DLM：Dialogue Language Model</span></h3><p>对比 Bert 中的 NSP， 似乎 DLM 更能把握句子的语义信息，且对于对话，问答这种形式的任务效果更好。 DLM 的训练过程与 NSP 也有很大的区别，其输入如下：</p>
<p><img data-src="https://pic2.zhimg.com/v2-68664a317aa9b18bb8d3377a99f4dd4d_b.jpg" alt="img"></p>
<p>为了使得 ERNIE 能够表示多轮对话，其输入采用QRQ, QQR,QRR（Q表示Query， R表示Response) 这几种形式， 如上图就是 QRQ 的一个例子。 ERNIE 会 mask 掉输入的一些 token， 然后让模型去预测这些被 mask 掉的 token（文章并没有给出mask比例以及如何分配mask）。 </p>
<p>同样有趣的是，ERNIE 也通过随机替换 Query 或 Response的方式来会添加一些 fake 样本来让模型去预测该输入是 real 还是 fake。</p>
<p>DLM 与 NSP 相比， 其更加复杂也更倾向于对话这种更高难度的任务，我个人认为，这种方式对于对话这种任务来说帮助很大。 </p>
<h2><span id="ernie-20">ERNIE 2.0</span></h2><p>相比与BERT与ERNIE 1.0， ERNIE 2.0 的最大特点是预训练任务的增多。不同于BERT的两个预训练任务，ERNIE 1.0 的4个预训练任务， ERNIE 2.0 提出了9个预训练任务。</p>
<p>但是在大规模预训练的时候，当存在多个预训练任务时，往往在预训练后面任务的时候会丢掉一些前面任务所学习到的信息。为了减轻多个任务下学习的遗忘，ERNIE 2.0 中引入了 sequential multi-task learning。</p>
<p>通读整篇论文，没有看到各个预训练任务的消融实验，因此对于每个预训练任务尤其是 Structure-aware 与 Semantic-aware 来说，是否真的为下游任务带来了增益呢？ 甚至更进一步来说，哪些预训练任务对于下游的哪些子任务产生了正向增益呢？ 比如说： IR Relevance Task  是否在句子匹配上产生了增益呢？</p>
<p>同时，我认可 sequential multi-task learning 的思想，在多重任务叠加的时候，sequential multi-task learning 的确具备其有效性。</p>
<h3><span id="1-sequential-multi-task-learning">1. sequential multi-task learning</span></h3><p><img data-src="./image/ERNIE2_1.png" alt></p>
<p>在描述 Sequential multi-task learning 之前，先简单介绍下 Multi-task Learning 与 Continual Learning：</p>
<ul>
<li><strong>Multi-task Learning：</strong> 多个任务一起进行学习，多个任务之间没有主次之分，在训练之前就需要准备好所有定制的预训练任务，每当有新任务时，模型都需要从头学习。</li>
<li><strong>Continual Learning：</strong> 在训练的每一个阶段仅通过一项任务来训练模型，其缺点是会忘记先前学习的知识。</li>
</ul>
<p>如上图所示， Sequential multi-task learning 本质上是融合了 multi-task learning 与 continual learning 的思想，其最关键的思想是：在预训练后面的任务时，应该与前面的任务一起进行 multi-task learning。</p>
<p>我们再仔细推敲一下，当我们采用多任务学习进行预训练的时候，其本质上多个任务是处于同等地位的，虽然可以通过loss权重等方式进行调整。而在预训练任务中，任务的优先等级其实是不一样的，比如mask token 的任务往往决定着根本的预训练表现。</p>
<p>因此，如果既能够将重要任务优先预训练，又能够通过多重任务引入多重信息，又能够在新任务预训练时不会过分遗忘之前预训练得到的知识，那么，最终似乎融合 multi-task learning 与  continual learning 就是顺理成章的了。 </p>
<p>当然，以上纯属猜测，但我觉得出发点应该是差不多的。此外， Sequential multi-task learning 一大好处是可以不断的融合新的预训练任务，而不用过度担心遗忘问题。</p>
<h3><span id="2-模型架构">2.  模型架构</span></h3><p><img data-src="image/ERNIE2_2.png" alt></p>
<p>与BERT 与 ERNIE 1.0 不同的是， ERNIE 2.0 的 embedding 层引入了一个 Task embedding，用来预训练的时候区分各个任务，task id 可以设置成0-N。然而却又说明，在fine-tune时候，又并不需要认真设置 task id，设置为任意的 task id 即可。</p>
<p>这反而让我怀疑预训练时候，该层的必要性，当然咱也没资源做消融实验，但是单纯从理论角度看，此处似乎并不能解释的通，此处留空等我读完源码在看。</p>
<h3><span id="3-pre-training-任务-word-aware">3. Pre-training 任务:  word-aware</span></h3><p>word-aware 顾名思义就是 word 级别的预训练，其目的是学习到 word-level 的细粒度特征。这是预训练任务的核心。</p>
<p><strong>Knowledge Masking Task</strong></p>
<p>ERNIE 2.0 沿用 ERNIE 1.0 中的 mask 机制，即 Basic-Level，Phrase-level， Entity-level。该机制的有效性在ERNIE 1.0 中已经证明其有效性了。</p>
<p><strong>Capitalization Prediction Task</strong></p>
<p>考虑到大写word英文中往往有着特定的意义，这在命名实体识别任务上具有一定的意义。因此，此处添加了一个任务：去预测word 是否为大写。</p>
<p>值得一提的是，在中文互联网环境中，往往大小写混杂，内容并不规范，因此实际应用中，大写word是否具有意义需要根据实际场景来定。</p>
<p><strong>Token-Document Relation Prediction Task</strong></p>
<p>该任务是去判断一个段落中的 word 是否会出现在 document 的其他段落中，其最终目的是希望模型能够去学习到哪些 word 是关键的。</p>
<p>从本质上来讲，其认为出现在多个段落中的词往往是比较有用的和与主题相关比较高的次。 对此有一点疑问的是，我们判断 word 是否重要，往往不会仅仅通过共现来判断，而是会通过 TF-IDF 等手段去判断，我这里认为再构造数据集的时候，ERNIE 2.0 肯定采用了一些类似 TF-IDF的算法来得到相对重要的word。</p>
<h3><span id="4-pre-training-任务-structure-aware">4. Pre-training 任务:  Structure-aware</span></h3><p><a href="https://zhuanlan.zhihu.com/p/369953813">https://zhuanlan.zhihu.com/p/369953813</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/112150383">https://zhuanlan.zhihu.com/p/112150383</a></p>
<p><strong>Sentence Reordering Task</strong></p>
<p><strong>Sentence Distance Task</strong></p>
<h3><span id="5-pre-training-任务-semantic-aware">5. Pre-training 任务:  Semantic-aware</span></h3><p><strong>Discourse Relation Task</strong></p>
<p><strong>IR Relevance Task</strong></p>
<p>该任务的目的是学习 IR 中的短文本相关性，其本质上学习的 IR 场景中 query 与 title 的相关性，分为三个类别：</p>
<ul>
<li>无关：用户输入query后，搜索引擎没有返回该title</li>
<li>强相关：用户输入query后，搜索引擎返回并点击了该title</li>
<li>弱相关：用户输入query后，搜索引擎返回没有点击该title</li>
</ul>
<p>我个人认为该任务对短文本相似性的帮助应该是蛮大的，但是可惜没有消融实验，且我们也很难拿到搜索引擎的数据。</p>
<h2><span id="6-实验">6. 实验</span></h2><p>第一部分的实验当然是 ERNIE 2.0 与 BERT 在多个任务上对比，结果当然是 ERNIE 2.0 更胜一筹，在某些数据集上效果还是比较明显的。 但如上文所述，本文的一大明显缺点是此处没有进行消融实验。</p>
<p>第二部分的实验是对比 sequential multi-task learning，Multi-task Learning，Continual Learning:</p>
<p><img data-src="./image/ERNIE_2_3.png" alt></p>
<p>总的来说，Multi-task 与 sequential multi-task learning 的差距并不是十分明显，但也算有一定说服力了。</p>
<h2><span id="ernie-30">ERNIE 3.0</span></h2>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-GPT系列</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20GPT%20%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#预训练语言模型-gpt-系列">预训练语言模型 - GPT 系列</a><ul>
<li><a href="#gpt-10-1">GPT 1.0 [1]</a><ul>
<li><a href="#1-语言模型">1， 语言模型</a></li>
<li><a href="#2-单向transformer">2， 单向Transformer</a></li>
<li><a href="#3-微调">3. 微调</a></li>
</ul>
</li>
<li><a href="#gpt-20">GPT 2.0</a><ul>
<li><a href="#1-语言模型">1. 语言模型</a></li>
<li><a href="#2-单向-transformer">2. 单向 transformer</a></li>
<li><a href="#3-gpt-10-vs-gpt-20-大就完事了">3. GPT 1.0 vs GPT 2.0 - 大就完事了</a></li>
<li><a href="#4如何适配下游任务-zero-shot">4.如何适配下游任务 - zero shot</a></li>
<li><a href="#5-最大的转变-思想">5. 最大的转变 - 思想</a></li>
<li><a href="#6-gpt-20-告诉了我们什么">6. GPT 2.0 告诉了我们什么</a></li>
</ul>
</li>
<li><a href="#gpt-30">GPT 3.0</a><ul>
<li><a href="#0-zero-shotfew-shot-fine-tuning">0. zero-shot,few-shot, fine-tuning</a></li>
<li><a href="#1-模型与语言模型">1. 模型与语言模型</a></li>
<li><a href="#2-数据集">2. 数据集</a></li>
<li><a href="#3-gpt-30-的意义">3. GPT 3.0 的意义</a></li>
<li><a href="#4-gpt-30-告诉了我们什么">4. GPT 3.0 告诉了我们什么？</a></li>
</ul>
</li>
<li><a href="#questions">Questions</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="预训练语言模型-gpt-系列">预训练语言模型 - GPT 系列</span></h1><h2><span id="gpt-10-1">GPT 1.0 [1]</span></h2><p>GPT 1.0 与 Bert 很相似，同样是作为二阶段的模型，只是在细节处可能相差较大。</p>
<p>预训练训练数据：8亿词的BooksCorpus ， transformer层数：12层，参数量与bert差不多，1.1亿</p>
<h3><span id="1-语言模型">1， 语言模型</span></h3><p>对于给定的 tokens $U = {u_1, \cdots, u_n }$ ， GPT 1.0 的语言模型的目标函数如下：</p>
<script type="math/tex; mode=display">
P(s) = P（w_i |w_{i-k}, \cdots, w_{i-1} ）\\</script><script type="math/tex; mode=display">
L_1(U) = \sum_i log P(u_i| u_{i-k}, \cdots, u_{i-1}; \Theta); \, \, \text{k为窗口大小}</script><p>从上式可以看出， GPT 1.0 是具有句子的生成能力的， 可惜 GPT 1.0 没有关于生成方面的实验。</p>
<h3><span id="2-单向transformer">2， 单向Transformer</span></h3><p>GPT 1.0 采用单向的 Transformer 来作为特征抓取器，这是由于语言模型本身决定的，因为是从前往后生成单词的。 采用 transformer 的整个过程如下</p>
<script type="math/tex; mode=display">
h_0 = UW_e + W_p， \\
W_e 为 \, token \, embedding ; W_P 为 \, position \, embedding \\
h_l = transformer\_block(h_{l-1})  \,\,  \forall \in [1,n]，n为层数 \\
P(u) = softmax(h_n W_e^T)</script><h3><span id="3-微调">3. 微调</span></h3><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1fwc9ch5yd3j30ua0h7gp9.jpg" alt></p>
<h2><span id="gpt-20">GPT 2.0</span></h2><p>采用800w高质量网页文档，40GB数据；48层单向transformer；参数量15亿。</p>
<h3><span id="1-语言模型">1. 语言模型</span></h3><script type="math/tex; mode=display">
P(s) = P（w_i |w_{i-k}, \cdots, w_{i-1} ）</script><p>GPT 2.0 的语言模型与 GPT 1.0 很相似， 变化很少，</p>
<h3><span id="2-单向-transformer">2. 单向 transformer</span></h3><p>与GPT 1.0 几乎相同，有一些微小的改动，</p>
<ul>
<li>Layer Normalization 的转移和添加</li>
<li>扩大字典，输入序列长度等</li>
<li>48层的transformer</li>
</ul>
<p>这部分也不是文章的主要创新点，因此我略过了。</p>
<h3><span id="3-gpt-10-vs-gpt-20-大就完事了">3. GPT 1.0 vs GPT 2.0 - 大就完事了</span></h3><p>GPT 2.0 相较 1.0 来说，在数据方面的改动很大，主要包括以下几个方面： </p>
<ul>
<li>大规模，高质量，跨领域数据：WebText</li>
<li>更深的 Transoformer 模型（15亿参数），48层</li>
</ul>
<p>GPT 2.0 验证了数据的重要性，即使单纯的从数据角度入手，效果就可以获得巨大的提升。GPT 2.0 采用800w 互联网网页数据，这样训练出来的语言模型，能够覆盖几乎所有领域的内容。</p>
<h3><span id="4如何适配下游任务-zero-shot">4.如何适配下游任务 - zero shot</span></h3><p>对于下游任务来说， GPT 2.0 认为可以不采用微调的方式来做，而是直接用训好的语言模型来做，那么它怎么就能够又能做分类，又能做翻译，还能做文本摘要的呢？</p>
<p>答案很风骚： GPT 2.0 在做下游任务时，添加了一些引导字符来预测目标，它的输出与语言模型一样，都是一个单词。 </p>
<p>那么 GPT 2.0 是如何做生成类任务的呢？ 那就是连续不断的进行预测，预测 n 次(设定)， 然后把这 n 个token 连在一起，取其中的几句话来做为生成的文本。</p>
<h3><span id="5-最大的转变-思想">5. 最大的转变 - 思想</span></h3><p>GPT 2.0 相较GPT 1.0 而言，改变最大的思想，具体来说， GPT 2.0 依旧是二阶段的框架，但对于下游任务，不再采用有监督的进行微调，而是采用无监督的方式直接去做。</p>
<p>作者认为，通过大模型，大规模数据，GPT 2.0 能够学习到很多通用知识，直接拿这些通用知识去做下游任务就可以获得很好的结果。 这其实就是<strong>证明预训练语言模型这条道路的正确性，预训练语言模型的确能够学习到语言的很多信息，并具有很强的泛化能力。</strong> </p>
<p>但， 真的不需要微调吗？ 我认为接下来一段时间的预训练语言模型的发展依旧会是二阶段或三阶段的框架： <strong>预训练语言模型 + [多任务学习] + [在特定数据集上预训练] + 下游任务微调。</strong></p>
<p>不可否认的是， GPT 2.0 同样打开了一个新思路， <strong>如果有一天， 模型足够大，数据足够多，我们还需要微调吗？</strong></p>
<h3><span id="6-gpt-20-告诉了我们什么">6. GPT 2.0 告诉了我们什么</span></h3><ul>
<li>预训练数据与网络深度的重要性，目前也没有到极限。</li>
<li>GPT 2.0 的生成效果非常惊艳，至少语法，流畅度等方面是没有问题的，就是没有灵魂</li>
<li>zero-flot 也不是不可以</li>
</ul>
<h2><span id="gpt-30">GPT 3.0</span></h2><h3><span id="0-zero-shotfew-shot-fine-tuning">0. zero-shot,few-shot, fine-tuning</span></h3><ul>
<li>FT，fine-tuning：就是微调啦</li>
<li>FS，few-shot：允许输入数条范例和一则任务说明</li>
<li>One-shot：只允许输入一条范例和一则任务说明</li>
<li>Zero-shot：不允许输入任何范例，只允许输入一则任务说明</li>
</ul>
<h3><span id="1-模型与语言模型">1. 模型与语言模型</span></h3><p>预训练时采用的模型，训练目标，语言模型与 GPT 2.0没有差别。</p>
<p>此处为了对比不同size 下的结果，GPT 3 预训练了8个不同参数量的模型：</p>
<p><img data-src="image/GPT3_1.png" alt></p>
<h3><span id="2-数据集">2. 数据集</span></h3><p><img data-src="image/GPT3_2.png" alt></p>
<h3><span id="3-gpt-30-的意义">3. GPT 3.0 的意义</span></h3><p>GPT 3.0 本质上是探索超大型预训练语言模型在 zero-shot上的可能性，这是延续之前 GPT 2.0 的研究，整体上，GPT 3.0 在 zero-shot 下能获得相当不错的结果。</p>
<p><img data-src="image/GPT3_4.png" alt></p>
<p><img data-src="image/GPT3_5.png" alt></p>
<p><img data-src="image/GPT3_6.png" alt></p>
<p><img data-src="image/GPT3_7.png" alt></p>
<p><img data-src="image/GPT3_8.png" alt></p>
<p><img data-src="image/GPT3_9.png" alt></p>
<p><img data-src="image/GPT3_10.png" alt></p>
<p><img data-src="image/GPT3_11.png" alt></p>
<h3><span id="4-gpt-30-告诉了我们什么">4. GPT 3.0 告诉了我们什么？</span></h3><ol>
<li>通过 TriviaQA 与CoQA的结果，我们知道，扩大模型与数据量能够帮助 knowledge intensive tasks 和 reading comprehension</li>
<li>few-shot 存在一定可能性</li>
<li>language model 预训练任务能够学习到上下文内容</li>
</ol>
<h2><span id="questions">Questions</span></h2><h2><span id="reference">Reference</span></h2><p>[1] GPT 1.0: Improving Language Understanding by Generative Pre-Training</p>
<p>[2] GPT 2.0: Language Models are Unsupervised Multitask Learners</p>
<p>[3] GPT 3.0: Language Models are Few-Shot Learners</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-XLNet系列</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20XLNet/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#前言">前言</a></li>
<li><a href="#xlnet-为何如此之屌">XLNet 为何如此之屌？</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="前言">前言</span></h2><p>又又又屠榜了，一开始，我以为只是噱头，直到鄙人打开了 RACE 排行榜：</p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g47usj10xmj30qq0bvaaz.jpg" alt></p>
<p>我近几个月来一直希望能够通过设计一个适合 RACE 数据集的 Attention 机制融合长距离文本来实现 <strong>终极反杀</strong>，然而，看到这一幕，我对 Attention 的必要性产生了严重的怀疑。</p>
<p>虽然说我们依旧可以在 XLNet 上加上 Attention 来实现超越 XLNet 本身的效果，但这真的有意义吗，或许再过几个月，就又会有屠榜的消息传来， 那么设计精巧的 Attention 机制又被 <strong>大力出奇迹</strong> 的模型按在地上摩擦的时候，意义何在？ </p>
<p>我觉得我近期可能要深入思考一下： <strong>Attention 的存在意义</strong>，有大佬理解深刻的话，希望能指点我一下。</p>
<h2><span id="xlnet-为何如此之屌">XLNet 为何如此之屌？</span></h2><p>XLNet 在多个任务上超出了 Bert 许多，我们先来看看 XLNet 是怎么做的，然后分析相对于 Bert 而言， XLNet 为何会如此优秀。</p>
<p>推荐张俊林大佬的讲解，真的是深入浅出： <a href="https://zhuanlan.zhihu.com/p/70257427">XLNet:运行机制及和Bert的异同比较</a></p>
<p><strong>1， AR LM </strong></p>
<p>AR 即 AutoRegressive language model， 其代表了一类从上文内容预测之后下一个词的语言模型，可以分为两种，一种是从左到右的语言模型(left-to-right)， 一种是从右到左的语言模型(right-to-left)。 语言模型的公式分别如下：</p>
<script type="math/tex; mode=display">
\text{left to right: } p(x) = \prod_{t=1}^T p(x_t | x_{<t}) \\
\text{right to left: } p(x) = \prod_{t=T}^1 p(x_t | x_{>t})</script><p>结合之前的模型， GPT 就是一个典型的 left-to-right 的语言模型， ELMO 是 left-to-right + right-to-left 的结合体。</p>
<p>AR 模型的缺点很明显：<strong>无法同时利用上下文信息</strong>， ELMO 的这种简单拼接的方式的确有点粗糙，效果也不是很好，但的确目前没有预训练模型采用 ELMO 这种方式，但估计效果并不会比 Bert 更好。而针对具体的任务尤其如阅读理解而言， AR 模型变现不佳也就在意料之中了。</p>
<p>AR 模型的优点很重要：<strong>对自然语言生成任务很友好。</strong> 这一点从 GPT 2.0 与 Bert 的对比就可以看出， GPT 2.0 在生成任务上的表现可以说惊艳， 因为生成语言的过程就是从左到右的， AR 模型天然的符合这个过程。</p>
<p><strong>2， AE LM</strong></p>
<p>AE 即 AutoEncoding Language Model， 其代表一类从被 mask 的输入中来学习上下文信息的方式， Bert 就是其中的典型代表，就我理解来看，其目标函数大概长这样：</p>
<script type="math/tex; mode=display">
p(x) = \prod_{i=1}^{mask \, num} p(x_i | X) \quad x_i \in mask</script><p>目前很多改进的文章都是按照这一套路来的，比如百度的 ERNIE ， 微软的 MASS等。</p>
<p>Bert 文章中已经提到， 这种 AE 模型的最大缺点是： <strong>由于引入了 [MASK] 造成的预训练阶段与 fine-tuning 阶段不一致的问题。</strong> 而 Bert 还特意提出一个 Trick 来减轻这个问题（参见：<a href="https://zhuanlan.zhihu.com/p/69941989">Bert 改进： 如何融入知识</a>。  且另一方面， 这种 AE 模型对于生成并不友好， MASS 一定程度上减轻了这一问题，但我认为依旧存在改进空间。</p>
<p>另外，文章还提到了 Bert 会忽略 <strong>被 mask 的各个 token 之间的相关性</strong>，额，，那为啥不像 Word2Vec 的 CBOW 那样一句话只 mask 一个token， 这样不就解决了吗？ 当然，这样做训练起来效率会很低，的确有点得不偿失。</p>
<p>而AE 模型的最大优点也很清楚了： <strong>能够很好的融入上下文信息。</strong> 这也是为啥 bert 能够在自然语言理解问题上实现巨大突破的根本原因。</p>
<p><strong>3， 如何 AR + AE ？ </strong></p>
<p>XLNet 出发点就是结合 AR 与 AR ， 从而实现二者的互补，从结果看，它做的很棒， 我们先抠模块细节，然后分析为什么这么做就能够避免某种问题。</p>
<p><strong>4， 预训练模型： PLM</strong></p>
<p>PLM 全称为 Permutation Language Modeling， 通过 PLM， 模型不仅能够保持 AR 模型的优势， 又能够捕捉到双向的上下文信息， 其核心思想如下：</p>
<h2><span id="reference">Reference</span></h2><p>[1]  XLNet: Generalized Autoregressive Pretraining for Language Understanding</p>
<p>[2]  Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</p>
<p>[3]  <a href="https://zhuanlan.zhihu.com/p/70257427">XLNet:运行机制及和Bert的异同比较</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-可解释性</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#bert-可解释性">BERT 可解释性</a><ul>
<li><a href="#分析可解释性的一些常见方法">分析可解释性的一些常见方法</a></li>
<li><a href="#what-does-bert-learn-from-multiple-choice-reading-comprehension-datasets1">What does BERT Learn from Multiple-Choice Reading Comprehension Datasets[1]</a><ul>
<li><a href="#1-un-readable-data-attack">1. Un-Readable Data Attack</a></li>
<li><a href="#2-un-answerable-data-training">2. Un-Answerable Data Training</a></li>
</ul>
</li>
<li><a href="#what-does-bert-learn-about-the-structure-of-language2">What does BERT learn about the structure of language[2]</a><ul>
<li><a href="#1-phrasal-syntax">1. Phrasal Syntax</a></li>
<li><a href="#2-探测任务probing-tasks">2. 探测任务(Probing Tasks)</a></li>
<li><a href="#3-subject-verb-agreement">3. Subject-Verb Agreement</a></li>
<li><a href="#4-compositional-structure">4. Compositional Structure</a></li>
</ul>
</li>
<li><a href="#open-sesame-getting-inside-berts-linguistic-knowledge">Open Sesame: Getting Inside BERT’s Linguistic Knowledge</a></li>
<li><a href="#bert-vs-elmo-vs-flair-9">BERT vs ELMO vs Flair [9]</a></li>
<li><a href="#bert-vs-elmo-vs-gpt-2">BERT vs ELMO vs GPT-2</a></li>
<li><a href="#bert-attention-学到了什么">BERT Attention 学到了什么</a></li>
<li><a href="#a-primer-in-bertology-what-we-know-about-how-bert-works">A Primer in BERTology: What we know about how BERT works</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="bert-可解释性">BERT 可解释性</span></h1><h2><span id="分析可解释性的一些常见方法">分析可解释性的一些常见方法</span></h2><ul>
<li>Probing tasks： 通过设计一些独立性较强的简单任务，来验证模型的不同层再不同Probing task 上的能力，进而得到模型对数据的深入解释</li>
<li>Visualization：一般都是通过可视化 Attention 系列来对模型做出解释。</li>
<li>Adversarial attacks：对抗性攻击通过使用特定干扰信息创建的例子来验证模型的鲁棒性</li>
</ul>
<h2><span id="what-does-bert-learn-from-multiple-choice-reading-comprehension-datasets1">What does BERT Learn from Multiple-Choice Reading Comprehension Datasets[1]</span></h2><ul>
<li>an un-readable data attack, in which we add keywords to confuse BERT, leading to a significant performance drop</li>
<li>an un-answerable data training, in which we train BERT on partial or shuffled input</li>
</ul>
<h3><span id="1-un-readable-data-attack">1. Un-Readable Data Attack</span></h3><p>The un- readable data is mainly obtained by randomly shuf- fling the word order of the input to make it gram- matically wrong and un-readable.</p>
<ul>
<li>We first fine-tune BERT on the original MCRC data and then test it under adversarial attacks. </li>
<li></li>
</ul>
<h3><span id="2-un-answerable-data-training">2. Un-Answerable Data Training</span></h3><h2><span id="what-does-bert-learn-about-the-structure-of-language2">What does BERT learn about the structure of language[2]</span></h2><p>本文通过设计不同粒度的任务探索 BERT 的不同层的向量能够扑捉到什么样的信息。</p>
<ul>
<li>浅层网络能够捕捉到 phrase-level 信息，而这部分信息在高层被稀释了</li>
<li>中层网络能够捕捉到语法结构信息</li>
<li>顶层网络能够扑捉到语义信息</li>
<li>BERT 需要深层网络才能学习到长距离的依赖</li>
</ul>
<h3><span id="1-phrasal-syntax">1. Phrasal Syntax</span></h3><p>这部分主要验证 BERT 能否扑捉到短语级别的结构信息。 对于短语片段$(s<em>i,s_j)$， 通过 concat 片段在 l 层的第一个向量$h_i$和最后一个向量$s_j$进行 ，得到该短语的向量表示$S</em>{(s_i, s_j)}, l$。通过对CoNLL 2000 chunking dataset 进行随机抽取，可视化结果如下：</p>
<p><img data-src="../image/006gOeiSly1ghh183ecndj30s30csq5r.jpg" alt="屏幕快照 2020-08-06 下午1.35.04.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">NP (noun phrase) # 名词短语</span><br><span class="line">VP (verb phrase) # 动词短语</span><br><span class="line">PP (prepositional phrase) # 介词短语</span><br><span class="line">ADVP (adverb phrase)  # 副词短语</span><br><span class="line">SBAR (subordinated clause) # 从句</span><br><span class="line">ADJP (adjective phrase) # 形容词短语</span><br><span class="line">PRT (particles) # </span><br><span class="line">CONJP (conjunction phrase) # 连词</span><br><span class="line">INTJ (interjection)</span><br><span class="line">LST (list marker)</span><br><span class="line">UCP (unlike coordinated phrase)</span><br></pre></td></tr></table></figure>
<p>从上图中可以得到：BERT 浅层能够扑捉到 phrase-level information，而随着层的加深，此特征被稀释了。</p>
<h3><span id="2-探测任务probing-tasks">2. 探测任务(Probing Tasks)</span></h3><p>Probing Tasks 主要是用来评估BERT每层向量对于不同语言信息的扑捉能力。本文的探测任务主要有十个，可以分为三组：</p>
<ul>
<li>Surface tasks（表层任务）：SentLen（）， WC</li>
<li>Syntactic tasks（句法任务）：BShift， TreeDepth， TopConst</li>
<li>Semantic tasks（语义任务）：Tense， SubjNum，SOMO， CoordInv</li>
</ul>
<p><img data-src="../image/1.png" alt></p>
<h3><span id="3-subject-verb-agreement">3. Subject-Verb Agreement</span></h3><h3><span id="4-compositional-structure">4. Compositional Structure</span></h3><h2><span id="open-sesame-getting-inside-berts-linguistic-knowledge">Open Sesame: Getting Inside BERT’s Linguistic Knowledge</span></h2><h2><span id="bert-vs-elmo-vs-flair-9">BERT vs ELMO vs Flair [9]</span></h2><p>本文主要探讨这三种上下文向量在 WSD（word sense disambiguation）上的表现，进而判断上下文向量能否解决 WSD 问题。</p>
<p><img data-src="../image/006gOeiSly1ghgx5p4aitj30fa07bwf6.jpg" alt="屏幕快照 2020-08-06 上午11.14.15.png"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>MFS</td>
<td>54.79</td>
<td>58.95</td>
<td>70.94</td>
<td>48.44</td>
</tr>
</tbody>
</table>
</div>
<p>从上表中看出，BERT 要远高于baseline 模型，且要比其他上下文向量表现更佳。</p>
<p><img data-src="../image/006gOeiSly1ghgxnodew6j30u00e9wj4.jpg" alt="屏幕快照 2020-08-06 上午11.31.21.png"></p>
<p>从上图中我们得出如下结论：</p>
<ul>
<li>The Flair embeddings hardly allow to distinguish any clusters as most senses are scattered across the entire plot.</li>
<li>In the ELMo embedding space, the major senses are slightly more separated in different regions of the point cloud</li>
<li>Only in the BERT embedding space, some senses form clearly separable clusters</li>
</ul>
<p><strong>BERT 的不足之处</strong></p>
<p>看 Error analysis</p>
<h2><span id="bert-vs-elmo-vs-gpt-2">BERT vs ELMO vs GPT-2</span></h2><h2><span id="bert-attention-学到了什么">BERT Attention 学到了什么</span></h2><p><a href="https://zhuanlan.zhihu.com/p/148729018">https://zhuanlan.zhihu.com/p/148729018</a></p>
<h2><span id="a-primer-in-bertology-what-we-know-about-how-bert-works">A Primer in BERTology: What we know about how BERT works</span></h2><h2><span id="reference">Reference</span></h2><p>[1] What does BERT Learn from Multiple-Choice Reading Comprehension Datasets? — 2019-5</p>
<p>[2] What does BERT learn about the structure of language?  — 2019-6-4</p>
<p>[3] Open Sesame: Getting Inside BERT’s Linguistic Knowledge - 2019-6</p>
<p>[4] What Does BERT Look At? An Analysis of BERT’s Attention — 2019-6-11</p>
<p>[5] A multiscale visualization of attention in the transformer model  —2019-6-12</p>
<p>[6] BERT Rediscovers the Classical NLP Pipeline — 2019-8</p>
<p>[7] How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer Representations — 2019-9</p>
<p>[9] Does BERT make any sense? interpretable word sense disambiguation with contextualized embeddings</p>
<p>[10] Contextual Embeddings: When Are They Worth It?  — 2020-3-18</p>
<p>[11] A Primer in BERTology: What we know about how BERT works —2020-2-27 综述</p>
<p>How Contextual are Contextualized Word Representations?</p>
<p>Linguistic Knowledge and Transferability of Contextual Representations</p>
<p> <a href="https://www.jiqizhixin.com/articles/2019-09-09-6">https://www.jiqizhixin.com/articles/2019-09-09-6</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/148729018">https://zhuanlan.zhihu.com/p/148729018</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/74515580">https://zhuanlan.zhihu.com/p/74515580</a></p>
<p><a href="https://lsc417.com/2020/06/19/paper-reading3/#prevalence-of-unseen-words">https://lsc417.com/2020/06/19/paper-reading3/#prevalence-of-unseen-words</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/145695511">https://zhuanlan.zhihu.com/p/145695511</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/110085059">https://zhuanlan.zhihu.com/p/110085059</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-多任务学习</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#预训练语言模型-多任务学习">预训练语言模型 - 多任务学习</a><ul>
<li><a href="#经验">经验</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="预训练语言模型-多任务学习">预训练语言模型 - 多任务学习</span></h1><h2><span id="经验">经验</span></h2><h2><span id="reference">Reference</span></h2><p><a href="https://zhuanlan.zhihu.com/p/56900939">如何利用深度学习模型实现多任务学习？这里有三点经验</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/59413549">Multi-task Learning(Review)多任务学习概述</a></p>
<p>MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition using Deep Bidirectional Transformers</p>
<p> MT-DNN: Multi-Task Deep Neural Networks for Natural Language Understanding</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-多语言</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E5%A4%9A%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#多语言预训练语言模型">多语言预训练语言模型</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="多语言预训练语言模型">多语言预训练语言模型</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-对话</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E5%AF%B9%E8%AF%9D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#预训练语言模型-对话">预训练语言模型 - 对话</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="预训练语言模型-对话">预训练语言模型 - 对话</span></h1><h2><span id="reference">Reference</span></h2><p>[1] Dialogpt: Large-scale generative pre-training for conversational response generation</p>
<p>[2] Towards a human-like open-domain chatbot</p>
<p>[3] Recipes for building an open-domain chatbot.</p>
<p>[4] Towards empathetic open- domain conversation models: A new benchmark and dataset. </p>
<p>[5] Plato: Pre-trained dialogue generation model with discrete latent variable.</p>
<p>[6] PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-无监督向量</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E6%97%A0%E7%9B%91%E7%9D%A3%E5%90%91%E9%87%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#生成一个好的-bert-句向量">生成一个好的 bert 句向量</a><ul>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="生成一个好的-bert-句向量">生成一个好的 bert 句向量</span></h1><h2><span id="reference">Reference</span></h2><p><a href="https://mp.weixin.qq.com/s/rtxclvyAEItZhRsHRJem8A">无监督语义相似度哪家强？我们做了个比较全面的评测</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-模型压缩</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#从模型压缩角度看预训练语言模型">从模型压缩角度看预训练语言模型</a></li>
<li><a href="#albert-的一些问题">ALBERT 的一些问题</a><ul>
<li><a href="#albert-的目的">ALBERT 的目的</a></li>
<li><a href="#三大创新">三大创新</a><ul>
<li><a href="#1-factorized-embedding-parameterization">1. Factorized embedding parameterization</a></li>
<li><a href="#2-cross-layer-parameter-sharing">2. Cross-layer parameter sharing</a></li>
<li><a href="#3-sop-替代-nsp">3. SOP 替代 NSP</a></li>
</ul>
</li>
<li><a href="#bert-vs-albert">BERT vs ALBERT</a><ul>
<li><a href="#1-从参数量级上看">1. 从参数量级上看</a></li>
<li><a href="#2-从模型表现上看">2. 从模型表现上看</a></li>
</ul>
</li>
<li><a href="#questions">Questions</a></li>
<li><a href="#reference">Reference</a></li>
<li><a href="#reference-1">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="从模型压缩角度看预训练语言模型">从模型压缩角度看预训练语言模型</span></h1><h1><span id="albert-的一些问题">ALBERT 的一些问题</span></h1><hr>
<p>需要注意的一点是：<strong>ALBERT降低了模型参数量从而降低了模型的训练时间（通信开销降低），但是，模型的预测推理时间并没有降低。</strong>这点需要牢记，并贯穿全文。</p>
<h2><span id="albert-的目的">ALBERT 的目的</span></h2><p>论文开篇就提到，在预训练语言模型领域，增大模型往往能够到来不错的效果提升，但这种提升是无止境的吗？[2]中进行了详细的实验，相当程度上解答了这一问题。这里先埋一个坑，过几天再填。</p>
<p>预训练语言模型已经很大了，大到绝大多数的实验室和公司都没有资格参与这场游戏，对于大模型而言，一个很浅的idea就是：<strong>如何对大模型进行压缩？</strong> ALBERT 本质就是对 BERT 模型压缩后的产物。</p>
<p>如果对模型压缩有了解的同学肯定知道，模型压缩有很多手段，包括<strong>剪枝，参数共享，低秩分解，网络结构设计，知识蒸馏</strong>等。ALBERT 也没能逃出这一框架，它其实是一个相当工程化的思想，它的两大 压缩Trick 也很容易想到，下面就细聊一下。</p>
<h2><span id="三大创新">三大创新</span></h2><h3><span id="1-factorized-embedding-parameterization">1. Factorized embedding parameterization</span></h3><p>该 Trick 本质上就是一个<strong>低秩分解</strong>的操作，其通过对Embedding 部分降维来达到降低参数的作用。在最初的BERT中，以Base为例，Embedding层的维度与隐层的维度一样都是768，但是我们知道，对于词的分布式表示，往往并不需要这么高的维度，比如在Word2Vec时代就多采用50或300这样的维度。那么一个很简单的思想就是，通过将Embedding部分分解来达到降低参数量的作用，其以公式表示如下：</p>
<script type="math/tex; mode=display">
O(V \times H) \to O(V \times E + E \times H)</script><ul>
<li>V：词表大小；H：隐层维度；E：词向量维度</li>
</ul>
<p>我们以 BERT-Base 为例。Base中的Hidden size 为768， 词表大小为3w，此时的参数量为：768 <em> 3w = 23040000。 如果将 Embedding 的维度改为 128，那么此时Embedding层的参数量为： 128 </em> 3w + 128 * 768 = 3938304。二者的差为19101696，大约为19M。</p>
<p>我们看到，其实Embedding参数量从原来的23M变为了现在的4M，似乎变化特别大，然而当我们放到全局来看的话，BERT-Base的参数量在110M，降低19M也不能产生什么革命性的变化。因此，可以说<strong>Embedding层的因式分解其实并不是降低参数量的主要手段。</strong></p>
<p>注意，我在这里特意忽略了Position Embedding的那部分参数量， 主要是考虑到512相对于3W显得有点微不足道。</p>
<p>文章在4.4中，对词向量维度的选择做了详细的探讨：</p>
<p><img data-src="/Users/songyingxin/Desktop/NLPer-Interview/7-深度学习自然语言处理/6-预训练语言模型/image/ALBERT_1.PNG" alt="1"></p>
<p>从上图中，我们可以看出，增大词向量维度所带来的收益在128之后十分少，这也呼应了上面的观点。</p>
<h3><span id="2-cross-layer-parameter-sharing">2. Cross-layer parameter sharing</span></h3><p>该Trick本质上就是对<strong>参数共享机制</strong>在Transformer内的探讨。在Transfor中有两大主要的组件：<strong>FFN</strong>与<strong>多头注意力机制</strong>。ALBERT主要是对这两大组件的共享机制进行探讨。</p>
<p><img data-src="/Users/songyingxin/Desktop/NLPer-Interview/7-深度学习自然语言处理/6-预训练语言模型/image/ALBERT_2.png" alt="2"></p>
<p>论文里采用了四种方式： <strong>all-shared，shared-attention，shared-FFN以及 not-shared。</strong></p>
<p>首选关注一下参数量，not-shared与all-shared的参数量相差极为明显，因此可以得出共享机制才是参数量大幅减少的根本原因。然后，我们看到，只共享Attention参数能够获得参数量与性能的权衡。最后，很明显的就是，随着层数的加深，基于共享机制的 ALBERT 参数量与BERT参数量相比下降的更加明显。</p>
<p>此外，文章还说道，通过共享机制，能够帮助模型稳定网络的参数。这点是通过L2距离与 cosine similarity 得出的，俺也不太懂，感兴趣的可以找其他文章看看：</p>
<p><img data-src="/Users/songyingxin/Desktop/NLPer-Interview/7-深度学习自然语言处理/6-预训练语言模型/image/ALBERT_3.PNG" alt="3"></p>
<h3><span id="3-sop-替代-nsp">3. SOP 替代 NSP</span></h3><p>SOP 全称为 Sentence Order Prediction，其用来取代 NSP 在 BERT 中的作用，毕竟一些实验表示NSP非但没有作用，反而会对模型带来一些损害。SOP的方式与NSP相似，其也是判断第二句话是不是第一句话的下一句，但对于负例来说，SOP并不从不相关的句子中生成，而是将原来连续的两句话翻转形成负例。</p>
<p>很明显的就可以看出，SOP的设计明显比NSP更加巧妙，毕竟NSP任务的确比较简单，不相关句子的学习不要太容易了。论文也比较了二者：</p>
<p><img data-src="/Users/songyingxin/Desktop/NLPer-Interview/7-深度学习自然语言处理/6-预训练语言模型/image/ALBERT_4.PNG" alt="4"></p>
<h2><span id="bert-vs-albert">BERT vs ALBERT</span></h2><h3><span id="1-从参数量级上看">1. 从参数量级上看</span></h3><p><img data-src="/Users/songyingxin/Desktop/NLPer-Interview/7-深度学习自然语言处理/6-预训练语言模型/image/ALBERT_5.PNG" alt="5"></p>
<p>首先，参数量级上的对比如上表所示，十分明显。这里需要提到的是ALBERT-xxlarge，它只有12层，但是隐层维度高达4096，这是考虑到深层网络的计算量问题，其本质上是一个浅而宽的网络。</p>
<h3><span id="2-从模型表现上看">2. 从模型表现上看</span></h3><p><img data-src="/Users/songyingxin/Desktop/NLPer-Interview/7-深度学习自然语言处理/6-预训练语言模型/image/ALBERT_6.PNG" alt="6"></p>
<p>首先，我们看到 ALBERT-xxlarge的表现完全超过了BERT-large的表现，但是BERT-large的速度是要比ALBERT-xxlarge快3倍左右的。</p>
<p>其次，BERT-xlarge的表现反而变差，这点在[2]中有详细探讨，先略过不表。</p>
<h2><span id="questions">Questions</span></h2><h2><span id="reference">Reference</span></h2><p>[1] ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</p>
<p>[2] T5 - Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</p>
<h2><span id="reference">Reference</span></h2><p>模型剪枝</p>
<p>Compressing BERT: Studying the effects of weight pruning on transfer learning.</p>
<p>精度</p>
<p>Q- BERT: Hessian based ultra low precision quantization of BERT.</p>
<p>Q8BERT: Quantized 8bit BERT</p>
<p>参数共享</p>
<p>ALBERT: A lite BERT for self-supervised learning of language representations.</p>
<p>模型蒸馏</p>
<p>DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. </p>
<p>TwinBERT: Distill- ing knowledge to twin-structured BERT models for efficient retrieval. </p>
<p>TinyBERT: Distilling BERT for natural language understanding</p>
<p>Patientknowl- edge distillation for BERT model compression.</p>
<p>Well-read students learn better: The impact of student initialization on knowledge distillation.</p>
<p>MobileBERT: Task-agnostic com- pression of BERT by progressive knowledge transfer.</p>
<p>MiniLM: Deep self-attention distillation for task-agnostic compression of pre-trained transformers</p>
<p>Extreme language model compression with optimal subwords and shared projections.</p>
<p>FastBERT: a Self-distilling BERT with Adaptive Inference Time</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-自然语言生成</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#预训练语言模型-自然语言生成">预训练语言模型 - 自然语言生成</a><ul>
<li><a href="#mass">MASS</a><ul>
<li><a href="#1-语言模型思想">1. 语言模型思想</a></li>
<li><a href="#2-mass-vs-bert">2. MASS vs Bert</a></li>
<li><a href="#3-mass-与-gpt">3. MASS 与 GPT</a></li>
<li><a href="#4-为何-mass-适合生成">4. 为何 MASS 适合生成</a></li>
<li><a href="#5-mass-小结">5. MASS 小结</a></li>
</ul>
</li>
<li><a href="#unilm">UNILM</a></li>
<li><a href="#bart">BART</a></li>
<li><a href="#questions">Questions</a></li>
<li><a href="#mbart">mBART</a></li>
<li><a href="#pegasus">PEGASUS</a></li>
<li><a href="#最后">最后</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="预训练语言模型-自然语言生成">预训练语言模型 - 自然语言生成</span></h1><h2><span id="mass">MASS</span></h2><h3><span id="1-语言模型思想">1. 语言模型思想</span></h3><p><img data-src="image/MASS_1.png" alt></p>
<p>MASS 的思想很简单， 对于输入序列 x，  mask 该句从 u 到 v 位置上的token，记为 $x^{\u:v}$， 而对应的， 从 u 到 v 位置上的 token 片段记为 $x^{u:v}$ 。 k = v - u + 1 表示 mask 的窗口大小 ， 表示一句话中多少个 token 被 mask 。 对于 MASS 的语言模型来说， 其输入为 mask 后的序列 $x^{\u:v}$ ， 输出为被 mask 后的序列 $x^{u:v}$。</p>
<p>同时， MASS 将 Seq2Seq 的思想融入进去，这样就可以同时预测连续的词，从模型上看，我们也能推断它的生成效果是要好于Bert 的。 MASS 的损失函数为：</p>
<script type="math/tex; mode=display">
P(s) = P(x^{u:v} | x^{\u:v})\\</script><script type="math/tex; mode=display">
L(\theta; X) = \frac{1}{|X|}  \sum_{x \in X} log P(x^{u:v} | x^{\u:v}; \theta) \\
= \frac{1}{X} \sum_{x \in X} log \prod_{t=u}^v P(x_t^{u:v} | x_{<t}^{u:v}, x^{\u:v}; \theta)</script><h3><span id="2-mass-vs-bert">2. MASS vs Bert</span></h3><p>前面提到， MASS 中有一个重要的参数 k， 该参数决定对于输入序列 x， 多少个 token 会被 mask 掉， 而 Bert 中会 mask 掉 15% 的token（MASS 3.2中是不是讲错了，并不是mask一个token呀）， 且 Bert 属于随机 mask， 而 MASS 是 mask 连续的 token。</p>
<p>MASS 原论文中谈及 Bert ，认为 Bert 一句话中只 mask 掉一个token， 因此它有一个比较：</p>
<p><img data-src="image/MASS_2.png" alt></p>
<p>而 Bert 其实在一句话中会 mask 掉15% 的token， 难道是我理解有问题？ </p>
<p>还有一点需要注意的是， BERT 并不是 encoder-decode 结构，这里只是为了比较把它转化为 encoder-decoder 结构，严格来说，bert 是一个 Encoder。</p>
<h3><span id="3-mass-与-gpt">3. MASS 与 GPT</span></h3><p><img data-src="image/MASS_3.png" alt></p>
<p>当 k = m 时， 与 GPT 的情形一样。注意，GPT 同样也不是一个 encoder-decoder 结构， 严格来说，它是一个 Decoder。</p>
<h3><span id="4-为何-mass-适合生成">4. 为何 MASS 适合生成</span></h3><p><strong>首先，</strong> 通过 Seq2Seq 框架来预测被 mask 的tokens 使得 Encoder 去学习没有被 mask 的 token 的信息， 而Decoder 去学习如何从 Encoder 中提取有效的信息。</p>
<p><strong>然后，</strong> 与预测离散的 tokens相比，Decoder 通过预测连续的 tokens， 其能够建立很好的语言生成能力。</p>
<p><strong>最后，</strong> 通过输入与输出的 mask 匹配， 使得 Decoder 能够从Encoder 中提取到有意义的信息，而不是利用之前的信息。 （其实是一句有用的废话）</p>
<h3><span id="5-mass-小结">5. MASS 小结</span></h3><p>MASS 总结来说有以下几点重新：</p>
<ul>
<li>引入了 Seq2Seq 来训练预训练模型。</li>
<li><strong>mask 掉的是一段连续的tokens而不是离散的 mask， 有助于模型生成语言的能力。</strong></li>
<li>Encoder 中是 mask 掉的序列，而 Decoder 中是对应被mask的 tokens。</li>
</ul>
<h2><span id="unilm">UNILM</span></h2><p>UNILM  就厉害了， 它想直接训一个预训练语言模型， 又能做自然语言理解，又能做自然语言生成。UNILM 的基本单元依旧是多层的 Transformer， 不同的是，这些 Transformer 网络要在多个语言模型上进行预训练：  unidirectional LM， bidirectional LM 和 Seq2Seq LM ， 下文会忽略一些细枝末节，主要专注如何预训练语言模型的。</p>
<p><strong>UNILM 这篇文章，厉害在同时使用多个预训练语言模型训练这个思想</strong>， 至于怎么做，我觉得倒是其次，不是很重要。</p>
<p>大致的框架如下：</p>
<p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g4d6mx2mcwj30o80jhdid.jpg" alt></p>
<p><strong>1， Input Representation</strong></p>
<p>这部分与Bert 大同小异， 不过还是得细说一下。 UNILM 的输入为单词序列，序列可能是一个针对unidirectional LMs的文本段， 也有可能是针对 bidirectional LM 和 Seq2Seq LM的一对文本段。 输入的序列格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[SOS] + segment1 + [EOS]</span><br><span class="line">[SOS] + segment1 + [EOS] + segment2 + [EOS]</span><br></pre></td></tr></table></figure>
<p>与 Bert 相同， 模型的输入都为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">token embedding + position embedding + segment embedding</span><br></pre></td></tr></table></figure>
<p>还有一点是， UNILM 将所有的 token 都处理成为 subword， 可以增强生成模型的表现能力，emmm， maybe？ 我觉得不是重点。</p>
<p><strong>2，Unidirectional LM </strong></p>
<p>输入单段落， UNILM 同时采用 left-to-right LM 与 right-to-left LM 来做（有点像 ELMO）， 这与 Bert 的方式有很大的区别， 我想这是从生成方面考虑因此如此设计， 细节，懒得抠了， 感兴趣的可以看看。</p>
<p><strong>3，Bidirectional LM </strong></p>
<p>输入段落对， 其实就是 Bert 的那种训练方式， 没啥好说的， 略。</p>
<p><strong>4， Seq2Seq LM</strong></p>
<p>输入段落对， 第一段采用 Bidirectional LM 的方式编码， 而对于第二句采用 Unidirectional LM 的方式解码， 然后同时训练。</p>
<p><strong>5， Next Sentence Prediction</strong></p>
<p>没啥好说的，和 Bert 里面差不多，略。</p>
<p><strong>7. 参数从 Bert-large 初始化</strong></p>
<h2><span id="bart">BART</span></h2><p>BART 与 MASS 的基本思想一致，都是受到 Transformer 在机器翻译领域的成功，尝试将 Transformer架构跟预训练结合起来。</p>
<p>但是与 MASS 不同的是，他们输入的数据格式有很大的差别，Decoder 也有较大的差别。与MASS 相比， BART 完全延续 Transformer 原来的架构方式。</p>
<p><strong>训练数据：</strong></p>
<ul>
<li><strong>Token Masking</strong> 和BERT一样，随机选择<strong>token</strong>用[MASK] 代替。</li>
<li><strong>Token Deletion</strong> 随机删除<strong>token</strong>，模型必须确定哪些<strong>位置</strong>缺少输入。</li>
<li><strong>Text Filling</strong> 屏蔽一个<strong>文段</strong>，文段长度服从泊松分布（λ=3）。每个文段被<strong>一个[MASK]</strong>标记替换。如果文段长度为0，意味插入一个[MASK]标记（灵感来自Span-BERT）。</li>
<li><strong>Sentence Permutation</strong> 以句号作为分割符，将一篇文章分成多个<strong>句子</strong>，并随机打乱。</li>
<li><strong>Document Rotation</strong> 随机均匀地选择一个<strong>token</strong>，以这个token为中心，旋转文档，选中的这个token作为新的开头，此任务训练模型以识别文档的开头。</li>
</ul>
<h2><span id="questions">Questions</span></h2><p><strong>1， MASS 中的 mask策略？</strong></p>
<p>对于 MASS  而言， 其采用随机 Mask 一段连续的 tokens， 有没有更佳的方式来学习， 比如， 30% mask 前面的 tokens， 20% mask 后面的tokens， 50% 随机mask 中间tokens。 这是考虑到对于句子生成来说， 开头和结尾可能需要更充分的训练与学习。</p>
<p><strong>2， Bert 能不能直接做 Encoder 端</strong></p>
<p>用已经学习好的<strong>预训练语言模型（如Bert）</strong>来做 Encoder 端（Freeze Encoder 端的参数）会不会更能把握输入序列的信息， 因为毕竟预训练语言模型在自然语言理解上已经获得了很大的成功，Decoder 只要学习如何从理解后的信息中提取信息来生成语言即可，这样能够大大减轻训练的时间和复杂度，或许效果也会更好。</p>
<p><strong>3， MASS vs UNILM</strong></p>
<p>二者相比，无疑 UNILM 更胜一筹，无论是从创新角度还是模型复杂度与精致程度而言。 但对于未来的发展来说，我个人更看好 <strong>Encoder-Decoder</strong> 这种方式， 语言生成是基于语言理解的基础上的，那么语言理解所诞生的预训练语言模型为何不直接用到生成预训练模型里面呢？ 有必要从头训吗？ 有必要<strong>生成+ 理解</strong>一起训吗？</p>
<h2><span id="mbart">mBART</span></h2><h2><span id="pegasus">PEGASUS</span></h2><h2><span id="最后">最后</span></h2><p>其实，我想表达的核心在于， <strong>理解与生成是否共存？</strong> 如果共存， 以哪种方式？ <strong>多任务学习</strong>会不会是一个解法， <strong>GPT 2.0</strong> 这种单纯<strong>堆数据和模型 + 无监督下游任务</strong>会不会是正解？ <strong>有没有可能用多阶段的预训练任务来做，先做理解，然后以理解的预训练语言模型为Encoder 来做生成预训练， 最后再在下游任务微调生成？</strong>还是像 UNILM 那样走多预训练语言模型共同训练的方式。</p>
<p>我现在倒是觉得， 目前预训练模型走的路子与认知神经科学有着很相似的地方。自然语言理解目前已经实现突破， 相信接下来自然语言生成将成为主要战场。 </p>
<h2><span id="reference">Reference</span></h2><p>[1] <a href="https://mp.weixin.qq.com/s/tQ4GyNxVYR9mKwnaAfeAbQ">https://mp.weixin.qq.com/s/tQ4GyNxVYR9mKwnaAfeAbQ</a></p>
<p>【1】<a href="https://yq.aliyun.com/articles/431463">阿士比亚：搜索团队智能内容生成实践</a></p>
<p>【2】 <a href="https://zhuanlan.zhihu.com/p/33956907">阿里-搜索团队智能内容生成实践</a></p>
<p><a href="https://www.infoq.cn/article/WiEUHYwyqFsYJIgLUed5">https://www.infoq.cn/article/WiEUHYwyqFsYJIgLUed5</a></p>
<p>A Survey of Knowledge-Enhanced Text Generation</p>
<p><a href="https://mp.weixin.qq.com/s/XdenY85LTpqC2p4HLe5CAw">https://mp.weixin.qq.com/s/XdenY85LTpqC2p4HLe5CAw</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247514230&amp;idx=1&amp;sn=97ff879c8b80d281b26319ba08357afd&amp;chksm=96ea67f6a19deee0dfd554f0ae1ee5d3ab49dbcf1d44fd0c2fa170e0d0420b9980136aaaa5df&amp;token=2093744412&amp;lang=zh_CN&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247514230&amp;idx=1&amp;sn=97ff879c8b80d281b26319ba08357afd&amp;chksm=96ea67f6a19deee0dfd554f0ae1ee5d3ab49dbcf1d44fd0c2fa170e0d0420b9980136aaaa5df&amp;token=2093744412&amp;lang=zh_CN&amp;scene=21#wechat_redirect</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模性-融入知识图谱</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/6-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20-%20%E8%9E%8D%E5%85%A5%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#预训练语言模型-融入知识图谱">预训练语言模型 - 融入知识图谱</a><ul>
<li><a href="#1-ernie-百度">1. ERNIE - 百度</a><ul>
<li><a href="#1-双向transformer">1. 双向Transformer</a></li>
<li><a href="#2-不同粒度的信息融合">2. 不同粒度的信息融合</a></li>
<li><a href="#3-basic-level-masking-预训练">3. Basic-Level Masking 预训练</a></li>
<li><a href="#4-phrase-level-masking-预训练">4. Phrase-level Masking 预训练</a></li>
<li><a href="#5-entity-level-masking-预训练">5. Entity-level Masking 预训练</a></li>
<li><a href="#6-多源数据">6. 多源数据</a></li>
<li><a href="#7-dlmdialogue-language-model">7. DLM：Dialogue Language Model</a></li>
</ul>
</li>
<li><a href="#ernie-清华-2">ERNIE: 清华 [2]</a><ul>
<li><a href="#1-模型架构">1. 模型架构</a></li>
<li><a href="#2-模型输入">2. 模型输入</a></li>
<li><a href="#3-t-encoder">3. T - Encoder</a></li>
<li><a href="#4-transeencode-知识图谱">4. TransE：encode 知识图谱</a></li>
<li><a href="#5-k-encoder">5. K - Encoder</a></li>
<li><a href="#6-dea-denoising-entity-auto-encoder">6. dEA: denoising entity auto-encoder</a></li>
<li><a href="#7-其余">7. 其余</a></li>
</ul>
</li>
<li><a href="#3-k-bert">3. K-BERT</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="预训练语言模型-融入知识图谱">预训练语言模型 - 融入知识图谱</span></h1><h2><span id="1-ernie-百度">1. ERNIE - 百度</span></h2><p>百度的这篇文章更像是 Bert 模型对于中文的针对性改进，当然对英文也有一定的作用，但对于中文来说更明显。</p>
<h3><span id="1-双向transformer">1. 双向Transformer</span></h3><p>ERNIE 同样采用多层的双向Transoformer 来作为特征提取的基本单元，这部分没啥创新，就是简单提一下。 </p>
<h3><span id="2-不同粒度的信息融合">2. 不同粒度的信息融合</span></h3><p>ERNIE 同样采用了多种粒度信息，只不过不同粒度信息的预训练过程与 Bert 不同， 对于一个 token， 其同样由 token embedding + segment embedding + position embedding 组成，与 bert 相同， 每一句话的第一个 token 都为 [CLS]。</p>
<p><img data-src="https://pic2.zhimg.com/v2-68664a317aa9b18bb8d3377a99f4dd4d_b.jpg" alt="img"></p>
<h3><span id="3-basic-level-masking-预训练">3. Basic-Level Masking 预训练</span></h3><p>这个过程与 Bert 中的 MLM 类似，是对于词粒度的预训练。 对于英文而言，粒度为 word， 对于中文而言，粒度为字。</p>
<p>随机 Mask 输入序列中 15% 的 token， 然后预测这些被 mask 掉的 tokens。这点与 Bert 相同， 不同的是，其论文中没有提到十分采用类似 Bert 的那种 Mask 的Trick 来降低预训练与预测的不一致性，这点需要看代码确认一下。</p>
<h3><span id="4-phrase-level-masking-预训练">4. Phrase-level Masking 预训练</span></h3><p>我个人认为短语级别的粒度信息对于中文，英文来说都是有用的。</p>
<p>对于中文来说， 比如 “放你一马”， 这从单单的字粒度信息是学习不到的，且这种信息相当多。而对于英文来说，英文短语也不在少数，就像： pull up, pull down, push up, push down 我觉得word粒度对这种短语信息也是难以捕捉的。</p>
<p>在这部分的预训练过程中，首先采用对应的工具识别出句子中存在的 Phrase， 然后随机 Mask 句子中的一些短语（文章并没有说 mask 多少百分比）， 然后预测 mask 掉的 Phrase 中的 word（字）， 即以 word（字）为预测单元。</p>
<h3><span id="5-entity-level-masking-预训练">5. Entity-level Masking 预训练</span></h3><p>实体信息包括人名，地名，组织名称，产品名称等， 而实体又是一种抽象的概念，且通常包含着一些重要的信息，且实体之间的关系也十分重要。 ERNIE 先用命名实体识别找出句子中的实体，然后与 Phrase-level 一样， mask 其中的一些实体并预测这些mask掉的 word (字)。</p>
<p><img data-src="https://pic1.zhimg.com/v2-c09fc9150ac135c0b26d24f2d0332860_b.jpg" alt="img"></p>
<p>对此，Entity-level Masking 预训练能够捕捉到实体的语义信息，这点是毋庸置疑的，但对于实体间关系的抽取，从模型上来看并不突出，希望有大佬解释一下（论文中是提到可以学习到实体间关系，只是我对此存疑）。</p>
<h3><span id="6-多源数据">6. 多源数据</span></h3><p>ERNIE 在预训练时采用了多源数据，包括：中文维基百科，百度百科，百度新闻，百度贴吧。其中，百度贴吧由于其社区的特性，里面的内容是对话形式的，而 ERNIE 中对于 Segement Embedding 预训练与 Bert 的 NSP 不同的是，其采用 DLM 来获得这种句子粒度级别的信息，而这对于句子语义的把握更佳准确。</p>
<h3><span id="7-dlmdialogue-language-model">7. DLM：Dialogue Language Model</span></h3><p>对比 Bert 中的 NSP， 似乎 DLM 更能把握句子的语义信息，且对于对话，问答这种形式的任务效果更好。 DLM 的训练过程与 NSP 也有很大的区别，其输入如下：</p>
<p><img data-src="https://pic2.zhimg.com/v2-68664a317aa9b18bb8d3377a99f4dd4d_b.jpg" alt="img"></p>
<p>为了使得 ERNIE 能够表示多轮对话，其输入采用QRQ, QQR,QRR（Q表示Query， R表示Response) 这几种形式， 如上图就是 QRQ 的一个例子。 ERNIE 会 mask 掉输入的一些 token， 然后让模型去预测这些被 mask 掉的 token（文章并没有给出mask比例以及如何分配mask）。 </p>
<p>同样有趣的是，ERNIE 也通过随机替换 Query 或 Response的方式来会添加一些 fake 样本来让模型去预测该输入是 real 还是 fake。</p>
<p>DLM 与 NSP 相比， 其更加复杂也更倾向于对话这种更高难度的任务，我个人认为，这种方式对于对话这种任务来说帮助很大。 </p>
<h2><span id="ernie-清华-2">ERNIE: 清华 [2]</span></h2><p>清华的这篇文章与百度的有很大的差异，同样是引入外部知识，清华走了与百度完全不一样的道路，我们先来看看他们是怎么做的。</p>
<p>两篇文章对比，百度那篇文章更侧重于训练一个更好的预训练语言模型， 而清华的这篇文章更侧重于如何融入知识图谱。</p>
<p><strong>融入知识图谱面临的两大挑战</strong></p>
<p>知识图谱本质是 实体 + 实体间关系， 其中实体为点，实体间关系为边。而将知识图谱引入到预训练语言模型，有两个主要的挑战：</p>
<ul>
<li>Structed Knowledge Encoding： 对于给定的文本，如何有效的提取其中的知识图谱信息并对其进行 encode。</li>
<li>Heterogeneous Information Fusion： 即如何将 encode 后的知识图谱信息融入预训练模型。</li>
</ul>
<h3><span id="1-模型架构">1. 模型架构</span></h3><p><img data-src="https://pic4.zhimg.com/v2-92067a2107fc7196a429e8bbc3ffdd2f_b.jpg" alt="img"></p>
<p>我们看到，上述整个模型可以整体分为两部分：</p>
<ul>
<li>T-Encoder： 与 Bert 的预训练过程完全相同，是一个多层的双向 Transformer encoder， 用来捕捉词汇和语法信息。</li>
<li>K-Encoder： 本文创新点，描述如何将知识图谱融入到预训练模型。</li>
</ul>
<h3><span id="2-模型输入">2. 模型输入</span></h3><p>对于一个给定的句子， 以下是其对应的 token 序列，划分按照word（字）： </p>
<script type="math/tex; mode=display">
{w_1, \cdots, w_n}; \, \text{n 为token序列长度}</script><p>同时，文章采用<strong>命名实体识别</strong>的方式识别出句子中的实体，并与知识图谱中的实体进行对应， 由于实体往往不止一个token， 因此实体序列的长度与token序列的长度往往并不相等： </p>
<script type="math/tex; mode=display">
{e_1, \cdots, e_m}, \, m 为实体序列长度</script><h3><span id="3-t-encoder">3. T - Encoder</span></h3><p>前面提到，就是与 Bert 完全相同的，一个多层的双向 Transformer encoder， 其输出为： </p>
<script type="math/tex; mode=display">
{w_1, \cdots, w_n} = \text{T-Encoder}({w_1, ...w_n})</script><h3><span id="4-transeencode-知识图谱">4. TransE：encode 知识图谱</span></h3><p>TransE 能够将实体与实体间关系转化为一种分布式表示， 而论文中就是采用这种方法，具体的我也不介绍了，对这方面了解有限： </p>
<script type="math/tex; mode=display">
{e_1, \cdots, e_m} = TransE({e_1, \cdots, e_m })</script><h3><span id="5-k-encoder">5. K - Encoder</span></h3><script type="math/tex; mode=display">
{ w_1^o, \cdots, w_n^o}, {e_1^o, \cdots, e_n^o } = \text{K-Encoder} ({ w_1, \cdots w_n}, {e_1, \cdots, e_m })</script><p>K - Encoder 的输入 tokens embedding 以及  entity embedding 首先分别经过一个多层的 Multi-head self-attentions(MH-ATTs)： </p>
<script type="math/tex; mode=display">
{\hat{w}^{(i)}_1, \cdots, \hat{w}_n^{(i)} } = \text{MH-ATT} ({w_1^{(i-1)}, \cdots, w_n^{(i-1)}}) \\ {\hat{e}^{(i)}_1, \cdots, \hat{e}_m^{(i)} } = \text{MH-ATT} ({e_1^{(i-1)}, \cdots, e_m^{(i-1)}}) \</script><p>然后要将 entity embedding  与 token embedding  融合， 其中，emtity  与 token 之间是有对应的，文中采用第一个 token 作为对应方式，一部分token有对应的entity， 一部分没有（如上图）。 </p>
<ul>
<li><p>对于有对应实体的情况，则有：   </p>
<script type="math/tex; mode=display">
w_j^{(i)} = \sigma(W_t^{(i)} h_j + b_t^{(i)}) \   e_k^{(i)} = \sigma(W_e^{(i)} h_j + b_e^{(i)}) \\
h_j = \sigma (\hat{W}_t^{(i)} \hat{w_j}^{(i)} + \hat{W}_e^{(i)} \hat{e}_k^{(i)} + \hat{b}^{(i)}) \\</script></li>
<li><p>对于没有对应实体的情况，则有：   </p>
<script type="math/tex; mode=display">
w_j^{(i)} = \sigma(W_t^{(i)} h_j + b_t^{(i)}) \\
h_j = \sigma (\hat{W}_t^{(i)} \hat{w_j}^{(i)}  + \hat{b}^{(i)}) \\</script></li>
</ul>
<p>此处的激活函数可以选择 GELU， <img data-src="https://www.zhihu.com/equation?tex=h_j" alt="h_j">h_j 表示集成了 emtity 信息与 token 信息的隐层状态。 </p>
<p>将上述操作简单描述， 那么第 i 个 aggregator  操作可以简述为： </p>
<script type="math/tex; mode=display">
{w_1^{(i)}, \cdots, w_n^{(i)} }, {e_1^{(i)}, \cdots, e_m^{(i)} } = \text{Aggregator}({w_1^{(i-1)}, \cdots , w_n^{(i-1)}}, {e_1^{(i-1)}, \cdots, e_m^{(i-1)} })</script><h3><span id="6-dea-denoising-entity-auto-encoder">6. dEA: denoising entity auto-encoder</span></h3><script type="math/tex; mode=display">
{\sum_{k=1}^m exp(linear(w_i^o) \cdot e_k)}</script><p>从上式我们可以看出，该阶段的目的就是对于token序列与entity序列，计算每个token所对应的 entity 序列概率分布，以此来进行预训练。 </p>
<p>该预训练模块的目的其实很明确，就是为了将 K-Encoder 输出的信息结合，毕竟不是每一个 token 都有对应的实体信息的。</p>
<p>在 dEA 的预训练过程中，考虑到 token 与 entity 之间的对齐误差， 因此采用一些策略进行调整：</p>
<ul>
<li>5% 的情况下，对于给定的 token-entity 对，我们将实体替换为其他随机实体， 旨在减轻对齐过程所带来的误差。</li>
<li>15% 情况下，mask token-entity 对， 旨在减轻对于新 token-entity 所带来的误差</li>
<li>剩下80% ， 保持不变。</li>
</ul>
<h3><span id="7-其余">7. 其余</span></h3><p>论文中的细节与创新点就是这些，其余的我觉得看的意义不是很大，因此我就简单过了，感兴趣的可以看一看，毕竟咱也没有资源去试。</p>
<h2><span id="3-k-bert">3. K-BERT</span></h2><h2><span id="reference">Reference</span></h2><p>[1]  ERNIE: Enhanced Representation through Knowledge Integration</p>
<p>[2]  ERNIE: Enhanced Language Representation with Informative Entities</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>预训练语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>信息检索</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/7-%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#上游任务-信息检索">上游任务 — 信息检索</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="上游任务-信息检索">上游任务 — 信息检索</span></h1><p><a href="https://www.msra.cn/zh-cn/news/features/ming-zhou-nlp-search-engine">https://www.msra.cn/zh-cn/news/features/ming-zhou-nlp-search-engine</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>阅读理解</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/7-%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#上游任务-阅读理解">上游任务 - 阅读理解</a><ul>
<li><a href="#1-attentive-reader-1">1. Attentive Reader [1]</a></li>
<li><a href="#2-standford-reader2">2. Standford Reader[2]</a></li>
<li><a href="#3-attention-sum-reader-3">3. Attention Sum Reader [3]</a></li>
<li><a href="#4-attention-over-attention-4">4. Attention-over-Attention [4]</a></li>
<li><a href="#5-gated-attention-reader-5">5. Gated-Attention Reader [5]</a></li>
<li><a href="#6-bidaf-6">6. BiDAF [6]</a><ul>
<li><a href="#核心点-双向注意力机制">核心点： 双向注意力机制</a></li>
</ul>
</li>
<li><a href="#7-dcn-7">7. DCN [7]</a><ul>
<li><a href="#核心-coattention-encoder">核心： CoAttention Encoder</a></li>
</ul>
</li>
<li><a href="#8-qanet-8">8. QANet [8]</a><ul>
<li><a href="#核心点-多维信息融合">核心点： 多维信息融合</a></li>
<li><a href="#context-query-attention-layer">Context-Query Attention Layer</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="上游任务-阅读理解">上游任务 - 阅读理解</span></h1><hr>
<h2><span id="1-attentive-reader-1">1. Attentive Reader [1]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g164kt342sj30bu07qaa9.jpg" alt></p>
<p>Attentive Reader 就有点常规模型的样子了。 </p>
<ul>
<li><p>首先，采用<strong>双向LSTM</strong>分别对 passage 与 query 进行 Embedding 来获得上下文表示；</p>
<p>其中，对于 passage  而言，其获得的是一个矩阵 y，矩阵的每一列是 passage 中词的上下文表示； </p>
<p>对于 query， 其将整个信息压缩为一个向量 u。 </p>
</li>
<li><p>其次是注意力机制的使用，这里的 Q 为 passage的表示 y， Key 为 query的表示 u， 这里的注意力机制计算公式为：</p>
<script type="math/tex; mode=display">
相似度/相关度计算公式： m(t) = tanh(W_{ym} y(t) + W_{um} u)    \\
注意力权重值计算： s(t) = \frac{e^{W^T_{ms} m(t)}}{\sum_{t=1}^{|p|} e^{W^T_{ms} m(t)}} \\
最终表示： r = ys</script></li>
<li><p>最后是以 r， u 作为接下来模型 output layer 的输入来进行预测。</p>
</li>
</ul>
<p>但可能会存在一个问题，如果 query 的长度也很长，那么压缩成一个向量，其信息的损失不得不考虑进去。</p>
<h2><span id="2-standford-reader2">2. Standford Reader[2]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1fxdmog4989j30kf0cfmyd.jpg" alt></p>
<p>该模型是 <strong>Attentive Reader</strong> 延伸， 但在 Attention 的部分又有所不同。</p>
<ul>
<li><p>首先，模型通过 <strong>双向LSTM</strong> 分别对 Passage 与 Query 进行Embedding， 对于 Passage， 我们获得一个词的上下文信息矩阵：$\tilde{p} \in R^h $； 而对于 Query， 我们获得一个句子级别的向量表示： $q \in R^h$。  </p>
</li>
<li><p>接下来，我们需要计算 Passage 中每个词与 Query的相关度， 然后获得最终输出到output layer 的输出表示：</p>
<script type="math/tex; mode=display">
\alpha_i = softmax_i \, q^T W_s \tilde{p}_i ; \quad W_s \in R^{h \times h } \\
o = \sum_i \alpha_i \tilde{p}_i</script></li>
<li><p>最后，我们将 $o$  输入到 output layer， 然后进行预测：</p>
<script type="math/tex; mode=display">
a = argmax \, W^T_a o</script></li>
</ul>
<p>很明显，该模型更加干净，简洁，且获得的效果是要比 <strong>Attentive Reader</strong> 好 8-10% 个点的。 我们来简单介绍一下二者的不同：</p>
<ul>
<li>首先，在score部分计算相关度时， Attentive Reader 采用的是 tanh， 而该模型中采用的是MLP， 这样不仅仅效果更好，也更高效。 </li>
<li>其次， 在 output layer 部分，Attentive Reader 在最终预测之前，采用 tanh 将 $r$ 与 $u$ 结合起来； 而Standford Reader 仅仅采用 $o$ 作为最终预测的输入， 这种用法更加高效。</li>
<li>考虑到预测的结果是一个会出现在 Passage 中的实体，因此 Standford Reader 仅在出现的实体范围内进行预测。而 Attentive Reader 会在Passage， Question 中出现所有单词中进行预测。</li>
</ul>
<h2><span id="3-attention-sum-reader-3">3. Attention Sum Reader [3]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g1710nay1rj30us0ix76a.jpg" alt></p>
<p>其实，该模型与上面的Standford Reader 很像，但加了一个小 trick。</p>
<ul>
<li><p>首先，采用双向 GRU 分别对 Document 与 Question 进行 Embedding； 对于Document， 我们获得了一个上下文Embedding 矩阵 $f$ ；对于 Question， 我们获得了一个 sentence-level 句子向量$g$。</p>
</li>
<li><p>然后，计算 Document 中每个词与 Question 的相关度，这里采用点积的方式来做：</p>
<script type="math/tex; mode=display">
s_i = softmax(f_i \cdot g)</script></li>
<li><p>最后，考虑到 Document 中同一个词可能会出现多次，因此这里将相同词的注意力权重相加得到该词最终的注意力权重。</p>
<script type="math/tex; mode=display">
Attention \, weight(word) = \sum_{i \in I(w,d)} s_i \\
I(w,d) \, 是 \, word \, 出现在 \, document \, 中位置的集合</script></li>
<li><p>最后，我们从实体选项中选择 Attention weight 最高的作为答案。</p>
<p>但是，分析一下那个Attention Sum 操作， 其源于作者观察到答案更多偏爱出现次数较多的词，这说明，该 trick 是任务偏好的，并没有很广泛的应用价值， trick 有取巧的嫌疑。</p>
</li>
</ul>
<h2><span id="4-attention-over-attention-4">4. Attention-over-Attention [4]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g1729bn779j30t30kdabj.jpg" alt></p>
<p>Attention-over-Attention 这篇文章质量很高，在后续的很多模型中都有使用，创新度也很高，<strong>值得精读。</strong></p>
<ul>
<li><p>首先， 依旧是使用<strong>双向RNN（LSTM or GRU)</strong> 来获得 Document 与 Query 的上下文表示矩阵： $h<em>{doc} \in R^{|D| * 2d}; \quad h</em>{query} \in R^{|Q| * 2d}$。 </p>
</li>
<li><p>然后，我们计算 <strong>Pair-wise Matching Score</strong>，其实就是计算 Document 中<strong>第 i 个词</strong> 与 Query 中的<strong>第 j 个词</strong>的相似度或相关度：</p>
<script type="math/tex; mode=display">
M(i, j) = h_{doc}(i)^T \cdot h_{query}(j)</script></li>
<li><p>再然后，进行 <strong>Individual Attentions</strong>， 其实就是对<strong>矩阵 M 的每一列</strong>做 softmax， 其中，M的一列代表的是<strong>对于 Query 中的某个词与所有 Document 中词的相关度</strong>， 那么对每一列进行 softmax 的意思就是对于给定的一个 Query 词， 对 Document 中的每个词进行 Attention，这里称之为 <strong>query-to-document  attention</strong>， 公式如下：</p>
<script type="math/tex; mode=display">
\alpha(t) = softmax(M(1,t), \cdots, M(|D|, t)); \quad a(t) \in R^{|D|}  \\
\alpha = [\alpha(1), \alpha(2), \cdots, \alpha(|Q|) ]；\quad \alpha \in R^{|Q|\times |D|}</script></li>
<li><p>然后，进行 <strong>Attention-over-Attention</strong>， 其实就是对<strong>矩阵M的每一行做 softmax</strong>， 而 <strong>M 的一行表示的是对于 Document 中的某个词与所有 Query 中词的相关度</strong>，那么对每一行进行softmax 的意思就是对于给定的一个Document 词，对Query 中的每个词进行Attention， 这里称为 <strong>document-to-query attention</strong>， 公式如下：</p>
<script type="math/tex; mode=display">
\beta(t) = softmax(M(t,1), ... M(t, |Q|)); \quad \beta(t) \in R^{|Q|}</script><p>然后， 对 $\beta(t)$ 求和平均来得到 query-level attention $\beta$， 从直观上而言，这里是获得对于整个document，每个query的Attention value:</p>
<script type="math/tex; mode=display">
\beta = \frac{1}{n} \sum_{t=1}^{|D|} \beta(t); \quad \beta \in R^{|Q|}</script><p>最后，我们将 $\alpha$ 与 $\beta$ 做点乘得到 <strong>attention document-level attention</strong>:</p>
<script type="math/tex; mode=display">
s = \alpha^T \cdot \beta \quad ; \quad s \in R^{|D|}</script></li>
<li><p>最终，Final Predictions 将相同词的score 合并，得到每个词的score， 其实就是Attention-Sum里面提出的创新部分：</p>
<script type="math/tex; mode=display">
P(w | D, Q) = \sum_{i \in I(w,D)} s_i, \quad w \in V</script></li>
</ul>
<p>本模型可以说是花式Attention的一个典型代表了，其不仅仅考虑了query到document的attention，而且考虑了document 到 query 的attention，于是称为 attention over attention。 虽然无法解释其内部的玄学，但的确该机制在很多后续的模型中都有应用，效果也不错。</p>
<h2><span id="5-gated-attention-reader-5">5. Gated-Attention Reader [5]</span></h2><p><img data-src="http://ww1.sinaimg.cn/large/006gOeiSly1g17xe43o1oj30qh0d3jsi.jpg" alt></p>
<ul>
<li><p>首先，采用双向RNN（GRU） 来获得 Document 与query的上下文表示矩阵，表示如下：</p>
<script type="math/tex; mode=display">
Document : X^{(0)} = [x_1^{(0)}, x_2^{(0)}, \cdots ,  x_{|D|}^{(0)}] \\
Query: Y = [y_1, y_2, \cdots , y_{|Q|}] \\
Document: D^{(1)} =  \overleftrightarrow{GRU}_D^{(1)}(X^{(0)}) \\
Query: Q^{(k)} =  \overleftrightarrow{GRU}_Q^{(k)}(Y)</script><p>原论文中的图好像画错了，$D^{(k)}$ 前不应该是 $X^{(k-1)}$ 吗？不过倒是不影响理解。</p>
</li>
<li><p>然后，在接下来计算中，我们要不断的迭代 D 与 X：</p>
<script type="math/tex; mode=display">
D^{(k)} =  \overleftrightarrow{GRU}_D^{(k)}(X^{(k-1)}) \\
X^{(k)} = GA(D^{(k)}, Q^{(k)})</script><p>其中， GA Attention 的计算公式如下：</p>
<script type="math/tex; mode=display">
\alpha_i = softmax(Q^T d_i) \\
\tilde{q_i} = Q \alpha_i \\
x_i = d_i \odot \tilde{q_i} \quad or \quad  x_i = d_i + \tilde{q}_i \quad or \quad  x_i = d_i || \tilde{q}_i \\</script><p>从直观上看，其实还是不断的融入 query 信息来获得在 document 中与 query 最相关的实体词 。与上述几个模型来比较，该模型是多层的，更能够把握这种相关语义。</p>
<p>这个过程，我们迭代了K次，最终得到了 $D^{(k)}$ 。 </p>
</li>
<li><p>在Answer Prediction 阶段，先找到空白处位置的词的表示， 然后与 $D^{(k)}$ 做内积，再进行softmax：</p>
<script type="math/tex; mode=display">
q_l^{(K)} = q_l^f || q_{T-L+1}^b \quad ?? \quad  这个不太懂\\
s = softmax((q_l^{(K)})^T D^{(K)})</script></li>
<li><p>最后，再将相同词的概率合并：</p>
<script type="math/tex; mode=display">
Pr(c | d,q ) = \sum_{i \in I(c,d)} s_i</script></li>
</ul>
<h2><span id="6-bidaf-6">6. BiDAF [6]</span></h2><p><img data-src="http://songyingxin-img.oss-cn-beijing.aliyuncs.com/19-1-4/32443699.jpg" alt></p>
<ul>
<li><p>首先，采用char-level 与 word-level 信息，通过 Highway Networks 融合信息来分别获得 Context 与 Query 的矩阵表示：</p>
<script type="math/tex; mode=display">
X \in R^{d \times T} ; \text{T 为 context 中的单词数}\\
Q \in R^{d \times J} ; \text{J 为 Query 中的单词数}</script></li>
<li><p>然后，通过双向 LSTM 来获得每个词的上下文表示：</p>
<script type="math/tex; mode=display">
H \in R^{2d × T} ; \text{Context 的上下文表示}\\
U \in R^{2d × J} ；\text{Query 的上下文表示}</script></li>
</ul>
<h3><span id="核心点-双向注意力机制">核心点： 双向注意力机制</span></h3><p>双向注意力机制包括 Context-to-Query 与 Query-to-Context 两大部分：</p>
<ul>
<li>首先，我们先计算 H 与 U 的相似矩阵：$S\in R^{T × J}$， 对于context 中的第 $t$ 个单词与 query 中的第 $j$ 个单词，有：<script type="math/tex; mode=display">
S_{tj} = \alpha({H_{:t}, U_{:j}}) = \alpha(h,u) = W_{(S)}^T[h;u;h \circ u] \\
H_{:t}：\text{context 的第 t 列} \\
U_{:j}：\text{Query 的第 j 列}</script></li>
</ul>
<ul>
<li><p><strong>Context-to-query Attention（C2Q）：</strong>其含义是对于 Context 中的第 $t$ 个单词， 我们计算 Query 中的每个单词与该词的相关度，然后进行加权求和将 Query 的信息融合入 Context。 </p>
<p>我们用 $a_t \in R^J$ 来表示对于单词 $t$ 的这种相关度：</p>
<script type="math/tex; mode=display">
a_t = softmax(S_{t:}) \in R^J ; \quad S_{t:}: \text{S 的第t行}\\</script><p>然后我们通过这些相关度信息来将计算 Context 中每个词的新表示：</p>
<script type="math/tex; mode=display">
\hat{U}_{:t} = \sum_j a_{tj}U_{:j} \in R^{2d \times T} \\
\hat{U}_{:t}: \hat{U} 的第 t 列 \\
U_{:j}: U 的第j列</script></li>
<li><p><strong>Query-to-context Attention（Q2C）</strong>：其本质是计算对于 Query 中的词， Context 中的每个词与它的相关度， 然后通过加权求和将 Context 的信息融入到 Query 中。 而此段中的计算与上述有所不同：</p>
<script type="math/tex; mode=display">
b = softmax(max_{col}(S)) \in R^T; \quad</script><p>上式的含义是先取 S 中每一列的最大值形成一个新的向量 ， 然后对这个新的向量求相关度， 其实意思对于 Query 的整体信息， Context 中每个词对其的相似度分配， 然后我们计算对于Query来说，Context 中的word信息：</p>
<script type="math/tex; mode=display">
\hat{h} = \sum_t b_t H_{:t} \in R^{2d}</script><p>然后 $\hat{h}$ 重复 T 次形成 T 列， 形成 $\hat{H} \in R^{2d \times T}$， 其实就是类似 Q2C 矩阵。 这里有一点疑问的是，为何不像上文一样计算， 是考虑到计算复杂度吗？</p>
</li>
<li><p>此时，我们将这些信息综合， 其实就我看来就是将 Query 的信息融入到 Context 中，如下：</p>
<script type="math/tex; mode=display">
G_{:t} = \beta(H_{:t}, \hat{U}_{:t}, \hat{H}_{:t}) \in R^{d_G}</script><p>其中， $\beta$ 可以选择多种方式，如多层感知机或者仅仅简单的将各个向量连接。 </p>
</li>
</ul>
<h2><span id="7-dcn-7">7. DCN [7]</span></h2><p><img data-src="..\img\DCN\1.PNG" alt="1"></p>
<ul>
<li>同样先通过 LSTM 来分别获得 Context 与 Query 的表示：<script type="math/tex; mode=display">
D = LSTM(Context) \in R^{|D| \times dim}\\
Q' = LSTM(Query);  \in R^{|Q| \times dim}\\ 
Q = tanh(Q^{(Q)}Q' + b^{(Q)}) \in R^{|Q| \times dim} ; 可忽略</script></li>
</ul>
<h3><span id="核心-coattention-encoder">核心： CoAttention Encoder</span></h3><script type="math/tex; mode=display">
L = D^TQ \in R^{|D| \times |Q|}\\
A^Q = softmax(L) \in R^{|D| \times |Q|}; \quad C^Q = DA^Q \in R^{dim \times |Q|} \\
A^D = softmax(L^T) \in R^{|Q| \times |D|}; \quad C^D = [Q; C^Q]A^D \in R^{2dim \times |D|} \\
U = LSTM([D; C^D])</script><h2><span id="8-qanet-8">8. QANet [8]</span></h2><p><img data-src="..\img\QANet\2.PNG" alt="2"></p>
<ul>
<li>首先，采用char-level 与 word-level 信息，通过 Highway Networks 融合信息来分别获得 Context 与 Query 的矩阵表示：<script type="math/tex; mode=display">
X \in R^{d \times T} ; \text{T 为 context 中的单词数}\\
Q \in R^{d \times J} ; \text{J 为 Query 中的单词数}</script></li>
</ul>
<h3><span id="核心点-多维信息融合">核心点： 多维信息融合</span></h3><p>与 BIDAF 中不同， 其在信息的表示层面做了一个很精巧的融合，采用多个如下图的 Encoder Block 来获得文本的表示：</p>
<p><img data-src="..\img\QANet\1.jpg" alt="1"></p>
<p>整个 Encoder Block 的结构是： 卷积层 + Self-Attention 层 + Feed-forward 层。 作者认为，卷积能够捕获文本的局部结构，而 Self-Attention 能够学习到全局的相互特征， 且最大的优点在于二者皆可并行。</p>
<p>最终得到 Context 与 query 的矩阵表示：$C$ 与 $Q$。 </p>
<h3><span id="context-query-attention-layer">Context-Query Attention Layer</span></h3><script type="math/tex; mode=display">
S = f(C,Q) \in R^{n \times m} \\
S_列 = softmax(S) \in R^{n \times m} \\
\text{context-to-query attention:} \qquad A = \overline{S} \cdot Q^T \in R^{n \times d} \\
S_行 = softmax(S) \in R^{n \times m} \\
\text{query-to-context attention:} \qquad B = S_列 \cdot S_行^T \cdot C^T \\

U = [C, A, C \odot A, C \odot B]</script><h2><span id="reference">Reference</span></h2><p>[1]  Teaching Machines to Read and Comprehend</p>
<p>[2]  A thorough examination of the cnn/dailymail reading comprehension task.</p>
<p>[3]  Text understanding with the attention sum reader network</p>
<p>[4]  Attention-over-Attention Neural Networks for Reading Comprehension</p>
<p>[5]  Gated-attention readers for text comprehension</p>
<p>[6] BI-DIRECTIONAL ATTENTION FLOWFOR MACHINE COMPREHENSION</p>
<p>[7] Dynamic coattention networks for question answering</p>
<p>[8] QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>数据集综述</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/7-%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#阅读理解数据集综述">阅读理解数据集综述</a><ul>
<li><a href="#1-阅读理解任务定义">1. 阅读理解任务定义</a></li>
<li><a href="#2-阅读理解任务类型">2. 阅读理解任务类型</a></li>
<li><a href="#3-阅读理解任务的评估方式">3. 阅读理解任务的评估方式</a></li>
<li><a href="#4-现有数据集分类">4. 现有数据集分类</a><ul>
<li><a href="#1-填空式阅读理解">1. 填空式阅读理解</a></li>
<li><a href="#2-抽取式阅读理解">2. 抽取式阅读理解</a></li>
<li><a href="#3-多选式阅读理解">3. 多选式阅读理解</a></li>
<li><a href="#4-生成式阅读理解">4. 生成式阅读理解</a></li>
<li><a href="#5-其他">5. 其他</a></li>
</ul>
</li>
<li><a href="#最后">最后</a></li>
<li><a href="#reference">Reference</a><ul>
<li><a href="#1-博客参考">1. 博客参考</a></li>
<li><a href="#2-填空式阅读理解">2. 填空式阅读理解</a></li>
<li><a href="#3-抽取式阅读理解">3. 抽取式阅读理解</a></li>
<li><a href="#3-多选式阅读理解">3. 多选式阅读理解</a></li>
<li><a href="#其他">其他</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="阅读理解数据集综述">阅读理解数据集综述</span></h1><h2><span id="1-阅读理解任务定义">1. 阅读理解任务定义</span></h2><p>阅读理解任务可以被当作是一个有监督学习问题，具体来说，该任务可 以详细描述为:给定一个数据集 T，其中 T 的每一个样本都以下的三元组来表示:</p>
<script type="math/tex; mode=display">
T = {(P_i, Q_i, A_i)}_{i=1}^n</script><p>其中，$P_i$ 代表第 $i$ 个样本中的文章片段，$Q_i$ 代表第 $i$ 个样本中的问题，$A_i$  代表第 $i$  个样本中根据文章和问题所回答的答案。阅读理解的任务是通过学习得到一个预测函数 $f$ ，使得我们能够通过给定的 $P_i$  与 $Q_i$  来预测出 $A_i$ :</p>
<script type="math/tex; mode=display">
f(P_i, Q_i) \to A_i</script><p>通俗来讲，阅读理解任务就是通过给定一个文章片段，给定一个问题，要求计算机能够通过文章片段与问题来获得答案。</p>
<h2><span id="2-阅读理解任务类型">2. 阅读理解任务类型</span></h2><p>阅读理解有多种类型，其划分的一个主要依据是根据答案的类型进行划分，这么区分的主要原因在于答案的不同使得模型输出层，损失函数，评估方式等发生很大变化。</p>
<p>目前来看，阅读理解任务根据具体答案形式的不同可以大致区分为以下四类:</p>
<ul>
<li><p><strong>填空式阅读理解。</strong></p>
<p>填空式阅读理解有一个很明显的特点：答案往往是一个单词而非句子。填空式阅读理解任务可以描述为:给定一段文章片段与一个问题，要求机器根据文章片段与问题来推理出合理的答案， 且答案往往是文章片段的某个词。</p>
<p>填空式阅读理解在阅读理解发展的早 期起到了至关重要的作用，现在已经退出主流数据集了，具体典型的数据集 有:CNN&amp;Daily Mail，Who did What等数据集。</p>
</li>
<li><p><strong>抽取式阅读理解。</strong></p>
<p>抽取式阅读理解任务可以描述为:给定一段文章片 段，给定一个问题，要求机器根据该问题从文章片段中找出一个连续的片段作为答案。</p>
<p>考虑到输出问题，此类问题又转化为预测答案的开始与结束的两 个位置 $pos<em>{start}$ 与 $pos</em>{end}$ 。此时，问题就转化成为一个分类问题，答案可以用篇章词片段表示为 $[ pos<em>{start} , pos</em>{end} ]$ 。</p>
<p>在过去两年中，此类数据集一直是学术界的主流数据集，极大的推动了阅读理解领域的发展，其中最典型的数据集包括 SQuAD，MS Marco，NewsQA，TriviaQA等数据集。</p>
</li>
<li><p><strong>多选式阅读理解。</strong></p>
<p>多选式阅读理解任务可以描述为：给定一段文章片段，给定一个问题，给定多个选项，要求机器根据文章片段与问题从答案选项中选择一个最合适的答案。</p>
<p>通过将阅读理解问题转化为分类问题可以更准 确的评估机器对语言的理解能力，这也是此类数据集强于抽取式数据集的一 大原因。</p>
<p>此类数据集是目前研究人员研究的热点之一，代表性的数据集有 RACE，CLOTH等。</p>
</li>
<li><p><strong>生成式阅读理解。</strong></p>
<p>生成式阅读理解任务可以描述为：给定一段文章片 段，给定一个问题，要求机器基于文章片段与问题生成一个合适的答案，该答案不局限于文章中存在的词语，而是自由生成的。</p>
<p>此类型的阅读理解任务 更适合实际生活场景，但是由于生成的句子无法做准确评估，因此一直无法 成为业界的主流数据集。代表性的数据集有 NARRATIVEQA，CoQA等。</p>
</li>
</ul>
<p><img data-src="image/cloze.png" alt="cloze"></p>
<p><img data-src="image/span.png" alt="span"></p>
<p><img data-src="image/multi.png" alt="multi"></p>
<p><img data-src="image/free-text.png" alt="free-text"></p>
<h2><span id="3-阅读理解任务的评估方式">3. 阅读理解任务的评估方式</span></h2><div class="table-container">
<table>
<thead>
<tr>
<th>任务类型</th>
<th>评估方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>填空式阅读理解</td>
<td>准确率(Accuracy)</td>
</tr>
<tr>
<td>抽取式阅读理解</td>
<td>EM(完全匹配值)，F1</td>
</tr>
<tr>
<td>多选式阅读理解</td>
<td>准确率(Accuracy)</td>
</tr>
<tr>
<td>生成式阅读理解</td>
<td>BLEU，ROUGE</td>
</tr>
</tbody>
</table>
</div>
<p>对于抽取式阅读理解任务，由于答案通常为一个片段，一般同时采用两<br>种评估方式:</p>
<ul>
<li><p>完全匹配值(Exact Match，EM)。该指标用来判定预测的答案与给 定的答案是否完全相同，即预测的开始位置 $pos^{pred}<em>{start}$ 与终止位置 $pos^{pred}</em>{end}$ 是否与真实值相同，其计算公式下：</p>
<script type="math/tex; mode=display">
EM = \begin{cases} 1, & pos^{pred}_{start} == pos^{real}_{start}  \, and \, pos^{pred}_{end} == pos^{real}_{end} \\ 0, & otherwise \end{cases}</script></li>
<li><p>F1 值。该指标主要评估预测的答案片段与正确答案的重合率，其计 算公式如下所示：</p>
<script type="math/tex; mode=display">
F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}</script></li>
</ul>
<h2><span id="4-现有数据集分类">4. 现有数据集分类</span></h2><p>本节汇集了当前大多数的阅读理解数据集，并对其进行简单描述</p>
<h3><span id="1-填空式阅读理解">1. 填空式阅读理解</span></h3><p>考虑到这部分其实已经几乎没人在搞了，因此就不做详细描述了。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>语言</th>
<th>状态</th>
</tr>
</thead>
<tbody>
<tr>
<td>MCTest [1]</td>
<td>English</td>
<td>过时，不推荐研究</td>
</tr>
<tr>
<td>CNN/Daily Mail[2]</td>
<td>English</td>
<td>过时，不推荐研究</td>
</tr>
<tr>
<td>CBT[3]</td>
<td>English</td>
<td>过时，不推荐研究</td>
</tr>
<tr>
<td>Quasar-S[4]</td>
<td>English</td>
<td>过时，不推荐研究</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>CNN&amp;Daily Mail： 最具代表的数据聚集，数据来源于CNN 和 Daily Mail。</li>
<li>CBT：数据来源于儿童读物。</li>
</ul>
<h3><span id="2-抽取式阅读理解">2. 抽取式阅读理解</span></h3><p><a href="https://www.leiphone.com/news/201903/QcmBwrYSo8QyWXRb.html">https://www.leiphone.com/news/201903/QcmBwrYSo8QyWXRb.html</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>语言</th>
<th>状态</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD 1.0</a> [5]</td>
<td>English</td>
<td>过时</td>
</tr>
<tr>
<td><a href="https://rajpurkar.github.io/SQuAD-explorer/"><strong>SQuAD 2.0</strong></a> [6]</td>
<td><strong>English</strong></td>
<td><strong>热点</strong></td>
</tr>
<tr>
<td><a href="https://zhuanlan.zhihu.com/p/36415104"><strong>DuReader</strong></a></td>
<td><strong>Chinese</strong></td>
<td><strong>热点</strong></td>
</tr>
<tr>
<td><a href="https://zhuanlan.zhihu.com/p/53525750"><strong>MS MARCO</strong></a></td>
<td><strong>English</strong></td>
<td><strong>非研究热点，但跟搜索引擎紧密结合</strong></td>
</tr>
<tr>
<td><a href="https://zhuanlan.zhihu.com/p/43050014">CoQA</a> [9]</td>
<td>English</td>
<td>热点，接替SQuAD</td>
</tr>
<tr>
<td><a href="http://nlp.cs.washington.edu/triviaqa/">TriviaQA</a> [10]</td>
<td>English</td>
<td>热点</td>
</tr>
<tr>
<td><a href="https://hotpotqa.github.io/">HotpotQA</a> [11]</td>
<td>English</td>
<td>热点</td>
</tr>
<tr>
<td>Quasar-T [4]</td>
<td>English</td>
<td>非研究热点</td>
</tr>
<tr>
<td>SearchQA[12]</td>
<td>English</td>
<td>非研究热点</td>
</tr>
<tr>
<td><a href="https://hfl-rc.github.io/cmrc2018/open_challenge/">CMRC 2018</a></td>
<td>Chinese</td>
<td>研究热点</td>
</tr>
<tr>
<td><a href="https://hfl-rc.github.io/cmrc2019/">CMRC 2019</a></td>
<td>Chinese</td>
<td>热点</td>
</tr>
<tr>
<td><a href="https://www.microsoft.com/en-us/research/project/newsqa-dataset/">NewsQA</a> [13]</td>
<td>English</td>
<td>有点意思</td>
</tr>
<tr>
<td><a href="http://quac.ai/">QuAC</a> [14]</td>
<td>English</td>
<td>非热点</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>SQuAD 1.0：来源于维基百科，给定 context 于 question， 从 context 中截取一个片段，该片段作为答案。 是一个典型的抽取式问题。</p>
</li>
<li><p>SQuAD 2.0：在 SQuAD 1.0 的基础上新增超过5万无法回答的问题。这要求模型不仅要在能够在问题可回答时给出答案，还要判断哪些问题是阅读文本中没有材料支持的，并拒绝回答这些问题。</p>
</li>
<li><p>DuReader： 中文阅读理解数据集，应该是国内最棒的阅读理解数据集。它的格式跟 下面的 MS MARCO 相似。DuReader中的问题和文档均来自百度搜索和百度知道。答案是人为产生的，而不是原始上下文中的片段。DuReader之所以与众不同，是因为它提供了新的问题类型，例如yes、no和opinion。与事实性问题相比，这些问题有时需要对文档的多个部分进行汇总。</p>
</li>
<li><p>MS MARCO：， 很工业化的数据集，来自Bing 用户查询，因此跟搜索引擎技术紧密相连，十分适合学习。为了克服以前的数据集的弱点，它具有四个主要功能。</p>
<p>首先，所有问题都是从真实用户查询中收集的；</p>
<p>其次，对于每个问题，使用Bing搜索引擎搜索10个相关文档作为上下文；</p>
<p>第三，人为这些问题标注了答案，因此它们不仅限于上下文范围，还需要更多的推理和总结；</p>
<p>最后，每个问题有多个答案，有时甚至冲突，这使得机器选择正确的答案更具挑战性。MS MARCO使MRC数据集更接近真实世界。</p>
</li>
<li><p>CoQA：， 对话式阅读理解数据集，这跟现实生活又近了一步，是现在研究的热点。CoQA包含约8000轮对话，问题的答案有五种类型，分别为Yes、No、Unknown，文章中的一个span和生成式答案。当根据文章和之前的对话信息无法回答当前问题时，答案为Unknown。该数据集不仅提供答案，而且给出了答案的依据，每一种类型的答案的依据都是文章中的一个span。</p>
</li>
<li><p>TriviaQA：。该数据集构造问答对，然后从维基百科等页面中寻找对应的论据。最终通过上述方式构造了约65,000个“问题-答案-论据”三元组，通过这种方式构造的数据集比SQuAD更接近实际使用场景。对比SQuAD数据集，其主要集中于是推理方面的问题，并且实验证明一些在SQuAD上表现良好的模型在TriviaQA上并不能获得理想的结果。</p>
</li>
<li><p>HotpotQA：研究基于多个信息内容的多步推理，然后回答问题。这意味着答案并不仅仅来源于单一文档。</p>
</li>
<li><p>Quasar-T：不建议深入研究。</p>
</li>
<li><p>SearchQA：作者构建该数据集的目的是构建能反映检索系统噪声的阅读理解数据集，作者通爬取 Jeopardy 上的问题，然后将问题作为query 在Google 上检索，获得 answer snippets。 该数据集是通过程序生成的，因此噪声不可避免的比较高，因此不建议深入研究。</p>
</li>
<li><p>NewsQA：该数据集是从CNN新闻网站上构造的，构造方法与SQuAD一致。</p>
</li>
<li><p>QuAC： 对话式阅读理解数据集。</p>
</li>
</ul>
<h3><span id="3-多选式阅读理解">3. 多选式阅读理解</span></h3><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>语言</th>
<th>状态</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://www.qizhexie.com//data/RACE_leaderboard">RACE</a> [15]</td>
<td>English</td>
<td>热点，可研究</td>
</tr>
<tr>
<td><a href="http://www.qizhexie.com/data/CLOTH_leaderboard">CLOTH</a> [16]</td>
<td>English</td>
<td>一般，已解决</td>
</tr>
<tr>
<td><a href="https://allenai.org/data/arc">ARC</a> [17]</td>
<td>English</td>
<td>一般，不推荐</td>
</tr>
<tr>
<td>Who did What [18]</td>
<td>English</td>
<td>过时，不推荐研究</td>
</tr>
<tr>
<td><a href="https://leaderboard.allenai.org/open_book_qa/submissions/public">OpenBookQA</a> [19]</td>
<td>English</td>
<td>一般，不推荐</td>
</tr>
<tr>
<td><a href="https://www.tau-nlp.org/commonsenseqa">CommonsenseQA</a>  [20]</td>
<td>English</td>
<td>一般，不推荐</td>
</tr>
<tr>
<td><a href="https://wilburone.github.io/cosmos/">COSMOS QA</a> [21]</td>
<td>English</td>
<td>一般</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>RACE： RACE 取自于中国中高考阅读理解题型，我个人认为这是目前最能体现阅读理解能力的数据集之一，十分值得研究。</li>
<li>CLOTH：来自中文中高考完形填空题型，相较于RACE， CLOTH 天然的适合 BERT 这种 AE 模型来填词，因此 CLOTH 可以说是已经被解决了，准确率比人高。</li>
<li>ARC：ARC 取自中学生考试中的科学问题，并进一步分为ARC-Challenge 于 ARC-Easy 两个子集，共包含大约8000个问题，此外，该数据集中提供与该任务相关的包含14M科学事实的语料库用来回答这些问题。</li>
<li>OpenBookQA：包含大约6000个问题，每个问题包括四个选项，此外，与ARC数据集相似，该数据集也提供了参考语料库，包含1326个事实，每个问题期望结合语料库中的某一个事实来得到答案。此外，还需要结合一些常识知识。如何准确的利用参考语料库与常识知识成为了该数据集的主要问题之一。</li>
<li>CommonsenseQA：来自于ConceptNet，其包含大约12000个需要结合背景知识的问题。在该数据集中，标注者根据ConceptNet中的实体概念来自由构造问题，来使问题包含人类所具有的、但难以在网络资源中检索到的背景知识，故回答问题需要利用问题、候选答案，以及仅仅使用检索策略无法检索到的背景知识。</li>
<li>COSMOS QA：包含35600个需要常识阅读理解的问题，其专注于解决需要跨越上下文、而不是定位指定片段的推理问题。</li>
</ul>
<h3><span id="4-生成式阅读理解">4. 生成式阅读理解</span></h3><p>生成式阅读理解目前还没有热起来的趋势，相关的数据集也没有进入主流视野，个人不建议做这方面的研究。 这一大原因在于文本生成作为单一的任务迟迟得不到突破，至少目前为止（2020年），看不到突破的影子，个人觉得还需要一些时间。</p>
<h3><span id="5-其他">5. 其他</span></h3><p>其他还有一些数据集，如bAbi，LAMBADA， SCT，MCScript，NarrativeQA，DuoRC，CliCR，WikiQA 等，水平有限，累了，就不做赘述了。</p>
<h2><span id="最后">最后</span></h2><p>本文总结了大多数的数据集，但是并没有对数据集进行详细描述，一来是因为工作量比较大，二来是觉得没有必要。 一般做阅读理解紧跟几个主流数据集就行，太多数据集反而会乱了自身阵脚。</p>
<h2><span id="reference">Reference</span></h2><h3><span id="1-博客参考">1. 博客参考</span></h3><p><a href="https://zhuanlan.zhihu.com/p/111410698">赛尔笔记 | 机器阅读理解简述</a></p>
<p><a href="https://github.com/thunlp/RCPapers">RCPapers</a></p>
<h3><span id="2-填空式阅读理解">2. 填空式阅读理解</span></h3><p>[1] (MCTest) <strong>MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text.</strong> Matthew Richardson, Christopher J.C. Burges, and Erin Renshaw. EMNLP 2013. <a href="http://www.aclweb.org/anthology/D13-1020">paper</a>.</p>
<p>[2] (CNN/Daily Mail) <strong>Teaching Machines to Read and Comprehend.</strong> Hermann, Karl Moritz, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. NIPS 2015. <a href="https://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf">paper</a></p>
<p>[3] (CBT) <strong>The Goldilocks Principle: Reading Children’s Books with Explicit Memory Representations.</strong> Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston. arXiv preprint arXiv:1511.02301 (2015). <a href="https://arxiv.org/pdf/1511.02301">paper</a></p>
<p>[4] (Quasar) <strong>Quasar: Datasets for Question Answering by Search and Reading.</strong> Bhuwan Dhingra, Kathryn Mazaitis, and William W. Cohen. arXiv preprint arXiv:1707.03904 (2017). <a href="https://arxiv.org/pdf/1707.03904">paper</a></p>
<h3><span id="3-抽取式阅读理解">3. 抽取式阅读理解</span></h3><p>[5 ]  (SQuAD 1.0) <strong>SQuAD: 100,000+ Questions for Machine Comprehension of Text.</strong> Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. EMNLP 2016. <a href="https://aclweb.org/anthology/D16-1264">paper</a></p>
<p>[6] (SQuAD 2.0) <strong>Know What You Don’t Know: Unanswerable Questions for SQuAD.</strong> Pranav Rajpurkar, Robin Jia, and Percy Liang. ACL 2018. <a href="http://aclweb.org/anthology/P18-2124">paper</a></p>
<p>[7] (DuReader) <strong>DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications.</strong> Wei He, Kai Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, and Haifeng Wang. ACL 2018 Workshop. <a href="https://arxiv.org/abs/1711.05073">paper</a></p>
<p>[8]  (MS MARCO) <strong>MS MARCO: A Human Generated MAchine Reading COmprehension Dataset.</strong> Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.  arXiv preprint arXiv:1611.09268 (2016). <a href="https://arxiv.org/pdf/1611.09268">paper</a></p>
<p>[9] (CoQA) <strong>CoQA: A Conversational Question Answering Challenge.</strong> Siva Reddy, Danqi Chen, and Christopher D. Manning. arXiv preprint arXiv:1808.07042 (2018). <a href="https://arxiv.org/pdf/1808.07042">paper</a></p>
<p>[10] (TriviaQA) <strong>TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.</strong> Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. arXiv preprint arXiv:1705.03551 (2017). <a href="https://arxiv.org/pdf/1705.03551">paper</a></p>
<p>[11] (HotpotQA) <strong>HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</strong>. Yang Z , Qi P , Zhang S , et al. . 2018.<a href="https://arxiv.org/abs/1809.09600v1">paper</a></p>
<p>[12] (SearchQA) <strong>SearchQA: A New Q&amp;A Dataset Augmented with Context from a Search Engine.</strong> Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho. arXiv preprint arXiv:1704.05179 (2017). <a href="https://arxiv.org/pdf/1704.05179">paper</a></p>
<p>[13] (NewsQA) <strong>NewsQA: A Machine Comprehension Dataset.</strong> Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman. arXiv preprint arXiv:1611.09830 (2016). <a href="https://arxiv.org/pdf/1611.09830">paper</a></p>
<p>[14] (QuAC) <strong>QuAC : Question Answering in Context.</strong> Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and  Luke Zettlemoyer. arXiv preprint arXiv:1808.07036 (2018). <a href="https://arxiv.org/pdf/1808.07036">paper</a></p>
<h3><span id="3-多选式阅读理解">3.  多选式阅读理解</span></h3><p>[15] (RACE) <strong>RACE: Large-scale ReAding Comprehension Dataset From Examinations.</strong> Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. EMNLP 2017. <a href="http://aclweb.org/anthology/D17-1082">paper</a></p>
<p>[16] (CLOTH) <strong>Large-scale Cloze Test Dataset Created by Teachers.</strong> Qizhe Xie, Guokun Lai, Zihang Dai, and Eduard Hovy. EMNLP 2018. <a href="https://arxiv.org/pdf/1711.03225">paper</a></p>
<p>[17] (ARC) <strong>Think you have Solved Question Answering?Try ARC, the AI2 Reasoning Challenge.</strong> Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. arXiv preprint arXiv:1803.05457 (2018). <a href="https://arxiv.org/pdf/1803.05457">paper</a></p>
<p>[18] (Who did What) <strong>Who did What: A Large-Scale Person-Centered Cloze Dataset</strong> Takeshi Onishi, Hai Wang, Mohit Bansal, Kevin Gimpel, and David McAllester. EMNLP 2016. <a href="https://aclweb.org/anthology/D16-1241">paper</a></p>
<p>[19] (OpenBookQA) Mihaylov T, Clark P, Khot T, et al. Can a suit of armor conduct electricity? a new dataset for open book question answering[J].  2018. <a href="https://arxiv.org/abs/1809.02789">paper</a></p>
<p>[20] Talmor A, Herzig J, Lourie N, et al. Commonsenseqa: A question answering challenge targeting commonsense knowledge[J]. 2018. <a href="https://arxiv.org/abs/1811.00937">paper</a></p>
<p>[21] Huang L, Bras R L, Bhagavatula C, et al. Cosmos QA: Machine reading comprehension with contextual commonsense reasoning[J]. arXiv, 2019. <a href="https://arxiv.org/abs/1909.00277">paper</a></p>
<h3><span id="其他">其他</span></h3><p>[22] (bAbi) <strong>Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.</strong> Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M. Rush, Bart van Merriënboer, Armand Joulin, and Tomas Mikolov. arXiv preprint arXiv:1502.05698 (2015). <a href="https://arxiv.org/pdf/1502.05698">paper</a></p>
<p>[23] (LAMBADA) <strong>The LAMBADA Dataset:Word Prediction Requiring a Broad Discourse Context.</strong> Denis Paperno, Germ ́an Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fern ́andez. ACL 2016. <a href="https://www.aclweb.org/anthology/P16-1144">paper</a></p>
<p>[24] (SCT) <strong>LSDSem 2017 Shared Task: The Story Cloze Test.</strong> Nasrin Mostafazadeh, Michael Roth, Annie Louis,Nathanael Chambers, and James F. Allen. ACL 2017 workshop. <a href="http://aclweb.org/anthology/W17-0906">paper</a></p>
<p>[25] (MCScript) <strong>MCScript: A Novel Dataset for Assessing Machine Comprehension Using Script Knowledge.</strong> Simon Ostermann, Ashutosh Modi, Michael Roth, Stefan Thater, and Manfred Pinkal. arXiv preprint arXiv:1803.05223.  <a href="https://arxiv.org/pdf/1803.05223.pdf">paper</a></p>
<p>[26] (NarrativeQA) <strong>The NarrativeQA Reading Comprehension Challenge</strong>.<br>Tomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette. TACL 2018. <a href="http://aclweb.org/anthology/Q18-1023">paper</a></p>
<p>[27] (DuoRC) <strong>DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension.</strong> Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, and Karthik Sankaranarayanan. ACL 2018. <a href="http://aclweb.org/anthology/P18-1156">paper</a></p>
<p>[28] (CliCR) <strong>CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension.</strong> Simon Suster and Walter Daelemans. NAACL 2018. <a href="http://aclweb.org/anthology/N18-1140">paper</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>阅读理解</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言推理</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/8-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%8E%A8%E7%90%86/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%20-%20%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%8E%A8%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#上游任务-自然语言推理">上游任务 - 自然语言推理</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="上游任务-自然语言推理">上游任务 - 自然语言推理</span></h1>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>自然语言推理</tag>
      </tags>
  </entry>
  <entry>
    <title>关系抽取</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/9-%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#上游任务-关系抽取">上游任务 - 关系抽取</a><ul>
<li><a href="#先抽取实体再判断关系">先抽取实体，再判断关系</a></li>
<li><a href="#联合抽取">联合抽取</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="上游任务-关系抽取">上游任务 - 关系抽取</span></h1><hr>
<p><a href="https://zhuanlan.zhihu.com/p/77868938">https://zhuanlan.zhihu.com/p/77868938</a></p>
<h2><span id="先抽取实体再判断关系">先抽取实体，再判断关系</span></h2><p>R-BERT: <a href="https://blog.csdn.net/xiaowopiaoling/article/details/105679350">https://blog.csdn.net/xiaowopiaoling/article/details/105679350</a>, Enriching Pre-trained Language Model with Entity Information for Relation Classification</p>
<h2><span id="联合抽取">联合抽取</span></h2><p>TPLinker： <a href="https://github.com/131250208/TPlinker-joint-extraction，">https://github.com/131250208/TPlinker-joint-extraction，</a> TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking， <a href="https://blog.csdn.net/li_jiaoyang/article/details/111315300">https://blog.csdn.net/li_jiaoyang/article/details/111315300</a></p>
<p><a href="https://github.com/weizhepei/CasRel，">https://github.com/weizhepei/CasRel，</a> A Novel Cascade Binary Tagging Framework for Relational Triple Extraction， <a href="https://zhuanlan.zhihu.com/p/143591841">https://zhuanlan.zhihu.com/p/143591841</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>关系抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>三大特征抽取器比较</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%85%B6%E4%BB%96%E5%9F%BA%E7%A1%80/%E4%B8%89%E5%A4%A7%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96%E5%99%A8%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#nlp-特征抽取器">NLP - 特征抽取器</a><ul>
<li><a href="#1-文本特点">1. 文本特点</a><ul>
<li><a href="#2-nlp-四大任务">2. NLP 四大任务</a></li>
</ul>
</li>
<li><a href="#3-rnn">3. RNN</a></li>
<li><a href="#4-cnn">4. CNN</a><ul>
<li><a href="#3-transformer-的优劣">3. Transformer 的优劣</a></li>
<li><a href="#5-三大特征抽取器比较">5. 三大特征抽取器比较</a></li>
</ul>
</li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="nlp-特征抽取器">NLP - 特征抽取器</span></h1><h2><span id="1-文本特点">1. 文本特点</span></h2><ul>
<li>输入是一个一维线性序列</li>
<li>输入是不定长的，这点对于模型处理起来会比较麻烦</li>
<li>单词位置与句子位置的相对位置很重要，互换可能导致完全不同的意思。</li>
<li>句子中的长距离特征对于理解语义也非常关键，特征抽取器能否具备长距离特征捕获能力这一点对于解决NLP任务来说也是很关键的。</li>
</ul>
<h3><span id="2-nlp-四大任务">2. NLP 四大任务</span></h3><ul>
<li><strong>序列标注：</strong> 分词， 词性标注， 命名实体识别， 语义角色标注。 特点是句子中每个单词要求模型根据上下文都要给出一个分类类别</li>
<li><strong>分类任务：</strong> 文本分类， 情感分析。 特点是不管文章有多长，总体给出一个分类类别即可。</li>
<li><strong>句子关系推断：</strong> Entailment， QA， 自然语言推理。 特点是给定两个句子，模型判断出两个句子是否具备某种语义关系。</li>
<li><strong>生成式任务：</strong>机器翻译， 文本摘要。特点是输入文本内容后，需要自主生成另外一段文字。</li>
</ul>
<h2><span id="3-rnn">3. RNN</span></h2><p>RNN 最大的优势是<strong>其天生的具有时序结构，十分适合解决NLP问题</strong>。NLP的输入往往是个不定长的线性序列句子，而RNN本身结构就是个可以接纳不定长输入的由前向后进行信息线性传导的网络结构，而在LSTM引入三个门后，对于捕获长距离特征也是非常有效的。</p>
<p>RNN 最大的缺点在<strong>于反向传播时所存在的优化困难问题， 即梯度消失，梯度爆炸问题</strong>。 后来的LSTM 与 GRU 相当程度上解决了这一问题，但对于超长文本依旧无法很好解决。后来陆续有研究对其优化来解决 RNN 的长期依赖问题，如 <a href="https://zhuanlan.zhihu.com/p/34490114。">https://zhuanlan.zhihu.com/p/34490114。</a> </p>
<p>RNN 的另一大缺陷在于其<strong>并行能力</strong>。由于每一时刻状态的生成都依赖于上一时刻的状态，这使得 RNN 无法并行。</p>
<h2><span id="4-cnn">4. CNN</span></h2><p><strong>CNN 能够捕捉到 n-gram 信息， filter 的size 决定了n的大小。</strong></p>
<p>只有一个卷积层带来的问题是：<strong>对于远距离特征，单层CNN是无法捕获到的，如果滑动窗口k最大为2，而如果有个远距离特征距离是5，那么无论上多少个卷积核，都无法覆盖到长度为5的距离的输入，所以它是无法捕获长距离特征的。</strong></p>
<p>那么怎样才能捕获到长距离的特征呢？有两种典型的改进方法：</p>
<ul>
<li><p>一种是假设我们仍然用单个卷积层，滑动窗口大小k假设为3，就是只接收三个输入单词，但是我们想捕获距离为5的特征，那么采用 <strong>Dilated 卷积思想， 跳着覆盖</strong>。</p>
</li>
<li><p>第二种方法是把<strong>深度做起来。</strong></p>
<p>第一层卷积层，假设滑动窗口大小 k 是 3，如果再往上叠一层卷积层，假设滑动窗口大小也是3，但是第二层窗口覆盖的是第一层窗口的输出特征，所以它其实能覆盖输入的距离达到了5。如果继续往上叠加卷积层，可以<strong>继续增大卷积核覆盖输入的长度。</strong></p>
</li>
</ul>
<p>TextCNN 中涉及到一个问题，就是那个 Max Pooling 层，这块其实与 <strong>CNN 能否保持输入句子中单词的位置信息</strong> 有关系。CNN 是否能够保留原始输入的相对位置信息呢？</p>
<p>其实<strong>CNN的卷积核是能保留特征之间的相对位置</strong>的，道理很简单，滑动窗口从左到右滑动，捕获到的特征也是如此顺序排列，所以它在结构上已经记录了相对位置信息了。但是如果卷积层后面立即接上Pooling层的话，位置信息就被扔掉了，这在NLP里其实是有信息损失的。</p>
<p>所以在NLP领域里，目前CNN的一个发展趋势是抛弃Pooling层，靠全卷积层来叠加网络深度，这背后是有原因的。</p>
<p><strong>想方设法把CNN的深度做起来，随着深度的增加，很多看似无关的问题就随之解决了。</strong></p>
<h3><span id="3-transformer-的优劣">3. Transformer 的优劣</span></h3><ul>
<li>不定长问题： 一般设定输入的最大长度，如果句子没那么长，则用Padding填充，这样整个模型输入起码看起来是定长的了。</li>
<li>位置信息： Transformer 是用<strong>位置函数</strong>来进行位置编码的，而Bert等模型则给每个单词一个Position embedding，将单词embedding和单词对应的position embedding加起来形成单词的输入embedding。 </li>
<li>长距离依赖问题： Self attention天然就能解决这个问题，因为在集成信息的时候，当前单词和句子中任意单词都发生了联系。</li>
</ul>
<p>Transformer 的缺陷：</p>
<ul>
<li><p>对于长输入的任务，典型的比如篇章级别的任务（例如文本摘要），因为任务的输入太长，Transformer会有巨大的计算复杂度，导致速度会急剧变慢。</p>
</li>
<li><p>Transformer整体结构确实显得复杂了一些，如何更深刻认识它的作用机理，然后进一步简化它，这也是一个好的探索方向。</p>
</li>
</ul>
<h3><span id="5-三大特征抽取器比较">5. 三大特征抽取器比较</span></h3><ul>
<li><p>语义特征抽取能力： Transoformer 显著超越 RNN 和 CNN， RNN 和 CNN 差不多。</p>
</li>
<li><p>长距离特征捕获能力： CNN 显著弱于 RNN 和 Transformer。 Transformer微弱优于 RNN（主语谓语距离小于13），但在比较远的距离上（主语谓语距离大于13），RNN微弱优于Transformer。</p>
<p>对于Transformer来说，Multi-head attention的head数量严重影响NLP任务中Long-range特征捕获能力：<strong>结论是head越多越有利于捕获long-range特征。</strong></p>
</li>
<li><p>任务综合特征抽取能力： Transformer 强于 RNN 和 CNN</p>
</li>
<li><p>并行计算能力： Transformer 与 CNN 差不多，都远强于 RNN。 </p>
</li>
<li><p>计算量： Transformer Block &gt; CNN &gt; RNN</p>
</li>
<li><p>训练速度： Transformer Base &gt; CNN &gt; Transformer Big &gt; RNN</p>
</li>
</ul>
<p>单从任务综合效果方面来说，Transformer明显优于CNN，CNN略微优于RNN。速度方面Transformer和CNN明显占优，RNN在这方面劣势非常明显。这两者再综合起来，如果我给的排序结果是Transformer&gt;CNN&gt;RNN. </p>
<h2><span id="reference">Reference</span></h2><p>[1] <a href="https://zhuanlan.zhihu.com/p/54743941">放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较</a></p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>其他基础</tag>
      </tags>
  </entry>
  <entry>
    <title>改进NLP模型的一些思路</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%85%B6%E4%BB%96%E5%9F%BA%E7%A1%80/%E6%94%B9%E8%BF%9B%20NLP%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%B7%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#1-快速构建-baseline">1. 快速构建 baseline</a><ul>
<li><a href="#1-分析数据">1. 分析数据</a></li>
<li><a href="#2-寻找合适模型">2. 寻找合适模型</a></li>
<li><a href="#3-简单模型简单baseline">3. 简单模型，简单baseline</a></li>
<li><a href="#4-剖析模型">4. 剖析模型</a></li>
</ul>
</li>
<li><a href="#2-改进模型">2. 改进模型</a><ul>
<li><a href="#1-数据角度">1. 数据角度</a></li>
<li><a href="#2-模型角度">2. 模型角度</a></li>
<li><a href="#3-调参优化角度">3. 调参优化角度</a></li>
<li><a href="#4-训练角度">4. 训练角度</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="1-快速构建-baseline">1. 快速构建 baseline</span></h2><p>构建一个有效的初始模型能帮助我们快速了解数据的质量和确定模型构建的方向。</p>
<h3><span id="1-分析数据">1. 分析数据</span></h3><p>我们在得到数据时，第一步是需要了解数据特点和使用场合。了解数据特点能帮助我们快速定位如何进行建模。确定使用场合能帮助我们进一步确定模型需要优化的方向。</p>
<ul>
<li>数据集规模</li>
<li>训练集，验证集，测试集的数据分布，样本数量，样本分布</li>
<li>数据是否存在缺失值</li>
</ul>
<h3><span id="2-寻找合适模型">2. 寻找合适模型</span></h3><p>根据数据与模型， 找到一个现有的，合适的模型作为 baseline。</p>
<h3><span id="3-简单模型简单baseline">3.  简单模型，简单baseline</span></h3><p>初始模型的作用在于迅速了解数据质量和特点，所以模型的性能通常不需要达到很高，模型复杂度也不需要很高。</p>
<h3><span id="4-剖析模型">4. 剖析模型</span></h3><p>一旦确定了一个初始模型时，无论你对该模型多熟悉，当其面对一批新数据时，你永远需要重新去认识这个模型，因为你永远不确定模型内部到底发生了些什么。</p>
<p>解剖模型一般需要在训练时注意误差变化、注意训练和验证集的差异；出现一些NAN或者INf等情况时，需要打印观察内部输出，确定问题出现的时间和位置；在完成训练后，需要测试模型的输出是否正确合理，以确认评价指标是否符合该数据场景。</p>
<h2><span id="2-改进模型">2. 改进模型</span></h2><h3><span id="1-数据角度">1. 数据角度</span></h3><p>数据决定模型的上限。</p>
<h3><span id="2-模型角度">2. 模型角度</span></h3><p>模型的容限能力决定模型的可优化空间。</p>
<p>模型的容限能力决定着模型可优化的空间。在数据量充足的前提下，对同类型的模型，增大模型规模来提升容限无疑是最直接和有效的手段。但越大的参数模型优化也会越难，所以需要在合理的范围内对模型进行参数规模的修改。而不同类型的模型，在不同数据上的优化成本都可能不一样，所以在探索模型时需要尽可能挑选优化简单，训练效率更高的模型进行训练。</p>
<h3><span id="3-调参优化角度">3. 调参优化角度</span></h3><p>如果你知道模型的性能为什么不再提高了，那已经向提升性能跨出了一大步。 超参数调整本身是一个比较大的问题。一般可以包含模型初始化的配置，优化算法的选取、学习率的策略以及如何配置正则和损失函数等等。这里需要提出的是对于同一优化算法，相近参数规模的前提下，不同类型的模型总能表现出不同的性能。这实际上就是模型优化成本。从这个角度的反方向来考虑，同一模型也总能找到一种比较适合的优化算法。所以确定了模型后选择一个适合模型的优化算法也是非常重要的手段。</p>
<h3><span id="4-训练角度">4. 训练角度</span></h3><p>很多时候我们会把优化和训练放一起。但这里我们分开来讲，主要是为了强调充分的训练。在越大规模的数据集或者模型上，诚然一个好的优化算法总能加速收敛。但你在未探索到模型的上限之前，永远不知道训练多久算训练完成。所以在改善模型上充分训练永远是最必要的过程。充分训练的含义不仅仅只是增大训练轮数。有效的学习率衰减和正则同样是充分训练中非常必要的手段。</p>
]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>其他基础</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理困难与现状</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%85%B6%E4%BB%96%E5%9F%BA%E7%A1%80/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9B%B0%E9%9A%BE%E4%B8%8E%E7%8E%B0%E7%8A%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#自然语言处理困难与现状">自然语言处理困难与现状</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h2><span id="自然语言处理困难与现状">自然语言处理困难与现状</span></h2><p>自然语言包括多粒度语言单元：字，词，短语，句子，语篇，乃至文档</p>
<p>自然语言处理的本质是结构预测， 本质是从无结构序列中预测有结构语义。</p>
<p>自然语言处理是实现人工智能，通过图灵测试的关键。</p>
<p>自然语言处理的特点：</p>
<ul>
<li>创新性，新词，旧词新意</li>
<li>递归性，带来精确表达能力，同时增加理解难度</li>
<li>多义性，普遍存在于各个粒度语言单元，自然语言理解的关键目标是自动消歧义</li>
<li>主观性，即使语言字面意思得到准确理解，仍然回受到堵着自身经历和认知的影响，产生不同的理解</li>
<li>社会性，社会结构影响人类语言，语言反映社会结构</li>
</ul>
<p>语言表示需要融入人类知识</p>
<ul>
<li>领域知识</li>
<li>世界知识</li>
<li>常识知识</li>
<li>语言知识</li>
</ul>
<h2><span id="reference">Reference</span></h2>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>其他基础</tag>
      </tags>
  </entry>
  <entry>
    <title>评估指标</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%85%B6%E4%BB%96%E5%9F%BA%E7%A1%80/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- toc -->
<ul>
<li><a href="#各大任务的评价指标">各大任务的评价指标</a><ul>
<li><a href="#1-语言模型-perplexity">1. 语言模型 — Perplexity</a></li>
<li><a href="#2-bleu">2. BLEU</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<span id="more"></span>
<h1><span id="各大任务的评价指标">各大任务的评价指标</span></h1><hr>
<h2><span id="1-语言模型-perplexity">1. 语言模型 — Perplexity</span></h2><p>PPL 主要用于衡量语言模型的好坏，其根据每个词来估计一句话出现的概率， 并用句子长度做 Normalization。</p>
<script type="math/tex; mode=display">
PP(s) = P(w_1w_2,...w_N)^{-\frac{1}{N}} \\
PP(s) = 2 ^{-\frac{1}{N}} \sum log(P(w_i))</script><h2><span id="2-bleu">2. BLEU</span></h2>]]></content>
      <tags>
        <tag>机器学习知识整理</tag>
        <tag>深度学习自然语言处理</tag>
        <tag>其他基础</tag>
      </tags>
  </entry>
  <entry>
    <title>一生只做一件事</title>
    <url>/posts/%E6%80%9D%E8%80%83/%E4%B8%80%E7%94%9F%E5%8F%AA%E5%81%9A%E4%B8%80%E4%BB%B6%E4%BA%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>互联网时代纷纷扰扰，接受到的信息太多了，就算自己不主动搜索，也会有各种新闻、视频推荐，每天映入眼帘的，有形形色色的人和五花八门的事情，<br>每天会被各种事情吸引注意力，刷刷抖音一个小时就过去了，吃吃瓜，一上午就没了，</p>
<p>王阳明一生只做一件事，就是做圣人，一生都在研究、传播心学，附带军神属性，平乱除匪，安邦定国； </p>
<p>我一生会做那件事呢？</p>
<p>我擅长什么呢？<br>心理、敲代码、摄影</p>
<p>我喜欢什么呢？<br>读历史、哲学、心学</p>
<p>所以我需要在这6个方面提升优化、突破自我，从而成为一两个领取的高手。</p>
]]></content>
  </entry>
  <entry>
    <title>夕阳老奶奶</title>
    <url>/posts/%E6%95%A3%E6%96%87%E8%AF%97/%E5%A4%95%E9%98%B3%E8%80%81%E5%A5%B6%E5%A5%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>夕阳也是位可爱的老奶奶吧<br>笑起来应该有酒窝和眯眯眼</p>
<p>要不怎么晚霞是少女粉色<br>可我怎么拍<br>也留不住她的美</p>
]]></content>
  </entry>
  <entry>
    <title>上杉达也</title>
    <url>/posts/%E6%97%A5%E8%AE%B0/22/Q1/%E4%B8%8A%E6%9D%89%E8%BE%BE%E4%B9%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>以前的达也会很轻易地说出，算了吧，要回家睡觉了。</p>
<p>我估计，我也是吧。</p>
]]></content>
  </entry>
  <entry>
    <title>认知的重要性</title>
    <url>/posts/%E6%80%9D%E8%80%83/%E8%AE%A4%E7%9F%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>认知真是一个能决定人阶级的东西，<br>我之前理解的“有钱人接收到的教育，会比穷人好很多”是，有钱人请到的老师是“清华”、“北大”毕业的，所以他们更会教学，能让你快速懂数学题、物理题，<br>虽然很早就听过“金锄头”的故事，我还在嘲笑无知的农民，但把“锄头”换成了“教育资源”，我就意识不到，我也是那个“农民”。<br>有钱人接受到的教育，不是更高深的“数学题解法”、“能考高分的结题秘诀”，而是不同的“认知”。</p>
<span id="more"></span>
<p>董事长儿子学到的是，“经济原理”、“如何创造价值”<br>高管儿子学到的是，“如何管理团队”<br>我学到的是，“如何解数学题”</p>
<p>多年以后，董事长儿子，只需要动一个念头，就可以动用手里的资源，再开一个赚钱的公司，再喝喝茶，去瑞士滑滑雪<br>高管儿子，从小就知道“如何压榨员工”、“如何让员工高效工作”，保证公司高效地运转，<br>我毕业后，凭借优秀的能力，听着高管的话，熬夜加班努力地敲着代码，赚着可怜的工资。</p>
<p>董事长儿子不一定比我聪明，高管儿子不一定比我动手能力强，可为什么我是最累的呢？</p>
<p>答案是：认知！</p>
<p>认知决定了思维方式，决定了你对这个世界的反应，决定了你要做的事。</p>
]]></content>
      <categories>
        <category>认知升级</category>
      </categories>
      <tags>
        <tag>认知升级</tag>
      </tags>
  </entry>
  <entry>
    <title>佳句摘抄</title>
    <url>/posts/%E6%91%98%E6%8A%84/%E4%BD%B3%E5%8F%A5%E6%91%98%E6%8A%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>读书到最后，是为了让我们更宽容地去理解这个世界有多复杂。</p>
<span id="more"></span>
<ol>
<li>我曾七次鄙视自己的灵魂<blockquote>
<p>第一次，当它本可进取时，却故作谦卑；<br>第二次，当它在空虚时，用爱欲来填充；<br>第三次，在困难和容易之间，它选择了容易；<br>第四次，它犯了错，却借由别人也会犯错来宽慰自己；<br>第五次，它自由软弱，却把它认为是生命的坚韧；<br>第六次，当它鄙夷一张丑恶的嘴脸时，却不知那正是自己面具中的一副；<br>第七次，它侧身于生活的污泥中，虽不甘心，却又畏首畏尾。——纪伯伦</p>
</blockquote>
</li>
<li>子欲养而亲不待。</li>
<li>此心安处是吾乡。</li>
<li>高度自律即绝对自由。</li>
<li>山河辽远，人间烟火，无一是你，无一不是你。</li>
<li>我看到了个笑话，我笑了。想到还能发给你，我又笑了。</li>
<li>当下每一次想要努力的念头，都有可能是未来的你在向现在的你求救。</li>
<li>长大后，家乡从此只有冬，没有春夏秋。</li>
<li>从让一个人生气的事情的大小就能看出一个人的价值。</li>
<li>读书到最后，是为了让我们更宽容地去理解这个世界有多复杂。</li>
<li>关山难越，谁悲失路之人？萍水相逢，尽是他乡之客。</li>
<li>凡有所相，皆是虚妄，若见诸相非相，即见如来。</li>
<li>小时候我就喜欢凝望星空，也不知是我读不懂它，还是它读不懂我。</li>
<li>大学之道，在明明德，在亲民，在止于至善。</li>
<li>读书贵在新得，作文贵在新知，这其中触发是关键。</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>治国论</title>
    <url>/posts/%E6%9D%82%E7%B1%BB/%E6%B2%BB%E5%9B%BD%E8%AE%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1637677213&amp;ver=3454&amp;signature=t9FdD0SCENSa2z9I7AMCkA3K788RfPE0d5SUt*XK-7RoP0NLHvRTHc0fPIpLOkq-QSqpXbwZHZ44af1LSVNFPmxAVTtzWgCa4TsPADavO1CseAbVkIu63aaarwablUpP&amp;new=1">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1637677213&amp;ver=3454&amp;signature=t9FdD0SCENSa2z9I7AMCkA3K788RfPE0d5SUt*XK-7RoP0NLHvRTHc0fPIpLOkq-QSqpXbwZHZ44af1LSVNFPmxAVTtzWgCa4TsPADavO1CseAbVkIu63aaarwablUpP&amp;new=1</a></p>
<p>宇文泰和苏绰的治国之论</p>
]]></content>
  </entry>
  <entry>
    <title>资讯、资料来源和参考</title>
    <url>/posts/%E6%9D%82%E7%B1%BB/%E8%B5%84%E6%96%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>资料参考</p>
<span id="more"></span>
<h1><span id="1-外部参考">1 外部参考</span></h1><h2><span id="11-外部内容源">1.1 外部内容源</span></h2><ol>
<li>用好百度、谷歌搜索</li>
<li>组织和公司官网：<ol>
<li>科技巨头和独角兽的官网：产品、方案、白皮书、发布的报告、服务支持、社区等</li>
<li>标准化组织：ISO/IEC，ITU、IETF、W3C、3GPP、IEEE、国家标准委（GB-T，GB-R等等）、工信部、发改委等，行业标准组织</li>
<li>咨询公司：中国信通院CAICT、Gartner公司，IDC咨询，ForresterResearch，埃森哲，麦肯锡，亿欧网，艾瑞，易观等</li>
</ol>
</li>
<li>一手+高质+深度的科技信息源：<ol>
<li>HackerNews：<a href="http://rte.weiyun.baidu.com/web/doc/ZFP0N_ga-gHgDk?source=http://wikigray.baidu-int.com&amp;appId=1&amp;uid=rWhQDLePub">https://news.ycombinator.com/news</a><ol>
<li>硅谷技术圈和投资圈都会关注的新闻网站，资讯不仅和AI有关，还会涉及到创业和信息安全。</li>
</ol>
</li>
<li>DataTau：<a href="http://datatau.com/">datatau.com</a>：<ol>
<li>专门给数据科学家看的HackerNews。</li>
</ol>
</li>
<li>AITopics：<ol>
<li><a href="https://aitopics.org/search">https://aitopics.org/search</a></li>
</ol>
</li>
<li>3Blue1Brown：<ol>
<li><a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw">https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw</a></li>
</ol>
</li>
<li>Two Minute Papers：<ol>
<li><a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg">https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg</a></li>
</ol>
</li>
<li>Robert Miles：<ol>
<li><a href="https://www.youtube.com/channel/UCLB7AzTwc6VFZrBsO2ucBMg">https://www.youtube.com/channel/UCLB7AzTwc6VFZrBsO2ucBMg</a></li>
</ol>
</li>
<li>Siraj Raval：<ol>
<li><a href="https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A">https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A</a></li>
</ol>
</li>
<li>著名公司博客<ol>
<li>Google：<ol>
<li><a href="https://ai.google/">https://ai.google/</a></li>
<li><a href="https://research.googleblog.com/">https://research.googleblog.com/</a></li>
</ol>
</li>
<li>Facebook：<ol>
<li><a href="https://research.fb.com/blog/">https://research.fb.com/blog/</a></li>
</ol>
</li>
<li>Nvidia：<ol>
<li><a href="https://blogs.nvidia.com/blog/category/deep-learning/">https://blogs.nvidia.com/blog/category/deep-learning/</a></li>
</ol>
</li>
<li>Apple：<ol>
<li><a href="https://machinelearning.apple.com/">https://machinelearning.apple.com/</a></li>
</ol>
</li>
<li>Microsoft：<ol>
<li><a href="https://blogs.microsoft.com/">https://blogs.microsoft.com/</a></li>
<li><a href="https://blogs.microsoft.com/ai/">https://blogs.microsoft.com/ai/</a></li>
</ol>
</li>
<li>百度<ol>
<li><a href="http://research.baidu.com/Index">http://research.baidu.com/Index</a></li>
<li><a href="http://ai.baidu.com/forum">http://ai.baidu.com/forum</a></li>
</ol>
</li>
</ol>
</li>
<li>Google Scholar<ol>
<li><a href="https://scholar.google.com/">https://scholar.google.com/</a></li>
</ol>
</li>
<li>ResearchGate<ol>
<li><a href="https://www.researchgate.net/">https://www.researchgate.net/</a></li>
</ol>
</li>
<li>Distill<ol>
<li><a href="https://distill.pub/">https://distill.pub/</a></li>
</ol>
</li>
<li>Medium：<ol>
<li><a href="https://medium.com/">https://medium.com/</a></li>
</ol>
</li>
</ol>
</li>
<li>科技报道网站：<ol>
<li><a href="https://spectrum.ieee.org/">https://spectrum.ieee.org/</a></li>
<li><a href="https://www.technologyreview.com/">https://www.technologyreview.com/</a></li>
</ol>
</li>
<li>开源网站：<ol>
<li><a href="https://github.com/weiaicunzai/awesome-image-classification">https://github.com/</a></li>
<li></li>
</ol>
</li>
<li>协同办公参考网站：<a href="https://www.uctoday.com/">https://www.uctoday.com/</a><ol>
<li><a href="https://www.uctoday.com/unified-communications/">Unified Communications</a><ol>
<li><a href="https://www.uctoday.com/unified-communications/ucaas/">UCaaS</a></li>
<li><a href="https://www.uctoday.com/unified-communications/cpaas/">CPaaS</a></li>
<li><a href="https://www.uctoday.com/endpoints/">Endpoints</a></li>
<li><a href="https://www.uctoday.com/tag/ai-in-unified-communications/">AI in Unified Comms</a></li>
<li><a href="https://www.cxtoday.com/">Contact Centre</a></li>
</ol>
</li>
<li><a href="https://www.uctoday.com/collaboration/">Collaboration</a><ol>
<li><a href="https://www.uctoday.com/collaboration/video-conferencing/">Video Conferencing</a></li>
<li><a href="https://www.uctoday.com/collaboration/team-collaboration/">Team Collaboration</a></li>
<li><a href="https://www.uctoday.com/collaboration/room-kits/">Room Kits</a></li>
<li><a href="https://www.uctoday.com/tag/ai-in-collaboration/">AI in Collaboration</a></li>
</ol>
</li>
<li><a href="https://www.uctoday.com/trending/">Trending</a><ol>
<li><a href="https://www.uctoday.com/tag/remote-working">Remote Working</a></li>
<li><a href="https://www.uctoday.com/tag/future-of-work">Future of Work</a></li>
</ol>
</li>
</ol>
</li>
<li>AI强相关<ol>
<li>Reddit和Quora帖子、问答和讨论<ol>
<li>machine_learning：<a href="https://www.reddit.com/user/techrat_reddit/m/machine_learning/">https://www.reddit.com/user/techrat_reddit/m/machine_learning/</a></li>
<li>MachineLearning：<a href="https://www.reddit.com/r/MachineLearning/">https://www.reddit.com/r/MachineLearning/</a></li>
<li>computervision：<a href="https://www.reddit.com/r/computervision/">https://www.reddit.com/r/computervision/</a></li>
<li>learnmachinelearning：<a href="https://www.reddit.com/r/learnmachinelearning/">https://www.reddit.com/r/learnmachinelearning/</a></li>
<li>Machine Learning：<a href="https://www.quora.com/pinned/Machine-Learning">https://www.quora.com/pinned/Machine-Learning</a></li>
<li>Computer Vision：<a href="https://www.quora.com/pinned/Computer-Vision">https://www.quora.com/pinned/Computer-Vision</a></li>
<li>Deep Learning：<a href="https://www.quora.com/pinned/Deep-Learning：">https://www.quora.com/pinned/Deep-Learning：</a></li>
<li>Reinforcement Learning：<a href="https://www.quora.com/pinned/Reinforcement-Learning">https://www.quora.com/pinned/Reinforcement-Learning</a></li>
</ol>
</li>
</ol>
</li>
<li>论文阅读：<ol>
<li>Arxiv：<ol>
<li>论文主动推送功能：<a href="http://arxiv-sanity.com/">arxiv-sanity.com</a></li>
<li>Computer Vision and Pattern Recognition：<a href="https://arxiv.org/list/cs.CV/recent">https://arxiv.org/list/cs.CV/recent</a></li>
<li>Artificial Intelligence：<a href="https://arxiv.org/list/cs.AI/recent">https://arxiv.org/list/cs.AI/recent</a></li>
<li>Learning：<a href="https://arxiv.org/list/cs.LG/recent">https://arxiv.org/list/cs.LG/recent</a></li>
<li>Neural and Evolutionary Computing：<a href="https://arxiv.org/list/cs.NE/recent">https://arxiv.org/list/cs.NE/recent</a></li>
</ol>
</li>
<li>论文的同行、大牛点评和笔记：<a href="http://shortscience.org/">http://shortscience.org/</a><ol>
<li>适合新手和看导读的</li>
</ol>
</li>
<li>Paper和code整合的网站：<a href="http://gitxiv.com/">GitXiv.com</a><ol>
<li>提供一站式服务</li>
</ol>
</li>
<li>计算机视觉最新论文：<ol>
<li><a href="https://github.com/amusi/daily-paper-computer-vision">https://github.com/amusi/daily-paper-computer-vision</a></li>
</ol>
</li>
<li>顶级论文合集：<a href="https://github.com//RedditSota/state-of-the-art-result-for-machine-learning-problems">https://github.com//RedditSota/state-of-the-art-result-for-machine-learning-problem</a><ol>
<li>持续更新，RedditSota 统计了各种机器学习任务的最顶级研究成果</li>
</ol>
</li>
<li>论文无法复现「真公开处刑」，PapersWithCode上线「论文复现报告」。<a href="https://mp.weixin.qq.com/s/iU-uoimkwxFZzKqTze9Vdg">https://mp.weixin.qq.com/s/iU-uoimkwxFZzKqTze9Vdg</a><ol>
<li>论文列表地址：<a href="https://openreview.net/group?id=ML_Reproducibility_Challenge/2020">https://openreview.net/group?id=ML_Reproducibility_Challenge/2020</a></li>
<li>PapersWithCode 复现报告地址：<a href="https://paperswithcode.com/conference/rc-2020">https://paperswithcode.com/conference/rc-2020</a></li>
<li>ReScience 复现报告地址：<a href="http://rescience.github.io/read/#volume-7-2021">http://rescience.github.io/read/#volume-7-2021</a></li>
</ol>
</li>
<li>IEEE网站，谷歌scholar搜索，百度学术搜索，国内的CNKI、万芳等。</li>
</ol>
</li>
</ol>
<h2><span id="12-外部公众号">1.2 外部公众号</span></h2><ol>
<li>Twitter：<ol>
<li>关注Deep Learning Hub；Marshall Kirkpatrick；Lynn Cherny；Top-N；Top 10 AI；Text Data, Vis &amp; Art</li>
</ol>
</li>
<li>个人博客：<ol>
<li>The Wild Week in AI：<a href="https://www.getrevue.co/profile/wildml">https://www.getrevue.co/profile/wildml</a><ol>
<li>周更，上面时不时还会有初创团队招人信息放出来。</li>
</ol>
</li>
<li>inFERENCe：<a href="http://inference.vc/">inference.vc</a><ol>
<li>不定期更，个人的一个学习机器学习的成长记录。</li>
</ol>
</li>
<li>The Morning Paper：<a href="https://blog.acolyer.org/">https://blog.acolyer.org/</a><ol>
<li>日更，多从投资者的角度出发。</li>
</ol>
</li>
<li>Inside AI：<a href="https://inside.com/ai">https://inside.com/ai</a><ol>
<li>Inside网站旗下的AI话题板块，专注于资讯的深度。</li>
</ol>
</li>
</ol>
</li>
<li>国内关注微博、微信、百度app、各大资讯客户端的上的内容号及相应的网站：<ol>
<li>知名公众号：<ol>
<li>InfoQ，云头条，CNCF，架构艺术，AI科技评论，机器之心，量子位，新智元，智东西，DeepTech深科技，爱可可-爱生活，36kr，钛媒体，TechWeb，雷锋网，浅黑科技，甲子光年，机器人大讲堂，iFeng科技，视频云技术，智媒之音，21世纪商业评论，5G通信，5G通信技术，SegmentFault，智能车参考。</li>
<li>企业相关：<ol>
<li>企业管理杂志，知识管理论坛，CIO之家，首席数字官，数字化企业，创业家</li>
</ol>
</li>
<li>生活相关：<ol>
<li>环球科学，每日小读十分钟，图图是道，Visa看天下</li>
</ol>
</li>
<li>国家大事：<ol>
<li>参考消息，长安街知事，环球时报，南方都市报，人民日报，新华社，央视新闻，中国经济网，中国新闻周刊</li>
</ol>
</li>
</ol>
</li>
<li>大厂和知名公司：<ol>
<li>腾讯，腾讯技术工程，腾讯大讲堂，腾讯研究院，企鹅智库，企业微信，腾讯会议</li>
<li>阿里技术，支付宝技术，阿里巴巴文娱技术，阿里研究院，阿里开发者，阿里云云栖号，钉钉</li>
<li>百度，百度AI，百度开发者中心，Apollo智能驾驶，爱奇艺技术产品团队</li>
<li>谷歌黑板报，谷歌开发者</li>
<li>微软科技，微软研究院AI头条</li>
<li>亚马逊云科技</li>
<li>华为，华为welink</li>
<li>字节跳动，字节跳动技术团队，飞书</li>
<li>哔哩哔哩</li>
<li>金山云</li>
<li>快手</li>
<li>网易传媒技术团队</li>
<li>声网Agora，声网Agora开发者</li>
<li>YY直播组</li>
<li>LiveVideoStack</li>
<li>特斯拉Tesla</li>
<li>思科科技</li>
</ol>
</li>
<li>投资公司和投资<ol>
<li>红杉汇、IDG资本、IT桔子、雪球、少数派投资</li>
</ol>
</li>
<li>咨询、机构：<ol>
<li>中国信通院CAICT、Gartner公司，IDC咨询，ForresterResearch，埃森哲，麦肯锡，亿欧网，艾瑞，易观等，音视频国检中心</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1><span id="2-牛人-机构和重要会议">2 牛人、机构和重要会议</span></h1><h2><span id="21-牛人">2.1 牛人</span></h2><ol>
<li>2021年9月，那些用推荐引擎改变世界的人。<a href="https://mp.weixin.qq.com/s/jBXH8PIeFGzKaHVoG9KXDw">https://mp.weixin.qq.com/s/jBXH8PIeFGzKaHVoG9KXDw</a><ol>
<li>致敬中国的技术创业者们，致敬阿北、王守崑、谷文栋、项亮、张栋、宿华、张一鸣、杨震原等等一代代技术创新者。</li>
</ol>
</li>
<li>2021年7月，IEEE技术领域大奖公布：ML先驱上榜，大陆唯一获奖学者来自清华。<a href="https://mp.weixin.qq.com/s/qbpk3cjPj9o7sFyIHdwCsA">https://mp.weixin.qq.com/s/qbpk3cjPj9o7sFyIHdwCsA</a></li>
<li>2021年4月，2021年人工智能全球最具影响力学者榜单AI 2000发布。<a href="https://mp.weixin.qq.com/s/OP1HAVFYzLKTZvYRdXZjqg">https://mp.weixin.qq.com/s/OP1HAVFYzLKTZvYRdXZjqg</a></li>
<li>2021年1月，ACM Fellow 名单重磅发布！12 位华人学者入选。<a href="https://mp.weixin.qq.com/s/0yKYiWrh8xXss3n1NBofPg">https://mp.weixin.qq.com/s/0yKYiWrh8xXss3n1NBofPg</a></li>
<li>2020年12月，谷歌传奇Jeff Dean获2021年IEEE冯诺依曼奖，8页本科论文被大学图书馆保存至今。<a href="https://mp.weixin.qq.com/s/Z9h7sdlG-8MeJhQa7psr_A">https://mp.weixin.qq.com/s/Z9h7sdlG-8MeJhQa7psr_A</a></li>
<li>2020年11月，IEEE Fellow、AAAS Fellow 同日公布，清华唐杰、京东郑宇等数十位华人入选。<a href="https://mp.weixin.qq.com/s/m2MD03D5rgxnTVUFgwRcUA">https://mp.weixin.qq.com/s/m2MD03D5rgxnTVUFgwRcUA</a></li>
<li>2020年6月，2020软科世界一流学科排名出炉！清华13个学科位居世界前十，计算机排全球第7。<a href="https://mp.weixin.qq.com/s/PH8ud2TfgzA3bxr97ThQdA">https://mp.weixin.qq.com/s/PH8ud2TfgzA3bxr97ThQdA</a><ol>
<li></li>
</ol>
</li>
</ol>
<p><img data-src="./imageDownloadAddress-20211122220139173.png" alt="img"></p>
<ol>
<li>2020年5月，2020全球顶尖计算机科学家排名发布：两位华人学者入全球前10，Top 1000华人学者过百。<a href="https://mp.weixin.qq.com/s/A06jVw3D_g8AWN-AKcB4nA">https://mp.weixin.qq.com/s/A06jVw3D_g8AWN-AKcB4nA</a><ol>
<li>榜单前 100 中的华人学者共计 14 名：</li>
</ol>
</li>
</ol>
<ul>
<li>韩家炜（Jiawei Han）：伊利诺伊大学香槟分校计算机系教授</li>
<li>俞士纶（Philip S. Yu）：伊利诺伊大学芝加哥分校信息技术教授</li>
<li>黄煦涛（Thomas S. Huang）：华人计算机视觉鼻祖、双院外籍院士，已于上个月逝世</li>
<li>陈关荣（Guanrong Chen）：香港城市大学讲座教授以及北京大学长江讲座教授</li>
<li>张宏江（HongJiang Zhang）：源码资本投资合伙人</li>
<li>吴恩达（Andrew Ng）：斯坦福大学客座教授以及教育平台 Coursera 创建者</li>
<li>王子栋（Zidong Wang)：布鲁奈尔大学信息计算与数学院教授</li>
<li>张世富（Shih-Fu Chang）：哥伦比亚大学工程与应用科学学院副院长</li>
<li>汤晓鸥（Xiaoou Tang）：香港中文大学信息工程系教授以及商汤科技创始人</li>
<li>陶大程（Dacheng Tao）：澳洲科学院院士，优必选科技有限公司 AI 首席科学家</li>
<li>David Zhang：香港中文大学</li>
<li>沈学民（Xuemin Shen）：加拿大滑铁卢大学</li>
<li>马维英（Wei-Ying Ma)：字节跳动副总裁</li>
<li>宋晓东：（Dawn Song）加州大学伯克利分校</li>
</ul>
<ol>
<li>2020年6月，《麻省理工科技评论》2020年度全球科技创新英雄榜发布，5位华人上榜。<a href="https://mp.weixin.qq.com/s/Y1rXBCKg8Q7hNk2zrkj_Sw">https://mp.weixin.qq.com/s/Y1rXBCKg8Q7hNk2zrkj_Sw</a></li>
<li>2020年5月，2019中国计算机高引学者榜单出炉，164人入选，周志华位列第二。<a href="https://mp.weixin.qq.com/s/Ww8WMGO0rgA7_pCdApmHfg">https://mp.weixin.qq.com/s/Ww8WMGO0rgA7_pCdApmHfg</a></li>
<li>2020年3月，最新图灵奖颁布！两位皮克斯“前员工”获奖，引领计算机技术和电影“联姻”。<a href="https://mp.weixin.qq.com/s/riF9e5G79iTsnQMIpsaqxA">https://mp.weixin.qq.com/s/riF9e5G79iTsnQMIpsaqxA</a><ol>
<li>国际计算机协会（Association for Computing Machinery，ACM）宣布，Patrick M. Hanrahan 和 Edwin E. Catmull 为 2019 年 ACM A.M. 图灵奖获得者，以表彰他们对 3D 计算机图形学的贡献，以及这些技术对电影制作和计算机生成图像（computer-generated imagery，CGI）等应用的革命性影响。</li>
</ol>
</li>
<li>2020年2月，2020 年斯隆研究奖公布，16位华人科学家入选，4名来自北大数院。<a href="https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&amp;mid=2247495712&amp;idx=1&amp;sn=2806c6effe248daeda8d8ba50a0cc394&amp;source=41#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&amp;mid=2247495712&amp;idx=1&amp;sn=2806c6effe248daeda8d8ba50a0cc394&amp;source=41#wechat_redirect</a></li>
<li>2020年1月，谁是杨强？首位AAAI华人主席，身兼5大顶级组织Fellow，也是华为诺亚方舟实验室开创者。<a href="https://mp.weixin.qq.com/s/ejiYXb9vm2VJGZqJ4jgqcg">https://mp.weixin.qq.com/s/ejiYXb9vm2VJGZqJ4jgqcg</a><ol>
<li><a href="http://news.sciencenet.cn/sbhtmlnews/2019/10/350657.shtm?id=350657">http://news.sciencenet.cn/sbhtmlnews/2019/10/350657.shtm?id=350657</a></li>
</ol>
</li>
<li>2020年1月，Hinton、何恺明等领跑！全球最具影响力2000名AI学者榜单：美国上榜1128人次，中国171人次。<a href="https://mp.weixin.qq.com/s/y440nacScmtRtidIXFeerw">https://mp.weixin.qq.com/s/y440nacScmtRtidIXFeerw</a></li>
<li>2020年1月，北大30岁女博导获2019 IEEE青年成就奖，全球仅三人，深耕微纳电子、神经形态计算。<a href="https://mp.weixin.qq.com/s/eK9otDTdNdt5IOWP5X4hbA">https://mp.weixin.qq.com/s/eK9otDTdNdt5IOWP5X4hbA</a></li>
<li>2019年12月，AAAI最新公布12名资深会员：3位华人教授入选，论文引用近2万次！<a href="https://mp.weixin.qq.com/s/0RBDRvaItg-ASeXVW5WnGQ">https://mp.weixin.qq.com/s/0RBDRvaItg-ASeXVW5WnGQ</a></li>
<li>2019年11月，2019 AAAS Fellow增选名单正式揭晓，谢涛、谢源兄弟双双入选。<a href="https://mp.weixin.qq.com/s/gyL3ao2MTGJxHdHfamYa3w">https://mp.weixin.qq.com/s/gyL3ao2MTGJxHdHfamYa3w</a></li>
<li>2019年11月，2020年IEEE Fellow刚刚揭榜！超70名华人入选，周伯文、叶杰平、陈宝权、熊辉等上榜！<a href="https://mp.weixin.qq.com/s/m3klLdqtqhVSYCSnAyJJtw">https://mp.weixin.qq.com/s/m3klLdqtqhVSYCSnAyJJtw</a></li>
<li>2019年11月，2019全球高引学者榜单出炉：中国735人次入选增速第一，计算机学科蝉联第一，中科院首次入围全球前三。<a href="https://mp.weixin.qq.com/s/KYsd3ffYO-g71hd7Lahy_w">https://mp.weixin.qq.com/s/KYsd3ffYO-g71hd7Lahy_w</a><ol>
<li></li>
</ol>
</li>
</ol>
<p><img data-src="./imageDownloadAddress-20211122220139720.png" alt="img"></p>
<ol>
<li>2019年2月，人工智能 21 个子领域高被引学者Top 3，<a href="https://mp.weixin.qq.com/s/y61AHYw8Sr6yxunuWWOS6g">https://mp.weixin.qq.com/s/y61AHYw8Sr6yxunuWWOS6g</a></li>
<li>各方向全球top 10人 ：<a href="http://wiki.baidu.com/download/attachments/399990097/机器学习.JPG?version=1&amp;modificationDate=1512633221000&amp;api=v2">机器学习.JPG</a>，<a href="http://wiki.baidu.com/download/attachments/399990097/数据挖掘.JPG?version=1&amp;modificationDate=1512633231000&amp;api=v2">数据挖掘.JPG</a>，<a href="http://wiki.baidu.com/download/attachments/399990097/自然语言处理.JPG?version=1&amp;modificationDate=1512633240000&amp;api=v2">自然语言处理.JPG</a>，<a href="http://wiki.baidu.com/download/attachments/399990097/计算机视觉.JPG?version=1&amp;modificationDate=1512633249000&amp;api=v2">计算机视觉.JPG</a>，<a href="http://wiki.baidu.com/download/attachments/399990097/人工智能.JPG?version=1&amp;modificationDate=1512633257000&amp;api=v2">人工智能.JPG</a>，<a href="http://wiki.baidu.com/download/attachments/399990097/网络信息检索.JPG?version=1&amp;modificationDate=1512633267000&amp;api=v2">网络信息检索.JPG</a>，<a href="http://wiki.baidu.com/download/attachments/399990097/计算机图形.JPG?version=1&amp;modificationDate=1512633279000&amp;api=v2">计算机图形.JPG</a></li>
<li>机器视觉方向全球top100人：<a href="http://wiki.baidu.com/download/attachments/399990097/计算机视觉top100.JPG?version=1&amp;modificationDate=1512633306000&amp;api=v2">计算机视觉top100.JPG</a>，<a href="http://wiki.baidu.com/download/attachments/399990097/计算机视觉top100_2.png?version=1&amp;modificationDate=1520569483000&amp;api=v2">计算机视觉top100_2.png</a></li>
<li>图灵奖得主：2019年3月，ACM 宣布2018 年图灵奖获得者是号称深度学习三巨头的 Yoshua Bengio, Yann LeCun 和 Geoffrey Hinton，得奖理由是：他们在概念和工程上取得的巨大突破，使得深度神经网络成为计算的关键元素（For conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.）。<ol>
<li>历年图灵奖得主：<a href="https://amturing.acm.org/byyear.cfm">https://amturing.acm.org/byyear.cfm</a></li>
</ol>
</li>
<li>Aminer：<ol>
<li>清华大学科技知识挖掘平台AMiner统计的近10年人工智能21个子领域被引用数量最高的学者<ol>
<li>全部名单见：<a href="https://www.aminer.cn/mostinfluentialscholar">https://www.aminer.cn/mostinfluentialscholar</a></li>
<li>21个子领域高被引学者Top 3：<a href="https://mp.weixin.qq.com/s/y61AHYw8Sr6yxunuWWOS6g">https://mp.weixin.qq.com/s/y61AHYw8Sr6yxunuWWOS6g</a></li>
</ol>
</li>
<li>清华大学知识挖掘平台AMiner统计的AI领域最有影响力的学者：AI-10 Most Influential Scholars：<a href="https://www.aminer.cn/ai10">https://www.aminer.cn/ai10</a></li>
</ol>
</li>
<li>2019年11月，从百度、微软出走的AI大牛都去哪了？世界华人AI精英流向图的背后……<a href="https://mp.weixin.qq.com/s/3HBHhFeaLnUd8cF3VBBu4A">https://mp.weixin.qq.com/s/3HBHhFeaLnUd8cF3VBBu4A</a><ol>
<li></li>
</ol>
</li>
</ol>
<p><img data-src="./imageDownloadAddress-20211122220140531.png" alt="img"></p>
<ol>
<li>2018华人AI学术影响力Top100：<a href="http://tech.163.com/18/0907/10/DR3I2G0I00098IEO.html">http://tech.163.com/18/0907/10/DR3I2G0I00098IEO.html</a><ol>
<li>综合了过去5年的学术表现，在全球范围内评选出一百位45周岁以下的华人AI学者。整体上，结果综合了全球权威大数据Google Scholar、AMiner学术指标，加权推导出学术指数（Scholar Index）。具体方法上，根据清华科技大数据中心的建议，采用100%的定量数据对学术指标进行评估，通过清华科技大数据中心AMiner团队的人工智能知识图谱筛选排行，综合筛选条件整理的数据结果。</li>
</ol>
</li>
<li>Guide2Research网站日前发布了2018年全球计算机科学和电子领域H-index排名前1000的科学家。中国29名上榜，大陆排名前10的科学家是：张宏江，源码资本（29）；马维英，今日头条（86）；高会军，哈尔滨工业大学（94）；周志华，南京大学（202）；高文，北京大学（228）；谭铁牛，中国科学院自动化研究所（260）；张亚勤，百度（353）；焦李成，西安电子科技大学（497）；王飞跃，中国科学院（556）；刘云浩，清华大学（750）。<a href="https://mp.weixin.qq.com/s/vlVFAk2_iiCEvMG33PLBtA">https://mp.weixin.qq.com/s/vlVFAk2_iiCEvMG33PLBtA</a></li>
<li>35岁以下：<ol>
<li>2021年10月，亚太地区“35岁以下科技创新35人”重磅出炉！20位中国青年学者崭露头角。<a href="https://mp.weixin.qq.com/s/0JY8fT3-mVZwbIXMoXHoKw">https://mp.weixin.qq.com/s/0JY8fT3-mVZwbIXMoXHoKw</a></li>
<li>2021年10月，2021年度全球“35岁以下科技创新35人”正式发布。<a href="https://mp.weixin.qq.com/s/pcytbDIzrEJ3T9s69afMZg">https://mp.weixin.qq.com/s/pcytbDIzrEJ3T9s69afMZg</a></li>
<li>2020年1月，邓磊：“0学姐学长”的7年，国内首个类脑计算博士造出一颗登上Nature的芯片。<a href="https://mp.weixin.qq.com/s/Gw8qlSjeoJxu3ioK50nOAA">https://mp.weixin.qq.com/s/Gw8qlSjeoJxu3ioK50nOAA</a></li>
<li>2019年12月，《麻省理工科技评论》年度中国科技青年英雄榜发布！35位入选者涵盖全球最前沿科学与技术。<a href="https://mp.weixin.qq.com/s/yWQWhlqCqgyps4KXVm7mKw">https://mp.weixin.qq.com/s/yWQWhlqCqgyps4KXVm7mKw</a></li>
<li>2018年6月《麻省理工科技评论》公布了第 18 届 35 Innovators Under 35 评选结果，即 2018 年度 全球 “35 岁以下科技创新 35 人”榜单。<a href="https://mp.weixin.qq.com/s/5J2wKA98GYo9OE99gj4TGQ">https://mp.weixin.qq.com/s/5J2wKA98GYo9OE99gj4TGQ</a></li>
</ol>
</li>
</ol>
<h2><span id="22-机构-期刊">2.2 机构、期刊</span></h2><ol>
<li>2020年7月，全球自然指数揭晓：中科院总榜夺冠，中科大领先北大、清华，位列全球第8。<a href="https://mp.weixin.qq.com/s/J9-5tz8Qn2KwByF8eFopgg">https://mp.weixin.qq.com/s/J9-5tz8Qn2KwByF8eFopgg</a><ol>
<li><a href="https://www.natureindex.com/institution-outputs/generate/All/countries-China/All/score">https://www.natureindex.com/institution-outputs/generate/All/countries-China/All/score</a></li>
<li>2019年6月，nature指数发榜：中科院总榜夺冠，北大、清华列学术机构Top 10。<a href="https://mp.weixin.qq.com/s/fVCL3CJEYbdH8Fr-iunncw">https://mp.weixin.qq.com/s/fVCL3CJEYbdH8Fr-iunncw</a><ol>
<li>Top 10研究机构：<a href="https://www.nature.com/articles/d41586-019-01922-z">https://www.nature.com/articles/d41586-019-01922-z</a></li>
<li>Top 10学术机构：<a href="https://www.nature.com/articles/d41586-019-01923-y">https://www.nature.com/articles/d41586-019-01923-y</a></li>
<li>Nature Index完整表单：<a href="https://www.natureindex.com/annual-tables/2019/institution/all/all">https://www.natureindex.com/annual-tables/2019/institution/all/all</a></li>
</ol>
</li>
</ol>
</li>
<li>2019年1月，CSRankings进行了年度更新，清华在整体排名中位居第十，CMU第一；在AI专业的细分小项中，清华、北大力压CMU，位列第一、第二，前十名的高校中，有六所在中国。并且给出了诸如视觉、nlp这些细分类的方向排名，可以参考。CSRanking的所有代码和数据均可通过链接公开获取：<a href="https://github.com/emeryberger/CSRankings，参考：https://mp.weixin.qq.com/s/cVkq6zpE6-gKGd2wNT2bLA">https://github.com/emeryberger/CSRankings，参考：https://mp.weixin.qq.com/s/cVkq6zpE6-gKGd2wNT2bLA</a></li>
<li>2020年7月，2020谷歌学术指标出炉，CVPR成AI学术会议总榜第一名。<a href="https://mp.weixin.qq.com/s/ULfMvPc2-ri5SdCDwvamMw">https://mp.weixin.qq.com/s/ULfMvPc2-ri5SdCDwvamMw</a></li>
<li>2018谷歌学术期刊&amp;出版物排名公布。在哪学期刊/会议上发表论文才算牛，一目了然。<a href="https://mp.weixin.qq.com/s/fUnn6xQI0bLXQkqacdtdPg">https://mp.weixin.qq.com/s/fUnn6xQI0bLXQkqacdtdPg</a><ol>
<li>Nature第一、Science第三，但值得关注的是，计算机视觉顶会CVPR排名第20，另一个AI领域的顶会NIPS也排名第54，名次较去年有了大幅提升。</li>
<li>排名第一的Nature里，过去5年被引用次数最高的论文，也是“深度学习三大神”Hinton、LeCun和Bengio合著的《深度学习》一文。不仅如此，在CVPR里，过去5年被引次数最多的论文，是当时还在微软亚洲研究院的孙剑、何恺明、张祥雨、任少卿写的的ResNet，被引次数已经过万。</li>
</ol>
</li>
<li>Aminer<ol>
<li>AI 领域全球最具影响力机构 TOP100。<ol>
<li>清华大学的AMiner 团队以 ACM 计算分类系统（CCS2012）为基础，并根据前期采样的中国人智能领域的专家数据，将人工智能细分为如下 21 个子领域。再获取 21 个子领域对应核心期刊和会议最近 10 年的论文，并从中挖掘出每个领域全球最具影响力的学者各 100 名左右，进而分析出top 100的机构<ol>
<li></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><img data-src="./imageDownloadAddress.png" alt="img"></p>
<ol>
<li><p><img data-src="./imageDownloadAddress-20211122220138947.jpeg" alt="img"></p>
</li>
</ol>
<p><img data-src="./imageDownloadAddress-20211122220138967.jpeg" alt="img"></p>
<p><img data-src="./imageDownloadAddress-20211122220139042.jpeg" alt="img"></p>
<p><img data-src="./imageDownloadAddress-20211122220138957.jpeg" alt="img"></p>
<ol>
<li>2019年9月，清华最新计算机推荐学术会议和期刊列表，和CCF到底差异在哪儿？<a href="https://mp.weixin.qq.com/s/7YSP-22VMcc7P2j5IheGBQ">https://mp.weixin.qq.com/s/7YSP-22VMcc7P2j5IheGBQ</a></li>
</ol>
<h2><span id="23-重要会议">2.3 重要会议</span></h2><ol>
<li>2017年的10大AI顶会：<a href="https://mp.weixin.qq.com/s/awHpnyQopspdh_uqcDfqFQ">https://mp.weixin.qq.com/s/awHpnyQopspdh_uqcDfqFQ</a></li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th>ICCV: IEEE International Conference on Computer Vision</th>
<th>领域顶级国际会议，录取率20%左右，2年一次，中国大陆每年论文数不超过10篇</th>
<th>计算机视觉，模式识别，多媒体计算</th>
</tr>
</thead>
<tbody>
<tr>
<td>CVPR: IEEE Conf on Comp Vision and Pattern Recognition</td>
<td>领域顶级国际会议，录取率25%左右，每年一次，中国大陆每年论文数不超过20篇</td>
<td>模式识别，计算机视觉，多媒体计算</td>
</tr>
<tr>
<td>ECCV: European Conference on Computer Vision</td>
<td>领域顶级国际会议，录取率25%左右，2年一次，中国大陆每年论文数不超过20篇</td>
<td>模式识别，计算机视觉，多媒体计算</td>
</tr>
<tr>
<td>ICLR：International Conference on Learning Representations</td>
<td>虽然建立的时间不长，但是质量非常高。2013 年才刚刚成立了第一届，但已经被学术研究者们广泛认可，被认为「深度学习的顶级会议」。由位列深度学习三大巨头之二的 Yoshua Bengio 和 Yann LeCun 牵头创办。ICLR 虽然并不一定是第一个采用 Open Review 进行论文评审的机构，但一定是做得最公开、影响范围最大的一个会议。众所周知，数据的应用表征对于机器学习的性能有着重要影响。表征学习的迅猛发展也伴随着不少问题，比如我们如何更好地从数据中学习更具含义及有效的表征。我们对这个领域展开了探索，包括了深度学习、表征学习、度量学习、核学习、组合模型、非常线性结构预测及非凸优化等问题。<strong>尽管表征学习对于机器学习及包括视觉、语音、音频及 NLP 领域起着至关重要的作用，目前还缺乏一个场所，能够让学者们交流分享该领域所关心的话题。ICLR 的宗旨正是填补这一鸿沟。</strong></td>
<td>深度学习、表征学习、度量学习、核学习、组合模型、非常线性结构预测及非凸优化等问题</td>
</tr>
<tr>
<td>ICML: International Conference on Machine Learning</td>
<td>领域顶级国际会议，录取率25%左右，2年一次，目前完全国内论文很少</td>
<td>机器学习，模式识别</td>
</tr>
<tr>
<td>NIPS: Neural Information Processing Systems</td>
<td>领域顶级国际会议，录取率20%左右，每年一次，目前完全国内论文极少（不超过5篇）</td>
<td>神经计算，机器学习</td>
</tr>
<tr>
<td>IEEE VR:IEEE Virtual Reality</td>
<td>IEEE虚拟现实会议，每年一次</td>
<td>虚拟现实领域</td>
</tr>
<tr>
<td>ACM VRST:ACM Virtual Reality Software and Technology</td>
<td>虚拟现实软件与技术ACM年会，一年一次</td>
<td>虚拟现实领域</td>
</tr>
<tr>
<td>ACL: The Association for Computational Linguistics</td>
<td>国际计算语言学会年会，是本领域最权威的国际学术会议之一，每年举办一次，计算语言学/自然语言处理方面最好的会议, ACL (Association of Computational Linguistics) 主办,</td>
<td>计算语言学，自然语言处理</td>
</tr>
<tr>
<td>COLING: International Conference on Computational Linguistics</td>
<td>计算语言学会议，也是本领域最权威的国际学术会议之一，两年一次</td>
<td>计算语言学，自然语言处理</td>
</tr>
<tr>
<td>IJCAI: International Joint Conference on Artificial Intelligence</td>
<td>人工智能领域顶级国际会议，论文接受率18％左右</td>
<td>人工智能</td>
</tr>
<tr>
<td>AAAI: American Association for Artificial Intelligence</td>
<td>美国人工智能学会AAAI的年会，使该领域的顶级会议</td>
<td>人工智能</td>
</tr>
<tr>
<td>PRICAI: Pacific Rim International Conference on Artificial Intelligence</td>
<td>亚太人工智能国际会议</td>
<td>人工智能</td>
</tr>
<tr>
<td>SIGKDD</td>
<td>数据挖掘方面最好的会议, ACM 主办, 每年开。录取率18％左右，会有推荐相关研究内容。</td>
<td>推荐系统</td>
</tr>
<tr>
<td>SIGIR</td>
<td>信息检索方面最好的会议，与检索、推荐、挖掘等都有关，ACM 主办, 每年开。录取率19％左右，会有推荐相关研究内容。ACM SIGIR是国际计算机学会主办的信息检索领域的最重要学术会议，中国计算机学会推荐国际学术会议 中的A类</td>
<td>推荐系统</td>
</tr>
<tr>
<td>RecSys</td>
<td>不是A类会议，ACM主办的推荐系统旗舰会议，其征文范畴包含推荐系统的各个领域，包括算法设计、系统实现、理论推导和评估测试等。RecSys是推荐系统领域最好的专门会议。</td>
<td>推荐系统</td>
</tr>
<tr>
<td>SysML</td>
<td>Jeff Dean、李飞飞等发起，底层系统、平台和机器学习结合。会议地址：<a href="http://www.sysml.cc/">http://www.sysml.cc/</a></td>
<td>机器学习、基础系统、资源、平台</td>
</tr>
</tbody>
</table>
</div>
]]></content>
  </entry>
  <entry>
    <title>人类误判心理</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E4%BA%BA%E7%B1%BB%E8%AF%AF%E5%88%A4%E5%BF%83%E7%90%86-%E8%8A%92%E6%A0%BC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>人类误判心理学-芒格</p>
<p>注：根据书本、网络等内容整理而成。</p>
<h1><span id="整体及25个心理学误区">整体及<strong>25</strong>个心理学误区</span></h1><p>​        总共25个人类误判心理倾向，查理通过自己的实践证明，他的这25条是比大多数心理学教材有用了，在实用性上拥有巨大的优势。人类的――经常出错但总体上很有用――心理倾向相当多，而且相当不同。大量的心理倾向的自然结果就是社会心理学的重要原理：认知往往取决于情景，所以不同的情景通常会引起不同的结论，哪怕是同一个人在思考同一个问题的时候也是如此。人不同于机器，不能非常科学精密地进行分析判断，因此人在决策时会有很多错误倾向，而且难以察觉。</p>
<span id="more"></span>
<h2><span id="一-奖励和惩罚超级反应倾向">一、奖励和惩罚，超级反应倾向</span></h2><ul>
<li>激励机制具有强大威力，但是也会引发偏见，激励机制能够导致人们在做坏事的时候觉得自己是正当的，人们倾向于钻制度的空子。惩罚也强烈影响到行为和认知。</li>
<li>激励机制的威力是无穷大的，它能改变个人/集体的行为。激励的威力并不全是正面的，它的另一个后果是会造成“激励机制引起的偏见”。</li>
<li>人是趋利性动物，只要激励作用在，无论怎么设计制度，都会有人想方设法去寻找漏洞。</li>
<li>方法：如果你想要说服别人，要诉诸利益，而非诉诸理性。设计制度时需避免奖励容易作假的事情</li>
<li>举例：<ul>
<li>联邦快递系统的核心和灵魂是保证货物按时送达，它必须在三更半夜让所有的飞机集中到一个地方，然后把货物快速转发到各架飞机上，由此才能确保货物准时到达客户手里。但是有一段时间，联邦快递的工人总是无法按时完成工作。公司用了各种办法都无法奏效。之后，他们找到了问题的症结，并做了调整：把原来给工人按小时来支付夜班薪水的激励机制调整为：按照班次来支付薪水，并允许夜班工人在把所有货物装上飞机后提前回家。结果是，这个办法奏效了。</li>
</ul>
</li>
</ul>
<h2><span id="二-喜欢热爱倾向">二、喜欢/热爱倾向</span></h2><ul>
<li>刚出生的人也会“天生就喜欢和热爱”对他好的人。芒格说，人类天生喜欢被喜欢、被爱。</li>
<li>促使人们忽略热爱对象的缺点，“爱屋及乌”，为了爱而扭曲事实。偏爱那些能够让自己联想起热爱对象的人、物品、行动</li>
<li>方法：发挥榜样的作用。</li>
<li>举例：<ul>
<li>他跟巴菲特都受益于一个人：巴菲特的叔叔弗雷德·巴菲特。文中说弗雷德·巴菲特在杂货店有干不完的活，但干活的时候总是很快乐，对芒格跟巴菲特的影响一直持续至今，激励他们变得更好。</li>
<li>芒格除了提到弗雷德·巴菲特，还经常提及富兰克林对他的影响，从芒格的书叫《穷查理宝典》就可见一斑。</li>
<li>在交易市场里面，对所选择的投资标的产生了“爱”往往是投资失败的重要原因</li>
</ul>
</li>
</ul>
<h2><span id="三-讨厌憎恨倾向">三、讨厌/憎恨倾向</span></h2><ul>
<li>芒格说，刚出生的人类会“天生就讨厌和憎恨”对他很坏的人。</li>
<li>促使人们忽略讨厌对象的优点，讨厌能联想到讨厌对象的事物，为了仇恨扭曲事实。</li>
<li><strong>恨而不敢表达，产生的是恐惧。恨而敢于表达，最先触发的情绪可能是愤怒。</strong></li>
<li>方法：<strong>训练自己容纳两种立场不同、相互矛盾，包括相反的观点。把自己的恨意，借助愤怒，表达出来</strong></li>
<li>举例：<ul>
<li>人类史很大程度上也是一部战争史</li>
</ul>
</li>
</ul>
<h2><span id="四-避免怀疑倾向">四、避免怀疑倾向</span></h2><ul>
<li>人类的大脑天生就有一种尽快作出决定，以此消除怀疑及不确定的倾向。</li>
<li>引发的因素通常是困惑和压力，在面对宗教问题时这两种因素当然都存在，因而，大多数人的自然状态就是需要有某种宗教信仰。</li>
<li>方法：面对一个自己不够确定性的问题时，去深入挖掘当中的成因，包括未来发展的走向。观察一下比自己认知高，比自己厉害的人是怎么判断、怎么做选择的。<strong>持续地刻意练习。</strong></li>
<li>举例：<ul>
<li>在投资上，当我选择了一个投资标的后，出于“价值投资”的考虑，我可能会觉得：既然经过了解，我已经相信这个投资标的是没问题的，是有长远的投资价值的。那么，在面对相关的各种负面信息时，我会选择不去相信，或者排斥去深入了解背后的成因。</li>
<li>想熬出怀疑倾向的形成，某种程度上，是为了帮助人类减少能量的损耗。但，它的另一方面是懒惰的心理（正如王兴所说：“多数人为了逃避真正的思考愿意做任何事情）。</li>
</ul>
</li>
</ul>
<h2><span id="五-避免不一致性倾向">五、避免不一致性倾向</span></h2><ul>
<li>为了节省运算空间，人类的大脑会不愿意作出改变。比如人们总是很难改变自己的坏习惯。</li>
<li><strong>本质不是它们的复杂性，而是因为它们与原有的旧思想不一致。</strong></li>
<li>如果精于运用避免不一致性，就能控制别人的态度。一个人只要假装拥有某种身份、习惯或者结论，他自己通常就会信以为真。</li>
<li>如果你拥有一个良好的习惯（如每日写作），那么，这种持续的保持势必会带给你极大的好处。当人们维持的某个习惯、某个结论是坏的、错的，那么，保持前后的一致性，可能会是一种灾难。。</li>
<li>方法：<ul>
<li>维持好习惯，避免或者戒除坏习惯。<strong>努力考虑任何有可能证伪他的假说的证据</strong>。一方面需要持续地提高自己的认知，敢于否定自己既有的观点以及习惯的做法；另一方面，在抵抗这种本性的过程中，当中会产生各种不适的情绪，你得能够做到不受其影响。所以，必然是需要持续地刻意练习的。</li>
</ul>
</li>
<li>举例：<ul>
<li>很多人会每天穿同样风格、甚至一样的衣服（如乔布斯的牛仔裤与黑体恤、周鸿祎的红T恤）；也有很多人在喜欢吃一样菜后，在之后很长的一段时间里，每天都吃；又有很多人随着在一个公司里工作的时间越来越长，会选择一直待着，不愿跳槽。</li>
<li>因为你过去的某个结论一直到现在都是正确的，那么，你在做每一个决定时，基本不需要耗费什么时间与精力。</li>
<li>人们倾向于积累大量僵化的结论和态度，而不经常去检查和改变，即便有大量的证据表明它们是错误的。</li>
</ul>
</li>
</ul>
<h2><span id="六-好奇心倾向">六、好奇心倾向</span></h2><ul>
<li>哺乳动物天生具有好奇心，人天生具有好奇心倾向</li>
<li><strong>好奇心能帮助人们防止或减少其他心理倾向造成的糟糕后果，也能让人哪怕结束了正式的教育也能持续拥有各种乐趣及智慧。</strong></li>
<li>好奇这种心理，如果肆意打开，会让外部的信息源源不断地进入到我们的大脑。如果我们没有足够的能力去做归类及删减，那么，这些过多的信息反而会限制我们。再者，我们很容易根据我们所接收到的信息，去形成一些观点。更可怕的是，我们会以为这些观点代表着事实。</li>
<li>方法：<strong>在面对我们习以为常的事实或持有的观点时，一定要把“好奇心”这匹马放出来遛一遛。在面对一些能让我们产生即时快感，包括容易快速产生价值判断的信息时，我们则要有意识地控制一下自己的好奇心。有效驾驭自己好奇心的一个方向是：我们要不断打磨自己的认知框架（筛选、界限等）。</strong></li>
<li>举例：<ul>
<li>前五个误判心理里面的“讨厌不确定性”及追求“一致性”，某种程度上都是人们为了节省能量，而抑制了求知、求真的欲望。</li>
<li>芒格本身就是一个好奇心极强的人。他平常大量涉猎各学科的知识，例如，物理学、生物学、气象学、哲学等，这些在很多外人看来与投资并无直接关系的知识，恰恰是帮助查理·芒格能做出精准投资决策的基础。</li>
<li>乔布斯的”Stay hungry. Stay foolish.”不也在提醒我们要时刻保持好奇心？</li>
<li><strong>新闻媒体在我看来，某种程度上是为人类的这种好奇心理寻得了一个释放的出口。</strong></li>
</ul>
</li>
</ul>
<h2><span id="七-康德式公平倾向">七、康德式公平倾向</span></h2><ul>
<li>人们表现出并期待从别人那里得到康德所定义的公平。康德式命令是某种“黄金法则”，它要求人们遵守这些方式，那么就能够保证社会制度对每个人来说都是最好的。同时，当人们期待然而没有得到公平分配时，往往会表现出不满的情绪。类似孔子的“己所不欲，勿施于人。”</li>
<li>追求公平是人的一种天性，而且，公平的存在，是能够提高群体的运转效率的。但规则总是有漏洞的</li>
<li><strong>薛兆丰：每当我们在讲公平的时候，背后的含义是说，它是符合效率的。只有那些让社会里每个人都有积极性去积累财富的规则，才是公正的规则；只有那些让社会能够存活下来的规则，才是公正的规则。</strong></li>
<li>方法：<strong>努力做个明白人，然后主动做出符合你需求跟价值观的选择</strong></li>
<li>举例：<ul>
<li>很多受过教育的人，多少都有这样的倾向：我愿意遵守规则，并期待别人也能遵守规则。对于不能遵守规则的人，会产生不满情绪。</li>
<li>也有人利用规则谋取个人利益。</li>
</ul>
</li>
</ul>
<h2><span id="八-艳羡妒忌倾向">八、艳羡/妒忌倾向</span></h2><ul>
<li>妒忌无处不在。“<strong>驱动这个世界的不是贪婪，而是嫉妒。</strong>”</li>
<li>嫉羡：眼红、得不到毁掉。贪婪：眼红、想办法占有但不毁灭。嫉妒：眼红、知道差别界限。</li>
<li>方法：只要能正视自己的欲望，并相信自己配得起并能拥有好东西，那么，自己会努力变得强大。甚至，如果还愿意承认其他比自己强大的人的存在，并且笃信，那些好东西，是从这些更强大的人身上获得的，那么，你甚至会感谢他们，并且愿意在他们面前低头。这个时候，你的嫉妒心理会转化成“感恩”。</li>
<li>举例：<ul>
<li>如果某个物种在进化过程中经常挨饿，那么这个物种的成员在看到食物时，就会产生占有那食物的强烈冲动。如果被看到的食物实际上已经被同物种的另外一个成员占有，那么这两个成员之间往往会出现冲突的局面。</li>
<li>大多数人在公共场合下也会避开承认自己有嫉妒的心理。从古至今，不同文化普遍都在宣扬嫉妒的邪恶</li>
</ul>
</li>
</ul>
<h2><span id="九-回馈倾向">九、回馈倾向</span></h2><ul>
<li>投桃报李、以牙还牙是人类的天性，请尽情释放。这种倾向的好处是可以促进有利于成员利益的团队合作。</li>
<li>很多人会利用这些心理让别人做出原本不会做的决策，需要提防。</li>
<li><strong>对坏人过于仁慈与宽容，某种程度上是在伤害那些真正的好人</strong>。<strong>如果对所爱的人都无法自然地去取悦，我会怀疑这种爱是虚伪的，甚至是假的。</strong></li>
<li><strong>如果你是期望通过以德报怨来获益，则可能显得有些一厢情愿。</strong>（外国人思维，中国人可能有些不一样了，这里就有冲突，需要综合看待，分类综合使用）</li>
<li>方法：<strong>敢爱敢恨，快意恩仇。</strong>互相让步。</li>
<li>举例：<ul>
<li>销售员善意行为会引起你额外多付出钱</li>
<li>谈判中，自己有所让步对方也大多会作出让步</li>
<li>情感关系中，正反馈会引发美好的感情互动</li>
<li>对于工作中的客户，我们也要主动地先去付出、去取悦他们。如果只是靠着“等靠要”的心理，就想获得客户的好感，我觉得是违反规律的，是一种妄想。</li>
</ul>
</li>
</ul>
<h2><span id="十-受简单联想影响的倾向">十、受简单联想影响的倾向</span></h2><ul>
<li>避免受到简单联想的误导。</li>
<li>相当于条件反射，由某个东西简单联想到另外一个东西从而产生影响。</li>
<li>方法：<ul>
<li>富兰克林提议：结婚前要睁大双眼看清楚，结婚后要睁一只眼闭一只眼。芒格提议：实事求是地看清现实，可还是去爱。</li>
<li><strong>审慎地看待每次的成功，提取出当中的偶然因素，以免夸大新行动的成功概率。</strong></li>
<li><strong>分析新的行动里将可能遇到哪些在过去没有出现的危险因素。</strong></li>
<li>成功往往是偶然的，而失败则常是必然的。</li>
</ul>
</li>
<li>举例：<ul>
<li>古代波斯人会把送来坏消息的信使杀掉。<strong>原因只是因为这些信使把真实的坏消息带回了波斯。</strong>但这样就不会有人敢送来任何消息。</li>
<li>实际质量相差无几的产品，我们会偏向去选择更贵的产品。因为价钱更贵，容易让我们联想到质量更有保证。</li>
<li>很多知名品牌的广告要么是充满爱的，要么是充满力量的。背后的原理很简单：我们会因为这些充满爱与力量的广告，联想到它们对应的产品也是充满爱跟力量的，由此，不由自主地去购买、消费这些产品。</li>
<li><strong>当我们在想做好事时，最好考虑一下人性的某些因素，否则，当遇到你完全没有预料到的结果时，你可能会对做好事这个行为产生怀疑。比如接济穷人、流浪人员等。</strong></li>
</ul>
</li>
</ul>
<h2><span id="十一-简单的-避免痛苦的心理否认">十一、简单的、避免痛苦的心理否认</span></h2><ul>
<li>当现实太过于让人觉得痛苦，人们倾向于去否认它。经常跟爱情、死亡和对化学物质依赖有关。痛苦：求而不得、丧失</li>
<li><strong>悲剧本身并不一定会导致心理问题，它之所以令我们陷入困境，常常是因为我们想否认人生的悲剧性。</strong></li>
<li><strong>会让你正视对于你真正重要的人与事，如果你顺着这个方向挖掘下去，可能就是你扭转人生的开始。</strong></li>
<li>方法：多数人要么完全不去让这种痛苦流动起来，要么干脆<strong>在头脑层面把这种痛苦给切割掉</strong>，然后声称自己已经不在意了，其实日后的每一天基本都受其影响。</li>
<li>举例：<ul>
<li>很多人沉迷于酒精与毒品，导火索普遍是因为当时那个痛苦实在太大了，大到让其难以接受</li>
<li>二战期间，芒格家有位世交的儿子非常优秀，可是他在乘坐飞机时遇难了。他母亲难以接受这个现实，所以，一直拒绝相信他儿子已经去世。</li>
<li><strong>悲剧本身并不一定会导致心理问题，它之所以令我们陷入困境，常常是因为我们想否认人生的悲剧性。</strong></li>
<li>有些人在面对大病、甚至是生死关头，最终活过来后，能就此彻底改变自己的原因。</li>
</ul>
</li>
</ul>
<h2><span id="十二-自视过高的倾向">十二、自视过高的倾向</span></h2><ul>
<li>过度重视自己，人们倾向于夸大各种与自己相关的人和事物的价值</li>
<li><strong>人们总是容易过度重视自己，会倾向于认为自己拥有的东西更好，并会偏好跟自己相似的人待在一起。</strong></li>
<li>禀赋效应：<strong>人们做出决定之后，就会觉得自己的决定很好，甚至比没做出这种决定之前所认为的要好。</strong></li>
<li>方法：努力做到客观。<strong>我们这个文明社会中最有用的成员就是那些发现他们管理的机构内部出现问题时愿意“清理门户”的负责人（习大大反腐、打黑，Robin、Qi、珊珊改变风气，良币驱逐劣币）。</strong></li>
<li>举例：<ul>
<li>“丢钱包实验”<ul>
<li>这是心理学的一个实验。实验的结果表明：如果捡到钱包的人，根据从钱包里找到的线索发现失主跟自己在某些方面有相似性，那么，归还钱包的概率是最高的。</li>
</ul>
</li>
</ul>
</li>
<li></li>
</ul>
<h2><span id="十三-过度乐观倾向">十三、过度乐观倾向</span></h2><ul>
<li><strong>过度自信。</strong>古希腊演说家德摩斯梯尼说：一个人想要什么，就会相信什么。</li>
<li>现实生活中，很多成功的人正是来源于他们的过度自信。有句格言是这么说的：”千万别低估那些高估自己的人”。他们肯定不只是自信，还有行吧，很多为人没成功前讲得话，在当初听是什么感觉？芒格认为，<strong>高度的自我称赞要比虚伪的谦虚好得多</strong>。</li>
<li>方法：学习应用概率论。把对“人”的关注转向对“事”的关注</li>
<li>举例：<ul>
<li>彩票、竞技项目中的过度自信研究发现，在买彩票时，如果号码是买家自己挑选的，那么相比号码是随机分配的而言，他们下的赌注会更多。而实际上这两种情况的获奖概率显然是一样的。</li>
<li>如果有人喜欢某项运动，例如足球，那么当他们觉得对各个球队的情况比较了解时，会很自然地去买体育彩票。再如，在一些竞技项目里，人们会倾向于挑选那些实际水平比自己高很多的选手。</li>
<li>芒格说，他在担任某个学术委员会的主席时，试图说服其他人不要对求职者进行面试，而只要看其书面申请材料里显得较优秀的人就可以了。当然，得到其他人的反驳，并被指不尊重学术。而芒格的观点是：<strong>学术研究表明，从面试中得来的印象，其预测价值很低。</strong>根据这个观点，当在面试中碰到的是能说会道的人时，一定要小心，不要太相信自己的印象。</li>
<li>“托尔斯泰效应”<ul>
<li>按托尔斯泰的观点，很多恶贯满盈的罪犯并不会觉得自己有多坏。他们通常认为：1、他们并没有真正犯过罪；2、基于他们过去糟糕的处境，包括面临的生存压力，他们所作出的行为，完全应该得到理解及原谅。事实上，我们在生活中会遇到这样一类人：他们在做错事后，把其自身贬得一文不值，诉说自己多么的不容易，有着太多的问题，并且也为此做了努力，只是结果还是这样。所以，需要得到谅解。甚至会让我们产生一种幻觉：如果不原谅他们，似乎是我们的错。芒格说，这样的人，应该把其当做是品德有问题。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><span id="十四-被剥夺超级反应倾向">十四、被剥夺超级反应倾向</span></h2><ul>
<li>厌恶损失。</li>
<li>方法：厌恶损失是人们潜意识层面的心理，难以彻底避免。一方面是提升我们自身的认知水平，另一方面，可以建立一种反思的机制，时刻监控自己的决策，事后总结自己的错误行为等。整理自己曾因厌恶损失的心理而犯错的各个事件，描述清楚当时的心理活动、情绪及行为等，而且，日后都可以把这种记录作为一种功课。</li>
<li>举例：<ul>
<li>失去才会懂得珍惜</li>
<li>芒格夫妇养了一条很温顺的狗，通常这只狗是不会咬人的。但是，只有一种例外情况：在给它喂食的时候，如果你把食物从它嘴里拿走，那么，它会去咬你。</li>
<li>一个人得到10美元的感受和失去10美元的感受分量是不同的。失去造成的伤害比得到带来的快乐多得多。除此之外，如果有个人即将得到某样他非常渴望的东西，而这样的东西却在最后一刻飞走了，那么他的反应就会像这件东西他已经拥有了很久却突然被夺走一样。</li>
<li>赌徒很容易倾家荡产的原因是在于：他们在输钱后，在“厌恶损失”的驱使下，会急于想要扳平。而一旦输的越多，这种急躁的情绪会更加明细，直至破产。</li>
<li>当时，芒格有个股票经纪人朋友打电话给他，说要以极低的价格卖给他300股那时交易率极低的贝尔里奇石油公司的股票，每股只要115美元。芒格买完的第二天，那朋友又想以同样的价格再卖给他1500股，但芒格考虑到需要变卖一些东西才能筹到相应的现金，所以他拒绝了。然而，不到两年之后，壳牌收购了贝尔里奇石油公司，价格大约是每股3700美元。</li>
</ul>
</li>
</ul>
<h2><span id="十五-社会认同倾向">十五、社会认同倾向</span></h2><ul>
<li>乌合之众，即从众心理倾向，只要模仿他们，不需要做过多的思考。这毫无疑问可以把复杂的事情简单化，很省能量。</li>
<li>人们在感到<strong>困惑或者有压力</strong>的时候，尤其是在既困惑又有压力的时候，最容易受社会认同倾向影响。</li>
<li><strong>多数人为了逃避真正的思考愿意做任何事情。</strong></li>
<li><strong>方法**</strong>：跟随自己抱有的价值观及信念行事，弱化短期反馈。为了真相而直面矛盾与困难的勇气，哪怕过程中头破血流也在所不惜**</li>
<li>举例：<ul>
<li>一名教授让10名实验员安静地待在电梯里，且背对着电梯口。那么，在其他人进入电梯时，通常也会像那10名实验员那样背对电梯口。</li>
<li>家长最无奈的地方是：在他们苦口婆心地教育孩子时，那些孩子基本上是很难真正听从的。<strong>年轻人最尊重的是他们的同龄人，而不是他们的父母或者其他成年人。</strong>聪明的家长一般不会试图通过教训子女来教育他们，而是会了解孩子的交友质量，并做出适当地引导、干预。</li>
<li>开商店，开教育机构，以及me too me later</li>
</ul>
</li>
</ul>
<h2><span id="十六-对比错误反应倾向">十六、对比错误反应倾向</span></h2><ul>
<li>心理锚定造成对现状的妥协以及微小错误积累导致悲剧结局，即“小错不补，能沉大船”</li>
<li><strong>当一个人逐步逐步走向灭亡时，如果他每一步都很小，大脑的对比错误反应（对标）倾向通常会任由这个人走向万劫不复的境地。这种情况会发生，是因为每一步和他当前位置的对比太小了。</strong></li>
<li>方法：不要忽略小失误。搞清楚自己真正要的对象是什么，利用专业人士来弥补你的认知缺漏，从系统的角度看待每一个问题。</li>
<li>举例：<ul>
<li>温水煮青蛙</li>
<li>你持有的某只你非常看好的股票，在熊市即将来临的时候，价格一天天的降低，但是因为每一天的降低跟前一天比并不显得很大，所以你没有理会。但是因为价格一直在下降，以致于某一天，其实相比价格的高点，其降幅已经很大。你那时想要做出卖出的操作，但是，亏损已经很严重。</li>
<li>你去买房的时候，人家房产经纪人先带你去看几套条件很差但价格很离谱的房子，紧接着，带你去看一套条件很一般价格也一般的房子，这个时候，你很可能会成交。</li>
</ul>
</li>
</ul>
<h2><span id="十七-压力影响倾向">十七、压力影响倾向</span></h2><ul>
<li>压力会引发两种心理倾向，一种是：避免怀疑倾向，一种是：社会认同倾向</li>
<li>轻度压力能轻微改善人们的表现，沉重的压力则会引发彻底失调。 </li>
<li>方法：<strong>自我组织力就是，当一个人的自我在高压下感觉要散架的时候，或者被击溃而瓦解的时候，能不能重新地组织起来。</strong>如果一个人的自我组织力较强，那么他哪怕在高压下，也能够确保自己不崩溃。这样的人一般有个特点：<strong>他们敢于面对现实，哪怕这个现实让他名誉扫地或者让他处于崩溃边缘，也能够正视，包括正视自己的弱点。</strong></li>
<li>举例：<ul>
<li>人在被邪教洗脑后，虽然难，也可以在压力下恢复。</li>
<li>巴普洛夫关于压力的研究<ul>
<li>巴普洛夫有一次发现，他原来训练有素的狗在一场洪水的影响下，其行为跟原来相比，显得很不一样。由此，他接下来做了看起来有点残忍的实验：他在那些狗接下来的余生里，不断地给其施加压力，让他们精神崩溃，然后再来修复这些崩溃。最终他给出了4个结论：<ul>
<li>他能够对这些狗进行分类，然后预测具体某只狗有多么容易崩溃；</li>
<li>那些最不容易崩溃的狗也最不容易恢复到崩溃前的状态；</li>
<li>所有狗都可以被弄崩溃；</li>
<li><strong>除非重新施加压力，否则他无法让崩溃的狗恢复正常</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><span id="十八-错误衡量易得性倾向">十八、错误衡量易得性倾向</span></h2><ul>
<li>人容易满足于易得的东西。人类的记忆通常分为<strong>工作记忆</strong>跟<strong>长期记忆</strong>。工作记忆“是一种对信息进行暂时加工和贮存的容量有限的记忆系统”。一方面，它是一种短期的记忆，另一方面，它记忆的容量是有限的。除非，它能被加工成长期记忆。</li>
<li>人容易满足于易得的东西，“如果我爱的女孩不在身边，我就爱身边的女孩。”</li>
<li>方法：按程序办事，包括使用检查清单。反面思考，寻找并聘请那些知识渊博、有怀疑精神、能言善辩的人，请他们扮演现有观点的反方角色。不因为容易得到而觉得更加重要。关注那些不容易被量化的因素，考虑这种倾向会让人更易记住那些鲜明的形象，所以你可以刻意让自己低估他们的重要性，尝试把注意力放在那些形象不那么鲜明的东西上。</li>
<li>举例：<ul>
<li>我们在写作平台上写文章，天然地会很关注阅读量、点赞数。虽然，这些数据在一定程度上能反映问题，但如果我们误认为这是更重要的东西，则可能会失去焦点。例如，我们会容易忘记：<strong>最终让读者愿意花费注意力来关注你文章的，是你的文章能满足他们的需求</strong>。</li>
</ul>
</li>
</ul>
<h2><span id="十九-不用就忘倾向">十九、不用就忘倾向</span></h2><ul>
<li>方法：勤奋。提醒人们，对于任何技能，需反复练习才能熟悉掌握；需终生练习才不会遗忘。</li>
</ul>
<h2><span id="二十-化学物质错误影响倾向">二十、化学物质错误影响倾向</span></h2><ul>
<li>人们对毒品等化学物质的依赖，通常是为了逃避痛苦的现实。一旦这种依赖让人成瘾，通常会导致道德沦丧。而且，虽然有方法戒除，但整个过程会非常困难。</li>
<li>方法：远离。</li>
</ul>
<h2><span id="二十一-衰老错误影响倾向">二十一、衰老—错误影响倾向</span></h2><ul>
<li>方法：带着快乐不断思考学习。</li>
<li>举例：据伦敦国王学院细胞与行为实验室副主任桑德琳·蒂雷（Sandrine Thuret）的观点，<strong>新的神经元对人的学习和记忆很重要</strong>。她曾做过实验，如果阻止海马体产生新神经元，大脑的一些记忆功能如空间认知能力会被关掉。如果想防止大脑衰老，显然需要让大脑产生新的神经元。据桑德琳的观点，<strong>促进新神经元产生的方法有：学习、运动和饮食。</strong>衰老是个不可逆的事情，但是，大脑却是终生都具有可塑性的。<strong>只要能通过持续学习等方式保持新神经元的产生，那么，大脑的衰老是可以得到控制的。</strong></li>
</ul>
<h2><span id="二十二-权威错误影响倾向">二十二、权威—错误影响倾向</span></h2><ul>
<li>人类服从权威的天性：自然历史和社会历史的长期发展。</li>
<li>迷信权威有危险，选择当权者需谨慎。</li>
<li>方法：把对人的关注转向对事的关注，按程序办事，例如使用检查清单</li>
<li>举例：<ul>
<li>美国有个医生给护士留了手写的纸条，吩咐的是给病人治疗耳痛。纸条上写着“Two drops, twice a day, r.ear.”（“每天两滴，右耳。”）这个护士把r.ear（右耳。r指的是right）看成了rear（屁股），于是，她让病人翻过身，把滴耳剂滴入了病人的肛门。</li>
<li>米尔格拉姆实验<ul>
<li>米尔格拉姆是耶鲁大学的心理学家，他这个实验是在纳粹分子阿道夫·艾希曼被判死刑后的一年后进行的。艾希曼及其纳粹追随者在二战期间参与了犹太人的大屠杀，其中，艾希曼是执行”最终方案“的主要负责者。米尔格拉姆试图测试权威人物到底能够在多大程度上促使普通人去做罪大恶极的事情。</li>
<li>在这个实验中，有个人假扮成权威人物，一个主导这次正规实验的教授。这个人能够让许许多多普通人将他们完全信以为真的假电刑用来折磨他们的无辜同胞。过程中，会配合被电击人假装的痛苦尖叫。</li>
<li>这个实验里呈现的结果，凸显了成年人在面对权威人士时，其服从的倾向是相当巨大的。</li>
<li>当然，这个实验并不只是凸显了服从权威一种心理倾向。被命令按下电击按钮的普通人，在那个当下他也许是有道德上的愧疚感的，但是，当在场的其他人都表现出无动于衷时，这样的沉默意味着他的行为是没问题的。这是典型的“寻找认同”倾向。可见，当服从权威跟其他心理倾向搭配的时候，其产生的破坏力是很大的。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><span id="二十三-废话倾向">二十三、废话倾向</span></h2><ul>
<li>人类爱闲扯淡：人是一种拥有语言天赋的社会动物，所以，天生就有本事啰里啰嗦。一方面他们释放了自己的说话欲望，另一方面，可以证明自己的存在</li>
<li>不要让废话多的人影响到自己。避免在正式场合扯淡。</li>
<li><strong>方法**</strong>：引领他们，而不是被引领。共情他们的感受、情绪，岔开话题。**</li>
</ul>
<h2><span id="二十四-重视理由倾向">二十四、重视理由倾向</span></h2><ul>
<li>万事都有理由。<strong>偏爱理由的背后，是一种对准确认知的追求。人们讨厌不确定，获得准确认知往往都很愉悦。</strong></li>
<li>好的方面：明确感知理由，有利于达到目的。</li>
<li>坏的方面：<ul>
<li>往往把理由当目的。我们会让理由成为我们前进路上的牵绊，会阻碍我们的执行力（有时候纷繁错杂，很难有准确的理由和依据）。</li>
<li>重视理由倾向是如此强大，乃至一个人给出的理由哪怕是毫无意义的或者是不准确的，也能使他的命令和要求更容易得到遵从。</li>
</ul>
</li>
<li>方法：合理使用，注意场合和时机</li>
</ul>
<h2><span id="二十五-lollapalooza倾向数种心理倾向共同作用造成极端后果的倾向">二十五、lollapalooza倾向——数种心理倾向共同作用造成极端后果的倾向</span></h2><ul>
<li>lollapalooza：音乐节的意思，多种音乐表演、活动形式在一起。</li>
<li>数种心理倾向共同作用造成极端后果的倾向</li>
<li><strong>人类一个行为的产生，其背后是由多种心理因素所造成的。</strong></li>
<li><strong>方法**</strong>：系统性的思考。**</li>
<li>举例：比如邪教组织吸引人、洗脑。</li>
</ul>
<h2><span id="问与答十个例子方法">问与答（十个例子/方法）：</span></h2><ul>
<li>一、卡尔•布劳恩的交流方法。<ul>
<li>卡尔.布劳恩掌管他的德式的大企业有一条非常简单的规矩：你必须讲清楚何人将在何时何地因何固做何事。如果你给属下写字条，吩咐他去做事情，却没有交待原因，布劳恩可能会解雇你。因为根据重视理由倾向，人们喜欢准确的认知，想要知道为什么。只有一丝不苟地把某个想法的原因都摆出来，这个想法才最容易被接受。</li>
</ul>
</li>
<li>二、飞行员训练中对模拟器的使用。<ul>
<li>所有的知识和技能以及天赋都会因为缺少训练而退化。明智的选择是对于那些很重要却很少派得上用场的技能等进行天天巩固练习。我们必须在多元思维模型上达到精通的状态。这需要每天练习。现实中，你除非刻意练习，否则很多重要的思维模型和技能并无用武之地。这时，飞行模拟器能够帮助你。飞行员使用飞行模拟器模拟训练各种场景，包括那些极端情境。这使得飞行员能够熟练地掌握各种必备的技能，即使飞机出现极端小概率事件，也能驾轻就熟地度过难关。</li>
</ul>
</li>
<li>三、酒瘾戒除组织的制度。<ul>
<li>酒瘾很难戒除。但是酒瘾戒除组织通过造成数种心理倾向一起来对抗酒瘾，能够把戒除率稳定在95%。</li>
<li>重视理由倾向：通过了解自己上瘾的原因；</li>
<li>奖励超级反应倾向：积极反馈；</li>
<li>社会认同倾向：抱团互助，我不是一个人在奋斗。</li>
</ul>
</li>
<li>四、医学院中的临床培训方法。<ul>
<li>床医学教育要求“先看，后做，再教”原则，只有自己看过和做过的，才可以教给别人。避免不一致的正向应用，教师会将自己相信的知识教给学生，而非相反。</li>
</ul>
</li>
<li>五、美国制宪大会的规则：绝对保密的会议；<ul>
<li>最终投票之前所有的投票都不记名；大会结束前选票随时可以重投；对整部宪法只投一次票。这些是非常聪明的、尊重心理学的规则。如果那些开国元勋当时使用的是另外一种表决程序，那么许多人将会受到各种心理倾向的影响，从而采用那些互不一致的、僵化的立场。那些英明的开国元勋让我们的宪法顺利通过表决，因为他们摸透了人们的心理。</li>
</ul>
</li>
<li>六、使用祖母的激励机制：<ul>
<li>让人们约束自己，从而更好地完成自己的任务。她说你们必须先吃完胡萝卜，然后才准吃甜点。</li>
<li>利用频率较高的活动来强化频率较低的活动，从而促进低频活动的发生。</li>
<li>管理人员每天强迫他们自己先完成他们不喜欢然而必要的任务，再奖励他们自己去处理那些他们喜欢的任务。考虑到奖励的超级威力，这种做法是明智而合理的。此外，这个规矩也可以被用于生活中非商业的部分。</li>
</ul>
</li>
<li>七、哈佛大学商学院对决策树的强调。<ul>
<li>在我年轻而愚蠢的时候，我经常嘲笑哈佛大学商学院。我说：“他们居然在教那些28岁的人如何在生活中应用高中的代数知识？”但后来我变得聪明了，终于明白他们的做法是很重要的，有助于预防某些心理倾向引起的糟糕后果。虽然明白得有点晚，但总比始终不明白好。</li>
</ul>
</li>
<li>八、强生公司所用的类似于尸检的做法。<ul>
<li>在绝大多数公司，如果你进行了并购，而这次并购成为灾难的话，所有造成这次愚蠢并购的人、文件和演说都会很快被忘记。没有人愿意提起这次并购，因为害怕联想到其糟糕的结果。但是强生公司规定每个人都要审视已完成的并购，将预测和结果进行比较。这么做是非常聪明的。</li>
</ul>
</li>
<li>九、查尔斯•达尔文在避免确认偏见方面作出的伟大榜样。<ul>
<li>美国药品管理局（FDA）效仿了达尔文的做法，很明智地要求在开发新药物的研究中必须采用反确认偏见的“双盲试验”（Double Blind）方法。</li>
</ul>
</li>
<li>十、沃伦•巴菲特关于公开竞拍的原则：别去。</li>
</ul>
<h1><span id="综合举例">综合举例：</span></h1><p>政府规定，新型飞机在销售之前，必须通过乘客撤离测试。测试要求满载的乘客在一段很短的时间内撤出机舱。政府的指示是，这种测试应该和现实的情况贴近。所以你撤离的乘客如果是一些只有20岁的运动员，那么肯定是通不过测试的。于是麦道安排在某个阴暗的停机库进行撤离测试，请了许多老年人来扮演乘客。飞机客舱离停机库的水泥地面大概有二十英尺高，而撤离的通道是一些不怎么结实的橡胶滑梯。</p>
<p>第一次测试在早晨进行。有二十个人受了重伤，而且整个撤离过程耗时超过了测试规定的标准。那么麦道接下来怎么办呢？它在当天下午进行第二次测试，这次也失败了，多了二十名严重受伤的人，其中有一个还落得终身瘫痪。</p>
<p>哪些心理倾向对这个可怕的结果作出了贡献呢？把芒格的心理倾向列表作为一张检查清单，将会作出如下的解释。</p>
<ul>
<li>1、激励<ul>
<li>富兰克林的名言：如果你想要说服别人，要诉诸利益，而非诉诸理性。</li>
<li>当一种激励机制能诱发人们获得利益，尤其是金钱利益时，人们常常会过快反应，产生误判。</li>
<li>对麦道公司而言，只要通过了飞机乘客撤离测试，就可以开始销售飞机了。销售飞机带来的收入有多大？所以难怪当事人会出现严重误判。</li>
</ul>
</li>
<li>2、讨厌不确定性<ul>
<li>人类的大脑天生就有一种尽快作出决定，以此消除怀疑及不确定的倾向。背后是进化的结果：在远古时代，当人类面对攻击时，如果需要花太多时间去思考该怎么做，这肯定是不够现实的事情。</li>
<li>而引发该倾向的主要因素有两个：困惑和压力。</li>
<li>对执行测试的人员而言，他们对测试的合理性也许存在疑惑，但是上层可能施与的巨大压力，让他们想排除各种不确定性，并快速做出决定。</li>
</ul>
</li>
<li>3、服从权威<ul>
<li>人类从古至今的等级制度决定了：人生下来就要跟随领袖（一开始是父母，然后是老师，接着是公司领导等），而充当领袖的人是少数。所以，服从权威是人类的一种天性。</li>
<li>政府给的指示是测试应与现实情况贴近，而在“服从权威”倾向的驱使下，麦道公司显然是过度遵守了该指令，采用的测试方法过于危险。</li>
<li>“服从权威”这个心理倾向本质跟“讨厌不确定性”、“简单联想”相关联。</li>
<li>我们在面对权威人士时，通常是会有压力的，由此，我们会不自觉地做出快速的决定，哪怕这个决定在事后清醒思考时会觉得很可笑。</li>
<li>另外，人容易因为喜欢一个人而产生简单联想。权威人士通常会引发我们的崇拜心理，在这种情况下，对于他们发布的指令，我们往往会简单地做出联想：因为他是我崇拜的人，所以他的指令我应该执行，哪怕事实上我更专业。</li>
</ul>
</li>
<li>4、一致性<ul>
<li>人们是讨厌前后不一的，因为这可以节省运算空间，省时省力，这是进化的结果。</li>
<li>当测试方法及行动方案确定下来之后，在避免不一致性倾向的作用下，按计划执行似乎成了一种自然结果。</li>
</ul>
</li>
<li>5、寻找认同<ul>
<li>从人进化的角度而言，“寻求认同”这个倾向是很省能量的，所以保留在人类的基因里也不奇怪。例如，你看到一群人在做着同样一件事，你只要模仿他们，不需要做过多的思考。这毫无疑问可以把复杂的事情简单化。</li>
<li>而在麦道公司进行测试的这个场景里，当麦道的员工看到那些老人走进阴暗的停机库，看到飞机客舱离里面那么高，正常人怎么可能会无动于衷？</li>
<li>可是，他们的心理台词可能是这样：连我的上级其其他同事都没有表示反对，那肯定没有问题的啦。</li>
<li>所以，他们原有的不安情绪被”寻找认同“倾向神奇地消解了。</li>
</ul>
</li>
<li>6、过度重视自己<ul>
<li>人们总是容易过度重视自己，会倾向于认为自己拥有的东西更好，并会偏好跟自己相似的人待在一起。</li>
<li>相关的心理学概念是“禀赋效应”：人们做出决定之后，就会觉得自己的决定很好，甚至比没做出这种决定之前所认为的要好。</li>
<li>或者”确认偏见“：人们会倾向于寻找能支持自己观点的证据，对支持自己观点的信息更关注。</li>
<li>所以不难理解，在早晨的测试失败之后，包括很多人受了重伤，麦道公司依然选择一意孤行，他们屏蔽了那些证明其测试有问题的反面证据。</li>
</ul>
</li>
<li>7、厌恶损失<ul>
<li>这种倾向也叫”被剥夺超级反应倾向“。</li>
<li>你得到1万块的快乐，一般是远远比不过你没了1万块给你的痛苦感觉的。</li>
<li>赌徒很容易倾家荡产的原因是在于：他们在输钱后，在“厌恶损失”的驱使下，会急于想要扳平。而一旦输的越多，这种急躁的情绪会更加明细，直至破产。</li>
<li>麦道公司在这个场景里也很像是赌徒：早晨的测试失败了，我得再赌一次，不然不能如期完成测试会让公司产生巨大损失。</li>
</ul>
</li>
</ul>
<h1><span id="摘录amp金句">摘录&amp;金句：</span></h1><ol>
<li>本章相关金句：</li>
</ol>
<ul>
<li>现实世界的问题不会恰好落在某一个学科的界线之内，它们跨越了界限。</li>
<li>人类的感知和认知系统中那些总体上很有用的倾向往往会出错，如果不对此加以小心提防，就会很容易受到别人故意的操控。</li>
<li>人类的大脑即使在有所知觉的时候，也会错误地估量它感知到的东西，因为大脑只能感知到鲜明的对比，而无法像精密的科学仪器那样以科学的单位来估算感知的变化。</li>
<li>驱动这个世界的不是贪婪，而是妒忌。</li>
<li>虽然明白的有点晚，但总比始终不明白好。</li>
<li>很多事情，自己动手去做。那我就自己来吧。</li>
<li>如果刺激被维持在一定水平之下，人类便察觉不到它的存在。</li>
<li>轻度的压力能够轻微的改善人们的表现，而沉重的压力则会引发彻底失调。</li>
<li>认知往往取决于情景，所以不同的情景通常会引起不同的结论。</li>
<li>如果你想要说服别人，要诉诸利益，而非诉诸理性。</li>
<li>重复有效的行为。即时的回报在改变和延续行为方面远远比延后的回报有效。</li>
<li>奖励超级反应倾向是一种推动人们百分百的去享受好东西的心理倾向。</li>
<li>创造出新习惯的反射行为是由以前得到的奖励直接引起的。</li>
<li>在只有铁锤的人看来，所有问题都特别像钉子。</li>
<li>避免不一致性倾向：为了节省运算空间，人类的大脑会不愿意做出改变。避免不一致性倾向造成的结果之一是，人们在获取新身份的过程中作出的重大牺牲将会提高他们对这种新身份的忠诚度。</li>
<li>化解过激的敌意的标准方法是，人们可以延迟自己的反应。</li>
<li>实事求是地看清现实，可还是去爱。</li>
<li>有意识的养成欢迎坏消息的习惯。</li>
<li>现实太过痛苦，令人无法承受，所以人们会扭曲各种事实，直到他们变得可以承受。</li>
<li>失去造成的伤害比得到带来的快乐多的多。</li>
<li>带着快乐不断的思考和学习，在某种程度上能够延缓不可避免的衰退过程。</li>
<li>你必须讲清楚和人将在何时何地，因何故做何事。</li>
<li>被剥夺超级反应倾向和避免不一致性倾向通常会联合造成一种形式的经营失败。在这种形式的失败中，一个人会耗尽他所有的优质资产，只为徒劳地试图去挽救一个变得很糟糕的投资项目。</li>
<li>人们在感到困惑或者有压力的时候，尤其是在既困惑又有压力的时候，最容易受社会认同倾向影响。</li>
<li>学会如何在其他人犯错的时候别以他们为榜样，因为很少有比这个更值得掌握的技能。</li>
<li>在前后对比度细微的变化误导之下，人们经常无法认识到通往终点的趋势。</li>
<li>不幸的是，重视理由倾向是如此强大，乃至一个人给出的理由哪怕是毫无意义的或者是不准确的，也能使他的命令和要求更容易得到遵从。</li>
</ul>
<ol>
<li>参考：全书金句</li>
</ol>
<p><img data-src="./imageDownloadAddress-20211122174040870.jpeg" alt="img"></p>
<h1><span id="todo">Todo：</span></h1><ul>
<li>定期复盘自己所遇到的事，是属于哪一种或几种误判心理倾向。<ul>
<li>这一种很重要的，如果只是看完不反思，没过多久就忘记了。</li>
</ul>
</li>
<li>把这些倾向列出一张清单，在遇到难以决择的事，可以拿出来进行一一检查。<ul>
<li>久而久之，操练下去，自然就会提高我们的思考力，洞察力。</li>
</ul>
</li>
<li>越开放、越客观的看待事物，越容易看到本质，越不容易被各种外在条件诱惑；</li>
<li>不要只以自我为中心，总认为自己就是对的，做决定前先找足够多的证据来试着推翻自己的结论；</li>
<li>要说服别人，要诉诸利益而非诉诸理性。或者也可以是友谊、情感等。</li>
<li>感恩身边的每一个人，每个人都对我有了一些帮助。</li>
<li>要及时回报，对待员工要及时奖励，这种奖励不一定是金钱上的，只要看见他的付出并加以认可。</li>
<li>在管理上有意识的养成欢迎坏消息的习惯，这样会给员工培养出价值观就是坏消息及时报比藏起来好。</li>
<li>当布置任务的时候一定要讲清楚原因，“你必须讲清楚和人将在何时何地，因何故做何事。”</li>
<li>并且适当的给员工压力，而不要施加过于沉重的压力。</li>
<li>要想得到一样东西，最可靠的方式让你自己配得上它，无论是工作还是配偶。</li>
<li>持续学习，每天睡觉前都比当天早晨聪明一点。</li>
<li>利用跨越科的思维模型并不断对其进行实践，以打破固有的意识形态和“铁锤人倾向。</li>
<li>逆向思维的能力，比如说如果想过的幸福，那就反过来想，去避免那些让生活变得更坏的（懒惰、嫉妒、言而无信)的行为。<ul>
<li>凡事多反过来想，再反过来想。</li>
</ul>
</li>
<li>注重环境的重要性：人、工作、生活等等。</li>
</ul>
<h1><span id="参考">参考：</span></h1><h2><span id="全书大纲">全书大纲</span></h2><p><img data-src="./imageDownloadAddress-20211122174040554.jpeg" alt="img"></p>
<h2><span id="第四章十一讲大纲">第四章十一讲大纲：</span></h2><p><img data-src="./imageDownloadAddress-20211122174040428.jpeg" alt="img"></p>
]]></content>
  </entry>
  <entry>
    <title>人类简史</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E4%BA%BA%E7%B1%BB%E7%AE%80%E5%8F%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="背景">背景</span></h2><p>早就听闻这本奇书，本身是一本历史书，却有多位商业大亨推荐，特写下读后感.</p>
<span id="more"></span>
<h2><span id="介绍">介绍</span></h2><p>《人类简史》的作者是一个以色列年轻的历史学家，人称怪才Yuval Noah Harari。<br>本书讨论范围跨度非常之大，不仅仅是讲述某段感触人心的历史，也不仅仅是罗列历史轨迹，而是从人类如何进化到食物链顶端，讨论到人类社会的构建（社会学），以及部落的形成、城市的形成、帝国的形成，</p>
<p>讨论范围跨度很大，从人类如何进化到食物链顶端，讨论到人类社会的构建，以及帝国的形成、殖民，到现代社会的科学革命。但是易读性超好，比如资本主义的部分，几个例子讲明白如果看经济学需要花费大量时间也未必明白的原理。</p>
<p>有些结论看起来有些沉重，比如人类对整个生态的影响；有些内容没有结论，比如为什么是父权社会。笔者更关注其中规律性的内容，下面摘要自动忽略了一些自己不太关注的内容。</p>
<p>最印象深刻的几个结论：</p>
<p>现代人脑容量不如采集社会的祖先脑容量大<br>人类跃居食物链顶端的原因是因为合作，可以合作的原因是因为人类的语言，有“虚构”功能。人类的贸易网络就是建立在国家、货币这些虚拟概念上的。<br>靠八卦能维持的社会单位时150人，再往上就需要故事，无论是宗教故事，民族主义还是公司愿景。<br>采集时代已经形成最初的富裕社会，农业革命和定居的推动力可能是一些宗教需要和气候变化。<br>蜂群的分工信息是靠DNA存储，而人类的分工信息靠大脑存储，大脑会随个体死亡而死亡，DNA不会，因此造成人类社群的不稳定。<br>非洲人基因上的先天优势却造成其在社会分工上的劣势，社会变迁往往是由偶然因素造成，然后不断强化。<br>经济泡沫依赖于实验室速度，一旦不同步就趋于破裂。<br>公司化、证券交易所都是欧洲殖民时期的产物，公司比国家名义更容易筹款。<br>全球化令和平比战争利润更高。<br>佛教所崇尚的内心平静与现代生物学殊途同归。<br>第一部分 认知革命<br>大约135亿年前，宇宙物质、能量、时间、空间有了现在的样子，形成物理学。</p>
<p>大约38亿年前，分子结合起来，形成精细结构——有机体，成就生物学。</p>
<p>大约250万年前，类人生物出现。大约200万年前，整个世界存在不同人种，包括东非的鲁道夫人，东亚的直立人，欧洲和西亚的尼安特人，但知道大约1万年前，只剩下智人这一种。 大约7万年前，“智人”开始创造更复杂的结构，形成“文化”，文化继续发展，形成历史学。在历史的路上有三大革命——7万年前的“认知革命”，大约1.2万年前的“农业革命”，大约500年前的“科学革命”。</p>
<p>60公斤哺乳动物的平均脑容量是200立方厘米，而250万年前的最初人类，脑容量600立方厘米，现代智人的平均脑容量是1200-1400立方厘米。但为什么没有进化出会微积分的猫？面对生存，大脑也是负担之一，占体积的2-3%，但却消耗25%的能量。所以代价就是肌肉萎缩，以及花更多时间寻找食物，如同国防经费拨给教育，人类也把工二头肌的能量拨给神经元。</p>
<p>直立行走后可以扫视草原，手解放出来可以传递信号，人就此越来越着重神经发展，且不断对手掌和手指的肌肉做修正，逐渐人类可以使用复杂工具。变大的大脑为颈椎带来负担，成为人类的苦恼。对于女性来说，直立行走使产道宽度受限制且婴儿头部逐渐变大，于是进化出了更短的生产周期以降低生育风险，相对生下来就会跑的小马，人类都是早产儿。为了获得食物养育孩子，需要全部落的努力，人类进化出突出的社交技巧，同时由于脱离子宫时进化不完全，有更强的可塑性，可以用教育和社会化方式改变。</p>
<p>大约100万年前，人类虽然有大容量脑和石器，但仍然在食物链的中间位置，很少猎杀大型动物，靠采集植物、挖找昆虫，以及吃大型动物吃剩的腐肉维生。早起石器主要用途就是另人类在大型动物用餐完毕，走进所剩无几的猎物尸体，敲开骨头吃唯一还能吃的骨髓维生。直到40万年前，几种人种才开始追捕大型动物，直到10万年前智人崛起，人类跃居食物链顶端，这对了解人类历史和心理至关重要。历史上食物链顶端的狮子、鲨鱼都经过数百万年演化，人类转眼就登上顶端，让整个生态猝不及防，很多生态灾难都是源于这场过于仓促的历史跳跃。</p>
<p>站上食物链顶端的路上，使用火是重要一步，大约30万年前人类可以熟练使用火。火可以改变化学结构另原本无法吸收的成分得到吸收，同时发生生物变化，杀死病菌寄生虫。同时拒绝时间也大大减少。黑猩猩每天5小时咀嚼生肉，人类一小时足够。这扩大了人类可摄取的食物种类，缩小牙齿，减少肠的长度，降低了倡导消耗，给大脑供能量铺平道路。</p>
<p>虽然熟练使用火，吓走狮子，烹调食物，寒冬取暖，但是15万年前人类仍在食物链中间位置，人口数百万，对生态来说微不足道。大约7万年前，智人开始迁徙到中东，东亚，每到达一个地点，当地原生人类族群久很快会灭绝。尼安特人大约3万年前退出历史舞台，其他人种也先后退出，只留下了一些DNA在我们身体里，留下智人成为人类最后的物种。征服世界的原因，很可能是因为独特的语言。</p>
<p>大约7万年到3万年前之间，智人发明了船、油灯、弓箭，针，以及第一个可以称为艺术品的雕塑，还有宗教、商业和社会分层。动物也有自己语言，人类语言的特别之处在于灵活性。有限声音组合无限多句子，储存和沟通惊人的信息量。大约7万年前，智人的语言体系可以让他们八卦数小时，在一个大约50人的部落中，了解谁更可靠谁不可信，称为发展出更紧密、更复杂合作形式的基础。</p>
<p>人类语言的独特之处，在于可以虚构。人类和动物都可以传递fact如“河边有只狮子”。在认知革命以后，传说、深化、宗教出现，因为人可以说“狮子是我们部落的守护神”。讨论虚构事务正是智人语言最独特的功能。虚构，让人类能够拥有想象，最重要时可以一起想象，共同编制出故事。智人的合作不仅灵活，还可以和无数陌生人合作，正因如此，智人才统治世界。</p>
<p>社会学研究表明，靠八卦能维持的团体大约是150人，超过后成员无法了解团体其他成员的生活情形。今天人类团体仍然受到这个神奇数字影像。社群、公司、社会网络、军事单位30人一个排，100人一个连，都不需要正视阶层就可以正常运作。一个小的家族企业，没有董事会也可以经营的有声有色。但是越过150人门槛，创造出城市、国家，秘密可能就在于虚构的故事。</p>
<p>教会的根基就是宗教故事，两个天主教信徒，从未谋面但是可以一起参加十字军东征，或者一起筹措资金盖医院。司法制度，也是基于法律的故事。原始人相信鬼神月圆之夜起舞，巩固了他们的社会秩序。现代社会，商人和律师就是巫师，设定规则建造社群，护着共同相信法律正义和人权从而为一位陌生人辩护。</p>
<p>公司就是一个集体想象。在“有限公司“出现之前，创业需要思考再三。这个概念出现之后，公司是独立个体，不等于设立者、投资者和管理者，从而规避了风险。人类现在已经有奇迹复杂的故事网络，即使虚构，只要人人都相信，力量就足以影响世界。如果没人相信，就是谎话。自认知革命以来，智人就一直生活在双重现实之中，一方面是客观的树木河流，另一方面是神、国家、企业。</p>
<p>行为在相当程度上取决于基因，但是还取决于环境和个体的特殊之处。在远古，改变社会和生态结构都是依赖基因突变，但是认知革命之后，人类的基因和环境都没有巨大改变，但智人还是可以迅速改变行为，并且将行为方式传递给下一代。人类社会出现了不生育的社会精英阶层，如天主教神父、佛教高僧、太监等，这直接抵触了自然选择的最大原则。而欣慰传递依靠的不是生育，而是圣经故事。远古人类行为及万年不变，但现代只要十几二十年就可能改变整个社会结构、人际交往和经济环境。</p>
<p>所有动物里只有智人存在贸易网络，之所以存在是因为人类相信美元、联邦储备银行、企业商标这些虚拟事务。智人打败尼安特人，一定程度上也是因为这种合作机构可以构建出500人的网络攻击尼安特人不超过50人的社会网络。为什么现在我们有洲际导弹但是3万年前只有长矛？原因也在于合作网络，导弹需要从矿工到物理学家的上百万人合作完成，而人类生理上制作工具能力没有显着提升。</p>
<p>要了解人类天性、历史和心理，需要了解狩猎祖先的头脑，他们的很多思维方式、饮食习惯、冲突、性欲至今仍在影响我们。远古采集者，如果遇到高热量甜食为了生存最优选择是一直吃吃到吃不下为止，到今天物质盈余，人类仍然无法戒掉高能量饮食，导致普遍的肥胖问题。有些演化心理学家认为，远古部落没有一夫一妻制，没有父亲概念（直到现代胚胎学发展才找到证据证明一个孩子只有一个父亲，远古则认为是一群精子与卵子结合形成婴儿），因此一群人共同抚养部落小孩，“远古公社”支持者认为，离婚率居高不下以及大人小孩都面对心理问题，尤其工业化之后人类拥有超级城市、飞机、计算机但是却感觉到疏离。都因为一夫一妻制，脱离社群不符合生物本能。</p>
<p>到农业革命前夕，地球上有500-800万人类狩猎采集者，几千个独立部落，形成不同语言和文化，这也是认知革命的重要成就。智人采集的不止是食物，还有知识。为了生存，智人需要对栖息地了如指掌，植物生长模式，动物生活习性，在采集时代智人需要有超高心智方得以生存，然而农业革命以来人类脑容量在不断下降，分工使现代人只擅长一个小领域，低等分工的人只要能生存就可以传承一个平庸的基因。</p>
<p>采集社会大概每三天打猎一次，每次3-6小时就足以养活部落，比现代人工作时间短。同时采集时代比农业时代的人更没有营养不良等问题，主要缘于其杂食习性，如果不考虑儿童夭折情况，以及意外事件，多数人自然寿命可以活到60岁甚至80岁，然而农民大多依靠单一作物作为热量来源。同时远古采集者较少遇到传染病问题，传染病主要来自于家禽，农业革命之后才传递到人类身上。这是最初的“富裕社会”，但是也会遇到各种致命意外，人类关系虽然亲密但是也会残忍杀害老弱以维持部落实力。因此战争也并不是农业社会出现私有财产之后的产物，采集社会就有。</p>
<p>然而智人所到之处，都有大量的物种灭绝。智人的殖民是整个动物界最大也最快的一场生态灾难。第一波是采集者的扩张，第二波是农民扩张，第三波就是现在工业活动造成的灭绝。 远古采集者多数是泛神论，即天地万物皆有灵，人类可以通过语言、舞蹈与他们沟通。采集社会对现代人影响深远，但我们又知之甚少。</p>
<p>第二部分 农业革命<br>公元前9500-8500人类由采集转向农耕，发源于土耳其东南部、伊朗西部等地。此后的几千年农业社会，人类持续驯化各种农作物和动物。到今天人类90%热量来源还是9000年前人类驯化的农作物－小麦、大米、玉米、马铃薯、大麦。至今人类仍有采集者之心，和古农民之胃。</p>
<p>公元前9000-小麦、山羊<br>公元前8000-豌豆、扁豆<br>公元前5000-橄榄树<br>公元前4000-马<br>公元前3500-葡萄<br>到公元前3500，驯化热潮结束。过去2000年，人类并没有驯化新的主要作物。比如家禽，驯化方法就是每一代都挑选出具有侵略性和不听话的先杀掉，经过几代就得到了驯化的家禽。 为什么农业革命发生在中东、中国和中美洲等地？因为农作物很难被驯化，因此农业革命发生在特定几种适合大面积种植的农作物适合生长的地方。</p>
<p>采集者基本已经达到温饱，是什么动力推动了农业？农民的劳作时间更长、更少自由被固定在农田旁边生活；农业更加不适应当时智人的身体，人类进入农业时代后，产生大量疾病，腰间盘突出、关节炎等都是因为人类身体更适合攀爬与奔跑而不是弯腰劳作和挑水。</p>
<p>从小麦角度看，更像是小麦驯化了人类。小麦是历史上最成功的植物，1万年前小麦只是世界上众多野草中的一种，生长在中东，短短1000年中小麦就遍布全世界。</p>
<p>农业革命是历经数百年的缓慢进程。如果说是人口推动，事实上人类有哺乳动物的数量调整自然机制，营养充足则女性较早进入青春期，怀孕成功率也较高；营养贫瘠时相反。这期间人类偶尔食用小麦。大约18000年前，最后一个冰河时代结束，中东气候非常适宜小麦生长，人们生活在这里采集的时间越来越长，于是定居在这里。</p>
<p>从英国巨石阵和哥贝克力石阵来看，采集者可能并不是为了增加日常食物供应，而是为了支持某种神庙的建造才从采集转向种植。传统认为人们先有村落才有信仰中心，事实可能相反。</p>
<p>进入农业社会后，定居称为人类常态，只有少数游牧民族。定居使人类产生了改造环境的欲望，人工岛屿适合人类却不再适合其他动物生存，人类会防止各类野生动植物入侵，无法赶走就消灭比如灭蟑、灭蝇等。农业时代，一个农民家庭拥有的物品总量远远超过采集时代一整个部落的物品总量。</p>
<p>采集时代有一天过一天，农业时代需要规划，因此“未来”的重要性被拉到历史新高。迁徙可以逃避恶劣环境，定居却不能，因此农民勤劳不懈希望保障自己未来的安全，这种压力也是后代大规模政治和社会制度的基础。</p>
<p>依靠农民生产出来的食物，加上新的运输技术，越来越多的人聚集在一个地区，形成村落、城镇和都市，再由王国和商业网络将他们相连。也正是这些多余的粮食，养活了整治、战争、艺术和哲学。</p>
<p>然而人类几百万年演化过程中，一只是几十人小部落。农业革命后，短短几千年就出现了城市、王国和帝国，这些时间不足以让人类发展出能够大规模合作的本能。能够养活一个城镇不代表能够让大家都同意如何划分领土和水资源以及解决他们争端。革命多半不是因为粮食短缺，古罗马公元前一世纪达到权利高峰，正在这个最富庶的时刻政治秩序甭哭哦。</p>
<p>公元前8500-几百人村落<br>公元前7000-土耳其加泰土丘城镇5000-10000人<br>公元前5-4世纪－fertile crescent 几万人城市，也管理附近小村<br>公元前3100- 下尼罗河谷统一，形成世上第一个埃及王朝，法老王掌握数十万人民<br>公元前2250- sargon the great建立起第一个阿卡德帝国，超100万子民，常备军5000人<br>公元前1000-公元前500-中东亚述帝国、巴比伦、波斯帝国，人口数百万<br>公元前221年－秦始皇统一东亚地区，常备军10万人，朝廷10万官员<br>公元1年－古罗马统一地中海地区，纳税人达1亿，常备军25-50万人<br>庞大网络如何支撑？公元前1776年《汉谟拉法典》，几十万巴比伦人的合作手册；巴比伦是当时最大的城市，子民超过100万，法典汇集当时的法律和判例，把汉谟拉国王塑造成正义国王榜样，法典的开头是汉谟拉的神职任命。这里将人类分成男女两种性别，上等人平民奴隶三种阶级，不同性别和阶级如果被杀索赔金额都不同。这里做了严格的阶级规定，并架设只要国王的臣民都接受个字的角色，整个帝国的上百万人就可以有效合作，为所有成员生产足够粮食，并可以抵御外敌。</p>
<p>公元1776年美国《独立宣言》是现代数亿美国人合作手册，它宣告自己是普遍和永恒的争议，所有殖民地民众不再是英国王室的子民，“人人生而平等，造物者赋予他们若干不可剥夺的权利，其中包括生命权、自由权和追求幸福的权利”。对比二者，无论平等还是阶级，都是想象出的四海皆准永恒不变的正义原则，而这些原则，从来就没有客观正确性。</p>
<p>如果用演化学角度审视《独立宣言》，演化的基础是差异而不是平等。自然界秩序相对稳定，比如重力不会一夜之间消失。但是人类靠想象建造的秩序总面对一夕崩溃的风险。因此需要人真正去相信才能持久，包括基督教徒相信教义、中国相信仁义礼智信令帝国持续两千年，美国相信人权否则不会持续250年，投资人和银行家相信资本主义。</p>
<p>如何建造秩序？首先要坚持这是客观事实，比如是神的旨意或者是自然规律；第二教育上从人出生就不断提醒他，葱童话、戏剧、歌曲到政治宣传、建筑、食谱。比如相信个人主义，小朋友在家会有自己房间，令秩序融入建筑；这种秩序也创造了我们的渴望，比如想要可乐而不是水；这种秩序存在于人和人之间的思想连接，比如美元货币体系，如果想要改变秩序，就需要思潮活着政党或宗教运动推动。</p>
<p>大型社会比如蜂群，社群稳定时基于它们的基因组储存了合作所需的大部分信息，DNA设定行为模式；然而人类使用大脑来储存信息，但是大脑会随人类死亡而死亡，因此早期信息多数在一个世纪内就消失。因此人类社会更加动态和复杂，农业革命前生存压力令人类大脑适合储存关于动植物、地形和社会信息，农业革命后，公元前大约3500年苏美尔人发明了数字和文字，来存储信息。至今人类大脑仍然可以高效检索信息。</p>
<p>公元前3000 苏美尔楔形文字加入符号，实现完整表意<br>公元前2500 国王可以使用楔形文字颁布法令、祭祀使用它记录神谕，平民可以写信<br>同期古埃及象形文字也诞生<br>公元前1200 中国甲骨文诞生<br>公元前1000-500中美洲发展出完整表意文字<br>此后几个世纪，官僚制度需要更高效的数据处理方式。公元9世纪印度人发明0-9数字，阿拉伯人工大印度发现并传播到全世界。</p>
<p>农业革命过后，人类创造出了秩序、文字等来弥补我们基因中的不足，称为大规模合作的基础。复杂的人类社会，似乎需要阶级和歧视来稳定社会结构，目前尚无一个大型人类社会真正完全免除歧视。阶级在令某些人高人一等，从而规范数百万人关系，无论是印度的种姓、美国的种族、土耳其的宗教。</p>
<p>印度种姓制度形成于大约公元前1000年，印度雅利安人入侵印度，征服土着。入侵者建立等级森严的社会，印度通过“洁净”与“不洁”来放置不同种姓的成员接触，方便管理。至今印度已经有3000种jati也就是出身，它深入人心决定了职业、饮食和住处，民主政府试图打破种姓区别但影响仍然难以消除。</p>
<p>现代美洲也是在16-18世纪由欧洲征服，欧洲人引进数百万非洲奴隶开矿和种地，除了非洲与美洲位置接近的地理原因，非洲有成熟奴隶贸易的社会原因，还有最重要的一点基因原因，美洲殖民农庄位于verginia巴西海地等疟疾肆虐的地区，欧洲人容易致死但非洲人早已经免疫，非洲人基因上的优势竟然造成了社会上的劣势。一定程度上属于历史偶发事件，但是为了体现公平正义，社会开始宣传种族差异，并很不公平的把黑人当作污染的来源，后来形成了jim crow laws黑人歧视法剥夺了投票权，不准就读白人学校等，进行种族隔离。因而又形成黑人学历较低，犯罪率远高于白人的事实。历史自为因果，形成不断自我强化的恶性循环。</p>
<p>各种政治制度也接近，并没有逻辑学和生物学基础，而是偶然事件引起，再不断强化和自我壮大。</p>
<p>农业革命以来，大多数人类社会都属于重男轻女的父权社会，一方面男人力气更大适合体力劳动，但是统治者往往社交技巧杰出而不是肌肉发达，所以结论不完全成立；第二种认为男性比女性更具侵略性，男性掌握军队，发动战争从而掌握社会，这也解释了为何战争无处不在。但是统帅往往不一定是好战的士兵而是运筹帷幄的军校生，结论也不完全成立；第三种从生物学讲，男性需要彼此竞争才能得到最优秀女性受孕机会，长期进化出最具野心、最积极、最好胜男性。女性照顾子女需要许多人协助分担，长期进化出最顺从、最愿意接受照顾的女性。</p>
<p>生物界雌性需要外部协助从而有更好的社交技巧，于是建立起协助彼此养育后代的母系社会。至今尚无最具说服力的父权社会解释，但是20世纪性别角色发生了翻天覆地变化，情况正在改变。</p>
<p>第三部分 人类的融合统一<br>人类文化常矛盾统一，中世纪欧洲的骑士精神和基督教，前者倡导奢侈精致追求荣誉，后者倡导远离虚荣一切皆空，于是在矛盾中引发十字军东征，对于这些骑士，东征能体现武力的长才，也能体现对宗教的虔诚。</p>
<p>现代的平等与自由也同样不可兼得，绝对平等必然限制自由可以参考公社时代，自由则也可能导致阶级分化不一定会走向平等。但是人类文化的矛盾，常常是文化创意的引擎。不同的概念和想法，引发思考、反思。想要看清历史的大方向，就需要看清不同时期地球上究竟有多少种共存的文化。</p>
<p>公元前10000年，地球上存在上千种人类文明。<br>公元前2000年，存在2000多种。<br>公园1450年，即将进入欧洲探险时代。<br>地球上9成居民紧密相连，都在亚非。另外一成在中美北美、安第斯南美、澳大利亚大陆、夏威夷到新西兰的大洋洲岛屿地区四个部分。</p>
<p>1532西班牙征服aztec进入南美；<br>1606欧洲人登上澳大利亚大陆；<br>1788英国殖民开始。<br>亚非花了几百年慢慢消化它吞下的其余世界，另今天几乎所有人类接受一套地缘政治体系（国际公认的国家边界）；同样的经济制度（大部分是资本主义）一样的法律和科学体系。</p>
<p>智人在演化中学会了“我们”和“他们”，学会与陌生人合作，并且在意整个种群的利益，这个在其他动物社会看不到。公元前1000年，发展出“世界一家”的观念，商人、征服者和各教先知最早跳出我们和他们的二元区分，他们想要建立全球适用的经济秩序、权力体系以及全球都信奉的真理。</p>
<p>货币<br>采集社会完全没有货币概念。</p>
<p>农业革命开始，村庄依靠互通人情以及一点点对外的以物易物交易。直到城市与王国兴起，各地土壤与气候不同，某些村庄以他们的美酒、橄榄油或者陶器闻名；同时人口稠密城市开始有服务业，养活鞋匠、医生、木匠、战士、律师等专业非农民或手工业工作者。随着专业化深入，如何交易策划功能为问题。比如鞋匠需要把修鞋服务用不同人的上百种商品分别定价，一次服务对应多少苹果、小麦、大米非常困扰，而且防火防水防贼都是问题，搬迁也成为问题。因此就有了各种贝壳、盐、布料、欠条作为交易媒介。这种媒介支持了一地到另一地的复杂商业网络以及蓬勃的市场经济。</p>
<p>从最初的宗教建立信任，到货币体系的建立称为最大的人类互信系统，人类的每次进步都是基于信任，或者“相信”，所谓价值观一致，就是都相信目前的体系规则。</p>
<p>公元前3000 苏美尔人 麦元<br>公元前2500 美索不达米亚－银社客勒<br>公元前640 土耳其 世界上第一批硬币<br>公元1世纪 古罗马硬币当时广受信任，成为当时的世界货币<br>吕底亚硬币系统从地中海传到印度洋，中国独特的使用铜钱和金银元宝，穆斯林和欧洲征服者将二者都传到地球上每个角落，现在地球上都有单一金钱货币区，早年的黄金白银，现在的美元英镑。分属不同文化的人，有不同的语言、法律、文化，金钱虽然尝尝被不屑，但却是人类历史上最能够被全人类接受的东西，跨越几乎所有的文化鸿沟。</p>
<p>帝国<br>帝国政治秩序有两种特征，1，统治多民族和文化，二三十个；2不需要改变基本架构和认同就可以纳入更多国家和领土，就好像1世纪前的大英帝国。即文化多元性和疆界灵活性两点，而起源、政府形式领土范围和人口规模并不重要。</p>
<p>雅典起源于自由联盟，通知超过100个曾经独立的城邦；aztec税收记录了371个不同民族和部落。当年世界上的民族数量比现在多得多，每个民族人数更少领地更小。然而帝国恰巧是民族多样性减少的原因之一，今天的希腊和墨西哥就不再符合帝国定义。</p>
<p>帝国循环通畅包括，一小群人建立一个大帝国，形成帝国文化、帝国文化得到属地居民认同、居民以共同帝国价值为名要求平等地位、帝国开国者失去主导地位，帝国文化继续蓬勃发展发扬光大。观察古罗马、伊斯兰和欧洲都有相似进程。</p>
<p>古罗马——古罗马人建立帝国，形成希腊－古罗马文化，庶民接受拉丁文、古罗马法、古罗马政治思想；伊利丽亚人、高卢人等以古罗马价值观要求平等地位，古罗马人不再是至高无上的族群，帝国控制权转移到多民族精英手中；伊利丽亚人、高卢人等继续发扬他们已经接受的古罗马文化。</p>
<p>伊斯兰——阿拉伯人建立阿拉伯哈利发王朝，形成阿拉伯穆斯林文化；庶民接受阿拉伯语、伊斯兰教；埃及人、伊朗人等以穆斯林价值观要求与阿拉伯人平等；阿拉伯人失去穆斯林世界控制权，形成多民族的穆斯林精英族群；埃及人、伊朗人等继续发扬穆斯林文化。</p>
<p>欧洲——欧洲人建立欧洲帝国、形成西方文化；庶民接受英语、法语、社会主义、民族主义、人权等；印度人、中国人、非洲人以西方价值观，要求与欧洲人同等地位；欧洲失去对全球控制，形成多民族精英族群；印度人、中国人、非洲人继续发扬他们已经信奉的西方文化。</p>
<p>到公元前200年，大多数人已经生活在各个帝国之中。现在冰冠融化、臭氧层破洞等问题，都不是单一国家可以解决。未来的全球帝国，可能正是环保当道。目前正在形成的全球帝国，并不受任何特定国家活着族群关系啊，越来越由多民族共同治理。</p>
<p>宗教<br>泛神论体系，人类规范价值观出了自己，还必须考虑其他动物、植物、精灵、鬼魂的利益，采集社会毕生活动范围不会超过1000平方公里，所以也没有传教的必要。</p>
<p>农业革命以来，宗教革命随之而来。平等的众生，在农业革命最初，就变成了人类的所有物，财产。农业革命的宗教意义就在于这里。</p>
<p>很多古代神话就是一种法律契约，人类崇拜神灵，换取人类对动植物的控制；祭天仪式就是大概这个目的。随着农业革命后期贸易网络开始扩张，local的神很难覆盖整个王国，因此多神教应运而生，它认为一群神灵分别掌管生育、雨水、战争。对于泛神论者，人类只是众多生物钟的一种；对于多神论者，这反映了人与神的关系，人类能决定整个生态系统的命运。它提高了神的地位，也提高了人的地位。</p>
<p>公元前1350第一个一神论教出现在埃及，虽然此后多神教不断演化出一神论宗教，但四知道基督教才有了重大突破，从一个小的犹太教分支到全世界。最早的教派领导者是保罗，他认为耶稣化身世人为拯救人民而被钉上十字架的事迹（福音）应该被全世界知道，于是开始传教。通常一神论教徒会更狂热的传教。公元500年，基督教已经征服全球最大的罗马帝国。</p>
<p>同时多神论也促成一些二元论宗教，他们相信“恶”独立存在，不归代表“善”的神掌管。它的魅力在于帮人们理解这个世界上的苦难。这种宗教兴盛于公元前1500-1000之间。以上宗教一个共同特征就是相信的都是神灵活着其他超自然对象，然而公元前1000年亚非大陆出现新型宗教，比如印度的jainism和佛教，中国的乳胶到脚，地中海的犬儒主义和享乐主义，这些都崇拜的不是神抵。</p>
<p>而最最成功的现代宗教，就是资本主义。</p>
<p>历史<br>我们无法解释历史作出的选择，但可以肯定：历史的选择绝对不是为了人类的利益。对人类不利的文化不一定会停止扩张。迷因学认为，文化就想寄生虫，而人类是宿主，不知不觉中改变，甚至丧命。人类复制机遇基因，文化基于迷因（meme）</p>
<p>大约公园1500年，历史作出最终大选择，改变了地球上所有生命的命运，科学革命发生了。</p>
<p>第四部分 科学革命<br>过去500年，人类力量前所未有的增长，公元1500年人口大约5亿，现在全球人口70亿。</p>
<p>现代科学体系与先前知识体系最大区别就是：</p>
<p>此前知识体系都基于无所不知，而现代科学承认自己无知；<br>以观察和数学为中心；<br>运用理论取得系能力发展出新的科技。<br>比如伊斯兰教、基督教、佛教、儒教都假设世上所有事情都为人活着为神所知，因此学习就是学习《圣经》《古兰经》等，遇到困惑去请教牧师就应该获得答案，如果知识体系内没人知道代表这件事不重要，比如蜘蛛是如何结网的，圣经中没有答案。而现代科学承认无知，就比此前的知识体系更有求知欲。但社会缺少一直信仰如何保持稳定？那就是类似宗教信仰一般的相信科技和科学研究方法：收集实证观察（感官感受）并用数学工具整理。</p>
<p>1744年两位苏格兰长老会教士打算成立一个寿险基金为神职人员的遗孀和孤儿提供补助，他们分析了几千份死亡记录计算了不同年龄段过世的概率，有遗孀和有孤儿的概率，他们计算到1765年基金会有58348英镑，而到那一年实际有58347英镑，精确到不可思议，这些概率计算后来成了精算学的基础，也成了人口统计学的重要概念。</p>
<p>中世纪的欧洲，教学核心是逻辑、愈发、修辞，数学通常就是简单的算术和几何学，但是到了今天，修辞变成文学一部分，逻辑变成哲学一部分，神学乏人问津，但是数学称为各个学科的基础。</p>
<p>公元1500年，科学和科技是两个不同领域，到19世纪才真正接轨。到二次世界大战，科学的重要性一日千里。1944年德国节节败退，顽强抵抗的一线希望就是相信德国科学家能研发出新武器来利往狂澜。然而与此同时，美国曼哈顿计划完成，1945年原子弹制造完成。如果美国决定入侵日本则需要百万军队丧命战争将拖延到1946年结束，于是杜鲁门决定使用原子弹，日本无条件投降，战争就此结束。</p>
<p>19世纪以前，军事主要变革都是在组织而不是科技，比如古罗马军队并无先进武器，但是组织有效率，还有铁一般的纪律。中国道士很早就在炼丹时发明了火药，但是没有哪个王朝意识到去使用火药发明武器，而是发明了鞭炮。情况一直到18世纪才有王朝意识到需要投入资金做武器研发。一直到资本主义、工业革命登场，科学、产业和军事科技才开始水乳交融。</p>
<p>在科学革命之前，很多文化都不相信人类还会再进步，需要恪守祖宗智慧。直到现代文化产生，比如18世纪，许多文化中还认为闪电时神怒象征，但富兰克林验证了闪电只是一到电波并发明了避雷针。而18世纪欧洲能征服世界，很大程度也是得益于科技进步。而科技进步又依赖亿万的投入。</p>
<p>人类在公平交换的困境中走了千年，直到近代，基于对未来的信任，才发展出了“信用”这种金钱概念。于是1776年亚当斯密出版了《国富论》第八章创新论述：如果地主、鞋匠赚得的利润高于养家糊口所需，就会雇佣更多助手进一步提高自己利润。利润越高雇佣越多。民间企业获利时社会整体繁荣基础。</p>
<p>这是人类历史上最革命性的概念之一，意思是，“利己”和“利他”不矛盾，经济应该是一种双赢局面。当然，基础是利润用来建设新工厂，雇佣更多人，而不是把利润浪费在没有生产力的活动上。因此现代资本主义的重点在于一种新的道德标准：利润应该拿出来再生产，扩建、研发等均可，目的就是增加产量，转化更多利润和雇佣。资本即因此而来，资本是用来投入生产的各种金钱，而财富指埋在地下不投入生产的金钱。</p>
<p>因此科学就在这种理念下变化，投入之前会先问这项研究会提高产量和利润，以及促进经历成长吗？资本主义架设经济可以无穷尽成长，类似狼群认为羊群会无限扩张，本身与常识相悖。但现代经济指数级成长，就依赖于科学家每隔几年有一项新发明，比如引擎、基因工程。银行和政府印钞票，然后盼望科学家在经济泡沫破灭之前，创造出新的产业带来庞大利润。如果实验室脚步不敌泡沫破灭速度，经济前景堪忧。</p>
<p>荷兰成功脱离西班牙独立，还成为全球海上霸主，成功秘诀就在于信贷。第一，他们坚持准时、全额还款，降低借款人风险。其次，荷兰司法独立，保护特人权利特别是私有财产权。相比之下独裁国家不保护私有财产，资本就逐渐离开流向保护私产的国家。当时的银行家如果分别在马德里和阿姆斯特丹开立分行，借钱给西班牙国王和荷兰商人，如果不愿意还钱，西班牙法院会推测上意，免遭雷霆之怒，而阿姆斯特丹法院独立，可以直接判你胜诉。</p>
<p>西班牙国王不还钱的同时，还叛你有叛国罪，要求交钱赎人，于是银行家意识到这是抢钱，需要到真正法制的国家经营。西班牙逐渐失去信任，而荷兰逐渐赢得信心。西班牙出征采用不断加征税收方法，而荷兰采用出售公司股份方法，于是欧洲各大主要城市都设立了证券交易所，进行股票交易。荷兰东印度公司就用这种方法筹集资金，不断攻下各个提高关税的政权，并且与竞争对手开展，带回当地的货物贩卖，就这样攻下一个一个岛屿。</p>
<p>同时西印度公司为掌握哈德逊河，建立了一个新殖民地阿姆斯特丹，1664年落入英国人手中改名新约克new yor，因为york为英国一个郡，即现在纽约，当时为了抵御英美人，西印度公司筑起一道墙，即今天的wallstreet。</p>
<p>17世纪末，荷兰人自满一集战争成本高昂，英法成了最有力竞争对手。1717年法国成立密西西比公司，在美洲殖民，新奥尔良在此时开始成型。当时这里只有沼泽和鳄鱼，但密西西比公司谎称这里金银遍地，股价一飞冲天，两年内涨幅200倍，全民购买股票致富。直到1719年末，某些得利者开始抛售，因此恐慌，股价雪崩。为了维持稳定，法国央行决定买进，但耗尽了央行资金，于是只能印钞票，因此法国金融体系成了一个巨大泡沫。这也是当时法国海外领土主见落入英国手中主因之一，此后法国国王越借越多，债台高筑，1789看法国大革命揭开序幕。</p>
<p>与此同时，大英帝国类似此前荷兰帝国，由民间股份公司在海外建立殖民地，这些公司也都在交易所上市，首次打下印度大陆的，也不是英国官方，而是英国东印度公司。直到1858年，英国王室才将印度以及用过东印度公司的佣兵收归国有。资本主义和帝国的关系从未结束。</p>
<p>1840年英国东印度公司靠向中国出口鸦片发了大财，30年代后中国政府发布禁烟令，但英国以自由贸易为名向中国宣战，然而当时中国太自信，完全敌不过英国新武器，此后战败签订赔款条约，并且割香港给英国从事安全贩毒。在19世纪末，中国鸦片成瘾者大约4000万，全国人口的10%。</p>
<p>资本与政治对信贷市场影响深远。一个市场得到多少信贷，除了资源更多事信用，比如政权更迭，或者是外交政策。</p>
<p>工业革命的核心，就是能源转换的革命。此前人类能源依赖植物，但是此后认为能源取之不尽只是知识不够，比如太阳能。过去200年，工业化生产成了农业支柱，动植物都被机械化，家禽的生物属性都被剥夺。然而正是以为如此，才释放了更多的人力，制造钢铁、建筑、以及各类产品。人类有史以来第一次，生产超过需求。但是谁来买单？</p>
<p>因此为了避免无人买单局面，新的伦理观出现，消费主义。消费主义鼓励善待和宠爱自己，抛弃节俭。而后果就是过去农业社会的饥荒，被现在肥胖所取代。资本和消费主义就像硬币的正反面，有钱人投资，其他人购买。</p>
<p>今天地球上居住70亿智人，工业革命以来人口成长处于前所未有的高峰。但与此同时带来的是其他物种的减少，以及自然栖息地的入侵。工业革命为人类带来了时刻表和生产线的概念，工厂采用后，其他地方也采用。1830年英国第一条商业铁路启用，10年后首次公布火车时刻表。1880年，英国政府迈出前所未有一步，立法规定英国时刻表以格林尼治时间为准。现代人每天都会看几十次时间。</p>
<p>工业革命之前日常生活的核心是核心家庭、大家庭、当地社群。家庭负责照顾生病的人，以及赡养老人。而工业革命带来了国家和市场，将很多家庭和社群功能由国家取代。这个过程，就是解放个人的过程，代价就是很多人悲叹家庭和社群功能不在，社群和家庭只留下了情感功能。</p>
<p>我们这个年代歧视比起过去更加和平，虽然还是有战争，但是战争的死亡人数已经远远低于过去。而现在因为车祸、自杀死亡人数比战争牺牲更大。</p>
<p>1945年英国还统治地球面积25%但30年后就只剩下几个小岛，1989年苏联解体，帝国退出后而独立的国家，对战事兴趣都不大。有了核武器之后，超级大国如果开战，等于集体自杀，武力征服全球成了不可能的任务，因此战争成本飙升，利润下降。过去的财富就是天地、牛、奴隶、黄金，而今天变成了人力资本、知识，以及银行这种复杂的社会结构，想要抢夺和占领都十分困难。比如加州，也从淘金地变成了硅谷和好莱坞闻名。相比战争，和平更加有利可图。</p>
<p>现代四大因素从今了良性循环：核子末日威胁促进了和平主义；战争退散贸易兴旺；贸易成长和平比战争利润更高；国际网络日益紧密，国家无法全然独立之外，任何一国片面宣战的机会大幅降低。</p>
<p>在人类心理上，现代人与1800年人类相比快乐不一定更多。比如自由，虽然可以自由选择拥有，对方也可以自由选择离去，社群和家庭凝聚力下降，这个世界上个人感觉越来越孤独。快乐不在于客观条件，而在于客观与主观期望是否相符。快乐是数百万年演化的生化机制所塑造，包括血清素、多巴胺和催产素。而演化机制让人类的快乐只是短暂奖赏，不然不会有心情做其他事情。人类心理就像一个恒温系统，所有正向和负向的波动都会回到正常水平线上。</p>
<p>因此佛教主张，所有主观感受都是瞬间波动，追求瞬间体验是徒劳。无论追求什么，持续的不满来自追求这件事本身，因此主张保持心灵平静。虽然这种主张与现代自由主义文化追求物质的文化不相融合，但这种说法与现代生物学不约而同。 现代有三种方式令智慧设计取代自然选择：生物工程、仿生工程、无机生命。</p>
<p>生物工程就是人类对生物的干预，比如阉割的公牛叫做ox，未阉割的叫做bull。大肠杆菌经过基因改造来生产燃料，改造奶牛乳腺炎问题带来的牛奶病菌，改造猪肉中的不健康脂肪。</p>
<p>仿生工程，类似助听器，人造视网膜，以及大脑就可以控制的外骨骼。其中最具革命性的就是脑机双向借口，计算机读取大脑信号并且传输回大脑，大脑也可以连上网络形成脑际网络，可以读取记忆，届时人类将面对新的问题和挑战。</p>
<p>无机生命，则是可以模仿基因遗传演化，自我复制并且繁衍的程序，届时如果能够构建一个数字个体心灵，计算机里面构建出人工大脑，虽然不是所有科学家都同意二者运转方式一致，但是不能排除这种可能性。现在的文化已经挣脱了生物学控制，越来越多行事方式已经大幅改变，无法守旧。虽然很难接受科学家不仅能改造身体，还能改造心灵。未来的数字物种，没人能预测准。如果智人即将谢幕，那么我能能做的就是开始思考我们究竟想要什么？</p>
]]></content>
  </entry>
  <entry>
    <title>孤夜</title>
    <url>/posts/%E6%95%A3%E6%96%87%E8%AF%97/%E5%AD%A4%E5%A4%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>加班到深夜</p>
<p>秋雨不禁让我戴上了卫衣的帽子</p>
<span id="more"></span>
<p>起夜的我爸</p>
<p>看到了我的背影</p>
<p>让我把帽子摘了</p>
<p>我随口说有点冷</p>
<p>他说，我给你拿件衣服吧</p>
<p>戴帽子显得很孤独</p>
<p><img data-src="./640" alt></p>
<p>给我披上衣服后</p>
<p>怕打扰我</p>
<p>静静地在我身后站了一会</p>
<p>却没忍住对我说：你没以前活泼了</p>
<p>回头看到两鬓斑白欲言又止的他</p>
<p>眼睛里仿佛又在回忆着什么</p>
<p><img data-src="./640-20211027204423943" alt></p>
<p>本来很困的我</p>
<p>现在躺在床上</p>
<p>却怎么也睡不着了</p>
]]></content>
      <categories>
        <category>散文诗</category>
      </categories>
      <tags>
        <tag>散文诗</tag>
      </tags>
  </entry>
  <entry>
    <title>到底什么是知行合一</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%9F%A5%E8%A1%8C%E5%90%88%E4%B8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
  </entry>
  <entry>
    <title>世界尽头的咖啡馆</title>
    <url>/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E4%B8%96%E7%95%8C%E5%B0%BD%E5%A4%B4%E7%9A%84%E5%92%96%E5%95%A1%E9%A6%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="序">序</span></h1><p>最近工作不是很顺心，经常闷闷不乐，跟老板吵了几次架，女朋友看到后，就给我买了这本《世界尽头的咖啡馆》，期望我能读完后，心情放松些，不要被工作中的不顺心扰乱我的思绪，打扰我的清净。<br>我本以为这本书写的是一些鸡汤，告诉我工作是工作，生活是生活，工作是为了更好的生活，所以轻松的工作，开心的生活， 仅此而已。<br>但显然，我写了这篇文章，就说明这本书所讲的内容，不是我简单理解的“轻松工作以便快乐生活”。</p>
<span id="more"></span>
<h1><span id="1-本书摘要">1. 本书摘要</span></h1><p>通篇看完，这本书讲得内容无非就是：</p>
<blockquote>
<p>作者工作惆怅，想休假放松一下，躲避繁杂的工作，然而事与愿违，假期的开始，就是毫无尽头的堵车，以及堵车带来烦躁的心情；<br>为了绕过预期1小时的堵车，却陷入了迷失之地，最后误打误撞，进入了一家“‘你为什么来这里？’咖啡馆”；<br>这家咖啡馆的厨师、服务员、厨师的女朋友给作者答疑解惑，让作者如获新生；</p>
</blockquote>
<p>故事其实很老套，以上是这本书的故事经过，但故事经过不是重点，重点是，咖啡馆的菜单上，有三个问题：</p>
<ol>
<li>你为什么来这里？</li>
<li>你害怕死亡吗？</li>
<li>你满足吗？</li>
</ol>
<p>作者在咖啡店中夜坐了8个小时，重点针对第一个问题进行了一系列的思考，而他的答案，也随着和别人的谈话内容的深入，有所改变。</p>
<h1><span id="莫名其妙的问题">莫名其妙的问题</span></h1><p>面对这三个莫名其妙的问题，我一时不知道作者在讲什么，所以我停下阅读，思考着如果我面对这三个问题，我的答案是什么呢？</p>
<p>我没去过作者所写的咖啡馆，无法体会作者的感受，所以我无法回答“你为什么来这里？”这个问题。<br>我所遇到的问题是，当前的工作环境让我惆怅、困惑，于是我把问题改为：“你为什么来到这里工作？”。</p>
<h2><span id="你为什么来到这里工作">你为什么来到这里工作？</span></h2><p>这个问题乍一看，很好回答：为了赚钱。<br>我想这个世界上大多数人每天努力的工作，就是为了赚钱吧。<br>看到这篇文章的你，是不是也是这个答案？</p>
<p>没错，我努力工作的目标就是为了赚钱，赚钱买房、买车，从而满足我的物质生活，赚钱旅游，见识世界上美妙的山水，赚钱吃美食，忙碌了一周后犒劳一下自己，满足自己的精神生活。</p>
<h2><span id="商人与渔夫">商人与渔夫</span></h2><p>作者给出他的答案之后，餐厅服务员给作者讲了一个“商人与渔夫”的故事：</p>
<blockquote>
<p>有一个美国商人坐在墨西哥海边一个小渔村的码头上，看到一个渔夫划着一艘小船靠岸，小船上有好几尾大黄鳍鱼。这个美国商人问渔夫要多少时间才能抓这么多鱼？<br>渔夫说，一会儿功夫就抓到了这么多。美国商人再问，<strong>你为什么不待久一点，好多抓一些鱼？</strong>渔夫觉得不以为然，因这些鱼已经足够他一家人吃的啦。<br>美国人又问：那么你一天剩下那么多时间都在干什么？<br>渔夫回答：“我每天睡到自然醒，出海抓十几斤鱼之后，回来后跟孩子们玩游戏；再跟家人一起吃个午餐，黄昏时到村子里聊聊天，跟哥儿们打打牌。我的日子可过得充满又忙碌呢！”<br>美国人帮他出主意，说：我是美国哈佛大学企管硕士，我建议你每天多花一些时间去捕鱼，到时候你就有钱去买条大一点的船，你就可以捕更多的鱼，再买更多的渔船，有了自己的渔船队。<br>到时候你就不必把鱼卖给鱼贩子了，而是直接卖给加工厂。然后你可以自己开一家罐头工厂，这样你就可以控制整个生产、加工和营销。然后你可以离开这个小渔村，搬到墨西哥城，再搬到洛杉矶，最后到纽约，在那里经营你不断扩充的企业。<br>渔夫问：这要花多少时间？美国人回答：十五到二十年。<br>渔夫问：然后呢？<br>美国人大笑着说：然后你就可以在家当皇帝啦！时机一到，你可以通过股票上市，把你公司股份卖给大众；到时候你就发啦！你可以几亿几亿地赚！<br>渔夫问：然后呢？<br>美国人说：到那个时候你就可以退休啦！你可以搬到海边的小渔村去住。每天睡到自然醒，出海钓钓鱼，回来后跟孩子们玩玩；再睡个午觉，黄昏时晃到村子里喝点小酒。<br>渔夫疑惑地说：<strong>我现在不就是这样了吗？</strong></p>
</blockquote>
<p>我陷入了沉思，<br>我的目标是什么？我怎么做达成我的目标？难道我也要放弃现在的工作，回家圈一片田园，日日登山砍柴，一眼看到了自己的未来吗？</p>
<h1><span id="我的目标">我的目标</span></h1><p>别人的目标是什么呢？</p>
<p>王阳明的目标是“做圣人”，乔布斯的目标是“改变世界”，<br>圣人我是做不到的，也没那个毅力和勇气😂，改天再聊一下王阳明的“知行合一”，我是如何“知行不合一”的。</p>
<p>没灵感了，未完，待续… </p>
<p>写于2021年10月10日</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>商业模式和盈利模式</title>
    <url>/posts/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F_%E7%9B%88%E5%88%A9%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="六大商业模式">六大商业模式</span></h1><p>现代商业受互联网经济的影响，经营模式也在不断的创新，商业模式在持续变化。企业在经营过程中，需要为销售方式选择适宜的商业模式，来适应市场的需求。<br>当前市场上存在的商业模式较为经典的模式有六种，下面来进行详细的特点介绍。</p>
<span id="more"></span>
<ol>
<li>第一种模式，互联网模式</li>
</ol>
<blockquote>
<p>互联网模式的特征：主业倒贴</p>
</blockquote>
<p>用户为王当年卡巴斯基杀毒软件还在收费时，360的杀毒软件已经免费让人使用了，跳出利润范畴，直接免费，干掉了卡巴斯基等收费杀毒软件，拥有了庞大的用户数，坐上了杀毒软件老大的位置。</p>
<ol>
<li>第二种模式，连锁模式<blockquote>
<p>连锁模式的核心关键：复制能力</p>
</blockquote>
</li>
</ol>
<p>麦当劳（207.400，-1.15%）作为全球知名连锁餐饮品牌，最初的店却是麦当劳两兄弟开的。雷·克罗克去吃饭，结果看到这家店生意这么好，而且可以把人工成本降到最低，就跟麦当劳两兄弟谈了合作，用这家店当样板店，让人加盟，开遍了全美国，后来又拿着从加盟商那里赚来的钱把麦当劳两兄弟的这家样板店收购了。</p>
<ol>
<li>第三种模式，直销模式<blockquote>
<p>直销公司的成功关键：教育能力</p>
</blockquote>
</li>
</ol>
<p>直销是去掉中间商，直接零售给消费者的销售形式，包括电视销售、邮购、自动供货机、目录销售、登门销售等等。直销的核心在于裂变速度，教育顾客，让顾客购买你的产品以后能够分享传播转介绍。</p>
<ol>
<li>第四种模式，金融模式<blockquote>
<p>金融模式的特征：杠杆能力</p>
</blockquote>
</li>
</ol>
<p>金融公司的盈利来源于成立基金，收取管理费，收益分成等。为什么说金融都有钱?因为可以利用杠杆效应，放大收益，这就是金融的魅力所在。</p>
<ol>
<li>第五种模式，投行模式<blockquote>
<p>投行模式的特征：放大能力</p>
</blockquote>
</li>
</ol>
<p>国际化公司走的基本都是资源整合，资源调配，他们自己基本不生产产品，比如小米（9.040，-3.21%），华为，都是外放给别人做，自己只做最核心的东西，技术和用户。</p>
<ol>
<li>第六种模式，产业整合模式<blockquote>
<p>产业链模式的特征：整合能力</p>
</blockquote>
</li>
</ol>
<p>在这个重资产过剩的时代，没有必要再去创造更多的重资产，你要做的是轻资产轻运营，善于去发现做的好的企业，投资他们，再进行相应的资源整合。经济市场的长期发展衍生出不同的商业模式，但是最重要的选择的商业模式要适应市场需求，满足消费者追求便捷、高效、高质生活品质的要求，这样的商业模式才会有市场。商业模式创新也是需要进行这方面的考虑的。</p>
<h1><span id="八大盈利模式">八大盈利模式</span></h1><p>当今如果说到创业，永远绕不开一个话题：<strong>“模式”</strong>。</p>
<p>非创业者往往最关注的是“产品”或“服务”；初级创业者往往最关注的的是“行业”；而高级创业者最关心的永远是 <strong>“模式”</strong>。<br>为什么？因为一旦模式选错，即是行业选得再好也没用。<br>模式拆开来谈，大概可以分为两类，一个是“商业模式”，一个是“盈利模式”。商业模式中包含了盈利模式。</p>
<p>关于商业模式的问题，其实有很多的经典书籍都有过论述。</p>
<blockquote>
<ol>
<li>《商业模式全史》</li>
<li>《商业模式新生代》</li>
<li>《重构商业模式》</li>
<li>《客户价值主张》</li>
</ol>
</blockquote>
<p>甚至还有一本书一口气论述了100多种商业模式，其中的核心依然是盈利模式。咱们就简单粗暴一些。</p>
<p>盈利模式，总体来说主要分为八大种：</p>
<ol>
<li>产品盈利<blockquote>
<p>以卖的最便宜为根本</p>
</blockquote>
</li>
</ol>
<p>比如，之前格力与奥克斯之争，再如之前小米宣布要出一款一根只要1元钱的“巨能写”笔，直接抗衡中性笔大佬晨光……你会发现，市场永远倾向于最便宜的商家，这是最基本的商业规律。再比如，日本的优衣库，瑞典的宜家，美国的沃尔玛……各个老板都是首富。具体怎么才能卖的更便宜，我们之后会在商业模式的讨论中细说。一旦你确定企业的主要盈利方式来自于产品，那说白了，就是比谁卖的更便宜。比如现在国内的券商竞争，在费率几乎完全透明，服务趋向同质化的时代，如果想硬性争取市场份额，那低佣策略是不二之选。</p>
<ol>
<li>品牌盈利<blockquote>
<p>持续不断地提高品牌附加价值</p>
</blockquote>
</li>
</ol>
<p>想尽办法卖的更贵。比如，LV，GUCCI，爱马仕……这样的品牌太多了。基本上可以理解为，买品牌送一个产品，买的是情怀、是情感、是精神。往往这样的品牌需要很强的品牌无形资产的护城河，需要时间，和庞大的市场预算做铺垫。以往广告4A公司，传统咨询公司最擅长做这样的品牌梳理和定位。如果是白手起家，无本创客，可以先略过这一盈利点，也因为会死的很惨，没人买你的账。</p>
<ol>
<li>模式盈利<blockquote>
<p>隐形盈利，把看得见的钱都分出去，赚背后看不见的钱。</p>
</blockquote>
</li>
</ol>
<p>目前基本上互联网公司全都是这个套路，懂不懂就会出现一些撸羊毛的事情，基本上全都是将原本的主业免费，先抓住流量，形成垄断后，通过后端收费来进行收割。比如，在所有杀毒软件都收费的情况下，突然杀出来一个永久免费的360，但通过广告商投广告来收费；再比如，在所有手机比谁配置好，卖的贵的时候，突然杀出来一个小米，成本价卖给你。但是他垄断的是流量，后端不断收费。你买回家了一台很便宜的小米电视，会发现每个想看的电影都需要额外收费，说白了，更像是一台小米POS机。其实目前的互联网券商也是这个套路，先赢再求利。</p>
<ol>
<li>系统盈利<blockquote>
<p>把该花钱的让别人去干，但钱都在我这里。</p>
</blockquote>
</li>
</ol>
<p>比如，很多厂商在一开始就会去掉所有固定成本，能外包的外包掉。只在自己家贴牌组装，但高利润的部分全都在自己手里。很多科技厂商，包括苹果也是这样。他们是不会花高额的价格投资于厂房的。系统盈利，需要有一定的整合能力，整合上游和同业者。</p>
<ol>
<li>资源盈利<blockquote>
<p>说白了就是垄断盈利。</p>
</blockquote>
</li>
</ol>
<p>对上游，进行资源垄断。对下游，进行渠道垄断。对互联网，进行用户垄断。这块，就全都归你了。比如，搜索引擎界的百度，比如社交软件界的腾讯，比如电商界的阿里，比如白酒界的茅台。</p>
<ol>
<li>收租盈利<blockquote>
<p>专利盈利。</p>
</blockquote>
</li>
</ol>
<p>这个很好理解，主要包括：技术、版权、电影、歌曲、图片等等。比如，视觉中国…… 算了不说了。总之，收租盈利是一种很高端的赢利方式，因为它完全被动化。</p>
<ol>
<li>金融盈利<blockquote>
<p>主要就是杠杆盈利。</p>
</blockquote>
</li>
</ol>
<p>以钱生钱，从无到有的游戏。在企业资产足以使用高杠杆的时候，可以进行金融盈利。比如，现在很多集团都或多或少地涉及到金融领域了，阿里、京东、腾讯、360等等，甚至一些非法的搞房租借贷的，其实这都属于金融盈利。</p>
<ol>
<li>国家盈利<blockquote>
<p>生态。</p>
</blockquote>
</li>
</ol>
<p>一个人从生到死，花的每笔钱都和我有关。其实，互联网公司都是照着这个方向去的。比如腾讯，你会发现微信里既能发短信、又能视频打电话、还能玩游戏、还整合了app、还能打车、还能存钱、还能购物、还能……同理，其他互联网公司，都是这个路子。对于一个创业者来说，以上八大盈利模式，是可以综合使用的。但无论如何都一定要想好，你的项目是打算通过哪种或哪几种盈利模式去盈利。千万别把目光只停留在产品或服务上，否则一旦做大了就是个死。或者更准确地说，盈利模式不创新，就根本做不大。</p>
]]></content>
      <categories>
        <category>商业</category>
        <category>经济</category>
      </categories>
      <tags>
        <tag>商业</tag>
        <tag>经济</tag>
      </tags>
  </entry>
  <entry>
    <title>21-10-01</title>
    <url>/posts/%E6%97%A5%E8%AE%B0/21/Q3/21-10-01/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>过完国庆，上班的第一天，不想上班~~~</p>
]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>日记</tag>
      </tags>
  </entry>
  <entry>
    <title>创业团队该如何管理，创始人该如何管理团队？</title>
    <url>/posts/%E7%AE%A1%E7%90%86/%E5%88%9B%E4%B8%9A%E5%9B%A2%E9%98%9F%E8%AF%A5%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>老丁我之前说过，创业这件事<strong>要看路，别看墙。</strong></p>
<p>对于<a href="http://www.wubenck.com/">互联网创业</a>，你如果总是看墙，你会发现到处都是墙。</p>
<span id="more"></span>
<p>有很多人一想到创业或开公司涉及到团队管理，觉得自己没什么领袖气质管不动人，就开始打退堂鼓，这简直是太可笑了。</p>
<p>这就好比是很多人永远陷入在问题本身里出不来，总是想把“镜子擦干净”。但我告诉你，镜子它本身就是干净的，它能不干净吗？</p>
<p>这本身是个逻辑错误。</p>
<p>镜子本身是干净的，只是它上面落着灰尘，而你要擦掉的也只是灰尘而已，并不是镜子本身。</p>
<p>还是思维习惯的问题；包括<strong><a href="http://www.wubenck.com/chuangyetuandui/">创业团队</a>如何管理</strong>，以及创始人<strong>如何管理团队</strong>，这个问题其实根本不是问题；就好比还没尝试就觉得<a href="http://www.wubenck.com/post/49.html">生意难做</a>，你起码尝试一下再下定论，起码去探究下它难做的原因。</p>
<p>老丁我可以很明确地告诉你，创业企业的<strong>创始人不会内部管理，是天经地义的</strong>；不会内部管理是一个创业者，乃至优秀企业家的天赋所在。</p>
<p>为什么这么说呢？</p>
<p><strong>因为企业内部管理本身就该是总经理、总监、职业经理该做的事，真正的领导者、创始人、企业家应该擅长的是对外融资、招商、策划、以及<a href="http://www.wubenck.com/shangyemoshi/">商业模式</a>设计和贩卖。</strong></p>
<p>也就是说，创业者应该是董事长的角色和性格，而不知是限于内部管理上。</p>
<p>你管不好团队，是应该的，因为你缺一个总经理，而天生的董事长就是不擅长内部管理的；这个是真理。</p>
<p>有很多人，小学的时候是小队长，中学当班长，大学学生会主席，后来你会发现这样的人往往步入社会打拼一些年后会当个总监、高管，也就到头了。</p>
<p>而往往是那些比较个性，不随大流，甚至比较孤僻的人，反而混的风生水起；这是为什么呢？</p>
<p>因为从人与人之间的关系上来看，分为两种人：<strong>一种喜欢纵向管理，一种喜欢横向合作</strong>。</p>
<p>喜欢纵向管理的人，必然会擅长内部管理，他们天生擅长于分工和协调，是个做总经理的料子；</p>
<p>而对于喜欢横向跨界合作的人来说，他们喜欢和强者保持对等关系互换利益式的合作，这样才能带来快感，而这才是创业者，或董事长该具备的品性。</p>
<p>老丁我从小到大都是一个比较个性的独行家，喜欢和比较强的人做朋友，所以结交的朋友都在某些领域比较有建树；后来读研了，打算挑战下自己，于是闷头努力当了个学生会副主席，主要就是管理全校的学生事务。</p>
<p>我发现自己能做的非常好，但是却非常心累，找不到任何一点快感；相比纵向管理，我还是更喜欢横向和不同的人去合作，这样能带来更多的成就感和快感，同时不会那么心累。</p>
<p>因为信任和赏识去合作，对我来说远远要好于去指挥一大堆不如我的人来的舒服。</p>
<p>我还有个朋友，他也在创业，但是家底比较厚实。开了个餐饮店，装修得很豪华，开在市中心的区域。</p>
<p>有一次我去和他谈事，看了看它书架上的书，全都是管理学的，桌子上还扣着一本《卓有成效的管理者》，我立刻就知道他方向错了，这么好的条件，方向错了永远做不大。</p>
<p>他该研究该看的不是管理学，而是应该多研究商业模式和盈利模式的创新，他要做的不是不断招聘劳动力做饭，而是应该多想想如何搞加盟，如何招商 。</p>
<p>碍于面子，我点了一下，没多说。直到1年后这家伙才反应过来开始对外招商搞加盟了，想想也是，估计是老爹的钱烧干净了，缺现金了。</p>
<p>好了，那么再说回来，创业团队该如何管理？CEO\创始人如何管理团队？</p>
<p>网上有很多文章去教你如何带领团队，但是老丁我想说的是，这本身就是个伪命题，你不必会。</p>
<p>内部的管理完全可以用事业部的股份制，让别人自己去管理，这是总经理的义务，不是董事长的义务。</p>
<p>董事长应该多去研究下六大商业模式，<a href="http://www.wubenck.com/post/48.html">八大盈利模式</a>的问题。</p>
<p>比如，我见过一个90后女孩，她的方法就很好，她只会忽悠，甚至连商业模式都不懂；那么她一定需要一个团队，而团队的人几乎都大她一轮，怎么管理呢？</p>
<p>很简单，几个创始人统一向她汇报，她自己不参与管理，每个创始人分管一摊，充分放权，自己专注于融资招商。</p>
<p>因为她压根就不想浪费时间和精力在公司内部的纷纷扰扰上，没有任何意义。</p>
<p>很简答，这不就解决了么，总比天天抱着管理学书强吧。而且有个真理是永远都改变不了的：</p>
<p><strong>对于每个员工来说，老板永远是不可见。</strong></p>
<p>然而还有无数的老板希望能和员工打成一片，留个好口碑，我只能说这人天真。</p>
<p>如果你说，我们规模小，也就2-3个人，没法不管理。</p>
<p>其实更简单，阵容小就更不该纵向管理了，小阵容就应该相互合作，阵容越小，就需要你合作的人越强力。</p>
<p>如何管理团队？不必管理，你该想想如何和这些伙伴合作。</p>
<p>一定要明白：“纵向分工”的核心并不是因为别人干的比你好你才招聘他，而是因为你能做的比他们都好，但是时间有限，只能分配出去让别人替你节省时间，而你才有时间做更有价值的事。</p>
<p><strong>本质是你自己花钱买时间</strong>，千万别理解错了。</p>
<p><a href="http://www.wubenck.com/post/148.html">参考</a></p>
]]></content>
      <categories>
        <category>管理</category>
        <category>创业</category>
      </categories>
      <tags>
        <tag>管理</tag>
        <tag>创业</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石-6</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="6-theory-of-generalization">6 — Theory of Generalization</span></h1><p>上一节课，我们主要探讨了当M的数值大小对机器学习的影响。如果M很大，那么就不能保证机器学习有很好的泛化能力</p>
<span id="more"></span>
<p>所以问题转换为验证M有限，即最好是按照多项式成长。然后通过引入了成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>和dichotomy以及break point的概念，提出2D perceptrons的成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>是多项式级别的猜想。这就是本节课将要深入探讨和证明的内容。</p>
<h3><span id="一-restriction-of-break-point"><strong>一、Restriction of Break Point</strong></span></h3><p>我们先回顾一下上节课的内容，四种成长函数与break point的关系：</p>
<p><img data-src="./04f493664b201b8df9c53b61298cab13.jpg" alt></p>
<p>下面引入一个例子，如果k=2，那么当N取不同值的时候，计算其成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>是多少。很明显，当N=1时，<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>=2,；当N=2时，由break point为2可知，任意两点都不能被shattered（shatter的意思是对N个点，能够分解为<img data-src="./7cd97d730040fe395178281c9bcd2896.jpg" alt>种dichotomies）；<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>最大值只能是3；当N=3时，简单绘图分析可得其<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>，即最多只有4种dichotomies。</p>
<p><img data-src="./e35fe0cc5f978367608fbe0832b89876.jpg" alt></p>
<p>所以，我们发现当N&gt;k时，break point限制了<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>值的大小，也就是说影响成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的因素主要有两个：</p>
<ul>
<li><p>抽样数据集N</p>
</li>
<li><p>break point k（这个变量确定了假设的类型）</p>
</li>
</ul>
<p>那么，如果给定N和k，能够证明其<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的最大值的上界是多项式的，则根据霍夫丁不等式，就能用<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>代替M，得到机器学习是可行的。所以，证明<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的上界是poly(N)，是我们的目标。</p>
<p><img data-src="./d93b83928aca7ad49c974a734e903c75.jpg" alt></p>
<h3><span id="二-bounding-function-basic-cases"><strong>二、Bounding Function: Basic Cases</strong></span></h3><p>现在，我们引入一个新的函数：bounding function，B(N,k)。Bound Function指的是当break point为k的时候，成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>可能的最大值。也就是说B(N,k)是<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的上界，对应<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>最多有多少种dichotomy。那么，我们新的目标就是证明：</p>
<p>这里值得一提的是，B(N,k)的引入不考虑是1D postive intrervals问题还是2D perceptrons问题，而只关心成长函数的上界是多少，从而简化了问题的复杂度。</p>
<p><img data-src="./8b0d2ebec1dc8e39584706453f0e95ea.jpg" alt></p>
<p>求解B(N,k)的过程十分巧妙：</p>
<ul>
<li><p>当k=1时，B(N,1)恒为1。</p>
</li>
<li><p>当N &lt; k时，根据break point的定义，很容易得到<img data-src="./458d09662b917b59905548a3993e96cc.jpg" alt>。</p>
</li>
<li><p>当N = k时，此时N是第一次出现不能被shatter的值，所以最多只能有<img data-src="./7cd97d730040fe395178281c9bcd2896.jpg" alt>个dichotomies，则<img data-src="./458d09662b917b59905548a3993e96cc.jpg" alt>。</p>
</li>
</ul>
<p><img data-src="./3b23bef628d9fbafbf28bc252d02cb09.jpg" alt></p>
<p>到此，bounding function的表格已经填了一半了，对于最常见的N&gt;k的情况比较复杂，推导过程下一小节再详细介绍。</p>
<h3><span id="三-bounding-function-inductive-cases"><strong>三、Bounding Function: Inductive Cases</strong></span></h3><p>N &gt; k的情况较为复杂，下面给出推导过程：</p>
<p>以B(4,3)为例，首先想着能否构建B(4,3)与B(3,x)之间的关系。</p>
<p>首先，把B(4,3)所有情况写下来，共有11组。也就是说再加一种dichotomy，任意三点都能被shattered，11是极限。</p>
<p><img data-src="./2c425af1bda39d5d4fdb515dba5f683c.jpg" alt></p>
<p>对这11种dichotomy分组，目前分成两组，分别是orange和purple，orange的特点是，x1,x2和x3是一致的，x4不同并成对，例如1和5，2和8等，purple则是单一的，x1,x2,x3都不同，如6,7,9三组。</p>
<p><img data-src="./a28d9ac1bc94143c369fa4385a0c8606.jpg" alt></p>
<p>将Orange去掉x4后去重得到4个不同的vector并成为<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>，相应的purple为<img data-src="./19eb420f01ddee8a442203359e539f63.jpg" alt>。那么<img data-src="./26491f4fd30de6f0330fd2bd7e364b44.jpg" alt>，这个是直接转化。紧接着，由定义，B(4,3)是不能允许任意三点shatter的，所以由<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>和<img data-src="./19eb420f01ddee8a442203359e539f63.jpg" alt>构成的所有三点组合也不能shatter（alpha经过去重），即<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>。</p>
<p><img data-src="./0f72079b59b2c590934d6fbc97f49b86.jpg" alt></p>
<p>另一方面，由于<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>中x4是成对存在的，且<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>是不能被任意三点shatter的，则能推导出<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>是不能被任意两点shatter的。这是因为，如果<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>是不能被任意两点shatter，而x4又是成对存在的，那么x1、x2、x3、x4组成的<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt>必然能被三个点shatter。这就违背了条件的设定。这个地方的推导非常巧妙，也解释了为什么会这样分组。此处得到的结论是<img data-src="./4b816d9a6c9d8dc65312017e305289d0.jpg" alt></p>
<p><img data-src="./62b7e9853cf1e2c93e36e734684ffedc.jpg" alt></p>
<p>由此得出B(4,3)与B(3,x)的关系为：</p>
<p><img data-src="./b70c0e4f3f5acaff10bb2ed9b63af571.jpg" alt></p>
<p>最后，推导出一般公式为：</p>
<p><img data-src="./16f8ad8a2b62816f059ac3bf3ed190a5.jpg" alt></p>
<p>根据推导公式，下表给出B(N,K)值</p>
<p><img data-src="./ae00d20e35b7b5ba26fda3c392c3be6d.jpg" alt></p>
<p>根据递推公式，推导出B(N,K)满足下列不等式：</p>
<p><img data-src="./ff23be6e6b260123571f2b06d03610d1.jpg" alt></p>
<p>上述不等式的右边是最高阶为k-1的N多项式，也就是说成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的上界B(N,K)的上界满足多项式分布poly(N)，这就是我们想要得到的结果。</p>
<p>得到了<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的上界B(N,K)的上界满足多项式分布poly(N)后，我们回过头来看看之前介绍的几种类型它们的<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>与break point的关系：</p>
<p><img data-src="./b274867af01a89518824fc6395aa4e50.jpg" alt></p>
<p>我们得到的结论是，对于2D perceptrons，break point为k=4，<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的上界是<img data-src="./e8576a0230698c0e77c5527cd1727568.jpg" alt>。推广一下，也就是说，如果能找到一个模型的break point，且是有限大的，那么就能推断出其成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>有界。</p>
<h3><span id="四-a-pictorial-proof"><strong>四、A Pictorial Proof</strong></span></h3><p>我们已经知道了成长函数的上界是poly(N)的，下一步，如果能将<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>代替M，代入到Hoffding不等式中，就能得到<img data-src="./775a32097a04956d0512e64ffb9c0fb4.jpg" alt>的结论：</p>
<p><img data-src="./56bdd9b5ca1eb9619f4b4bed3a1be4e0.jpg" alt></p>
<p>实际上并不是简单的替换就可以了，正确的表达式为：</p>
<p><img data-src="./2335ae24f94e920920f39ab0664a756d.jpg" alt></p>
<p>该推导的证明比较复杂，我们可以简单概括为三个步骤来证明：</p>
<p><img data-src="./e0333ab9074c1b4afadfd11d448a5f53.jpg" alt></p>
<p><img data-src="./7b8f0bee962842fa8de95a3990251150.jpg" alt></p>
<p><img data-src="./862f46fc4f65abf0ef3e91350620320d.jpg" alt></p>
<p>这部分内容，我也只能听个大概内容，对具体的证明过程有兴趣的童鞋可以自行研究一下，研究的结果记得告诉一下我哦。</p>
<p>最终，我们通过引入成长函数<img data-src="./b119518687af4f52fd05706b858d5b4e.jpg" alt>，得到了一个新的不等式，称为Vapnik-Chervonenkis(VC) bound：</p>
<p><img data-src="./bfe096b23bc59dc545bade37df21c182.jpg" alt></p>
<p>对于2D perceptrons，它的break point是4，那么成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>。所以，我们可以说2D perceptrons是可以进行机器学习的，只要找到hypothesis能让<img data-src="./1737a139505385980c969238ed819727.jpg" alt>，就能保证<img data-src="./8bc76a1f5706eb9d7282ce1655f95eb4.jpg" alt>。</p>
<h3><span id="五-总结"><strong>五、总结</strong></span></h3><p>本节课我们主要介绍了只要存在break point，那么其成长函数<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>就满足poly(N)。推导过程是先引入<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的上界B(N,k)，B(N,k)的上界是N的k-1阶多项式，从而得到<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>的上界就是N的k-1阶多项式。然后，我们通过简单的三步证明，将<img data-src="./b5dfc1d72d3bc59070321b6dc617fce2.jpg" alt>代入了Hoffding不等式中，推导出了Vapnik-Chervonenkis(VC) bound，最终证明了只要break point存在，那么机器学习就是可行的。</p>
<p><strong><em>注明：</em></strong></p>
<p>文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。</p>
]]></content>
      <categories>
        <category>机器学习基石</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石-5</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="5-training-versus-testing">5 — Training versus Testing</span></h1><p>上节课，我们主要介绍了机器学习的可行性。首先，由NFL定理可知，机器学习貌似是不可行的。但是，随后引入了统计学知识，如果样本数据足够大，且hypothesis个数有限，那么机器学习一般就是可行的。本节课将讨论机器学习的核心问题，严格证明为什么机器可以学习。从上节课最后的问题出发，即当hypothesis的个数是无限多的时候，机器学习的可行性是否仍然成立？</p>
<span id="more"></span>
<h3><span id="一-recap-and-preview"><strong>一、Recap and Preview</strong></span></h3><p>我们先来看一下基于统计学的机器学习流程图：</p>
<p><img data-src="./d4d611e1cde44e47a847daee299e34aa.jpg" alt></p>
<p>该流程图中，训练样本D和最终测试h的样本都是来自同一个数据分布，这是机器能够学习的前提。另外，训练样本D应该足够大，且hypothesis set的个数是有限的，这样根据霍夫丁不等式，才不会出现Bad Data，保证<img data-src="./10a4dae1cec5139479645b24e2d5bac7.jpg" alt>，即有很好的泛化能力。同时，通过训练，得到使<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>最小的h，作为模型最终的矩g，g接近于目标函数。</p>
<p>这里，我们总结一下前四节课的主要内容：第一节课，我们介绍了机器学习的定义，目标是找出最好的矩g，使<img data-src="./7752b07a006d650d158f817d75bd73b2.jpg" alt>，保证<img data-src="./31fe209114ce4d8ba43e0a1ed9bb700c.jpg" alt>；第二节课，我们介绍了如何让<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>，可以使用PLA、pocket等演算法来实现；第三节课，我们介绍了机器学习的分类，我们的训练样本是批量数据（batch），处理监督式（supervised）二元分类（binary classification）问题；第四节课，我们介绍了机器学习的可行性，通过统计学知识，把<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>与<img data-src="./4418c9184ff74a48310d23cad2779bbb.jpg" alt>联系起来，证明了在一些条件假设下，<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>成立。</p>
<p><img data-src="./4a3a79987b60d91f6dff1723fa5cc43f.jpg" alt></p>
<p>这四节课总结下来，我们把机器学习的主要目标分成两个核心的问题：</p>
<ul>
<li><p><img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt></p>
</li>
<li><p><img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>足够小</p>
</li>
</ul>
<p>上节课介绍的机器学习可行的一个条件是hypothesis set的个数M是有限的，那M跟上面这两个核心问题有什么联系呢？</p>
<p>我们先来看一下，当M很小的时候，由上节课介绍的霍夫丁不等式，得到<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>，即能保证第一个核心问题成立。但M很小时，演算法A可以选择的hypothesis有限，不一定能找到使<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>足够小的hypothesis，即不能保证第二个核心问题成立。当M很大的时候，同样由霍夫丁不等式，<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>与<img data-src="./4418c9184ff74a48310d23cad2779bbb.jpg" alt>的差距可能比较大，第一个核心问题可能不成立。而M很大，使的演算法A的可以选择的hypothesis就很多，很有可能找到一个hypothesis，使<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>足够小，第二个核心问题可能成立。</p>
<p><img data-src="./515657ef4f74ecb1e625faf55c2561f5.jpg" alt></p>
<p>从上面的分析来看，M的选择直接影响机器学习两个核心问题是否满足，M不能太大也不能太小。那么如果M无限大的时候，是否机器就不可以学习了呢？例如PLA算法中直线是无数条的，但是PLA能够很好地进行机器学习，这又是为什么呢？如果我们能将无限大的M限定在一个有限的<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>内，问题似乎就解决了。</p>
<h3><span id="二-effective-number-of-line"><strong>二、Effective Number of Line</strong></span></h3><p>我们先看一下上节课推导的霍夫丁不等式：</p>
<p>其中，M表示hypothesis的个数。每个hypothesis下的BAD events <img data-src="./6d273c6f30ef79a7f95288318ceb74fa.jpg" alt>级联的形式满足下列不等式：</p>
<p>当<img data-src="./c1903a9f9905c6ff6e894fd0d56e0bba.jpg" alt>时，上面不等式右边值将会很大，似乎说明BAD events很大，<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>与<img data-src="./4418c9184ff74a48310d23cad2779bbb.jpg" alt>也并不接近。但是BAD events <img data-src="./6d273c6f30ef79a7f95288318ceb74fa.jpg" alt>级联的形式实际上是扩大了上界，union bound过大。这种做法假设各个hypothesis之间没有交集，这是最坏的情况，可是实际上往往不是如此，很多情况下，都是有交集的，也就是说M实际上没那么大，如下图所示：</p>
<p><img data-src="./5b3bc7e09c268c58482ab0a9d2694515.jpg" alt></p>
<p>也就是说union bound被估计过高了（over-estimating）。所以，我们的目的是找出不同BAD events之间的重叠部分，也就是将无数个hypothesis分成有限个类别。</p>
<p>如何将无数个hypothesis分成有限类呢？我们先来看这样一个例子，假如平面上用直线将点分开，也就跟PLA一样。如果平面上只有一个点x1，那么直线的种类有两种：一种将x1划为+1，一种将x1划为-1：</p>
<p><img data-src="./10f1124294e47c6e25f06b8112df0375.jpg" alt></p>
<p>如果平面上有两个点x1、x2，那么直线的种类共4种：x1、x2都为+1，x1、x2都为-1，x1为+1且x2为-1，x1为-1且x2为+1：</p>
<p><img data-src="./343b2affaea086aa393dc4728514c6f5.jpg" alt></p>
<p>如果平面上有三个点x1、x2、x3，那么直线的种类共8种：</p>
<p><img data-src="./cfc2fa7880a02679c63f6863ae6dc4aa.jpg" alt></p>
<p>但是，在三个点的情况下，也会出现不能用一条直线划分的情况：</p>
<p><img data-src="./9e6dad04106cafdddc7c53fb11073fb3.jpg" alt></p>
<p>也就是说，对于平面上三个点，不能保证所有的8个类别都能被一条直线划分。那如果是四个点x1、x2、x3、x4，我们发现，平面上找不到一条直线能将四个点组成的16个类别完全分开，最多只能分开其中的14类，即直线最多只有14种：</p>
<p><img data-src="./2cb0459146a5948ee0b85bd32a897f36.jpg" alt></p>
<p>经过分析，我们得到平面上线的种类是有限的，1个点最多有2种线，2个点最多有4种线，3个点最多有8种线，4个点最多有14（<img data-src="./4243463ae8bbaad7b7ab9f781d0b0424.jpg" alt>）种线等等。我们发现，有效直线的数量总是满足<img data-src="./3c884fbbada83b4df889aa99e7ab5941.jpg" alt>，其中，N是点的个数。所以，如果我们可以用effective(N)代替M，霍夫丁不等式可以写成：</p>
<p>已知effective(N)&lt;<img data-src="./159eaf12f34ccf7fa235f448748ec23b.jpg" alt>，如果能够保证effective(N)&lt;&lt;<img data-src="./159eaf12f34ccf7fa235f448748ec23b.jpg" alt>，即不等式右边接近于零，那么即使M无限大，直线的种类也很有限，机器学习也是可能的。</p>
<p><img data-src="./894b9209fae5660943ca79dadf141471.jpg" alt></p>
<h3><span id="三-effective-number-of-hypotheses"><strong>三、Effective Number of Hypotheses</strong></span></h3><p>接下来先介绍一个新名词：二分类（dichotomy）。dichotomy就是将空间中的点（例如二维平面）用一条直线分成正类（蓝色o）和负类（红色x）。令H是将平面上的点用直线分开的所有hypothesis h的集合，dichotomy H与hypotheses H的关系是：hypotheses H是平面上所有直线的集合，个数可能是无限个，而dichotomy H是平面上能将点完全用直线分开的直线种类，它的上界是<img data-src="./159eaf12f34ccf7fa235f448748ec23b.jpg" alt>。接下来，我们要做的就是尝试用dichotomy代替M。</p>
<p><img data-src="./80fef61e7ef1c22b65b111edc0d44b84.jpg" alt></p>
<p>再介绍一个新的名词：成长函数（growth function），记为<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>。成长函数的定义是：对于由N个点组成的不同集合中，某集合对应的dichotomy最大，那么这个dichotomy值就是<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>，它的上界是<img data-src="./159eaf12f34ccf7fa235f448748ec23b.jpg" alt>：</p>
<p><img data-src="./b9b6be119129e41c22d02cd57df58eb7.jpg" alt></p>
<p>成长函数其实就是我们之前讲的effective lines的数量最大值。根据成长函数的定义，二维平面上，<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>随N的变化关系是：</p>
<p><img data-src="./f2089254d3581f0327f559b18a38bbfb.jpg" alt></p>
<p>接下来，我们讨论如何计算成长函数。先看一个简单情况，一维的Positive Rays：</p>
<p><img data-src="./b006be7b1e918f78dd6f9211023195ce.jpg" alt></p>
<p>若有N个点，则整个区域可分为N+1段，很容易得到其成长函数<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>。注意当N很大时，<img data-src="./eb2a34db68421a63aa6751d9d25d7c7f.jpg" alt>，这是我们希望看到的。</p>
<p>另一种情况是一维的Positive Intervals：</p>
<p><img data-src="./dfc7d98d33e91b28688d996844a7c1ab.jpg" alt></p>
<p>它的成长函数可以由下面推导得出：</p>
<p><img data-src="./01ca5ad564ffd99d6f9bf0b29552032f.jpg" alt></p>
<p>这种情况下，<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>，在N很大的时候，仍然是满足的。</p>
<p>再来看这个例子，假设在二维空间里，如果hypothesis是凸多边形或类圆构成的封闭曲线，如下图所示，左边是convex的，右边不是convex的。那么，它的成长函数是多少呢？</p>
<p><img data-src="./fda778820036a7d6c87d960bc99f27cc.jpg" alt></p>
<p>当数据集D按照如下的凸分布时，我们很容易计算得到它的成长函数<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>。这种情况下，N个点所有可能的分类情况都能够被hypotheses set覆盖，我们把这种情形称为shattered。也就是说，如果能够找到一个数据分布集，hypotheses set对N个输入所有的分类情况都做得到，那么它的成长函数就是<img data-src="./159eaf12f34ccf7fa235f448748ec23b.jpg" alt>。</p>
<p><img data-src="./8e877ce4ae32d59208285b20183577c5.jpg" alt></p>
<h3><span id="四-break-point"><strong>四、Break Point</strong></span></h3><p>上一小节，我们介绍了四种不同的成长函数，分别是：</p>
<p><img data-src="./a67ab6e15d74a733b70fcd8c8f8d18c7.jpg" alt></p>
<p>其中，positive rays和positive intervals的成长函数都是polynomial的，如果用<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>代替M的话，这两种情况是比较好的。而convex sets的成长函数是exponential的，即等于M，并不能保证机器学习的可行性。那么，对于2D perceptrons，它的成长函数究竟是polynomial的还是exponential的呢？</p>
<p>对于2D perceptrons，我们之前分析了3个点，可以做出8种所有的dichotomy，而4个点，就无法做出所有16个点的dichotomy了。所以，我们就把4称为2D perceptrons的break point（5、6、7等都是break point）。令有k个点，如果k大于等于break point时，它的成长函数一定小于2的k次方。</p>
<p>根据break point的定义，我们知道满足<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>的k的最小值就是break point。对于我们之前介绍的四种成长函数，他们的break point分别是：</p>
<p><img data-src="./464bc2b6cc1c88d2ca74f3d31071e434.jpg" alt></p>
<p>通过观察，我们猜测成长函数可能与break point存在某种关系：对于convex sets，没有break point，它的成长函数是2的N次方；对于positive rays，break point k=2，它的成长函数是O(N)；对于positive intervals，break point k=3，它的成长函数是<img data-src="./9dfa6d1f3f1817b8a29acbc48a98f25d.jpg" alt>。则根据这种推论，我们猜测2D perceptrons，它的成长函数<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt> 。如果成立，那么就可以用<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>代替M，就满足了机器能够学习的条件。关于上述猜测的证明，我们下节课再详细介绍。</p>
<h3><span id="五-总结"><strong>五、总结</strong></span></h3><p>本节课，我们更深入地探讨了机器学习的可行性。我们把机器学习拆分为两个核心问题：<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>和<img data-src="./88932c7439f7a0027095882f92530e11.jpg" alt>。对于第一个问题，我们探讨了M个hypothesis到底可以划分为多少种，也就是成长函数<img data-src="./492c221de7c92ebe91289195611c018d.jpg" alt>。并引入了break point的概念，给出了break point的计算方法。下节课，我们将详细论证对于2D perceptrons，它的成长函数与break point是否存在多项式的关系，如果是这样，那么机器学习就是可行的。</p>
<p><strong><em>注明：</em></strong></p>
<p>文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。</p>
]]></content>
      <categories>
        <category>机器学习基石</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石-4</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="4-feasibility-of-learning">4 — Feasibility of Learning</span></h1><p>上节课，我们主要介绍了根据不同的设定，机器学习可以分为不同的类型。其中，监督式学习中的二元分类和回归分析是最常见的也是最重要的机器学习问题。本节课，我们将介绍机器学习的可行性，讨论问题是否可以使用机器学习来解决。</p>
<span id="more"></span>
<h3><span id="一-learning-is-impossible"><strong>一、Learning is Impossible</strong></span></h3><p>首先，考虑这样一个例子，如下图所示，有3个label为-1的九宫格和3个label为+1的九宫格。根据这6个样本，提取相应label下的特征，预测右边九宫格是属于-1还是+1？结果是，如果依据对称性，我们会把它归为+1；如果依据九宫格左上角是否是黑色，我们会把它归为-1。除此之外，还有根据其它不同特征进行分类，得到不同结果的情况。而且，这些分类结果貌似都是正确合理的，因为对于6个训练样本来说，我们选择的模型都有很好的分类效果。</p>
<p><img data-src="./c4912fc4b106a71eb0a6bbaab4bfe73f.jpg" alt></p>
<p>再来看一个比较数学化的二分类例子，输入特征x是二进制的、三维的，对应有8种输入，其中训练样本D有5个。那么，根据训练样本对应的输出y，假设有8个hypothesis，这8个hypothesis在D上，对5个训练样本的分类效果效果都完全正确。但是在另外3个测试数据上，不同的hypothesis表现有好有坏。在已知数据D上，<img data-src="./777c1c6806abe7e3635c0e5443932447.jpg" alt>；但是在D以外的未知数据上，<img data-src="./777c1c6806abe7e3635c0e5443932447.jpg" alt>不一定成立。而机器学习目的，恰恰是希望我们选择的模型能在未知数据上的预测与真实结果是一致的，而不是在已知的数据集D上寻求最佳效果。</p>
<p><img data-src="./8cb724d6c8907309ce8e3c668babf164.jpg" alt></p>
<p>这个例子告诉我们，我们想要在D以外的数据中更接近目标函数似乎是做不到的，只能保证对D有很好的分类结果。机器学习的这种特性被称为没有免费午餐（No Free Lunch）定理。NFL定理表明没有一个学习算法可以在任何领域总是产生最准确的学习器。不管采用何种学习算法，至少存在一个目标函数，能够使得随机猜测算法是更好的算法。平常所说的一个学习算法比另一个算法更“优越”，效果更好，只是针对特定的问题，特定的先验信息，数据的分布，训练样本的数目，代价或奖励函数等。从这个例子来看，NFL说明了无法保证一个机器学习算法在D以外的数据集上一定能分类或预测正确，除非加上一些假设条件，我们以后会介绍。</p>
<h3><span id="二-probability-to-the-rescue"><strong>二、Probability to the Rescue</strong></span></h3><p>从上一节得出的结论是：在训练集D以外的样本上，机器学习的模型是很难，似乎做不到正确预测或分类的。那是否有一些工具或者方法能够对未知的目标函数f做一些推论，让我们的机器学习模型能够变得有用呢？</p>
<p>如果有一个装有很多（数量很大数不过来）橙色球和绿色球的罐子，我们能不能推断橙色球的比例u？统计学上的做法是，从罐子中随机取出N个球，作为样本，计算这N个球中橙色球的比例v，那么就估计出罐子中橙色球的比例约为v。</p>
<p><img data-src="./15f9d2722823307c158559957d378254.jpg" alt></p>
<p>这种随机抽取的做法能否说明罐子里橙色球的比例一定是v呢？答案是否定的。但是从概率的角度来说，样本中的v很有可能接近我们未知的u。下面从数学推导的角度来看v与u是否相近。</p>
<p>已知u是罐子里橙色球的比例，v是N个抽取的样本中橙色球的比例。当N足够大的时候，v接近于u。这就是Hoeffding’s inequality：</p>
<p>Hoeffding不等式说明当N很大的时候，v与u相差不会很大，它们之间的差值被限定在<img data-src="./3ceac491143c898df94d6ebb92cfa25f.jpg" alt>之内。我们把结论v=u称为probably approximately correct(PAC)。</p>
<p><img data-src="./f64fab987011ed7db0989e5053384b39.jpg" alt></p>
<h3><span id="三-connection-to-learning"><strong>三、Connection to Learning</strong></span></h3><p>下面，我们将罐子的内容对应到机器学习的概念上来。机器学习中hypothesis与目标函数相等的可能性，类比于罐子中橙色球的概率问题；罐子里的一颗颗弹珠类比于机器学习样本空间的x；橙色的弹珠类比于h(x)与f不相等；绿色的弹珠类比于h(x)与f相等；从罐子中抽取的N个球类比于机器学习的训练样本D，且这两种抽样的样本与总体样本之间都是独立同分布的。所以呢，如果样本N够大，且是独立同分布的，那么，从样本中<img data-src="./014d5d4e87c2d86bbc8f5f93ab9f0ef7.jpg" alt>的概率就能推导在抽样样本外的所有样本中<img data-src="./014d5d4e87c2d86bbc8f5f93ab9f0ef7.jpg" alt>的概率是多少。</p>
<p><img data-src="./422a4a4e35abaca291d0594bbc78966a.jpg" alt></p>
<p>映射中最关键的点是讲抽样中橙球的概率理解为样本数据集D上h(x)错误的概率，以此推算出在所有数据上h(x)错误的概率，这也是机器学习能够工作的本质，即我们为啥在采样数据上得到了一个假设，就可以推到全局呢？因为两者的错误率是PAC的，只要我们保证前者小，后者也就小了。</p>
<p><img data-src="./6ab071e96063c210af9dad03d7890ab2.jpg" alt></p>
<p>这里我们引入两个值<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>和<img data-src="./fe9b1118427000a29a9f9e54d288c701.jpg" alt>。<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>表示在抽样样本中，h(x)与<img data-src="./48d037eec62d870708acff75f000806d.jpg" alt>不相等的概率；<img data-src="./fe9b1118427000a29a9f9e54d288c701.jpg" alt>表示实际所有样本中，h(x)与f(x)不相等的概率是多少。</p>
<p><img data-src="./cbd827a026cbac360360200496b6ace4.jpg" alt></p>
<p>同样，它的Hoeffding’s inequality可以表示为：</p>
<p>该不等式表明，<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>也是PAC的。如果<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>，<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>很小，那么就能推断出<img data-src="./fe9b1118427000a29a9f9e54d288c701.jpg" alt>很小，也就是说在该数据分布P下，h与f非常接近，机器学习的模型比较准确。</p>
<p>一般地，h如果是固定的，N很大的时候，<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>，但是并不意味着<img data-src="./777c1c6806abe7e3635c0e5443932447.jpg" alt>。因为h是固定的，不能保证<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>足够小，即使<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>，也可能使<img data-src="./fe9b1118427000a29a9f9e54d288c701.jpg" alt>偏大。所以，一般会通过演算法A，选择最好的h，使<img data-src="./d7456181e4a1dc67ec0595e27aa6cb2a.jpg" alt>足够小，从而保证<img data-src="./fe9b1118427000a29a9f9e54d288c701.jpg" alt>很小。固定的h，使用新数据进行测试，验证其错误率是多少。</p>
<p><img data-src="./e1489a185d2f234739f2d60cd11f93db.jpg" alt></p>
<h3><span id="四-connection-to-real-learning"><strong>四、Connection to Real Learning</strong></span></h3><p><img data-src="./75f824b59ab187340120505c35679e38.jpg" alt></p>
<p>假设现在有很多罐子M个（即有M个hypothesis），如果其中某个罐子抽样的球全是绿色，那是不是应该选择这个罐子呢？我们先来看这样一个例子：150个人抛硬币，那么其中至少有一个人连续5次硬币都是正面朝上的概率是</p>
<p>可见这个概率是很大的，但是能否说明5次正面朝上的这个硬币具有代表性呢？答案是否定的！并不能说明该硬币单次正面朝上的概率很大，其实都是0.5。一样的道理，抽到全是绿色求的时候也不能一定说明那个罐子就全是绿色球。当罐子数目很多或者抛硬币的人数很多的时候，可能引发Bad Sample，Bad Sample就是<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>和<img data-src="./02ff91b1115630455f0eaac83fd1a6f4.jpg" alt>差别很大，即选择过多带来的负面影响，选择过多会恶化不好的情形。</p>
<p>根据许多次抽样的到的不同的数据集D，Hoeffding’s inequality保证了大多数的D都是比较好的情形（即对于某个h，保证<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>），但是也有可能出现Bad Data，即<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>和<img data-src="./02ff91b1115630455f0eaac83fd1a6f4.jpg" alt>差别很大的数据集D，这是小概率事件。</p>
<p><img data-src="./975737cb37c1124aa9e8d5ff644ea1f3.jpg" alt></p>
<p>也就是说，不同的数据集<img data-src="./7147db75452155b77c4f943044ef30c4.jpg" alt>，对于不同的hypothesis，有可能成为Bad Data。只要<img data-src="./7147db75452155b77c4f943044ef30c4.jpg" alt>在某个hypothesis上是Bad Data，那么<img data-src="./7147db75452155b77c4f943044ef30c4.jpg" alt>就是Bad Data。只有当<img data-src="./7147db75452155b77c4f943044ef30c4.jpg" alt>在所有的hypothesis上都是好的数据，才说明<img data-src="./7147db75452155b77c4f943044ef30c4.jpg" alt>不是Bad Data，可以自由选择演算法A进行建模。那么，根据Hoeffding’s inequality，Bad Data的上界可以表示为连级（union bound）的形式：</p>
<p><img data-src="./3e987fcc8d8ee3395d800efa97d30a76.jpg" alt></p>
<p>其中，M是hypothesis的个数，N是样本D的数量，<img data-src="./3ceac491143c898df94d6ebb92cfa25f.jpg" alt>是参数。该union bound表明，当M有限，且N足够大的时候，Bad Data出现的概率就更低了，即能保证D对于所有的h都有<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>，满足PAC，演算法A的选择不受限制。那么满足这种union bound的情况，我们就可以和之前一样，选取一个合理的演算法（PLA/pocket），选择使<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>最小的<img data-src="./805c7ce97d4ef084bcbe43d0b12d7d0f.jpg" alt>作为矩g，一般能够保证<img data-src="./777c1c6806abe7e3635c0e5443932447.jpg" alt>，即有不错的泛化能力。</p>
<p>所以，如果hypothesis的个数M是有限的，N足够大，那么通过演算法A任意选择一个矩g，都有<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>成立；同时，如果找到一个矩g，使<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>，PAC就能保证<img data-src="./02ff91b1115630455f0eaac83fd1a6f4.jpg" alt>。至此，就证明了机器学习是可行的。</p>
<p><img data-src="./ac553e6c89d844665df47903b119eab5.jpg" alt></p>
<p>但是，如上面的学习流程图右下角所示，如果M是无数个，例如之前介绍的PLA直线有无数条，是否这些推论就不成立了呢？是否机器就不能进行学习呢？这些内容和问题，我们下节课再介绍。</p>
<h3><span id="五-总结"><strong>五、总结</strong></span></h3><p>本节课主要介绍了机器学习的可行性。首先引入NFL定理，说明机器学习无法找到一个矩g能够完全和目标函数f一样。接着介绍了可以采用一些统计上的假设，例如Hoeffding不等式，建立<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>和<img data-src="./02ff91b1115630455f0eaac83fd1a6f4.jpg" alt>的联系，证明对于某个h，当N足够大的时候，<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>和<img data-src="./02ff91b1115630455f0eaac83fd1a6f4.jpg" alt>是PAC的。最后，对于h个数很多的情况，只要有h个数M是有限的，且N足够大，就能保证<img data-src="./c4d371480622b6ea2e62ad466017e7c9.jpg" alt>，证明机器学习是可行的。</p>
<p><strong><em>注明：</em></strong></p>
<p>文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。</p>
]]></content>
      <categories>
        <category>机器学习基石</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>天涯神贴-房价思考</title>
    <url>/posts/%E6%9D%82%E7%B1%BB/%E5%A4%A9%E6%B6%AF%E7%A5%9E%E8%B4%B4-%E6%88%BF%E4%BB%B7%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="kkndme_tianya持续更新中">kkndme_tianya（持续更新中…）</span></h1><p>天涯神贴<a href="http://bbs.tianya.cn/post-house-252774-1.shtml">「2010年的房地产调控，我们收获了什么？写在房价暴涨前」</a>脱水版，内容时间顺序和原贴一致，原贴中的优质非楼主写的内容，添加了引用格式便于区分。</p>
<span id="more"></span>
<h2><span id="调控降房价是刚需的一厢情愿">调控降房价是刚需的一厢情愿</span></h2><p>2010年的房地产调控，让很多人看到了希望：让房价降得再猛烈些吧。还有人更是幸灾乐祸似的呼喊：让房地产赶紧崩盘吧。让没房子的好好看看有房子的笑话，是人生的一大快事。</p>
<p>但是我们是不是要仔细想想，为什么调控？调控期望得到什么样的效果？</p>
<ol>
<li>是如千千万万想买房子的人期望的那样，让人人买的起房吗？</li>
<li>是如千千万万的流氓无产者期望的那样，让房地产崩盘，开发商上吊，dfzf不再靠卖地实现gdp吗？</li>
</ol>
<p>2010年房价下跌已经变成了人民最急切的期望，已经高过了解决超贫困家庭的温饱问题，已经超过了子女教育，医疗和养老。并且为房地产必须下降提出了若干义正言辞理由，总结下来无外乎三条：</p>
<ol>
<li>人人都有居住权。房子是用来住的，不是用来炒的。</li>
<li>房子太贵了，租售比严重不合理，空置率太高，人均收入太低，早晚要崩盘。</li>
<li>房价上涨造成物价上涨，人民生活变得困难。</li>
</ol>
<p>的确，当经济过热，房价过高，会对经济运行和社会安定带来较高的风险。这也是国家所担忧的。防范金融风险，一切维稳才是zy考虑的重中之中。</p>
<p>而民间所总结的三条，应该和调控的原因和目的基本不沾边。让我们一条一条的分析一下：</p>
<h3><span id="1-人人都有居住权-房子是用来住的不是用来炒的">1、人人都有居住权。房子是用来住的，不是用来炒的</span></h3><p>其实这是一个伪命题。房子包括房屋及房屋所属的土地两个部分。房屋本身只有居住价值；而土地所具备稀缺性，决定了土地的投资价值。房地产贵的不是房屋，而是房屋下面那块地皮。所以商品房具备了投资与自住双重属性。</p>
<p>任志强说的并没有错，居者有其屋并不等于人人享有商品房的产权。居住的房屋也不等于商品房。</p>
<blockquote>
<p><strong>liougehooa：</strong></p>
<p>“任志强说的并没有错，居者有其屋并不等于人人享有商品房的产权。居住的房屋也不等于商品房。” 任志强这句话绝对没说炒房价，房子在他眼里还是住的。<br>难道你用byt是你老er比较稀缺才买？那也没看见byt暴涨到5W一个。<br>”而土地所具备稀缺性？“任志强也说了，拿出全国耕地的1%也够老百姓住了！现在是啥科技了，舍掉1%耕地对农作物有什么影响？</p>
<p><strong>kkndme：</strong></p>
<p>华北平原从河北到山东有大片的盐碱地，你都可以用于盖房，而且会非常便宜，也没有人跟你竞价。但是你在那里盖了房子并不能保证你天天按时在北京城区上班。</p>
</blockquote>
<h3><span id="2-房子太贵了租售比严重不合理空置率太高人均收入太低早晚要崩盘">2、房子太贵了，租售比严重不合理，空置率太高，人均收入太低，早晚要崩盘</span></h3><p>这个问题比较大。房价是不是太贵了？有没有泡沫？</p>
<p>我们首先从国民的收入结构来分析</p>
<p>一个遵从“丛林法则”的精英社会决定了国民收入的金字塔结构。</p>
<p>既然是金字塔，底端的中低收入者占据了金子塔的最大比例，但是大家要知道金字塔的顶端既使只有10%人口，那也将是一个1亿多的绝对庞大的数字，远远超过了绝大多数西方国家的人口总和。</p>
<p>而北上广深以及三十多个省会，这些个靠掠夺全国或者一省资源，以牺牲大多数人口的利益为代价发展壮大起来的超大型及大型城市，需要容纳全国1亿多的精英人群，是否能得出房地产严重泡沫，空置率过高的结论？</p>
<p>当低收入者们努力挥洒汗水期望着自己年薪能够超过5万，8万，10万。。。的时候，他们可能做梦也想不出精英阶层手中究竟拥有多少财富。</p>
<p>精英们会象流氓无产者们一厢情愿认为的那样：因为一个区区房产税而恐慌性抛弃手中的大量房产吗？</p>
<blockquote>
<p><strong>liougehooa：</strong></p>
<p>”因为一个区区房产税而恐慌性抛弃手中的大量房产吗？“ 现在不说哪个富豪不是靠偷税漏税爆发的，我就举个例子，一套房不收税，二套房也不收税，三套房收300%税，你龟儿子还敢买三套房？</p>
<p><strong>kkndme：</strong></p>
<p>你说的事情在历史上已有发生，大明律明令禁止超标准建房，如果违禁，不仅仅是收税的问题，而是打板子下大狱，没收充公的，比房产税可要狠多了。但是终究没能执行下去，原因在于官员太腐败，不符合官员地主阶层的利益，最后名存实亡了。光是梗着脖子叫唤是没有用的，利益驱动着社会的发展，违背统治阶层利益的事情即使出台也难以执行，最后的下场都是不了了之。</p>
</blockquote>
<p>答案显然是否定的。</p>
<p>可以确认的是，房价不是由统计局的平均收入决定的。而是精英的平均收入决定的。</p>
<p>为了便于分析，我们剥离掉商品房（注意：只是商品房，而不是房屋）的社会属性，先把它看做商品。是商品就有他的内在规律。</p>
<p>什么决定商品的价格，价值？对不起，我只能说你上学上傻了。</p>
<p>是供求关系，只有供求关系。</p>
<p>我们判断一个核心城市市区内的商品房是具备足够稀缺性的。</p>
<p>如果你在北京海淀区上班，即使你在山海关拥有1000平方米的住宅也不能替代你住在北京市近郊区以内的愿望。而无论你是租房，分房还是买房，只要你还在海淀区上班，你就必须住在北京市近郊区以内。</p>
<p>假设你挣得钱不足够多，你需要租一套房子解决你的上班问题，上班距离的远近及居住的质量，取决于你愿意支付的租金。</p>
<p>假设你的钱够买房子，我相信你更愿意买房，因为你可以拥有房屋的产权和房产增值的收益。而买房子的大小，品质，离你上班的远近，取决于你手中的资金和你对未来收入的预期。</p>
<p>买房问题很象是中国的上学问题，而且简直是异曲同工。</p>
<p>假设你家附近有个重点中学，教学质量很好，考大学几率很高，而其他的学校你觉得不理想，你肯定希望无论如何自家小孩也要上这个重点中学。</p>
<p>上重点中学凭什么？我们简单的剥离掉其他社会因素的影响，可以认为想上重点中学就要凭好成绩，小孩努力考到前多少名，就可以上重点中学。这与努力赚钱买房是一个道理，有钱的出高价就能买到好位置好环境的房子。</p>
<p>我们再加入社会因素的影响，比如某大人物看到这个中学很抢手，很可以赚一笔，于是就设计了加分项，谁给自己送的钱多，就给谁加分，于是小孩要上重点中学不但要考高分，还要送钱加分。</p>
<p>同理，当好位置的商品房成为稀缺资源，各类炒房客的出现是必然的。</p>
<p>如果说炒房客加高价给最终住户的行为会产生泡沫，那么重点小学和公立幼儿园高昂的择校费应不应该也叫做泡沫？</p>
<blockquote>
<p><strong>liougehooa：</strong></p>
<p>”如果说炒房客加高价给最终住户的行为会产生泡沫，那么重点小学和公立幼儿园高昂的择校费应不应该也叫做泡沫？“ 你拿一个错误的现象，说这个现象是正确的来证明你错误的房价观念是正确的，可笑！</p>
<p><strong>kkndme：</strong></p>
<p>事情不能简单用正确还是错误来评价，一件事物发生一定有发生的原因。你说皇帝统治老百姓，想杀谁杀谁是正确还是错误？如果是错的，但是却在中国延续了几千年。</p>
</blockquote>
<p>尽管炒房和公立幼儿园加价成为普遍的社会现象是令人痛心的，但它们不以刚需人群的意志为转移的存在着，且与泡沫无关。</p>
<p>最被提及与泡沫有关的是以下两点：</p>
<p>第一，中国的房价甚至高于某些发达国家的房价。</p>
<p>其实，众所周知的是：不光房价高于某些发达国家，石油，高速，教育，医疗，税收等费用都远远高于某些发达国家。</p>
<p>而且中国的精英人群尽管所占比例不大，但是绝对数量足够大，而且精英平均收入甚至远远高于某些发达国家的收入水平。</p>
<p>第二：租售比问题</p>
<p>这个问题不用过多解释，使租售比更合理的方法不是只有降低房价一种，还有一种更靠谱的：房租大幅度上涨。而且已经在行动中。房租长期保持低价就像1990年以前的和田玉长期保持低价一样不可能。</p>
<h3><span id="3-房价上涨造成物价上涨人民生活变得困难">3、房价上涨造成物价上涨，人民生活变得困难</span></h3><p>这个问题其实也不用多解释，懂经济学的该明白自然会明白，不会轻易被忽悠，不懂的解释半天也不会明白。</p>
<p>简单的可以这样说，物价上涨是经济过热，钞票印多了的后果。而房地产因为稀缺性和易保存比较吸金，所以吸收了大量的钞票，以至于大家光看到了房地产的飞涨。</p>
<blockquote>
<p><strong>liougehooa：</strong></p>
<p>”而房地产因为稀缺性和易保存比较吸金，所以吸收了大量的钞票，以至于大家光看到了房地产的飞涨。“</p>
<p>房价高涨，你要发的钞票必须要多，不然怎么去买房子？你发的钞票越多，钞票不是你发下来去买房子就死掉了不流通了，它只要流到人的口袋或者银行的口袋，这钱立马回出现流动，能不造成通货膨胀吗？除非这笔钱收到后限制房东使用。<br>为了支持高房价，国家必须发大量货币，这也是去年房价高涨的原因。</p>
<p><strong>kkndme：</strong></p>
<p>请先了解一下中国的货币发行制度，人可以无知，但不可以乱说。让人笑话。</p>
</blockquote>
<p>其实如果房地产交易量下降，不再具有吸金功能，那么农产品等生活必须品以及房屋租金等等就会大幅上涨。这是因为多出来的大量钞票总要有个流向，如果不被房地产吸收，就会被大蒜，绿豆，姜，及全部生活必须品的上涨来吸收</p>
<p>事实也证明确实如此。2010年房产调控后，物价上涨的势头非常迅猛。</p>
<h2><span id="调控的真正目的防范金融风险-amp-通过垄断实现gj利益最大化">调控的真正目的：防范金融风险 &amp; 通过垄断实现gj利益最大化</span></h2><p>那麽是不是房地产就没有泡沫呢？</p>
<p>这个问题谁也不知道，因为到现在zf拿不出一份权威的数据来说明房地产到底有无泡沫。</p>
<p>但是房价高了就有风险，zf从感性上还是有清楚认识的。</p>
<p>注意，我们前面啰嗦了很多，现在才开始接近这次调控的真实意图。</p>
<p>防范金融风险？不错，你说的很对，但是没这么简单。</p>
<p>辨别利益是看透一切事物真相的武器。</p>
<p>高房价谁是受益者？</p>
<p>房地产游戏的模式三个环节：dfzf卖地、银行贷款、开发商在二级市场销售</p>
<p>dfzf卖地之后，剩余的风险和收益都归银行和开发商</p>
<p>dfzf卖地的款则用于地方广场，地铁，公路之类的建设和权贵的挥霍。</p>
<p>dfzf只负责卖地，是无风险的买卖。</p>
<p>只要房价不断上涨，加杠杆的炒房客就会赚到盆满钵满</p>
<p>这么分析下来，最受益的地方政府、开发商、炒房客。</p>
<p>独独缺了zy。</p>
<p>这时你是否猜到zy为什么要调控？如果还猜不到没关系，听我道来。</p>
<p>纵观古今，上位者最不能容忍的是别人受益，自己被黑锅。</p>
<p>大kfs，小kfs，大炒房客，小炒房客，dfzf都是收益者，但是风险却由zy来抗。这是一笔很不划算的买卖。</p>
<p>而房地产混战的局面，造成了国家队央企成员只有凭财大气粗高价拿地的份，钱花的最多，风险却抗的最大。</p>
<p>zy深深的感觉到要想国家队受益，要想控制风险只有做到两个字：垄断。</p>
<p>提高资金门槛，让小kfs，小炒房客，有点钱的小老百姓推出这个游戏。房地产很好玩，但不是小人物应该玩的。</p>
<p>先让市场冷静，彻底整顿，踢出那些个跳梁小丑，然后国家队出马，绝对垄断的市场，才能够统一定价，才能够控制风险，才能够利润最大化。</p>
<p>既然油价高于美国是合理的，那麽房价高于美国一定也是合理的，关键在于垄断。</p>
<p>不仅仅是房价的垄断，因为过高的垄断定价将会使交易量下降，国家队也需要资金周转。</p>
<p>真正厉害的，还是房租的垄断。公租房的推出是房租垄断进程的里程碑。</p>
<p>至于苦等廉租房的同志，不要抱太大的希望。城市要建设，地铁，广场，政府大楼都要上马，钱从哪里来？不会无缘无故凭空出来。</p>
<p>想想小学就近上学，但是重点小学真的就近就能上吗？小学名额可以寻租，经适房，廉租房也是一个道理。</p>
<blockquote>
<p><strong>tjOOSAN：</strong></p>
<p>真扯啊~~~ 油价跟房价去比？？</p>
<p>这位kkndme ，你就别忽悠了！~~</p>
<p>汽车对于百姓而言，可有可无，油价涨到是美国的一百倍，中国百姓才高兴了。</p>
<p>大哥！房子是必须品。ok？那么既然你也认为政府的钱大多从地产来。</p>
<p>那么这种发展正常嘛？会持续吗？？没有实体经济，能行吗？</p>
<p>招你的法子说，炒楼才是中国的前途？</p>
<p><strong>kkndme：</strong></p>
<p>这位兄弟，您比那些希望钱钱去炒大米的还不靠谱。</p>
<p>石油影响的不仅仅是开车的人花费多了。疯狂上涨的运输成本会导致民不聊生的。</p>
<p>假设一斤蔬菜从广西的农民地里收购是0.5元一斤，但是由于油价的像你说的上百倍的涨，运到北京，这斤蔬菜要卖300块一斤。</p>
<p>社会就瘫痪了</p>
<p><strong>tjOOSAN：</strong></p>
<p>那么这种发展正常嘛？会持续吗？？没有实体经济，能行吗？</p>
<p><strong>kkndme：</strong></p>
<p>实体经济的发展不是简单的钱不去投资房产，就会去投资实体经济，实体经济就发展起来了。估计媒体洗脑洗的比较厉害，你中毒了。</p>
<p>资本是趋利的。无论是哪个国家，哪个社会，只要存在市场经济，这个道理就一定不会错。</p>
<p>为什么资金进入房地产及其他资本市场而逃离实体经济？是因为实体经济环境不好，不赚钱。</p>
<p>一是税赋太高，二是各种需要打点孝敬的部门、管理人员、工作人员太多，比税赋还高，不能承受之重。三是国家队在各个重要领域的垄断，使国企变成了变相税务局的职能，垄断企业的暴利定价，又是压在本应该蓬勃发展的实体经济上的又一座大山。</p>
<p>现在央企基本是不垄断的行业不做，把产能过剩，充分竞争的产业交给民间资本，并且还要给这些资本压上高昂的负担.</p>
<p>有可能垄断的行业包括房地产都会收到国家队手里，以后更是将发展成为一个高度垄断的社会。</p>
<p>资本不是傻子，一定会趋利，所以资本放弃了操心受累不挣钱的实体经济，转而投向房地产。房地产的调控，让资本又进入了黄金、农产品领域参与爆炒，反正就是不进实体经济。因为国家不给实体经济的环境做任何的改善。</p>
<p>如果实体经济有一个好的环境，有一个好的获利空间，大量的资金就不会撤出实体经济，没有资金潮涌般的投入房地产市场，中国的房地产将会是一个平稳的上涨趋势。</p>
<p>但是体制决定了资金的去向，不以人的意志为转移。</p>
<p>高税赋、暗箱成本及垄断不但造成巨大的贫富差距，而且将会导致生活成本的大幅提高，生活负担日益沉重。</p>
<p>一方面百姓生活负担的加重，导致一些非生活必须品严重产能过剩，将会出现大量亏损倒闭的内需企业。</p>
<p>另一方面精英阶层快速聚集大量财富，使奢侈品供不应求。古董，字画，玉器，豪车，顶级服装的消费比重也将越来越大。</p>
<p>但是能够容纳大量资金的只有两个领域：农产品领域（满足老百姓的肚子）和商品房领域（居住权要满足老百姓的需求，产权要满足精英阶层的需求）。</p>
<p>资金的流向只能疏导不能强堵，zf很明白这个道理。两者危害取其轻，你认为zf会选择哪个领域？</p>
<p><strong>tjOOSAN：</strong></p>
<p>真扯啊~~~ 油价跟房价去比？？</p>
<p>这位kkndme ，你就别忽悠了！~~</p>
<p>汽车对于百姓而言，可有可无，油价涨到是美国的一百倍，中国百姓才高兴了。</p>
<p><strong>vavan2010：</strong></p>
<p>这种人肯定最后就是蠢死的。你没车，不用汽油，你可知道生活中有多少东西是需要用汽油的？无知才最可悲！</p>
<p><strong>kkndme：</strong></p>
<p>我们为确实买不起房的低收入群体，只能感到无奈</p>
<p>但有些本来能买房却嫌这嫌那而不买房的傻空通知，我们只能说你买不起房，完全是自己的原因，连油价上涨意味着什么都搞不懂，贫穷真的不能怨别人。</p>
</blockquote>
<h2><span id="官方公布的统计数据只要关系到某个群体的利益就一定会被修饰导致失真">官方公布的统计数据，只要关系到某个群体的利益，就一定会被修饰导致失真</span></h2><p>说到房产泡沫的问题，就不得说说官方的统计数据。</p>
<p>官方的统计数据从来是可以很雷，但不可以很真。</p>
<p>我们的统计原则基本就是：村骗乡，乡骗县，一骗骗到国务院。</p>
<p>不知道有人去市、县、乡、村进行过社会调查没有？</p>
<p>社会调查是怎么一回事？</p>
<p>我来告诉你，所有的关于人口、收入、田地、贫困户的数据都是官方统一编写，统一口径，如果胆敢有哪个小民对调查人员乱说，那是吃不了兜着走的。</p>
<p>你问了数据编来编去的意义在哪里呢？</p>
<p>意义很大，起码跟向上申请拨款是关系非常密切的。数据不假，钱从哪来？</p>
<p>统计数据无所谓是否真实并不重要，重要的是它是获取利益的重要手段。</p>
<p>假设官方想证明房地产不存在泡沫，那么一定拿的出不存在泡沫的统计数据作证。</p>
<p>反之，也一样。</p>
<p>好比,CCAV为了证明高空置率的结论，派出记者专门找偏远且刚刚完工的楼盘，进行了一次纯粹为了证明内部已事先得出结论的毫无科学依据的调研。</p>
<p>而dfzf，为了证明刚需多么强劲，也立刻拿出了选择性失明的统计数据来进行回击。</p>
<p>无论是左还是右，同样都是不科学，都是现有结论，再有证据。</p>
<p>我们到底应该信谁</p>
<blockquote>
<p><strong>cdw1：</strong></p>
<p>商品房本来名字中就有商品二字不准投资岂不是笑话？真正不准投资的那叫公房，这才是保证老百姓有房住的关键，商品房诞生的时候就很明确是改善居民居住条件的，现在政府怪商品房价格过高造成老百姓没房住本来就是颠倒黑白，政府不造保障老百姓居住的公房，而让老百姓去购买改善居住条件的商品房来解决本该政府解决的居住问题，政府不作为才是造成老百姓出现居住问题的罪魁祸首。我不期望人人有房，我只希望每一个在城市里找到工作的人通过努力工作勤俭持家能在生活城市里有希望拥有一套安稳的房子来容身，不管这房子的性质是商品房、经适房、廉租房或者其他什么房子。</p>
<p><strong>kkndme：</strong></p>
<p>你说的正是根源所在啊，zf的职责应该向无房者提供的保障房，建成经适房、两限房，被权贵占有牟利，而非要把商品房赋予稳定社会的职能。zf不是不知道问题的根源，而是不愿意放弃巨大的利益。</p>
</blockquote>
<h2><span id="税收从来都是向下游转嫁的-amp-房产税迟迟不出台的真正原因">税收从来都是向下游转嫁的 &amp; 房产税迟迟不出台的真正原因</span></h2><p>闲扯了一下统计数据</p>
<p>还是回到这次调控中来</p>
<p>房地产游戏的模式三个环节：dfzf卖地、银行贷款、开发商在二级市场销售</p>
<p>dfzf卖地之后，剩余的风险和收益都归银行和开发商</p>
<p>dfzf卖地的款则用于地方广场，地铁，公路之类的建设和权贵的挥霍。</p>
<p>dfzf只负责卖地，是无风险的买卖。当然还有人企图利用流氓无产者和无知群众的群情激奋来进一步收取房产税来提高dfzf收入。</p>
<p>税收从来都是向下游转嫁的，zf多收出来的钱一定是通过最下游的房租来体现。</p>
<p>当然，也有很多明白人士大声疾呼反对房产税。</p>
<p>自古而今，即使最辉煌的朝代，最被广大群众津津乐道的太平盛世，普通群众也仅仅只是解决了温饱而已，包括贞观、文景、康乾。</p>
<p>国家的富庶都是以老百姓勒紧裤腰带为代价的。</p>
<p>所以，zf是不会理会部分明白人反对房产税的呼声的。</p>
<p>真正对房产税的顾及来自于dfzf对土地出卖前途的担忧，真是鱼与熊掌不可兼得。</p>
<p>尽管流氓无产者和无知群众的呼声很高，然而房产税征收一旦实际操作起来，就会变的不得人心，征收难度非常之大，实际效果难以预知。也就是说zf没有底。而如果房产税征收效果不佳，dfzf卖地收入再受到巨大影响，那就真正是得不偿失了。</p>
<p>就会变成赔了夫人又折兵。</p>
<p>这样的买卖，zf是不会轻易做的</p>
<h2><span id="房地产的现状">房地产的现状</span></h2><p>房地产的现状是，商品房二级市场是由各种类型的开发商自由竞争的，一手房开发商之间的竞争，二手房投资客之间的的竞争。</p>
<h2><span id="房价持续上涨的本质是稀缺性让好房子成为资金最好的去处">房价持续上涨的本质是稀缺性让好房子成为资金最好的去处</span></h2><p>房价为什麽在一个自由竞争的市场上能够持续上涨？因为稀缺性。不是房屋的稀缺性，而是房屋所必须占用的土地的稀缺性。</p>
<p>有些群情激奋的群众立刻以6500万套房子空置的事情提出质疑，还有ccav的报道，那是要多煽情又多煽情。</p>
<p>我们无需说6500万套的真实性（明白人都知道非常离谱）和空置我心的科学性。为什么不说，因为这种稀缺性跟空置率就完全没有关系。商品房的稀缺性是相对人民币而言的。人民币印多了，资金没地方去，商品房就涨价了。</p>
<h2><span id="关于垄断">关于垄断</span></h2><h3><span id="1-垄断的好处是没有风险">1、垄断的好处是没有风险</span></h3><p>垄断的市场是没有风险的，土地是完全垄断的，所以dfzf完全没有风险。</p>
<p>而商品房是自由竞争的市场，是具备风险属性的，尽管由于大量印钞造成了商品房的飞涨，但随着房价的高涨，风险也在积聚。</p>
<p>dfzf土地垄断没有风险，完全可以置身事外。</p>
<p>可是银行呢？属于国家的银行。</p>
<p>银行正在承担自由竞争市场房价高涨积聚的风险。</p>
<p>这是zy不允许看到的，dfzf受益，而风险全部甩给zy。</p>
<p>既然垄断的市场是没有风险的，那还是让房屋和土地一起垄断好了。</p>
<h3><span id="2-垄断可以解决社会稳定">2、垄断可以解决社会稳定</span></h3><p>垄断还可以解决一个问题：社会稳定。</p>
<p>常被媒体和群情激奋群众所提及的一个重要问题就是：房价收入比。</p>
<p>大量印刷的人民币促成了房价高企（因为商品房实在是具备了大资金需要的所有投资品属性），可是那些个巨额的资金普通老百姓并没有见到。</p>
<p>路人甲：我们一个月就挣2000多块钱，干一辈子买不起房啊。</p>
<p>路人乙：我一个月上万都买不起房。</p>
<p>媒体：一个家庭不吃不喝22年买一套房</p>
<p>大量的疯狂印刷的人民币在哪里呢？</p>
<p>在精英手里。</p>
<p>我们在回顾一下开篇，我们奉行的是精英社会，丛林法则，金字塔式收入结构。</p>
<p>人民币再多，也不可能流到金字塔的底端。</p>
<p>dfzf垄断卖地也就让百姓们发发牢骚。</p>
<p>而炒房客，kfs赚的盆满钵满就让生活在中下层的老百姓眼红和不能容忍。</p>
<p>不患寡而患不均啊。</p>
<p>垄断，国家队的垄断，可以解决眼红问题，也就是社会稳定问题。</p>
<h3><span id="3-房屋垄断只会愈演愈烈底层人民想要拥有一套房子的难度只会越来越难">3、房屋垄断只会愈演愈烈，底层人民想要拥有一套房子的难度只会越来越难</span></h3><p>还有一个最重要的问题：银行和民营开发商之间，是官与民之间的问题。</p>
<p>而银行和国家队央企，是左兜和右兜的问题。</p>
<p>土地是垄断的</p>
<p>然而房屋垄断并不是一件容易的事情。</p>
<p>因为民间百姓手里是存在大量二手房的，当然这也是为什么调控的板子只打在二套房、投资客、炒房客身上的原因。</p>
<p>同样，房租的垄断也并不是一件容易的事情，因为民间百姓手中的大量二手房都具备出租的特性。</p>
<p>俗话说，问渠哪得清如许，唯有源头活水来。</p>
<p>要垄断，必须抓住源头。</p>
<p>源头在哪里？</p>
<p>在一级市场，而不是二级市场。</p>
<p>房地产的垄断就是要国家队从一级市场做起，从一级市场开发着手完成对商品房开发的垄断。</p>
<p>一级市场，那是一个高高的门槛，民间资金，就让他该干嘛干嘛吧，房地产不是你玩的。</p>
<p>一级市场包括的内容是一般开发商无法参与的：</p>
<p>城市规划，城中村改造，旧房拆迁，城市综合体开发。</p>
<p>可以说从规划、改造拆迁、开发、到二级市场销售，一条龙服务。</p>
<p>一级市场开发的最大特点就是可以创造需求：你不是有房子吗？我拆掉你的房子，看你有没有刚需。</p>
<p>国家垄断控制风险的意义还在于：需求可以拆出来。</p>
<p>以后的路，民营开发商的日子将变得越发艰难。</p>
<p>土地是dfzf的，商品房开发是央企和国企的。</p>
<p>处于金字塔下层的40%家庭，如果还没有一套自己的房子，那么买一套自己的房子就越发的变得不可能。</p>
<p>商品房将逐渐往金字塔的上层积聚。</p>
<p>处于金字塔下层40%的无房家庭将只能以租房来解决居住问题。</p>
<p>租金的快速上涨期即将到来，zf已经盯上了房租这块巨大的蛋糕。因为房租的收益比房产税更靠谱，更具有操作性。</p>
<p>公租房，呼之欲出</p>
<h2><span id="民生问题">民生问题</span></h2><blockquote>
<p><strong>sunxinmfc：</strong></p>
<p>政府无需考虑民生问题么，本次号称史上最严厉的打压政策再起不到一点效果，ZF威信力将进一步下降，需要仔细考量</p>
<p><strong>kkndme：</strong></p>
<p>自古以来，民生问题的底线就是不要出现陈胜吴广的极端情况。所以zf更在意的是农民问题。</p>
<p>因为历史的改朝换代都是大饥荒引起的，无论是汉末、唐末、隋末、还是明末。农产品价格上涨的对zf的震动要远远大于房价的上涨。</p>
<p>农民具备最原始的力量，而他们关心的并不是三线以上城市的房价，而是能否填饱肚子。</p>
<p>而关心自己能否拥有一套产权房的都市白领，除了呻吟一下意外，几乎是没有什么有效反抗的可能的。</p>
<p><strong>sunxinmfc：</strong></p>
<p>秀才造反，三年不成，自古已然。</p>
<p>但我们还没有谈到所谓“造反”的地步，只是说房价如你所述，暴涨，中国的中产和以上人士将进一步携款合法外流（在房价暴涨的09年，中国外流人口达到历史峰值）。这一部分人利益如何保证？您觉得zf不需要考虑对么？</p>
<p><strong>kkndme：</strong></p>
<p>现在社会跟几百年前最大的不同是，世界是开放的，这得益于地理大发现和世界经济一体化，即使缅甸朝鲜这样封闭的国家也免不了受到来自世界范围的影响。大一统的集权社会融入了西方民主的思想，同时互联网的出现也让人们对过去的思维进行了再思考。</p>
<p>尽管底层百姓出国还是一个梦想，但对于精英人群，基本上是在世界范围自由流动的。</p>
<p>中国自古以来，商人都是没有地位的，商人的财产可以随时被官员没收，自古如此，至今如此，即使是今天也并没有出现私人财产神圣不可侵犯的宣言。即使出现了，也没有任何可以操作的可能。</p>
<p>明朝以后大量的商人移居海外成了华侨，现今的商人为了安全移居海外也不是什么新鲜事，不过是步明朝华侨的后尘罢了，zf会真的放在心上吗？朱元璋没有放在心上，朱棣没有放在心上，现在同样也不会放在心上。</p>
<p>真正可怕的是官员一方面谋取私利一方面把亲属和存款送到国外，这其实是一种国家背叛。在国内榨干老百姓的血汗，得到的金钱却在国外挥霍。什么叫卖国，不过如此。</p>
<p><strong>connstr：</strong></p>
<p>假如商人可以移居海外，官员自然也可以。官商能分家吗？</p>
<p><strong>kkndme：</strong></p>
<p>商人还是要分的吧：红顶商人就是官商，统治阶级，那是上位者。</p>
<p>普通商人，比如开个袜子厂赚个辛苦钱，最后袜子厂不挣钱了，官员还天天找他，让他孝敬，他就只好移民了。</p>
<p>普通商人在中国也是海量的，有点钱，但是没一点地位。</p>
</blockquote>
<p>中国自古以来都不是人人都能有属于自己的房子，大量的丫鬟、仆妇、管家、小厮寄养在权贵人家，身体都是不自由的，何谈拥有自己的房子。</p>
<p>自古以来，最多的就是失去土地的农民，住在地主家做长工，又何谈属于自己的房子。</p>
<p>只要是有贫富差距的社会，只要存在阶级，只要存在统治和被统治，这个社会就会不以人的意志为转移的出现大量的底层居民，没有这些底层居民。权贵就不能很好的生活。</p>
<p>为了权贵生活的更好，就要维持大量的底层群众。</p>
<p>权贵必须保证大量底层群众的基本生活，才能够让自己过得更舒服，仅此而已。这就是民生</p>
<blockquote>
<p><strong>sunxinmfc：</strong></p>
<p>删掉了一大段，不得不说，你说的很对。</p>
<p>（呻吟一下）。君不见，天涯上多少盼着被美军解放的铁杆准汉奸，政府楼被炸七成网民不是替死者默哀，而是一片欢呼。为什么会有这样的民意，参考前苏联，ZF确实应三思</p>
<p><strong>kkndme：</strong></p>
<p>爱国是与中华的历史分不开的，自秦统一以来，中国由封建时代转变为帝国时代，只有在项羽焚烧咸阳后，对诸侯进行了一次分封，但时间非常短暂，刘邦重新统一了天下，帝国时代经历了漫长的汉、唐、宋、元、明、清。天下一统的爱国情结是根深蒂固的。</p>
<p>而在秦以前，与中世纪的欧洲是极为相似的，齐国人可以到秦国做宰相，赵国人可以到燕国做将军。中世纪法国的诺曼底公爵可以到英格兰继承王位，瑞典的贵族可以到基普做大公，封建时代的国家概念并不是明显。欧洲经历了漫长的封建时代，国家观念很淡薄，能够抛弃国家货币成立欧盟就是明证。这对于漫长帝国时代，天下一统的国家是很难想象的。</p>
<p>爱国只跟历史文化传统有关。</p>
<p>1978年越南入侵红色高棉，当时的红色高棉对内实行红色恐怖，以gongchanzhuyi的名义对全国700万人口进行奴役和屠杀，总共屠杀了100万人。当越南军入侵时，受到了广大柬埔寨群众的热烈欢迎，称越南军解放柬埔寨是解放人类的战争。</p>
<p>红色高棉失去了民心，必然败亡。</p>
<p>那时，为了支援红色高棉，中越战争打响。有我国的强力支持，红色高棉仍然走向败亡。</p>
</blockquote>
<h2><span id="房产税的制定原则">房产税的制定原则</span></h2><blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>不过从政府要分租房市场的蛋糕而言，我有不同的看法</p>
<p>政府的公租房要想租出好价格，有两种方式</p>
<p>1）减少市场可出租房源（北京就这样干了，拆迁廉价城中村）</p>
<p>2）提高竞争房源的成本。（所以我认为推出房产税是大概率的事情，因为政府的公租房是不需要交房产税的）</p>
<p>于是竞争房源的房租暴涨，政府的公租房也就可以羞羞答答的打个9则来</p>
<p>安抚一些底层了，反正所有的黑锅都有竞争房源的房东背了</p>
<p><strong>kkndme：</strong></p>
<p>房产税的问题我觉得zf还是慎重的</p>
<p>1、如果采用不公平法则：</p>
<p>公务员，垄断企业，事业单位的福利房不上税，权贵与利益集团购买囤积的大量商品房不上税，只有普通百姓上税，会加剧社会矛盾，而房产税会大幅提升租金，在公租房没有大量建起来之前，对稳定不利，维稳才是第一要务。</p>
<p>2、如果实行公平法则</p>
<p>小产权房，福利房，权贵囤积房都要上税，执行难度太大，可操作性不强，阻力几乎难以逾越。</p>
<p>如果真的收房产税，采用不公平法则的可能性最大，普通的无房百姓生活将变得非常艰难。</p>
</blockquote>
<h2><span id="维稳的本质是人民能吃饱饭">维稳的本质是人民能吃饱饭</span></h2><p>维稳问题其实最终还是吃饭问题。</p>
<p>房价上涨可以不买，如果房租价格不能控制，农产品价格不能控制。一旦大批群众吃饭出现了问题，维稳就无从谈起了。这个底线，还是要严守的</p>
<h2><span id="公租房是为体制内服务的">公租房是为体制内服务的</span></h2><p>说到公租房问题</p>
<p>首先还是要提到我们实行的双轨制</p>
<p>从某一方面可以简单的理解为统治阶级内和统治阶级外。<br>也就是我们常说的体制内，体制外。</p>
<p>体制内：公务员、垄断企业及医院高校科研院所等事业单位。</p>
<p>体制外：外资、私企打工者，个体工商户，农民，这里面也应当包括高层的老板和最底层的长期无业人员。</p>
<p>我们感受最深的就是涨工资的问题，一旦政府涨工资，那就一定是体制内涨工资，跟体制外完全没有关系。在金融危机的08年，大批企业关门，减薪，裁员，美国欧洲因为钱紧不得不降低公务员薪水。而这时，我们神奇的国家在干一件事：公务员普遍加薪，是为了全国百姓着想—刺激消费。</p>
<p>还有保障房问题，这个也是我们感受最深的：保障房=公务员及垄断企业住房；解决住房问题变成了如何让领导干部住更多更大的房子，如何让体制内员工拥有足够舒适住房的问题。</p>
<p>体制外的群众，那是别想得到一点好处的。谁让你是被统治阶级呢。</p>
<p>公租房的推出，也要解决两个问题：</p>
<p>1、体制内的最下层（最下层也是统治阶级，也就是是古代官吏中的吏）员工的基本住房问题</p>
<p>2、向体制外被统治的小民稳定收钱的问题。</p>
<h2><span id="房产税一定会转嫁给租房人">房产税一定会转嫁给租房人</span></h2><blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>对公租房的问题受教了</p>
<p>不过当前从来不存在什么公平正义</p>
<p>税收向来是穷人多交，富人不交或少交</p>
<p>不过我很感兴趣的是假如推出了房产税</p>
<p>政府采取何种方式收</p>
<p>难道是如同鬼子进村了，挨家挨户的收？</p>
<p>但鬼子本身就是房产税的征收对象（不然也当不了鬼子）</p>
<p>他们自己都抵制，难道还指望他们向屁民收</p>
<p>遇到那种要钱没有，要命有一条的主</p>
<p>难道政府还开拖拉机来收？</p>
<p>5年前就叫嚣对房租收个人所得税</p>
<p>到现在也没有个影了</p>
<p>操作性实在太差</p>
</blockquote>
<p>房产税无论是持有环节征收，还是交易环节征收都是要向最终租房人转嫁的。</p>
<p>好比鸡饲料上涨没有可能鸡肉不涨价，但是养鸡的并没有赚更多钱。</p>
<h2><span id="巨大的税收消耗也决定了gdp必须快速增长-amp-公务员越精减越多">巨大的税收消耗也决定了GDP必须快速增长 &amp; 公务员越精减越多</span></h2><p>降低百姓租房困难的唯一国际通行办法就是减税。但是减税，在我国是很难行的通的。一个高增长高通胀的国家，高昂的腐败成本和巨大的浪费将导致国家必须维持高税收才能维持运转，gdp保8实际上是必须的也是迫不得已的。维持正常的运转，维持庞大的消耗税收而不是创造税收的公务员队伍，没有gdp快速的增长怎么可能呢。</p>
<blockquote>
<p><strong>feiying：</strong></p>
<p>这种看法很有道理，但保8毕竟会有个尽头，一旦走到头了那怎么去做呢</p>
<p><strong>kkndme：</strong></p>
<p>对于小富即安的我等小老百姓来说，希望此生不要见到这一天的到来。</p>
<p>对于流氓无产者来说，盼望着这一天的到来。届时新的英雄将从流氓无产者中产生。如同威武的 同志。</p>
<p><strong>艾馨999：</strong></p>
<p>我也觉得应精减公务员，也许减掉三分之二房价就见效了，呵呵。中国确实存在很多不应有的机构。</p>
<p><strong>kkndme：</strong></p>
<p>千万不能精减，越精减越多。<br>一般裁减公务员都是专门裁那些没背景，没关系，不会拍马屁，傻干活的。而留下的就是有背景有关系，会拍马而不干活的。<br>当傻干活的公务员被裁掉以后，剩下的不干活的公务员照样不干活。<br>于是政府发现没人干活了，人不够用了，再大批量招人，所以越精简人越多。<br>这就叫精减膨胀</p>
<p>特别是把熟悉业务的熟手减下来后，不得不招3个新手才能顶的住。等新手熟练了，人又富裕出来了。<br>精减膨胀这是不可更改的。<br>千万别精减，谁提出精减跟谁急，到时人民更没活路了。</p>
<p><strong>跳坑的青蛙：</strong></p>
<p>楼主关于精简膨胀的见解很精辟~<br>很多事情看起来、听起来很美，也仅仅是看起来、听起来而已，<br>有丰富生活经验的人仔细思考一下、观察一下就不是那么回事了~</p>
<p><strong>kkndme：</strong></p>
<p>是啊，很多空空们扯着脖子呼喊这个政策那个政策，殊不知执行下来，最倒霉的还是自己。管老爷利用空空们鸡冻的心情趁机敛财，赚个盆满钵满。等空空们明白过来，也没办法了。<br>好比许多人最欢迎的费改税，结果税增加了，费却一点没见少。</p>
</blockquote>
<h2><span id="调控的好处是让zf利益最大化amp防范金融风险">调控的好处是让zf利益最大化&amp;防范金融风险</span></h2><blockquote>
<p><strong>骑自行车买别墅：</strong></p>
<p>就说政府为什么要调控？</p>
<p>难道就为了给你说的P民面子？？</p>
<p>如果房价一直暴涨，不更符合食利阶层的利益？房价低价一起彪～</p>
<p><strong>kkndme：</strong></p>
<p>真不知道你仔细看了没有。我通篇也没下过调控是为了给P民面子的结论。</p>
<p>调控的根本原因还是zy在房地产的游戏中没有得到好处。调控是为了让zy的国家队参与进来，成为主体。</p>
</blockquote>
<h2><span id="垄断可以控制价格维持稳定">垄断可以控制价格，维持稳定</span></h2><p>垄断的目的还在于能够控制价格，为了维稳，zy是不希望暴涨的，但也不希望不涨。</p>
<h2><span id="体制内的住房问题有国家保驾护航">体制内的住房问题有国家保驾护航</span></h2><p>回头还说公租房</p>
<p>在私企打过工的都知道，毫无归属感可言，老板脑袋一发热，随时让员工卷铺盖卷走人。那是要多没保障有多没保障。原因是社会关系，关键客户，都掌握在老板一个人手里，员工就是打个下手，一不爽了，就换人呗。</p>
<p>统治者可知道不能这么用人的。一个庞大的国家机器要想正常运转，必须得让手下的和自己的利益一致。如果自己吃肉，手下的连汤都没得喝，这个机器就转不动了。</p>
<p>因此，在房价高涨的时代，保障房才成为zy默认的公务员房、垄断企业房。<br>公租房首要解决的就是手下里面最底层人士的住房问题。<br>我认为针对于体制内来说，无论是公务员，事业单位，还是国有企业的初级员工，都可以通过所在单位申请公租房，公租房的租金会略低于市场，主要是单位一定会提供补贴。<br>体制外对公租房的申请就没有那么幸运了。</p>
<h2><span id="依靠但又不能完全依靠开发商建公租房">依靠但又不能完全依靠开发商建公租房</span></h2><p>钱的问题，dfzf也想到了解决的办法。</p>
<p>在卖地时就要求开发商配套建设一定比例的经适房、廉租房或公租房。<br>然而，羊毛出在羊身上，开发商不可能做赔本的买卖。经适房好说，反正是卖个住户，大不了利润很低，顶多挣得少点。而廉租房和公租房就纯粹是只见投入不见产出的（开发商可没资金没耐心收租子）。廉租房和公租房的建设成本必须加到所建的商品房身上，这肯定会抬高房价。<br>关键是拿地成本逐年上涨，孝敬的资金也在逐年上涨，在加上多出来的廉租房和公租房建设成本，房价不可能无限抬高的。开发商也需要资金回笼周转。房价越高风险越大只是无论zf，开发商，炒房客和买房群众都有的共识。只是房价多高才是高，不同的人理解是不同的。</p>
<p>显然，把大量廉租房和公租房的建设寄托在开发商配套身上是完全行不通的，不仅不能解决住房问题，还让本来就高企的房价更加雪上加霜。</p>
<h2><span id="体制内的住房问题不难解决">体制内的住房问题不难解决</span></h2><p>体制内公务员、垄断企业和事业单位的员工住房问题是不难解决的，因为有zf行为的强制意志在里面。</p>
<p>1、df划拨土地，征集开发商建经适房、公租房</p>
<p>2、dfzf强制要求开发商建配套经适房、公租房，建设成本就转嫁给购买商品房的冤大头吧。</p>
<p>3、体制内单位自有土地，集资建房。</p>
<p>多管齐下，体制内人员的住房不难解决，甚至体制内人员每人住好房子大房子多套房子的问题都不难解决。处于金字塔的中上层，他们俯瞰着芸芸众生。</p>
<h2><span id="解决体制外的住房问题国家垄断细水长流收租">解决体制外的住房问题：国家垄断，细水长流收租</span></h2><p>处于金字塔下层的体制外的广大群众怎么办？</p>
<p>体制内员工的住房舒适性和投资获利是首要保证的，不然光让干活不给好处，怎么能让手下听话呢？</p>
<p>体制外广大群众的住房问题也要解决，这关系到社会稳定。</p>
<p>能不能拿出一个办法，即解决了群众住房问题，又可以从群众手里长期获取收益？</p>
<p>细水长流收租子的事情开发商做不了，但zf可以做。</p>
<p>公租房，如果解决了钱的问题，面向广大群众的公租房的推出，将会取得双赢的局面。</p>
<p>既然房地产开发最肥的肉留给了国家队，国家队也应该投身到公租房的建设中来。</p>
<p>国家队全面进场之前，大鱼小鱼虾米泥鳅，皆可得利。</p>
<p>不把小鱼虾米泥鳅赶出池塘，市场无法控制，风险无法控制，公租房建设也无从谈起。</p>
<p>二套房首付提高到50%，第三套房停止贷款，小开发商的清理整顿，民营企业在招拍挂中无论价高价低都无法取得土地，等等一系列重拳直击小鱼虾米。</p>
<p>土地将回到国家队手中，这个世界将变得清爽。</p>
<p>让时光倒流到80、90年代，我们的dfzf守着蕴藏着巨大财富的金矿、锡矿、铜矿却过着贫穷的日子。没有资金，矿山是没有办法变成财富的。于是招商引资，为了gdp,为了解决就业问题，出台了各种优惠政策，于是外商堂而皇之的走进来了。成为了这些矿山的主人。5年，7年或者10年，外商享受的免税期满的时候，外商卷着巨额财富走了，留下了一个个废弃的充满危险的大坑。这是血琳琳的教训，zf没有理由不吸取。外资、私企、小业主总有一天会让他们清场，尽管这一天晚来了十几年。</p>
<p>在土地日益稀缺的今天，房租难道不是可持续产出的金矿？让炒房客、投资客、民企开发商见鬼去吧。</p>
<blockquote>
<p><strong>kkndme：</strong></p>
<p>在土地日益稀缺的今天，房租难道不是可持续产出的金矿？</p>
<p><strong>百无一用一书生：</strong></p>
<p>如果人们宁愿住桥洞呢，如果人们决定离开呢，如果房租收入不断下降呢</p>
<p><strong>kkndme：</strong></p>
<p>宁愿住桥洞的早晚要当盲流处理的</p>
<p>逃离城市基本是一部分人被淘汰掉，选择，离开，而又有更多的人冲击去。</p>
<p>房租收入下降基本是做梦才会出现的事情，国家队的进场就是不让房租下降</p>
</blockquote>
<h2><span id="普通人买得起优质商品房就尽早买把">普通人买得起「优质商品房」就尽早买把</span></h2><blockquote>
<p><strong>懒兔爱散漫：</strong></p>
<p>楼主的意思是今后体制外的人（除最高层)外，是无缘商品房，只能住公租房了？</p>
<p><strong>kkndme：</strong></p>
<p>如果你现在还买的起商品房，那你就尽早买吧</p>
</blockquote>
<h2><span id="商品房和公租房的区别">商品房和公租房的区别</span></h2><blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>有个疑问</p>
<p>商品房和公租房相比，优势在什么地方？</p>
<p>那些楼裂裂的商品房估计质量还不如公租房吧</p>
<p>楼主应该加一句，买质量好的商品房</p>
<p><strong>kkndme：</strong></p>
<p>商品房和公租房的区别实际就是土地性质的不同，一个是出让，一个是划拨</p>
<p>出让那必须是招拍挂，那必须是天价。</p>
<p>划拨就基本算是白给，收钱就是象征性的意思意思。</p>
<p>是商品房还是公租房，土地的性质说了算，dfzf说了算。跟房屋质量没有关系。</p>
<p>一套房子假设20000一平，房子的价值也就占30%，剩余的都是土地的价值</p>
</blockquote>
<h2><span id="提议通过征普税调节贫富差距不是傻就是坏制定政策的人不会让政策针对自己那么政策都是谁制定的呢">提议通过征普税调节贫富差距，不是傻，就是坏（制定政策的人不会让政策针对自己，那么政策都是谁制定的呢）</span></h2><p>今天看到搜狐上一篇文章说道要通过征税来调节贫富差距，提出这个方案的人不知是无知还是故意，如果zf听了这种无耻参谋的建议，不知道多少老百姓会活的更惨。</p>
<p>假设出台又一个新税种，无乱它叫什么，我们暂定为财产税。既然有了新税种，就要定任务，那好了为了这个税种制定了年上缴多少多少的任务。</p>
<p>实操的时候，执行的工作人员发现一旦轮到权贵脑袋上的事就没办法执行，你执行，他先让你下课。</p>
<p>但是任务必须完成，那还是从普通老百姓身上打主意吧。于是政策就完全走样了，非但起不了劫富济贫的目的，反而加重了穷人的负担。</p>
<p>往近里说，个人所得税，挣的是谁的税？权贵没看见交，月薪3000块的工薪层可一个都跑不了。3000块月薪上缴的个人所得税你看着不多，可对于养孩子糊口的老百姓来说，哪怕10块钱都是重要的。他们可没有资本象月薪上万的小资一样动不动花500块钱泡个吧。</p>
<p>个人所得税是有任务的，工作人员必须完成任务，税别管是局级干部交的，还是连孩子幼儿园都上不起的穷光蛋交的，总之完成任务就是好样的。既然局长的税收不上来，就要从穷光蛋身上加倍收上来。</p>
<p>往远里说，王安石变法是怎么失败的，以史为鉴可以知得失。王安石的初衷难道不是好的吗，可结果怎么样呢？只有一个——民不聊生。</p>
<p>书生误国啊。</p>
<h2><span id="调控带来的影响">调控带来的影响</span></h2><p>许多兄弟关心房价什么时候会涨</p>
<p>那么先看看这次调控后都出现了什么样的现象。</p>
<ol>
<li>全国房产成交量大幅下降</li>
<li>一线城市房价略有下跌，但并不持续，到现在基本跌不动了</li>
<li>多数二三线城市房价不跌反涨，成交量逐渐回升</li>
<li>大多数二线以上城市租金持续上涨</li>
<li>农产品价格有上涨迹象，大蒜、姜等小品种农产品遭遇爆炒。</li>
<li>变化莫测的政策导致精英阶层出现移民潮</li>
</ol>
<p>还有什么，欢迎大家补充</p>
<h2><span id="农产品的价格关系到影响稳定的吃饭问题">农产品的价格关系到影响稳定的吃饭问题</span></h2><p>农产品价格的上涨是很值得警惕的。想买房子但嫌房子贵的都市白领对农产品的价格很不敏感，但是金字塔最底层的最大多数群众是很敏感的。领导们也很敏感。这牵扯到相当大比例人口的吃饭问题，稳定压倒一切。</p>
<h2><span id="农产品价格的抬头会导致物价全面上涨但国家不会坐视不管且有能力管">农产品价格的抬头会导致物价全面上涨，但国家不会坐视不管且有能力管</span></h2><p>农产品价格的抬头将会导致物价全面上涨，在不引起质变的前提下，房价作为商品也不例外。这个引起质变的前提是出现饥荒的极端情况，这样的几率在现在社会很少。尽管干旱和洪涝使农产品大幅度减产，但是农产品还可以进口，国家还有粮食储备，保证全国人民填饱肚子还是不存在问题的。</p>
<h2><span id="资金会在优质资产之间流动而决定优质资产价格的是精英阶层的购买力">资金会在优质资产之间流动，而决定优质资产价格的是精英阶层的购买力</span></h2><p>一线城市仍然沉默，国家队在积极运动。二三线城市的房价上涨的成交量的回升却给了市场一个明确的信号。这是资金运动的规律。国家队对一线城市的布局，迫使资金流向二三线城市。二三线城市相对（与一线城市相比）不高的价位给出了较大上升空间的预期。</p>
<p>全国富人买北京上海，全省富人买省会，房价的合理性已经不能用简单的本地平均收入来衡量。精英阶层的购买力才是关键。</p>
<h2><span id="资金流向规律决定了农产品和资产价格总有一个要涨人为压制一定会按下葫芦浮起瓢">资金流向规律决定了农产品和资产价格总有一个要涨，人为压制，一定会按下葫芦浮起瓢</span></h2><p>明年物价进入持续上涨期是一个不容回避的问题。</p>
<p>在资金总量不变的前提下，巨量资金推动农产品价格上涨或者推动房价上涨是一个必须的选择。</p>
<p>今年zf用行政手段严厉打击蒜和绿豆价格的暴炒，基本上没有起到作用，资金有自己的运作规律，光靠拿张悟本出气也不能解决问题。</p>
<h2><span id="资金流向规律决定了洼地不会一直是洼地">资金流向规律决定了洼地不会一直是洼地</span></h2><p>二三线城市的房价的上涨使与一线城市的差价缩小，为一线城市的发力提供了动能。</p>
<p>无论你喜欢还是不喜欢，都不是以人的意志为转移的</p>
<h2><span id="大城市对近距离的小城市有虹吸效应">大城市对近距离的小城市有虹吸效应</span></h2><p>许多人心怀房价肯定会跌回2004年的美好愿望，刻舟求剑似的思维错过了一次次购房的机会。在患得患失中，在牛刀的号角声中，在任志强的大炮声中，迷失了自我。</p>
<p>任何事物都是有其规律性的。关键是否有一双慧眼能够穿透重重的迷雾。</p>
<p>假设你是个投资客，你非要去石家庄和长沙买房子，结果发现不怎么升值，怨天怨地：</p>
<p>石家庄作为一个二线省会怎么会不涨？长沙的房价怎么那么低？</p>
<p>我们知道，北京的房子是全国有钱人买的，省会的房子是全省的有钱人买的。但是当省会城市距离一线大城市在6个小时高速以内，省里的有钱人的资金就会流向一线大城市，而不是省会。河北的富人一定会选择在北京投资房产，湖南的富人一定会选择广州深圳投资房产。</p>
<p>假设你是一个投资客，你去昆明旅行，发现昆明的房价甚至高过重庆，很不理解。你很疑惑昆明这么小的西部边陲城市投资价值在哪里？</p>
<p>昆明是云南省内唯一的大城市，且相邻的二线以上城市离云南省都比较远。云南地州资源丰富，虽然穷人占的比例大，富人的数量却也不少。昆明南有滇池，北有长虫山，作为一个700万人口的城市，土地资源非常稀缺。所以贵，一定有贵的原因。便宜一定有便宜的道理。</p>
<h2><span id="决定房价的因素有很多具体情况具体分析">决定房价的因素有很多，具体情况具体分析</span></h2><blockquote>
<p><strong>zzz4697：</strong></p>
<p>楼主针对南昌的房价做个分析吗？从刚公布的100个城市房子均价看，南昌5k每平左右，是高了还是低了？</p>
<p><strong>kkndme：</strong></p>
<p>对于不了解的城市不敢妄下断言。没到现场调查就没有发言权啊。</p>
<p>房价会不会涨还要看dfzf的规划。<br>比如广州拥有大量的城中村，其周边有较多的大城市，广州的房价就比北京和上海低。如果广州的城中村一旦大规模拆迁，房价将会大幅上涨。</p>
<p>比如南宁东盟贸易自由港的概念使南宁的房价涨幅惊人。</p>
<p>南昌的地理位置，zf规划，发展前景，江西富裕人口的多少，都是决定房价的因素</p>
</blockquote>
<h2><span id="房价暴涨是相对于钱而言的不是相对于实际购买力而言的">房价暴涨是相对于钱而言的，不是相对于实际购买力而言的</span></h2><blockquote>
<p><strong>tjOOSAN：</strong></p>
<p>。。。。。。暴涨之后。。。。。。</p>
<p>我们不就是第二个日本吗？</p>
<p>供求关系？供求关系，现在是谁在决定？国家！</p>
<p>国家的经济结构决定的。制造业的资金都进入房地产了。能不涨吗？普通人有几个可以够炒房资格的？</p>
<p>日本 当初也是供求关系！~~ 供求关系的根本也不应脱离，国家的经济实力！！</p>
<p>还暴涨？怎么涨？再涨都够去美国买房了！！ 你这不扯淡么</p>
<p><strong>kkndme：</strong></p>
<p>中国和日本最大的不同在于日本的货币是开放的，中国的不是，是不能自由兑换的。</p>
<p>暴涨是相对于钱而言的，不是相对于实际购买力而言的。</p>
<p>80年代工资200多块钱一个月的时候，是不能想象90年代末北京城区5000每平米的房价的。那时候万元户已经是富人的代表了。</p>
<p>90年代末工资1000块钱的时候是不能想象现在30000一平米的房价的。90年代的100万绝对是富裕群体。可现在连个中产都算不上。</p>
<p>货币的持续贬值你没有考虑</p>
</blockquote>
<h2><span id="土地不稀缺优质土地稀缺">土地不稀缺，优质土地稀缺</span></h2><blockquote>
<p><strong>tjOOSAN：</strong></p>
<p>在反驳楼主一句！！</p>
<p>在中国的土地，可不稀缺！~~ 只是没开发罢了！！~~</p>
<p>中国与世界不同！ok？13亿人！！用十三亿的居住权作为市场竞争的资本。</p>
<p>那太可怕了！真的！！！如果可能，中国绝对可以产出世界第一贵的地价！</p>
<p>为什么？这么多人需要房子。能不涨吗？</p>
<p>呵呵！多少有点扯淡！！别再提供求关系了！~~ 供求根本是平衡的！！</p>
<p><strong>kkndme：</strong></p>
<p>中国有13亿人口，960万平方公里土地，土地一点不稀缺。</p>
<p>但假设你在北京西城上班，让你去塔特拉马干买房子，你愿意去吗？</p>
<p>全国有点钱的都要在一线城市和省会城市买房子，所以才会稀缺。</p>
<p>大兴安岭有大量的土地，哪个有钱愿意跑去置业呢？</p>
</blockquote>
<h2><span id="集中发展大城市是导致优质土地稀缺的原因">集中发展大城市是导致优质土地稀缺的原因</span></h2><p>中国经济发展不平衡，牺牲全国大多数城市和乡村，来保证北上广深及大部分省会城市的繁荣才是造成土地稀缺的愿意。</p>
<p>土地有的是，房子有的是，但好位置的土地和房子并不多。</p>
<p>一方面大量的小县城和乡镇、村庄人口锐减，因为缺乏谋生手段不得不背景离乡外出打工，另一方面超大型城市越来越拥挤，土地资源越来越稀缺。</p>
<p>这就是中国集中发展极少数标杆城市所造成的呀，也是因为如此，才造成了中国金子塔式的收入结构，贫富差距越来越悬殊。</p>
<h2><span id="为人民服务是说给人民听的">为人民服务是说给人民听的</span></h2><p>很多人很疑惑，贪官越来越多，根本不把老百姓的利益放在心里，这些贪官即使被曝光了，还能继续当官。这是为什么呢？</p>
<p>首先理解一下老百姓，也就是民到底是什么？</p>
<p>民就是牛养，古代的时候，官员管理百姓叫做牧。官员管理百姓就是替君主放牧，只要保证牛羊不逃跑，不骚乱，那么就是合格的官员。</p>
<p>秦始皇暴政，百姓揭竿而起，可是陈胜起事后基本视民众如草芥，项羽屠杀平民比始皇更残暴。</p>
<p>萧何是一个很贤德的人，对百姓很好，赢得了很高的名声。刘邦在广武山和项羽对峙，得知了萧何在关中深受百姓爱戴，就疑心萧何要造反。一个君主爱民如子是为了百姓的支持，江山永固，一个臣子对老百姓好是不是要造反呢？于是派人去调查萧何。</p>
<p>萧何是个聪明人，感觉到刘邦已经不信任他了。于是赶紧改变工作作风，开始霸占百姓的田产，上大街欺负漂亮的妇女同志，并且派自己的子女上前线给刘邦做人质。</p>
<p>刘邦看到了萧何的行为非常高兴，知道萧何不会造反就放心了。</p>
<p>百姓不是牛羊是什么？</p>
<p>在红色高棉统治下的柬埔寨人，民连牛羊都不如呀。</p>
<p>波尔布特同志坚持gongchanzhuyi的按需分配，取消了货币。于是市场经济完全没有了。群众完全变成了按阶级分配了。</p>
<p>阶级只分为两种，波尔布特老板及其打手是绝对的统治阶级，其他人为被统治阶级，也可以称为奴隶阶级。统治阶级对奴隶阶级不爽可以直接拿ak47突突。柬全国700万人口被波老板突突死了100万，当然不光是突突，还有活埋。</p>
<p>以至于越南派了10万军队侵略柬埔寨，受到了柬埔寨人民的夹道欢迎，称为解放人类的战争。</p>
<p>公道自在人心</p>
<h2><span id="历史是一面镜子不同的国情决定了采取同样的政策结果可能是南辕北辙">历史是一面镜子，不同的国情决定了采取同样的政策结果可能是南辕北辙</span></h2><p>博古才能通今，不了解历史无法治理国家，不了解历史也无法对事务有一个清楚的认识。</p>
<p>我们的今天本来就是历史的延续，前人经验和智慧的总结，不是一句话就可以抹杀的。</p>
<p>因为秦以后漫长帝国时代的大一统，才会把中央集权延续到现在。</p>
<p>而西方封建时代延续到地理大发现，诸侯割据王国、公国、侯国林立为现代的西方提供了民主制度的可能。</p>
<p>在制度上完全的不可比性，使向国际接轨成为了笑话。</p>
<p>我们看到的结果就是，物价上涨与西方接轨，甚至堂而皇之的超过西方，体制外的工资则与非洲结果，也算是国际化了。</p>
<h2><span id="zf限制政策房的利润那kfs就一定会偷工减料">zf限制政策房的利润，那kfs就一定会偷工减料</span></h2><blockquote>
<p><strong>mellyzhang：</strong></p>
<p>大家听过那个西三旗的有名的限价房——旗胜家园吧~！外表看起来那么光鲜，地段也不是特别偏，紧邻城铁，当然是被人疯抢都抢不到的两限房呀~！还不是质量问题一大堆。</p>
<p> ZF安排的政策房也是要KFS建的，哪个KFS没肉吃还能保证把房子盖好？？！！所谓检测都TMD是虚的~。</p>
<p><strong>kkndme：</strong></p>
<p>这是肯定的，开发商都追求利润最大化。</p>
<p>zf建设两限房限制开发商利润，开发商必然偷工减料，zf都知道怎么回事，必须争一只眼闭一只眼，否则这个政策就执行不下去了</p>
</blockquote>
<h2><span id="屁股决定脑袋人民不知厉害关系选房子zf选农产品">屁股决定脑袋，人民不知厉害关系选房子，zf选农产品</span></h2><p>对于渴望拥有一套产权住房的都市小白领对希望房价狂降已经到了歇斯底里的程度，他们赞成农产品价格放开，让资金炒作农产品，而离开房地产市场。理由很简单，一套房子一涨就是几十万甚至上百万，而大米小麦，一斤就算涨到10块，也根本不能影响到自己的生活质量。</p>
<p>如果我国农产品价格是开放的，资金流向大米、小麦、猪肉，并且允许囤积，房地产一定会下跌的，这是毫无疑问的。</p>
<p>但是，我们看到的绝不是10块钱一斤的大米、小麦，而是500块钱、1000块钱一斤的大米、小麦。</p>
<p>我国将会出现大面积的饥荒，几千万甚至上亿的底层人士饿死街头，社会将出现大的动荡。</p>
<p>而产权房屋价格的上涨牺牲的主体只是体制外部分都市白领的利益，换来的不过是网络上没完没了的牢骚和咒骂。</p>
<p>巨量资金必须有地方去，如今面临的房地产和农产品之间的选择，你认为zf会怎么做？</p>
<h2><span id="各个阶层的住房问题都安排的妥妥的">各个阶层的住房问题都安排的妥妥的</span></h2><p>体制内中层、高层可以分到多套福利房，低层至少能够分到一套保障房，即使最不重要部门的底层员工，搞到由单位补贴的公租房是没有问题的。</p>
<p>体制外的高层、中层，以他们的资金实力买多套房子都是不成问题的。</p>
<p>农民，分配有宅基地。国家要稳定，首先就是要农民稳定，因此我国只有农民能够分到土地自己盖房子。</p>
<p>军人，会享受到比公务员更好的福利，让军人享受更高标准的福利待遇，国家有深刻的认识。</p>
<p>那么只有体制外的都市中下层群众才是高房价的受害者，可是这个群体的地位真的很微不足道。</p>
<h2><span id="顶层的岁月静好来自于底层的负重前行">顶层的岁月静好来自于底层的负重前行</span></h2><p>这些既无稳定工作（低层都市白领失业的概率还是蛮大的）又无自己的房产的都市小白领是金子塔底层被压榨的对象，甚至远远不如交通便利地区的农民。</p>
<p>没有这个群体的存在，金字塔上层的权贵是无法享受舒适的生活的。</p>
<p>社会需要底层群体用巨大的付出和极少的收获为金字塔上层群体服务。</p>
<p>当然，在巨大的付出后，有少数人会从低层脱颖而出，爬到金子塔的中层、甚至上层。<br>这些少数人带给了底层群体奋斗的希望。</p>
<p>拥有一套属于自己产权的房子，就只有一套路：从金字塔的底层往上爬。这条路很艰辛，并且会越来越艰辛，但总有希望。</p>
<h2><span id="底层指的是体制外底薪白领">底层指的是体制外底薪白领</span></h2><blockquote>
<p><strong>天地间间：</strong></p>
<p>楼主有一点没说透彻，那就是白领的工资普遍较高，他们有能力买房子，但是受到几千年以来的小农经济思想的约束，他们普遍认为买房子不划算，占便宜心里普遍严重，别看他们外表光鲜，其实还都是一帮农民</p>
<p><strong>kkndme：</strong></p>
<p>我说的是买不起房的低收入小白领</p>
<p>高薪白领不买房的不多吧，都是网上吹的吧。</p>
<p>高薪白领一般还是有自住房的，只是有人不愿意投资房产。每个人想法不同而已。</p>
</blockquote>
<h2><span id="资金终会流向具有稀缺性的资产">资金终会流向具有稀缺性的资产</span></h2><blockquote>
<p><strong>天地间间：</strong></p>
<p>请问楼主所说的低薪白领一个月赚多少钱算底薪？</p>
<p>就拿我说吧，我06年买的房子，当时月薪3000元，这在当时算不算低薪？</p>
<p>但是我买房了，还是一个人买的，当然老爸赞助了点。每个月还完月供兜里就剩几十元，硬扛下来了。</p>
<p>目前年薪12万，我老婆年薪6万？这算不算高新？</p>
<p>如果我当时没买房子，以我们2个人的收入当下也买的起，只不过生活负担重一些。</p>
<p>所以请楼主明示，什么是低薪？</p>
<p><strong>kkndme：</strong></p>
<p>兄弟，你所描述的是另外一个问题。先说说你所说的这个问题，再谈谈什么叫低薪</p>
<p>先说06年你月薪3000买房子的问题。</p>
<p>我们打一个比方：</p>
<p>假设80年代，咱们两个月薪都是100块。你喜欢清朝的瓷盘子，咬咬牙，一年用好不容易攒下的100块钱买了清朝瓷盘子。我喜欢缝纫机，用一年好不容易攒的钱买了一个缝纫机。</p>
<p>市场有价值发现功能。显然，80年代清代瓷盘子的价值没有得到发现。</p>
<p>进入90年代，随着社会的发展，社会财富的增加，钞票也大幅度增加。清代瓷盘子的市场价值发现出来了，瓷盘子价格开始大幅上涨，你的瓷盘子由100块涨到1000块。而我买的缝纫机已经淘汰了</p>
<p>瓷盘子具备投资品的一切属性，能够吸收社会的富裕资金，而缝纫机没有这个功能。我很眼红，我虽然买的起这个瓷盘子（因为90年代我的工资由100涨到了800），但是我觉得价格太高了，没有买。而你的瓷盘子在90年代为你挣了900元钱。</p>
<p>时光又到21世纪，社会资金越来越多，钞票越印越多，可瓷盘子在市场上越来越少（都被收藏了），于是瓷盘子涨到了1千万一个，我即使想买瓷盘子再也买不起了，而不是嫌价格高的问题。而你已经成为了千万富翁。那个瓷盘子也并没有因为1千万的价格实在太高而暴跌，相反价格仍以每年20%的速度增长。</p>
<p>06年你在房价价值发现的初期买了房子，就像90年代你用1000块买清代瓷盘子。</p>
<p>如果你的工资不变，或者变化不足够大，现在你将没不起房子，就像你在21世纪不可能买的起瓷盘子。</p>
<p><strong>天地间间：</strong></p>
<p>楼主啊，你有一个概念错误：清代的瓷盘子是收藏品是古董，其价值是由拥有瓷盘子的收藏家决定的，而房子是商品（我指的是商品房，不是公租房之类的保障房），其价值远没有古董增值速度快，所以说收藏品和商品是有区别的。</p>
<p><strong>kkndme：</strong></p>
<p>呵呵，商品房当然和清代磁盘是不同的，升值空间不同，投资对象也不同，但价值发现的道理是一样的。投资品的基本属性：稀缺性是共有的，当然稀缺的程度不同。</p>
<p>我所讲的是投资品的价值发现，而不是商品房=清代瓷盘</p>
</blockquote>
<h2><span id="土地的稀缺决定了大多数人永远买不起想买的房子">土地的稀缺决定了大多数人永远买不起想买的房子</span></h2><blockquote>
<p><strong>天地间间：</strong></p>
<p>此外，您还没有正面回答我什么是低薪</p>
<p>我今年30多岁，如果我刚毕业肯定是拿底薪的，往最坏了想，我毕业几年到今年混的不好，今年只赚3000元一个月，我就买不起房么？</p>
<p>如果你觉得是，那么你错了，我仍然可以买的起，我会到比较偏远的地段去买房子，比如密云，延庆等买套小户型二手房，那里的房价我仍然可以支付月供，当然我还是要像老爸要点钱付首付的。</p>
<p>可是如果我不这么想，觉得去哪里不划算，在四环里买房子多好啊！那么我可能就买不起了，因为在四环里买房已经超出了我的能力</p>
<p>那么请问我买不起四环里的房子是房价的问题呢还是我的问题呢？是不是说我买不起四环里的房子就是我买不起房？</p>
<p>综上所述，每个人都有自己的能力极限，不同能力的人去不同的地段买房子，一味的强求自己做能力不及的事情，反而还怨天尤人的，这就是小农意识。</p>
<p><strong>kkndme：</strong></p>
<p>如果我们买首套房，不是为了投资。我们买房总有个基本的要求：</p>
<p>有一个自己的家，并且上班相对方便</p>
<p>如果你在长城饭店上班，你跑去密云买个房子。首先你上班就成问题。</p>
<p>如果我月薪3000块，我甚至不能在密云买房子（因为也上万了），但我可以在山西的某个县城买套房子。问题是我买这套房子干什么？</p>
<blockquote>
<p><strong>先天下之友：</strong></p>
<p>请问楼主，在密云延庆买房子就不能去长城饭店上班吗？貌似密云延庆的城轨马上就要开通了，一个小时就可以到三元桥的，如果你仍然觉得不可能，那么我就很同情生活在东京纽约的白领了，他们买房子都在离工作单位50-100公里的地方，他们大部分人也靠城铁上下班的，所以说东京和纽约的白领生活在水深火热中啊</p>
<p>此外，密云和延庆的二手房子10000元一平？用不用我贴个卖房帖子啊？密云和延庆县城里的二手房子均价6000一平，一居室50平吧，总价 约30万，首付12万，月供1200元左右，这个对于月薪3000元的人来说是不成问题的，当然去密云延庆买别墅确实是10000元一平。</p>
<p><strong>kkndme：</strong></p>
<p>这种抬杠没什么意义，如果密云的轻轨修通了，1小时到三元桥，密云就由远郊区变为了近郊区，房价也不会维持现有水平，一定会水涨传高。</p>
<p>我没看过密云的规划，如果真有这个规划，且密云房子还没有大涨的时候，还时值得购买的。</p>
<p>密云的房价我倒真没去看过，不过以前有个住密云的同学说密云的新盘1万多了，老房子价格我并不知道。</p>
<p>我们只不过打的一个比方，假设密云到城里上班没有问题，普通小白领又买得起，那么不买的可以称为傻空。</p>
<p>但是确实有真正买不起的，连密云也买不起的，月收入3000，但要供养老人和孩子的，即使能在河北某个县城买，可是房子不能上班就完全没有意义了。</p>
</blockquote>
<p><strong>天地间间：</strong></p>
<p>我的中心思想是：北京的白领普遍买的起房子，但是有一部分不买，其原因是想花最少的钱去获得最好的地段，最好的楼层，最好的朝向的房子，这是划算不划算的问题，不是买得起买不起的问题</p>
<p>当然有的人会说：买房了，得病了怎么办？失业了怎么办？一大堆怎么办！那么请问：既然你知道早晚要见马克思，为什么现在还活着啊？一刀了断了算了，呵呵</p>
<p><strong>kkndme：</strong></p>
<p>你说的这类人其实是因为贪婪和恐惧，幸运不会垂青即贪婪又恐惧的人。用天涯的语言来说：就是传说中的傻空</p>
</blockquote>
<h2><span id="不同阶层的人对收入高低有不同的理解">不同阶层的人对收入高低有不同的理解</span></h2><p>再说说收入高低，不同城市，不同消费水平，对收入高低有着不同的理解。<br>我们举北京为例。</p>
<p>反映真实居住成本的是房屋租金，而不是房价。</p>
<p>在北京生活，一家三口的通常情况</p>
<p>一个位置能够满足上班条件的两居室租金大约3000元，小孩花费没有3000块是下不来的，再加上夫妻俩2000元的基本生活花费，也就是说8000月收入的家庭，刚好能达到收支平衡。</p>
<p>如果是体制外的都市白领，这个收入是很可怜的，因为还要考虑到失业问题，并且应付万一发生的意外支出。所以每月能有2000元的结余是必须的，那么10000元是在北京生活的基本水平。</p>
<p>而购买商品房所支付的金钱是要远高于租金成本的，因为你买的不是房屋居住权，而是房屋的产权，一定会出现溢价。</p>
<p>如果你现在的家庭收入能够再买得起一套房子，那么你的收入水平应该至少是小康，甚至达到中产</p>
<blockquote>
<p><strong>天地间间：</strong></p>
<p>楼主，一对有工作经验的年轻的北京白领夫妻月收入只有8000元？这是怎么统计的？</p>
<p>您的统计结果不准啊，我的结论是10000-12000元/月是北京标准的白领夫妻的月收入，那么这笔钱能不能买房子？</p>
<p>能，能不能付首付？可能不能，首付款怎么来的？一部分是父母赞助的。</p>
<p>作为父母就要把自己的孩子扶上马，再送一程，这和啃老没关系</p>
<p><strong>kkndme：</strong></p>
<p>呵呵，这个也不好这么说，不同行业间的薪水差距实在太大了。</p>
<p>比如一个有6、7年职业学校的教师或者一个有5，6年电脑分销经验的产品经理（都是大学毕业），他们辛辛苦苦干一年多点的也就7、8万块。他们都不晓得招商银行随便一个客户经理轻轻松松年薪几十万。</p>
<p>同是大学毕业，同是5、6年工作经验，北京几十万年薪收入的人不少，但一个月只挣3、4000块的数量更庞大。</p>
<p><strong>先天下之友：</strong></p>
<p>楼主，我说的是北京白领夫妻的标准工资，什么是标准工资？就是这个城市的可提供工作岗位加权平均工资，也就是说，你在北京混，正常的情况下，北京的白领夫妻在成为这个公司的主力员工以后就可以拿到的工资，什么是主力？就是在你的单位里能够独立挑起一滩活。</p>
<p>此外，在北京的白领，月薪3000元在大多数公司都是起薪价，工作几年后工资翻一番的比例很大，我在北京混了很久了，我相信在北京的绝大多数老板是给员工出路的，楼主你说是么？</p>
<p><strong>kkndme：</strong></p>
<p>我倒是觉得平均工资真没有什么意义。</p>
<p>你在中石化工作，各种收入加一起一年低于20万的还真没有。</p>
<p>你做基金经理年薪低于100万的还真不好找。</p>
<p>你在电力系统，有点职务的，一年搞个上百万都是轻轻松松的。</p>
<p>你要是公务员有点级别，好的一年收入上千万，不好的一年收入也就十来万。</p>
<p>但你要是在某个私营或者股份公司做个人事，行政，一年弄好了也就几万块钱</p>
<p>你要是做销售，好的销售年薪几十万，上百万，不好的销售一年也就挣2、3万。</p>
<p>我真不知道平均工资意义在哪里？</p>
<p>一个年收入千万的总经理跟100个失业的白领平均，人人都是年收入10万</p>
<p><strong>先天下之友：</strong></p>
<p>我还是要强调白领的平均工资，这个很重要，也是很多北漂留下来的重要理由，不同行业收入不同，但是主流行业的收入差距是不大的，至于你说的中石油和其他的高薪公司这个一般人进的去么？</p>
<p>至于失业问题，这个和国家的政策密切相关，属于不可抗力，一味的强调这一点没意思</p>
<p><strong>kkndme：</strong></p>
<p>如果仅指北漂而言，一般大学毕业的普通北漂白领有个几年经验的月薪大概是8000-15000不等吧。北漂几年的普通家庭月收入在15000-20000.</p>
<p>这个收入，即使在现在，在北京五环以外买房还是没问题的。</p>
<p>低于这个收入，真的考虑回家吧</p>
</blockquote>
<h2><span id="一二线买房只会越来越难最终租房会成为主流">一二线买房只会越来越难，最终租房会成为主流</span></h2><p>在北京一个年薪15万的普通家庭仍然买的起房，在五环外，只是你愿不愿意买。</p>
<p>但以后一个年薪15-20万的普通家庭买房子，即使是五环外的，也只能是梦想了。</p>
<p>租房将成为今后小白领主流的生活方式。</p>
<h2><span id="人需要一个安身之所能买早买比晚买好">人需要一个安身之所，能买早买比晚买好</span></h2><blockquote>
<p>房价是由土地决定的，而土地是咱们这个国家的根本，当年不就因为要改变土地的属性，才有了我们的党。</p>
<p>凡房屋也都是只有土地的使用权，土地属于国家，说收回的话不管你有无房证更不会和住房者商量，如（拆迁），这个性质决不变，想下，对有房者如此，会为了没有房子的而制定均衡均分的土地政策下降房价吗？</p>
<p>现在贫富分化越来越严重，真买的起房的考虑的重点不会是贷款，买不起的，房价跌去三分之一也还是买不起，不要看政府如何了，如果能少贷款或不贷款买处房的话就买吧，人早晚得有个安身之所，不要贪大求全，战争或地震来了房子不值钱，但万一战争或地震不来呢？</p>
<p>kkndme</p>
<p>没错，就是这个意思，如果战争来临，你手中的钱也变成废纸</p>
</blockquote>
<h2><span id="股市">股市</span></h2><blockquote>
<p><strong>新智战者：</strong></p>
<p>楼主对楼市的分析让人佩服！能否谈谈股市？现在的股市不管涨跌，我只是看到ZF在疯狂的发行新股大盘股，压大盘是肯定的了，看样子又是下一盘很大的棋！</p>
<p><strong>kkndme：</strong></p>
<p>你要注意2010年的股市与以往是不同的。因为股指期货的出现。</p>
<p>要时刻关注股指期货投入的资金量。</p>
<p>当股指期货资金量足够大的时候（什么叫足够大就要看个人的判断了），期指将指导沪深300指数。大盘会跟着固执期货走</p>
</blockquote>
<h2><span id="如果房价不涨那其他产品会怎么涨">如果房价不涨，那其他产品会怎么涨</span></h2><blockquote>
<p><strong>lfastro：</strong></p>
<p>“上帝欲使其灭亡，必先使其疯狂！”</p>
<p>很想看看“报复性上涨”是个什么样子。</p>
<p><strong>kkndme：</strong></p>
<p>你可以这样理解（只是为了理解方便做个示意）：</p>
<p>假设房价从2004年的4000一平，涨到2010年的20000一平</p>
<p>猪肉从2004年的6块一斤，涨到2010年的10块一斤。</p>
<p>但是如果房价2004年4000一平，到了2010年还是4000一平</p>
<p>那么，猪肉从2004年的6块一斤，将在2010年涨到30块一斤，不仅猪肉，还有大米，小麦，大蒜、葱、姜、房租都会翻几倍的价格。</p>
</blockquote>
<h2><span id="zf如何利用公租房控制租房市场">zf如何利用公租房控制租房市场</span></h2><blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>政府要垄断房租市场？市场上已有的和不断要产生的出租房源政府怎么让它们消失呢？</p>
<p>还是说政府要造足够多的公租房来占据市场主体 那就更难了 要花多少钱呀 公租房的地段好不了的</p>
<p><strong>kkndme：</strong></p>
<p>公租房将为房租市场树立一个标杆。有了这个标杆，私人出租房将会对比公租房做一个参照。</p>
<p>公租房是有限的，是需要申请的，而私人出租房会在相同位置将自己的房租定价高于公租房。</p>
<p>这样就保证了公租房的价格低于市场。</p>
<p>公租房不是廉租房，zf要持续赚钱，他的定价不会低，私人房就会定得更高，这将导致市场上的房租整体上涨。</p>
<p>公租房的吸引力在哪里？</p>
<ol>
<li>对体制内会有单位补贴</li>
<li>对体制外人员可以提供一个较长的稳定租期。</li>
<li>zf定价的标杆作用，无论怎么定价，公租房都会低于周边市场价格.</li>
</ol>
</blockquote>
<h2><span id="城中村不会长期存在">城中村不会长期存在</span></h2><blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>城中村可是提供廉价房源的地方 这个公租房的竞争对手肯定要被政府干掉 所以城中村的拆迁改造那是一定的</p>
<p><strong>kkndme：</strong></p>
<p>城中村一定会消失的，不消灭城中村，哪来的GDP</p>
</blockquote>
<h2><span id="三四线城市的未来">三四线城市的未来</span></h2><blockquote>
<p><strong>alice_xg：</strong></p>
<p>写得非常好</p>
<p>楼主能否分析下未来三四线小城市的发展，是否会空心化</p>
<p>另外，请分析下海南的城市有没有投资价值</p>
<p><strong>kkndme：</strong></p>
<p>四线城市房价也会缓步上涨，但比较慢，主要还是因人工成本，原材料价格上涨造成的建筑成本上涨。</p>
<p>城市的空心化可能性不大，人口仍然会缓慢增长。但偏远乡镇却存在空心化的可能。</p>
<p>海南具备得天独厚的海岸线资源，这是全国任何一个其他海滨城市无法比拟的（其他的海滨确实比较差，毫无美感）。但关键还是zf如何开发，急功近利的开发，和毫无节制的圈海岸线可能会大幅降价海南的旅游与投资价值。</p>
<p>取决于政策，有较高风险</p>
</blockquote>
<h2><span id="房租价格涨不上去本质是买房还看起来有希望">房租价格涨不上去，本质是买房还看起来有希望</span></h2><p>今天下午才出门，上午闲来无事，跑来再说两句。</p>
<p>一是再说说房租问题，房租的发展趋势：</p>
<p>现在房租低的一个重要原因是因为，大多数都市小白领还希望能够买一套属于自己的产权房，至少他们觉得即使现在钱钱不够，但是努力一把，跳个脚还能够得着。所以他们省吃俭用拼命的存钱。一个月薪10000块的小白领租一套月租金3000元的还算舒适的两居室是没有问题的，但是他为了攒钱买房宁可几个人合租一室，仅仅愿意在居住上花费少得可怜的500元钱。</p>
<p>随着国家队的进入，民营资本的退出，房地产开发和房地产投资的门槛都会大幅度提高，投资房产以后就成为富人的专属。</p>
<p>小白领的生活将变得“轻松”，因为除非能够上位，否则一般人跳脚是够不到属于自己的那套房子的。对于拥有房产失去希望，将使他不得不搬出合租房而转而租住一套还算舒适的两居室。</p>
<p>高昂的商品房价把大量的小白领从合租房中解放出来，转而去租住两居室或者三居室。</p>
<p>房租的价格一定会通过市场发现功能，找到他的位置。</p>
<blockquote>
<p><strong>想住清合吗：</strong></p>
<p>看了那么久，突然间觉得，楼主会不会过于武断了？</p>
<p>尽管我也看好房价和房租都上涨，但是，买房应该不会只是富人的专属。例如在日本，有许多的普通白领买的起房，难道在中国，白领就买不起吗？</p>
<p><strong>kkndme：</strong></p>
<p>白领是分层次的，有技术，有能力，有背景，肯吃苦的白领将通过努力获得更多的收入，获取更高的职位，走进金字塔的中层，买房子肯定没有问题。但进入金字塔中层的绝不会占大多数比例。</p>
<p>低级白领，公司办公室普通职员，一无技术，二无资 没有特殊的技能或本领，又没有什么关系和背景，对机会的把握能力也不是很强，如果家里也不富裕，这样的同志今后买房子就比较困难了。金字塔的底层人数比例是最大的。</p>
<p>日本的国情确实跟中国有很大不同，另外日本东京的房子也不是普通白领买的起的。我认识个NEC的部长（相当于中国企业的总监），也算大企业的中层干部，他也在东京买不起房子，家在离东京很远的郊区。</p>
<p><strong>中年不惑吗：</strong></p>
<p>日本的城市化已完成 不过东京市中心的房子小白领是买不起的 他们买的是东京卫星小城市的房子 如同你在上海工作 去扬州买房子还是能承受的 人家的地铁一个小时能跑200公里 你说生活半径能扩大多少呢 再说日本是有选票的</p>
<p><strong>kkndme：</strong></p>
<p>没错，就是这个道理。天涯里有些人说年薪30万买不起房，年薪70万买不起房。原因还是期望太高了，以为自己年薪70万了，就是人上人了，就必须住市中心的大房子。</p>
<p>但事实上市中心的大房子是绝对稀缺的，人上有人，天外有天。</p>
<p>买房子还是量力而行。有1000万资产的人是买不起价值2000万的翡翠的。有1个亿资产的人也不能买下故宫的居住权。</p>
</blockquote>
<h2><span id="稀缺房的价格永远涨">稀缺房的价格永远涨</span></h2><blockquote>
<p><strong>sunxishila：</strong></p>
<p>我认为房价不可能跌的（至少5年内） ，尤其北上广，因为</p>
<ol>
<li>地球资源就那么点，美国人不可能允许所有的人都过上他们那样的高消耗生活，所以美国人就尽可能地创造无产阶级国家来为其当奴隶进行打工，中国的现状也一样，利益集团以及国家政府为了其利益以及维稳庞大的执政集团必须要通过工具将更多的人丧失生产资料以便当其奴隶。试想如果人人都有房住，人人都有闲钱可以自由的选择生活方式，我们以出口为主的血汗工厂还能招得到工人吗？北上广还能存在这么多外资企业吗？外资企业没的话，没这么多就业机会，所有的外地人回家了，上海的办公楼，出租房不全完蛋了 ，那么势必减少了各种税收，那么北上广正常的维持城市运行的资金必将断裂…怎么可能呢。</li>
<li>适度宽松的货币政策（也就是过量发行的货币）必将导致通货膨胀，在中国货币多了必将走进房地产，因为在中国基本没有别的更靠谱的投资渠道。长期看来，货币一直是贬值的 ，世界上几乎所有的国家货币一直都在贬值，这是货币的固有属性，就是剥削。除非取消货币，可能吗？</li>
<li>房价下跌或者价格合理当然是有可能的，可是这取决于政治，除非取消一党执政，除非土地似有话，原因相信大家都清楚，你们认为近期可能吗？</li>
</ol>
</blockquote>
<h2><span id="粮食和房子的不同是房子无法和土地剥离">粮食和房子的不同是，房子无法和土地剥离</span></h2><p>二是再说说粮食问题</p>
<p>中国的粮食实行储备制度，国家每年从农民手里收购一定数量粮食以及进口一定数量的粮食用于储备。</p>
<p>中国的稻米主要出自东北和广西，东北米好吃但产量小价格高，广西米难吃但产量达价格低，都市人都愿意花高点的价格购买东北米。</p>
<p>各地储粮通行的做法是以储粮为名收购的东北米加价在市场上出售牟取利润，再低价收购难吃的广西米用于粮食储备。</p>
<p>米在市场上的价格差别还是很大的，好的东北米可以卖到5块钱一市斤，一般的东北米卖到3块钱左右一斤，差点的东北米卖到2块钱一斤。而广西米基本在2块钱以下，而且除非比较穷的，一般人都不愿意吃。</p>
<p>大家可以看到在市场上交易的大米跟其他商品并没有什么不同，好的稀缺的就贵，差的产量大的就便宜。<br>但是米和房子不同，一方面米是当年的好吃，放到第二年陈了就不值钱了，第二年土地上新的稻子又长出来，会有新的米下市。但是房子不会，一栋楼今年卖掉了，明年这块已经卖掉了的土地并不能长出另外一栋楼。另一方面，中国实行的储备粮制度将会在粮食减产的时候平易粮食价格的上涨（尽管储粮和市场上销售的粮食完全不是一个品质），而且国家对口粮的问题会高度重视。<br>粮食作为商品本身是与土地剥离的，而房屋作为商品却无法从土地剥离出来。这是粮食与房子的根本不同。</p>
<p>商人在粮食稀缺时期进行囤积会枪毙，在粮食丰收时期囤积粮食只能亏损（第二年的米就没人吃了。</p>
<p>商品房作为商品在市场上交易，而保障房是为了保障低收入群体的最基本居住，这与粮食分为储备粮和商品粮又多少有些相似。</p>
<p>但是商品房土地和房屋无法剥离，产权和居住权却是剥离的，这就使既保障人民的基本居住权，又通过产权的升值牟取巨大的利益成为可能。zf实在是再明白不过了。</p>
<h2><span id="购买房价基数低的省会城市怎么都不会亏的">购买房价基数低的省会城市，怎么都不会亏的</span></h2><blockquote>
<p><strong>Razerwu：</strong></p>
<p>我也年纪小，07年才毕业，学经济的，人文历史基础有一点，关注房价有两年了。看了楼主帖子，更是开朗了。</p>
<p>升斗小民一定要跟形式跑，千万别一厢情愿，也别被媒体的话语误导了。</p>
<p>以后，征服会逐渐保证居者有其屋，但是不是每个家庭住的房子有自己产权。中国社会阶层分化很严重。主要分体制内和体制外两个群体。体制内的即使明摆着的收入一般，但是福利好。体制外的，有高薪的，但是低收入的更多。我们公司一般在年收入到手5-6W左右。这个应该是这个城市的平均水平了。我相信50%的人都在这个数。这个收入租个房子，除去其他生活开支，一年还能余个1,2W，如果是两个人一起生活，也能养小孩的，只是，你永远买不起自己的房子。</p>
<p>但是我也知道，更多的小白领，在空调房里工作，一个月就领1000来块的薪水，而那里房价也不低，8000-10000了。你还是买不起。</p>
<p>所以，未来你可以选择在房价高的地方生活，然后租房。你也可以选择回到三四线城市。但是很可能，到时候那里的房子价格也不低，如果你能力够，还是有希望买到商品房。</p>
<p>非常有钱的人很多，我不知道他们会怎样投资。</p>
<p>我想给一些跟我一样收入层次的人一些建议。</p>
<p>物价必涨，这是趋势，如今农村的农民都不怎么种地了，征服在搞平整，以后都会自动流转，每个村的徒弟承包给一个人，别的农民给他打工。有资金的农村出来的，可以考虑往农业方向发展。</p>
<p>我薪水收入一般，但是有外快，跟女友一块存钱，年收入超过20W，</p>
<p>楼主在帖子里提到长沙和石家庄的例子，我认为，二三线城市也要具体分析，像我老家长沙，房产升值空间还是有的，只要每年涨20%，我就满足了。一线城市的房子更稀缺，但是，城市化的进程，不可能继续像上一个10年那样，大家都往一线城市跑了。所以，房地产暴涨的时代我不相信还有。我还相信二线城市和一线的房价差距会慢慢拉近。</p>
<p>所以，我用09年的结余，在今年上半年长沙贷款买了一套，我准备下半年再买一套。我不是炒房，我是略有结余的工薪阶层，我选择保值，总比放在银行要好。事实证明我是对的上半年买的现在已经涨了10%了。</p>
<p>一线和省会城市的商品房，未来一定会成为更加稀缺的资源。</p>
<p><strong>kkndme：</strong></p>
<p>长沙的房子一定会涨，只不过涨得会比其他城市慢。</p>
<p>低价买涨幅滞后的房子有一个好处，一旦长沙放出“大量拆迁”等利好因素，你就赚大了。购买房价基数低的省会城市，怎么都不会亏的</p>
</blockquote>
<h2><span id="房地产是资本市场还是实体经济">房地产是资本市场还是实体经济？</span></h2><p>还有一个关于实体经济的问题，房地产是资本市场还是实体经济？</p>
<p>我们回顾一下，房地产的居住属性和产权属性是剥离的。</p>
<p>依照房地产的居住属性，房地产绝对属于实体经济。</p>
<p>从下游来说，不搬新家重新购买一套家具、一套家电、做一次大的装修的可能性都不大。在没有改善住房的前提下，去换家具家电，搞装修的应该是一个很小的比例。</p>
<p>从上游来说，钢铁、水泥、机械等行业无一不受到到房地产的影响。</p>
<p>房地产影响到钢铁、水泥、机械、家电、家具、建筑建材等多种领域，影响真的不小。</p>
<p>依照房地产的产权属性，房地产又是资本市场。</p>
<p>资金推动了商品房价格的快速上涨。</p>
<p>房地产为政府积聚了大量的财富（卖地），这些财富用来建造地铁、公园、广场、办公大楼、公款招待、潇洒挥霍，又推动了实体经济的增长。</p>
<h2><span id="什么是傻空">什么是傻空</span></h2><p>关于买房量力而行的事，还是有必要再说得清楚些的。</p>
<p>还是打个比方</p>
<p>假设某人家庭月收入15000块（都市小白领的通常收入），工作6年，手里有50万存款，我可以在北京北五环外（比如西三旗或者回龙观）买一套价值150万的房子（2万每平米，70几平米）。首付50万，贷款100万，月供7000多，是完全买的起的，而且因为轻轨的开通，即使在市中心工作，上班时间肯定可以在2个小时之内（作为北京这个城市来说是可以接受的）。</p>
<p>但是这个人心比较高，非要在北四环内，买一套100平的住宅，二手房3万一平米，100平米就是300万。首付按30%算，也就是90万，还要贷210万，已经完全超过了他的收入水平及收入预期。于是这个人成天怨天尤人，成天喊自己买不起房，抱怨zf，憎恨炒房客和开发商。天天叫唤社会不公平。</p>
<p>过了1年，国家队布局完毕，西三旗、回龙观房价涨到30000一平米了，买个70平的还要210万。首付30%，要60多万，贷款150万，月供12000左右。这时，他买西三旗70多平米的房子已经很费劲了。</p>
<p>这种行为叫什么？这就叫傻空。</p>
<h2><span id="什么是真买不起房">什么是真买不起房</span></h2><p>再比如说</p>
<p>某人家庭月收入比较低，8000块，在北京上班，西三旗和回龙观的房也要150万的总价，是买不起的。他的收入水平只能在密云或者河北买房子，但是即使在密云或者河北买了房也没办法上班。这个人就叫做真的买不起房。</p>
<p>如果他对未来的收入预期也不是很高的话，房价未来的上涨将使他进一步对买方绝望，他将彻底放弃攒钱买房，带着老婆孩子搬出跟人合租的城中村，每月花费2500块钱在回龙观租一间两室一厅的住宅。</p>
<p>日子就这么过下去了。</p>
<p>量变将引起质变，8000块钱的家庭月收入，是真买不起房的家庭，而15000月收入的家庭买不起房就叫傻空。</p>
<h2><span id="具体情况具体分析如果看不懂一定是没有抓住问题本质">具体情况具体分析，如果看不懂，一定是没有抓住问题本质</span></h2><p>小时候看春秋战国之类的书籍，总弄不明白一个问题：</p>
<p>a国家跟c国家打，他的邻国b就会很害怕，害怕a国家灭了c国家实力更强大，对自己不利。</p>
<p>e国家跟g国家打，他的邻国f就会很高兴，高兴e国家与g国家两败俱伤，自己可以获取利益。</p>
<p>后来我终于弄懂了。</p>
<p>当a国家跟c国家打仗时，如果a的国力明显强过c,他的邻国b就会很害怕，因为a国家很轻易就会灭掉c国家变得更强大。</p>
<p>当a国家跟c国家打仗时，如果a的国力跟c差不多,他的邻国b就会很高兴，因为a国家跟c国家会拼得两败俱伤。</p>
<p>分析问题，一定要深入的研究啊</p>
<h2><span id="桂林-vs-南宁">桂林 vs 南宁</span></h2><blockquote>
<p><strong>leeyq88：</strong></p>
<p>楼主的观点高明，因为把房价与整个经济及政治层面的东西联系起来了。请教一个问题，桂林属于5线城市了吧，现在均价近5000，请楼主分析一下桂林这种级别城市房价的趋势。</p>
<p><strong>kkndme：</strong></p>
<p>缓慢上涨，有钱买南宁吧，东盟贸易提供了巨大的空间</p>
</blockquote>
<h2><span id="公租房的量级不会冲击到商品房市场">公租房的量级不会冲击到商品房市场</span></h2><blockquote>
<p><strong>vavan2010：</strong></p>
<p>楼主说得好，根据你所描述的，关于房租的这一块，我看到的前景是，由于国家队的加入和垄断，以后开发商只有可能是财雄势大集团的地产商和国家队这两种了。</p>
<p>而大量的建筑公屋，也是要分租赁市场的一杯之羹，又有公租房又有廉租房，再加上物业税的出台，这样愿意持有普通住宅多套的收租客会不会减少？</p>
<p>因为没钱买的会去租公租或廉租，有钱租的也去租高端好房，就象香港一样，有钱的买商品房，一般的买普通限价房，经济实用房，没钱的住公屋或廉租。反而持有普通住宅多套的会不会逐渐减少？</p>
<p><strong>kkndme：</strong></p>
<p>公租房只能是有一定量，不会是大量，首先解决的也是体制内的住房问题。持有多套住宅的有自己的市场空间</p>
<p><strong>醉生梦思1：</strong></p>
<p>这个问题很好解答，香港公租房占5成比例，私人租房市场委缩了吗？没有，这是市场上不同档次的产品，对应不同的需求。</p>
<p>就像有人看盘，绿化不好，没有游泳池的房子坚决不要是一样的道理。</p>
</blockquote>
<h2><span id="贵阳资源的稀缺导致权贵更容易垄断通过低收入高物价的方式剥削底层群体">贵阳，资源的稀缺导致权贵更容易垄断，通过低收入高物价的方式剥削底层群体</span></h2><p>旅行的第一站，是贵阳。</p>
<p>一座低收入高消费的西部边远城市。</p>
<p>当地人说贵阳的消费太黑人，太畸形了。大多数当地人的收入相当于中部城市的县城水平，生活必需品的消费却超过了北京。</p>
<p>越偏远的地方越黑暗，越偏远的地方越不存在公平，越偏远的地方贫穷群众的比例越大，越偏远的地方权贵生活的越腐败、越奢华。</p>
<p>越是资源匮乏的地区，权贵阶层越富裕，这是以绝大多数人的贫穷为代价的。</p>
<p>资源的稀缺，导致权贵易于对资源形成垄断，通过以低收入高物价的方式，对底层群体进行赤裸裸的掠夺。</p>
<p>于是权贵们鲜衣怒马，下层群众褴褛衣衫。</p>
<p>贵州难道不是中国的缩影吗？</p>
<p>在欧洲的商业区，我国权贵们一掷万金，引来欧洲群众围观，瞠目结舌。以至于全世界都没法相信我国不是超级发达国家。</p>
<p>贵阳的近郊房价已经9000一平米，远郊的金阳房价已经接近了6000一平。</p>
<p>但是我们能就此判断贵阳的房价存在巨大泡沫吗？</p>
<p>贵阳到处是山，地少人多，物产极不丰富。</p>
<p>因此，贵阳的商品房就像贵阳的餐厅一样，和普通群众是完全没有关系的。而对于权贵与精英来说，即使再翻几倍的价格也一样买得起。（腐败啊）</p>
<p>看看贵阳，想想中国。</p>
<p>资源的匮乏将形成高度的垄断，导致贫富分化进一步加剧，生活成本大幅度提高，中国正走向低收入高消费的畸形社会结构，群众生活越艰难，权贵的生活就会越富足。<br>生活必需品和房价都会变得比西方国家更贵。</p>
<blockquote>
<p><strong>fzh_0931：</strong></p>
<p>鉴定完毕，聪明的房托！<br>通篇围绕通货膨胀核心立论，既然商品房是商品，那就不具备投资品的一些属性，（帖子里关于清代磁盘子的案例很不错）为什么还要在这里忽悠呢？抵御通货膨胀的手段，除了买房以外还有很多不错的选择，为毛还在这里大谈特谈房价暴涨呢？既然在上世纪90年代是商品房价值发现初期阶段没有买进，那么到了现在这个所谓的价值发现中期或者后期阶段还有什么理由买进呢？（当然，没有自住房的例外，对于投资者来说，眼下投资房产恐怕不是最好的选择）我相信，随着通货膨胀的加剧，我们手里的钞票不断贬值，房子肯定还是会上涨，只不过不是暴涨和普遍上涨，会是局部的，具有某些概念的，那么试问，我们作为普通百姓，怎么才能未卜先知到底是哪一部分的房子会上涨？那一种概念的房子会上涨？恐怕也只有那些个具有神通的精英阶层才能知道，所以作为一个普通小民来说，俺是不会淌这趟浑水滴，俺自己够住就行，真要有天，时来运转，中了六合彩或者虾米大奖之类的，俺实在是不知道那钱做什么用时才会考虑在海南？还是杭州？抑或是南京买所蜗居来等待升值，否则俺只能望房兴叹。。。</p>
<p><strong>kkndme：</strong></p>
<p>从2005年开始</p>
<p>傻空眼里<br>凡是认为房价不会降的都是房托<br>凡是买房子的就认为49年加入国民党的。</p>
<p>装成傻空专骗真傻空的人，一面天天喊着房价暴跌，一面抄了一套又一套</p>
<p>真傻空除了骂街恨社会，什么也没得到</p>
</blockquote>
<h2><span id="重庆高层和别墅怎么选">重庆：高层和别墅怎么选？</span></h2><blockquote>
<p><strong>yourrainbow：</strong></p>
<p>Lz还在吗？咨询下重庆房价的走势呀！</p>
<p>投资别墅与高层的比较！</p>
<p><strong>kkndme：</strong></p>
<p>我个人很不喜欢重庆这个城市，但是我不得不说重庆的发展空间很大，无论是经济还是房价。</p>
<p>别墅，如果有钱投资，一定是别墅，只要不是太偏远的。</p>
<p><strong>hollybible2018：</strong></p>
<p>我给你解释为什么楼主推荐别墅了。看问题不是看短时间内，而是要看长远。</p>
<p>第一，中国富裕阶层追捧什么房型？别墅。要想富，先学会用富人的思维方式思考问题。</p>
<p>第二，随着中国经济越来越强，人均住房面积会进一步增加，人们选择的房型会由公寓逐渐转移到别墅。</p>
<p>第三，如果你有在欧美，日本这些发达国家的生活经验，你会知道，公寓是给穷人住的地方，而稍微收入可以的住的都是别墅型的房子。我国按照这样的发展趋势，是能达到这些发达国家的水平。我国曾经现在将来发生的事情都是那些发达国家曾经现在发生的事情。</p>
</blockquote>
<h2><span id="货币贬值">货币贬值</span></h2><p>刚从青岩古镇玩回来，饭前说说货币贬值。</p>
<p>货币贬值，来自于大量的印钞</p>
<p>可不可以少发点钞票。</p>
<p>对不起，不行。</p>
<p>这是我国的官有经济体制决定的。</p>
<h2><span id="为什么美国人工高于中国但大多数商品的物价却低于中国">为什么美国人工高于中国，但大多数商品的物价却低于中国</span></h2><p>凡是去过美国的朋友，会惊奇一个现象<br>除了人工服务行业，几乎大多数产品的绝对价格都低于国内。</p>
<p>从数码产品，到奢饰品，从矿泉水，鸡蛋到汽车，统统比国内的绝对价格（把美金换成人民币，再拿人民币进行比较）便宜。（美国的餐馆比较贵是因为包含了人工服务成本）</p>
<p>不仅仅是美国货比在中国卖的便宜，几乎所有made in china的商品在美国卖的绝对价格都低于国内售价（一件国内生产出口的服装在美国售价150人民币左右，但在国内售价竟然达到800-1000人民币）</p>
<p>贫穷的发展中国家——我们的物价却远远高于美国，这是什么样的原因呢？</p>
<p>我想主要还是我们的体制决定的：</p>
<p>1、高昂的行政成本</p>
<p>中国庞大的公务员队伍对货币的消耗达到惊人的程度。任何一种商品的销售都要分摊政府高昂的行政开支。不大量印钞票是无法维持正常运转的</p>
<p>2、过渡依靠政府投资。<br>大家都知道，中国的经济发展，是依靠政府投资为主导的，全世界都知道，政府投资的效率是最底下的，1个亿的投资往好了说只能产生3000万的效益，剩余7000万损耗掉了。因此政府不得不持续增加货币发行量<br>3、惊人的fb成本</p>
<p>一集中箱货物运到美国的成本甚至低于从北京运到深圳的国内运费。这是令人惊讶的事情，又是确凿的事实。中国高昂的高速费用使物流贵得吓人，从农民手中2分钱收购的蔬菜，运到了目的地，成本就变成了1元钱。</p>
<p>这中间不仅仅是高速费，当公路及铁路运输变得紧张的时候，你不得不花费比高速费更贵的支出用于打点关系。</p>
<p>关系的成本已经远远贵过商品本身。惊人的fb成本是物价上涨的重要原因，因为权贵贪心也是逐年增加的，fb成本越来越高。fb成本的每年高速增长，迫使印钞需求高速增长。</p>
<p>4、低附加值产品出口创汇</p>
<p>低附加值产品出口创汇是我国经济发展的主要支柱。</p>
<p>可以这样理解，我们的商品卖到了国外，换回的是外汇。国内的商品少了，就变贵了。换回的外汇，国家就会按照外汇的总金额依据汇率全都印成人民币，投放到社会。社会上不但商品变少了，每年还会多印出一大堆钞票，这就是通货膨胀。货币的购买力在持续贬值，国家通过货币持续贬值来收割普通劳动者的羊毛。</p>
<p>所以说我国高通胀，货币持续贬值，是官有经济体制所决定的。</p>
<p>是不可能改变的。</p>
<p>持有闲置现金的风险，比持有任何一种可保存的商品的风险都大。</p>
<h2><span id="还能上车的赶紧上车">还能上车的赶紧上车</span></h2><p>奉劝那些盼着zf政策出打击房产直到崩盘，以此得到高潮的同志们，真的不要等了，除非出现明末的极端事件，否则一辈子等不到高潮。</p>
<p>也奉劝希望房价能降个30%-50%好买套自己的房子的善良百姓，还是看有什么机会多挣点钱吧，等房价大降真的不现实。</p>
<p>百姓们希望领导们能给自己做个主，可是几千年以来，中国的上位者们从来都只考虑一个问题：“卧榻之上，岂容他人安睡。”真的没有时间管你们的那些小事儿。</p>
<blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>大家应该知道所谓的康乾盛世，开元盛世都是什么样子了</p>
<p>上层阶级的盛世而已</p>
<p>底层老百姓在史书上连“某人甲，某人乙”都留不下</p>
<p><strong>dantez13：</strong></p>
<p>康乾确实是虚假的所谓“盛世”开元还是不错的</p>
<p>看历史不光纵向看 也要横向看</p>
<p><strong>kkndme：</strong></p>
<p>开元盛世留下巨大的隐患才导致玄宗悲惨的人生，不应简单的认为是杨玉环和安史之乱的原因。</p>
<p>首先是大量的土地兼并，大量的农民同志逃跑，社会的不安定为安史之乱埋下了隐患。还有就是节度使的权力太大，以全国之力供养节度使的军备，而内地养了一群废兵。</p>
<p>相当于老大把精兵干将派去边远山区收保护费，结果自己身边连个像样的保镖都没有。有个收保护费的领班突然不爽，自己想当老大，带着打手跑回去揍老大，准备上位。这时老大就光杆司令一个，看着自己的手下叛变之能干瞪眼</p>
<p><strong>dantez13：</strong></p>
<p>我说的看历史纵向横向的意思是指</p>
<p>康乾时期 纵向来看 还算是个稳定时期 但是17 18世纪 欧洲正轰轰烈烈的搞工业革命</p>
<p>乾隆却几下江南 还搞什么骑射乃满洲之本</p>
<p>而开元时期 ，虽然的确有很多隐患 但是大唐还是当之无愧的世界老大</p>
<p>唐朝也是那个时候达到的巅峰</p>
<p><strong>kkndme：</strong></p>
<p>呵呵，大唐当世界老大也不知道是好事还是坏事</p>
<p>欧洲经历了漫长的中世纪黑暗时代，结果由诸侯割据的封建社会直接进入了资本主义社会，并向国家社会主义过渡。</p>
<p>中国早在秦就结束了诸侯国林立的封建时代，进入了大一统高度集权的帝国时代，到现在也没完全结束。</p>
</blockquote>
<h2><span id="武汉城市发展空间的大小往往和房价的升值空间成正比">武汉：城市发展空间的大小，往往和房价的升值空间成正比</span></h2><blockquote>
<p><strong>dantez13：</strong></p>
<p>挨楼主好近 呵呵</p>
<p>请教一下楼主对武汉这个城市的看法 房价 以及将来发展的空间</p>
<p>今年刚在武汉出手两套房</p>
<p><strong>kkndme：</strong></p>
<p>对武汉的房价真没研究过，不敢妄言。但很看好武汉这个城市的发展。城市发展空间的大小，往往和房价的升值空间成正比，虽然不是绝对</p>
</blockquote>
<h2><span id="权利让革族成为苗族的一支">权利让革族成为苗族的一支</span></h2><p>刚从大山深处（枫香）出来，做了6个小时车，到榕江现城，居然赶上全程停水，狂晕。</p>
<p>枫香是革家聚居区，名族识别的时候本来应该定为革族，结果苗王（也是贵州shengzhang)一句话就把完全不同祖先的革族变成苗族的一支啊。这就是权利的力量。</p>
<h2><span id="房价是否会跌如果会会怎么跌">房价是否会跌，如果会，会怎么跌</span></h2><p>几天没有上来，发现来了很多比较鸡冻的同志。心情可予以理解。</p>
<p>但是鸡冻并不能让日子过的更好。</p>
<p>油价大涨小跌，我们鸡冻了，但是事实并没有改变。</p>
<p>高速费早就收回成本，可是依然雷打不动的收着，我们鸡冻了，可是事实也没有任何改变。</p>
<p>房价就能真如很多人所愿，使劲跌到人人买的起吗？今后的现实将告诉我们答案。</p>
<p>房价会不会跌？</p>
<p>我说在较远的将来一定会跌，但下跌的方式是完全不同的。不可能象大家所期望的由2010年的30000一平跌到2004年的6000一平。</p>
<p>下跌一定是另一种方式：当农产品价格以几年翻10倍甚至几十倍的速度上涨的时候，房产却相对滞涨。这是最有可能的下跌方式。</p>
<h2><span id="通货膨胀是减缓灭亡最好的良药">通货膨胀是减缓灭亡最好的良药</span></h2><p>最善良的意愿并不能阻止事务向邪恶的方向发展。</p>
<p>我们大家都很清楚却都没关注的一个常识，当我们满怀热情无偿献血的时候，有哪个贫穷的患者在需要输血时，能够因为广大群众的无偿献血而得到医院的优惠吗？</p>
<p>不能，无论你是穷是富，只要你是平头百姓，你都不得不因为需要输血而支付昂贵的医药费。</p>
<p>同样，zf并不会因为拆迁给你补偿的太低，而强迫开发商降低房价卖给群众。压低建设成本，抬高售价，中间的利润由商人和权贵进行分配，这是官商结合的通行做法。自古以来，能够赚大钱的都是红顶商人，而不是普通个体户。</p>
<p>对于很多鸡冻的群众，指着鼻子问我：国家会不管吗？疯狂难道不是导致灭亡吗？</p>
<p>我告诉你，通货膨胀就是减缓灭亡时间的最好良药</p>
<blockquote>
<p><strong>被忽悠的群众：</strong></p>
<p>请楼主解释一下</p>
<p>通货膨胀是zf偷偷掠夺人民财富的手段，极少数人暴利，怎是良药？？？</p>
<p><strong>kkndme：</strong></p>
<p>通货膨胀是zf偷偷掠夺人民财富的手段，极少数人暴利————没错，通货膨胀就是剪老百姓的羊毛，让权贵的财富更集中，中下层群众更贫穷。</p>
<p>但是，从国家的统治与巩固来讲，的确是良药啊（当然有一定限度）。</p>
<p>当大多数资源掌握在少数人手中的时候，占有绝大多数的金字塔下层的群众能够分配到的资源就越少，资源的价格就会越高，少数的金字塔中上层的既得利益者就会越富有。</p>
<p>大家知道，有些资源会变成富人间的游戏（比如现在的古董，字画），完全失去群众基础；而如果与生活密切相关的资源过度集中，一定会爆发极端冲突事件，造成社会动荡。</p>
<p>zf通过不断稀释货币的实际购买能力，并且对粮食等生活必需品实行平准制度，一方面保证了绝大多数人民的基本吃饭问题，另一方面让中下层群众手中的余钱基本消耗在特定的商品上，以至于不得不马不停蹄的劳作，这才能保证社会的稳定和向前发展。而上层精英就可以坐享其成。</p>
<p>让我们回顾一下过去</p>
<p>80年代，那时的人们靠省吃俭用积攒出节余，被消耗在自行车、手表、缝纫机上。通过不断的劳动，才能吃饱饭，才能攒点钱买三大件取媳妇。</p>
<p>80年代末，90年代初，人们的工资提高了，手里的结余增加了，彩电、冰箱的大规模普及又消灭了老百姓手中的流动性。</p>
<p>紧接着电话、空调又接过了彩电、冰箱的大旗。那时安装个电话可要5000大元啊。</p>
<p>随着工业化水平大幅度提高，经济高速增长，货币发行量也迅速增加，彩电、冰箱等工业化大规模产品已经不具备稀缺资源的特性，也无法吸收百姓手中庞大的结余资金。</p>
<p>汽车和商品房的发展成为消灭老百姓手中的流动性的最好工具。</p>
<p>在经济发展的大潮中，一旦对资源的支配权可以换取利益，贫富两极分化是发展的必然。随着贫富分化开始加剧，财富集中在少部分人手中，集中了大量财富的少部分人已经不满足于购买普通的消费品（汽车是工业化的产物，不具备稀缺性），对投资品的追捧造就了2005年房地产的崛起。</p>
<p>房地产具备了投资品和生活必须品的双重属性，即可以让金字塔中上层的精英群体依靠房地产保值增值，又可吸收掉中下层群众的未来若干年的结余资金。</p>
<p>大量印刷的货币还是有一定数量留到勤劳肯干的白领手中的，而这些货币又因为通货膨胀因素消耗在不断上涨的生活必需品上，必需品中商品房占了大头。</p>
<p>于是拥有大量房产的金字塔中上层精英可以坐享其成，享受房产升值带来的收益，而中下层群众不得不为房子打工。</p>
<p>发行大量货币满足经济发展的需要，同时通过通货膨胀来消灭广大群众手中的流动性，是zf稳定社会，发展经济的法宝，适度的通货膨胀当然是缓解社会矛盾的良药</p>
<p><strong>tjOOSAN：</strong></p>
<p>楼主！这段话，我不是很明白。</p>
<p>好像世界上，每个国家都是如此把？谁会不买东西？谁会不买生活必须品？</p>
<p>别忘了，中国发展到现在，百姓也没有能力购买一切生活必须品！当然，随着社会的发展，人民在一点一点的去完善基本生活。</p>
<p>这你却说成。。。精英和国家的阴谋。。。我。。。很难理解。</p>
<p>稳定粮食价格，这对每个国家而言，都是必须的啊！？？这最最基本了吧？</p>
<p>房子为什么涨价？？？国家决策！懂吗？间接取消了经济适用房政策。市场上百分之九十都是商品房！！你告诉我，房价能不涨吗？</p>
<p>房价涨了，受益人是谁？？？是政府！！不是你嘴里所谓的精英，他们只是傀儡罢了！</p>
<p><strong>kkndme：</strong></p>
<p>不是阴谋，我没提过一句阴谋，是国策</p>
<p>好比美国，以中产阶级利益为代表的美国，一个币值相对稳定的国家，主导借钱消费，这就是国策。</p>
<p>当08年的金融危机，多数中产却尝到了惨痛的教训。而在美国的华人，因为热爱储蓄的原因（这跟美国币值相对稳定、华人储蓄习惯都有关系），生活并没有受到太大影响。</p>
</blockquote>
<h2><span id="货币供应不足是明朝的真正原因">货币供应不足是明朝的真正原因</span></h2><p>明朝末年，可怜的崇祯皇帝面临的最可怕的问题貌似两个:一是努尔哈赤的入侵；一是大饥荒下，到处闹蚁贼。光是努尔哈赤的入侵，明末的关宁铁骑完全可以将满人挡在山海关外；光是蚁贼肆虐，凭洪承畴、孙传庭等名将镇压一群乌合之众还是易如反掌的；内忧外患才导致了明朝的灭亡。这是通行的说法。</p>
<p>明朝灭亡的真正原因，是经济原因。</p>
<p>当然，这也是句废话，无论是社会的稳定，还是国家的动乱，或者邻国间的战争，都是经济原因导致的。</p>
<p>明朝真正灭亡的原因是：货币供给不足。</p>
<p>不要说百姓的经济行为受到很大制约，即使是军队也发不出饷银。以至于除了关宁铁骑以外，明朝就找不出一支有战斗力的军队，甚至洪承畴、孙传庭打高迎祥、李自成、张献忠，居然靠农民军的馈赠过日子。</p>
<p>货币供给不足，明朝的经济崩溃了。</p>
<h2><span id="经济问题是导致清朝灭亡">经济问题是导致清朝灭亡</span></h2><p>再谈谈鸦片战争和那个满脑子浆糊的林则徐。</p>
<p>鸦片战争的原因，在于大清国与欧洲诸国之间存在的巨大贸易顺差。</p>
<p>大清虽然闭关锁国，丝绸、茶叶、瓷器通过民间和官员私下大量出口欧洲换取白银，却没有任何的进口需求。以至于英、法国家不得不世界范围开采银矿，但依然不能满足采购中国商品的需求。</p>
<p>英法诸国必须要与中国通商贸易，才能解决贸易顺差这个根本的问题。英国人实在不知道拿什么商品来进行贸易(貌似中国什么都不需要），于是不法商人想出了鸦片撬开中英贸易缺口的馊主意——这并没有得到英国官方的支持。</p>
<p>但是林则徐同志既不懂得经济，又不懂得外交，对欧洲人的认识也就停留在：我不给你茶叶，你的腿都站不直。<br>不管洋人打算干什么，总之洋人就是邪恶的，就该抓起来打板子。于是，自然而然的一顿开打，结果可想而知。<br>于是清朝官员施展出了村骗乡，乡骗县，一骗骗到guowuyuan，的传统技能，咸丰同志在故宫几乎自始至终听到的都是捷报频传。</p>
<p>清末，一会儿闹拳匪，一会儿闹白莲教，一会儿闹太平天国。然而，靠鸡冻的群众杀几个洋毛子并不能使中国变得强大。林则徐如果能够有点知识，不妄自尊大，能够说动咸丰开放正常通商贸易、拒绝鸦片，联军入侵圆明园的事大致可以避免。</p>
<p>经济问题才是导致社会动荡，战争爆发的根源。</p>
<blockquote>
<p>挑个刺 第一次鸦片战争清的皇帝是道光不是咸丰 白莲教不是清末的而是清中叶嘉庆年间的</p>
<p><strong>kkndme：</strong></p>
<p>确实是道光不是咸丰，笔误，特此道歉。</p>
<p>白莲教始于宋，最早可以追朔到南北朝时期，最早的名字叫“白莲社”。白莲教其实就是摩尼教，也就是倚天屠龙记里的明教，朱元璋靠白莲教得了天下，所以明代对白莲教的镇压异常残酷。清代的白莲教出现了许多分支，如八卦教、天地门教，先天教等等，总之白莲教从元代开始一直到清末都是闹得很凶的。</p>
</blockquote>
<h2><span id="房产投资的几点建议">房产投资的几点建议</span></h2><p>感谢大家的支持，不少朋友还提了一些关于房产投资的问题。</p>
<p>我觉得无论做什么样的投资，自己一定要做足功课。就房产来说，对于区域经济发展，要有深刻的理解，否则就不要轻易出手。</p>
<p>关于房产，我只是从大方向上说了一下自己的判断，并没有对区域的房产升值做过研究，所以没法给大家提供建议，请大家谅解。</p>
<p>不过，关于房产投资的方向，也有几点心得：供大家参考：<br>一、坚决不能投资自己不熟悉的城市<br>二、坚决不投资中小城市，一般省会及计划单列以上城市问题都不大，但中小城市即使房价上涨也存在变现困难问题。<br>三、坚决不投资距离大城市较偏远的旅游城市，比如山东乳山之类的，几乎无法变现。<br>四、慎重投资大城市的郊区，除非价格绝对低。如果外来人口比较多，zf又有发展规划，且价格与城区相比有较大的价差，才可以考虑</p>
<h2><span id="人民币对外升值对内贬值">人民币对外升值，对内贬值</span></h2><blockquote>
<p>楼主，据sz的统计公布09年底的商品房存量4~5万套，33%左右的自由率，10年新建成面积在300万平米左右，应该不算泡沫吧？目前美元走强，人民币贬值会导致国外热钱以及权贵的钱逃走么？对房地产影响怎么看？</p>
<p><strong>kkndme：</strong></p>
<p>人民币对外是升值，对内贬值</p>
</blockquote>
<h2><span id="南宁买房建议">南宁买房建议</span></h2><blockquote>
<p><strong>showforme：</strong></p>
<p>LZ帮忙分析南宁的楼市情况，这边的房价均价是6000多，最近中央说要投资1.5万亿给广西发展北部湾经济，也许对南宁楼市有一定的刺激作用，我想近期买一套房自住+投资，现在入手合适还是等到年底合适？</p>
<p><strong>kkndme：</strong></p>
<p>自住+投资？</p>
<p>自住房首要考虑的还是生活方便，不要太多考虑涨跌，没有意义，如果手里有钱就可以买。</p>
<p>南宁的房价我不清楚。但南宁是一个经济高速发展的城市是毋庸置疑的。</p>
<p>相对于昆明，南宁在面向东南亚贸易方面，有着更得天独厚的优势——港口。</p>
</blockquote>
<h2><span id="经济适用房都是内部分配的">经济适用房都是内部分配的</span></h2><blockquote>
<p><strong>yjfsam：</strong></p>
<p>看新闻说,在经济适用房里提供一定数量的廉租房,而不是大量廉租房,经济适用房是可以购买的,而且是建在市中心附近,如果是我,我当然是想买经济适用房,而廉租房又不多,这会不会跟楼主的意思有点不一样?</p>
<p>另外经济适用房在高价房附近推出,可以打压附近房价?</p>
<p><strong>kkndme：</strong></p>
<p>你认为建在市中心附近的经济适用房是给普通老百姓建的吗？是低收入群众有资格购买的吗？</p>
<p>经济适用房都是内部分配的，但一旦走进市场就可以牟取暴利了。</p>
<p><strong>tjOOSAN：</strong></p>
<p>大哥！！我真服你了。。。。。。</p>
<p>你知道 定向分配吗？？？就是只有拆迁户才有资格买的房子。不存在收入的问题！！</p>
<p>你纯粹是胡诌啊！我发现</p>
<p><strong>kkndme：</strong></p>
<p>兄弟，你一直比较鸡栋，呵呵</p>
<p>拆迁户的定向房属于另外的问题，作为有产阶级的拆迁户来说，部分是城市扩大化的受益者，而部分又是受害者，不能一概而论。时机不同，城市不同，境遇也不同。</p>
<p>但是有一点可以肯定，拆迁的目的，不是为了拆迁户过得更好更舒服。开发商愿意支付高额的拆迁费（只限于超大型文明的城市，许多城市拆迁户的补偿是很可怜的）而是有更大的利润可图。</p>
<p>zf为主导建设的市中心经济适用房也不仅仅为了拆迁户回迁，拆迁户回迁比例最多占小区总放量的30%，而其余的基本上是权贵房</p>
<p><strong>tjOOSAN：</strong></p>
<p>我可不激动！就是闲的没事，来找事吧！还算是正事！</p>
<p>你说的什么给权贵房，固然存在。但是比例太太少了！！你说的话，根本没有依据！</p>
<p>现在买限价房的和经济适用房的人，都要在报纸上公布姓名和住址。</p>
<p>而且只要不是太穷的，基本都希望拆迁！因为第一，给的钱多。 第二 可以有定向分配。而且还是好地段的房子！！</p>
<p><strong>kkndme：</strong></p>
<p>兄弟你还是去了解一下体制内分福利房的真相吧。</p>
<p>福利房占用的都是经济适用房的指标啊</p>
<p>真正向社会公示的保障房才有多少呢？相对于数量庞大的福利房，可以说凤毛麟角。</p>
<p>不了解真相就没有发言权啊</p>
<p>特别是在二三线城市，房源比一线相对略为宽松，一个有点级别的公务员，通常都是分两三套房，这些房子占用的都是保障房的指标，都是要统计入保障房数据的。</p>
<p>不信你可以问问身边的公务员、银行员工、垄断企业员工。</p>
<p><strong>tjOOSAN：</strong></p>
<p>奥！你说的是，传说中的 国企员工啊！！</p>
<p>可你一开始却说得是 经济适用房！是你搞错了把？</p>
<p>国企员工分配房子的，也要够一定工龄！一定级别！不是谁都有的。好伐？</p>
<p>而且 现在中国地产，很大一部分就是国企投资的。</p>
<p>所以叫内部分配么！！国企分房，在中国的体制内是正常的！</p>
<p><strong>kkndme：</strong></p>
<p>传说中的上海人？</p>
<p>我没有搞错，体制内员工分配的福利房就是经济适用房。</p>
<p>我举个例子，昆明武警干部的福利房叫恒安新邻居，它的官方名称叫什么？</p>
<p>我告诉你，叫做“武警经济适用房小区”</p>
<p>你看到的内部分房，占用的都是经济适用房的指标，也就是占用的是：我们所说的为了解决民生问题的保障房的指标。</p>
<p><strong>tjOOSAN：</strong></p>
<blockquote>
<p>kkndme</p>
<p>你认为建在市中心附近的经济适用房是给普通老百姓建的吗？是低收入群众有资格购买的吗？</p>
<p>经济适用房都是内部分配的，但一旦走进市场就可以牟取暴利了。</p>
</blockquote>
<p>这可是您自己的原话啊？？对吧？？</p>
<p>市中心的经适，就是叫做定向分配。就是 在这附近拆迁的人，住的！！</p>
<p>你非要说，有人谋私，我也不反对！但绝对不会多。</p>
<p><strong>kkndme：</strong></p>
<p>我估计是你理解错了，谋私和牟取暴利是两回事。</p>
<p>假设你是某市科级公务员，分到两套房子，以保障房的价格购买，但是却可以按照市场价格出售，只要一转手就可以进账几十万甚至上百万。</p>
<p>这就是分房双轨制给体制内有级别的员工带来的暴力机会。这跟谋私没有关系</p>
<p><strong>tjOOSAN：</strong></p>
<p>我觉得楼主拿经济适用房 做例子。很愚笨。</p>
<p>中国房价高起的根本原因，不就是国企，制造业资金进入地产么。</p>
<p>经济适用，现阶段就是为拆迁户盖得。</p>
<p><strong>kkndme：</strong></p>
<p>晕，也许你们上海是吧，放眼全国肯定不是</p>
<p><strong>jellyoak：</strong></p>
<p>上海今年以前根本没有过经济适用房，恰恰相反，上海是商品房最彻底的城市</p>
<p>给动迁户的叫动迁安置房，绝对都是建在最偏僻的地方的，最近5年基本上没有原拆原回的安置。</p>
<p>那位激动的同志有点多动症的嫌疑，忽略算了。</p>
<p><strong>tjOOSAN：</strong></p>
<blockquote>
<p><strong>kkndme：</strong></p>
<p>我估计是你理解错了，谋私和牟取暴利是两回事。</p>
<p>假设你是某市科级公务员，分到两套房子，以保障房的价格购买，但是却可以按照市场价格出售，只要一转手就可以进账几十万甚至上百万。</p>
<p>这就是分房双轨制给体制内有级别的员工带来的暴力机会。这跟谋私没有关系</p>
</blockquote>
<p>你。。我不知道你说这个是什么意思？</p>
<p>贪污腐败是少数。这是肯定存在的现象。但我现在讨论的是大众现象！</p>
<p>而且内部分房的们都要够一定级别！就算他们一人分三套，那根本对楼市没有影响的</p>
<p><strong>kkndme：</strong></p>
<p>我说的是房产双轨制，是一种制度，不是说个人的以权谋私。</p>
<p>房屋问题实际上是土地问题，当一少部分人群能够以很低的代价占有更多的土地，市场上的土地就会变得稀缺，价格就会上升。</p>
<p><strong>jellyoak：</strong></p>
<p>可以说上海是最彻底的商品房市场化的城市。</p>
<p>没有小产权，没有福利分配，完全的市场化。</p>
<p>唯一的例外就是动迁户能分配到动迁安置房，虽然都是地处偏远但现在也都价值高昂。</p>
<p>lz说的那种公务员分配的安置房在很多城市是很普遍的。</p>
<p>情况绝非那位偏执狂TX所理解的</p>
<p>事实是庞大臃肿的公务员机构都有机会给这些公务员分配到一套住房，总数量很是惊人。</p>
<p>如果严控贷款的话，现在上海的房价是得不到长久支撑的。</p>
<p>看长期政策如何了。</p>
<p>现在没人相信贷款可以一直这样卡下去。</p>
</blockquote>
<h2><span id="普通人怎么办尽早买房努力挣钱抵御通胀">普通人怎么办：尽早买房，努力挣钱抵御通胀</span></h2><blockquote>
<p><strong>被忽悠的群众：</strong></p>
<p>楼主：我们P民怎么办呢？只有买房保住自己的社会地位！？</p>
<p><strong>kkndme：</strong></p>
<p>问题是房子将会是普通人越来越难以参与的游戏，门槛越来越高。</p>
<p>只有努力工作赚钱才是唯一能抵抗通胀的办法，这也是zf最希望看到的。</p>
<p>当然体制内员工，工资制度本身就可以抵御通胀。这些多发出来的钱是需要体制外广大群众创造出来的，因为体制内员工本身并不直接创造价值。</p>
<p>而体制外的广大群众要想抵御通胀，就必须努力工作，创造更大的价值来提高收入水平。</p>
<p>这也就是国家能够维持运转的根源所在啊</p>
</blockquote>
<h2><span id="房价会出现很多上下波动">房价会出现很多上下波动</span></h2><blockquote>
<p><strong>fengyu1218：</strong></p>
<p>楼主，你所分析问题透彻明晰，很受启发</p>
<p>但是立足于将任何问题都用P民跟精英阶层对立的观点，我觉得有点绝对</p>
<p>社会阶层的复杂性，以及相互之间的博弈会在特定的阶段</p>
<p>有特定的表现形式，比如，当房价太高，P民阶层抗议不断的时候</p>
<p>会有所谓的调控出来，尽管成效不大</p>
<p>统治阶层也不会任由社会矛盾积累到最大程度而不作为</p>
<p>所以房价的表现形式会出现很多的上下波动</p>
<p><strong>kkndme：</strong></p>
<p>你说的对，房价趋势是上涨，但一定会有短期的波动</p>
<p><strong>tjOOSAN：</strong></p>
<p>而且对于你所标榜的“暴涨” 你自己后来也改了，是在波动中上涨！</p>
<p>那还是暴涨吗？你都违背了自己的标题。</p>
<p><strong>kkndme：</strong></p>
<p>呵呵，短期的调控并不能改变长期上涨的趋势，</p>
<p>当资金的运作规律收到外力的压制，短暂低头的房价就会迎来暴涨。这是规律。</p>
</blockquote>
<h2><span id="买房时机的选择真tm厉害这竟然是2010年的建议可恨的是2020年才看到">买房时机的选择（真TM厉害，这竟然是2010年的建议，可恨的是2020年才看到）</span></h2><p>很多朋友都关心买房时机问题</p>
<p>对于自住需求者和投资需求者是要区别对待的</p>
<p>对于一线城市与二三线城市也是要区别对待的</p>
<p>对于自住需求者（仅指普通群众）来说，只要你还有钱能够买的起房，那你就买吧。</p>
<p>不要赌博和赌气，因为真的赌不起。</p>
<p>人人都可以买得起商品房，只是一个美丽的童话。</p>
<p>当然如果你赶上了国家调控的好时机，那你就要认真选房，做足功课，迅速出手。因为买到一套户型、位置、楼层都让你满意的房子，在商品房热销期，是很难的事情，根本没有给你挑选的机会，而在调控期，或许房价没怎么下降，但绝对给了你挑选的余地。</p>
<p>对于投资来说，问题就比较复杂，要考虑的问题就会更多，不同条件的人就有不同的需求。</p>
<p>总的来说在严厉调控期，需要关注以下几点：</p>
<p>一、当新盘的价格低于周边二手房的价格。<br>二、当看房的人不断增加<br>三、当kas拿地热情大减，以至于多处土地流拍</p>
<p>以上三点是提示你准备出手的信号。</p>
<p>对于一线城市，一定会有一段时期小幅下跌，及跌后滞涨。</p>
<p>对于二三线城市，多数城市会缓步持续上涨。但遇到大规模拆迁的城市，那房价就会忽视调控，选择快速上涨。近期，在二三线城市，无论自住还是投资，都是早买好于晚买。</p>
<h2><span id="收入分配改革跟体制外的人没关系">收入分配改革跟体制外的人没关系</span></h2><blockquote>
<p><strong>feifeilongdi：</strong></p>
<p>请问楼主国家的收入分配改革调整的是哪一部分人的收入？</p>
<p>我们底层p民如果真的连公租房都只能勉强供得起，那以后子女的抚养费用，夫妻以后的养老资金如何解决</p>
<p><strong>kkndme：</strong></p>
<p>工资收入分配改革应该只是个说法，对公有制经济是很有实惠的。但非公有制员工的工资是阳光雨露都撒不到的。</p>
<p>以前说涨工资基本都是公务员，收入分配改革后可能对事业单位及国企工资收入有明显改善。</p>
<p>至于体制外，无论打工仔和个体户都是自生自灭的</p>
</blockquote>
<h2><span id="体制外的人要早早考虑养老问题">体制外的人要早早考虑养老问题</span></h2><p>体制外人员养老确实是个问题</p>
<p>做生意的赚钱养老</p>
<p>聪明的下手早的以房养老</p>
<p>最惨的是没有混上去，且又没有特殊技能的私企打工仔。养老实在是个大问题。</p>
<p>所以东部地区才有宁挣老板1000元，不赚打工5000块的说法。</p>
<p>双轨制下，低层群众想翻身确实比较难。</p>
<h2><span id="永远不要和白痴争辩因为他会把你的智商拉到和他同一水平然后用丰富的经验打败你">永远不要和白痴争辩，因为他会把你的智商拉到和他同一水平，然后用丰富的经验打败你</span></h2><p>鸡冻先生</p>
<p>能够有资格跟你辩论的一定只有两种人</p>
<p>一种是智商极高，世间罕见的</p>
<p>一种是智商比较低的。</p>
<p>其他人跟你辩论那是自找苦吃</p>
<h2><span id="当个农民也要懂政策要顺政策而为">当个农民也要懂政策，要顺政策而为</span></h2><p>刚从深山老林钻出来，终于找到地方洗澡了，我激动啊。</p>
<p>洗完澡轻松，讲一个刚从支书那里听来的故事。</p>
<p>大家普遍感觉很穷的贵州省榕江县栽麻乡宰荡村，在解放前却是有名的富裕村，他们靠勤劳开垦荒地，良田多到种不过来，直到土改后，zf将宰荡的良田分给了加所、林所等周围几个土地较少的村子的村民（这些村子土地少的原因主要还是周围几个村子的村民比较懒惰，宁肯受穷也不愿意开垦荒地），宰荡才穷下来。</p>
<p>因为宰荡村过去比较富裕，拨给的富农指标就比较多。有一户人家很富裕，按理应该划为富农，但这户人家很了解政策，知道评上富农就会挨整，于是走关系，成分改成了中农。</p>
<p>而其他大多数依靠勤劳致富的人家非常老实，也不懂评为富农有什么不好，认为什么成分都无所谓，还不是老老实实干活。结果可想而知。当上了富农接下来就是没完没了的批斗。</p>
<p>这个故事告诉我们，哪怕当个农民也必须了解zf的意图。</p>
<h2><span id="存钱不如存资产钱会贬值资产会升值">存钱不如存资产，钱会贬值，资产会升值</span></h2><p>去年在宰荡做了一段时间的田野调查，今年这次来算是回访。时过一年，发现去年村子附近的大多数农田，今年都变成了房子。</p>
<p>现在农民政策还是可以的，即使贫困如贵州山区，农民除了能够完全自给自足外，多余的粮食蔬菜也能换来一定的经济收入，随着家境变好了，对更大的房子的需求也就产生了，农民愿意把闲钱都用来盖成更大的房子，宁肯牺牲掉自有耕地。这其实是一件可怕的事情。</p>
<p>这次同样对村民做了入户调查，发现了一件有意思的事情。</p>
<p>村民最感到遗憾的事情就是早在2000年初，那时村里还没有电，村民为了想让全村通电，卖掉了所有山上的古树。电通了，当时的村民很高兴，而且认为古树卖了一个高价格（当时总共卖了6万块钱），换来了全村的生活方便。</p>
<p>大约在三年后，其他村寨，zf都给免费通了电。如果那些古树不卖掉，现在随便一颗的价格都超过了6万。现在那些古树至少值几百万。</p>
<p>村民们用最朴实无华的思想总结了一个道理：存钱不如存房子、存木头、存树</p>
<h2><span id="房子越早买越好zf想钱想疯了">房子越早买越好，zf想钱想疯了</span></h2><p>全国人民都知道有个以雷厉风行著称的球书记</p>
<p>球书记曾说过一段著名的话，大意是：昆明的开发商拿地价格很低，卖的价格却很高，腐败才是高房价根源。</p>
<p>当时昆明的很多无房户都很鸡冻，以为这下可好了，找到问题根源了，昆明房价要降了。</p>
<p>可是我听到的意思却是：zf卖地卖得太低了，应该大幅提高土地价格。</p>
<p>果然不久就出台了54321政策，以前拿地没走招拍挂程序的，一律按照54321补交土地款，否则开发商不发放任何证件，以至于升级到已买了房的业主也拿不到房产证。</p>
<p>于是昆明的新盘由于手续问题都无法开盘，已经卖掉很久的老盘，开发商还要求业主补交房款，否则退房。</p>
<p>结果可想而知，昆明的房价以一环与二环之间为例，由去年下半年的6000多涨到现在的均价过万。</p>
<p>如果从民生着想，会做出这样荒唐的事来吗。</p>
<p>帖子里有朋友问昆明的买房时机，我只能说越早买越好，因为dfzf想钱已经想疯了</p>
<h2><span id="利益才是zf行为的指挥棒">利益才是zf行为的指挥棒</span></h2><p>北大朱晓阳用了十多年时间跟踪昆明城中村，对刚刚建好5年的宏仁村就要因为商业利益而拆迁已经出离了愤怒，结果这事捅到CCAV曝光了，拆迁的事只好暂停。</p>
<p>利益才是zf行为的指挥棒</p>
<h2><span id="建议一定是建立在严肃考察的基础上">建议一定是建立在严肃考察的基础上</span></h2><blockquote>
<p><strong>爱情就像跳恰恰：</strong></p>
<p>这两天全部看完了，深受触动，楼主是个睿智的人，赞一个~</p>
<p>想说下自己的情况，楼主帮我参谋一下，我在上海，女性，前几年由于一些特殊个人原因，导致一直没有自己的房子，这两年专注于事业，今年发展不错，进帐了260万左右，但是，通过几次看房，我发现 300万以内，已经找不到理想的房源！</p>
<p>我现在是租住的市中心高档住房，每月租金 8500块，100个平米左右，这样的房子大概售价 500万左右，所以，现在的情况是 我想住的房子买不起，买的起的我也不想住~</p>
<p>我本人对买房和租房没有太大感觉，从某种意义上说 我倒更喜欢租房，可以每两年换个区 换套新房住住 比较有新鲜感~但是，我手上也不想持有现金，由于物价上涨，通货膨胀，我觉得持有现金的风险也不小！</p>
<p>不知道楼主对扬州的房产怎么看，我想放弃上海，到扬州购入房产，处于保值或者以后升值空间大后再售出，比如在市中心购入两三套高档小户型，用于出租！扬州由于地理优势，一两年后可能开通上海高铁，这样考虑在扬州安个家也不错，再置入一套生活便利的大点房子，以后可以考虑自住~</p>
<p><strong>kkndme：</strong></p>
<p>你的想法显然是经过深思熟虑的，在扬州买房子自住，花更少的钱过更舒适的生活很好啊，当然前提是你自己喜扬州这个城市。</p>
<p>说到投资，其实没人能够取代你自己的判断。我也没法给你提供究竟有多大升值空间的建议，因为建议一定是建立在严肃考察的基础上的。</p>
<p>我只能说东部地区的城市房产保值还是没问题的，但在哪个城市投资更好，确实需要认真实地考察。</p>
<p>如果从全国范围看，仅对投资而言，我比较看涨西安和重庆。但我个人不会在这两个城市买房子，因为本人不喜欢重庆的酷热和西安的气氛。</p>
</blockquote>
<h2><span id="石家庄">石家庄</span></h2><blockquote>
<p>楼主，请评价下石家庄的楼市，是暂时的价值洼地还是长期？</p>
<p><strong>kkndme：</strong></p>
<p>石家庄的地理和经济上的位置都比较尴尬。山西和天津都比石家庄有更好的优势</p>
</blockquote>
<h2><span id="投资最重要的是稀缺性买房首选公务员小区">投资最重要的是稀缺性，买房首选公务员小区</span></h2><p>说到买房子，无论投资还是自住，最重要的还是稀缺性，首选还是学区房。</p>
<p>自住最好买政府公务员小区，无论是商业配套，教育配套以及休闲娱乐配套都是商品房所无法比拟的。特别是商品房经过十几二十年，房子旧了，电梯很容易出故障，如果物业有问题或者小区里有人不交物业费，那么这个小区就很难住了。公务员小区则完全不用考虑房子老旧的问题，那都是zf包干到底的。</p>
<blockquote>
<p><strong>usstcai：</strong></p>
<p>怎么找这种房源呢？</p>
<p><strong>kkndme：</strong></p>
<p>每个城市的情况不一样，北京基本上是单位的老公房，老计委的房，中石化的房都有上市交易的，但新房很难找。</p>
<p>至于二三线城市，现在还存在大量的公务员、垄断企业的新小区，并且很多房源都在市场上交易。比如昆明，存在大量的权贵小区，比如金江小区是省政府公务员小区，月牙塘小区是市政府公务员小区。</p>
</blockquote>
<h2><span id="远离垃圾人">远离垃圾人</span></h2><p>关于流氓无产者，在宰荡村子里还听了个故事</p>
<p>说很久以前的事情。</p>
<p>宰荡村民都很勤劳很淳朴。但是意外的出了一个叫罗老黑的人。</p>
<p>这个人好吃懒做无所事事，看见人家地里庄稼蔬菜长的好就跑去抢，为此挨过几次打。有一天罗老黑路上遇到个大兵，骗了大兵的枪，于是开始在村子里耀武扬威，不但抢人家辛辛苦苦种的菜，遇到单身的姑娘还动手动脚。</p>
<p>罗老黑在村里到处宣传他的逻辑：村里的庄稼、蔬菜、猪牛应该见者有份。</p>
<p>村里一些年轻人受了罗老黑的感染，开始变得好吃懒做，谁家种的东西都跑去拿。于是，村里人都不愿意劳动了，宰荡村开始变穷。</p>
<p>村里有个人很憎恨罗老黑的行为，但不敢明着跟王老黑作对，就在晚上在王老黑家放了一把火。侗族人住的房子都是杉木的，一旦一家着火，很可能全村遭殃，那把火烧了整个宰荡寨子，连青石板都烧裂了。</p>
<p>罗老黑，这个典型的流氓无产者，他的光荣事迹被当作反面教材激励着世世代代的宰荡村民。</p>
<h2><span id="高房价或许有天会崩盘但你等不到那一天">高房价或许有天会崩盘，但你等不到那一天</span></h2><blockquote>
<p><strong>zhuce010022：</strong></p>
<p>不合理的制度不会永远的存在下去的。。。正如国父当年说的一句“天下大势浩浩荡荡，顺之者昌，逆之者亡”。。。</p>
<p>现在的高房价是目前中国的政治、经济结构失序造成的。</p>
<p>楼主上面分析了那么多，确实是，在目前这种局面下可能一直冲到崩是唯一的选择，但是，你怎么知道这种失序的大局面会一直持续下去呢？</p>
<p><strong>kkndme：</strong></p>
<p>一个朝代从鼎盛到衰亡至少维持个一两百年。所谓天下大势分久必合，合久必分，由合到分，总还是有个时间跨度的。</p>
<p>侥幸能在有生之年平平安安就是最大的福气，身死之后，哪管洪水滔天</p>
</blockquote>
<h2><span id="房子不仅要早买而且有能力的话不要怕压力争取一步到位">房子不仅要早买，而且有能力的话不要怕压力，争取一步到位</span></h2><blockquote>
<p><strong>傻子也疯狂：</strong></p>
<p>楼主</p>
<p>你好</p>
<p>跟你的帖子已经两晚上了，还是没看完</p>
<p>不过已经到第六页了，我会继续跟下去</p>
<p>感觉你分析很有道理，也很深奥<br>以前在一个炒房人的终极预测也看到过类似的帖子<br>慢慢的也有所感悟<br>现在想请教你个问题，也是我自己面临的问题</p>
<p>人在深圳，想趁今年调控在武汉买套房子，因为有回武汉发展的想法<br>我毕业三年，收入不高，目前可能首付都不够（40万总价我想付10—15万，别笑我无能）总是在想是等我存够了首付再回去看房子还是现在就订下来，订下来吧钱不够，可能要问朋友借点，既要还债又要月供怕压力大，如果先不买等存够钱我怕那时候房价又上去了，所以想你帮我参考参考，给点建议，谢谢，诚信请教</p>
<p>另外，我和我女朋友月总收入8000左右，你觉得买总价40万的压力大吗<br>准备两年后结婚，再次感谢。</p>
<p><strong>kkndme：</strong></p>
<p>40万首付15万，贷款25万，月供1000多，你和女朋友月收入8000，你觉得有压力吗？</p>
<p>二三线城市往往早买好于晚买，特别是你是自住。</p>
<p>40万的房子要不然是比较小的，要不然就是郊区了，如果你们有8000的月收入供60万的房子是不成问题的，建议不要图便宜，首选还是位置，宁可买贵点买离城中心近的房子，因为将来能够买得起改善性住房的会越来越少，有能力的话还是尽量买到位。要特别考虑今后小孩上学的配套问题。</p>
<p><strong>傻子也疯狂：</strong></p>
<p>楼主可能还不明白我的意思</p>
<p>我的首付目前也就10万</p>
<p>如果买大了首付要三成，按你说的卖60万的好是好</p>
<p>可首付至少要18万</p>
<p>我没有这么多怎么办呢</p>
<p>如果借钱，还债又月供，还要考虑两年后结婚。。。。。。。。</p>
<p>你觉得怎么办好，或者你有更好的建议</p>
<p>谢谢</p>
<p><strong>kkndme：</strong></p>
<p>如果只差8万，家里支持一些，亲戚朋友借一些，一挺就过去了。很多刚开始买房的年轻人都是要咬牙买的，换来以后的轻松。甚至很多人因为今后收入的提高，几年就把贷款还完了。</p>
<p>当然，如果真的凑不上，还是量力而行，但买房还是买位置，首选离城中心近的，宁可买小一点。住在远郊区的大房子里花1个多小时的时间上班才是受罪</p>
</blockquote>
<h2><span id="金融杠杆是炒房赚钱的放大器">金融杠杆是炒房赚钱的放大器</span></h2><blockquote>
<p><strong>错误角色：</strong></p>
<p>其实个人觉得普通炒房者不一定就能获多少利，比如他买一套新房是三千每平，等新房价到六千时出手，他能卖到五千每平。看上去他每平赚了二千…但是，他要继续炒的话，就要再加每平一千的本金进去买新房…看上去他们是资产翻翻了，但是他们的二次投资也是翻翻的…也就是说他以前三十万买了一百平，现在卖出去是五十万，看上去赚了二十万，但是，他想再买个一百平的却需要六十万…他还得从老本掏十万买同样大小的房子…这样算我也不知道对不对…要是对的话，就说明炒房的人不是抬高房价的最根本原因和最关键因素…… </p>
<p><strong>kkndme：</strong></p>
<p>你没考虑金融杠杆的作用，真正的投机炒房是贷款炒房，而投资客更愿意一次性付清。一个炒房客用20万可以买100万的房子，等到200万卖掉，投入20多万，赚了170多万。然后用变现的钱又可以贷款买多套，这就是投机炒房比股市更吸引人的地方，但是一旦资金链断掉就会比较惨。</p>
<p>这种赌徒心态的投机炒客还是比较遭人恨的，这次调控提高首付比例，对这类投机炒家打击不小。小资金的纯粹投机客数量控制在一个比较小的范围内，房产市场才会健康发展，这个国家是有共识的。所以二套房首付比例提高后，有可能变成常态</p>
<p><strong>tjOOSAN：</strong></p>
<p>这话。。。让我肝颤！~~ 投入20万？赚170？？还贷了80万呢</p>
<p>还有利息呢！~~</p>
<p><strong>kkndme：</strong></p>
<p>09年初20万首付买的100万的房子，2010年初涨到200万卖掉，你认为1年能还多少利息。难道炒房客一套房子拿满20年再卖？</p>
</blockquote>
<h2><span id="要用发展的眼光看问题只要努力只会越来越好越来越轻松">要用发展的眼光看问题，只要努力，只会越来越好，越来越轻松</span></h2><p>要用发展的眼光看问题，只要你还年轻，即使你现在给老板打工只能赚4000块，并不意味着以后多少年都只赚4000块，随着经验和阅历的增长，薪水是会提高的，当然前提是肯学习，肯吃苦，提高能力和才干。</p>
<h2><span id="性格决定命运">性格决定命运</span></h2><blockquote>
<p><strong>错误角色：</strong></p>
<p>我只买得起4000元内100平的房子！哪怕住小点，住旧点…我也不愿意背着几十年的债度过我最美好的青年和中年时代、我更不愿意每天睁开眼就开始为了还房贷而奋斗。我不想短短的一辈子只是为了一堆只有七十年产权的砖瓦而奋斗。我只是一个平凡普通的人，我只想和老婆有一个快乐安逸的小家…但是“家”这个商品已经成了现在对我来说最昂贵的奢侈品。哈哈！</p>
<p><strong>kkndme：</strong></p>
<p>有一句话叫做怎么样付出就会怎么样的收获，看到许多人买房获利，另一些人坐不住了，心态变得鸡冻了，但是，当初人家咬牙买房的时候，另一些人还在追求所谓的生活品质。性格决定了命运</p>
</blockquote>
<h2><span id="2012年不取消调控还有房价维稳顺利换届考虑">2012年不取消调控，还有房价维稳顺利换届考虑</span></h2><p>zf希望房价维稳，为2012年换届后上涨留出空间，所以调控政策不会轻易取消，但是在高通胀预期的背景下，能不能稳住房价是很考验zf智慧的。</p>
<p>换届后的老板不可能去接一个烂摊子，这是关键的地方</p>
<h2><span id="洼地最终都会被填平多数城市是早买胜于晚买">洼地最终都会被填平，多数城市是早买胜于晚买</span></h2><p>目前传言与辟谣越来越频繁，如何透过重重的迷雾看到事情背后的真相。</p>
<p>这次调控zy盯的主要还是一线城市，从提高首付比例，直到监管预售款的准备推出，都是为了提高房地产进入门槛，踢出大量小资金投资客，让小开发商民营开发商知难而退，为国家队入场铺路，zy需要稳定一线城市房价，使2012年能够顺利换届，为换届后的上涨留足空间。有了国家队的后盾，zy无需因为调控导致部分小开发商资金链断掉而担心，相反这是zy希望看到的。</p>
<p>当然在政策和市场的博弈中，是否能够达到zy的预期，zy的心理也不一定完全有底，因为资金有他自己内在的规律。在打压房地产的同时，会带来农产品等生活必须品的价格全面上涨，这就需要xy做出一个权衡。因为填饱肚子的问题比房价的问题更重要。</p>
<p>多数二三线城市会在一线城市滞涨期间进行补涨，补足09年行情中远低于一线城市的涨幅。</p>
<p>作为二三线城市的刚需买房者，多数城市的情况都是早买胜于晚买</p>
<h2><span id="西部">西部</span></h2><blockquote>
<p><strong>mstsc_XP：</strong></p>
<p>楼主对成都的房子咋看？</p>
<p><strong>kkndme：</strong></p>
<p>在西部地区，重庆、西安、成都、昆明投资房产都不会有问题。西部的其他城市就要谨慎，不是因为房价不会涨，而是因为变现比较困难。</p>
<p>四川、重庆经济的高速发展是不容置疑的，但存在最大的隐忧就是三峡大坝对生态和环境的破坏根本无法预测。</p>
</blockquote>
<h2><span id="短期波动属于正常现象需要关注的是长期趋势">短期波动属于正常现象，需要关注的是长期趋势</span></h2><blockquote>
<p>mobster6789</p>
<p>楼主的一番讲解真如拨云见日！</p>
<p>但是本人认为，在目前基本面疲软的情况下，成交会进一步萎缩，房价在短期内也还有小规模下调的趋势，请楼主评议。</p>
<p>kkndme</p>
<p>短期的波动是再正常不过的事情，把握政策可以把握趋势，但很难做到准确的逃顶与抄底</p>
</blockquote>
<h2><span id="领导人的智慧和才干决定了国家的命运统帅的智慧和才干决定了军队的命运而个人的智慧和才干决定了个人的命运">领导人的智慧和才干决定了国家的命运，统帅的智慧和才干决定了军队的命运，而个人的智慧和才干决定了个人的命运</span></h2><p>领导人的智慧和才干决定了国家的命运，统帅的智慧和才干决定了军队的命运，而个人的智慧和才干决定了个人的命运。</p>
<p>精英社会相对于法制社会存在更多的不稳定性，更崇尚个人能力、才干与职业精神，如果刘备只懂得眼泪是不可能得到三分天下的。</p>
<p>精英社会的根本就是以人治国，就是要承认人与人之间的差别。</p>
<p>百年战争，法国拥有全世界最强大的重骑士军团，可是由于统帅的无能，被英国长弓兵打得落花流水。</p>
<p>而耶路撒冷王国的鲍德温四世，一个年轻的麻风病人，率领几百个骑士打得萨拉丁三万马木流克骑兵溃不成军，几乎全军覆没。</p>
<p>一个人很可能决定一个国家的命运。</p>
<p>也许任何一个国家，甚至中国历史上任何一个朝代都没有象现在那样金权至上。</p>
<p>无论中国的儒家思想还是西方的骑士精神，都告诉人们，人总是要有所追求的，不能仅仅盯着钱。</p>
<p>秦时，有个老头叫郦食其，70多岁了还跑到刘邦大营参与革命，当然最后下场比较凄惨，被齐王煮了。郦老头本事很大，只身到齐国说服齐王归降了汉王刘邦。韩信害怕郦老头功劳太高，超过自己，于是很不仗义，在郦老头人还在齐国的时候，带兵攻打了齐国。齐王很愤怒，后果很严重，把郦老头放在锅里煮了。郦老头的才能出众，本想做一番事业，可惜没有算到人类本性丑恶的一面。</p>
<p>当然韩信也没有好下场，这个军事上的天才，政治上的白痴，本来做了齐王，汉、楚、齐三足鼎立，结果向刘邦缴了枪，直接兔死狗烹了。</p>
<p>另一个喜欢没事找事的老头叫姚广孝，是个和尚，法号道衍。虽是和尚，但既无和尚的慈悲心肠，又无和尚的遁世清修，这个老头专门搞权谋，不玩阳谋专玩阴谋，背靠朱棣这颗大树，不图名不图利，专搞武装夺取政权。</p>
<p>姚老头的头脑比郦老头高得多，不但是牛叉的阴谋家，也是牛叉的政治家，此人协助朱棣夺权后，深味帝王权术的精髓。不立家室，不营产业，把一脑袋阴谋全都转向文化事业，跟大才子解缙纂修《永乐大典》，是为数不多投身权谋得了好死的大师级人物</p>
<p>另一个喜欢没事找事的老头叫姚广孝，是个和尚，法号道衍。虽是和尚，但既无和尚的慈悲心肠，又无和尚的遁世清修，这个老头专门搞权谋，不玩阳谋专玩阴谋，背靠朱棣这颗大树，不图名不图利，专搞武装夺取政权。</p>
<p>姚老头的头脑比郦老头高得多，不但是牛叉的阴谋家，也是牛叉的政治家，此人协助朱棣夺权后，深味帝王权术的精髓。不立家室，不营产业，把一脑袋阴谋全都转向文化事业，跟大才子解缙纂修《永乐大典》，是为数不多投身权谋得了好死的大师级人物</p>
<blockquote>
<p><strong>打工不易：</strong></p>
<p>我个人认为：个人的智慧来自对大方向的把握，否则再有才干也难有作为。</p>
<p>单位司机，工厂工人即便技术再好，工资也高不到哪去。</p>
<p><strong>kkndme：</strong></p>
<p>聪明智慧决定了人的眼界，有远见的人一定会未雨绸缪。刘邦身为区区亭长可以得天下，朱元璋一个穷和尚驱除鞑虏重建朝廷，一个司机未尝不能当富商，一个小姐也可能当局长</p>
</blockquote>
<h2><span id="对于具备投资属性的商品供求关系是指货币与商品之间的关系">对于具备投资属性的商品，供求关系是指货币与商品之间的关系</span></h2><p>关于供求关系还是有必要解释一下的</p>
<p>一提起供求关系，马上口水就来了，什么空置率啦，闲置率啦，空置我心啦，电表显示6000万套房没人住啦。</p>
<p>实际上供求关系跟空置率和闲置率完全没有关系。</p>
<p>对于具备投资属性的商品，供求关系是指货币与商品之间的关系。当货币量大于商品供应量时，商品价格就会上涨，即使人为打压也是短期行为，这是铁律。</p>
<h2><span id="早买的风险小于晚买">早买的风险小于晚买</span></h2><blockquote>
<p><strong>fantabulouski：</strong></p>
<p>楼主给点意见吧，想在上海市内环内买套二手房，现在出手合适嘛？</p>
<p>等等的话可能跌点么？有没有什么风险吗？</p>
<p>多谢！ 因为首套房可以贷款七成，多谢！！</p>
<p><strong>kkndme：</strong></p>
<p>如果手头有钱，又是自住，到不一定非要考虑抄在最底部。</p>
<p>因为钱要贬值是毋庸置疑的，房价在一段较长时期上涨的趋势也是毋庸置疑的。</p>
<p>但短期，波段性的抄底和逃顶是很难把握的，尤其是自住，考虑太多实在没有意义。</p>
<p>持币要冒房价持续上涨的风险，买房可能会面临短暂小幅下跌，哪个风险更大，需要自己认真考虑。</p>
<p>一线城市如上海一定会有短期的滞涨甚至小幅的下跌，当新房的价格低于周边二手房价，并且成交量开始逐渐攀升就是买房的时机。<br>我反复强调，这次调控期却是二三线城市的补涨期，对于一线城市正好可以仔细的挑选好房，这种机会在房价上升期是难以遇到的。</p>
<p><strong>fantabulouski：</strong></p>
<p>楼主再问一个问题，看看这一两天调控的信息满天飞，上海房产税的消息也到处都是，银行在不断的紧缩，感觉这次调控可是不同以往，是外松内紧啊，至少到年底前看不到放松的迹象，还什么情况下才可能会放松呢？难道要等到KQ 接班不成？</p>
<p><strong>kkndme：</strong></p>
<p>可以肯定的是首付款的比例是不会轻易放松的。房产税的推出就没那么容易了。</p>
<p>上海和北京城区的二手房价有点幅度的下跌几乎不可能，很长一段时间都会滞涨或者维持小幅度的上涨。</p>
<p>手里资金多的人全款买房的比例大幅提高，精英阶层的购买力基本能够维持一线城市的正常的成交量（09年下半年的高成交量zy认为是反常的，已经影响了金融秩序，是zy不愿意看到的。）</p>
<p>现在的状况是，zy对调控后一线城市的房价增幅及成交量基本是满意的。</p>
</blockquote>
<h2><span id="小开发商的房子能不能买">小开发商的房子能不能买？</span></h2><blockquote>
<p><strong>mstsc_XP：</strong></p>
<p>楼主的分析让我明白了很多之前误解的东西，所以自己错过了买房时机也是有一定道理的O(∩_∩)O哈哈~</p>
<p>比如空置率、供求关系、当地房价和当地平均收入关系等的解释，非常感谢</p>
<p>想再请教一下，zy要挤出小开发商的话，到2012年，这些小开发商修的房子会不会烂尾?因为被挤出了，也不好好修了，或者干脆跑了…..因为我买的房子不是华润、中海这些有实力的开发商的楼….</p>
<p><strong>kkndme：</strong></p>
<p>如果不是经济危机，基本不会出现这种情况，当然排除个别不诚信的开发商</p>
</blockquote>
<h2><span id="大兴土木搞建设的城市房价都底不了">大兴土木搞建设的城市，房价都底不了</span></h2><blockquote>
<p><strong>黛眉轻：</strong></p>
<p>LZ厉害，分析得很透彻。请教LZ，对于目前的合肥房价怎么看呢？做为皖江城市带的中心城市，合肥的房价目前中心城区已经到了7000，也有了超过万元的所谓豪宅。和武汉长沙比起来，经济上感觉合肥还是差的，可是房价却已经不差了。</p>
<p><strong>kkndme：</strong></p>
<p>凡是大兴土木积极拆迁的城市，房价都低不了，城市发展规划的资金都要得益于dfzf卖地。这是zf主导投资经济模式的必然结果。这也是二三线城市在这次调控中补涨的根本原因</p>
</blockquote>
<h2><span id="北京老式砖混板楼的最终命运">北京老式砖混板楼的最终命运？</span></h2><blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>楼主我想请教一下：就是北京二三环甚至四环有不计其数的老式砖混板楼，年代分布从六七十年代到八十年代初的都有，这些房子都是北京城市发展的产物，也是北京留给土著们的天然福利，但是现在有个问题是它们的房龄已经超过30年奔着40,50去了，这些房子的命运如何呢？拆迁吗？在原址上盖回迁房或者重新规划把里面的居民赶到周围郊区？</p>
<p>因为随着政策的收紧，这类房子越来越不容易流通了，银行不给贷款，升值空间也逐渐放缓，但是地段都非常好。是不是随着房龄的增加，这类房子只剩下保值功能而最终无法流通了呢？</p>
<p>这批房子最终会大规模寿终正寝，不知道dfzf会怎么处置？很想听听你的看法。</p>
<p><strong>kkndme：</strong></p>
<p>这个情况比较复杂，因为大多数老房子是各大部委的单位房。原则还是谁的孩子谁包干，谁的孩子谁认领。所以说买房子买到公务员小区最保险，即使房子旧了也不会没人管，也不会存在物业跑路、小区沦为贫民窟的问题，即使老房子拆了单位盖了高楼，保证会在原址上还你一套。</p>
<p>至于说单位不行了或者单位不存在了的老公房也是有的，早晚会走拆迁的路子，那就没有原址回迁那么幸运了，肯定是搬到远郊区县，但补偿条件肯定不差，离开城中心到郊区就成了富翁。</p>
<p>位置决定了价值。北京郊区农民房拆迁补偿两万一平就算高的，但是城中心房屋拆迁，补偿款那都是10万一平起步的。愿意一掷千金全款买城中心老房子的人只会多不会少，说白了就是：哥买的不是房子，是位置。</p>
<p><strong>welldayzwb：</strong></p>
<p>现在貌似 还没有听说10万的，反而是听说政府给你的补偿比市价二手房价格还低不少，如果没有拼死斗争的话</p>
<p>前段看新闻说是北京要控制拆迁成本，估计就是为了这一步压缩成本来着</p>
</blockquote>
<h2><span id="把房买在zf边差不了">把房买在zf边，差不了</span></h2><blockquote>
<p><strong>yy45678：</strong></p>
<p>楼主您好，想请教下，最近想买房，三线城市老住宅区（我们那里最早的商品房90年建的）附近一幢私房，上下二层半，120平一层,带地皮93年的房子，所有证件齐全，不好的是建在一个山坡上不能进车子。售价一起30W，另是城市新区，新市政府边，小区房。现在还很荒，什么都不方便,但环境很好。请问是买哪一个房子好？我们那里平均楼价2000左右。</p>
<p><strong>kkndme：</strong></p>
<p>2000一平的地方，好像算不上三线城市，大概应该是地级市或者县级市的房价。</p>
<p>一般来说房子买在市政府边上怎么也不会有问题，只要确定新市政府已经搬到你说的那个地方，该地的升值空间肯定是有的。但是如果仅仅是zf规划就要谨慎了，因为规划并不等于真的搬迁。</p>
</blockquote>
<h2><span id="天子脚下二手老房买得好拆迁补偿少不了">天子脚下：二手老房买得好，拆迁补偿少不了</span></h2><p>旅行中，上个网是很不容易的事情。</p>
<p>关于拆迁补偿的事，巨大的利益驱使，那真是鲜血淋淋的。所以二手老房买在哪里很重要。银行的房、zf的房、各大部位的房，有上市交易的，买下来肯定不会吃亏。</p>
<p>存在风险的就是弱势群体聚居区。但是北京，毕竟天子脚下，不能搞得太僵，最终该补的还是会补到位，至于外省就很不好说了</p>
<h2><span id="3万入手北京四环你也是幸运的">3万入手北京四环，你也是幸运的</span></h2><blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>北京七八十年代的砖混老房有体制内的，也有体制外的。现在公房上市流通，好多央产房也易主了，也许过个十年二十年的这批房子的产权证上早已换了一波又一波人。除非像楼主所说的昆明那种大型的省市公务员小区，房子新，户型好，环境和地理位置都不错，一般公务员没个20年轻易不会卖。</p>
<p>北京的这些老楼，不管谁是房主，肯定值钱，房子不值钱，位置还值钱呢。</p>
<p>至于这些房子使用寿命到了以后怎么处置，谁也说不清，能不能回迁，要看dfzf和规划局的利益。比如眼下金融街西侧月坛的老房子就要被集体拆除，连中学都要搬迁，这些西城人很有可能被撵到昌平回龙观西去，那边已经在建大批安置房了。</p>
<p>所以说，这些老房子不管是体制内的还是体制外的，命运如何不在自己手里。即使体制内的比较不错的老小区（比如三里河的建设部小区），如果牵涉到地方的利益，肯定也是毫不犹豫全部拆除，除非那里面住着实权人物当官的不让拆。这个时候就要看这些被拆迁户的谈判能力了，谈判能力强的，当个钉子户，当然是要得越多越好。</p>
<p>我以前买房的时候，也想了这些，不过最后还是买了新楼。现在因为地皮的价值，北京新老楼的房价差距不大，这个在别的城市是不可思议的。</p>
<p>很感谢楼主发这么一个帖子，版主还给了个绿脸，要不然可能就错过拜读的机会了</p>
<p>其实有些问题平时自己也在思考，比如GDP为什么保八，房价和滥发纸币等等，但是关于炒房和房租这一块，思考的并不多，而楼主的帖子比较有条理和逻辑的分析了这些方面，真的是很感谢，我甚至不用自己写分析，只要把楼主的帖子稍微整理，就是一篇很不错的分析资料了。</p>
<p>关于zf收紧口子，抬高小老百姓炒房门槛这一块，天涯房观有几个高人和楼主的看法一致。我细细想了一下，这个提高首付到50%的政策，确实会成为长期政策保持下去，而其实即使没有这个政策，稳健型的小老百姓也会掂量自己的钱袋买房。没有谁想断供，因为刚需需要房子。</p>
<p>至于以后十年甚至更长时间，房价仍然会涨。因为城市的发展离不开勤劳的人民，zf在不断的修建地铁画大饼，就是为了土地能卖个好价钱，只有不断的卖地搞铁公鸡，才会有gdp，才会有政绩。统治阶级带着他的各种利益集团一起玩，而老百姓以后可玩之物会越来越少，只能老老实实的干活挣钱。</p>
<p>由于家人的优柔寡断和缺乏对北京房地产现实的认识，我直到今年初才在四环买了第一套房，3w多的均价，让家里背负了100多w的债务。我错过了07年1w的机会，和09年1w+的机会。世上没有后悔药，历史也不会重演，那些07年买房和09年买房的人是幸运的。我现在努力攒钱挣钱的同时，最希望看到的事情居然是房价尽快远离我的成本区，我知道没有买房的同学一定会抨击我这种想法，但是现实就是这样可笑，一方面希望房价能降，这样可以把老人接到身边，另一方面又希望房价涨，这样自己在还贷的时候心里稍微能好受点。呵呵，不知道自己这样是不是活得太累。</p>
<p>不管怎么说，希望大家都能住上自己称心如意的房子，这几年来，zf真把我们这些人折腾的够呛。我和家人都是传说中的体制内，体制内确实有福利，可惜要想自己的财富不缩水，还得靠自己。</p>
</blockquote>
<h2><span id="君为贵商人-技工次之农民为轻打工人为底">君为贵，商人、技工次之，农民为轻，打工人为底</span></h2><blockquote>
<p><strong>傻子也疯狂：</strong></p>
<p>今天看到新闻<br>什么房产市场回暖啊<br>温州炒房团又出江湖了<br>成交均价上涨啊</p>
<p>请问这个是真的吗，房价会在短时间涨上去吗<br>如果是真的，那中央调控有什么用，在没有下降的基础上再涨10%<br>不是自己打自己嘴巴吗</p>
<p>很想听听楼主怎么看待这个事情。</p>
<p><strong>kkndme：</strong></p>
<p>维持在正常成交量，保持一个缓步上涨的趋势，是zy最愿意看到的。因为zy很清楚，除非体制上有大动作，否则让房价下跌只是唱给人听的口号。体制是不能动摇的根本，是国家稳定的基础，高房价是体制造成的必然结果。zy很清楚，最好的方式就是以一个平缓的速度增长。但是决策者是不是有此能力控制房价缓慢上涨，这是值得仔细研究的。</p>
<p>任何一个朝代，即使是我们在电影里常看到的奸佞当权，往往政策的初衷都是好的，但是执行效果却常常适得其反，领袖的智慧与执政能力对国家的命运起着至关重要的作用。</p>
<p>明朝朱厚照时期有个太监刘瑾，权势一手遮天，是个典型的奸佞。但他其实是很想做点事情的。</p>
<p>明朝开国时，朱元璋搞了个戍边屯田，相当于现在的军垦，因为军队自给自足，给国家省了大笔的银子。但是到了后来，军官们都变成了大地主，霸占了士兵的土地，把士兵当作佃农，依靠盘剥士兵来实现让一部分人先富起来的号召。这是与杀良冒功、贪吃空饷并列齐名的第三大快速发家致富手段。</p>
<p>我们说了刘瑾是个有雄心壮志，很想做点事业的高责任心人士。对于军官霸占士兵田产导致士气低下这件事很看不惯，很不满意。决定坚决打击这种行为。于是下令地方zf</p>
<p>清理军官霸占田产的问题。</p>
<p>军官霸占的田产不仅仅是士兵的，更多的是当地老百姓的。</p>
<p>按理说，这应该是个老百姓叫好的政策，而事实上这是老百姓头上的噩梦。</p>
<p>执行人是谁？地方官。</p>
<p>地方官执行的时候就实在为难了，军官老爷手里都是握着重兵的，你上门还没开口，兵大爷的刀已经架在脖子上了。可是刘瑾刘老板下达命令的同时，还是要下达任务指标的，没收的田产有任务指标，以前军官老爷占有的田都不交税，既然清理田产就要交税，交税也有任务指标。</p>
<p>有些地方官比较聪明，不敢找军官大爷收，就摊派给了老百姓，结果老百姓又交田又交税，自然是连活路都没了。有些地方官脑子不清醒，真的跑去找军官老爷要田要税，结果造成军官勾结宁王造了反，最后刘瑾自己的脑袋也保不住了。</p>
<p>历朝历代，统治者代表的都是地主阶级的利益。历朝历代的改革都只是为了缓和底层群众与地主阶级的矛盾，防止因为过激发生极端群体性事件。</p>
<p>调控也是为了缓和矛盾，要温水煮青蛙，而不要一把火把青蛙烧死。</p>
<p>关于自己打自己嘴巴的事，那是太多了，自古以来，统治者也从来不怕自己打自己嘴巴。古人就总结过，只准州官放火，不准百姓点灯。</p>
<p>以前的科举制度与现在的公务员考试制度基本目的都是相同的，让全天下的优秀的和不优秀但有出身的知识分子依附于官，这样就有了绝对的话语权。无法进入体制内的知识分子，有商业头脑和技术专长的人员，就相当于过去的商人、小作坊主，尽管也许还算富裕，但是没有任何地位，任人支配。要是没有一技之长，又不能经商，就基本上在社会的最底层很难翻身，相当于过去城市里的贩夫走卒，甚至无片瓦立锥，糊口都是困难，地位和稳定性反而远远不如自给自足，拥有宅基地的农民</p>
<p><strong>中年不惑吗：</strong></p>
<p>说到底空空太幼稚了 当年拖拉机之夜太学生怎么也想不到机关枪和拖拉机真的会招呼到自己身上 这和他们从小接受到的教育不一样 呀 主流宣传中party妈妈都是慈祥的温柔的全心全意为p民服务的</p>
<p>有皇帝大力支持的王安石变法到了地方法令也大变味 如今虎温的威权要远远小于当年的宋神宗和王安石 而且统治阶层从上到下的改革从来是为了巩固统治地位 至于p民收益那从来都是附属作用</p>
<p><strong>kkndme：</strong></p>
<p>这就是中西方的不同，西方的拖拉机是对外的，中国的拖拉机从来对的都是p民，对外基本比较忪。所以才有元和清，明明是外族入侵灭了国，还要把蒙古人和女真人一起拉进来统一叫中华民族，居然认为中华民族很强大，元朝时一直打到亚得里亚海。也不管蒙古人跟中华的两河文明有关系没有。</p>
</blockquote>
<h2><span id="10年的调控和08年调控的区别-带来的影响-机会">10年的调控和08年调控的区别、带来的影响、机会</span></h2><p>这次调控与08年调控后的结果是有所区别的。08年调控的结果是一线城市的暴涨；而2010年调控的结果是房价以二三线城市为主的全面上涨。不但是二三线城市，高房价甚至已经传到至四线及以下城市。</p>
<p>在二三线以下城市，无房户的需求其实并不大，真正的刚需来自改善性住房。城市升级使人们开始不满足过去老旧式住房的居住环境，开始追求大盘大开放商的品质住宅。房价也由此迎来全面上涨。这种全面上涨，不能理解为全面泡沫，而是有基础存在的。不能理解为全国炒房。特别是四线及以下城市尽管新盘价格高涨，老旧住宅却乏人问津，县级市二手房变现也比较困难。在2010年的调控的大背景下，却神奇的出现了二三线以下城市的刚需大量释放现象，不得不令人叹为观止。这神秘的幕后推手其实就是资金的规律。</p>
<p>对于在2010年初布局二三线城市的房开商和有远见的投资者，在这次调控中，无疑是受益者。</p>
<p>一线城市，这次调控给刚需买房者一个最好的入市良机，但是能够抓得住的只是少数。</p>
<h2><span id="历史总是惊人的相似">历史总是惊人的相似</span></h2><blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>其实，几千年来，唱的都是同样的戏，只不过台上的演员变换而已。</p>
<p><strong>kkndme：</strong></p>
<p>赞赏这一句，呵呵，历史规律是不变的，变化的只是时间、地点、人物、事件。</p>
<p>城头变换大王旗。</p>
<p><strong>tjOOSAN：</strong></p>
<p>历史规律是不变！但他妈世界变了！~~ 中国采用资本主义制度了</p>
<p>还只参考中国历史？</p>
<p><strong>kkndme：</strong></p>
<p>你知道什么叫资本主义制度吗？</p>
<p>首先基础是三权分立。</p>
<p>早在1748年，孟德斯鸠男爵发表了伟大的划时代的巨著“论法的精神”明确提出了三权分立。奠定了资本主义制度的基础。三权分立制度就是国家的立法、行政、司法三权分别由三个机关独立行使，并相互制衡的制度。讲的是法律精神，讲得是私人财产神圣不可侵犯。</p>
<p>而作为一个人治而非法制国家，怎么能说是资本主义呢？</p>
<p>建议个别（tjOOSAN）不读书，不研究，不了解中西方历史，不懂经济，对社会制度基本的理解基本是个白痴的同志，就不要乱发表议论了，惹人笑话。</p>
</blockquote>
<p>无论是中国还是西方历史对现在都是很有借鉴意义的。这就使毛说过的“古为今用，洋为中用”，毛建的武装斗争及建国思想其实很大程度来自于朱元璋。</p>
<p>古代君主统治国家征服世界靠战争武器，现在则靠金融武器。</p>
<p>西方，我们所熟悉的具备最纯正贵族血统的哈布斯堡家族，曾经的德意志王国和神圣罗马帝国的统治者，家族成员曾经统治过欧洲诸国：包括波希米亚王国 、匈牙利王国 、克罗地亚及斯洛文尼亚王国、伦巴第及威尼斯王国 、奥地利皇室领地 、萨尔茨堡公国 、塞尔维亚及塔米斯-巴纳特公国等等无数欧洲国家。</p>
<p>而现在，哈布斯堡家族控制着华尔街，继而通过华尔街控制着全球的经济。</p>
<p>历史是在继承的前提下发展的，特别是在西方，现在几乎每一个显赫的家族都能追根溯源。因为尽管西方也发生大革命，但是象文革一样彻底否定历史是完全不可思议的。</p>
<p>我们有点英雄情结的人听到最多的西方中世纪十字军三大骑士团：圣殿骑士团、条顿骑士图案、医院骑士团；直到现在仍有两大骑士团存在。条顿骑士团总部现在还在德国，专门从事慈善事业。医院骑士团后来改名为马耳他骑士团，也就是现在的马耳他，世博会还来上海参展。只有圣殿骑士团灰飞烟灭，但现在仍有大量的修士组织自称为圣殿骑士团的继承人。</p>
<p>完全不懂历史，就等于完全不懂得社会。</p>
<h2><span id="关于房贷">关于房贷</span></h2><blockquote>
<p><strong>四环四环：</strong></p>
<p>同意LZ。<br>刚刚父母帮忙首付、自己还贷，在北五环边买了个小房。<br>判断依据非常简单：一个是国家政策和我等屁民生活是两岔儿的，既然移民无望，就赶快站队；一个是力所能及、负担得起。</p>
<p>07年底和09年底都错过了机会，也是当时条件不允许，一次是自己嫌弃燕郊太远；一次是嫌弃通县太远。完后工作逐渐稳定，一狠心安了家，剩下的就是往体制外金字塔中层挤吧。</p>
<p>LZ所说，正是我说不清楚、但能判断大概的那些事儿。<br>哈哈。</p>
<p>请教LZ：</p>
<p>眼下商业贷款贷款46万。<br>分20年还，月供3066<br>分30年还，月供2562</p>
<p>朋友劝我贷款时间越长月供越少越好。<br>直觉判断我觉得也是这样。<br>有科学依据么？</p>
<p><strong>kkndme：</strong></p>
<p>你的朋友考虑是有道理的。<br>如果不考虑通货膨胀，当然是利息越少越好，20年还的利息要少于30年还的利息。<br>但是因为通货膨胀的因素，我国是高增长高通胀的国家，每年的通胀率远远大于实际公布的数字，更远远高于贷款利息，所以贷款时间越长越好。<br>至于月供是否越少越好，完全取决于个人的承受能力，有条件当然买大房子，宁肯月供多一点。但是条件不够就买小的，量力而行。</p>
<p><strong>四环四环：</strong></p>
<p>谢谢楼主指点。</p>
<p>假设通胀率有一个固定值（当然实际这是没有的，它也是个取决于经济规律和国家意志的不确定因素）、贷款利息有一个值。<br>完后不同的贷款年限。<br>就能估算出两个值此消彼长。</p>
<p>需要选择判断的是，通胀率这个值的数字。<br>但通过对国际意志不确定因素极端情况的估算，预计这个值。</p>
<p>完后把这变成一个数学题。</p>
<p>是这意思么？</p>
<p>那不用算了，按常识，知道该怎么选了。</p>
<p><strong>kkndme：</strong></p>
<p>银行贷款的年限越高，利息支出越高，但不会高过通胀。你能贷30年就贷30年，这是你年轻的优势。年纪大点的就只能贷25年，甚至20年了。</p>
<p>所以说40岁买房的人很不靠谱，首先40岁的人不一定有钱，反而错过了最敢买房的黄金年龄。其次是40岁贷款年限就短了好多，相当于月供压力更大了。</p>
</blockquote>
<h2><span id="买卖商品房会逐渐变成富人的游戏">买卖商品房会逐渐变成富人的游戏</span></h2><p>以后，商品房本来就变成了富人间的游戏，普通人将不能卖进参与的门槛。</p>
<p>到多数人真的买不起房时也就安心了，也不用关心房价的涨跌了。</p>
<p>但是现在，房价还没有到那个高度，很多人还觉得有希望，所以对房价的涨跌才会特别关注。这个时期应该就是普通人最后买房的机会。错过了，将不会再有。</p>
<h2><span id="zf还是更在意农民问题">zf还是更在意农民问题</span></h2><blockquote>
<p><strong>肖肖19850706：</strong></p>
<p>楼主虽然有很多观点写的很有道理，但是对于历史这块，并不太正确</p>
<p>引用一段楼主的话：<br>——————<br>自古以来，民生问题的底线就是不要出现陈胜吴广的极端情况。所以zf更在意的是农民问题。<br>因为历史的改朝换代都是大饥荒引起的，无论是汉末、唐末、隋末、还是明末。农产品价格上涨的对zf的震动要远远大于房价的上涨。<br>农民具备最原始的力量，而他们关心的并不是三线以上城市的房价，而是能否填饱肚子。<br>而关心自己能否拥有一套产权房的都市白领，除了呻吟一下意外，几乎是没有什么有效反抗的可能的。<br>——————</p>
<p>其实在当今政权建立之前，还有一个政权，叫做中华民国<br>这个政权是由民主革命带来的<br>他们所举的旗帜是资产阶级革命，所建立的政权是资本主义社会<br>为什么会失败？<br>这是一个值得思考的问题<br>让一个经历了5000年封建社会的国家经过一次革命就达到资本主义社会的境界<br>没有工业革命的基础<br>没有原始的积累<br>有的只是借鉴西方<br>想先变制度再进行调整，结果固然是失败<br>于是“农民起义”卷土重来，我想大家肯定明白“农民”所指的是什么<br>于是又了现在的这个政权<br>由工人阶级和资产阶级去推翻帝制<br>再由农民阶级把土地抢回来，最终回到封建政权来压迫资产阶级<br>他们最怕的还是农民么？<br>显然不再是了<br>他们最怕的正是资产阶级<br>其次就是你说的那些<br>“关心自己能否拥有一套产权房，除了呻吟一下意外，几乎是没有什么有效反抗的可能的都市白领”<br>攻占巴士底狱的不是农民<br>正是这些“几乎没有什么有效反抗可能的都市白领”<br>是工人阶级结束了地球上长达上千年的封建统治<br>而改革开放，市场经济的发展，给了这一切充足的物质基础<br>社会的转化过程有两种<br>一种是和平演变<br>一种就是革命</p>
<p>现在所存在的问题，不是他们更怕谁<br>而是他们选择面对哪种演变方式</p>
<p><strong>kkndme：</strong></p>
<p>最可怕的不是农民而是失去土地的农民。<br>为什么说新民主主义革命是工人阶级领导的？<br>那时的工人阶级是什么？就是失去土地的农民和破产的手工业者，除了体力一无所有，所以他们才具备脑袋掖在裤腰带上，为了抢土地而玩命的动力。解放战争时期，我军的宣传就是：“同志们，国民党要把分给你们的土地抢走，你们说怎么办？”于是广大失去土地的农民兄弟不干了，玩命了。<br>工农红军一四方面军胜利会师，在选择南下和北上发生了分歧，真的为了北上抗日吗？1935年抗日战争还没有打响，日本人在东北而不是西北。北上抗日的说法实在有些牵强。<br>我想真正的原因还是群众基础。<br>近几年多次在西南地区的乡村进行田野调查，发现一个问题：解放前，即使如贵州山区的偏僻乡村，农民自给自足吃饱肚子是完全没有问题的，更别说富庶的四川平原。<br>那时参加红军要有不要脑袋的玩命精神，对于多数能够填饱肚子的农民来说，主动参加革命显然是不现实的。红军在西南地区完全没有群众基础，战斗中的减员得不到有效的补充，所以人才会越打越少。<br>而西北地区完全不同，自然条件恶劣，农村耕地很少，存在大量食不果腹，无地可种的农民。李自成起义也是从陕西发起的，可以说具备了随时发动武装暴动的群众基础。所以毛选择了北上的正确路线。而张同志南下凄惨的下场印证了毛的正确判断。<br>北上延安的另一个重要原因是获得苏联的支持，没有强大的后援是无法取得决定性胜利的。</p>
<p>一旦农民失去了土地，而又没有去处，那是相当可怕的，所以农民工就业问题是zy最为关注的。甚至提出如何让农民工在城镇买房子置业，处理好农民问题，是社会稳定的重中之重。</p>
<p>将来，有地可耕的农民将会成为都市中的底层群众羡慕的对象，农民有地有住宅有粮食。进可以在城市打工，有聪明的甚至通过经商迈进富人阶层，退可以回乡种田，虽然现钱不多，但是吃穿住行都是没有问题的。</p>
<p>而真正一无所有的将是大量在都市中沦为贫困的人群。在打拼挣扎的打工仔，如果没有能力购置房产，也没有得到向上爬的机会，在都市立足将变得困难，而又毫无退路。</p>
</blockquote>
<h2><span id="治国需要用贪官-反贪官">治国需要用贪官、反贪官</span></h2><p>讲个故事，可能这个故事很多人都看过，并且曾经多次被转帖：</p>
<p>宇文泰是北周开国的奠基者。当他模仿曹操，作北魏的丞相而“挟天子令诸侯”之时，遇到了可与诸葛亮和王猛齐名的苏绰。宇文泰向苏绰讨教治国之道，二人密谈 三日三夜。</p>
<p>宇文泰问：“国何以立？”</p>
<p>苏绰答：“具官。”</p>
<p>宇文泰问：“如何具官？”</p>
<p>苏绰答：“用贪官，反贪官。 ”</p>
<p>宇文泰不解的问：“为什么要用贪官？”</p>
<p>苏绰答：“你要想叫别人为你卖命，就必须给人家好处。而你又没有那么多钱给他们，那就给他权，叫他用手中的权去搜刮民脂民膏，他不就得到好处了吗？”</p>
<p>宇文泰问：“贪官用我给的权得到了好处，又会给我带来什么好处？”</p>
<p>苏绰答：“因为他能得到好处是因为你给的权，所以，他为了保住自己的好处就必须维护你的权。那么，你的统治不就牢固了吗。你要知道皇帝人人想坐，如果没有贪官维护你的政权，那么你还怎么巩固统治？”</p>
<p>宇文泰恍然大悟，接着不解的问道：“既然用了贪官，为什么还要反呢？”</p>
<p>苏绰答：“这就是权术的精髓所在。要用贪官，就必须反贪官。只有这样才能欺骗民众，才能巩固政权。”宇文泰闻听此语大惑，兴奋不已的说：“爱卿快说说其中的奥秘。”</p>
<p>苏绰答：“这有两个好处：其一、天下哪有不贪的官？官不怕贪，怕的是不听你的话。以反贪官为名，消除不听你话的贪官，保留听你话的贪官。这样既可以消除异己，巩固你的权力，又可以得到人民对你的拥戴。其二、官吏只要贪墨，他的把柄就在你的手中。他敢背叛你，你就以贪墨为借口灭了他。贪官怕你灭了他，就只有乖乖听你的话。所以，‘反贪官 ’是你用来驾御贪官的法宝。如果你不用贪官，你就失去了‘反贪官’这个法宝，那么你还怎么驾御官吏？如果人人皆是清官，深得人民拥戴，他不听话，你没有借口除掉他；即使硬去除掉，也会引来民情骚动。所以必须用贪官，你才可以清理官僚队伍，使其成为清一色的拥护你的人。”</p>
<p>他又对宇文泰说：“还有呢？”</p>
<p>宇文泰瞪圆了眼问： “还有什么？”</p>
<p>苏绰答：“如果你用贪官而招惹民怨怎么办？”宇文泰一惊，这却没有想到，便问：“ 有何妙计可除此患？”</p>
<p>苏绰答：“祭起反贪大旗，加大宣传力度，证明你心系黎民。让民众误认为你是好的，而不好的是那些官吏，把责任都推到这些他们的身上，千万不要让民众认为你是任用贪官的元凶。你必须叫民众认为，你是好的。社会出现这么多问题，不是你不想搞好，而是下面的官吏不好好执行</p>
<h2><span id="二线城市典型代表">二线城市典型代表</span></h2><blockquote>
<p><strong>klid：</strong></p>
<p>LZ 成都属于您口中的二三线城市么？<br>那么这次属于补涨阶段？</p>
<p><strong>kkndme：</strong></p>
<p>成都、重庆、西安、昆明、武汉都是二三线城市的典型代表。</p>
</blockquote>
<h2><span id="关于商铺和住宅投资">关于商铺和住宅投资</span></h2><blockquote>
<p><strong>马甲马甲_马马甲：</strong></p>
<p>请教楼主：</p>
<p>因为种种原因， 错过了很多买房的好时期，现在租房住，（ 享受到了朋友提供的体制内的好处， 远低于市场价格租了一套房子）。</p>
<p>手上200万左右的现金， 在上海，想买房子保值增值，</p>
<p>1，有套著名大学附近的二手房子，57平米， 130万左右，估计租金大约是2.5万-3万 之间，<br>2，在市中心成熟的商业区有个店铺， 124万， 年租金现在是6.4万一年。</p>
<p>2个选择，个人倾向于投资店铺， 因为在上海店铺的涨价远远低于住宅的涨幅，况且店铺的资金回报率也达到了 5% ，不知道楼主是否有更好的建议？</p>
<p><strong>kkndme：</strong></p>
<p>很多人不愿意投资商铺还是在于风险大，好位置熟铺是很少有人愿意拿出来卖的，谁愿意放弃生蛋的母鸡呢？而新开发的商铺要不然位置比较偏，不知道能不能做的起来，要不然就溢价太高，超出了大多数人的承受。好的商铺是市面上很难买到的。</p>
<p>如果经过考察确认商铺没有问题，还是首选商铺，但是一定要经过认真的考察。</p>
<p>而住宅的风险就相对小多了，而且投资不需要很多的经验，更适合一般投资者。</p>
</blockquote>
<h2><span id="关于房产调控">关于房产调控</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>请问楼主，房价会在年底重新确立上涨趋势吗？如果再不涨，政府的地卖不上好价钱，地方财政就回吃紧，地方政府还会像去年那样出各种政策救市吗</p>
<blockquote>
<p><strong>九五二七八：</strong></p>
<p>全国各地 一线二线三线 情况都有不同<br>楼主预测时点 怕不好预测啊</p>
<p><strong>kkndme：</strong></p>
<p>不但是不同城市情况有区别，同一城市的不同区位情况也有区别。就拿北京来说，过渡爆炒的通州房山等远郊区县，房价一定会有所回调，但是城市中心，特别是学区房是没有下降可能的。</p>
<p>而对于多数二三线城市，均价下降的原因主要还是远郊区的房源投放量增加，城区内的房子不但不降，而且涨得还很厉害。</p>
<p>房产投资最重要的还是位置，当远郊区县的房价远低于城中心的时候，一定会有补涨的要求，但当远郊区县的房价向城中心接近的时候，一定会出现城中心的补涨，当然在调控期也会体现为远郊区县房价的回调。</p>
</blockquote>
<p><strong>kkndme：</strong></p>
<p>仔细看一下各地的房价，不要被公布的所谓均价迷惑，只有少部分城市价格下降或者持平，多数城市都在上涨，只不过幅度不大而已。现在成交量属于正常水平，不存在dfzf吃紧的问题，当然不可能象09年那样的疯狂，09年底甚至银行出现无款可贷，太高的成交量会被zy视为危险的信号，是达到危害金融安全的高度的。</p>
</blockquote>
<h2><span id="关于房产税">关于房产税</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>还有一问题请教楼主，目前我一共有三套房，一套自己住，一套父母住，一套是投资房，在大连最繁华的地方，租金回报是百分之六点五，请问房产税会很快推出吗？我的那套投资房是卖掉还是持有呢？卖的话能赚白分之五十</p>
<p><strong>kkndme：</strong></p>
<p>在卖掉之前，你要先问问自己，拿这笔钱打算干什么？如果没的可做，干等着贬值，那你为什么要卖呢？<br>如果你有更好的投资或者创业渠道，那当然立刻卖掉，不用犹豫。<br>至于房产税，第一：近两年一定不会征收，因为条件还不成熟。第二：房产税只是一项苛捐杂税，目的是补充财政收入，并没有降低房价和租金的功能，并且只能导致租金的上涨。怕房产税的应该是租客，而不是房东。</p>
</blockquote>
<p>任何税种最终都要转嫁到社会最底层群众身上。丛林法则实际就是大鱼吃小鱼，小鱼吃虾米。</p>
<p>上层人士的享受是靠底层群众勒紧裤腰带过日子换来的。</p>
<h2><span id="老公房的拆迁问题">老公房的拆迁问题</span></h2><blockquote>
<p><strong>wofuleyumin1：</strong></p>
<p>从头至尾，一口气看完了。。赞同之极。。。</p>
<p>也向楼主问些问题。。。</p>
<p>是否老公房都会拆迁？<br>在成都，一环，二环内还有非常多的老公房，总量比商品房还多，这么多的房子都会拆迁吗？<br>我在想是否先买套老公房。。因为价格也便宜。新的商品房一般八九千。。老公房才5千多。买了后灯拆迁。</p>
<p>但这么多老公房都会拆迁吗？我觉得可能很多房子是不会拆迁的吧？否则只要现在买这些房子，以后都发财了。</p>
<p>是否拆迁的只是很少部分？</p>
<p><strong>kkndme：</strong></p>
<p>将来多数房都会拆迁，这是中国体制和经济发展模式决定的。在城市拆迁改造升级过程中，大量的老房拆毁，大量的新房拔地而起。而随着拆迁改造的成本的上升，房子也越来越贵。<br>现在拆迁改造集中建设70-90的小户型，将来会沦为新的城中村，通过二手置换，这类房子会变成新的贫民窟，而将来的拆迁改造建设的一定是追求环境品质的大户型。<br>因为zf官员任期的限制，决定了官员的短视，决定了城市规划的短视。<br>但是市中心的房子，即使在将来人口下降的过程中，仍然是稀缺的，房价高不可攀的。如果手有余钱首选的是市中心的大户型。<br>关于市中心老旧二手房的购买，还是有一定学问的，一定要选择位置好，低密度的矮层住宅楼，因为密度低，便于拆迁。而密度高的塔楼拆迁非常困难，拆迁成本太高，开发商很难有利可图。现在住在市中心高层旧式塔楼的富裕人口，将来一定会二次置业，这些旧式塔楼逐渐会沦为新一代年轻中产阶层的过渡性住房。</p>
</blockquote>
<h2><span id="投资新房还是老公房">投资新房还是老公房</span></h2><blockquote>
<p><strong>wofuleyumin1：</strong></p>
<p>楼主。。谢谢你的答复</p>
<p>我接着问</p>
<p>你说现在投资是投资一套新房好，，还是找个老公房投资？</p>
<p>新房，，一切都好，但价格贵。。</p>
<p>老公房，一切都不好，但价格便宜。。主要是等拆迁。。但可能要等七八年。。（从我近2年的观察，一般都要这么久。。除非有内部消息）</p>
<p><strong>kkndme：</strong></p>
<p>有钱当然是新房舒服。</p>
<p>老公房如果是学区房，随着住着不舒服但是不影响小孩上学。至于啥时拆迁那真是有年头等了。运气好，三年五年，运气不好十年八年。</p>
<p>关键是拆迁后，原地回迁是很难的，拆迁后安置一般都到远郊区县。如果碰上个铁腕书记，拆迁还真不见的能得什么便宜。条件还没谈好，推土机就开来了。</p>
<p><strong>wofuleyumin1：</strong></p>
<p>有钱当然是新房舒服。<br>老公房如果是学区房，随着住着不舒服但是不影响小孩上学。至于啥时拆迁那真是有年头等了。运气好，三年五年，运气不好十年八年。关键是拆迁后，原地回迁是很难的，拆迁后安置一般都到远郊区县。如果碰上个铁腕书记，拆迁还真不见的能得什么便宜。条件还没谈好，推土机就开来了。<br>。。。。。。。。。。。。。。。。。。。</p>
<p>楼主的意思是。。还是投资新房比较好？</p>
<p><strong>kkndme：</strong></p>
<p>还是量力而行，买老公房也比不买强，有条件当然买新房。</p>
</blockquote>
<h2><span id="高端盘有房价带动作用">高端盘有房价带动作用</span></h2><blockquote>
<p><strong>wofuleyumin1：</strong></p>
<p>楼主。。。又有一个问题</p>
<p>我附近的普通房子大概9000 旁边有个02年的别墅现在13000 现在又有一个新的楼盘开盘了。。是电梯 容积3 十多层的 是中海的高端项目，装修过的 居然卖将近2万。。。离谱吗？旁边容积0.8的老别墅才13000啊 </p>
<p>请问中海这个项目是否价格过高？ 另外，这个项目对我这附近的房价能拉动多少？</p>
<p><strong>kkndme：</strong></p>
<p>高端房产，开发商都是不急着卖的，而且也从来不乏有钱人慷慨解囊。你说的情况跟昆明的空间俊园完全相同。在市中心徘徊在万元关口的时候，空间俊园直接开出了19000的均价，之后市中心的二手房紧随攀升到15000.而一环二环间的房价在万元关口徘徊。</p>
<p>大盘高端盘对房价的带动作用是显而易见的。</p>
<p>自调控刚刚推出的时候，与一个朋友闲聊，说起调控将是二三线城市大涨的机会，还聊了聊昆明的发展，结果那个朋友头顶调控的大棒，去昆明投了n套房产，当时价格7000多点，时过几个月，现在看房价已经涨到9000.而且他买的位置周边先后有高端大盘推出，预计开盘价格在12000-15000，一旦高端大盘开盘将让他买的房子直接迈上万元的台阶。</p>
</blockquote>
<h2><span id="买房和没买房的差距">买房和没买房的差距</span></h2><blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>新穷三代。。。ORZ<br>我可不想做穷一代。。。。</p>
<p>房子真的让人抓狂，当跟你同样起点的人早你三年买房的时候，这种感觉尤为明显。</p>
<p>我老公是77年的，他一个女同学2007年底在清河新城买了一套房，一百多平100多万吧，找家里东拼西凑的全款。其实当时我老公也能拿出100w不用借钱的，可是他偏不听我的话，认为清河在五环外，那种地方还要100多万不可思议。结果北京经历了09年的疯狂以后他同学那套房子已经翻倍，借的钱也已经还清。</p>
<p>而我们呢，在犹豫和老公的优柔寡断中错过了时机，终于在2010年3月最疯狂的时候入手了，这时候即使首付160多万，还要背负100多万的贷款，生活质量比他的女同学差的不是一点半点。</p>
<p>这是真实发生的事情，犹豫和无知真的能让人付出很大的代价。</p>
<p><strong>kkndme：</strong></p>
<p>清河新城好像是50年产权吧。反正我对50年产权的都不感冒。<br>我一朋友06年买的水木天成，买时5000多，现在25000，调控都不带降价的。</p>
<p><strong>汝爱之罪：</strong></p>
<p>清河新城盘子还是很大的，分好几期，有70年也有50年，他们买的是70年的。07年底刚开第一期，相当于股市里的打新股了，基本上没什么风险。</p>
</blockquote>
<h2><span id="房产交易历史">房产交易历史</span></h2><p>最早的房产交易，出现在一个名字叫“盉”的西周青铜器上。在公元前919年农历三月份，一个叫矩伯的人分两次把一千三百亩土地抵押给一个叫裘卫的人，换来了价值一百串贝壳的几件奢侈品，包括两块玉，一件鹿皮披肩，一条带花的围裙。</p>
<p>周厉王三十二年又发生了一宗土地买卖。这宗土地买卖的交易过程也被刻在青铜器上。 </p>
<p>这次记录的是周厉王买地的事，周厉王为扩建王宫，买下一个叫鬲从的人的地，没有立即给钱。鬲从担心周厉王赖账，周厉王派人对鬲从说：“你别怕，我一定会照价付款的，如果我赖账，就让上天罚我被流放好了。”这是个很毒的誓。</p>
<p>周厉王买地花了多少钱，铭文上没写。不过李开周说，有人买地，有人卖地，说明当时除了有土地抵押，还存在土地买卖，房地产市场已经有了雏形。</p>
<p>隋唐时，有个叫窦乂的人，他生在陕西，很小的时候就死了爹娘，无依无靠，跟着舅舅一块儿生活。</p>
<p>他舅舅是个公务员，住在长安城。窦乂先通过卖鞋、卖树等生意赚了一些钱，后来有了80万钱的身家，于是开始向房地产行业进军。</p>
<p>当时长安西市有一个废弃的化粪池，面积不小，有十几亩，闲置七八年了，一直没人买。窦乂把它买了下来，雇人填平，在上面盖了20间店铺，租给波斯胡人做生意，平均每天都收上来几千钱的房租。</p>
<p>再后来，窦乂听说当朝太尉李晟喜欢打马球，于是斥资70万钱买下一块地，又花30万钱把这块地建成一片马球场，送给了李晟。</p>
<p>李晟很高兴，从此跟窦乂结成死党，有求必应。有这种靠山保驾护航，窦乂发得更快了，不到40岁就成了长安首富，人称“窦半城”。</p>
<p>除了像窦乂这样的开发商，古代的业余开发商还有一些是公务员、退休干部等，甚至官府自己就是开发商。 </p>
<p>比如在北宋，中央政府下面就有个专门搞开发的机构，叫做“修完京城所”。这个机构本来只能是修筑城墙和宫殿，后来城墙修得差不多了，宫殿也盖得够豪华了，这个机构就开始转型，开始给中央财政搞创收。</p>
<p>怎么搞创收呢？修完京城所向朝廷请示，划拨给他们大片地皮，他们在上面盖住宅盖店铺，盖好了，有的卖给老百姓，有的赁给老百姓，给国库做了很大贡献。</p>
<p>古代是没有专业的开发商的。做开发商最需要的是钱。买地、买建材、雇人、摆平关系，哪个环节都得花钱。尤其买地，流动资金不能少，钱不够，就得找同行拆借，或者找银行贷款。</p>
<p>古代没有银行，但有钱庄，可是钱庄规模一般很小，即使有一些大型的全国连锁的钱庄，他们也不做开发商的生意，都把钱借给别的老板了。</p>
<p>史料上有这样两个办理房地产抵押贷款的例子，一个是南北朝时候的梁朝郡王萧宏，让人家拿着房契去贷款，一张房契最多只贷给几千钱；还有一个是明朝嘉庆年间山阴县的一个富户，名叫求仲，最多的一次才贷给15000文。这点儿钱别说搞开发，吃一顿大餐都不够。<br>直到民国时期，外国银行纷纷到中国开展业务，开发商们才能贷到大笔的贷款。所以中国的职业开发商直到民国才出现。 </p>
<p>古代开发商如果大量囤地得挨板子</p>
<p>以唐朝为例。唐玄宗在位时，土地政策里有这么一条：“应给园宅地者，良口三口以下给一亩，每三口加一亩，贱口五口给一亩，每五口加一亩，……诸买地者不得过本制。”意思就是说，政府给老百姓划拨宅基地，划拨的宅基地大小取决于家庭等级和家庭人口，如果是平民家庭，每三口人给一亩宅基；如果是贱民家庭，每五口人给一亩宅基。另外老百姓也可以购买宅基，但是购买的面积有限，不能超过政府规定的指标。</p>
<p>政府规定的指标是多少呢？平民家庭买地，每三口人，最多只能买一亩宅基；如果是贱民家庭买地，每五口人，才能买一亩宅基。</p>
<p>在唐朝，商人也属于贱民，再有钱的商人也是贱民，贱民老板去买地，即使是上百口人的大家庭，最多也只能购买20亩地，用这20亩地搞开发，一两年就倒腾光了。而如果超标大量买地会怎么样呢？</p>
<p>唐朝法律规定：“诸占田过限者，一亩笞十。”意思是买地超过指标的，得挨板子，每超出一亩指标，挨10大板。</p>
<p>虽然古代开发商没有现如今的开发商这么“牛”，环境和政策对他们都不太有利，但是在拆迁问题上，始终还是开发商们占优势。就比如窦乂，他就知道要搞房地产，首先得朝上有人，于是傍上了当朝太尉。</p>
<p>古代拆迁过程更为暴力，因为普天之下，莫非王土，国家要用哪里就用哪里。</p>
<p>当然，在古代，也不乏一些民主的君主。例如北宋元丰六年(1083年)，开封外城向外拓展，规划中的新修城墙要占用120户居民的住宅，宋神宗让开封府制定拆迁补偿计划，开封府写报告说，总共需要补偿款两万零六百贯，平均每户至少能拿到补偿款171贯。</p>
<h2><span id="契税的历史">契税的历史</span></h2><p>关于契税、物业税或者房产税，其实也不是现在的创造或者纯粹的拿来主义。</p>
<p>早在东晋时期，就开始收契税，当时叫“散估”，这也是中国第一个有据可查的契税。其后，几乎所有朝代都有契税。</p>
<p>唐初魏征等人写出了房产税的实质：“其实利在剥削也”——当时“剥削”没有现今这么贬义，与“增加财政收入”是一个意思。</p>
<p>从税率上看，东晋税率为4%，隋唐税率是5%，宋代4%，元明清三朝基本是3%。我们现在的契税大户型也是3%。</p>
<p>万历三十三年，利玛窦在北京宣武门附近买了处房子，他在意大利、葡萄牙、印度都呆过，那些地方并没有“契税”这一说，所以他也没有去有关部门办理手续。</p>
<p>《大明律》规定：“凡典买田宅不税契者，笞五十，仍追田宅一半价钱入官。”好在利玛窦同志上面有人，托了户部官吏，最后交了一笔可观的滞纳金了事。 </p>
<p>相比之下，“物业税”这税种兴起较晚，而且断断续续。公元783年，唐德宗向长安城内拥有房产的市民开征物业税，叫作“间架税”，乃是按照房屋的等级和间架计税，上等房屋每年每间缴纳两千文，中等房屋一千，下等房屋五百。</p>
<p>结果民怨载道，当年深秋五万军兵哗变，口号就是“不税汝间架”。迫于压力，784年唐德宗废止了这个税种，也就是说，中国第一个正规的物业税仅仅活跃了半年就夭折了。</p>
<p>到了五代十国，梁唐晋汉周的每一代帝王都曾征收物业税，不过鉴于“间架税”惹过乱子，改叫“屋税”。</p>
<p>北宋物业税不是常设税种。南宋由于军费困难，每年两次向城乡居民征收屋税。元代，不叫间架税或屋税了，改叫“产钱”，按地基面积征稻米若干或折成钱若干。明朝，物业税不常设，江浙地区小范围征收过一段，叫“房廊钱”。清代，物业税也不常设，往往临时征收，比如1676年由于对吴三桂用兵，朝廷财政紧张，康熙下诏“税天下市房”，规定“不论内房多寡，惟计门面间架，每间税银二钱，一年即止。”算下来，是只对门面房征税，二钱税额相当于两斗大米或七斤白糖的价钱，不多。</p>
<p>总而言之，无论是间架税、屋税、地基钱、产钱、房捐，都是不折不扣的物业税。只不过，它们与国际上通行的物业税是不同的——不是为了调节需求，而是单纯地敛财。 </p>
<p>然而物业税在中国并不能成为常设税种，因为这个税是纯粹的苛捐杂税，税又比较重，很容易激化矛盾，直接结果是百姓吃不起饭，太容易导致大规模的农民运动，所以很难持续征收。</p>
<h2><span id="廉租房的历史">廉租房的历史</span></h2><p>言及公房和廉租房系统，最是宋朝搞得好。</p>
<p>宋朝原则上不分房，京官无论大小，一律租房居住，宰相那样的高干都是如此。偶尔有“赐第”，只照顾部级领导和有军功的将军。算起来大家的住房自有率不高。</p>
<p>南宋初年，大量流亡人口涌进杭州，三十平方公里的杭州城一度住了一百万人口，人口密度接近上海浦西。</p>
<p>因人多地少房价高，居民普遍租住公房。除了大规模公房出租，宋朝还有住房救济体制，一是灾年对租住公房的市民减免房租；二是政府建房（福田院、居养院）免费安置流民和赤贫民众；三是修建比公房条件要差的简易房，但是租金更低，堪称“廉租房”。此外，宋朝还有安济坊——慈善医疗，还有漏泽园——安葬无人认领的尸身，比较有人性。 </p>
<p>如果是公务员的话，生在元代也还不错。建国开始，就给半数京官和所有地方官分了房，叫“系官房舍”。一般分不到的市民以自主建房为主导，但是盖房不用买地，政府批给一块官地，然后每月交一次租金，时称“地基钱。” </p>
<p>满人刚进北京那会儿，也给领导们分房子。一品官二十间，二品官十五间，三品官十二间，四品官十间，五品官七间，六、七品官四间，八品官三间，不入流小军官每人两间。按照每间十五平方米估算，从一品官的三百平方米、到小军官的三十平方米不等。 </p>
<p>廉租房主要由寺观经营。土地由政府划拨，建房资金由民众捐献，房产维护可以从香火钱里冲销，僧尼道士理论上讲不以盈利为目的，再加上信仰需要，正适合执掌这项半慈善业务。大都市的庙宇常有上千间客房，供应试的学生、出门的商旅和遭了天灾的百姓临时居住。</p>
<p>《西厢记》里张生和崔莺莺在山西停留一整月，在那永济县普救寺里，莺莺住西厢，张生住东厢，该故事充分说明：在廉租房里也可能发生爱情。</p>
<p>到了明清两代，又多出个廉租房的来源，便是会馆。在这异乡人建立的聚会场所里，客房租金相当便宜。顺治十八年建于北京的漳州会馆，福建人来租住，只象征性地收取租金：每月三文钱！ </p>
<h2><span id="历史上买房最好的朝代">历史上买房最好的朝代</span></h2><p>历朝历代，哪朝买房最容易呢？</p>
<p>南北朝最不靠谱，贫富相差极为悬殊，普通居民收入只有几千，房价则是几百万。谢灵运那样的大财阀“左江右湖，南北二山”，房价都被他们给炒上去了。 </p>
<p>唐朝不用说啊，我们都知道“居长安，大不易”，而且士大夫时兴攀比，为了写诗题名好看，非得有个别墅不行。比如王维有辋川别业，岑参有南溪别业，杜牧有樊川别业，就是白居易本人，后来也在洛阳买了十七亩地，修了个“履道园”。</p>
<p>宋朝文人叶梦得说：“人未有无产而致富者也。有好便田产，可买则买之……勿计厚值。”这话一再被地主老财们重复。有点闲钱，买房子置地，不惜一切代价。</p>
<p>明代买房也不是件容易事。《金瓶梅》第五十六回，西门庆的结义兄弟要买房，朋友帮他算了算帐，“一间门面，一间客座，一间床房，一间厨灶——四间房子是少不得的。论着价银，也得三四千多银子”。小户型房子，要三四千两银子。而清河县县令，从七品国家公务员，每年薪水不过三百五十两。就是说，就算县长去买房，如果不贪污的话，需要十年不吃不喝才能攒够房钱。明代楼市虚火上延，与攀比之风分不开。尽管明太祖规定，任何人不得超越等级建房，例如居民门窗不得使用朱红油漆；庶民住房不得超过三间；功臣宅邸两边可以保留五丈空地；军民房屋不许建成五间或九间；寺观庵院不得使用斗拱。但如小说里所说，庶民西门庆“现住着门面五间到底七进的房子”，超标超大发了。</p>
<p>嘉靖年间，大家纷纷打肿脸充胖子，浙江人的房子必须带客厅了，江西人的房子必须带兽头了，江苏人的房子里必须摆上时尚家具和精美古玩了。明朝中叶，北京的地皮已经涨到每亩纹银两千两，就是折成人民币也有好几十万。</p>
<h2><span id="未来房地产市场的发展">未来房地产市场的发展</span></h2><blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>楼主旅行结束呢？</p>
<p>将来房租市场会如何演化？</p>
<p>房租涨的太多，如果大多数租客的收入承担不起该如何？</p>
<p>例如租客的平均工资4000元/月，你让他和别人合租一个小两室要6000元<br>他们承担不起恐怕就只能离开这个城市了</p>
<p><strong>kkndme：</strong></p>
<p>公租房具有平准作用，zf要敛财，不能定价太低，但也不会高的离谱。有了这个参照物，个人普通房出租应该保持在比公租房稍高水平，当然位置好的高端房精装房也可能租出天价。</p>
<p>中国的房价在未来将成为多数群众遥不可及的梦想，也可以说大多数人都不再关心商品房的房价涨跌。</p>
<p>未来，租房将成为常态，所以房子的位置环境装修的档次不同，房租的差距将会非常明显。但好房子一定只有中等收入以上家庭才租得起。</p>
<p>而买房子是富人阶层的事，中等收入家庭想都不敢想。</p>
<p><strong>中年不惑吗：</strong></p>
<p>呵呵，将来，只要中等收入的家庭2个月的收入能买1平米，他们也会买房子的</p>
<p>难道将来的房价要涨到中等收入家庭半年甚至更长的时间才能买1平米？</p>
<p><strong>kkndme：</strong></p>
<p>除了房价高，贷款也没那么容易。而且除了房子，各方面的花销都会涨得离谱，这是太平盛世后期的普遍规律。</p>
<p>关键还在于体制外的中产，都是逆水行舟，一旦不能前进，就可能沦为赤贫。</p>
</blockquote>
<h2><span id="房产到期">房产到期</span></h2><blockquote>
<p><strong>不明真相的草民：</strong></p>
<p>向LZ请教</p>
<p>商品房的土地证年限有多重要？</p>
<p>现在一个二线城市的开发区，中心地段很多小区房子倒是新盖的，但地是90年代初拿的，有40年、50年的，还有30年20年的，大部分房子的土地证从现在算起只有10几年20几年，有的房子土地证已经到期了，但由于位置较好所以房价一点不便宜。按KFS的说法，土地证到期将来再续就是了，没有大的影响。</p>
<p>LZ给分析一下，这样房子将来的风险在哪？如果买来自住又如何？</p>
<p>谢谢！</p>
<p><strong>kkndme：</strong></p>
<p>其实有无土地证都无所谓，无论有没有土地证，最大的风险都在dfzf，人治社会法律文件其实就是一张纸，关键还是zf做得不要太过份。</p>
<p>即使你证件齐全zf想拆一定会拆，即使没有土地证拆的时候也会同样补偿。</p>
<p>这个东西实在没多大意义。</p>
<p><strong>不明真相的草民：</strong></p>
<p>感谢LZ答复。都是新建的高层，应该不会轻易拆迁，这么说自住还好。但如果将来要出手是否就存在困难？？</p>
<p>期望LZ继续指明。</p>
<p>Lz似乎没有看到这个问题，再次感谢Lz，望答复。</p>
<p><strong>kkndme：</strong></p>
<p>出手不存在困难。二手房交易国家不会对土地证进行严格限制，关键还是房产证。</p>
</blockquote>
<h2><span id="买学区房问题">买学区房问题</span></h2><blockquote>
<p><strong>开洋木瓜：</strong></p>
<p>楼主，有个问题想咨询一下。</p>
<p>家在南京，郊区有一套自住房，130平，市值大概150万左右。市中心有一套小公房，居住权，目前空置（刚分到的，还没有装修，而且单位也禁止对外出租）。现在宝宝一岁，想给宝宝买个学区房，很多名校都要求提前三年落户，所以必须要在2年内买房。一线的学区房单价在2万2-2万6之间。一线小学的分校学区房在1万5-2万之间。我想买的是一个名小的分校，近几年的小升初成绩都非常不错，可以进入南京前三名。</p>
<p>我想买的一个房子位于这个小学的学区，是拆迁安置房，97年的房子，小区环境比较杂乱，没有物管，停车也不方便。但是周围配套都非常齐全，菜场超市医院都很近，上学也不用过马路。今年年初，2月份的时候我本来在这个小区买了一套，但因为房价上涨房主违约。当时买的房价是12500，现在看中一套，房主要17000，挂了很久没卖掉，我出15000，可能有机会成交。</p>
<p>这个隔壁有个新小区，物管环境都很好，但价格也上到2万一平了，如果要在这个新小区买房，我们家里的钱就不够了，如果要卖掉现有的房子去买，老公也不愿意。</p>
<p>还有个问题是，房主要求净得价，12月的时候满五年，就不用付营业税。如果现在交易过户也可以，但要多付几万块。如果算上这几万的税，房价就差不多一万七一平了，我也不愿意现在过户多付这个钱。如果现在签约等12月再交易过户会不会有风险？另外现在是否是出手时机？请楼主赐教。</p>
<p><strong>kkndme：</strong></p>
<p>学区房即使在调控最严厉的时期也几乎不可能下跌。但是在上涨期就很难买到，因为房东会跳价。</p>
<p>12月过户有一定风险，如果到12月时，房价上涨比较厉害，房东有可能违约。</p>
<p>制约房东违约的方法就是签较高的违约金。</p>
</blockquote>
<h2><span id="历史的结局">历史的结局</span></h2><blockquote>
<p><strong>Peter_Takeshi：</strong></p>
<p>LZ写的不错，有些意见不敢苟同。<br>LZ既然熟读历史，又在安抚众人去接受被统治的命运，那能否告知最后的结局呢？<br>是否跟前几十个朝代一样？呵呵~<br>人性几千年从未根本改变，所以即使过程不同，结局仍旧是一样。<br>谁上台都改变不了这一切。</p>
<p><strong>kkndme：</strong></p>
<p>历史上的结局三条路：<br>和平演变——在中国好像没发生过，今后也不可能，没有土壤<br>大革命——哪次也少不了<br>外来入侵——这个也比较靠谱</p>
<p><strong>facetowall：</strong></p>
<p>对lz的深厚的历史功底十分佩服。lz说改朝换代的方式有三种：1.和平演变；2.农民qiyi；3.外族入侵。我觉得前苏联的解体看似像是和平演变吧，第2、3条好像不符合。lz说zhongguo无和平演变的土壤，但是前苏联好像也没有啊。这该如何解释呢？</p>
<p><strong>kkndme：</strong></p>
<p>苏联的文化背景与中国完全不同。我国是自秦以来进入帝国时代，是一个上千年大一统的国家。<br>而苏联是在近代革命后才出现的。俄罗斯的主要人种是斯拉夫人，在日耳曼民族眼中是奴隶的意思，人种低劣。中世纪叫做罗斯地区，由基辅公国、莫斯科公国、立陶宛公国等多个公国割据，在元代一直附属于拔都建立的金帐汗国。罗斯诸国在西方中世纪非常弱小，直到波兰立陶宛联军大破德意志的条顿骑士团后，才逐渐强大。俄罗斯于1721年彼得大帝时期才开始崛起，19世纪末才成为帝国主义国家，根本就没有大一统的土壤存在，这也就是苏联能够和平演变，而中国不行的原因。</p>
</blockquote>
<h2><span id="人口普查">人口普查</span></h2><blockquote>
<p><strong>平静的房奴：</strong></p>
<p>看来楼主今天比较空闲，一口气发了这么多帖子。</p>
<p>有个问题想青椒哈楼主，我在武汉，最近武汉在全免清理个人和家庭住房信息，晚上调查人员还上门登记、记录，请问这是何意？是否在为出台房产税做准备。</p>
<p><strong>kkndme：</strong></p>
<p>人口普查。不但武汉，连穷山沟里也在忙这个，穷乡僻壤的支书天天忙得不亦乐乎。这是第六次人口普查，前面查过五次了</p>
</blockquote>
<h2><span id="昆山房价分析与买房">昆山房价分析与买房</span></h2><blockquote>
<p><strong>買房難：</strong></p>
<p>樓主﹐麻煩你分析一下昆山的房價吧﹐先謝謝﹗﹗</p>
<p>昆山是一個縣級市﹐原先是屬于蘇州的﹐離上海很近﹐動車只要20分鐘﹐現在高鐵也開通了﹐原先房價還算便宜的﹐現在連鎮上也貴到五千多六千了﹐市中心最便宜的也要七千多八千﹐09年10月的時候一下子漲了很多﹐原先我看好的一套二手房32萬﹐現在要50多萬﹐太奇怪了</p>
<p><strong>kkndme：</strong></p>
<p>昆山不能理解为县级市，要理解为上海的卫星城。相当于北京的燕郊。所以房子八千多一点也不奇怪。</p>
<p><strong>買房難：</strong></p>
<p>謝謝樓主回復﹗昆山市中心的房子大一點的開發商開發的如世茂在一萬左右一平﹐這個價位算不算高啊﹖</p>
<p>買房子要在市中心好點呢﹐還是城東靠近上海方向好些﹖</p>
<p>昆山很小的﹐就那么几個鎮﹐現在火車站﹐汽車站﹐高鐵﹐人才市場都在城南﹐另外除市中心的玉山鎮外﹐其它的都是工廠很多﹐污染還是多。</p>
<p><strong>kkndme：</strong></p>
<p>买在哪里合适，你要看zf规划，跟着zf规划走。比如房山，zf打造的是长阳而不是老的镇中心，所以买房就应当买在长阳。道理是一样的。</p>
</blockquote>
<h2><span id="为什么现在租售比这么低-amp-同小区买一套大还是两套小">为什么现在租售比这么低 &amp; 同小区买一套大还是两套小</span></h2><blockquote>
<p><strong>我爱的飞飞：</strong></p>
<p>对待房子，我的看法是这样的，50-60年代的人，兄弟姐妹至少5-10个，2004-2020年之间正50、60、70、80、90年代共存的时代，人口达到了爆发阶段，现在好多小年轻70、80代人因为买不起房结不起婚，甚至晚婚索性不育，等50.60后在未来20-30年离世之后，将会有大量的房子空出来。而80后的子女2000后，人口根本不足以养活上一辈。</p>
<p>我在成都，我的父母是体制内的，我是体制外的80后，刚结婚，老公是体制内的。原家里有一套单位的集资建房，只有小产权，在二线城市的一环内，98年的房子，因为担心迟早有一天拆迁以后没有房子住，小产权也不会赔多好的地段或者得到较好的补偿，再加上以房养房的心理作祟，以及我参加工作以后想从家里独立出来，于是父母在08年底四川地震以后全国大降价赶上好时光在三环外买了一套140的房子，那会儿才买成2900，今年交房以后装修到一半，就有人以双倍价格想买入，父母不卖，留着养老。一年不到翻了一番起来，我结婚以后，也和老公一起在一环附近购入一套小户，8千多。老公家在外省某市有2套，这样算下来，我门要是生一个孩子，以后这孩子手里就有我父母在成都的2套加上老家的1套，我和我老公的1套，孩子爷爷奶奶的2套，一共6套，您说等我父母和老公父母都去世以后，房子嗖的一下就空出来了不少。所以我觉得80后到了四十岁左右肯定都能住上房子，那个时候房子也不再值钱，不过话又说回来，其实我的父母也是年轻的时候住在单位的公房，三十五近四十岁才有了第一套集资建房，而他们的第二套和第三套相对比较快了。所以我现在觉得年轻人还是应该多奋斗吧。但是我真的不清楚，到了房子不缺的时候，那个时候又会炒什么。</p>
<p>虽然我是土著，也不缺房子，但是压力也不小，特别是还贷，连车也没敢买。有时候我跟LG也想，为啥我们买的房子首付了二十几万，装修十万，我们每个月还还着2500的按揭款，租房客2000就租走了，那不是我们垫着钱给别人提供福利么？向楼主求解。</p>
<p><strong>kkndme：</strong></p>
<p>打个比方，假设你打算在某地开个游乐园，竞拍一块地，经过计算当时的门票定价10元一张，根据人流测算，你认为出500万投标这块地，5年可以回本，于是你出了500万，但是别人出到了1000万，你认为1000万要10年回本，风险太大了，于是你放弃了。你冷笑着认为那个傻子一定会赔钱。</p>
<p>结果过了2年，票价涨到100元一张了，人流量一点也没减小。人家5年就回本了，以后赚的盆满钵满。可是这个生意你却因为太能算计没有做成。</p>
<p>为什么房价租售比低？</p>
<p>其中原因之一是现在的房价预期了以后的租金。</p>
<p>另一个也是最重要的原因就是：现在的房价不够高，说明了很大一部分普通家庭都有希望买得起房，所以宁肯省吃俭用住合租房，为了攒首付。但当房价高到普通家庭不敢问津的时候，这部分中等收入的合租家庭就会放弃买房转而追求租住有一定舒适度的房屋，房屋租金就会上涨到合理的程度。</p>
<p><strong>welldayzwb：</strong></p>
<p>楼主在线啊，真好，这个道理大概也明白，不过现在出于”活雷锋”阶段，心里还是很不舒服<br>去年底在北五环投资的一套大一居，首付加税款超过60％，贷了30年的公积金，现在房租还是不顶月供，而且空租期很长<br>很怀疑自己的投资决策，好象不是一个很明智的选择，纠结中</p>
<p><strong>kkndme：</strong></p>
<p>当房价快速脱离你的成本区，你的心理就好受了。</p>
<p><strong>welldayzwb：</strong></p>
<p>再多问一句，有机会一步到位买个满意的大房好(也是老房，得房率高，三居)，还是买两套小房，一套凑合着住，一套放租好？</p>
<p>当然两套小房的总额比一套还是要多不少，帮忙分析一下，短期和长期来看的情况？谢谢！</p>
<p><strong>kkndme：</strong></p>
<p>其实买两套同一小区的房子是最好的，投资自住兼顾，可进可退。如果家里有老人，和老人分别居住，又在同一小区，照顾起来很方便。</p>
</blockquote>
<h2><span id="买房难之回不去的乡-amp-拉美人过得比你想象的好">买房难之回不去的乡 &amp; 拉美人过得比你想象的好</span></h2><blockquote>
<p><strong>九五二七八：</strong></p>
<p>楼主说的以后大部分人买不了房的论题<br>中美在这个方面的差距 怎么这么大呢<br>现在产业转移 一部分人就业就有回乡的趋势<br>今后再有一波转移 会不会再离故乡近一些<br>这样 分散置业 购买难度会不会下降</p>
<p><strong>kkndme：</strong></p>
<p>中美体制不同、文化不同、人口不同。一辆在美国2万美金的汽车，国内要卖几十万人民币。一件made in china的服装美国卖20美金，国内卖900人民币。</p>
<p>不管一线城市、三三线城市都是人满为患的，从一线城市逃离的也会驻扎在二三线城市，绝没有可能大中型城市向小城市回流。</p>
<p>返乡潮指的是家有自留地的农民工，如果工资待遇差不多，与其到沿海地区漂泊不如回乡打工或者种地。比如贵州镇远的油漆工一天工资是150，而在珠三角打工一天工资还不到150，这也是大量农民工返乡的原因。</p>
<p><strong>九五二七八：</strong></p>
<p>最难的怕是现在三四流的大学生和跟着打工父母生活在城里的二代<br>失去了农村生活本领<br>在城里也无法立足<br>楼主<br>难道拉美化真的不远了</p>
<p><strong>kkndme：</strong></p>
<p>很多人都丑化拉美，但是拉美的生活水平要高过我国。不说远超中国的巴西，即使是法属及荷属圭亚那(苏里南）这样的小国，人民的生活也很富足。</p>
<p>前几年有个援助项目去苏里南等拉美国家，去之前所有的人给我灌输的都是拉美国家如何贫困。但事实上，这些国家与中国完全不同，国穷民富，藏富于民，与中国正好是相反的，只要勤快点的家庭都还比较富裕。当然不排除也有很多穷人（美国也有很多穷人），穷人一般以当地的黑人为主，好吃懒做，整日无所事事。</p>
<p>这些国家的人民不如中国人勤奋，从不攒钱，只图眼前享受，我想主要原因还是由于币值不稳定，通货膨胀比较严重，所以没有人愿意攒钱。在拉美国家是无法炒房地产的，比如苏里南平均25平方公里有一口人，真的是地广人稀。所以才保留了世界上最高的森林覆盖率。</p>
<p>拉美人的懒惰会让中国人瞠目结舌，当地的蔬菜价格昂贵，尽管有大片肥沃的土地，当地却没有人愿意耕种，很多去苏里南种植蔬菜的中国人为此发了大财。</p>
<p>而相反中国人可以说是全世界最勤劳的民族，但是大量勤劳的中国人却过着低水准的生活。这与中国的国富民穷，藏富于国，与民争利的政策是分不开的。</p>
<p>拉美国家尽管有这样那样的问题，但是确实是法制国家与民主国家，私人财产神圣不可侵犯，这是与中国完全没有可比性的。</p>
<p><strong>九五二七八：</strong></p>
<p>一般对“拉美化”的定义是这个吧：贫富悬殊扩大、腐败严重、国有企业效率低下、社会治安恶化、城市人口过多、地下经济泛滥、对外资依赖性强、金融危机频繁和政局不稳定，等等</p>
<p>没去过拉美 不知道真实的拉美</p>
<p><strong>kkndme：</strong></p>
<p>看来拉美妖魔化后，深入人心了。好比在越南旅游，越南人自己说越南官僚太腐败，我笑了，能有中国腐败？</p>
<p>拉美的官僚机构，国企、医院、警察我都见识过。</p>
<p>说到官员的官僚，相比中国我真的觉得那里的官员很亲切。我曾经以一个游客的身份和苏里南的司法部长一起在街边小店喝咖啡。以一个陌生的外国游客身份在财政部长家里做客，逗他家的几个黑小孩玩。</p>
<p>说到治安，我在街边咖啡店坐了一下午，每二十分钟一辆巡逻车从我身边经过。里约热内卢的治安绝对不会差过广州。</p>
<p>国有企业效率低下恐怕是全世界的通病，况且拉美根本没有可能赚钱的行业全部由国企垄断。</p>
<p>政局不稳要看怎么理解，拉美国家是相对民主的国家，国家元首倒是常常因为民众的不满而换届（排除少数经常政变的军政国家）。但人民并没有感觉到不幸福。</p>
<p>拉美国家的经济基本被美国所控制，所以才会对外资依赖严重和金融危机频繁。作为一个主权国家我们看到的是国家财政贫困，但是作为拉美地区的中下层人民群众，生活水平和幸福感是要高于国内的中下层群众的。</p>
</blockquote>
<h2><span id="租房的苦">租房的苦</span></h2><p>说到租房举个活生生的例子。</p>
<p>我有朋友是个房产的死空头，一直租住着北京一套两居室的老公房，租金不高1000多点，所以没什么负担，对买方族恨不能理解。结果今年他租住的那片老公房要拆迁，限期20天内搬家走人，结果终于理解了找房子的辛苦，而且随便租一套两居室也找不到2500以下的了。</p>
<p>真是心态决定命运。</p>
<h2><span id="北京西三旗">北京西三旗</span></h2><blockquote>
<p><strong>bjwxw：</strong></p>
<p>楼主在线啊，今天几乎花了大半天的时间从头至尾的看了楼主的帖子，分析和解释的真的很实在到位，也许我了解的不是很多，但是确实觉得现实好多都是这样的，麻烦我现在有个问题，我住在西三旗，我租住的这个小区去年的这个时候价格是60-70左右，我失去了机会，可是今年这些房子基本都是120-140万之间了，我现在是在忍不住，也憋不住了，因为我是刚需，虽然心里是万分的懊丧和后悔，但是事情还的做，房子还是的买，可是我很担忧，我花140万买只隔一年就升值一倍多的房子，后果会是什么，我真的怕等了好久，可是等我出手了，房子真的跌了，尽管不会跌很多，但是把我的首付跌光那也是件很可怕的事，毕竟辛苦的攒了这么多年的钱，我是实实在在像楼主说的那样的底层奋斗着的接近中年的刚需外地人，挣钱太辛苦了，所以很害怕，楼主，我现在也很急，老婆看好了一套140万的房子，要我去买，我也知道她也很无奈了，可是我心里这关好难过啊，想听听你的指点，急盼回音</p>
<p><strong>kkndme：</strong></p>
<p>西三旗的房子与不远的立水桥相比，涨速是相当慢的，尽管离市区更近当房价跟回龙观相仿，并没有拉开差距。随着8号线的即将开通，8号线地铁站中央部位保障房项目的启动，西三旗房价上升空间还不小。</p>
<p>西三旗附近最值得购买的小区是枫丹丽舍，因为低密度将来必定稀缺，但是目前价格也高过其他几个楼盘，甚至高过新盘富力桃园。配套最成熟的小区当属育新小区。象硅谷先锋、森林大第也都比较好住。西三旗这片地区属于难得的价值洼地，值得购买。</p>
<p><strong>bjwxw：</strong></p>
<p>多谢楼主，看来您真的对西三旗了解的太透彻了，我真的很幸运，我就直接跟您说了吧，我说的房子是龙乡小区，您肯定也很了解，这个是个老小区，房子已经超过了10年，优点就是交通好，周边医院，学校，购物都极其的方便，因为钱有限的原因，只能买这里的，情况就这样，您能给我多说几句吗？多谢</p>
<p>一着急字都打错了，不好意思</p>
<p><strong>kkndme：</strong></p>
<p>龙乡小区的房价在西三旗片区相对较低，因为房子是90年代的，但是周围配套相当齐全，去超市购物也很方便。如果你在上地上班也算比较近，唯一的遗憾就是房子旧了点，户型与2000年后的次新小区相比，有点不尽如人意。</p>
<p><strong>bjwxw：</strong></p>
<p>确实是这样，今天通过从头看到尾您的帖子，基本心中已经有了概念，买吧，尽管我从这个小区的70万的房子如今花140万去买这个心理关很难过去，但是还是过吧，既然已经这样了，认命吧，不害羞的问一句，房子价格已经16000了，您说这个地段在将来是会升些，还是会跌一些，呵呵，实在不好意思，添麻烦了</p>
<p><strong>kkndme：</strong></p>
<p>这个地区的房价，两年内是可以看到25000的。</p>
<p><strong>喜欢8号线：</strong></p>
<p>楼主看好西三旗地区房价，本人深有同感。<br>西三旗地区的焦点不在京藏高速路口，也不在林翠路路口，而在西三旗东路。也就是地铁8号线西三旗站附近。<br>现在这附近已经有宾馆、饭店、百汇商品市场、中小学、3甲医院、银行。<br>到2012年，8号线开通，百汇市场新增电影院，龙旗广场新增写字楼2座和3星级酒店一座，<br>随着北新建材厂的搬迁，原厂区还会有更多的新楼拔地而起，西三旗东路将南延、拓宽至永泰。整个地区的房价将随着新楼盘的不断推出而节节高升。</p>
<p><strong>kkndme：</strong></p>
<p>西三旗地区一直相对滞涨主要还是缺乏大品牌开发商入住，没有高端楼盘的带动，涨幅偏低。但也正因如此，才形成了一块价值洼地，以后才有更大的上涨空间。</p>
<p><strong>跳坑的青蛙：</strong></p>
<p>没想到楼主对西三旗地区如此熟悉~<br>想问问楼主对于上地附近二手房的看法，如当代城市家园这样的地方，有没有升值潜力？<br>觉得这边交通还是有很大问题~</p>
<p><strong>kkndme：</strong></p>
<p>上地区域的房产在2008年之前，涨幅较快。但在2008年以后由于上地区域的产业以民营iT为主，属于充分竞争，利润下滑较快的产业，区域经济的发展前景远不如望京，所以上涨空间受限，涨幅趋缓。<br>区域发展是房价升值的动力，个人不太看好上地区域。</p>
<p><strong>汝爱之罪：</strong></p>
<p>对上地一点也不了解，不过今后北京的私企郊区化应该是趋势，好多公司因为成本问题已经开始向密云等地搬家。上地的价格若被炒太高，也难逃此运。</p>
<p>也许zf会注意到这个发展趋势，引导郊区，现在大力发展郊区地铁就是为今后的卫星城铺路吧。不过能不能成功，是另一回事。里面牵涉利益太多，比如海淀，主导还是高科技产业，如果全都搬家，地区zf就头大了。上地区域，可是海淀政府大力度发展的重点区域。</p>
<p><strong>kkndme：</strong></p>
<p>你说的很有道理，现在海淀的it产业基本就是以处于链条底端的制造业，毫无科技科研，急需产业升级，才能得到持续的发展。象联想这样的it公司完全沦为了90年代家电厂商的境遇，毫无未来。</p>
</blockquote>
<h2><span id="买房争取一步到位">买房争取一步到位</span></h2><blockquote>
<p><strong>hohowell：</strong></p>
<p>楼主，诚心请教下，从开贴开始就一直在潜水关注，终于坚定了买房的决心</p>
<p>现在在犹豫，一是买个80平米的小户型，开发商一般，房型尚可，这样贷款比较少，基本不影响供车，旅游和以后小孩的开销，不过考虑5到8年左右，这个房子就不能满足居住要求了，回头换，又是一大笔钱，而且城区内的好小区也会越来越小，另外一个就是保利的大户型，开发商物业都靠得住，基本上短期可以不用换，不过贷款至少贷100多万，短期内还会要小孩，压力会比较大，基本手里每个月都没有闲钱了，很容易回到赤贫线，一直犹豫不决，诚心请教楼主解惑，我在南京，一个一线以下二线以上的鬼地方，两处房子都靠地铁，周边商业中心配套齐全，谢谢！</p>
<p><strong>kkndme：</strong></p>
<p>买房子如果有能力还是要争取一步到位。将来改善，除非个人有较大的发展，否则将很难很难。而且买楼首选好位置，大开发商，大盘，升值空间才大。</p>
<p><strong>welldayzwb：</strong></p>
<p>看来楼主分析说购房应该一步到位，我就犯了一个错误，用投资的眼光来选择自住房，后来买的两居室比同小区的三居室性价比高很多，但是居住环境不好，临一条小街，所以现在住起来不是很爽，现在调控着价格先不说了，光是现在限制换房的一些条条框框感觉再置换就很麻烦<br>另外一套买的外面一点，小区环境非常棒，不过当时是被环境给迷惑了，放租的房子管那么多环境做什么，感觉两套房子操作反了<br>纠结中啊纠结中，现在唯一能安慰自己的就是，买上房子总比没买强，如果去年年底再犹豫一下或是赌气的话，那就真是悲剧了，一个好三居得活活等成质量差些的两居了</p>
</blockquote>
<h2><span id="收入稳定的家庭如何买房">收入稳定的家庭如何买房</span></h2><blockquote>
<p><strong>黑眼圈钱：</strong></p>
<p>请教楼主，买房子的事情，比较纠结。</p>
<p>1）夫妻两人均在西部某高校任职，一个教师，一个行政人员，年龄都不小了，37和35，两人每月总收入在8000-10000，1年算10万收入，应该会多一点。</p>
<p>2) 一个女儿，才两个多月。<br>3)<br>3）每年给双方父母1万，双方父母均已60出头，一方父母城里的有退休金及医保。另一方父母农村的，得为他们准备点钱。</p>
<p>4）目前租住单位两室一厅房，就在学校住宅小区内，除了小点，别的都好，房租100。</p>
<p>5）公积金两人很少，约1000元每月，未来1-2年内会有购福利房机会，估计90多平方的旧三室一厅（约需 10万元），可能有120平米的房子，但需要排队看单位建房情况（2000每平米）。</p>
<p>6）两人都有单位医疗保险。</p>
<p>7）孩子可以上学校的幼儿园和小学、初中，就在150米范围内。</p>
<p>8）对于车没有什么想法，每天步行上班用不到车代步。不过会买辆10万左右的。</p>
<p>9）现在没有任何投资和理财。银行存款1-2年期定期存款50万，这个傻了，已经存2年了，平时光顾着干活。</p>
<p>有没有必要买个商品房呢，周围的房价从08年的4500涨到现在8500，容积率还非常高，并且楼间距等等不理想，那种房子我不想住的。</p>
<p>其实在附近买套120平米的房子，首付后也供得起，买房子放那等涨价或者出租？ 不想放弃单位的房子，每天睡到自然醒再去上班还是挺惬意的，送孩子上幼儿园上学也方便。</p>
<p>买了房子后经济会紧张些，不像现在自由。财务自由也算一种幸福吧，我太太对于房子没什么要求，所以也不给我什么压力。</p>
<p><strong>kkndme：</strong></p>
<p>对于工作稳定，收入不错的体制内家庭，基本上的情况就是有闲钱就买房。主要还是由于收入稳定不用担心失业，钱放着只有贬值，不如置业。投资型住房与自住型住房在选择方向上有很大不同。</p>
<p>举个例子，昆明打造了个螺丝湾，几乎半个昆明做生意的人都聚集在哪里。如果自住没有人愿意选择在那里买房，实在是不好住。但是投资确是最好的选择，因为可以获取较高的租金的收益，将来升值空间也不会小。</p>
<p>假如在昆明一环附近买一套两居室，月租金一般在1500-1800，而房价在万元左右。而在螺蛳湾附近买一套两居室，月租金都在2000多，而房价在7000多。</p>
</blockquote>
<h2><span id="北京回龙观">北京回龙观</span></h2><blockquote>
<p><strong>baiyang11112010：</strong></p>
<p>LZ,你好，我2010年3月在回龙观买一复试房子120平米，户型不是很好，全部下来，161万，我尽量提前还贷，控制在3-5年以内，所以，这房加利息定能控制在170万以内，我想问的是，3-5年我想出手，会不会亏？</p>
<p><strong>kkndme：</strong></p>
<p>你的问题太短了，虽然问了几遍，居然没看见。<br>回龙观地区的配套设施齐全，积水潭医院入住将提升该地区的物业价值。随着中关村高新区北延规划的利好，回龙观地区的房价在未来两年内有50%左右的上涨空间。</p>
<p><strong>baiyang11112010：</strong></p>
<p>我觉得LZ你的分析思路不错，但是这种涨幅应该不会再有了吧？虽然我今年4月投资了一套，但是，我能回本就行，没敢过分估计，你这样有煽动别人之心啊</p>
<p><strong>kkndme</strong>：</p>
<p>首先投资房产不是炒股，不能有炒股的心态。目前说起投资房产是最安全的品种，指的是长线投资，而不是短线投机炒房。短线投机炒房还是因政策的不稳定有较高风险的，一旦资金链断掉，将万劫不复。</p>
<p>对于4月份，在山雨欲来风满楼的特殊时期，投资一线城市郊区房地产肯定是欠考虑的。</p>
<p><strong>对于房地产调控，主要针对一线城市，且一线城市在09年行情涨幅过大，郊区楼盘一定会受到调控影响，而资金的运作规律告诉我们，调控抑制住了一线城市的投资资金，一定有相当部分转向二三线房价相对不高的城市，大开发商对二三线城市的入住，将加速城市升级。所以调控征兆的开始，正是布局二三线城市的时机，而不是一线城市。：</strong></p>
<p>值得安慰的是，回龙观地区并没有遭遇疯狂炒作，表现比较抗跌，即使被套损失也不会大。从未来两三年看，回龙观的区位一定会有50%左右的涨幅，这是不用担心的。</p>
</blockquote>
<h2><span id="贷款还是全款">贷款还是全款</span></h2><blockquote>
<p><strong>jhjdream：</strong></p>
<p>楼主，请教一下，</p>
<p>也正是8月初看来楼主的帖子，坚定了我此时买房的决心</p>
<p>我在3月份卖了一套小房子，8月底买了套大点的，也是学区房，学校在建</p>
<p>现在考虑一个问题，是全款付清好还是贷款比较好<br>全款付清，欠亲戚10多万，没有还钱压力，年底可还清，但是手头没有余钱<br>贷款的话，手头会有20多万余钱，可以装修，或者等年底再攒点钱，投资其他的<br>所在省会城市房价8000多，偏一点的6000左右。</p>
<p>装修好出租2500左右，贷款月利息2000左右<br>也就是说我全款还清，一年相当于收益2.4万的利息及3万的租金，房款70万左右，<br>是否值得？还是贷款35万比较合适？</p>
<p>因为考虑到通货膨胀时期，应该是负债比较划算～～ 谢谢！</p>
<p><strong>kkndme：</strong></p>
<p>肯定是贷款划算，这是毋庸置疑的。当然如果你的余钱实在找不到其他投资渠道，也可以一次性付清。如有可能也可以贷款买两套，而不是买一套。<br>70万的总房款月租金达到2500，租售比还是很高的，贷款35万，租金抵月供完全没有问题，说明你所在地区的房价具备较大的上涨空间。</p>
</blockquote>
<h2><span id="00后的买房需求从何而来">00后的买房需求从何而来</span></h2><blockquote>
<p><strong>和风中的树叶：</strong></p>
<p>看了那么多 有点意思</p>
<p>不过在下有一事想不明白：</p>
<p>因中国的计划生育政策 往近了说 人口红利会在这几年消失 往远了说 80后基本都是独生子女 父辈在城市里都是有房子的 这些房子作为遗产 按理说 在未来应该使00后没有买房的需求。<br>LZ如何解释在这种情况下在未来房子仍然看涨？</p>
<p><strong>kkndme：</strong></p>
<p>前面已经说过了，你往前翻。</p>
<p><strong>和风中的树叶：</strong></p>
<p>LZ能不能再贴一次？或者说明一下在第几页？谢谢哈~</p>
<p><strong>kkndme：</strong></p>
<p>回去找了一下，居然被删了。<br>大意基本是讲中国经济未来的发展模式，城市升级与拆迁改造的关系，没想到这样也不允许说。实在懒得再长篇大论说一遍。<br>关键的意思就是一方面是富裕阶层对更高端产品，更大面积的追求，一方面是城市升级带来的大规模拆迁改造。下层群众将被挤出城市核心区。许多住房都会被拆迁置换。</p>
</blockquote>
<h2><span id="意大利的住房模式">意大利的住房模式</span></h2><p>我本人对意大利的住房模式还是比较赞同的。<br>有去过米兰的朋友可能很清楚，米兰城区的房屋居住的大多数是富豪显贵，一旦出了城区，则是大片大片鳞次栉比的公租房供普通工薪族居住。<br>以后的中国有可能学习这个模式，原市中心的居民被拆迁安置到郊区，城区居住的都是达官贵人。郊区将形成拆迁安置房、中产阶级商品房、公租房、廉租房混居的模式。</p>
<h2><span id="中国的学术">中国的学术</span></h2><p>97年我大学毕业的第一任老板就是在龙乡小区买的房，我还到他家送礼。那时从城里骑车到西三旗，花了我将近两个小时。一晃就十几年过去了，真是有很多感慨。</p>
<blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>感觉您是学者型的啊，看您去做田野调查什么的。大学毕业送礼给老板。。。。</p>
<p>看您点评回龙观的那一段，估计很多人要捶胸顿足的后悔了。回龙观真是个奇迹，从2600涨到15000，让所有人大跌眼镜。</p>
<p><strong>kkndme：</strong></p>
<p>送礼也算学者型？晕</p>
<p><strong>九五二七八：</strong></p>
<p>他是说本以为你是学者型的 不需要送礼<br>现在看到你说送礼 觉得自己判断失误了 呵呵<br>现在这个时代 学者也需要送礼啊</p>
<p><strong>汝爱之罪：</strong></p>
<p>差不多这个意思，呵呵。我一直以为楼主是搞学术的。</p>
<p>其实吧，虽然大多数学者砖家都成了贬义词，但我觉得在北京这个大环境里，还是有土壤培养一些目光敏锐犀利的人，BBS的P民也需要这样有前瞻性的引导者，因为毕竟不是每个人都强大到能把这些东西娓娓道来，没有积淀，根本悟不出。</p>
<p><strong>kkndme：</strong></p>
<p>中国的学者是很难拿出点时间好好搞搞学问的，功利性太强。</p>
<p>以前跟一伙民族学者到元阳考察，这帮人没呆满两个星期就跑回去了，说是又要评职称了，人不能不在单位。而日本学者已经在元阳与当地人同吃同住了3年，还没有一次回日本。真不知道这帮民族学者研究了两个星期的东西能发表什么样的惊世论文出来。</p>
</blockquote>
<h2><span id="北京远洋山水">北京远洋山水</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>不知楼主了解远洋山水吗？在西四环外，我舅舅想在那买房，去年一万七没买，今年最高到过三万，现在两万六左右，能买吗？还有升值空间吗？诚心请教。</p>
<p><strong>kkndme：</strong></p>
<p>别提了，08年的那次调控，开盘才1万1，这是个让人悔得肠子都青了的楼盘。<br>北京的楼市前景，在未来的两三年，北四环西四环东四环达到5万，北五环西五环外到达3万应该不是什么难事，南面可能相对低一点。远洋山水的位置2万6不能算便宜，但将来只有更贵。</p>
</blockquote>
<h2><span id="精英的资产">精英的资产</span></h2><p>5万一平的房子对于中国的精英阶层真算不上什么。500、600万一套的房子一次性付清的人群在北京大把的存在着。这是很多工薪阶层一辈子都觉得不可能挣到的财富，但对于另外一些人却可以轻而易举的拿出来。平均工资的概念在中国是完全没有用处的。</p>
<h2><span id="北京三环塔楼">北京三环塔楼</span></h2><blockquote>
<p><strong>bluesyang2010：</strong></p>
<p>请问楼主，北京三环内的塔楼，80年代末的房子，以后会有什么走向，现在能出手吗？谢谢</p>
<p><strong>kkndme：</strong></p>
<p>三环内都是老公房，干嘛不买个板楼呢。这种房子老到不好住了，迟早还是要换。板楼还可以拆迁，塔楼拆迁就比较困难了。不过今后的北京可能存在一个相当奇怪的现象，一部分高端富裕人群居住在市中心老旧的小区，而令广大住在远郊的中产阶层羡慕不已。</p>
</blockquote>
<h2><span id="普通人买房的未来">普通人买房的未来</span></h2><blockquote>
<p><strong>baiyang11112010：</strong></p>
<p>直白说，我刚毕业一年，完全靠着父母资助，要完全靠自己根本买不起房，我一些同学在北京两人的话年薪也就15万左右吧，现在好歹还能惦念着买房，要是像您所说，“北四环西四环东四环达到5万，北五环西五环外到达3万应该不是什么难事”，那他们根本就没有盼头了，这是很可怕的事啊</p>
<p><strong>kkndme：</strong></p>
<p>将来年薪20万的中产阶层一定连北京6环内的房子都买不起。这一天，不会很远。</p>
</blockquote>
<h2><span id="北京房价超香港">北京房价超香港</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>金岩石说未来五年房价还得翻一翻，北京核心区域得到二十万一平，真会那样吗？请楼主说说</p>
<p><strong>kkndme：</strong></p>
<p>北京北四环，东三环，西三环，南二环内区域的房子，价格一定会超过香港。</p>
<p><strong>tianxiaobing11：</strong></p>
<p>香港怎么也得几十万一平吧，还是得早买房，早买早心安</p>
<p><strong>kkndme：</strong></p>
<p>香港都是按尺算的。富翁住的千尺豪宅相当于我们的大约100平米。现在香港的房价换算成平米大概是十五、六万一平吧。</p>
</blockquote>
<h2><span id="中国的新闻不可信精英的有钱是你想象不到的">中国的新闻不可信，精英的有钱是你想象不到的</span></h2><blockquote>
<p><strong>bluesyang2010：</strong></p>
<p>搂主分析一下,现在的新闻都说房屋成交量的上升是因为kfs打折才上升的,但这个很不成立,为什么新闻这么懵老百姓.是不是政策上还有可能收得更紧?</p>
<p><strong>kkndme：</strong></p>
<p>中国的新闻最不可信，为了抓眼球不惜胡编乱造，不惜前后自相矛盾。我倒觉得这个成交量放大的背后的意义更值得深入研究。</p>
<p>在二套房首付50%，三套房首付更是严格控制的前提下，成交量大幅提升，中国的货币到底泛滥到何种程度，中国的精英阶层的绝对数量多么庞大，手里多么有钱。中国的贫富差距很可能已经达到了一般人不敢想象的程度。</p>
<p>这是一个坏的预兆。</p>
</blockquote>
<h2><span id="40年的商住房没有70年的住宅有投资价值">40年的商住房没有70年的住宅有投资价值</span></h2><blockquote>
<p><strong>klid：</strong></p>
<p>LZ 请教一下，市中心没有天然气的房子能买么？自住兼投资</p>
<p><strong>kkndme：</strong></p>
<p>商改住，40年产权？<br>不影响出租，但是变现可能不那么容易。</p>
<p><strong>klid：</strong></p>
<p>是70年产权住宅，但是不通天然气！<br>LZ请教一下啦，可以自住兼投资么</p>
<p><strong>klid：</strong></p>
<p>自住只要你觉得不用天然气也很方便，当然没问题。</p>
<p>投资首先是出租不存在问题，另外市中心的位置可以填补任何房屋设计方面的不足，70年产权具备投资价值。购买这样的房产还是可以的。</p>
</blockquote>
<h2><span id="限贷对精英没用">限贷对精英没用</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>楼主，我也是不明白，现在成交量确实上来了，按说现在贷款控制的这么严，第三套房都贷不到款，是谁在买房，难道都是第一套房的刚需吗</p>
<p><strong>kkndme：</strong></p>
<p>民币发行泛滥，有钱人绝对数量庞大。在北京上海等城市，手中拥有千万现金的人不在少数，都是全国的精英阶层啊。精英阶层的财富积累已经逐步完成，提高首付，严控贷款只能抑制小白领保值的需求，但对于精英阶层是没有任何作用的。</p>
<p>如果将来推出房产税就更好笑了。精英阶层谈笑风声，小白领神情紧张，最终结果是全部转嫁租房客。</p>
<blockquote>
<p><strong>bluesyang2010：</strong></p>
<p>我认为,这个跟kfs和政府之间的博弈有很大关系,投资人前段时间一直在观望或者投入到农产品等领域,我不记得是7月还是8月,突然听到热钱大量涌入国内房地产市场的传闻,之后成交量就上来了,这些信息之间有很大的关系,但我捋不清.<br>请楼主评评</p>
<p><strong>kkndme:：</strong></p>
<p>你说的很有道理，当资金泛滥无处可去，一定会找到一个出口。资金如洪水在于疏而不在于堵，资金一旦冲破调控所筑的堤坝，将一发不可收拾。所以屡次调控屡次暴涨。如果不能有效开渠，将注定调控政策的失败。</p>
</blockquote>
<p><strong>tianxiaobing11:：</strong></p>
<p>我现在就被抑制住了，现在是认房不认贷，我也不能贷款了，可现在动不动就得百万以上才能买房，真是力不从心啊，房贷新政看来是堵塞了中低收入的房产投资渠道了，对精英阶层反而是利好，这调控就搞笑了</p>
<p><strong>bluesyang2010:：</strong></p>
<p>zf倒是想调控精英层呢,但zf本身就是精英的组成部分,所以zf只能借砍掉投机者之名,开拓自身,抢占市场,特别是楼主说的租赁这个大市场,所以特别佩服楼主之前说的:zf找到了吃租赁这块蛋糕的最好时机,明着是抑制房价,其果却是让很大部分老百姓租着zf的房,zf的钱就更多了,到时候想拆哪儿拆哪儿,精英更精英,百姓更百姓….可悲呀</p>
<p><strong>kkndme:：</strong></p>
<p>估计给政府出这主意的幕僚熟读过宋史，宋代官府就是靠出租房给群众敛财的。</p>
</blockquote>
<h2><span id="外汇管制决定了大部分有钱人只能在国内投资">外汇管制决定了大部分有钱人只能在国内投资</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>还有一个问题始终不明白，请教楼主，现在五六百万的房子都有人全款买，这些人为什么不买国外的别墅呢？难道就因为中国的房子升值快吗？要我有那么多钱早移民了</p>
<p><strong>kkndme：</strong></p>
<p>我国实行的是外汇管制，人民币不能自由兑换，不可能大批人口通过地下钱庄转移资产。只有官员和少部分有背景的高端人士才能做到人民币资产顺利兑换转移。</p>
<p>一旦发现较多资金量的人民币兑换美元出境，国家将采取强制管制措施。</p>
<p>现在国家对外汇外流已经非常重视，携带价值50美元以上的商品入境都要交税，实际上国家给出了一个不希望人民币兑换成外币外流的一个强烈信号。</p>
</blockquote>
<h2><span id="外国国籍在中国生活是更好的选择">外国国籍在中国生活是更好的选择</span></h2><blockquote>
<p><strong>理财的猫咪：</strong></p>
<p>我有段动过移民的念头，但现在基本放弃了。不知自己的选择正确与否，想听听楼主高见。</p>
<p><strong>kkndme：</strong></p>
<p>移民不见得能够适应，毕竟文化差异太大，但是如果拥有一个外国国籍，在中国生活，是一个比较好的选择，至少，你的财产是受到保护的。</p>
</blockquote>
<h2><span id="分期付款买房如果房价上涨很容易毁约-amp-自住要选大品牌开发商">分期付款买房，如果房价上涨，很容易毁约 &amp; 自住要选大品牌开发商</span></h2><blockquote>
<p><strong>showcar:：</strong></p>
<p>楼主说的正确啊，除非世界经济再次崩溃或者朝内变天，否则的房价要跌，太难！</p>
<p>到处听说是纸币不受截至的发行，有点现金留在手上都发抖啊，是因为“贬值”发抖！</p>
<p>所以，出手了，淘一套保值去吧！！总价150万左右。</p>
<p>楼主请教付款方式：<br>1：分期付款，30%首付，6个月内付30%， 12个月内付30%，10%交房前付清（约24个月）；<br>2：商业银行贷款，需要50%首付，50%余款贷款，首付3个月后按揭，110%的贷款利息。<br>商业贷款的话，计划交房后就付清。</p>
<p>不知道哪个更合算？期待楼主解惑。。。。</p>
<p><strong>kkndme:：</strong></p>
<p>分期付款是你和房东的约定？这个比较不靠谱，如果是付清后过户，一旦房价上涨，很可能出现毁约。</p>
<p><strong>showcar:：</strong></p>
<p>楼主，忘记说了，是期房，我们这里是房子盖到一层高就预售了。房子结顶是按揭。结顶后1年半左右交付。</p>
<p><strong>kkndme:：</strong></p>
<p>貌似你们那里的房产商很不规范。我还是觉得投资自住都要选择大开发商、大体量楼盘，不仅配套好，升值空间也大，这样的楼盘几乎没有风险。</p>
</blockquote>
<h2><span id="通货膨胀和房价的关系">通货膨胀和房价的关系</span></h2><p>要解释通膨和房价的关系，我来建个简单的模型，跟大家说说</p>
<p>假设5年前，某个国家一共有10个一篮子生活必须品（包括吃，穿，住，行的所有的必需品），这个国家发行了100万货币，一共有10个人。那么这个国家的毎个篮子生活必须品价值10万。</p>
<p>假设这10个人每人得到了10万元收入，则每个人刚好分配了一个篮子。</p>
<p>实际情况是，这10个人中，有人得到了10万元，有人得到了8万元，有人得到12万元。那么这10个篮子通过在品质上的差别有所区分，卖给这10个人，刚好1人1份，只不过有的品质略好些，有的品质略差些。<br>时间过了5年，这个国家增加到20个一篮子生活必须品，人口还是10个人，但是发行了1000万的货币，那么这个国家的毎个篮子生活必须品价值50万。价格翻了5倍。如果每个人平均是100万，则每个人可以得到2篮子生活必需品，生活提高了。但实际上是，这10个人中，4个穷人每人还是10万，3个普通人每人是20万，剩下3个富人每人300万。</p>
<p>这3个富人共900万可以买掉18个一篮子生活必需品。剩下7个人只能分配到2个一篮子生活必需品。这样势必有人会饿死。而且无论是穷人还是普通人都买不起任何一个一篮子生活必需品。社会不可能只有富人才配生存，没有穷人，富人就不会存在。</p>
<p>因此必须有一项物品能够从一篮子生活必须品中剥离出来，吸收掉富人庞大的资金，同时也要让穷人和普通人能够买的起一篮子生活必需品中能够维持生命的最基本的生活品。</p>
<p>于是就要把一篮子生活必须品进行拆分。找到一项物品，不拥有不会饿死，但拥有能够让人过的舒服，具备高的使用价值，能够保存，具备稀缺性。</p>
<p>这个东西就是具备产权房屋（注意不是使用权），而一篮子生活必须品中其他的东西都不具备这个条件。<br>吃的不能保存，</p>
<p>衣服不具备稀缺性，</p>
<p>土地和房屋，是生产，居住，商业贸易的必需品，可以保存，具备稀缺性，富人拥有房屋土地的所有权可以租给普通人和穷人进行生产和居住。土地和房屋超过租金部分的溢价就变成了富人中吸收资金，炫耀财富的特殊品。</p>
<p>所以请注意，真正吸收大量发行的被富人拥有的货币的，是土地和房屋超过租金部分的溢价，所以房屋的租售比很低是货币大量发行造成的。房屋土地租金成为了新的一篮子货币中的必需品，而房屋土地所有权被剥离出来变成了富人之间货币再分配的游戏。<br>这样一篮子生活必须品进行了重新定义，本来包括的房屋，变成了房屋租金，而房屋所有权被从一篮子生活必须品中剥离出来，变成了吸收富人多出来的货币的奢嗜品。而一篮子生活品分成两大类，即最基本的和品质高的。</p>
<p>最基本的又变成了10万一个，保证这个国家的4个穷人可以每人得到一份。</p>
<p>品质高的，20万一个,3个普通人和3个富人每人得到一份就可以得到较好品质的生活。</p>
<p>多出来的840万，就是房屋的所有权，供3个富人拥有。房屋所有权的价格远高于租金，这是因为房屋所有权已经变成了富人炫耀的资本，身份的象征。<br>因此说，高房价的根本原因是由于货币发行泛滥和收入分配不公。这个根本问题不解决房价不可能下降。</p>
<p>而且单纯的依靠行政手段让房价下跌不但不能抑制通货膨胀，多出来的流动泛滥的货币得不到有效吸收，会推动生活必需品上涨，使穷人的生活更加艰难。<br>当然，有人的说，这多出来的840万为什么不投入到创新领域带动需求，增加一篮子生活必须品的品质。</p>
<p>这显然是不现实的，900万的财富集中在3个人手里，剩余7个人总共只分到100万，而平均一篮子生活必需品的价格是50万，7个人应该有350才能满足生活需要。购买力的不足一定会使远离生活必须品的任何东西都没有市场。</p>
<p>高房价，低租金是货币泛滥发行和分配不公的必然结果，而不是推动通货膨胀的，阻碍实体经济发展的原因。</p>
<p>货币泛滥和分配不公才是实体经济发展困难，房价高企的根本原因</p>
<blockquote>
<p><strong>fataltomato：</strong></p>
<p>有钱人的投资渠道一般都不是房子</p>
<p>房子最多是资产配置中的一项</p>
<p>开始投房收租，说明财富控制能力的下滑，往往意味着人生下坡路的开始</p>
<p>所以诸君，还是努力赚钱改变人生为第一要务</p>
<p>评来论去，于事无补</p>
<p>别人说到了，你不一定明白，你明白了，不一定有体会</p>
<p>你有体会，不一定能做到，你做到了，不一定能做好</p>
<p>你做好了，还不一定有机会呢，呵呵</p>
<p><strong>welldayzwb：</strong></p>
<p>对于不善理财的人来说，买房收租未尝不是一个选择，到没必要上纲上线，当然为了收租而买房，目前看起来不是很理想的一个选择</p>
</blockquote>
<h2><span id="南京买房分析-amp-买房要做好调查分析工作">南京买房分析 &amp; 买房要做好调查分析工作</span></h2><blockquote>
<p><strong>闲坐庭前也：</strong></p>
<p>楼主，一直跟帖，<br>觉得你的认识颇有见解<br>请教一下<br>最近看了南京奥体附近的仁恒楼盘<br>2万2左右每平方<br>不是自住，用做投资的话现在出手是否合适呢？<br>一直在犹豫中<br>望不吝赐教</p>
<p><strong>kkndme：</strong></p>
<p>尽管南京去过多次，但对于那里的楼盘并不熟悉，所以不敢妄言。如果能够提供更详细的信息，或许可以试着为你分析。但以你目前提供的信息，真的不好评判</p>
<p><strong>闲坐庭前也：</strong></p>
<p>恩，<br>详细的话就是南京河西奥体那块推出了仁恒G53精装公寓<br>简称高汤，90平方复式上下两层的，180万左右<br>我对南京不太了解<br>有人说2014青奥会召开，<br>有点升值空间<br>我不准备贷款<br>因为平时也不怎么会理财<br>全付可以95折<br>楼主，请问我能买进吗？<br>汗一个先，我买房好像总买在高点呢<br>泪奔<br>不知道这次怎么样<br>楼主不吝赐教哦！！！</p>
<p><strong>kkndme：</strong></p>
<p>房产毕竟是一笔相当大的投资，对于一个不了解的城市，就轻易购买，显得过于轻率。青奥会是噱头但不是利好，对于房产的长期升值没有任何促进作用，充其量也不过有些资金参与短线炒作。<br>经济的发展才是一个城市房价上升的驱动力。<br>建议在你购买之前，认真去南京进行考察。不但要考察周边楼盘，还要考察你所购买地区的经济发展状况、交通状况、商业和学校的分布。最好能够了解当地政府的规划。</p>
</blockquote>
<h2><span id="北京华清嘉园">北京华清嘉园</span></h2><blockquote>
<p><strong>dog19972009：</strong></p>
<p>请教楼主点评华清嘉园的房子以及上地一带的房子，谢谢楼主！</p>
<p><strong>kkndme：</strong></p>
<p>学区房，房价坚挺，配套齐全，环境也还凑活，紧邻轻轨，唯一的遗憾就是交通比较拥堵。如果有钱是可以考虑的。但是绝大多数人只能对华清嘉园的高房价兴叹了。我预计两到三年内，华清嘉园就将冲击5万关口。<br>上地可参加前两页的评述。</p>
<p><strong>dog19972009：</strong></p>
<p>谢谢楼主，但如果是上地的低密度低板房格局朝向及位置都较好的小3居可以考虑吗？另外知春路一带的九十年代的塔楼还有板房可以考虑吗？</p>
<p><strong>kkndme：</strong></p>
<p>北四环周围有许多不错的小区，都值得考虑，无论自住还是投资都还是比较合适的。比如志新村、塔院、牡丹园小区等等，配套齐全，居住舒适，特别是志新村还是学区房，这一片区位肯定是好过上地的。缺点就是户型较老，物业等于没有。</p>
</blockquote>
<h2><span id="中国的朝代更替">中国的朝代更替</span></h2><p>中国与西方最大的不同，是历次革命都要推倒重来，革命总是伴随着血琳琳的屠杀和破坏，无论是财富还是文化。每次建朝人民都要从一穷二白做起，所以才说中国人民苦难深重，几千年的历史，居然没有什么积累，有的只是统治者根深蒂固的帝王思想世代传承。<br>从项羽焚烧阿房宫到近代的破四旧，革命的都非常彻底，人民洗脑也非常彻底。所以帝国时代才能够一直延续。西方人贪婪对财富是占有和继承，东方人重义轻利所以破坏焚烧和屠杀。</p>
<p>西方的大革命产生了资产阶级新贵阶层，然而当时却不为普通群众接受，尽管他们有钱有势，但是却得不到群众的尊敬，直到资产阶级新贵们捐钱捐物，为群众做了大量的善事之后，才得到人民的认可。<br>而我们这个时代产生的新贵却太多的为富不仁。</p>
<p>而中国古代的乡村，通常族长就是村子里的大地主，族长是非常重视名胜的，一个族长必须有足够的威望，象修桥补路，借无米下锅的族人粮食，都是族长份内的事。去徽州旅游的人都知道，道路、桥梁等公益设施无不是富商修建。古人不但讲个人声望，还讲积阴功。假设你去贵州的深山中旅游，发现山径上常常有个亭子，不但有坐的地方，还有水井或者用水管从山上引来的泉水供路人休息。这都是周围的村里人为积阴功修建的，绝非政府投资。<br>时值社会主义的今天，反而一切行善积德的事都不讲了，全民金钱至上。没有文化建设的民族是悲哀的。</p>
<h2><span id="中国可以无限印钞吗">中国可以无限印钞吗</span></h2><blockquote>
<p><strong>tianxiaobing11:：</strong></p>
<p>中国可以无限印钞票吗？有没有个限度呢？我是请教楼主，肉食者会怎么思考呢？他们的幕僚能从历史中找到答案吗？楼主的历史资料库中有这方面的吗？</p>
<p><strong>kkndme:：</strong></p>
<p>如果你收集过铜钱，你会发现有一种大钱叫一当十五。这就是中国古代的铸钱方式。当铜不够了，zf用铸造2枚铜钱的铜铸造一枚大钱当作十五个大钱用。那时还没有纸币，所以采取了这种方法。<br>到了解放战争时期，物品紧缺，国军大量印制金圆券，今天用一捆钱没一斤米，明天用同样一捆钱却只能买一两米。当然这种金圆券无限制满天飞也和我军大量投放伪币有关。<br>当物质紧缺时，必然会通过发行纸币来缓和矛盾。小时候我常去买2毛钱的肉馅包一顿饺子，现在2毛钱仍在大街上也没人捡。肉馅从2毛钱涨到4块钱，货币贬值了20倍。为什么我们认可肉馅从2毛钱涨到4块钱的既定事实，但是却不能想象现在的物价会在未来的10年再涨20倍呢。<br>如果你收集过邮票，会发现50年代的老有票的票面价格都是500元一张，1000元一张，我们建国后的货币也并不是一开始就是圆角分的。50年代圆是最基本的货币单位，随便买个最小的东西，都是1000元起步的，很象现在的越南盾。<br>我们国家的印钞制度，主要跟外汇挂钩，在帖子里已经做过了描述，你可以在帖子里找一找。正是由于国内商品的内需不足，完全依靠低附加值商品出口创汇，才造成了人民币的外升内贬。</p>
</blockquote>
<h2><span id="读史读的不是故事还是找历史规律以古鉴今">读史读的不是故事，还是找历史规律，以古鉴今</span></h2><p>读史读的不是故事，还是找历史规律，以古鉴今，毛就是这方面的天才。<br>读史难在古人常常作假，事件往往扑朔迷离，必须象破案一样，从重重的迷雾中寻找真相，这也是读史的乐趣所在啊。<br>好比喜欢三国的度魏延，总认为此人天生反骨。事实上，魏延作为仅次于关张马黄（没有赵云，赵云的才能和级别都不能和魏延相比）的第五员上将，在关张马黄死后，成为了西蜀的军方顶梁柱，不但有极高的军事天赋，而且忠心耿耿，不足的是政治头脑不大灵光，结果诸葛亮刚死，就被小人杨仪给黑了，不但掉了脑袋，还被按上了背主的罪名。</p>
<blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>《三国演义》里这一段完全是黑魏延来着。<br>我心里还想，其实魏延还是比较大度的，马谡刚愎自用的时候，诸葛亮很不爽，但是魏延还一个劲的替马谡说好话，我就觉得魏延一直忠心耿耿，怎么可能晚节不保呢？</p>
<p>唉，看来正史和演义，还是有很大区别啊</p>
<p><strong>kkndme：</strong></p>
<p>正史里很多信息都是极其可疑的，就更别说演义了，呵呵。<br>每次听评书赤壁大战一段，诸葛亮给关张布置任务就觉得好笑，赤壁大战时诸葛亮官拜军师中郎将，官职远不如关张，关张不可能直接听诸葛亮的将令。当时，诸葛亮顶多给刘备出出主意，调兵遣将还应该是刘备的事。演义一夸张诸葛亮，，就没刘备什么事了。</p>
</blockquote>
<h2><span id="毛太阳往事">毛太阳往事</span></h2><p>当年毛太阳发动文ge的原因是因为政府被刘奇和邓平的政经系所把持</p>
<p>当年要是老毛召开人大来决定谁去谁留，老毛肯定被PK掉</p>
<p>如此不发动底层，通过正常的程序夺不回权利</p>
<p>什么防止腐败，打到走资派都是借口</p>
<p>毛太阳比任何人都要腐败</p>
<p>死的时候存款有1亿多（不是工资积攒的，都是稿费，垄断市场的稿费）</p>
<p>70几年的时候，1亿多，确实恐怖</p>
<p>但是后来被邓平给没收了，讽刺呀，以这是全党的财富为由</p>
<h2><span id="北京大兴">北京大兴</span></h2><blockquote>
<p><strong>VVVMMMABC：</strong></p>
<p>楼主,现在大兴的房子新楼盘较多,某楼盘推出两次均卖光光.地理位置占尽优势,因为紧挨着将要建好的地铁.现在能出手买吗?首套,没有立马买房结婚的压力,但三四年内总得买吧.首付提高后也就刚刚好付首付.要是利率也真的不打折,真不知道如何是好.</p>
<p><strong>kkndme：</strong></p>
<p>通州、房山、大兴都是前期炒作比较厉害的区域，在楼市调控期要慎重购买，如果遇到明显低于周边二手房的楼盘可以立即下手购买，否则观望。</p>
<p><strong>VVVMMMABC：</strong></p>
<p>楼主圣明,楼主说得明显低于周边二手房的话是指大于多少一平的时候呢?现在的二手房和新房都互相盯着呢,都差不多</p>
<p><strong>kkndme：</strong></p>
<p>一般来说调控期内，郊区新盘比调控前的周边二手房大约低10-20%%之间，且成交放量，说明底部已见。</p>
</blockquote>
<h2><span id="贵阳">贵阳</span></h2><blockquote>
<p><strong>努力看透：</strong></p>
<p>楼主，谢谢你对贵州的关注！<br>我是贵阳的，想听听你对贵阳的看法，我07年在小河区2400买了120平方的新房子，今年八月初买了套市里的二手房，93年的，65平方，学区房，总价43万，送家具家电！<br>非常想听听你对贵阳房市的看法，还有金阳新区的看法，感觉金阳就是房地产撑起的，如果地产有个风吹草动，金阳会是最容易受打击的，不知对否？<br>另外93年的老房子以后卖时不好贷款，是不是会影响成交价格？<br>谢谢</p>
<p><strong>kkndme：</strong></p>
<p>刚从贵阳回来没多久，呵呵。<br>贵阳投资房产有一定的风险，主要是城市比较小，不好变现。如果我在贵阳投资，即使再贵也会选择喷水池附近市中心的楼盘，稀缺性较强，变现相对容易。<br>贵阳是一个城区尚未开始升级改造的城市，zf大力打造金阳花溪等外围区域，但是将来一定会遇到较大的交通瓶颈，城区的升级改造早晚都要启动。<br>关于金阳实际上就是政府的造城运动，因为市政府的搬迁对房价有一定的支撑力，但是随着人口的大量入住，从金阳到主城的交通可能出现瘫痪状态，谁又能保证政府不进行二次搬迁呢？<br>贵阳的美女确实很多啊，是这个城市最靓丽的风景，令人留恋。</p>
<p><strong>努力看透：</strong><br>贵阳小了，为什么房子不容易变现呢？毕竟全省只有贵阳繁华点，地方小，人多，更应该容易变现啊！我指的是市区房，不含郊区</p>
<p><strong>kkndme：</strong></p>
<p>市中心中高档房屋变现是没问题的，但市中心老房变现也不是很容易。贵阳的城中心改造升级还没有启动，市区存在大量的老公房，而贵阳最需要的是改善型中高端住房。现在zf全力打造金阳等外延区域，大片的新楼盘拔地而起，二手房交易的活跃度远不如其他省会城市。</p>
<p>贵阳与成都、昆明这些西部城市略有区别，昆明、成都有大量的外地人口，这些外地人口构成了买房刚需，因此市区位置的稀缺性就显得尤为重要。<br>但是贵阳的外地人口相较昆明、成都要少，以本地改善型需求为主，所以城区楼盘的档次尤为重要。<br>作为相邻的省会城市，重庆的吸引力要大于贵阳，贵州许多地州的资金可能会被重庆分流。</p>
</blockquote>
<h2><span id="富人越富-穷人越穷">富人越富、穷人越穷</span></h2><blockquote>
<p><strong>我爱的飞飞：</strong></p>
<p>其实很多空军比较SB，天天叫着加息，说是提高收入就可以买得起房子，试问穷人手里10万，富人有100万，按照现在的利息，穷人每年整存整取10万不开税收是2250元，而富人得到的是22500，加息以后假设穷人每年收入是4000，富人是40000万，成千上万的富人每年多出40000，而生产资料和资源是有限的，当每个富人的4万流入市场，试问是不是又要通膨呢？所以加息是最愚蠢的均贫富方法。行之有效的办法其实是重新发行货币。但是除了改朝换代几乎不可能。<br>其实穷人一穷就注定穷下去，除了少数几个可以翻身，原因很简单，因为生产资料掌握在富人手中，富人为什么有生产资料的支配和拥有权，答案很简单，只有革ming。<br>由此则可以明白为什么房子可以按照富人的想法定价，就因为土地，建材等生产资料掌握在富人手中。<br>妄想房子降价其实是更愚蠢的想法，为什么？GCD拼命给公务员和arm加薪，这些钱用印刷机印出来发到公务员手里最终却让老百姓埋单？统治阶层当然首先第一位维护和最大化自己的利益，任何朝代都是如此，只有当民心涣散的时候才出台一些政策缓和民心。现在看CCAV，对社会主义这充满美好想象的词的强调都逐渐弱化了，你不得不承认，在GCD的领导下大家都有肉吃了，国家安定，在这里嚷嚷的，不过是对贫富不均不满而已。</p>
<p><strong>kkndme：</strong></p>
<p>今年朝鲜搞货币改革，重新发行货币，结果导致不可控的通货膨胀，财政部长给枪毙了。</p>
<p><strong>我爱的飞飞：</strong></p>
<p>所以民众还是愚蠢的，只看到了15元最后换成1元的落差和失落，没有看到除去附加值的生产资料的价值。货币改革是富人最不愿意看到的，跟加息是一个道理，因为改革让货币的附加值骤然缩水，富人的货币不再比穷人有更多的附加值，而统治阶级恰恰是富人，没人愿意搬石头砸自己的脚。所以为什么我说不可能。</p>
</blockquote>
<h2><span id="通货膨胀的形成原因">通货膨胀的形成原因</span></h2><blockquote>
<p><strong>我爱的飞飞：</strong></p>
<p>在谈谈通膨是怎么形成的。生产资料是有限的，生产资料其实一直都没有变，而货币只是一种虚拟附加值而已。像楼主所言，一个国家，有人手里有8元（假设他是建材行业的），有人有12元（假设是石油行业的），但是人心不足蛇吞象，建材行业的员工觉得不够用了，8元的想变成13元，石油行业的12元想变成20元。因此，建材行业把原来卖8元的水龙头提价成13元，对于石油行业的人，装修的时候拿着12元发现自己买不了13元的龙头了，于是琢磨着把石油卖到20元，由此各行业依次提价，物价越来越高，实际上水龙头还是水龙头，一桶石油还是一桶石油，生产资料始终没有变，稀少，远远不够人均分配，但是生产资料的价值变了，提高了。拿成都的房价为例，02年的时候成都人均收入800-1200，房价2000-4000，约为房价的3倍，现在成都人均收入2500-3000，成都房价7500左右，仍然为3倍比例，看似7500比2000翻了多翻，实际上房子作为所谓的生产资料，始终是稀缺的，在02年的时候，拿着当时的工资买4000的房子仍然不容易。任何时候，其实都是一种相对平衡的比例，而空军喜欢拿现在的工资跟过去的房价相比，但是那种状态太过理想，想明白的，就会觉得房子不贵。</p>
<p>什么时候房价会下降，一句话供求关系，人口减少是房价下降的唯一出路。即便是出台房产税，很有可能富人顶着房产税不卖，变相加租抵消房产税，特别当今租房市场存在中介的操纵，很多房子都是通过中介渠道才租出，垄断的中介忽悠房东集体涨价，房产税很容易就转嫁给租房者。ZF也不是完全不作为，当你开着车逛着公园坐着快铁地铁的时候，就应该加速印刷的钞票有一部分投入了基础设施建设，如果不通过税收和出让土地收入来建设，我们很可能还走在乡间小路上。</p>
<p>虽然瓷器国是中yang高度集权的国家，但是任何朝代都是诸侯之间相互制约，上面出台个政策，各个诸侯执行与否或者执行是否到位都可以影响房价甚至很大影响，且不谈上面是不是真的想降房价，即便是动真格，下面的诸侯听不听招呼是另外一回事。有心无力的事情不是不可能发生。共同富裕其实是一种美好愿望，因为人与人的竞争天性，不可能人人平等，只要有人还想凌驾于其他人之上，就永远不可能GC主义。</p>
<p>任何社会都是这样的形态，忍无可忍-geming-平稳-不满足-垄断与剥削-改革-改革失败-再次忍无可忍。为何历史反反复复如此？就是因为人的劣根性，因为人性的贪婪。所以周而复始而已。</p>
<p>人性的贪婪决定了社会进程，刚开始穷人只想平均，从富人手中夺取生产资料，当GEming之后，穷人开始不满足于仅仅是平均，穷人想要凌驾于其他人之上，想变成富人，于是利用geming占有的各种手段获取利益，最终变成了富人，被凌驾的穷人再次想通过变革改变自己的地位。。。。如此循环。。。</p>
</blockquote>
<h2><span id="深圳-amp-昆明仇书记-amp-通货膨胀体制内高枕无忧-体制外自求多福">深圳 &amp; 昆明仇书记 &amp; 通货膨胀体制内高枕无忧、体制外自求多福</span></h2><blockquote>
<p><strong>sprina0321：</strong></p>
<p>楼主真是高人啊，追了两天，终于看完了。也想向楼主请教下房事</p>
<p>不知楼主对深圳了解吗，我们来深圳七年了，结婚也好几年了，可是最近才去布吉买了首套，布吉的可园，二手，单价一万四。现在深圳关内10年的二手都一万六，好一点的两万，关内基本没新房了，有的都3万左右了。大量的新房都在关外，基本2万吧。我们本来也想买关内，可是想着同样的价格在关外可以买好点的，就买了关外，不知这个决定是否正确？按楼主的意思，还是要买市中心，可是市中心的话，只能牺牲面积，房子也旧，这样住着也不舒服啊。</p>
<p>另外，我父母就在昆明，他们本来在一环上有套房改房，挺方便的，就像楼主说的，可恨的仇书记要制造需求，现在他们的房子说是要拆了，他们现在想买，可是一环外的都8000多，他们觉得有点贵，买了以后，手上的钱就都用完了，又想干脆等回迁。楼主觉得要不要买呢？<br>我父母就我一个孩子，他们在深圳买过一套房子，就是市中心的塔楼，等我们不住了，这套房子要不要卖掉，还是留着出租好？</p>
<p><strong>kkndme：</strong></p>
<p>深圳不太了解，不过宁肯牺牲点品质也要选择市中心，这是无数人经过从市中心搬到郊区大户型再搬回市中心老房子而取得的宝贵经验，当然如果你在关外上班就另当别论了。<br>往历史人物上套，qh应该算作集酷吏与奸佞于一身，横施暴（）政早晚落到身败名裂的下场，不是不报时候未到。等拆迁主要是在昆明风险比较大，几年不知道能建起来，志远综合体就是很好的例子，如果有能力不妨先买一套。</p>
<p>至于说房子卖不卖关键你是否需要用钱，如果不需要，又没有更好的投资，不妨先留着。</p>
<p><strong>sprina0321：</strong></p>
<p>我有时候想，像QH这样的人应该不得好死，断子绝孙，老天还真是不长眼。</p>
<p>请楼主明示 志远综合体是怎么回事</p>
<p>我父母家就在东站，董家湾中间那里，原来厂里也在，现在厂子搬到开发区了，家里的房子也逃脱不了被拆迁的命运了。<br>现在家里在一环出去点看中一个房子，房子挺不错的，大社区，新房，算下来9000多，不便宜啊。一环内的估计我们买不起，家里人年纪大了，想住电梯房。</p>
<p>楼主对昆明现在的房价怎么看呢，会不会回调，感觉今年涨很多。<br>现在9000，难道以后涨到2万，和深圳现在价格一样？我和老公也工作很多年了，现在年收入30多万，我们都买不起2万的，我们去看过万科在深圳的新盘，房子没得说，带精装修，2万多一平，一套要300万，虽然很心动，也只能放弃，怎么现在昆明人这么有钱了？<br>按照通货膨胀来说，如果以后昆明的房子卖2万，那深圳的岂不是要卖4万，那我们的收入也会涨到60多万吗？哈哈，实在算不过来了。通货膨胀对我们的收入有影响吗</p>
<p><strong>kkndme：</strong></p>
<p>一环外9000多的新盘，昆明还真没几个，滨江俊圆9000多，但容积率太高，又有大量的回迁户，个人很不看好。翡翠湾达到了12000，云上城、翠园等要开的楼盘估计开盘价也要上万了。呵呵<br>昆明的房价，我预计市中心将达到2万，一环二环间15000，滇池板块将达到12000，北市区及世博板块将达到1万。东市和西市在8000-9000。螺丝湾板块最不确定，但未来不会低于9000。<br>志远综合体早在几年前完成了莲花池片区的拆迁，但迟迟不动工盖房，时隔几年一点动静都没有，拆迁户没有买房的现在还在租房住。</p>
<p>关于通货膨胀问题，体制内的职工工资一定会与时俱进的。体制外人员的薪水不取决于通货膨胀，而是取决于行业的利润率，企业的利润和个人的能力运气。对于多数竞争激烈，产能过剩行业内的民营企业一般员工，工资增长是很难抵御通胀的，而且由于通胀导致生产成本的价格上涨，减薪甚至裁员的可能反而更大。</p>
</blockquote>
<h2><span id="长春">长春</span></h2><blockquote>
<p><strong>wkzjx2008：</strong></p>
<p>楼主你好，请帮我分析一下，谢谢</p>
<p>我在长春</p>
<p>长春的市政府在前几年的时候搬到了城市的南部，南部因为是空地，所以盖的都是新盘，价钱现在7000多，而我工作的所在的位置是原来的一个商业区，这里原来都是学校，医院和一些机关单位，好企业的家属楼，因为原来的购买力强所以居民楼的一楼都变成了小店铺，所以形成了这个城市的一个没有大商场的一片繁华商业区，但现在随着原住民的逐渐迁走，这里租房的人多。但这里有一个优势是离市里最好的小学和高中都很近，这也是这里房价坚挺的原因。现在这里的二手房如果是大户型在5000左右每平米，小户型6000左右，基本都是八九十年代的房子，2000年以后的次新房很少，距离这个区域较近的一个新盘是商住两用的卖到9000多每平</p>
<p>孩子现在在这上幼儿园，堵车太厉害了，为了孩子我在这租的房子<br>我现在手里有20万现金，请问这片区域值得购买么，买大的还是小的，我已经贷过一次公积金贷款，现在已经结清</p>
<p>现在这个城市很远的地方新开的楼盘也要4000多一平米</p>
<p>请楼主赐教，不胜感激</p>
<p><strong>kkndme：</strong></p>
<p>政府所在地区域又是学区房，这样的房子优势还是很大的，但是由于有大体量的老房子存在，将来有可能大规模拆迁，而拆迁补偿却决于zf是否铁腕，如果遇到铁腕领导，补偿额一定不会太高。这是购房的风险。对于非一线城市，新盘的风险肯定小于老房。</p>
</blockquote>
<h2><span id="佛山">佛山</span></h2><blockquote>
<p><strong>爱佛僧傲瞪詹牧师：</strong><br>lz高人！<br>不知道来过佛山没有？佛山紧邻广州，两地的地铁即将贯通接轨，房价应该会快速飙升，但是另一方面，佛山是个制造业城市，村镇工业高度发达，外来打工的比较多，流动性很大，lz所说的，今后买房只是有钱人游戏，房租会高涨，这点对佛山这样的小城市不知道成不成立？村镇里还是有很多便宜的出租屋的，高端点的打工者，如果房租太贵，应该会嫌贵干脆回家发展，最后只能留下低端制造业产业工人吧？这样房租应该还是很难上涨。</p>
<p><strong>kkndme：</strong></p>
<p>佛山还真没去过，只去过东莞和中山，呵呵。<br>对于广州一带房价相对偏低的原因是广州并非全省唯一的大型繁华城市，而是广东省内形成了大片的都市群，使得城市的经济得到了均衡的发展。这是最健康的城市发展模式，但也制约了房价的上升空间。随着地铁的贯通接轨，佛山的房价将呈稳步上涨态势。</p>
</blockquote>
<h2><span id="首付提高的逻辑">首付提高的逻辑</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>请教楼主，最近有银行提高了首付，这是为什么？政府真要让中低层租房子吗？政府吃租赁的大蛋糕吗？</p>
<p><strong>kkndme：</strong></p>
<p>主要还是防范金融风险，政府调控的目的从来也不可能是解决穷人的买房问题。恰恰相反，金融风险来自于让穷人买房，所以提高首套房首付比例，杜绝穷人买房，才是防范金融风险的有效手段。同时可以推升租金上涨，政府推出的公租房才有市场，有钱可赚。</p>
</blockquote>
<h2><span id="四线城市">四线城市</span></h2><blockquote>
<p><strong>shs2009：</strong></p>
<p>楼主，我们这个城市离武汉60公里，四线城市吧。我打算在新开发的工业园区买一套房子，买的理由是认为工业区是人员比较集中的地方，应该有比较大的需求，无论租售都应该有潜力的。我的看法对吗？</p>
<p><strong>kkndme：</strong></p>
<p>四线城市一定要选择城中心或者高档住宅区买房</p>
</blockquote>
<h2><span id="苏州工业园">苏州工业园</span></h2><blockquote>
<p><strong>夏天来了我也来：</strong></p>
<p>我是昨天才看到LZ这个帖子的，一口气读完了，眼睛虽然有些累，但心里却是收获颇丰，今年四月ZY刚开始严厉调控的时候，我可是抱了一百分的信任，心想我们老百姓的好日子终于来了，终于可以用较低的价格买套属于自己的房子了，可现在都九月了，看着周围一直慢慢望上爬的房价，真的是失望极了！<br>我九月三号的时候刚定了一套二手房，是我们的第一套房子，不知道LZ是否了解苏州工业园区的发展前景和房价，我们这套房子在园区的中心位置，也相当于市区吧，位置还不错，可就是这个房子属于政府修高速路时的拆迁安置房，房龄有十年了，原来房东的两证上写的土地性质是“出让”，不知道这样的房子以后是否有升值空间？因为在苏州园区同样的地段，同样旧的拆迁房价格基本都快一万了（我们定的这个房子因为离马路有些近，而且在顶楼，户型是小户带阁楼，上下两层复式结构的那种，所以便宜一些，只有八、九千），附近的高档商品房价格也要一万五左右！苏州和上海离的这么近，如你所说，江苏的有钱人都跑到上海买房了，苏州的房价是不是很难涨呢，同时也担心以后房价再继续上涨，ZY会出重拳打击楼市，真到那个时候，房价是不是要暴跌呢？</p>
<p><strong>kkndme：</strong></p>
<p>土地性质“出让”没有问题，“划拨”才有问题。<br>zf初重拳打击的结果往往取得相反的效果，因为政府如果希望继续执政是绝不可能让房地产崩盘的，房地产的崩盘将同时埋葬现有体制，社会“和谐”将不复存在。如何让房地产持续稳定与gdP同步上涨是政府最大的难题，完全取决于领导的智慧，但是以现在的水平来看，是很难做到的。<br>苏州工业园区房地产不是很了解，但是一个工厂及仓储所在地，缺乏高科技与文化历史底蕴的支持，房价一定会涨，但涨幅一定有限。</p>
</blockquote>
<h2><span id="住房公积金利率">住房公积金利率</span></h2><blockquote>
<p><strong>facetowall：</strong></p>
<p>另一个问题啊，我准备用住房公积金购买首套房，在其它的一些帖子上看到政府将在某个时间点上加息，那么对住房公积金的贷款利息（3.87%）会不会同样上调呢？上调幅度会是多少？对这个比较关心，麻烦楼主给解答一下吧。谢谢了！</p>
<p><strong>kkndme：</strong></p>
<p>如果当年加息，再次年的元旦后贷款利率也会相应增加，但公积金贷款利率增加的幅度很小，不用担心。加息说明通货膨胀严重，如果不是连续过度加息，对房价没有影响。从长期看更是不可能影响房价上涨趋势，除非经济崩溃。如果经济崩溃，持有纸币也没有意义，等同于废纸。<br>90年代我国高度通货膨胀，银行存款年利率曾达到百分之十几，但并没有影响房价的上涨趋势。</p>
</blockquote>
<h2><span id="济南-amp-大规律拆迁的城市房价不会下降">济南 &amp; 大规律拆迁的城市房价不会下降</span></h2><blockquote>
<p><strong>facetowall：</strong></p>
<p>不知道楼主对济南的房市了解如何？去年接着全运会的东风，济南房价涨了35%到40%，让许多人措手不及。现在市区的新开盘的楼盘依据位置不同大约在8000到13000rmb每平方。济南奥体中心附近的房子在9000到13000rmb每平方吧。我和老婆都在济南高校工作，目前俩人月收入6000+，公积金1100多吧。相比于其它省市地区高校，无论工资还是公积金</p>
<p>都比较少。我感觉高校老师属于体制内的边缘群体，工作忙(很多人不认同这点)报酬少，并且目前已经没有什么福利分房了，都要到市场上购买商品房。我们的家庭情况是这样的：均为独生子女，目前有一个孩子，二岁了，双方父母均是事业单位退休人员，我父母退休金合计1万每月吧，她父母大约7000.由于我父母在济南有两套房改房，所以现在他们住一套，我们三口住一套，房产证上都是我父母的名字，所以我和老婆属于无房户。目前想买一套房子给岳父母住，毕竟我们俩是独生子女，将来接到济南来住是早晚的事。感觉济南的房价几乎没有下降的可能，因为全济南正处于最火热的拆迁阶段，山东省已经把济南的改造升级列为战略了，并且全国的知名地产商如绿地、中海、保利、绿城、万达(好像万科没有)都来拿地盖房并且已经推向市场了。目前看中了奥体中心附近的一套2005年的二手房，房子很新，毛坯房，环境物业都不错，大约120平米，单价得9100，总价110万。我们想拿出70万现金，再以公积金贷款50万(10万装修)/20年，不知道这样有没有风险。一个是担心房价下跌，再一个加息。请楼主给出明示，指导一下，万分感谢。</p>
<p><strong>kkndme：</strong></p>
<p>大规模拆迁的城市，房价没有下降的可能，可以忽略政策因素。既然城市大规模拆迁，就晚买不如早买，这是本贴中一再提到的。</p>
<p><strong>facetowall：</strong></p>
<p>多谢楼主的解惑。感觉济南不像北京上海那样具有巨大的政经优势吸引全国的阔商巨贾和精英汇集，也不像昆明、杭州那样为渡假天堂，还不像西安、南京、武汉那样高校云集具有巨大的教育资源。也就是说济南不能吸引相当多的精英投资，始终是个不温不火的地方，所以济南的房价有点虚，再上涨的话就脱离了实际的承受能力。楼主对此有何看法？</p>
<p><strong>kkndme：</strong></p>
<p>济南的地理区位并不差，但城市搞的不好跟领导有关，济南的经济前景不错，而且房价的上涨是拆迁带动的，以后很多城市都会走这一步。</p>
</blockquote>
<h2><span id="公务员小区牛逼">公务员小区牛逼</span></h2><blockquote>
<p><strong>何金银银金何：</strong></p>
<p>不知楼主是否了解哈尔滨的房价？小弟有套小房子 想换大点的，现在可是时机？哎 早拜读你这文章 今年年六月份就能换套大的了，可惜现在搞得自己换不起了……杯具&amp;</p>
<p>哈尔滨的公务员小区是没有产权的，不知道这种房子买了做第二套之后要不要征税？而且也非常贵，按使用面积要1w多一平了</p>
<p>小弟小白，您有空给指点指点……</p>
<p><strong>kkndme：</strong></p>
<p>公务员小区比房产证和土地证还保险。我国不是一个法制国家，任何颁发的纸质文件的可信度都不高，反而公务员小区因为是特权房，信用度要远高于产权证。</p>
</blockquote>
<h2><span id="房屋朝向只要不是纯北西就行-amp-买房首选市中心-公园地产">房屋朝向只要不是纯北西就行 &amp; 买房首选市中心、公园地产</span></h2><blockquote>
<p><strong>pohangcity：</strong></p>
<p>楼主。兄弟在一北方省会城市太原，目前这里的商品房平均价为5000左右，上周看了市中心的一套房子，112平米，紧挨市区里的公园（有一大湖），周边就是万达广场，万达的房子均价8500，已经售完，这个房子售价7000，已经是现房，结构还可以，唯一的问题是不是正房，朝向向东，周边一片混乱，全是施工的、拆迁的，说以后要以万达广场为中心，打造太原的CBD，也不知道能不能实现。<br>房子总价74万，首付24万，按揭月供3400，现家庭年收入税后10万，不可以公积金贷款，我已有一套住房，不过感觉还款压力很大。<br>我的问题是：<br>1、楼主帮我房子一下这个房子值不值？我想以后自己居住，现在的房子可出租1500左右。<br>2、太原也有万达、恒大的楼盘，位置是在太偏，价格6000带精装，户型也好，如何取舍？<br>非常谢谢楼主<del>~</del>~</p>
<p><strong>kkndme：</strong></p>
<p>房屋朝向问题，随着城市房价的不断飙升，已经不那么讲究了。只要是不是纯北房或者纯西方，都可以接受。<br>建议首选还是城中心，特别是公园地产，未来将更稀缺。</p>
</blockquote>
<h2><span id="zf搬迁">zf搬迁</span></h2><blockquote>
<p><strong>xhyyhzy：</strong></p>
<p>楼主您好，从您的帖中收获很多。觉得以前真的被洗脑洗的很厉害，从天涯学到很多。非常感谢您，又让我明白了很多事情。</p>
<p>请教您，市政府从原来的市中心，搬迁到另外一个地方，相对较远，因为城市不大。好的医院，学校，各种好的资源都在市中心。现在搬到一个特别偏远，荒凉的地方，重新开始建设，政府这么做是什么意思阿？以后这些医院，学校也会搬吗？多浪费阿。另，您怎么看该城市未来房价的变化。（注，离上海很近的3线城市）</p>
<p>期待您的分析。</p>
<p><strong>kkndme：</strong></p>
<p>政府搬迁到郊区不仅仅是个别城市问题，而是大多数二三线城市面临的问题。政府的用意在于扩大城市规模，扩充人口，追求gDP的高速增长，但对于新开发出一块荒郊野地，没有政府的带头搬迁，是很难炒作起来的。政府的迁入是一个信号，告诉老百姓，政府都搬过去了，以后配套肯定不会有问题。于是概念将透支未来，房地产价格就会飙涨。但是未来建成后政府是否真的搬迁就不一定了。<br>医院和学校全部搬迁会加深社会矛盾，所以通常是在新规划的区域建分校。如果自住还是主城，如果投资投机，可以考虑新城。</p>
</blockquote>
<h2><span id="俄罗斯">俄罗斯</span></h2><p>有同志提起俄罗斯很可以再说一说的。</p>
<p>俄罗斯的前身叫罗斯公国。首都不在莫斯科，而在基辅。</p>
<p>建立罗斯公国的，是东斯拉夫人，日耳曼人眼中的劣等民族。有人说过，俄罗斯和西方国家的差别，并不仅仅是经济上的差别，而是民族和文化的差别。这种说法还是很有道理的。用我们现在的话来说，斯拉夫的人种有问题。善于侵略，欺软怕硬，野蛮无礼。这是斯拉夫人的特点。所以在罗斯的土壤，永远出不了骑士精神。</p>
<p>罗斯人信奉基督教，源于弗拉基米尔一世娶了东罗马帝国安娜公主为妻。所以我们看到的俄罗斯教堂全部是拜占庭式的。拜占庭帝国灭亡后，东正教的中心就搬到俄罗斯。</p>
<p>罗斯国并不是统一的帝国，而是象我们的西周，搞的是封建分封制（我国在秦以后就不是封建社会了，因为取消了封建分封制，丞相都是打工仔，这一点是与我们的课本不同的），到了十二世纪，礼崩乐坏，罗斯国分裂了，罗斯的周天子弗拉基米尔二世·莫诺马赫的统一大业未能完成，故罗斯的土地上居然出现了十八个公国，很有点象我们的十八路诸侯。</p>
<p>十三世纪，成吉思汗的孙子，术赤的儿子，英勇的拔都同志西征，一个强大的统一的蒙古帝国攻击分裂的罗斯诸公国，很有点欺负人的味道。于是强大野蛮的东斯拉夫人在金帐汗国的铁蹄下，当了孙子。<br>莫斯科公国的伊凡一世·达尼洛维奇以贿赂的方式从金帐汗那里获取了弗拉基米尔大公的封号，并把东正教罗斯教区总主教驻地从弗拉基米尔迁到莫斯科。</p>
<p>莫斯科大公是很有一手的，一面拍金帐汗的马屁，一面组织军队，终于利用金帐汗国的内部分裂，一举击败了马迈汗率领的大帐汗国军队，并且兼并了科斯特罗马公国、加里奇公国、白湖公国、乌格里奇公国、下诺夫哥罗德公国、木罗姆公国和苏霍纳河流域北部等广大东北罗斯地区。</p>
<p>14世纪，莫斯科大公依凡三世在乌格拉河战役中，迫使阿合马特汗撤退，终于结束了金帐汗国长达两个多世纪的统治。</p>
<p>直到1713年，莫斯科公国干掉了罗斯地区的绝大多数王公，才形成了统一的集权国家，正式命名为俄罗斯帝国。</p>
<p>罗斯公国打得最精彩的战役就是楚德湖战役。<br>对手是称霸普鲁士的赫赫有名的三大骑士团之一，条顿骑士团，欧洲强大到令人恐怖的军事组织。<br>罗斯的最高指挥官是亚历山大诺夫格罗德公爵。<br>俄罗斯联军一方有1.5万到1.7万，主要是步兵。而条顿骑士团的大约有1万人，以重骑兵为主，其中大骑士应该不下千人，这是一支让整个欧洲都发抖的军队。<br>罗斯联军的步兵排成密集队形，据守冰湖东岸。骑士团的重骑兵以楔形阵发起冲锋。按常理看这是一场毫无悬念的战斗，罗斯步兵在强大的世界第一军事组织面前应该不堪一击。<br>但是亚历山大诺夫格罗德公爵是军事天才，军事才能相当于中国的乐毅。这位乐毅公爵仔细研究了重骑兵的楔形阵，认为弱点在于两翼的防御力量有限，如果重骑不能迅速撕开步兵防线，重骑的两翼会慢慢被侵蚀。<br>亚历山大同志于是把联军中主要的轻步兵安排在中间，列成加厚的方阵，消磨条顿重骑的突击能力，然后把他自己的诺夫格罗德精锐步兵放在两翼。<br>条顿骑士团的攻击开始还是成功的，但无法撕开罗斯步兵的军阵。最惨的还是条顿骑士狂妄自大，非要在楚德湖的冰面上发起冲锋（冬天结了冰），可想而知重骑兵跑到冰面上冲锋是什么样的效果，战争逐渐陷入僵持。<br>亚历山大的精锐步兵攻击骑士团的两翼，骑士团被包围了。亚历山大同志果断的派出最精锐的骑士亲兵卫队，从右翼后方包抄攻击骑士团。<br>可怜的条顿骑士，拥有世界上最强悍的战力，但在湖面上根本发挥不出来，大量的重装甲骑士掉进冰窟窿里，条顿骑士大团长也被俘虏了。<br>每次看这段历史，都为条顿骑士团唏嘘不已。</p>
<p>条顿骑士团败的最惨的是另一场战役，塔能堡。是中世纪欧洲最大规模的战争。<br>对手是波兰、立陶宛联军。<br>著名的波兰小说“十字军骑士”就是讲的这段历史。<br>骑士团的大团长是荣金根，大概有投入1万多名士兵。<br>波兰、立陶宛联军大约有3万名士兵。<br>联军方面指挥官是波兰国王Jagiello和立陶宛大侯爵Witold。<br>条顿骑士大团长荣金根是一个位标准的日耳曼大骑士，开战前，骑居然给波兰国王Jagiello送去两把剑，表示要进行一场骑士之间的较量。斯拉夫人是不敢这么玩命的，立刻拒绝了日耳曼骑士的要求。<br>条顿骑士团的骑士拥有强大的武力，真不是盖的，荣团长挥动旗枪组织冲锋，立陶宛军立刻溃败，波兰的翼骑兵也根本无法抵挡日耳曼骑士强大的冲击力，准备开始溃逃。这时一个意外发生了，大团长兼倒霉蛋荣金根同志在奋勇冲锋时突然遭了冷箭挂掉了，骑士团缺了指挥官陷入混乱，无法阻止有效的进攻，波兰立陶宛联军乘机组织起冲锋，条顿骑士团莫名其妙的大败。<br>真是谋事在人，成事在天。强大的条顿骑士的惨遭溃败居然因为一个意外。</p>
<h2><span id="珠海-amp-唯一自住房不只是投资-amp-调控是最佳的选房时机">珠海 &amp; 唯一自住房不只是投资 &amp; 调控是最佳的选房时机</span></h2><blockquote>
<p><strong>期待艳阳天：</strong></p>
<p>楼主，想就以下问题请教：<br>1、珠海属几线城市？您对投资珠海的房产前景作何分析？<br>2、我一朋友刚出手一套自住的房，打算租房住一段时间，想抄底再入，他是坚信房价会跌派，考虑到目前他供房确实有困难，且对刚出手的那套房不是很满意，请问他的做法是值得借鉴？<br>3、我目前的对自住的房朝向及大小不太满意，也想倒手后再入，我目前的房出手的话比同地段的新房价略低10-30%（主要是小区及户型有差异），如果换大、好的承受不了借贷压力，但如果淘二手房的话，可以在附件找比我目前房价低20%左右的二手房，请问我是否可以考虑换个朝向、大小更满意的房？现在是好时机吗？</p>
<p><strong>kkndme：</strong></p>
<p>以上，请楼主不吝赐教！</p>
<p>珠海是个适合居住的城市，干净整洁，生活节奏不快，相当安逸。<br>将自己唯一一套自住房卖掉，跌了买回，这样做的投机性心理太强，风险很大，往往得不偿失。当然如果为了换更大更好的住房就令当别论了。</p>
<p>人的一生很短暂，在衣食住行中，住占了人生的大部分时间，有一个温暖的家，生活才觉得安逸。如果有能力确实应该换一套自己满意的舒适的住房。至于出手时机，我觉得房产不是股市，不能总想着抄底逃顶，只要房价的长期上涨趋势未变，调控时期正是选房的最佳时机。</p>
</blockquote>
<h2><span id="经济崩溃最后接盘的是老百姓">经济崩溃，最后接盘的是老百姓</span></h2><blockquote>
<p><strong>vipboy223：</strong></p>
<p>看了LZ的帖子，受益非浅！谢谢！<br>有一个问题还请教下：就像LZ所说，此次调控是ZY布局，赶出炒房者和小的kfs，目的是实现房子的垄断。但从政策和执行看，停止3套房贷并没有真正打击到真的炒房者，至多是改变了预期；二套房首付比例和利率的提高，确实实实在在的把改善性需求排除在外了；现在有些银行对首套房的首付都提高到4成，利率优惠也没有7折优惠了。当然我很愿意相信这次ZF在保护LBX，阻止老百姓去接房产暴利的最后一棒；显然这不是真正的原因。当然，首付和利率提高可以让银行增强金融防范能力。<br>随意想请教LZ对这个问题的看法；</p>
<p><strong>kkndme：</strong></p>
<p>政府阻止老百姓去接最后一棒？晕，如果真的到了崩盘的一天，接最后一棒的一定是老百姓，而且zf会千方百计的让老百姓接最后一棒。<br>分析问题不能用喜羊羊的头脑。</p>
<p><strong>vipboy223：</strong></p>
<p>显然LZ没有仔细看我写的内容。<br>换种方式问下：改善性需求是否现在就入市？首付高就不说了，利率1.1倍可是很厉害的；</p>
<p><strong>kkndme：</strong></p>
<p>如果是忙于拆迁的二三线城市就要抓紧买了，利率高也认了。<br>如果是一线城市不妨再看一下，但是观望也是有风险的，一旦上涨就买不到合适的房子了。</p>
</blockquote>
<h2><span id="命运之矛">命运之矛</span></h2><p>荣金根团长的挂掉会不会跟命运之矛有关呢。</p>
<p>1189年，神圣罗马帝国皇帝红胡子腓特烈一世在与教皇和解后，与狮心王理查一世、腓力二世·奥古斯都开始了第三次十字军东征。然而，红胡子腓特烈一世在小亚细亚渡过萨列法河时竟然意外溺死。原因是他突然丢失了传说中的命运之矛。</p>
<p>命运之矛也叫郎基努斯之枪。</p>
<p>正是一个叫郎基努斯的罗马士兵用这杆抢刺入了十字架上耶稣的身体，这只枪因沾有圣血成为圣物。</p>
<p>传说持有命运之矛的人可以主宰世界的命运，但失去的人会即时毙命，神圣罗马帝国的皇帝红胡子腓特烈一世就拥有这只命运之矛。</p>
<p>二战时期，希特勒从维也纳博物馆夺取了命运之矛，差不多占领了整个欧洲。但是在1945年4月30日下午2点10分，命运之矛又被美军夺走了，不到2小时，希特勒便吞枪自杀而亡，死时是下午3点30分，这难道仅仅是巧合？</p>
<p>荣金根是否也拥有过这只命运之矛？</p>
<p>我以为我们每个人都有一把属于自己的命运之矛，当你得到它的时候，你的事业、家庭、健康、财富都相当不错，但是当你失去它的时候，你的生命也将完结。</p>
<p>每个人对生命之矛都有自己的理解，希望我们都能够找到它。</p>
<h2><span id="除非外族入侵或全国大饥荒否则双轨制决定了房价不会崩盘">除非外族入侵或全国大饥荒，否则双轨制决定了房价不会崩盘</span></h2><blockquote>
<p><strong>戈者：</strong></p>
<p>不要枪，不要炮，我只要选票，有了票，谁不让老百姓好过，就让谁滚蛋</p>
<p><strong>kkndme：</strong></p>
<p>我们连依法治国都办不到，何谈选票。<br>我们是实行双轨制国家，在经济全球一体化的今天，内部并不与外部接轨。这个好比是互联网，我们重要部门的内网是绝不会跟外网联结的。<br>改变只有两个前提，一是外族入侵，二是出现全国性的大饥荒。否则期望房价崩盘重建一个新世界是没有可能的。</p>
</blockquote>
<h2><span id="kkndme聊北宋-唐朝">kkndme聊北宋、唐朝</span></h2><p>北宋时期，有个文豪及公务员叫苏东坡，一辈子也没能在首都开封买上房子，不得已，在外省小县城投资了几套房地产。苏文豪公务员的儿子在首都结婚的时候，居然都没搞到一套新房，苏公务员急眼了，最后想办法跟朋友借了一套房子，总算把喜事办了。北宋跟我们的现实还是有区别的，象苏文豪公务员这样的中层国家干部，在京城大都是有几套房子的。可见北宋时期公务员待遇还不如现在。</p>
<p>苏文豪公务员的弟弟苏辙就比较幸运了。该同志也是公务员国家干部，工作上兢兢业业，勤勤恳恳，熬了几十年工龄，在七十岁的时候终于买到了房子，但是买的位置还算不上首都开封，而是在开封南边的许昌买的，相当于首都的卫星城。就好比在北京买不起房的同志，跑到天津去搞了一套。<br>苏辙公务员同志专门为买房的事写了诗，“我生发半白，四海无尺椽”，我老未有宅，诸子以为言”诗的意思反正是比较愤青，很想现在的傻空</p>
<p>唐朝还有个白居易同志，也是个公务员，级别相当于正处级，工作是在中央办公厅负责校对红头文件。白公务员职务一般，但工资可不低，每月一万六千钱。但是白公务员却买不起房，在长安东郊常乐里租了四间茅屋，因为房租比较高，城区的租不起，所以上班比较远，很潇洒的买了一匹马，相当于我们买车。白公务员还是很懂享受生活的，雇了两个保姆，每月的总支出大约是七千五百钱。白公务员很象蜗居里的海萍，不肯高价租城里的好房子，而是把剩下八千五百钱存起来，一心要买套房。但是存了十年，他也没能买的起长安的房子，白公务员兼诗人的文学功底很高，但是不懂经济，不了解通货膨胀。</p>
<p>最后白公务员急了，很愤青的说：“你们局级干部在长安炒房子，我处级干部就去周边炒房子。”于是白公务员跑到长安城的卫星城——陕西渭南县，买了套房子，平时在单位蹭房子住，逢假期和周末回渭南的家里跟老婆叉叉呕呕。可见唐朝时处级及以下公务员待遇也就跟我们的都市普通小白领差不多。</p>
<h2><span id="宋代房奴">宋代房奴</span></h2><p>关于房奴，也是宋代就有记载。宋代有本书叫《白獭髓》，写的就是房奴生活：“妻孥皆衣蔽跣足……夜则赁被而居。”<br>大意就是所有的存款不够，还借来钱砸在房地产上，不得不节衣缩食还债，别说家里人买新衣服，就连被子都是租的。<br>不知此人炒房后来发财没有，那时买房可都是全款，没有银行贷款一说。</p>
<h2><span id="zg民主">ZG民主</span></h2><p>只许州官放火，不许百姓点灯，这就是我们的民主</p>
<h2><span id="王安石的青苗法之国家出政策的动机">王安石的青苗法之国家出政策的动机</span></h2><p>关于呼唤国家出政策已达成自己买车买房心愿的空空们，有必要听听王安石变法的故事。</p>
<p>我国的官僚有几千的当官经验，最不怕的就是新政策，只要是新政策，无论目的是为了民生还是敛财，反正就找到了由头，就有办法敛财，有空子可钻。</p>
<p>王安石变法的初衷是好的，但是不了解中国的官僚体制，变法让老百姓吃饭都成为了困难，加速了北宋的灭亡。所以盼着出房产税的空空要认真的用脑子想问题，梗着脖子泄愤是没有用处的。</p>
<p>说说王安石同志的青苗法。</p>
<p>青苗法，按理说是一项最为民生考虑的政策。</p>
<p>在百姓青黄不接，缺少粮、钱的时候，让老百姓自己估计当年谷、麦产量，先向官府借钱，谷熟后还给官府，称“青苗钱”。</p>
<p>青苗法规定把以往为备荒而设的常平仓、广惠仓的钱谷作为本钱。每年分两期，即在需要播种和夏秋未熟的正月和五月，按自愿原则，由农民向政府借贷钱物，收成后加息，随夏秋两税纳官。</p>
<p>实行青苗法的目的肯定是好的，可以让农民在青黄不接时免受高利贷盘剥、并且让农民不至于在没粮的时候土地被大地主所兼并。同时,让政府获得一大笔“青苗息钱”的收入————单纯为了民生，政府收不到钱的事情王安石同志也不同意。 </p>
<p>按理说，出了这个政策，农民该欢呼了，zf出面了，农民们不用受地主老财剥削了，很多傻空老农民鸡冻的喊：“还是王领导的政策好啊。”</p>
<p>地方官员也鸡冻了：“太牛了，发财的机会来了，王领导这人人品虽然不怎么样，但是很给我们挣钱的机会啊。”</p>
<p>于是，王领导的青苗法一推行下去，完全走样了。</p>
<p>首先青苗息钱从王领导定的年息二分，本来就挺高的贷款20%利率，比我们房贷可高多了。但是就这个年息二分，在地方一下子变成了半年息二分，年利率高达40%：因为是春季发一次贷款，秋季发一次贷款，所以地方官每半年收回本利，还是按二分收，所以变成了半年息二分，年息四分。到了后来地方官想怎么收怎么收，甚至年息高达百分之几百。</p>
<p>傻空农民立刻傻眼，说反正自愿的，我不贷还不行吗？接着管地主老财借不行吗？</p>
<p>zf说了：不行。你贷也得贷，不贷也得贷，于是变成了强制高利贷。</p>
<p>王领导在推行青苗法的时候，还下了定额，贷款多少那是有任务的。任何朝代推行某个政策，只要涉及到收钱，都是有任务的。</p>
<p>王领导下达了任务，地方官必须完成，不然要罢官丢脑袋，扣个阻碍变法的帽子可不得了，同时本着无利不早起的伟大思想，不但要完成任务还要层层加码。</p>
<p>这下，傻空老农民彻底傻了，饭都吃不上了。</p>
<p>结果是王领导给zf增加了税收，官员闷声大发财，老百姓彻底崩溃。</p>
<p>所以请呼唤房产税的朋友，好好读一下王安石变法</p>
<blockquote>
<p><strong>tjOOSAN:：</strong></p>
<p>我想 这个 “房产税”出不出。不是什么决策问题吧？</p>
<p>是我们产权的解释问题！我们产权只有70年，换句话说就是租七十年，地和房子本身还是国家的！那么国家的房产再收税，是不是有点法理不通呢？ 这是 郎咸平说的</p>
<p>楼主！这个。你让我再次质疑你了</p>
<p>我其实 很想看进去你的文章！可惜。。。。唉 这成了您的历史秀了~~ 海</p>
<p><strong>kkndme:：</strong></p>
<p>连法制国家都不是还提什么法理。</p>
<p> 拆迁条例是违背宪法的，后来又违背了物权法，但是管用的既不是宪法也不是物权法，而是拆迁条例。一群人说要修改条例，牵扯到利益就没了下文。</p>
<p>有时间你不妨研究一下，看看我们的政策有多少是违反宪法的。<br>在中国拿法理说事就比较搞笑了</p>
</blockquote>
<p>读懂历史</p>
<p>对自己真没坏处。</p>
<p>王安石不但动员zf放高利贷。</p>
<p>还是我国搞中央政采、垄断企业和官倒的先驱。这就是王领导推行的均输法。</p>
<p>宋初以来，为了供应京城皇室、百官、军队的消费，在东南六路设置发运使，负责督运各地“上供”物质。 　　</p>
<p>发运司只照章办事，各路丰年物多价贱时不敢多办，歉年物少价贵时却又必须办足。物货运到京城后往往因不合需要而削价抛售，朝廷所需却又要另去搜括。这些做法给富商大贾操纵物价，控制市场，囤积居奇提供了方便。</p>
<p>王领导希望能够节省劳务费，减少政府的财政支出和减轻人民的负担，就想出了均输法，相当于中央政府采购。 </p>
<p>于是官府直接做生意，行政机构变成了大型国有垄断企业。</p>
<p>中石化、中石油、中国移动、电力等大企业的苦大家都吃过。</p>
<p>垄断企业的低效率，fb，强迫定价，强制消费，这些古今中外都是一样。</p>
<p>而且老百姓跟官府做生意，必须得上供。zf采购那是要多黑有多黑。<br>紧俏商品，官倒搞双轨制，体制内搞配额，体制外高价卖指标。<br>结果是zf闷声大发财，老百姓直接崩溃。</p>
<p>王领导的独断专行，刚愎自用还是很为大家所称道的，呵呵</p>
<p>张居正的一条鞭法从地主阶级的利益出发，反而成功了。</p>
<p>而王领导从民生的利益出发，搞改革，失败的很惨。</p>
<p>不能不说，历史是很搞笑的</p>
<blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>符合地主阶级利益的张居正变法？？</p>
<p>怎么后来张被清算呢？</p>
<p>封建社会官僚本来就是地主阶级的代言人</p>
<p><strong>kkndme:：</strong></p>
<p>张同志的清算不是因为变法，而是把万历同志架空了，比皇帝还牛的首辅能活到寿终正寝已经算是奇迹了，跟他的变法无关。</p>
<p>这位徐阶先生的得意门生，政治上是青出于蓝的，无懈可击，贪污受贿大概也师承徐阶吧，呵呵</p>
<p>很多人只对张居正同志是否和太后有一腿感兴趣，呵呵</p>
<p>张居正通常是以正面形象出现，但是在贪污受贿方面是很有一手的。另一个贪污受贿的正面人物是戚继光。</p>
<p>我国历朝历代的体制，不搞点潜规则什么事都干不成。</p>
<p>比如一事无成的海瑞，光赢得了个好名，其实毫无建树。</p>
<p>关于写青词的严嵩搞掉了正值的夏言，忍耐力超强的徐阶搞掉了老奸巨猾的严嵩，心狠手辣的高拱搞掉了徐阶，而张居正又搞掉了高拱。</p>
<p>这是各机关、企业学习政治斗争的最好案例啊。</p>
</blockquote>
<h2><span id="什么是社会公平">什么是社会公平</span></h2><p>古今中外，任何一次武装革命，无论最终成功还是失败，上位者因为野心的极度膨胀，都变得更加专制。陈胜、李自成、朱元璋、罗伯斯皮尔、斯大林、 ，都是一个个鲜活的例子。</p>
<p>真正公平的社会并不是均贫富、等贵贱的乌托邦，也不是贵族享有领地少女初夜权的强权社会，而是法制社会，大家在一个完善的法律制度下，享有人身和财产自由，知道什么该做什么不该做，法典之下对于任何人都是平等的，无论是平民还是权贵。</p>
<p>作为爱好和平，小富即安的我等小民，最愿意看到的是社会的稳定而不是动乱。</p>
<h2><span id="还是有很多有钱人">还是有很多有钱人</span></h2><p>说起空空们们不买房是因为没钱，我还真不相信。</p>
<p>在某二线城市，调控重拳刚出的时候，我赶紧去买房，碰见一个大姐。</p>
<p>那个大姐很有意思，说从08年底看房，一直觉得房价高，所以坚决不买，结果等到了2010年，一直盼着降，但是调控政策刚一出就心慌了，害怕后面是大暴涨，赶紧把房买了，这位大姐买房是一次性付款。到现在房价涨了30%。</p>
<h2><span id="双轨制之体制内的福利">双轨制之体制内的福利</span></h2><blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>水木社区上有很多愤青打电话给北京建委，举报领秀慧谷捂盘内购的事，我跟了个贴子说不要太幼稚，结果被骂的很惨。今天他们接到建委电话了，说是没有违规。我在想：有这些不明真相的群众存在，房价怎么会跌呢？通胀怎么会停呢？股市IPO怎么会停呢？底层不被收割就奇怪了</p>
<p><strong>kkndme：</strong></p>
<p>让北京建委去查国资委就比较搞笑。北京的房优先安置各大部委，剩余很少的部分才用于商品房开发，所以才说北京四环房价5万一平都不算贵。</p>
</blockquote>
<h2><span id="开发商思维">开发商思维</span></h2><blockquote>
<p><strong>鼻使豆豆：</strong></p>
<p>高房价不可怕，可怕的是没有辩别是非的能力，明明是老百姓，却有开发商的意识，可悲</p>
<p><strong>kkndme：</strong></p>
<p>其实这个道理是很浅显的，你不买房并不能代表房价不涨，而你买了房不但可以住的舒适，还可以获利。反而是有开发商的思维才能有好日子过。</p>
<p>这个道理跟炒股票是相同的。大家知道，股票与房地产不同，并不能创造财富，只是财富再分配的工具，但是财富再分配，是庄家分配散户的钱，而不是散户分配庄家的钱。所以炒股要有庄家的思维才能挣钱。</p>
<p>道理都是一样的。</p>
</blockquote>
<h2><span id="农民政权的缺点">农民政权的缺点</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>请问楼主，为什么历史上的农民起义军领袖，一旦得势后比原来的统治阶级还残暴呢？像黄巢，张献忠等等</p>
<p><strong>kkndme：</strong></p>
<p>是因为缺乏一个纲领。</p>
<p>农民伯伯因为没饭吃拿起武器造反了，造反之后怎么办？——对不起，从来没想过。国家治理到底是怎么回事？——对不起，一概不懂。</p>
<p>比如陈胜，刚占了一块地盘就不知道姓什么了，老子天下第一，农民暴富后，就想拼命享受，自己的属下和革命战友在自己眼中就是一坨屎，就更别说老百姓了。武装还没胜利呢，就生怕别人夺权，大搞内部政治斗争。吴广挂掉最高兴的就是陈胜。太平天国表现的更是淋漓尽致。</p>
<p>朱元璋就不同，是个军事天才和政治天才，懂得治国之道，有做皇帝的野心，也懂得当皇帝需要的知识，朱清楚的知道靠均贫富等贵贱是不能坐天下的。</p>
<p>古代能够夺取天下的，基本都是贵族阶层，有野心有理想有知识。最典型的就是李世民。汉高祖刘邦同样不是单纯的流氓无产者，他幸运的娶了吕雉，一跃成为地主家族的一员。</p>
<p>历史上只有朱元璋是个异数。这也是毛为什么要推崇朱的原因。</p>
</blockquote>
<h2><span id="郑州有前景">郑州有前景</span></h2><blockquote>
<p><strong>larryzs：</strong></p>
<p>最喜欢看楼主评说历史了</p>
<p>呵呵，看来历史要重新好好读一下了</p>
<p>不知道楼主对河南郑州的房价了解吗？</p>
<p>希望楼主对郑州将来的发展分析一下。</p>
<p>现在郑州的房价均价也差不多快到6000了，郑东新区的一万以上。</p>
<p>市政府也在大力修建地铁，个人认为还是有发展前景的。</p>
<p><strong>kkndme：</strong></p>
<p>郑州的交通区位决定了经济发展的空间，同意你的说法，很有前景</p>
</blockquote>
<h2><span id="公园地产是稀缺资源">公园地产是稀缺资源</span></h2><blockquote>
<p><strong>klid：</strong></p>
<p>LZ，省会城市二环边公园边房产和市中心无天然气房产，选择哪个比较好？</p>
<p><strong>kkndme：</strong></p>
<p>公园地产未来是稀缺资源，市中心虽好，但是没有天然气毕竟不方便。两者相较还是公园边合适。</p>
</blockquote>
<h2><span id="张献忠屠川">张献忠屠川</span></h2><p>关于张献忠屠四川，尽管学术上存在争议，但大致是不差的，虽不见于正史，但《蜀碧》及《求幸福斋随笔》都有记录。很多学者也做了大量的考证。</p>
<p>张献忠此人曾经读过书，做过zf最基层公务员——捕快，但是被开除了。人格比较扭曲，不但好色，且好杀成性，是典型的流氓无产者。大明的苦难子民指望这样的有严重心理疾病的杀人狂拯救，那是毫无指望的。</p>
<p>张献忠每攻城略地特别喜欢把当地的妇女同志送进军营当营妓，并且乐此不疲，军队没粮了，就把美丽的少女切成块做成腊肉。把儿童成群的围起来用火烧，谁往外跑就用刀刺，也是张大义军领袖最喜欢的游戏。</p>
<p>对于张的行为，我们只能用有严重的心理疾病来解释。</p>
<p>一个仇视社会的愤青，掌握了军队，破坏力是相当可怕的，是人民的灾难。</p>
<p>张攻陷四川建立大西国政权，与柬埔寨的红色高棉政权简直是异曲同工。以至于清军进入四川受到了百姓的欢迎而不是抵抗。这跟越南入侵柬埔寨，越南军受到了柬埔寨人民的欢迎是多么相似啊。</p>
<p>人民的眼睛是雪亮的，违反人性的，即使打着爱国的旗号，也终将被人民抛弃。</p>
<h2><span id="洪秀全-黄巢-李自成">洪秀全、黄巢、李自成</span></h2><p>洪秀全同志，人生比较悲剧，人家好歹是个落地秀才。洪教主考了20多年，连个秀才都没考上，相当于小学都没毕业。</p>
<p>洪教主考试不行，搞邪教确是个高手，夜里做梦居然梦见上帝（形象大概是个白胡子老道）说洪教主是他的二儿子。这个梦确实不太靠谱。很可能是洪教主有意编的。</p>
<p>洪教主的拜上帝教应该算是白莲教的一支或者说是余孽。</p>
<p>洪教主搞革命，对解放劳苦大众却一点不感冒，最感兴趣的是一夫多妻制，娶了88个后妃。好像历史上的农民军领袖对妇女同志都有出奇好感，大概是小时候性压抑的结果。</p>
<p>太平天国攻下南京得了半壁江山，洪教主从41岁开始，直到11年后自杀，竟然没出南京城一步。大概是收罗的漂亮的妇女同志太多了，实在没有时间干别的。</p>
<p>比起张大义军领袖的变态，洪教主还是比较有人性。好色，人之天性。</p>
<p>不过洪教主进南京，并没有因为女性的爱情滋润，而让他变得温柔。虽然没有张大领袖变态，实行的也是三光政策：杀光、烧光、抢光。</p>
<p>“凡掳之人，每视其人之手，如掌心红润，十指无重茧者，恒指为妖，或一见即杀，或问答后杀，或不胜刑掠自承为妖杀，或竞捶楚以死。”大意是手上没长茧子的就是妖人，就要统统杀掉。</p>
<p>农民起义带来的不是均田地等贵贱的乌托邦，而是血腥恐怖</p>
<p>说起洪教主玩弄的美女确实让人流口水，除了88个妃子外，女官侍婢不计其数，算下来用了11年时间玩了2300名妇女。</p>
<p>有一本《江南春梦笔记》：王后娘娘下辖爱娘、嬉娘、妙女、姣女等16个名位共208人；24个王妃名下辖姹女、元女等七个名位共960人，两者共计1169人。以上都属嫔妃，都是要和洪秀全同床共枕的。天王府不设太监，所以另外还有许多服役的“女官”。以二品掌率60人各辖女司20人计算，合计为1200人。各项人数加起来，总计有2300多名妇女在天王府陪侍洪秀全一个人。</p>
<p>一个农民当了教主，就有这样的眼福。换做了傻空当教主，会怎么做？</p>
<p>黄巢比洪教主学问要高一些，但是屡试不第，当了私盐贩子。</p>
<p>从起义的第一天开始，黄巢的脑子里也从来没有过百姓该如何如何的。</p>
<p>他是一个彻头彻尾的投机分子，说是义军，不如说是强盗。</p>
<p>新唐书中说，贼军所过州县，老百姓皆烧杀殆尽。黄巢的兵可并不懂三大纪律八项注意，那是能抢救抢，抢不了就烧就杀。</p>
<p>无论是旧唐书、新唐书、还是资治通鉴，从头到尾，就没有出现过黄巢的一句好话。</p>
<p>黄巢攻陷广州，至少屠杀了十二万人，把皇帝气晕了。</p>
<p>皇帝还知道体恤子民呢，而黄巢就是彻头彻尾的强盗外加杀人犯。</p>
<p>黄巢攻进长安当了天子，充分显现了流氓无产者的本质，穷奢极欲，挥霍无度，治理国家的事彷佛就跟他没有一点关系。不搞建设就只能做吃山空，结果长安的粮食都被糟蹋完了。</p>
<p>长安没有余粮，黄巢就把长安老百姓抓来，煮着吃，十万大军靠吃老百姓过日子。</p>
<p>幸好老天开眼，官军打进了长安，结果是老百姓对官军夹道欢迎。<br>农民军真是义军吗？</p>
<p>不但中国的农民军领袖都是杀人魔鬼的化身，就是法国资产阶级大革命领袖罗伯斯皮尔，同样也是法西斯暴政的先驱者。最后被人民送上了断头台。</p>
<p>只有一个真正的法制化国家，人民在法律的制约下，享有人身与财产自由，才能够安居乐业。</p>
<p>李自成在军队纪律上，是要比张献忠高明一点的，所以李自成打进了北京。李自成到北京后，拷贝了黄巢进长安的淫乐经验，对美女极尽淫乱之能事，对百姓烧杀抢劫做的也很出色。</p>
<p>历代农民军对妇女的态度与《水浒传》中梁山好汉完全相反。</p>
<p>施耐庵笔下的梁山好汉们似乎对妇女有天生的仇视，动不动就把女同志劈死，李逵甚至终生不尽女色，就凭这一点，我们只能说梁山好汉是农民军中的异类。</p>
<p>但是梁山好汉不是为了起义，而是为了招安。一群由小公务员和渔民组成的社会最底层群众梦想通过拉山头再跳槽的方式走进金字塔的中层，但是这个梦想破灭了。</p>
<p>古代历史上，能够治理天下的穷苦人，只有一个：朱元璋。</p>
<h2><span id="朱元璋">朱元璋</span></h2><p>为什么朱元璋可以，而别人不可以。</p>
<p>经过仔细研究发现，朱元璋的人生际遇不像黄巢、张献忠和李自成，他有点像刘邦，但又有很大区别。</p>
<p>朱元璋是一个到处要饭吃的和尚，但是喜欢思考，见世面，交朋友，并且找到了自己的宗教信仰——明教（也叫摩尼教、白莲教）。</p>
<p>朱元璋走投无路投奔起义军的时候，娶了起义军濠州大帅郭子兴的义女当老婆，就是那个著名的马皇后。郭子兴并不是一个农民，而是一个大地主，所以朱元璋加入的这个新家族，思想完全不同一个扛着扁担造反的农民。</p>
<p>郭子兴作为农民军的统帅，却在逛街的路上，被其他的农民军兄弟（真正的农民）绑了票，大概是因为农民对地主阶级比较仇恨。最后被朱元璋救了出来。</p>
<p>郭子兴看见朱元璋比自己强，反而起了憎恨之心，一心想把朱元璋弄死。</p>
<p>朱元璋在丰富的人生经历中看到了农民起义军领袖们的鼠目寸光，要想成大事，必须有远大的理想和抱负，而这些是黄巢、张献忠、李自成、洪秀全都没有的。</p>
<p>朱元璋与那些个农民军领袖最大的不同在于，他熟读历史，因此他把汉高祖刘邦作为榜样。目标是建立一个基业长青的强大统一的国家。</p>
<p>朱元璋就懂得无论是得到天下，还是治理天下，就必须有能力的人来辅佐。嫉贤妒能的人只能被历史的车轮碾碎。</p>
<h2><span id="曹参治国">曹参治国</span></h2><p>人们最希望的，就是在一个良好的社会环境下，安居乐业，自食其力。zf的职责就是健全法制，维护一个良好的环境，剩下的事，交给民间去做。三天两头出政策，过度插手百姓如何过日子，甚至朝令夕改，就会让百姓的正常生产生活无所适从。<br>早在汉朝初期，曹参已经参悟了这个道理。<br>曹参是刘邦当亭长时的领导，也是刘邦最亲密的战友。萧何是文官，曹参则是武将，曾经在韩信麾下效力，除了披坚执锐外，最重要的工作就是监视韩信，防止韩大军事家谋反。<br>这样一个万夫难敌的勇将，却在革命胜利后被分配给齐王刘肥（刘邦的私生子）当相国，主抓齐国的政务。</p>
<p>曹参是一介武夫，只懂得军事，并不懂治理地方，就用厚礼聘请了精通黄老之术的盖公。盖公认为：治理国家很简单，只要按照律法办事，给老百姓提供一个安全的稳定的环境，其他的都不用管，官府千万不要好大喜功，追求政绩，过多插手百姓的事物，顺其自然就好了。<br>曹参很赏识盖公，并且按照盖公的话去做，九年的时间，齐国变得非常繁荣。<br>这时候，传来噩耗，萧何挂了，皇帝刘盈聘请曹参出任相国。曹参上任以后，几乎罢免了所有办事效率高、口才好，有追求有抱负的能吏，提拔了一群只知道按部就班，照章办事的老实巴交的官员，然后就彻底大松心，成天喝酒吃肉听小曲。</p>
<p>很多人对曹参不满就给皇帝刘盈打小报告，刘盈的表现是很愤怒。<br>曹参就问刘盈：是陛下你牛呢，还是先皇刘邦牛呢？<br>刘盈：当然是先皇牛<br>曹参又问：那我跟萧何比，谁牛呢？<br>刘盈愤怒的说：你比萧何差远了。<br>曹参做了个总结：您讲的太对了，先皇和萧相国拟定的法令已经非常清楚了，只要贯彻执行下去就好，我只要按照他们的法令办，不就行了吗？<br>刘盈虽然不事朝政，但应该算是比较聪明的君主，一听就懂：对于已经定下的治国方针大略，只要执行下去，一定会使人民休养生息，国家富足。如果大搞政绩工程，对于先皇刚死，吕后掌权时期风雨飘摇的大汉来说，将是灾难性的。<br>民间把成天喝酒吃肉听小曲的曹参称为贤相。司马迁在史记中也给了曹参极高的评价。</p>
<p>假设一个工程队要盖楼房，起初设计人员设计了20层，刚盖了两层，队长换人了，非要盖成30层，工人于是绞尽脑汁费劲办法改造。等盖到25层的时候，又换队长了，新队长说还是改成两层的别墅吧。刚把楼房都拆掉，别墅建了一半，又来了一个队长，说要建成比迪拜塔还高的大塔楼。这个楼建了n年也没建起来。<br>建房子跟治国的道理是一样的，我国汉代的相国曹参就已经明白了这个道理。</p>
<h2><span id="晁错">晁错</span></h2><p>刚才有人提到吴楚七国之乱，讲得是晁错。晁错其人是很值得讲讲的，一个有才能的人在错误的时间做了一个理论上正确的事，却导致吴楚七国之乱，汉景帝差点完蛋。结果是景帝砍了晁错的脑袋。</p>
<p>这个故事，几乎家喻户晓，蕴藏的道理却很深，大家如果懒得看史料，有兴趣可以参看易中天“帝国的惆怅”，还是很值得一看的</p>
<h2><span id="民营小企业的老板和打工者">民营小企业的老板和打工者</span></h2><p>糊涂人即使把道理说的再浅显，他也听不明白，呵呵。<br>现在我国已经进入高通胀期，但是地方巨额债务与人民币的升值又封杀了加息的空间，经济形式有可能恶化，民营小企业的老板和打工者只能自求多福了。</p>
<blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>刚查了一下央行的数据，8月份的M2是68.75万亿，我没记错的话，7月份的M2控制的很好，基本没怎么涨，但是到了8月份，没想到有那么猛的涨幅，看来不到12月，我国的M2就要到70万亿了。2007年1月份，我国的货币供应量是35万亿。</p>
<p>今早去小摊买早点，原来一块五的加鸡蛋灌饼现在卖两块。如果涨工资，只会把通胀越推越高，如果不涨工资，P民就要忍受通胀的剥削。真是无语了</p>
</blockquote>
<h2><span id="郭解">郭解</span></h2><p>从古到今，小老百姓遇到不公，受了委屈，幻想最多的就是跳出一个大侠，劫富济贫，为自己伸张正义。所以金庸的小说广为流传，被称为成年人的童话。<br>我国古代，真有大侠，不过古代的大侠并不是会降龙十八掌的郭靖，也不是小李飞刀，而是黑帮的老大，相当于西方的教父。<br>最有名的大侠叫郭解，汉朝时有极高的威望，不然也不会写进史记。<br>郭解的爸爸是个职业杀手，非常有名，用古龙的话说，最厉害的杀手是没有名字的，郭解的老爸名声太大，注定活不长。有个米商请郭解的老爸到监狱里救出犯了法的儿子，郭老爸看在钱的份上去了，就再也没能回来。</p>
<p>郭解跟他老爸学过功夫，很有两下子，于是干起了抢劫和盗墓的这份很有前途的职业。因为功夫高，谁只要说句话让他不爱听，必然遭遇一顿暴打。本着流氓会武术谁也挡不住的精神，到了三十岁，郭解已经钱多的数不过来了。男怕入错行，女怕嫁错郎，看来抢劫和盗墓的职业选择对了。<br>30岁以后，郭解为了从强盗升级为教父，开始积累自己的名声，并且学习战国四公子，开始蓄养门客，但凡是哪个人有难，有求必应。俨然形成了一个严密的黑社会组织。在民间的声望，甚至超过了皇帝。<br>皇帝的权威是不容冒犯的，一个地方黑社会头子怎么能够这么嚣张呢？就把郭解抓了起来，虽然有大量的证据证明郭解作奸犯科草菅人命，但都是汉武帝大赦前的事情，没有办法定罪。汉武帝一筹莫展，人抓了不能定罪，又不能放掉，该怎么办呢？<br>这时，正好有个书生，骂郭解不遵纪守法。正巧被郭解的门客听到了，就把那个书生给杀了。<br>汉武帝听了哈哈大笑，正巧找这个理由把郭解灭族。<br>侠客的黄金时代，从此结束</p>
<p>剑侠情侣，快意江湖，听着是一个充满了浪漫的世界，而事实是完全不可取，一个没有法制的社会，奉行者赤裸裸的丛林法则，什么是对？什么又是错？理由就永远站在强者一边，强者可以随自己的意愿决定弱者的生死。<br>这个社会是可怕的。<br>郭解，就让他永远埋葬吧</p>
<h2><span id="2010年的中国房地产">2010年的中国房地产</span></h2><blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>今天跟家里人打电话，姨妈说了下近一年来老家云南东北方向一个地级市曲靖的变化。</p>
<p>主要就是：好些有资金的外地大佬大手笔拿地，开发酒店和商品房。都是市区的黄金地段。</p>
<p>其实房地产开发在中国的任何一个城市每天都在发生，不过令人感慨的是这样的“四线”城市也如此火爆，购买力之强令人感慨，她说最近几天曲靖正在举行房交会，人头攒动。<br>现在老百姓有钱都向往好的房子和户型了，已经不满足90年代的老旧房子了，而且通货膨胀也逼得大家不得不置业保值。</p>
<p>再回头看看北京，简直找不到跌的理由。那么多地铁要修，那么多优质生源每年涌向北京高校，那么多人口，每天要造就那么多富人。。。。</p>
<p><strong>kkndme：</strong></p>
<p>钱太多了，流动性泛滥，老百姓恐慌了。这次调控暂时抑制了一线城市房价的上涨势头，但是却直接导致了全国性房价的上涨，不光二三线城市，连四级以下城市都是如此。这就是领导水平。</p>
</blockquote>
<h2><span id="房奴算不上不幸相当当不了才算">房奴算不上不幸，相当当不了才算</span></h2><p><strong>lanyu1121：</strong></p>
<p>普通老百姓都成房奴了。</p>
<p><strong>kkndme：</strong></p>
<p>成为房奴还算不上不幸，相当房奴当不了才不幸</p>
<h2><span id="精英人群的平均收入决定房价">精英人群的平均收入决定房价</span></h2><blockquote>
<p><strong>skysurfer2208：</strong></p>
<p>想请教一下楼主，对于很多的二线城市，比如武汉，市区房子的均价一万左右了，但当地的平均收入一般也就3000左右吧，难倒你不认为现在的房价里面有泡沫吗？特别是现在正处在调控期，对于我们这些近年打算买房的来说，是在等等看呢还是在在这个时期出手？多谢楼主</p>
<p><strong>kkndme：</strong></p>
<p>你所说的平均收入是什么概念？是人人都挣3000块，还是有人挣2000块，有人挣1万块。武汉的房价，要看湖北省包括各地市的人口，家庭收入上万的人有多少，如果你认为很少，几乎没有，那房价肯定存在泡沫。如果湖北省有20%的人口家庭月收入超过万元，那么武汉市区的房价就没有泡沫。</p>
</blockquote>
<h2><span id="内地不是香港-海南">内地不是香港、海南</span></h2><blockquote>
<p><strong>johny__：</strong></p>
<p>那香港97年的时候还不是一样跌了一大截，按LZ的说法，1）土地资源很稀缺；2）作为消费群体的白领收入也能买房；3）作为世界城市，更是汇聚了世界级精英的购买力，仿佛现在上海。最后，不是一样大跌？？中产都成了负资产了。就连林百欣的儿子林建岳97年以69亿港元高价购入中环富丽华，还不是赔得一塌糊涂。</p>
<p>楼价涨高了就要跌，哪都不例外，这个才是规律。什么通涨，精英购买力决定房价，都是涨了之后在找理由。</p>
<p><strong>kkndme：</strong></p>
<p>这就是体制上的不同啊，所以我们无法重复香港和日本。97年的金融风暴，还是中国以国家之力对抗索罗斯的量子基金，保住了香港，这种行为在西方国家是难以想象的。一个国家动用全国人民的外汇储备与美国的民间资本打一场战争，这是令全世界震惊的。索罗斯因为不了解中国的体制，悻悻而归。</p>
<p>人民币不能在世界流通，依照我国实行的货币制度，货币只不过是一种符号。如果有一天我们的人民币能够自由兑换，香港发生的事也一定会发生在我们身上，但你认为我们的人民币能够自由兑换吗？</p>
<p><strong>johny__：</strong></p>
<p>那92年的海南崩盘有从何说起？从7000多掉到了几百元，这难道是海南体制？发币行是海南银行？同样是国内，同样的外汇管理制度，不是日本也不是香港，是中国海南。</p>
<p>—据《中国房地产市场年鉴（1996）》统计，1988年，海南商品房平均价格为1350元/平方米，1991年为1400元/平方米，1992年猛涨至5000元/平方米，1993年达到7500元/平方米的顶峰。短短三年，增长超过4倍。</p>
<p>—海峡对岸的北海，沉淀资金甚至高达200亿元，烂尾楼面积超过了三亚，被称为中国的“泡沫经济博物馆”。</p>
<p>[经验交流]92年海南房地产泡沫始自于“击鼓传花”(转载)<br><a href="http://www.tianya.cn/publicforum/content/house/1/163988.shtml">http://www.tianya.cn/publicforum/content/house/1/163988.shtml</a></p>
<p><strong>kkndme：</strong></p>
<p>全国的资金去炒海南、北海，炒的纯粹是概念，没有实体的支撑，就是一种博傻游戏。今年年初海南房地产的爆炒，同样积聚了巨大的风险。买房并不是全无风险，好比通州、燕郊，经历疯狂的炒作一定会理性的回归。但是如果指望北京四环内房价下跌，也只是痴心妄想。</p>
<p>房产投资也不是随便买套房就只涨不跌，比如说山东乳山的房子，开发商疯狂炒作旅游地产概念，但如果真的想投资升值，那就成了天大的笑话，因为根本无法变现。</p>
<p>什么样的房产适合投资，投资者不是傻子，都会有理性的判断。</p>
<p>90年代初的强硬调控让海南和北海的经济崩盘，对全国来说不可怕，毕竟只是一隅之地，但是如果用粗暴手段搞崩了全国，zf一定会好好掂量的。</p>
</blockquote>
<h2><span id="历史是一面镜子">历史是一面镜子</span></h2><p>如果以为本帖讲的历史故事，那就完全理解错了。</p>
<p>本帖讲得不是历史，而是总结前人的经验，讲得是故事背后的道理。<br>如果毛不是熟读历史，也不可能取得胜利。毛在进京的时候，说过一句话：我们不学李自成。</p>
<p>只有认真总结过李自成失败的教训，才能够做出正确的选择。</p>
<h2><span id="买房一次性到位比较好">买房一次性到位比较好</span></h2><blockquote>
<p><strong>包容会通：</strong></p>
<p>我老婆是长春人,岳父母退休,都有退休金.我和我老婆现在都在国外,准备3年以后回长春工作,我们现在有40万的现金,放在银行也没什么用,也担心3年以后,长春的房价还要涨.</p>
<p>因此,现在准备用其中的20万作首付买套70平的小户型的,让岳父母住(岳父母有住房,但很快就要拆迁了).等3年以后回长春,把这套小的卖了换成大的.不知这样的计划是否可行?贷款如何弄?<br>　　　　　　　　<br>谢谢兄弟.</p>
<p><strong>kkndme：</strong></p>
<p>既然是自住型需求，何不买套大点的，70平（建筑面积）的房子无论是自住、父母住还是合住，都比较拥挤。既然有40万的闲钱，还是一次到位比较好，3年后长春的房价一定要比现在高的多。</p>
<p>只是贷款比较麻烦，你的父母是无法贷款的，除非你们夫妻能够回国，这种事用别人的名字办肯定是不行的，房价上涨后就有可能会陷入扯皮甚至打官司的境地。</p>
</blockquote>
<h2><span id="外汇管制">外汇管制</span></h2><blockquote>
<p><strong>tianxiaobing11：</strong></p>
<p>楼主，这个tj连人民币不能自由兑换都不知道，可见他的水平也太差了，就不用和他计较了，从上个月开始人民币换美圆好象收紧了，是怕民众把人民币换美圆出逃吗？</p>
<p><strong>kkndme：</strong></p>
<p>外汇外流趋势比较严重，zf开始严管，包括携带50美元以上商品入境必须征税等措施，都是限制外汇外流。富人从穷人身上赚了钱，换成美元在国外消费，这是zf不愿意看到的，zf不在意富人搜刮穷人，但肉一定要烂在锅里</p>
</blockquote>
<h2><span id="一线和二线">一线和二线</span></h2><blockquote>
<p><strong>yamazaki28：</strong></p>
<p>楼主好，小弟有问题请教，本人所在二线省会城市，存款40w,近来看中本市CBD区域高端住住宅一套，各方面条件十分优越，面积100左右，均价18000。但通过观察，又看中觉得北京五环附近的待建地铁房，均价16000，想贷款弄小户型60左右，不知哪个升值潜力大，本人已有房一套。谢楼主指点。</p>
<p><strong>kkndme：</strong></p>
<p>短期来看，二三线城市的房产升值速度要高于北京，这是这次调控造成的结果，从长期来看，北京房产的升值速度要高于二三线城市。五环附近地铁房，还是很有优势的。</p>
</blockquote>
<h2><span id="吕后篡权">吕后篡权</span></h2><p>大凡是60年代末，70年代初生人，小时候肯定看过一本小人书：吕后篡权。<br>在那个时代推出这本书，很有寓意，起到了很好的宣传效果。<br>吕后真的是十恶不赦的妖妇吗？让我们还原历史的真相。<br>我们读到的吕雉，通常的形象是蛇蝎心肠的女强人。<br>大家感兴趣的，首先是关于吕雉在项羽大营和审食其是否有一腿。<br>然后看到的是吕雉协助刘邦诛杀异性王、与倾国倾城的戚夫人争宠、帮助儿子刘盈与戚夫人的儿子刘如意争夺太子、杀害戚夫人和刘如意、提拔吕氏家族成员。<br>但是因为宣传的需要，几乎所有人都忽略了吕雉的另一面</p>
<p>刘邦见上帝以后，吕雉掌权期间，对待老百姓还是很够意思的。<br>俗话说嫁出的女就是泼出去的水。吕雉可不同，吕雉非常照顾自己的娘家人，想把自己的娘家人都提拔起来。<br>秦始皇把分封制改成郡县制，搞天下大一统，意识比较超前，结果政权不稳定，秦朝很短时间就完蛋了。高祖刘邦吸取了这个教训，仍然搞分封制，不过分封制做了重大的改革:首先是分封的诸侯王必须是皇族，也就是说必须姓刘。其次是从中央派丞相给诸侯王，丞相掌握诸侯国的军政大权，防止生变。<br>吕雉提拔娘家干部最大的障碍就是：高祖说过，诸侯王只能姓刘。</p>
<p>吕雉是一个极其精明的女人，她追尊自己的老爹吕公为宣王，吕公是刘邦的老岳父，追尊皇帝的老岳父，旁人自不能有异议。既然有了先例，剩下的事就好办了，吕雉趁机把自己吕姓家族的成员封为吕王。<br>吕王吕嘉这个人很嚣张，仗着外戚的身份，飞扬跋扈，不尊法纪。<br>吕雉是一个出色的国家领导人，不是黄巢李自成之类的强盗流民，是很关心民生的，所以很生气，把吕嘉给废了，让吕嘉的叔叔吕产当吕王。<br>吕雉掌权后，做了很多亲民的好事，减免老百姓的税赋，加强建设健康的人民文化娱乐，最受百姓欢迎的是废除了“三族罪”和“妖言令”。<br>三族罪的意思很直白，就是一人犯罪株连三族。<br>妖言令有点象后来的文字狱，哪里出现统治者认为的妖言，就把那个地方的所有百姓全部处死。这是一个伟大的历史进步。<br>吕雉还是女权运动的先驱者，在吕雉时代，女子也可以封官封侯，可以随意离婚再嫁。那个时代是中国古代史上，女人最幸福的时代之一。<br>吕雉，一个柔弱的女子，在残酷的宫廷政治斗争中表现的异常凶狠，然而权力的斗争本身就是你死我活，在治国方面，吕雉却无愧于一个贤明的统治者，可谓巾帼不让须眉。吕雉与后来的老佛爷完全就不是一个等级，毫无可比性。<br>吕雉执掌朝政十五年，直到病死后，吕氏家族才土崩瓦解。<br>还原真实的历史，我们不应该对这位叱诧风云的女政治家，致以深深的敬意吗？</p>
<h2><span id="小产权房">小产权房</span></h2><blockquote>
<p><strong>大水牛跟水牛仔：</strong></p>
<p>楼主,可以谈谈小产权房的看法吗?父母是珠海的原居民且拥有两套小产权房,无房产证只有村里所发的使用证,是村委会卖给原居民的,离市中心约半小时车程,近河边,而一路之隔的位置己建有大型高尚住宅小区,在售价一万二以上,请问这些小产权房可靠吗?听说往后政府对这些小产权房采取放宽政策,只需补一点钱就可改成商品房,你觉得有可能吗?</p>
<p><strong>kkndme：</strong></p>
<p>这个补点钱就改商品房的可能性不大，如果是大片的小产权房，拆的可能性也不大。这个问题很让zf头痛，城乡双轨制的结果，所以zf能拖就拖。</p>
<p>但是对于片区不大的小产权房，风险就很大</p>
<p><strong>大水牛跟水牛仔：</strong></p>
<p>谢谢楼主回复,父母手上的两套小产权房在同一小区,小区比较大,这类小区有好几个,由于村内将进行旧村改造,规划成高级住宅片区,那此类小产权房如遭迁拆的话会得到赔偿吗?</p>
<p><strong>kkndme：</strong></p>
<p>这个会比较扯皮，最坏的情况是按照原价退赔，最好的情况是回迁安置。如果原价退赔损失就很大。</p>
</blockquote>
<h2><span id="商铺和住宅">商铺和住宅</span></h2><blockquote>
<p><strong>deeplp：</strong></p>
<p>kkndme 兄，你好。</p>
<p>从这个帖子一开始就一只跟着，每天必看。受益良多。</p>
<p>你对广州感觉如何？请教一个问题，不知你对商铺是否有研究？你觉得眼下投资商铺好呢，还是继续投资房产。<br>本人已有2套房产，都在广州市区且近地铁但不带很好学位。现有如下两个想法，</p>
<ol>
<li>分散投资，投资一个商铺，目前看中一个广州北京路拐弯处二楼商铺一个，靠近地铁。</li>
<li>继续房产，买一个130以上大户型且带学位房，方便以后小孩读书。（计划明年要小孩，现在就做打算是怕以后买不起阿。）<br>麻烦兄台给些意见。十分感谢。</li>
</ol>
<p><strong>kkndme：</strong></p>
<p>找到合适的商铺是很难的，因为商铺投资风险大，所以非常考验个人的眼光，属于高风险高回报，找对了，将财源滚滚，找错了很可能血本无归。<br>如果你有眼光，首选商铺。如果不具备这方面的能力投资住宅比较保险。</p>
</blockquote>
<h2><span id="体制内外">体制内外</span></h2><blockquote>
<p><strong>tuzi1976：</strong></p>
<p>kkndme兄，你好。上周提了几个问题，可能你没看到，再请教一次，请抽空指点一二。<br>看到楼主说过“人民币对外是升值，对内贬值”，我认识到“人民币对外是升值，对内贬值”这一点也有一年多了吧，主要是从生活经历、经济新闻中得到的结论（本人学工科、不懂经济）。虽然看到了表面现象，但对其发生的根本原因、对群众生活的深刻影响、“中产阶级（勉强算是有这么个阶级）”的应对之策等等尚没有深刻的认识。楼主看到我提的这些问题恐怕也觉得范围太大、难以回答？难道体制外的“中产阶级”只有任人宰割、移民海外、钻营往上爬这几个选择？诚心求教，风险自担（呵呵，楼主也不是神仙）</p>
<p><strong>kkndme：</strong></p>
<p>普天之下莫非王土，决定了今天的土地国有<br>万般皆下品，也决定了以后知识分子的前途必须进入体制内。<br>不能考中进士的明清两代知识分子，即使经商发了大财，也一样让人看不起，不能光宗耀祖。今天的知识分子将面临同样的命运。<br>体制外，凭个人的本事和运气，自生自灭。</p>
</blockquote>
<h2><span id="2010年的上海">2010年的上海</span></h2><blockquote>
<p><strong>youme5845：</strong></p>
<p>看到LZ的帖子真是太及时了！因为要解决小孩子上学，我最近开始密集型的看房子.</p>
<p>感慨房价高的同时后悔没有早点考虑买房。头痛啊！！！</p>
<p>说说我们的情况：目前现金40W,家庭收入1W5,住上海，目前看的房子为周边世纪公园地铁10分钟老公房(新房很少)，81P 190W,地段很好，但房子都是95年左右的了。算下来除了首付家里帮助外每个月供5K还30年(扣除公积金还款),我们现在可以出手么？还是等十一新政策出来后买？</p>
<p>还是在交通稍微不便的地方买低价的房子？</p>
<p>请LZ给个意见~ 在线等~<br>多谢！！！！</p>
<p><strong>kkndme：</strong></p>
<p>月供5k,收入1万5，说明的你的压力不大，完全可以承受。如果地段好，可以不考虑房子的新旧。一线城市的买房时机最不好拿捏，因为一线城市是调控的目标，你要仔细观察，如果发现中介的铺面里看房客越来越多，建议赶紧下手。</p>
<p><strong>youme5845：</strong></p>
<p>多谢！！！ 那我最近关注多一些！<br>还有这块小区同时是学区房，是否可以买个100W出头的出租，然后自己租房住(我们长期租住房租很便宜 1700两室户)，这样即使以后出现金融危机等情况也不会担太大风险，是这样么？</p>
<p><strong>kkndme：</strong></p>
<p>对自己好一点的就会自己住，对钱看的比较重，可以买房出租，自己租便宜的。因人的性格而已。<br>不过人生苦短，在短短的有生之年，还是要对自己好一点。自己买的房子住起来跟租房子的感觉是完全不同的。</p>
</blockquote>
<h2><span id="收紧住房贷款">收紧住房贷款</span></h2><blockquote>
<p><strong>welldayzwb：</strong></p>
<p>顶楼主，越读越觉得受益良多<br>楼主分析一下，最近几年一线城市是否会一直收紧贷款，想改善住房是否也得必须全款了？一想起这个就很郁闷，去年机会没利用好，后面不仅仅是经济成本的问题了，又面临和无房空空类似的问题，攒钱永远赶不上房价了。。。</p>
<p><strong>kkndme：</strong></p>
<p>收紧住房贷款起码在未来的一段时间会成为常态。由于货币泛滥，一次性付款的人群数量庞大，收紧贷款虽然不能降低房价，但可以抑制房价上涨的速度，防止商品房卖给穷人，以规避金融风险，对社会稳定和经济平稳增长都是有利的。</p>
</blockquote>
<h2><span id="买房物业与房贷">买房：物业与房贷</span></h2><blockquote>
<p><strong>fallenleafe：</strong></p>
<p>关注本贴多日，非常欣赏楼主的睿智和理性。<br>小女子也是上海众多买房人之一，目前所谓单身剩女，得家人支持有一百五十万的首付金。基本确定买在内环交通方便的次新房（老公房停车太成问题）。<br>对上海浦西内环内的诸多区位和楼盘做过研究，发现离地铁近的同时能有苏州河景观的房源最具性价比，满足交通性和景观稀缺性的双重优势（上海内环内几乎没什么安静同时又具有自然资源的地方）。<br>现在基本确定了两个小区，比较纠结的问题有两个。<br>第一个问题，一个是小区管理和区位优势明显单价在3万3左右，另一个区位和管理比较差，名声不好，但是面苏州河的独一无二景观，单价在3万左右。从小区管理的角度，我也认可楼主的看法，管理好的小区升值空间大，管理差的小区由于群租问题严重，目前价格偏低，但是这个软件问题在日后随着自住率的提高貌似也能解决。究竟我该选一个景观资源非常稀缺的管理和配套相对较差的小区，还是一个相对成熟价格稍高同时综合配套比较好的小区？那个小区比较有保值和投资优势？<br>第二个问题，目前的月收入税后刚过万元，如果拿150万的首付买一房大概80平左右，是比较轻松的，月供不成问题（目前租的一室一厅租金3500，已经可以做为还贷资金了）。但是考虑长远问题和一些小户型的局限性，非常想投资一套能长久居住的两房甚至三房（众所周知，一个小区里好的位置总是留给最大的户型）。这样的话，大概一套就要在320万甚至350万，我需要每月还贷1万2左右，基本和我的月工资持平。从个人观点来看，我比较想冒这个风险，比较合适的做法是首付降低到3成左右，留出三十万左右的还贷资金用以应付前面两至三年的还贷。由于目前单身，两至三年后也许家庭收入就可以完全承受这个月供。即使还是单身，目前事业发展良好，对2年后的收入在2万以上很有信心，因此还是认为可以目前阶段多点勇气，目光长远，以保证日后生活安康。<br>不知道楼主怎么看这个问题？如果是房价持续上涨的情况，也许更该相信我的工资也会持续上涨，是否我看问题太乐观？贷款200万的风险是不是会太大？</p>
<p><strong>kkndme：</strong></p>
<p>第一个问题：物业管理对于小区的价值起着至关重要的作用，好的物业管理才能让人居住舒适，这一点是非常重要的。软件的提升往往比硬件的提升难度更大。物业很差的景观楼盘，可以比喻为鲜花丛中的一坨屎，周边环境再好，它也是一坨屎。一坨屎能否脱胎换骨变成黄金，存在着较大的不确定性。<br>第二个问题：是否承受较高月供，取决于你对未来的预期，所以你要仔细分析你的行业前途，如果你所处的行业告诉成长，或者你的能力职位将得到进一步提升，你可以承受较高的月供。<br>一般来说月供不要超过全部收入的70%，如果超过这个边际，就会有较大风险。</p>
</blockquote>
<h2><span id="奸臣蔡京">奸臣蔡京</span></h2><p>现代的纸币发行成本很低，拿着印钞机印就是了。古代就没那么好办，金银的开采量是有限的，别说金银，就是铸铜钱用的铜，也不是想要多少就有多少。</p>
<p>古代要想制造通货膨胀，最绝的办法就是拿一个铜钱当十个铜钱花，叫做当十大钱。搞当十大钱，扰乱货币秩序的领导，最有名的就是蔡京。</p>
<p>蔡京这个名字并不陌生，不爱读历史的人也一定看过水浒传。就是这个领导，被宋史称为六贼之首。大家一提起他，就自然把他跟奸臣划了等号，恨不得在他脸上踹几脚。</p>
<p>蔡京的确是个奸臣，但很多人可能不知道的是：蔡京是王安石的最得力干将，他的很多祸国殃民的政策，竟然是源于恢复王安石的变法。</p>
<p>王安石可以说是一个品德高尚的人，但是变法的流毒，竟直接导致了北宋的灭亡。王安石是一个在历史上有争议的任务，但是他的得力骨干蔡京同志，却是不折不扣的奸臣。</p>
<p>蔡京领导的罪恶，大家一致公认的就是那么几条<br>第一、花石纲，水浒传有精彩的描述，这个纯属于皇帝的个人爱好，似乎都推到蔡领导身上比较冤枉。<br>第二、大兴土木，大搞基础设施建设拉动内需，顺便搜刮点民财，以至于百姓怨愤<br>第三、恢复王安石时期的方田法，并且更改盐法茶法，国库和官员一起大肆搜刮民财，与民争利，结果租税混乱，富人把负担全部转嫁给穷人，穷苦百姓的负担更加沉重。<br>第四、就是当十大钱，制造通货膨胀，严重扰乱金融秩序和金融安全，北宋的经济崩溃了<br>蔡京，一个王安石变法的坚定执行者，最后成为祸国殃民的奸贼。</p>
<p>关于蔡京的奸臣形象，到了现在，有人企图为他翻案。但终究声音比较弱小。<br>因为在中国的古代，肆意敛财、大兴土木、搞官商垄断，与民争利，以至于人民不堪重负的领导，都被称为奸臣。对于减轻人民赋税，不胡乱插手民间生产和贸易，让人民修养生息的，被称为贤臣。<br>中国的古代，奸臣远远多于贤臣。</p>
<h2><span id="体制内的28原则">体制内的28原则</span></h2><blockquote>
<p><strong>facetowall：</strong></p>
<p>有人说，高校里20%的人掌握着80%的资源和财源，本人深有同感。所以经常想怎样才能成为20%里面的人。每天也很努力工作着，科研教学也可以，但是总看不到希望。</p>
<p><strong>kkndme：</strong></p>
<p>从一个小吏变成中高级干部，是需要深入研究中国古代政治斗争史的。否则就变成了宋江，企图另立山头通过跳槽达到目的，最终的结果只能是失败。宋江是一个政治上的白痴。</p>
<p>还有一个白痴叫贾谊，我们所熟知的“过秦论”的作者，才高八斗，政治却很白痴。被文帝做了棋子。如果贾谊同志知道晁错的下场，是无论如何不会仗着有才胡说八道，口无遮拦的</p>
</blockquote>
<h2><span id="贾谊">贾谊</span></h2><p>贾谊的粉墨登场，是有很深的政治大背景的。<br>首先要从吕雉死翘翘，以陈平、周勃为首的功臣集团铲出了吕氏一党说起。<br>吕氏一党灰飞烟灭，小皇帝是个吕雉制造出来的傀儡，甚至跟高祖刘邦都没有任何血缘关系。<br>难题是让谁当皇帝呢？<br>于是中国历史上最为搞笑的一幕发生了，在高祖刘邦的子孙中要搞最弱外戚选举。</p>
<p>大概是被吕雉专权搞怕了，大家推举皇帝，专门看哪个皇子的外戚弱。于是众人的目光投向了刘邦的第四个儿子，代王刘恒。原因是刘恒的母亲薄氏出身低微，为人又很低调，堪当最弱外戚之名望。<br>提起薄氏，野史里记载的很香艳，很可以拍三级片</p>
<p>野史里说，楚汉争霸时期，高祖刘邦大败。<br>薄氏还是个姑娘的时候叫薄姬，逃难的时候占领了一个无人居住的民宅。忽然有一天看见一个浑身是血，穿着盔甲拿着兵器的男人闯进了自己的屋子，这个人就是刘邦。<br>薄姬听到后面有追兵，就把刘邦的盔甲和兵器藏了起来。然后放了一大桶洗澡水，把自己和刘邦脱光光，洗起了鸳鸯浴。追兵闯了进来，惊奇的看了一通三级片，然后走人。<br>这个只是野史，可信度不高，但是说明了薄氏的低微出身。</p>
<p>不管怎麽说，有着最弱外戚称号，并且做事很低调的刘恒当了皇帝。但是对于刘恒来说，陈平、周勃等功臣集团有着很高的声望，齐王刘襄是高祖长孙并且在铲除吕党是很有功劳，声望也很高，受到了很多人的支持，而刘恒却毫无功劳，因为功臣集团平衡关系，天上掉下了皇帝的帽子，砸在自己脑袋上。<br>所以刘恒必须提拔自己人，这个人不能有很高的功劳，也不能有结党的嫌疑，最好比较有本事能治理国家，于是大才子贾谊粉墨登场了</p>
<p>贾谊同志很有口才，一腔热血，要到现在来说最适合搞传销或者卖保险。<br>贾谊同志激愤起来甚至说：自己完全可以带兵打仗，灭了匈奴，把匈奴王象狗一样牵回来。”刘恒很贤德，但也很老谋深算，当然认为贾谊同志满嘴喷粪，所以一笑置之。<br>贾谊同志的胆子不是一般的大，向皇帝刘恒提供了一个深的帝心的建议：让所有的诸侯王滚回自己的封地。<br>为什么说这是深得帝心的建议？因为朝里功劳大的人太多，居功自傲，而自己却没有什么威望和功绩，如果功臣集团和齐王、淮南王联合起来造反怎么办？<br>所以，最好的办法就是让诸侯王滚回封地。汉代的诸侯王可跟周朝不同，周朝的诸侯王是有实权的，有自己的军队。而汉代的诸侯王只能收收领地的税，军政事务全说了不算。<br>这个事，从贾谊嘴里说出来最好不过。</p>
<p>汉代的京城是最繁华的，有全国最好的教育、医疗、商业，有钱人的天堂，大臣们都可以花天酒地。让诸侯王回到封地，大家都不干了，回封地有什么好？房价又低，又没什么娱乐，漂亮姑娘也不好找，偏远的地方气候还不好，梅雨一来全身都要发霉。<br>首先带头反对的是功臣集团的领袖周勃（陈平已经死翘翘了）。在历朝历代，多数皇帝并不是想干什么就干什么的。既然所有大臣都反对，那就先暂且作罢。<br>但是贾谊，已经为刘恒种下了希望的种子，给自己埋下了祸根。<br>贾谊注定了只能是一颗棋子。</p>
<p>贾谊的建议没有被采纳，估计很郁闷，成天滔滔不绝的演讲，甚至建议刘恒削藩，要是贾谊知道晁错的下场，一定不敢这么建议。<br>这时候，贾谊已经得罪光了朝中几乎所有的大臣。于是大家的不满全部转移到贾谊的身上。<br>刘恒要的就是这个效果。</p>
<p>随着政权的逐渐稳固，刘恒把矛头指向了周勃。给予周勃最高的赏赐，却经常在治理国家方面，询问一些周勃不可能知道的问题。让周勃很尴尬。<br>周勃有个门客，就对周勃说：“皇帝经常给你很多赏赐，您就安心的接受，这很危险。皇帝给你的赏赐越多，说明皇帝对您越不放心啊。”<br>功高震主，弄不好会有杀身之祸，周勃不是傻子，立刻明白了这个道理。所以周勃才能称的上除曹参外，最有政治头脑的武将，最后得了善终。<br>于是周勃就上表辞职，表示年老体病干不动了。周勃还期望皇帝能挽留一下，但皇帝一点挽留的意思都没有，立刻同意了。<br>刘恒让周勃起个带头作用，回到自己的封地去吧。并且赐予了大把的金银。其他诸侯王看周勃都走了，也扛不住了，只好都回到了封地，这叫射人先射马，擒贼先擒王。<br>刘恒为了安抚大家，把遭人恨的贾谊明升暗降，贬到了长沙，从此离开了政治中心。<br>后来有一天，刘恒想起了贾谊，找他来中央谈话。贾谊一见皇帝立刻滔滔不绝，把皇帝立马侃晕了。<br>刘恒想：我靠，这厮死不悔改，留着没用，有多远滚多远吧。<br>再次把贾谊贬到了梁国。<br>贾谊不多久就死了。</p>
<p>关于魏豹和薄姬是否有一腿，也不好就肯定，也是个悬疑。因为记载薄姬的版本太多，我国古代人也比较八卦，呵呵。</p>
<h2><span id="kkndme-推荐的历史书">kkndme 推荐的历史书</span></h2><blockquote>
<p><strong>welldayzwb：</strong></p>
<p>这个帖子最大的感受就是应该认真读一下历史了，麻烦楼主给列个入门级的书单，鉴于我的历史水平只有演艺级的，书单请尽量入门级，当然演绎过的就免了，别读历史还别人顺带洗脑，比较郁闷了</p>
<p>先再次表示感谢！</p>
<p><strong>kkndme：</strong></p>
<p>比较浅显的是“史记”，入门级基本都读的懂。如果开始觉得部头太大，觉得累，刚开始可以从“古文观止”入门。逐渐增加难度。<br>入门以后，很多古文就好读了。<br>现代翻译的一般都加工的比较多，同一部历史可能有无数个解释。象易中天和当年明月，都是写的不错的。</p>
<p>关于古文观止，很多文章都曾被节选进中小学课本，篇篇堪称经典，其中就包括贾谊的“过秦论”。不看过秦论真的不知道贾谊的才华呀。所以想读读历史的童鞋，不妨回过头再温习温习古文观止，边品茶边看，真是一种享受。</p>
<p><strong>EchoMa9999：</strong></p>
<p>楼主晚上好！<br>我看之前有跟贴的朋友提过，请楼主列个史书入门级的书单，我不求列了很多书的书单，只请楼主推荐三本，佛渡有缘人，楼主，望不吝赐书名，先谢了！</p>
<p><strong>kkndme：</strong></p>
<p>我觉得读史最基本的就是古文观止，读了古文观止，有了功底，再读其他的就好读了。<br>开始读的时候，通史类是很难看得进去的，象“资治通鉴类”的也不好读，因为“资治通鉴”应当算评史算不上史书。<br>入门开读的话还是选择文学性强的比较好读，故事性趣味性都高，比如“史记”“三国志”“汉书”。<br>有了兴趣再读大部头的“宋史”“明史”<br>现代编写的中国史纲之类的就不要读了，纯粹洗脑，很多加工过的历史类读物就是瞎扯。</p>
<p>特别是： 千万不要读“中国通史”那样的垃圾!!!!!!!!</p>
<p>一定要读懂原文，跟中国通史讲得完全不是一回事。读不懂原文宁可不读，也不要让中国通史洗脑。</p>
<p><strong>打工不易：</strong></p>
<p>请问楼主，范文澜的《中国通史》也不值一读吗？</p>
<p><strong>kkndme：</strong></p>
<p>从始至终以唯物主义角度阐述的历史，可信度究竟有多高？</p>
<p>唯物主义要很深的理解，比如子虚乌有的抢渡大渡河，就是唯物主义的杰作。</p>
<p>范对封建社会的理解，也很有问题，是唯物主义的需要，不能还原历史的真实</p>
<p><strong>welldayzwb：</strong></p>
<p>这个唯物主义的定义是什么？</p>
<p><strong>kkndme：</strong></p>
<p>我只能用唯物主义这个词，再直白就和谐了，呵呵</p>
<p>我们的历史教科书很多都出自中国通史，但是你真正熟读了史官的著作以后，发现那有多扯，歪曲的有点太不靠谱。中国通史我把它定义成政治类书籍，是政治需要产生的，专门用于洗脑，不能当史书读。</p>
<p><strong>EchoMa9999：</strong></p>
<p>楼主，简单研究了一下古文观止/三国志/汉书/后汉书/史记，古文观止，以目前的水平，看起来着实吃力，决定还是先从史记开始看起吧</p>
<p>淘宝上搜了一下，史记 （全四册），北方文艺出版社出版，2007年9月1号出版的，萧枫主编，绣像本，盒装， 这个版本的买来自读加收藏，可以吗？请楼主点评，谢谢！</p>
<p><strong>kkndme：</strong></p>
<p>古文观止可以买带注解的，但不要带译文的，看译文对读原文是有害的，可以通过注解提高古文水平。</p>
<p>史记买太好的版本，我是舍不得拿出来读，不能勾勾画画，我一定会把它高束焉,庋藏焉。读史记，最好买个普通本，带注解的，方便阅读，可边读边勾画，以提高阅读水平。</p>
</blockquote>
<h2><span id="年轻人要早买房">年轻人要早买房</span></h2><blockquote>
<p><strong>GGKMM：</strong></p>
<p>看了三天，终于看完了。。有些是一眼带过的，有些是比较认真的看下来的；</p>
<p>感觉回帖的筒子大多数都挺有钱的啊，至少相对我来说。因为都在计划一二百万的房子了。</p>
<p>本人在福州，目前月薪只有4K，但是福州市区的房产均价已经越过一万了，市中心的更是到了1.5万这样高不可及的地步。我就那楼主口中那种民企私企的体制外的P民了，属于自生自灭型的。但也还是得活下去啊，今年也二十五了，过两年也要结婚了。房子成为不可避免的头等大事；</p>
<p>不知道楼主对福州这样一个三线或者四线城市的房产怎么看待？平均工资水平约2000，有钱人据自己观察应该不少，至少超过20%的福州人口（有关这个，从大街上越来越多的好车做判断的，或许数字不准，但有钱人不少是肯定的）。如果在郊区能找到六千左右的小户型（65平左右），首付（还得存两年或者去借钱）自己掏，剩下的做货款，因为家里实在是没办法再支援了。这样的话应该还可承受，前提是付房贷的这二十年或者十五年里不失业。。</p>
<p>希望楼主给分析分析，写得有点乱。。。</p>
<p><strong>kkndme：</strong></p>
<p>25岁不是考虑失业的年龄，35岁体制外没有混出来的群众才应该考虑失业问题。<br>所以房子一定要趁年轻买，刚开始钱不够，就不要计较太多，先买个小的，以后有能力再换，如果没混出来，以后起码有个自己的窝住。不至于租房子被人赶出来。</p>
<p>福州是有点尴尬，明明是省会，又比不过厦门，不过市区1万左右的房价，在省会城市里真的谈不上高。你是自住，你又不打算去厦门生活，所以你该买还是得买。福州的房价也许涨得没那么块，但是也不可能跌。</p>
</blockquote>
<h2><span id="不要低估通货膨胀">不要低估通货膨胀</span></h2><blockquote>
<p><strong>someway2010：</strong></p>
<p>跟楼主请教一下：<br>楼主怎么看知春里小区的房子？那边连着双榆树小区，有大片的老房子，都是6层的板楼，都是上世纪8、90年代建的。环境看起来有点乱，以前的老公房，原单位早就没了，物业基本等于没有。将来拆迁的可能性有多大？值得买不？</p>
<p><strong>kkndme:：</strong></p>
<p>只要是4环内保值升值不会有问题，那个位置还是可以。关键是看投资还是自住，如果是自住，我就觉得那边有点乱糟糟的，不舒服。挨着中关村其实住着都不舒服，但不耽误升值。</p>
<p><strong>someway2010：</strong></p>
<p>多谢楼主，是自住~因为老公在中关村上班，想离公司近些，所以就挑了那里~是挺乱的，唉~<br>希望以后等我们有钱了能换个别的地方的大房子，不过按照楼主的分析这个是极有可能实现不了了。。。5555<del>~</del>~<br>再问一个，现在市场上卖200w的房子，十年后大概会涨到多少钱？麻烦楼主</p>
<p><strong>kkndme:：</strong></p>
<p>80年代你想象不出以后一瓶茅台会卖1000块<br>现在你同样想象不出十年后你的房子能卖多少钱。<br>那时也许人民币都是1000块一张的</p>
</blockquote>
<h2><span id="二三线城市与重庆">二三线城市与重庆</span></h2><blockquote>
<p><strong>dali_05：</strong></p>
<p>浏览了楼主观点，和我之前的货币推动楼市的看法完全一致<br>但由于无法像楼主那样掌握一些基础数据，对一些楼市的演变细节还有几个疑问</p>
<p>，还请lz指点<br>（1）二三线城市在这轮调控中的增长不出意料，但是二三线城市的房价增长，我始终认为存在一个最终谁接盘的问题。我是重庆人，以重庆为例，这个城市代表了典型的二三线城市。外来人口少，特别是外来的普通白领阶层。据我了解的数据，2008年之前，重庆的具备房子购买力的人群任然是净流出。到08年后才得以改观。但是流入任然缓慢，这也就是意味着重庆的楼市将没有长期稳定的接盘群体。而本地人，没有房子的是非常少的。在没有外来人群接盘的情况下，本地人在有房的情况下，任然投资囤积房产，最终，这些房产将如何变现。</p>
<p>一句话，房价要持续的上涨，还得有没房者接盘，而且这些人还得要有购买力。多次购房者无法稳定的解决这个问题。那么我就有理由对这样的二三线城市的房产前景表示担忧。</p>
<p><strong>kkndme：</strong></p>
<p>重庆房价的上涨得益于zy的战略规划，打造中国的大后方，把重庆的经济发展提升到了政治的高度。因为如果发生战争，重庆将变成第二首都，是中国最安全的大后方，蒋同志就很有眼光的选择过重庆。<br>重庆并不是以城中心为核心向外辐射的城市，繁华区域相对比较分散，所以房价很难快速上涨。这也就是过去重庆长期滞涨的原因。<br>重庆房价的崛起可以说完全是中央规划概念推动的，至于日后是否会吸引大量的精英和富人来重庆发展，我想一定可以。作为上升到国家政治高度的发展计划，就算是代价再大，也一定会搞得起来。</p>
<p><strong>dali_05：</strong></p>
<p>（2）高端房产还是普通住宅？<br>看了lz的观点，认为高端房产，由于其稀缺性，更具价值。<br>但我认为，房产和古玩还是存在差别的。古玩最大的价值在于收藏把玩，只要有钱，买再多古玩来玩都无所谓。但是房产不一样，房产的价值除了和古玩一样的投资外，真正的功能在于居住。但是目前的二三线城市，精英阶层的数量是非常有限的，他们谁没个3，5套别墅，在没有外来精英加入购买的前提下，这些高端的房产也就是在精英圈子中流转，这样封闭的流转，如何实现价值的增长呢？</p>
<p>要知道，在2，3线城市，普通白领阶层能跳出自己的阶层而具备购买高端房产能力的概率是非常小的，不具有代表性。那这些每个富人，有权人都有很多的高端房产有什么价值可言？</p>
<p>而普通住宅由于有普通白领的接盘，是否投资价值更大？</p>
<p><strong>kkndme：</strong></p>
<p>二三线城市房价的支撑，要因城市而异的，大体上二三线城市的核心区域与高端住宅区都不会有问题。毕竟一线城市的体量，不可能满足全国中产以上群体定居，而且一线城市随着竞争的日益激烈，钱也不是那么好赚的。有很大比例的富裕人群仍会选择二三线城市生活。<br>中国的二三线城市的富裕人口，要比大家想象的多的多，特别是二三线城市，有相当比例的人口都有较高的隐性收入，权力寻租现象更为严重。</p>
<p><strong>dali_05：</strong></p>
<p>（3）长期持有房产的变数<br>中国房产只有70年，甚至50年的使用权，如果长期持有，随着时间推移，房产价值是否会受到影响。因为我在重庆，这个问题尤其严重，重庆只有50年。</p>
<p>如果我只是持有，出租。那我的租金将是较低的（相对房价而言），因为zf不会允许房租像房价那样疯涨，原因和粮食问题一样，基本需求嘛。那有可能50年到了，我的房租收益实际上还抵不上房款的综合支出。而那时房子早就是危房了，强拆将是完全可能的情况。那做为普通人，怎么可能和zf在赔偿上博弈。这个风险lz是怎么理解的？？</p>
<p>我的理解是，房子不能长期持有，必须在5年左右变现，否则将存在贬值和变现难度加大的风险，请lz指点</p>
<p><strong>kkndme：</strong></p>
<p>关于中国的房产能够持有多少年的问题，这要持续观察zf的动向。对于现在的80后来说，如果在有生之年能够平安度过，不经历大的动乱，已经是很值得庆幸了。<br>如果有动乱发生，即使你没有买房，你手中的现金也将变成废纸。</p>
<p><strong>dali_05：</strong></p>
<p>（4）天津现象（或者即将出现的重庆现象）<br>天津房价在二线城市中增长是惊人的，但收入水平并没有达到那样的高度。这种依靠所谓开发区吸引资金推动房价的模式，是否具备可持续性？？</p>
<p>我认为真正的天津常住精英阶层的资金实力是无法支撑这样的价格的，只能理解是外来游资的介入，推高了价格。<br>我想问的是，这些游资有可能退去吗，一旦退去，面临的风险是否很大。</p>
<p>据我的理解，中国真正成功的开发区，都是由于本身的条件好，而非开发区本身的作用。</p>
<p>比如深圳，享受的是经济转型的首发政策优势。上海浦东是由于本身就实力雄厚。而所谓的滨海新区，重庆两江新区，本身实力就不过如此，即使要真正实力上来，那也将是非常漫长的过程。那这些进入房地产的游资，将在概念炒作一遍之后，获得一定收益后撤出，一旦撤出，这些地区的房价将会是怎样的趋势？</p>
<p>放眼中国，房价高的地方无不是富人集中，或周边富人多的区域。天津重庆这样的地方，一旦外地资金撤出，将何去何从？</p>
<p>（5）新兴城区和老核心城区<br>新兴城区环境好，轨道交通也使得原本偏远的新兴城区变得方便起来。那老核心城区的房产是否不如这样的新兴城区有价值。这个问题一直很困惑。因为我是重庆人，这个问题尤其明显。现在重庆房价最高的是以前的郊区，江北，渝北。而传统的渝中，房价反而排着中等水平。这和北京的一二环贵，上海的黄埔徐汇贵完全不同。这样的状况具备可持续性吗，还是仅仅是阶段性的。但是感觉现在zf的规划更倾向于向外发展，避免主城区拆迁的高成本，这会否导致传统主城区的边缘化</p>
<p>先问这几个问题，困惑很久了，期待lz的高论</p>
</blockquote>
<h2><span id="城区和郊区">城区和郊区</span></h2><blockquote>
<p><strong>hey-hey：</strong></p>
<p>楼主 我在上海， 小白领一枚。最近想买房。稍微好点的区均价已经至少2万5+了， 现在考虑在其他价格洼地的区买套新房，看中了均价1万7左右，买90送30，到手面积120左右。此楼盘开发建造定位2万/米以上，因政策调控，故现1万7。好处是小区规划不错，属大型国企房产公司，2012年交房。附近有超大型公园，地铁明年开通（升值利好），附近有医院，学校，路上看到的在建建筑较多（百废待兴）。不好处是离上班开车要1个小时，属工业区（在另外一个方向），路上集卡较多，有传空气质量不好。 </p>
<p>另外一个选择是在市中心或其他比较好的区买个小房子，大概5、60平方米左右，预算也是180万左右。 好处是地段好，租金回报可能较高。如果自住相对比较方便。</p>
<p>单身，买房投资愿望大于自住愿望。 请楼主给分析分析。谢谢</p>
<p><strong>kkndme：</strong></p>
<p>多数人买房子都是郊区买个大的，后来上班实在不方便，再想办法城里买套小的。住郊区牺牲时间，住城里牺牲面积。总得来说，还是住城里更方便些。<br>关于房价升值，一定是郊区和城区版块轮动的。当郊区房价较低时，资金就会关注价值洼地，当郊区房价炒起来以后，城区的房价跟着上涨，但总的来说，城区的房价涨幅一定高于郊区，且比郊区更抗跌。</p>
<p><strong>hey-hey：</strong></p>
<p>谢谢楼主。真是纠结阿。一样的钱想买个新点的。而且周边的觉着还有这样那样的优势，比如公园，比如现在的性价比。比如大了一倍。比如该区未来发展空间和前途。如路建好了地铁修好了，城市辐射发展的面扩展了。<br>市区现在虽然完善，但未来没什么发展空间，该发展的都饱和了该配套的都配好了。升值的空间是否相对就小了。 </p>
<p>还请楼主再给说说。</p>
<p><strong>kkndme：</strong></p>
<p>你说的其实还是性价比的问题，比如郊区（前提是配套能发展的起来）1万7，城区2万5，那肯定是选择城区，毕竟相差不大。如果郊区1万7，城区3万以上，那肯定选择郊区。<br>好比北京的通州，城区2万的时候，通州8000，肯定选择通州，升值会快。但城区3万，通州2万5的时候，肯定会选城区。</p>
</blockquote>
<h2><span id="守着金碗要饭吃">守着金碗要饭吃</span></h2><p>守着金碗要饭吃，最典型的就是老一辈玩田黄寿山石的，收藏了一屋子石头，穷了大半辈子，第一次参加石头交易会，居然发现自己随便拿块石头出来能卖上千万。</p>
<h2><span id="人制的社会人就是制度">人制的社会，人就是制度</span></h2><p>让李荣融来讲垄断巨头的功劳，这个事很有意思。</p>
<p>西汉时期，功臣集团和他们的后人势力比较大，大街上瞎晃的黑社会头子比较多，皇帝提倡以法治国，靠法律来制约功臣集团，先是重用了皇宫守大门出身的张释之大法官。<br>张法官完全按法律办事，该杀头的绝不会流放，但是该流放的也绝不会杀头。张大法官实现了我国历代百姓追求的天下无冤民的梦想。<br>史书上记录：汉文帝车驾过中渭桥，一个人从桥底下突然钻出来把皇帝的御马惊了，刘恒很生气，让张法官治他的罪。张法官审讯后发现是个意外，属于民事事件，打算罚点钱放掉。刘恒不干了，那可是惊了圣驾呀。罪该杀头。张法官却认为：律条上没有说因意外惊了圣驾就必须杀头，按律条就应该罚钱放人。要不然陛下你就不要把这个人交给我审，直接杀掉算了。既然陛下让我审，就必须按法律办事。刘恒只好按照张法官的审判结果，放掉了那个人。<br>其实，遵守法律，按照法律办事的不仅仅是张法官，而是刘恒自己。刘恒为了保证社会安定、基业长青，就必须限制特权阶层，限制特权阶层就必须依法治国。<br>但是文景之后，武帝就不满足于完全依法办事的张释之法官这样的人了，而是开始重用酷吏，张汤、义纵、宁成这些新一代法官登上了历史舞台。法律是什么？法律就是张汤，张汤就是法律，犯了法的要往死理打，没犯法的也要往死里打。<br>唐朝武则天时期，出现了一个史无前例的酷吏：来俊臣。<br>来俊臣法官不管法律专搞冤狱，专门养了一大群打手无赖，凡是武则天不喜欢的人，还有他自己不喜欢的人，一律刑讯逼供，屈打成招。发明的酷刑比张汤有过之而无不及。<br>古代，法律是什么？是皇帝？是张释之？是张汤? 是来俊臣？其实，法律什么都不是。</p>
<h2><span id="准公务员的好处">准公务员的好处</span></h2><blockquote>
<p><strong>xufangliang1120：</strong></p>
<p>楼主，请问新进公务员队伍的人员今后还会不会有住房福利。像年纪大的都有分房或定向开发的商品房，已经分过了。象新进来的，工资不高，每月不到2000，平时无任何待遇，过年也就发个千来快意思意思。我在湖南常德，这里的房价也在4000左右，今年涨起来的。象我们这种情况要怎么办才好？请您指教！！谢谢！</p>
<p><strong>kkndme：</strong></p>
<p>大哥，公务员也是有级别的，想想宋江为什么上梁山呢？<br>你要是在重要部门，或者到了级别自然就有了。<br>西汉的张释之，冯唐、郅都都是皇宫守大门的出身。皇宫看大门的，不算是公务员，是体制外编外人员，相当于协管员，连工资都不发，但为什么大家都趋之若鹜的争当皇宫传达室老大爷这种有前途的职业？因为，可以有机会见到皇上，有机会成为高级公务员。当上了高级公务员，你就有了票子房子妹子。</p>
</blockquote>
<p>最著名的皇宫传达室看门老大爷叫冯唐，头发都白了还在未央宫值班呢。皇帝刘恒没事瞎溜达，看见老大爷一脑袋白头发，就叫过来神侃。不侃则已，一侃才知道冯大爷的爷爷是赵国的官帅将，跟大名鼎鼎的名将李牧是哥们。而且冯大爷不愧是名将之后，太懂带兵打仗的道道了。<br>刘恒说：我要是能有李牧这样的大将，还怕什么匈奴啊。<br>冯唐很牛叉的说：就是有李牧这样的大将，也得不到重用。<br>冯大爷直接把皇帝气晕，皇帝转身就走了。<br>后来刘恒气消了，又找冯大爷问话。<br>冯大爷就说了一番大道理：<br>对待将士，要以激励为主，才能得到将士拼死效力的心。重惩罚，轻奖励，光拿大棒不掏胡萝卜，将士怎么肯用命呢？（皇帝是信奉法家的，法家的精神领袖商鞅同志认为管理手下最高境界就是基本不怎么用胡萝卜，直接用大棒的最牛——罚九赏一。）<br>云中太守魏尚是个名将，让匈奴文风丧胆。魏尚的手下都是农民子弟，魏尚对待士兵很好，很舍得犒劳，也和舍得给钱，所以大家都很拼命。但是陛下您经常因为军兵的一点小错误，就扣掉军兵的赏赐，因为魏尚虚报了几个斩获的首级数量，就把魏尚抓起来关监狱，奖励太轻，而惩罚太重了。所以说陛下有李牧这样的良将也不能重用。<br>刘恒大悟，拜冯大爷为车骑都尉。<br>唐代的王勃，很不得志，于是写了《秋日登洪府滕王阁饯别序》:“嗟乎!时运不齐，命途多舛;冯唐易老,李广难封。” 冯大爷一下子因为王勃的文学作品，家喻户晓了。</p>
<h2><span id="小城市房价会因为人民币贬值涨价但依然难变现">小城市房价会因为人民币贬值涨价，但依然难变现</span></h2><blockquote>
<p><strong>xufangliang1120：</strong></p>
<p>楼主,谢谢您的回复!<br>你您怎么看常德的房价呢,那我们现在还是想点办法先买房?</p>
<p><strong>kkndme：</strong></p>
<p>买一套自住房还是应该的，不是所有公务员都能够上位，也不是所有公务员能够分到房子，特别是二线以上城市，将来普通的底层公务员住公租房的可能性更大。</p>
<p>对于小城市，房价也会因为人民币的贬值而上涨，只是可能不如大城市好变现而已。所以，有能力还是应该买一套自住房的。</p>
</blockquote>
<h2><span id="一线杭州">一线杭州</span></h2><blockquote>
<p><strong>钱江风帆：</strong></p>
<p>看了个通宵啊，不知楼主对杭州了不了解，目前市区大概25000/m2,杭州未来房价的趋势如何？</p>
<p><strong>kkndme：</strong></p>
<p>杭州我都当一线城市看的，你就当一线城市理解。富人的天堂，房价多高都不稀奇</p>
</blockquote>
<h2><span id="二三线城市的发展靠拆迁">二三线城市的发展靠拆迁</span></h2><blockquote>
<p><strong>dali_05：</strong></p>
<p>支持楼主房价大涨房租必涨的观点</p>
<p>但是这仅限于外来人口众多的一线城市<br>二三线城市本地人几乎没有没房的，如果算上父母的，将来普遍一个家庭拥有两套以上的房子<br>房租也就失去了大涨的基础<br>唯一可导致房租上涨的就是拆迁，一旦便宜的旧房子少了，房租肯定是要上调的<br>但那也是有限的<br>总之，外来人口极其可支配收入是房租的决定性因素</p>
<p><strong>kkndme：</strong></p>
<p>二三线城市的敛财和追求政绩方式，全靠大规模拆迁，城市搞升级改造，这个拆迁规模是一线城市市民难以想象的。有的城市已经搞得如火如荼了，有的城市还没开始，但都会走这一步。</p>
</blockquote>
<h2><span id="转篇文章一个忽悠了几亿中国人的伪概念所谓中国房地产泡沫">转篇文章：一个忽悠了几亿中国人的伪概念：所谓“中国房地产泡沫”</span></h2><p><strong>中年不惑吗：</strong></p>
<p>一个忽悠了几亿中国人的伪概念-所谓“中国房地产泡沫”</p>
<p>作者：罗伯特卡帕</p>
<p>中国大陆大家目前最为关心，讨论最为热烈的一个问题就是中国的房地产泡沫问题。从政府到民间，从经济专家到普通百姓，大家都在关注这个问题。以前，我也觉得中国存在一个叫“中国房地产泡沫”的所谓概念，但今天我忽然感悟，原来多少年来包括我在内的几亿中国人都被蒙骗了，中国根本就不存在所谓“房地产泡沫”的问题，“房地产泡沫”这个概念本身就是一个伪概念。</p>
<p>如同市场经济一样，房地产泡沫也是一个外来事物，它是市场经济的产物。但问题是，中国是市场经济吗？显然不是，否则为什么大多数西方国家都不承认中国是一个市场经济国家。尤其是中国大陆的房地产市场，更不是市场经济，而是计划经济与市场经济相结合的一个怪物，政府操纵着房地产行业，政府对房地产有着绝对的掌控能力。</p>
<p>房地产泡沫是市场经济的产物，既然是泡沫，那么这个泡沫也会遵循市场经济的规律，即当泡沫足够大的时候，会破裂。因为日本与美国的经济是市场经济，所以当日本与美国的房地产产生泡沫的时候，就会破裂。</p>
<p>目前包括中国在内的几乎所有世界经济学家都以为，当年日本与美国的房地产泡沫破裂了，中国的房地产泡沫比日美大几倍，当然也会破裂。事实却是，中国的房地产泡沫在几年年前的膨胀程度就超过了当年日本与美国的房地产泡沫，中国的泡沫几年来虽然翻倍，但却没有破裂，这是何故？显然，经济学家们犯了一个错误，那就是把中国的房地产乃至中国经济当成了市场经济来看待，而事实是中国的房地产市场根本不是市场经济。所以，西方市场经济国家所有的房地产泡沫，在中国也根本不存在，所谓的“中国房地产泡沫”根本就是一个伪概念。</p>
<p>当然，我说到这里时，肯定有很多人不服气，中国的房地产明明几年之内翻了很多倍，远远超过了普通人的收入水平，这不是泡沫这是什么？我的回答是，中国的房地产价格确实虚高，远远超过普通人的收入水平，这是事实，但这不是“房地产泡沫”，因为泡沫会破，而中国的这个被大家称为“泡沫”的东西却不会破，因为它的真实名字其实不叫泡沫，应该叫“变相的税收”或者“房地产垄断价格”。</p>
<p>中国的房地产业本质上已经不是一种行业，像中国大陆的税收与垄断行业的垄断价格一样，成了少数人剥夺多数人财富的一种工具。在这个工具上，寄生着很多食利者。这个食物链的最上层为地方政府，地方政府通过卖地与房地产税收，养着一大批高薪的公务员及满足他们的奢侈需求。食物链的第二层为与官员勾结的房地产商以及受贿吃回扣的官员，第三层是炒房者，炒房者相当部分为拥有大量现金的官员及家属。</p>
<p>市场经济的泡沫会破裂的，但中国的房地产不是市场经济，房地产价格也不是“泡沫”，所以它也不会破裂。中国的房地产价格被政府严格操控着，不说是操控自如，也是有绝对的控制力。因为政府掌控着土地银行汇率等房地产的关键要素。中国的高税收是泡沫吗？中国的垄断行业的高垄断价格如水价电价油价是泡沫吗？当然不是，他们是转移财富的手段。中国的房地产价格也是一种变相的“税收与垄断价格”，其“税率”与“垄断价格”是政府控制的。这也解释了为何中国几年来房价如此之高，却不下跌，所谓“泡沫”却不破裂的原因。</p>
<p>中国房地产的所谓“泡沫”会“破裂”吗？会，只要政府愿意。中国的房地产的“泡沫”会不破裂吗？会，只要政府愿意。</p>
<p>其实，中国所有的问题都是政治问题，而不是经济问题，离开政治谈经济，永远找不到问题的答案。</p>
<h2><span id="拆迁补偿">拆迁补偿</span></h2><p>拆迁补偿的两种方式：1、现金补偿；2、回迁安置。<br>在二三线及以下城市，通常采用第二种，因为多数开发商没有钱现金补偿，房地产开发基本上是靠zf关系，空手套白狼，就是有钱也不愿意拿出来。<br>对于拆迁户来说，现金补偿也不划算，因为补偿的现金在与原地同级别的位置肯定是买不了相同面积的住房的，所以多数拆迁户选择回迁安置。<br>但是越小的城市开发新盘的速度越慢，往往回迁房盖个三五年也不见得盖得起来。在这期间，开发商会按月补偿拆迁户一定的租金，用于过渡。<br>手里现金多的拆迁户会先买房住，慢慢等拆迁，但是现金不多的拆迁户，就不得不拿着开发商的过渡款租房住。通常这笔过渡款都要高于相同位置的租金，所以拆迁户就把房租炒起来了。</p>
<p>北京已经没有原地回迁的说法了，一线城市，还有部分较发达的二线城市都不搞原地回迁了，土著一旦拆迁了就赶到郊区。反而是二、三线城市，特别是三线以下城市多数还在搞原地回迁。主要原因是城市小，住户多多少少都有些背景，特别是单位的老公房，开发商不让原地回迁，根本就拆不动，阻力太大。</p>
<p>房子从拆到迁是有时间的，快的情况是1年多，但很多情况都是拆迁安置房3,4年盖不起来。比如昆明的莲花池片区，大概是06年左右拆迁的，但拆迁安置房现在才开始动工，2012年才盖的起来。这种事情并不是个案。<br>贵州更离谱，房子04年拆了就再也没有音讯，开发商一直盖不起来，到现在都6年了。原来的拆迁户，现在还在租房住。</p>
<h2><span id="城市底层">城市底层</span></h2><blockquote>
<p><strong>游泳横渡马六甲：</strong></p>
<p>经常有人说收入是决定因素，其实人均收入没有意义。北京姑娘去外企做前台一个月2000，和公司外地姑娘拿这么多，和做公务员的外地姑娘拿这些，生活成本天差地远。不是说有10万个月入2000的外来人口，四环内就有一万处他们能承受的住房。而个体的外来人口的支出，会随着生活成本调整。开始很难理解月入两三千的白领在北京市如何生活，毕竟他们不可能像楼下卖蔬菜水果的大叔那样，炖点猪肉粉条就算开荤，穿特价五块的汗衫就算工作服。一样的月入，白领的幸福起点高得多。后来知道他们原先偶尔用兰蔻改成一直用大宝，早餐不再喝豆浆，住单位附近的搬到五环外，有人在燕郊买了房……突然想起小时候学新概念英语，说起蓝领工资比白领高，但还有人为了能西装革履宁可减薪做白领。</p>
<p>对80后而言，最恐怖的绝不是房价，而是养老。这也不是计生的问题，一个社会的生活资源是有限的，老龄化早晚会到来，为了改变老龄化呼吁多生育，那是饮鸩止渴。等多生出来这部分老了，再这么循环？而福利社会如英国是50多岁的人最幸福，有稳定养老金，二三十岁最痛苦，看不到未来依靠。家底不厚的像希腊，透支做社会福利，后果还不如不做。中国则是取不足以奉有余，竭全民之力供特权阶层挥霍，没有哪个年龄段享受过全民福利，还得共同面对养老难题。房子，真不算此生最纠结的事</p>
<p><strong>kkndme：</strong></p>
<p>正是如此，以后城市的底层吃饭都是问题，zf最喜欢拿房子说事转移矛盾</p>
</blockquote>
<h2><span id="垄断企业">垄断企业</span></h2><p>我们的垄断企业其实都是第二税务局的角色，比如石油、移动、电力、水务、地产、银行等等。zf一定要掏空百姓的钱包，所以说什么泡沫不泡沫，就是个笑话</p>
<h2><span id="农村自来水">农村自来水</span></h2><p>说起农村建自来水更搞笑，亲眼目睹要不然真不敢相信。<br>贵州有个村子，以前，自来水是村子集体出钱买的管子，然后全村出劳力从山上接下来（用的山泉水），要是水管坏了，大家再摊钱摊劳动力修。<br>结果zf不愿意了，说他们修的不规范，zf给重新修，还是从山泉引水下来，zf包给工程队换了一下管子，然后每户给按了水表，安好了以后，要按照2块钱一吨收费，全村都炸了窝了，集体抗议，现在还没有结果。</p>
<h2><span id="袁盎">袁盎</span></h2><p>丛林社会就是要承认人与人之间的差别，性格决定命运。<br>我要讲一个奇人，这个人叫袁盎。故事的出处是《史记·袁盎晁错列传》，如果鸡冻同志认为我瞎编，可以自己去看原文。</p>
<p>袁盎同志的神奇是一般人都无法想象的，这个奇人在吴国当相国的时候，他手下的一个小公务员跟老袁同志的爱妾乱搞，经常背着老袁嘿咻嘿咻。老袁知道了这个事就装聋作哑。<br>有人跟那个小公务员说:坏了，你跟袁领导的二奶私通的事让袁领导知道了，你死定了。<br>小公务员一听吓坏了，骑了马就跑，公务员这份全世界最令人羡慕的工作也不要了。<br>小公务员一跑，袁领导就使劲追，小公务员就更拼命跑，袁领导就更拼命追。袁领导的马要好一点，跑的快，终于把小公务员追上了。小公务员只好下马等死。<br>袁领导急了，对小公务员说：你跑什么呀？我正打算把我的二奶送给你。兄弟如手足，妻子如衣服。大概就是这个意思。<br>小公务员感激涕零，抱着袁领导的二奶继续嘿咻。<br>所以说老袁这人最仗义，人缘最好。上下都买他的帐。</p>
<p>老袁也有个把敌人。老袁在皇宫里当小跟班的时候，得罪了汉文帝宠爱的一个太监叫赵谈的，所以特别害怕，怕赵太监哪天找茬把自己给黑了。<br>老袁征求了侄子的意见，认为自己应该先下手为强，应该当众侮辱一下赵太监，这样如果赵太监再黑自己，就没人信了，别人都以为是公报私仇。老袁的政治手腕还是相当高的。<br>一天，文帝刘恒跟找太监坐在一辆车子里外出，老袁上前拦住车子，大义凛然的说：能够跟天子共乘一车的，都是天下豪杰，天子怎么能跟一个没小鸡鸡的人坐一辆车呢？<br>赵太监当场就气哭了，还不能说什么。以后赵太监要黑老袁，也没那么容易了，因为大家都知道老袁义正言辞，充满正义的得罪了赵太监，如果赵太监再说老袁坏话，就是公报私仇。</p>
<p>老袁的人缘是公认的好，但是在朝里有一个最大的敌人，就是大名鼎鼎的晁错。<br>晁错这个人学的是商鞅之术，法家的代表人物。为人冷酷，不讲人情，人缘特别差。老袁和晁错关系不好，可能跟两个人的性格很有关系。<br>晁错跟贾谊很有一拼，特别喜欢喷，口才也特别好，跟贾谊同志喷的内容也差不多，一会儿说打匈奴其实很简单啦，一会儿说必须削藩啦。刘恒听晁错喷的很有水平，很欣赏，但是刘恒不是傻子。<br>打匈奴？那得是国力强大以后的事，现在必须让老百姓修养生息。<br>削藩？我也想削藩，但是总得有合适时机才行啊，现在削藩不是逼人造反吗？<br>刘恒对晁错这种人的态度就是，你建议你的，我听听就可以了，不能当真。</p>
<p>晁错同志懂得要想发达，必须选择一个有前途的职业，所以凭着他气死保险推销员的口才，当上太子的老师。这个太子就是汉景帝刘启。<br>晁错的时代终于来了，原因是刘恒挂掉了。<br>刘启生下来就是锦衣玉食，可没他老子那两下子，也不怎么懂帝王之术，晁错说什么就是什么。<br>晁错于是抖起来了，不知姓什么了，仗着是皇帝的老师，飞扬跋扈，人缘极差。晁老师最爱追求政绩，立刻提出削藩。<br>削藩的结果就是吴楚七国反了。<br>这个故事跟明代朱允文同志的削藩如出一辙。明朝朱允文同志削藩的结果就是朱棣反了，当了皇帝。朱允文被迫流浪，泡吉普赛美眉去了。<br>吴王不是朱棣，性格有点象袁绍，生性多疑，手下有人才不会用，所以没能成大事，被周亚夫跟干掉了。如果吴王能有朱棣的本事，汉朝的历史就会改写。</p>
<p>吴王一反，老袁就着急了。老袁给吴国当过相国，吴王造了反，晁错必然要借机宰了老袁，老袁觉得自己冤枉啊，吴王造反不是你晁错逼的吗？<br>晁错果然趁机对老袁打击报复，安排了两个手下去弹劾老袁。但是晁错的人缘实在太差了，老袁的人缘实在太好了，那两个手下竟然不同意弹劾老袁。而且还劝晁错,大意是：现在七国兵马造反了，形式很危急，我们还搞内斗就不好了。老袁这个人是不可能参与谋反的。<br>晁错也着急叛乱的事，就把老袁放一边了。政治斗争，不是你死就是我活。<br>晁错错了，赔进了自己的老命。<br>窦婴同学也曾经在吴国当过相国，立刻跟老袁站在了一条战线上，准备给晁错来个致命一击。<br>晁错这个人的死，完全是他自己性格造成的，对人苛刻，政治上又是白痴。吴楚七国打着“诛晁错，清君侧”的名义造反，皇帝问晁错应该怎么办?<br>晁错的白痴精神充分发挥了出来，“陛下您御驾亲征，臣留守长安，做好看家的工作。”<br>皇帝估计当时心里要多愤怒有多愤怒。你自己惹的祸，你一个当臣子的在家躲起来，让我当天子的上去当炮灰，你是何居心? 不过刘启涵养好，没说出来。<br>这时候老袁跑了进来，说有平乱之计，要单独跟皇帝说。刘启很不客气的就把晁老师请了出去。<br>老袁立刻献计，既然反叛打着清君侧的名义，就先把晁老师宰了，叛军就出师无名了，就得不到老百姓的响应，事情就好办了。<br>刘启一听挺高兴，正恨晁老师让自己当炮灰的事呢，立刻同意，腰斩晁错。<br>晁错的下场要比贾谊惨多了。</p>
<p>不过老袁的下场也并不好。皇帝的老妈想让皇帝的弟弟梁王在刘启驾崩后继承皇帝这份工作，但是老袁不同意，坚决表示反对，得罪了梁王。<br>梁王不是一般的高级公务员，最喜欢搞黑社会，找了杀手把老袁干掉了。<br>这个故事又告诉我们，即使人缘再好，在政治斗争中活下来也是不容易的。</p>
<blockquote>
<p><strong>welldayzwb：</strong></p>
<p>最好把历史故事表达的直白的意思讲出来，不排除观众里像我这么愚钝的人不少</p>
<p><strong>kkndme：</strong></p>
<p>我说的不是袁盎也不是晁错，说的是削藩，皇帝削藩怎么样？看看朱允文的下场，晁错几乎独揽了大权，削藩的下场是什么？腰斩。清查空置率，zf不参与一级开发，不是扯淡吗？</p>
</blockquote>
<h2><span id="二三线城市选新城还是老城">二三线城市，选新城还是老城</span></h2><blockquote>
<p><strong>wofuleyumin1：</strong></p>
<p>楼主 我又有问题了。。。。请务必回答 谢谢</p>
<p>1。目前很多城市开发新城 我们主要谈二三线城市吧。。。这些地方的新城会超越老城吗？ 我们投资该投新城还是老城？</p>
<p>比如成都 南边的天府新城，口号国际城南。。</p>
<p>2。投资一定投越靠市中心越好吗？ 比如成都，西三环是比东二环还好。。但未来2环是否最终比3环好？</p>
<p><strong>kkndme：</strong></p>
<p>拆迁是块硬骨头，不够铁腕的领导会避开破旧但繁华的老城区的问题，转而开发新城，所以往往形成倒挂，即新城一下子变成了新贵聚居区，新城的房价甚至高过老城区。 但这是一种倒挂，老城升级改造是必然的一步棋，只是时间的早晚。未来老城区的升级改造，老城区的价值就会凸显，价格要远远高于新城。</p>
<p>但是老城区的多数老房子都可能面临拆迁，投资老城区的老房子不见得划算，特别是二三线城市的拆迁，离皇帝越远的城市，争取合理补偿越困难。</p>
</blockquote>
<h2><span id="在中国普通人手上闲钱不多的人被剥削">在中国，普通人手上闲钱不多的人被剥削</span></h2><blockquote>
<p><strong>抽着雪茄喝着绿茶：</strong></p>
<p>兰州，我近来盛干人民币的贬值力度之强烈<br>现在手上还有十万的盈余<br>做什么好呢<br>咬紧牙关供一套房？买黄金？还是买车呢？<br>总之不能空放着，<br>这样通货膨胀下去，汽车的价格也会涨吗？</p>
<p><strong>kkndme：</strong></p>
<p>买车是消费，不是投资，如果追求享受，可以买车，但不能保值增值。汽车属于工业品，通过扩大生产规模可以使边际成本下降，所以汽车会因为档次的不同有涨有跌。<br>黄金可以适当配置，但由于黄金的定价权不在国内，所以买黄金有一定的风险。<br>十几万买房子估计不够首付，除非特别小的城市。但小城市的房产变现起来比较麻烦。<br>至于古玩字画茅台酒之类的，真假难辨，不是专家很难参与投资，且一般人变现还是很困难的。<br>所以资金越小，资金实现保值增值越困难。我国实行的高通胀低利率政策，是对手中闲钱不多的普通群众赤裸裸的剥削。而手中闲钱较多的中产阶层，相对好一点，可以投资住宅商铺进行保值增值。</p>
</blockquote>
<h2><span id="三分天注定七分靠打拼">三分天注定，七分靠打拼</span></h2><blockquote>
<p><strong>汝爱之罪：</strong></p>
<p>从晁错的上位过程可以看出，口才很重要</p>
<p><strong>kkndme：</strong></p>
<p>呵呵，这个也不一定，一个是看老板的风格，一个是看自身的运气。<br>说汉文帝刘恒去参观皇家动物园（上林苑）就问动物园园长：“咱们动物园有多少动物啊，都有什么品种啊？”一下子把园长问晕了，吭吭叽叽答不上来。<br>这时有个负责老虎的工作人员跑了出来，作了一通汇报，如数家珍，回答的头头是道。刘恒特别高兴，觉得这个管理老虎的工作人员口才特别好，想提拔他当动物园园长。<br>这时候张释之蹦了出来，对皇帝说：秦朝的时候，赵高口才就特别好，特别巧言善辩，结果忠厚的大臣都被迫害了，天下大乱，秦朝完蛋了。陛下要是提拔这个管理大老虎的人，恐怕所有的大臣都会效仿他，专门学习卡耐基演讲，并且天天琢磨吹牛拍马，就没人真正为皇帝干活了。<br>结果是可怜的管理老虎的工作人员白高兴了一场，不但没得到奖赏，还得罪了动物园园长。</p>
</blockquote>
<h2><span id="人的前程有的时候不掌握在自己手里">人的前程有的时候不掌握在自己手里</span></h2><p>某城市从外省调来个姓q的一把手。该一把手一上任就把该市原来的骨干公务员全部晾到一边，一概不用，名义上对外宣称的是：领导干部年轻化。提拔了一批没有工作经验刚毕业的博士生当处级干部，大多数30岁还不到。这些人一点工作经验没有，以至于外界都很惊讶，甚至惊动了日本友人。<br>该一把手正是要用这些毫无工作经验的白纸，第一：人是自己一手提拔的，他能不感激涕零吗？第二：这些人啥也不懂，自己想怎么干就怎么干，这些人听话就行。不这样做，怎么能一手遮天呢？<br>一批期望往上爬的老公务员就这样牺牲掉了，而一批新丁就此崛起。人生的前程往往不掌握在自己手里。</p>
<h2><span id="河南郑州与洛阳">河南郑州与洛阳</span></h2><blockquote>
<p><strong>scdf1234：</strong></p>
<p>楼主，我想咨询一下，像洛阳这样的城市，它的经济在河南是第二位，但又离省会郑州很近，洛阳的房价现在大概是四千多，您认为洛阳的房价上涨的空间大吗？<br>谢谢！！！！！！！！！！！！</p>
<p><strong>kkndme：</strong></p>
<p>洛阳只能成为郑州的影子，如果自住，趁早在洛阳买房，以后一定会涨，如果投资，还是在郑州买，郑州的上涨空间，肯定大于洛阳。<br>不过95年以后，我就再也没去过洛阳，所以洛阳买哪个楼盘升值快，你得自己仔细研究。</p>
</blockquote>
<h2><span id="杭州">杭州</span></h2><blockquote>
<p><strong>灵魂被枪决：</strong></p>
<p>不知道楼主还在不在，因为只看完前面几页。</p>
<p>我前两天刚定了一套二手房，昨天打了首付款，下星期应该就要办银行按揭手续了。</p>
<p>我一直很想买房，但我LG一直不愿意买房，就在定下这套房子之前他还是很不乐意，但</p>
<p>因为我的坚持，我们终于买了房子了。房子定下后一个石头落地了，但另一个石头有悬</p>
<p>地半空了，因为我们是做个体户生意的，就怕生意有变故贷款接不上（我是个悲观主义</p>
<p>者，总先把最坏情况打算在前）。我们是在杭州，虽然不是市中心，但也算是市区了，</p>
<p>请问楼主能分析一下杭州楼市情况吗？？</p>
<p>先谢过了，楼主的文章对我启发真的很大</p>
<p><strong>kkndme：</strong></p>
<p>前面说过了，杭州我是当一线城市看的。杭州这个城市，本来就是富人的天堂，房价涨到多高都不奇怪，而且极好变现。所以你根本无须担忧资金问题。</p>
</blockquote>
<h2><span id="西安与重庆">西安与重庆</span></h2><blockquote>
<p><strong>ttan12345：</strong></p>
<p>用了一整天的时间拜读了楼主的精彩文章，很是佩服！</p>
<p>印象最深刻的就是北周宇文式和苏的关于贪官的对答，古人真有高人啊！</p>
<p>感觉楼主知识面相当的宽广，尤其对世界历史比较精通，许多观点非常符合世界发展的规律</p>
<p>关于房产的问题，我也一直认为，最终不是我们小老百姓可以玩的东子，所以能买就</p>
<p>尽早买。看了楼主不止一次给大家推荐去投资西安和重庆的地产，楼主问什么看好西安</p>
<p>和重庆这两个地方，现在各个省会城市哪个不是大兴土木呢？为何西安和重庆会进入你</p>
<p>的法眼？</p>
<p><strong>kkndme：</strong></p>
<p>重庆我就不多说，论述的比较多了，发展重庆是国家战略性的，这是政治任务。<br>西安是西北地区唯一的大城市（乌市比较特殊，不讨论乌市），教育资源丰富，且房价基数较低，所以说后续发展潜力很大，未来该城市的发展一定会纳入zy的视野</p>
</blockquote>
<h2><span id="谢国中空置率">谢国中「空置率」</span></h2><blockquote>
<p><strong>林语边的鸽子：</strong></p>
<p>谢国中:”一是加息预期；二是政府对房地产的政策调控力度不改；三是市场对人民币升值的预期减弱；四是参考了实际的供应量，“到2012年，房地产的空置率会非常高，全中国13亿老百姓要有的房子都有了。”<br>谢国忠预测，“接下来可能会看到交易量一直在增长，而房价却不死不活地拖几年，房地产没有第二场戏了</p>
<p>请问楼主对谢国中的说法怎么看?<br>谢谢</p>
<p><strong>kkndme：</strong></p>
<p>谢是油价和中国房地产的长期唱空者，从04年开始唱空中国房产。谢的有些话还是很有道理的，但有些预测就另有目的了，毕竟屁股决定脑袋。<br>今年谢一直呼吁的是加息，兼带唱空房地产，唱空房地产的主要依据是空置率。<br>谢自己也说中国的房地产最大受益的是zf，但却用空置率给出了一个下跌的结论。<br>人民币升值，呼吁加息，唱空房地产，摩根史丹利的喉舌作用显而易见的</p>
</blockquote>
<h2><span id="打工不如有一技之长的小老板">打工不如有一技之长的小老板</span></h2><blockquote>
<p><strong>中年不惑吗：</strong></p>
<p>现在他们已经比一般的小白领强了</p>
<p>人力成本只会越来越高</p>
<p>现在去读个技校，当个技工</p>
<p>肯定比一般大学出来强多了</p>
<p>还有一个问题：</p>
<p>一般企业的工资10年没有变</p>
<p>10年前某个职位是5000，</p>
<p>10年后这个职位也是5000；</p>
<p>而在10年间，民工工资可能从1000涨到了3000，<br>房价更是涨了10倍；</p>
<p>菜价生活用品也翻了数倍</p>
<p>高房价问题其实就是分配问题</p>
<p>如果某个从事的职位10年前和10年后是一样的</p>
<p>那也就相当于这个职位的薪水降了相当多</p>
</blockquote>
<p><strong>kkndme：</strong></p>
<p>进不了体制内的，无论是不是大学毕业，凡是有头脑的、懂做生意的，会一技之长的，只要不懒，活的肯定比无特长一般在公司打工的小白领强。<br>古代也是这样的，街面上卖爆肚的肯定比大户人家厨房里负责切葱的日子过的稳当。卖爆肚的小本生意很累很辛苦，但是有个手艺就不会饿肚子。大户人家切葱的上班期间日子过的比较轻松，甚至收入比卖爆肚的还强点，在大户人家也体面些。但一旦大户人家不要切葱的了，裁员了，这个切葱的出来还真没办法养活自己。<br>大学文凭顶多算个秀才资格，有这个资格才有机会举士，但是举不了士的，就必须学点技术，否则收入远远赶不上瓦工、电工。<br>过去的穷秀才，饭都吃不饱，但是社会地位却不差，一旦中了恩科，就是宰相根苗。现在有点不同，进不了体制内，又没点技术，那肯定沦为社会的最底层，不要说买房子了，能不能解决吃饭问题都不一定。</p>
<h2><span id="一线-二线的生活">一线、二线的生活</span></h2><p>一线和二线选择哪个城市生活，其实就是围城。<br>在一线打拼，有技术有背景或者机会好的，进了金字塔的中层。对于没背景的，运气差点的，看着没什么希望就离开了，到二线发展，起码二线生活成本还低点。混不下去的离开了，又有大量的打算拼一把的冲进来。<br>很多人宁可在大城市当底层，也不愿意回小城市。这还是个观念问题。小城市从城东走到城西也就二十分钟，觉得过得太枯草。大城市灯红酒绿的，虽然跟自己其实没多大关系，但是看着就是舒服。</p>
<h2><span id="讲故事含沙射影zg之房子不属于市场经济">讲故事含沙射影ZG之房子不属于市场经济</span></h2><p>不说历史了，讲个故事吧。这个故事纯属虚构，如有雷同，纯属巧合。讲故事麽，就不要和谐了。<br>传说王安石变法失败，后人小王跑到了海外，发现了大西洲。大西洲正处于混乱阶段，军阀割据，外族入侵。小王是个政治军事天才，煽动农民起义，统一了大西洲政权，建立了大西国。<br>小王继承了王安石变法的理想，建立了一个中央高度集权，百姓与百姓之间完全消灭差别的理想国家。农场、工厂、商场全部由国家统一经营，老百姓只需要在国家的农场、工厂、商场里快乐打工就行了。老百姓穿一样的，吃一样的，连结婚都是国家给安排。<br>大西国里有的知识分子认为这样治理国家太机器化了，有违人性。小王同志对这些知识分子很生气。<br>遥远的东方，有一个白鹿洞书院，书院的院长是个伟大的导师，这个人叫朱熹，此人提出了存天理、灭人欲的理论，给了小王同志治理国家理论上的支持。<br>于是小王同志大搞禁欲主义，凡是学习过陆九渊、王阳明心学理论的都抓起来改造。</p>
<p>不久，大西国经营的农场、工厂、商场就出了问题。效率特别低，老百姓出工不出力，胡干蛮干的比比皆是，后来出现了大饥荒，饿死了不少人。小王同志干不下去，被人赶走了。<br>新领导上台后，先把农场划分给农民，提高农民的积极性，先解决粮食问题。但是工厂、商场就比较不好办。<br>新领导认为，工厂、商场效益低，赔钱是因为负担太重了，城市里的老百姓生老病死都是由国家的工厂、商场负责，国家哪里管的起呢？<br>于是新领导就提出给国家的企业减负，给点优惠政策，拿出胡萝卜，让胆子大愿意自己单干的同志们主动离开国家企业。对于很多死活不肯走的同志，新领导强令这些人卷铺盖，国家不再负担这些人的生老病死了。大家自己解决吧，国家不管了。<br>新领导把还留在国家企业的自己人，定义为内部人员。离开国家企业的，就是外人，定义为社会闲杂人等。<br>社会闲杂人等，有人欢喜有人忧。有人利用内部人员的关系，大把赚钱，有人跑去给外国人当洋买办赚的也不少，还有的知识分子凭着有点文化，给人打工生活的也不错，反正这些人都挺高兴，比在内部受穷强。当然也有没本事的，就比较惨，生活的比较困难。</p>
<p>新领导看见内部都是自己人了，闲杂人等都清理掉了，于是着手内部改革，凡是稀缺的，与老百姓生产生活密切相关的行业，都由内部来经营，不需要动脑子搞创新，只要定个价，老百姓就必须得接受。<br>而需要创新动脑子的产业，不具备稀缺性必须充分竞争的产业，不是跟老百姓生产生活密切相关的产业都交给社会闲杂人等去自由竞争。<br>相当于把肉都留给了内部自己，把骨头扔给了外部闲杂人员。<br>这样做还有个好处：新领导喜欢内部自己人直接跟外国人做生意，但是只要跟外国人做生意就赔钱，赔的还不是一点半点。赔的钱从哪里补呢？<br>只要通过内部自己人经营的企业，抬高定价，将赔掉的钱转嫁给社会闲杂人等就可以了。<br>于是，当初离开内部的社会闲杂人等发现，钱也难赚了，生活成本也越来越高了，日子过得变得越来越艰难了。<br>这时有个傻空跳出来说：我就不信了，市场经济没有只涨不跌的商品。房价肯定会跌。<br>有个明白人告诉他：市场经济是分品种的。外部社会闲杂人等经营的电脑、电视是市场经济。但是内部人经营的石油、房地产不是市场经济。不能拿市场经济来解释。<br>这个傻空不信，本来在大西国能买房的，结果一直没买，后来买不起了，只好一直租房住。但是房租老涨价，吃饭越来越困难，一年难得吃两回肉。</p>
<h2><span id="什么是好的政策">什么是好的政策</span></h2><p>好的政策就象挂在驴子鼻子上的胡萝卜，让人永远有希望，但是拼命追也吃不到。这就是中国政治家的最高智慧。</p>
<p>洋人进北京，老佛爷把义和团推出来，结果拳匪搞的鸡飞狗跳，没法收场。<br>保钓也打算发动群众，靠爱国激情转嫁矛盾。不过好像这招不灵了。老板怎么对待员工，员工就会怎么回报老板。</p>
<h2><span id="李商隐渣男祖师爷">李商隐「渣男」祖师爷</span></h2><p>中秋节将至，撇开房地产的涨跌。喝一壶好酒，聊聊古人。</p>
<p>云母屏风烛影深，长河渐落晓星沉。 　　<br>嫦娥应悔偷灵药，碧海青天夜夜心。</p>
<p>借着中秋节的千古名句，我们八卦一下李商隐。<br>李商隐帅哥很有女人缘，据说谈了n多次荡气回肠的恋爱，不过这些恋爱经历没记录进正史，而是唐代的八卦记者通过李商隐帅哥的文学作品，侦破出来的。</p>
<p>李商隐帅哥不光会写诗，年轻人还在玉阳山修习过道术。但是当道士期间并没有认真的清修，以李帅哥的魅力，竟然吸引了一个美丽多情的女道士的目光。</p>
<p>这个女道士叫宋华阳，本来是个侍奉公主的宫女，跟随公主进山当了女道士。两人邂逅于山中，缠绵悱恻，但终究没有结果，宋美眉怀了李帅哥的宝宝，李帅哥也被轰下了山。但好像李帅哥也没负什么责任。</p>
<p>李帅哥伤痛的写下了“无题”以示纪念：<br>昨夜星辰昨夜风， 画楼西畔桂堂东。<br>身无彩凤双飞翼， 心有灵犀一点通。<br>隔座送钩春酒暖， 分曹射覆蜡灯红。<br>嗟余听鼓应官去， 走马兰台类转蓬。</p>
<p>李帅哥的第二个女朋友，被八卦记者们认为是锦瑟，锦瑟是谁？八卦记者们认为是令狐楚家的一个美丽温婉的侍女。</p>
<p>李帅哥很有才华，但是在晚唐时代，有点生不逢时。当时牛僧孺和李德裕搞党争，李帅哥跑去给牛党的重要人物令狐楚当幕僚，结果泡上了令狐大人的侍女。这个李帅哥和锦瑟谈恋爱的证据是根本没有。八卦记者是根据李帅哥的诗找到的蛛丝马迹。</p>
<p>这首诗就叫锦瑟。</p>
<p>锦瑟无端五十弦，一弦一柱思华年。 　　<br>庄生晓梦迷蝴蝶，望帝春心托杜鹃。 　　<br>沧海月明珠有泪，蓝田日暖玉生烟。 　　<br>此情可待成追忆，只是当时已惘然。</p>
<p>春 　　<br>风光冉冉东西陌，几日娇魂寻不得。<br>蜜房羽客类芳心，冶叶倡条遍相识。 　　<br>暖蔼辉迟桃树西，高鬟立共桃鬟齐。<br>雄龙雌凤杳何许？絮乱丝繁天亦迷。 　　<br>醉起微阳若初曙，映帘梦断闻残语。<br>愁将铁网罥珊瑚，海阔天宽迷处所。 　　<br>衣带无情有宽窄，春烟自碧秋霜白。<br>研丹擘石天不知，愿得天牢锁冤魄。 　　<br>夹罗委箧单绡起，香肌冷衬琤琤佩。<br>今日东风自不胜，化作幽光入西海。</p>
<p>夏 　　<br>前阁雨帘愁不卷，后堂芳树阴阴见。<br>石城景物类黄泉，夜半行郎空柘弹。 　　<br>绫扇唤风阊阖天，轻帏翠幕波洄旋。<br>蜀魂寂寞有伴未？几夜瘴花开木棉。 　　<br>桂宫流影光难取，嫣薰兰破轻轻语。<br>直教银汉堕怀中，未遣星妃镇来去。 　　<br>浊水清波何异源，济河水清黄河浑。<br>安得薄雾起缃裙，手接云輧呼太君。 　　</p>
<p>秋 　　<br>月浪衡天天宇湿，凉蟾落尽疏星入。<br>云屏不动掩孤嚬，西楼一夜风筝急。 　　<br>欲织相思花寄远，终日相思却相怨。<br>但闻北斗声回环，不见长河水清浅。 　　<br>金鱼锁断红桂春，古时尘满鸳鸯茵。<br>堪悲小苑作长道，玉树未怜亡国人。 　　<br>瑶琴愔愔藏楚弄，越罗冷薄金泥重。<br>帘钩鹦鹉夜惊霜，唤起南云绕云梦。 　　<br>璫璫丁丁联尺素，内记湘川相识处。<br>歌唇一世衔雨看，可惜馨香手中故。</p>
<p>冬 　　<br>天东日出天西下，雌凤孤飞女龙寡。<br>青溪白石不相望，堂上远甚苍梧野。 　　<br>冻壁霜华交隐起，芳根中断香心死。<br>浪乘画舸忆蟾蜍，月娥未必婵娟子。 　　<br>楚管蛮弦愁一概，空城罢舞腰支在。<br>当时欢向掌中销，桃叶桃根双姊妹。 　　<br>破鬟倭堕凌朝寒，白玉燕钗黄金蝉。<br>风车雨马不持去，蜡烛啼红怨天曙。</p>
<p>这是李帅哥写的燕台诗四首。<br>有个叫柳枝的美女，是洛阳大富翁的女儿，吟唱了这首诗后，就爱慕上了李帅哥。这个美女很大胆主动跟李帅哥约会，并没有嫌弃李帅哥没车没房，但不幸被李帅哥放了鸽子。李帅哥其实很喜欢这个柳枝，事后非常后悔，准备把失去的爱情找回来，但是柳枝已经给有权有势的大佬做了妾。</p>
<p>飒飒东风细雨来，芙蓉塘外有轻雷。<br>金蟾啮锁烧香入，玉虎牵丝汲井回。 　　<br>贾氏窥帘韩掾少，宓妃留枕魏王才。<br>春心莫共花争发，一寸相思一寸灰。</p>
<p>这首诗名为“无题”，写得是荷花。荷花是民间传说中李帅哥又一个女朋友的名字，也是李的初恋。美丽的荷花陪李帅哥进京赶考，半路上得了重病，李帅哥天天陪伴着她，但不幸的是，荷花还是香消玉损。李帅哥悲痛不已，常常以荷花为题，以纪念此段恋情。</p>
<p>李帅哥的才华，被节度使王茂元看中了，把女儿嫁给了这位帅哥。李帅哥娶了这位娇妻的同时，也给自己带来了麻烦。</p>
<p>原因是王茂元是李党的重要人物，而李帅哥的老师令狐楚却是牛党的重要人物。娶了王美人，李帅哥掉进了牛、李两党的夹缝，于是前途杯具了。</p>
<p>这个故事告诉我们，如果有个老大罩着你，日子过的还不错，就千万别轻易向老大的对手抛媚眼。否则，只能是杯具。</p>
<p>李帅哥尽管前途杯具了，但是跟娇妻王氏感情很好，王氏突然病逝，李帅哥伤痛万分，写下了“悼伤后赴东蜀辟至散关遇雪” 　　</p>
<p>剑外从军远，无家与寄衣。 　　<br>散关三尺雪，回梦旧鸳机。</p>
<p>无题<br>相见时难别亦难，东风无力百花残。<br>春蚕到死丝方尽，蜡炬成灰泪始干。<br>晓镜但愁云鬓改，夜吟应觉月光寒。<br>蓬山此去无多路，青鸟殷勤为探看。<br>　　<br>夜雨寄北<br>君问归期未有期，　　<br>巴山夜雨涨秋池。 　　<br>何当共剪西窗烛， 　　<br>却话巴山夜雨时。<br>　　<br>读这两首诗，第一个感觉就是李帅哥的用情之深，令人叹为观止；第二个感觉就是，其克女朋友的本事，也令人叹为观止啊</p>
<p>将近中秋，闲扯了一通李商隐，就以李商隐的无题结束这个闲话吧。</p>
<p>凤尾香罗薄几重，碧文圆顶夜深缝。<br>扇裁月魄羞难掩，车走雷声语未通。<br>曾是寂寥金烬暗，断无消息石榴红。 　　<br>斑骓只系垂杨岸，何处西南待好风。 　　<br>重帏深下莫愁堂，卧后清宵细细长。 　　<br>神女生涯元是梦，小姑居处本无郎。 　　<br>风波不信菱枝弱，月露谁教桂叶香。 　　<br>直道相思了无益，未妨惆怅是清狂。</p>
<h2><span id="西五环内的别墅是相当稀缺的资源">西五环内的别墅，是相当稀缺的资源</span></h2><blockquote>
<p><strong>黎</strong>明中的星光：**</p>
<p>楼主，认真阅读您的帖子快两周了，以史为鉴，深入浅出，感觉受益匪浅！</p>
<p>这两天，也在为在北京买房子的事很纠结，请您指点一二：</p>
<p>为自住，我们最近要买房了，此前，已经关注一年了，一年中，看上的房子都翻了倍。</p>
<p>最近我们在西四环西五环之间选了一个低密度花园别墅，叠层，新房，小区面积不大，只有200多户，（第一期08年开盘，大约2万上下单价，已入住，这次是二期）。小区密度是1.0。一期为3到5层，2期为5层坡屋顶。小区本身绿化环境不错，堪称绿意盎然，对内部环境很满意，我们选的是1、2层叠层带小花园的房子，220平方米左右。<br>这个小区叫：“金隅—长安山麓”，您从网上可以查到。</p>
<p>目前价格均价37000元左右。年初开盘时31000左右。开发商的策略是每次小部分放量，慢慢卖，拉开每栋楼开盘时间。最近我们看上的这个，是8月份开盘的。</p>
<p>我们认为优点是：<br>1、低密度带花园；这在大都市太难得了。<br>2、周围绿色环境好，多。向北是香山方向，一路绿色。<br>3、距离石景山万达距离近，3公里左右吧。万达出现在哪里，哪里基本是一个商业服务中心了。</p>
<p>缺点是：<br>1、周围没有紧密连接大型服务超市，商场等。最近的沃尔玛在2公里以外。<br>2、周围环境还不够理想。饭后散步、娱乐休闲的地方几乎没有。</p>
<p>担忧和想咨询您的问题是：<br>1、现在出手买，是否太冒险？<br>2、您对这个小区的前景判断如何？<br>3、我有朋友说买市中心的高层更好，万一卖掉也方便。怕这里以后不好出手。</p>
<p>楼主，再次打扰，百忙中能帮分析下吗？不胜感谢！</p>
<p><strong>kkndme：</strong></p>
<p>关于西五环内的别墅，是相当稀缺的资源，相当于奢侈品，奢侈品是不会随着调控有大幅度的调整，可以参考收藏品的投资，收藏品的风险在于战乱发生或者**经济崩盘。</p>
</blockquote>
<h2><span id="奸臣贾似道">“奸臣”贾似道</span></h2><p>说一个存在争议的人物，这个人被宋史写入“奸臣传”，就是大名鼎鼎的贾似道。几乎所有人眼中的贾似道都是大奸贼的形象，仗着是贵妃的姐姐，由一个游手好闲不学无术的二流子，摇身一变成了飞扬跋扈的大汉奸。他贪污受贿，搜罗奇珍美女，蒙古人打过来媚外卖过，还向皇帝谎报军情，最后南宋在他手里灭亡。反正老百姓眼中奸臣能干的所有坏事，都安在了贾似道的头上，然而历史真的如此吗？</p>
<p>经过多方面史料对照，读书仔细的筒子会发现，宋史的说法并不可信，自相矛盾的地方太多，几乎可以说宋史几乎收罗的都是野史和民间传说。是什么原因使一部正史却采用了大量的野史资料呢？</p>
<p>原因只有一个，贾似道得罪的人太多。</p>
<p>贾似道得罪人的原因，在于推行了一个政策：公田法。推出的背景是连年征战，南宋需要庞大的军费开支。军费的开支从哪里来呢？当然是从最底层的农民的肚子挤出来。南宋的经济已经是非常困难了，巧妇难为无米之炊，于是zf推出了纸币，相当于给人民打白条，可见纸币并不是现在的专利。这就是恶性通货膨胀。眼看国家经济崩盘了。贾似道想的办法就是：公田法。</p>
<p>公田法的意思跟傻空说的把多军的财产充公的意思差不多，就是限制地主的田地，凡是超过标准的，超过部分的三分之一充公给zf，zf给佃农耕种，产出的粮食用于军粮。有点相当于物业税的意思。</p>
<p>就凭贾似道想出的这个政策，说贾似道是个不学无术的混混，说什么我也不会相信的。</p>
<p>贾的办法很大程度上缓解了南宋经济的彻底崩盘，延缓了南宋生存的时间，但是贾却得罪了几乎所有的地主士大夫阶层。</p>
<p>贾不是一个贤臣，但绝非二流子，政治上也许不够成熟，但是为了南宋的艰难维持也算是呕心沥血。关于向蒙古大军求和，也并不能就说明他是个汉奸，那样一个经济崩溃，军队毫无战斗力的朝廷，你让他硬着头皮打，下场也就相当于鸦片战争。当然，关于宋史里讲到的贾似道极尽献媚之能事，把汉奸表演得淋漓尽致，应当是士大夫出于地主阶层对公田法的憎恨，狂泼的屎盆子。因为宋史的记录实在是疑点颇多。</p>
<p>南宋的将领如范文虎、夏贵之流，才真是腐败透顶，拥兵自重，对抗元军极尽脚底抹油之能事，而贾似道能够亲自督师，所以说贾似道是个大汉奸，实在开玩笑有点过火。南宋灭亡了，元世祖抓了南宋投降的将领问话：你们为什么这么容易就投降了呢？</p>
<p>降将回答：都是贾似道，只重视文官，不重视我们，所以就投降了。</p>
<p>元世祖哈哈大笑：就你们这样的武将，贾似道能重视你们才怪。</p>
<p>贾似道最后被郑虎臣擅自给杀了。郑虎臣是个大地主，自己的利益被公田法害得不轻，恨透了贾似道。</p>
<p>贾似道死了，全体士大夫阶层拍手称快，并且把他列入了奸臣传，永世不得翻身。</p>
<p>全因为一个公田法。</p>
<h2><span id="关于拆迁">关于拆迁</span></h2><p>关于拆迁，我国只有一部91年颁布的拆迁管理条例，但是就是这个简单的东西，很多拆迁时并不遵守。</p>
<p>常规来说，拆迁应持有拆迁许可证，开发商的开发项目应通过规划局的审核（这个可以在规划局查到），如果连开发商是谁，有没有资格开发都不知道就奇怪了。</p>
<p>是否同意拆迁取决于拆迁户和拆迁方的博弈，但是拆迁补偿办法一定要具体详细，包括如何补偿，过渡期的约定，具体要有时间和操作办法，还要签订违约责任。关于协议不可能只留在拆迁方手中，这是不合法的。</p>
<p>暴利拆迁，zf侵害拆迁户的利益的例子比比皆是，关键是自己如何争取主动。</p>
<h2><span id="保钓事件之死要面子活受罪">保钓事件之死要面子活受罪</span></h2><p>保钓事件，既定对策就是争取更多小国穷国的舆论支持，减免他国债务，加大对外经济援助。钱的来源，要靠底层国民勒紧裤腰带。</p>
<p>自古以来，泱泱大国，威仪四海，对外“恩”显示国力强大，对内“威”显示权力强大，恩威并施，千古国策。</p>
<p>朱棣的恩泽海外，死要面子，是做的比较极致的。结果是国库空虚，人民吃饭一下成了问题。所以才有后来坚定的禁海。</p>
<p>如果开通海外贸易，不是为了皇帝的面子，而是为了充实国库和老百姓的腰包，明代的官僚就不会坚持禁海，中国的历史就会改写。</p>
<p>郑和下西洋，反而堵塞了中国通向大海的道路。</p>
<blockquote>
<p><strong>tjOOSAN</strong></p>
<p>我只能说，楼主不懂政治，就触及了。钓鱼岛就算所有您所谓的“小国”都支持。也没用啊。神经病 就是神经病</p>
<p><strong>kkndme</strong></p>
<p>这个做法不新鲜，从周恩来时期，我们的外交政策就是拉拢第三世界国家的选票，远到非洲拉美，近到越南缅甸柬埔寨，支援铁路基建，捐钱捐物，自认第三世界国家的带头人。但是第三世界国家基本有奶就是娘。比如拉美的苏里南，我国刚捐了钱物，米国给了点好处，马上又投向米国。</p>
<p><strong>tjOOSAN</strong></p>
<p>建议您看看nhk的中国力量。真实偷拍的中国在非洲都做了什么。</p>
<p>1、资源。铁矿石 2、建立国家通信网 3、人力。</p>
<p>呵呵。援助是拉拢，但是有条件的。</p>
<p>越南最新的高铁，由日本公司建设。中国从来没援建过越南。</p>
<p>唉。。。。你把中国当傻子了。</p>
<p><strong>kkndme</strong></p>
<p>周时代，越南的生产工具、军火、粮食，都是中国无偿援助。无知不可怕，无知还满嘴喷粪最可怕</p>
<p><strong>tjOOSAN</strong></p>
<p>呵呵！</p>
<p>援建越南？？！哪了？给我证据？！？</p>
<p>关于非洲，我给你们穿了视频！自己看就知道了</p>
<blockquote>
<p><strong>中年不惑吗</strong></p>
<p>还非洲的力量</p>
<p>当年红太阳把大米鸡蛋东方红拖拉机运到阿尔及利亚</p>
<p>换来的是“中国人民是我们最好的朋友”和对中国各种口头的声援</p>
<p>这和kkndme兄说的难道不一致吗</p>
<p>现在不给钱给物了</p>
<p>你还能听到“中国人民是我们最好的朋友”的说法吗？</p>
<p>拉拢非洲小兄弟，是具有政治意义的</p>
<p>你英国是一票，人家再穷的小国也是一票</p>
</blockquote>
<p><strong>kkndme</strong></p>
<p>你理解力看来真有问题，你哪只眼睛看到争取小国穷国的舆论支持里面，包括越南。</p>
<p>这个事是温总定的调子，挂在搜狐首页</p>
<p><strong>tjOOSAN</strong></p>
<p>中年！kk！！<br>你们这两个同学啊！一看就跟成天上网的学生，没两样。争来争去。</p>
<p>哎呀，非要你赢他输。</p>
<p>唉。。。你说的怎么就对呢？？！证据！！明白吗？？</p>
<p>光你自己打嘴炮。没用啊！</p>
<p>呵呵 我得出去玩会了</p>
<p>你们继续网络吧！~~ 两个宅男</p>
<p><strong>kkndme</strong></p>
<p>tjOOSAN你去图书馆查查当年的报纸，什么都清楚了。</p>
<p>典型的愚民政策教育出来的傻蛋。</p>
</blockquote>
<h2><span id="中国的房地产不可能软着陆">中国的房地产不可能软着陆</span></h2><p>中国的房地产不可能软着陆，甚至也不可能出现日本的硬着陆。一旦积蓄的问题爆发，会直接崩，崩的绝不会只是房地产。那时候绝对没有人会关心房价，很多人将庆幸于当天能够勉强填饱肚子，但绝不奢望还能见到第二天的日出。</p>
<blockquote>
<p><strong>xiangshangpa</strong></p>
<p>请教楼主，如果出现您说的大部分老百姓勉强甚至不能填饱肚子，房价没人关心的时候，也就是社会动荡的时候，作为您这样的中产以上的阶级，还没有移民，如何自保？我很感兴趣，谢谢！祝中秋快乐！</p>
<p><strong>kkndme</strong></p>
<p>这种事要静观其变，所谓山雨欲来风满楼，发生之前一定会有大的征兆。<br>自保是没**有办法的，只能看形势不对，脚底抹油。</p>
<p><strong>xxx</strong></p>
<p>按照我的理解，在发生很大征兆之前，党国就会采取措施，实施闭关锁国政策（倒回50年代），跑是跑不掉的，如果大量难民出去，也没有几个国家会接受，中产，富裕阶层也不例外，现在很多国家已经提高移民门槛了，我对这种情况的出现感到悲观，调适空间十分有限，权贵集团真的是永远无法满足，唉</p>
<p><strong>kkndme</strong></p>
<p>呵呵，人的命，天注定，自求多福吧。</p>
<p><strong>中年不惑吗</strong></p>
<p>我倒没有kkndme兄那么悲观</p>
<p>去看看美国20世纪30年代的新闻和文章</p>
<p>也是一片哀嚎</p>
<p>资本主义已经完蛋了，无可救药了</p>
<p>贫富差距太大，老百姓活不下去了</p>
<p>美国当时的知识界很多人都是向往苏俄模式的</p>
<p>左倾的名流非常多（包括卓别林和爱因斯坦等等）</p>
<p>即使到了20世纪50年代，美国还要搞麦卡锡主义</p>
<p>也说明了当年左倾很有市场</p>
<p>现在了，苏俄成为历史，资本主义反倒越活越精神了</p>
<p>还有就是如果在南北战争的时候想象一个黑人能当总统</p>
<p>人家肯定说你是凡尔纳</p>
<p>就是马丁路德的时候</p>
<p>也只是奢望能给黑人争取公平和权益<br>　　<br>社会进步总是靠人推进的</p>
<p>可以是谭嗣同蔡锷，也可以是邹容和陈天华</p>
<p>何必太悲观了</p>
<p>难道不是事在人为吗<br>　　<br>自己都不努力改变</p>
<p>怎么能埋怨前辈的选择错误不作为了</p>
</blockquote>
<h2><span id="关于购买经济适用房">关于购买经济适用房</span></h2><blockquote>
<p><strong>大学生007</strong></p>
<p>楼主你好，质询个问题：<br>我家要买个二手房，房子是经济适用房，房产证上写的是土地划拨，中介说买了之后就是商品房了，那买了以后房产证上写的还是不是划拨啊，如果以后遇到拆迁什么的是不是补偿跟人家正规商品房不一样啊？谢谢</p>
<p><strong>kkndme</strong></p>
<p>经济适用房需要补交土地款后才能上市销售，补交土地款后，就变成了商品房，所以不用担心。<br>购买经济适用房一定要把补交的地价款算进去，才知道房价是否高于或低于周边商品房楼盘。<br>我国房地产交易很不规范，特别是中介有很多办法欺骗客户，买房无论是自住还是投资都要多长几个心眼。</p>
</blockquote>
<h2><span id="地级市买房">地级市买房</span></h2><blockquote>
<p><strong>我是射手520</strong></p>
<p>楼主，您好。有幸看到您盖的楼，您对历史、政治和经济的研究让我如醍醐灌顶，很多隐约迷惑的东西，似乎有了出路能去寻找答案。万分感谢。<br>说到置业，您对一线二线城市谈的较多，想听听您对类似我们这样城市楼市和经济的看法。<br>我所在的是地级市，离您帖子提到的武汉有500公里。我所在的地市以汽车工业为主导，是三大汽车集团其中之一的发源地，目前是该企业的商用车基地。<br>在全省范围，离省会最远，但是在城市建设、居民生活水平、物价和房价可以排在全省前面，以前分析是因为我们这里是以工业为主，故经济发展比其他以农业为主的地市发展的要好，看了楼主的帖子，感觉跟离武汉最远也有关系。<br>我们当地最贵房价从05年前2000以内，到09年3000-4000元，到今年的5000元，最贵的6000元。<br>房价的飙升一方面随着全国大环境有关，我分析同时跟当地政府的发展思路密不可分，05年开始引进外地大开发商，新修了很多路，其中跟旧城区主干道平行的最重要的一条路，随着市政府入住，体育馆、美术馆，大开发商进驻，经过5年发展，该路段已经成为我们这里房价最贵的一条路，我们是小城市，在这里买房子的，除了投机成分以外，大部分应该是改善型住房，要大型小区，要绿化，这条路目前房子也是越盖越高。通过建设，当地政府财政也充裕，明显感觉对市政投入也大多了。<br>我们这里养老还是不错的，山多，空气好，工业城市，经济发展也交好。<br>我目前的置业状况是，在老城区广场旁边有单位分高层住宅一套，虽然是塔楼，但在广场旁边，弱化了容积率高，当年放弃了单位地段相对没这个中心，总价低的多层住宅，就是看中了地段，这个投资较成功，按照现在市价，房屋总价基本翻番，该房屋目前由父母住。<br>08年底，在开始说的新地段够买一套房屋，120平米，多层住宅，周边政府规划为大学城，周边有两所大专院校，对于该房屋地段较为满意，虽然比不上新修的路的北边和中部靠近体育馆，靠近政府地段升值快，但较看好该地段前景，该地段新修了 一条连接老城区的通道，唯一不太满意是购买的顶楼，因为是购买的该小区的多层住宅没有电梯，如果有了孩子，住顶楼生活就不太方便。购入均价2900，目前周边的新盘均价4500元，该楼盘创造了摇号去选房的记录。该套房屋自住，当年购买房屋没有多贷款一步到位，现在如果想换个满意的难度就大的多，满意的房屋都5000往上了。这套房屋有15万左右的贷款。<br>虽然很看好武汉的楼盘，远远现阶段大于经济承受能力，目前放弃。<br>对于我们当地的楼盘，也超出了我们这种普通人的能力，虽然最近楼盘都卖的很火。<br>好在单位公积金较多，我打算收复30%，剩下用公积金贷款，再购置一套房屋，怕再过一段时间，我的改善型需求就满足不了。<br>前一段时间，有个机会，但是考虑按照目前房价，30%首复，要耗尽目前自己和家人积蓄，犹豫中，错过了机会。<br>目前这种状况，不知道是否该再次买房？<br>再次买房考虑标准时什么？我不太喜欢高层，但是原中心城区，没有大盘，都是单位或者小开发商盖的，基本没有绿化，在中心城区边上也有了一套高层住宅。<br>考虑学位房？我们城市不大，目前这套中心城区房屋虽然没有画片在最好的小学中学，但是离这些学校距离比较近。<br>在靠近那条政府搬入的路的北边靠近体育馆、美术馆（同时也靠近两所重点高中）地方置业，那里房价已经5000多，年底开盘的都是30层以上的高层，自住又不太考虑高层，总价也超出了承受范围。<br>在当地，离那个大企业居住地，区政府也新开了一条路，那条路待开发状态，据说区政府要搬过去（要搬也是2年以后，现在那条路只有一个大开发商在开发），那条路开车到市中心20分钟，那次有机会买的就是那个大开发商的楼盘，主推多层住宅并且带电梯，去年就预售完毕，这次犹豫中，错过了，住宅品质较好，目前地段太偏。<br>如果再有机会，该如何选择呢？</p>
<p><strong>kkndme</strong></p>
<p>地级市选房是比较麻烦的，因为投资风险要大于一线城市和省会城市。<br>地级市的购房需求，主要是以改善性需求为主，追求的是大盘，低密度，低楼层，高绿化，最好有个江景或者水景，环境优美的别墅是首选。<br>因为低级市城市较小，绝对的城中心如果环境比较嘈杂，小区不够高档最好不要选择。没有实力购置别墅，可以选择环境优美的高端住宅，最好是品牌大盘，一眼能够让人赏心悦目。</p>
</blockquote>
<p><a href="https://github.com/laoshenkaopu/kkndme_tianya">参考</a></p>
]]></content>
      <categories>
        <category>房价思考</category>
      </categories>
      <tags>
        <tag>房价思考</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石-3</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="3-types-of-learning">3 — Types of Learning</span></h1><p>上节课我们主要介绍了解决线性分类问题的一个简单的方法：PLA。PLA能够在平面中选择一条直线将样本数据完全正确分类。而对于线性不可分的情况，可以使用Pocket Algorithm来处理。本节课将主要介绍一下机器学习有哪些种类，并进行归纳。<br><span id="more"></span></p>
<h3><span id="一-learning-with-different-output-space-y"><strong>一、Learning with Different Output Space Y</strong></span></h3><p>我们在上节课引入的银行根据用户个人情况判断是否给他发信用卡的例子，这是一个典型的二元分类（binary classification）问题。也就是说输出只有两个，一般y={-1, +1}，-1代表不发信用卡（负类），+1代表发信用卡（正类）。</p>
<p>二元分类的问题很常见，包括信用卡发放、垃圾邮件判别、患者疾病诊断、答案正确性估计等等。二元分类是机器学习领域非常核心和基本的问题。二元分类有线性模型也有非线性模型，根据实际问题情况，选择不同的模型。</p>
<p><img data-src="./5c6d3459fba2b7d3da1fe29dda9a8c09.jpg" alt="这里写图片描述"></p>
<p>除了二元分类，也有多元分类（Multiclass Classification）问题。顾名思义，多元分类的输出多于两个，y={1, 2, … , K}, K&gt;2. 一般多元分类的应用有数字识别、图片内容识别等等。</p>
<p><img data-src="./33b3456668ed201b68aafa318ce5685b.jpg" alt="这里写图片描述"></p>
<p>二元分类和多元分类都属于分类问题，它们的输出都是离散值。二对于另外一种情况，比如训练模型，预测房屋价格、股票收益多少等，这类问题的输出y=R，即范围在整个实数空间，是连续的。这类问题，我们把它叫做回归（Regression）。最简单的线性回归是一种典型的回归模型。</p>
<p>除了分类和回归问题，在自然语言处理等领域中，还会用到一种机器学习问题：结构化学习（Structured Learning）。结构化学习的输出空间包含了某种结构在里面，它的一些解法通常是从多分类问题延伸而来的，比较复杂。本系列课程不会详细介绍Structured Learning，有兴趣的读者可以自行对它进行更深入的研究。</p>
<p>简单总结一下，机器学习按照输出空间划分的话，包括二元分类、多元分类、回归、结构化学习等不同的类型。其中二元分类和回归是最基础、最核心的两个类型，也是我们课程主要介绍的部分。</p>
<p><img data-src="./42f7b7f9525d0b9dec6cb751ae179553.jpg" alt="这里写图片描述"></p>
<h3><span id="二-learning-with-different-data-label-yn"><strong>二、Learning with Different Data Label yn</strong></span></h3><p>如果我们拿到的训练样本D既有输入特征x，也有输出yn，那么我们把这种类型的学习称为监督式学习（Supervised Learning）。监督式学习可以是二元分类、多元分类或者是回归，最重要的是知道输出标签yn。与监督式学习相对立的另一种类型是非监督式学习（Unsupervised learning）。非监督式学习是没有输出标签yn的，典型的非监督式学习包括：聚类（clustering）问题，比如对网页上新闻的自动分类；密度估计，比如交通路况分析；异常检测，比如用户网络流量监测。通常情况下，非监督式学习更复杂一些，而且非监督的问题很多都可以使用监督式学习的一些算法思想来实现。</p>
<p><img data-src="./027cbda81af889745bbd0bf08263a48e.jpg" alt="这里写图片描述"></p>
<p>介于监督式和非监督式学习之间的叫做半监督式学习（Semi-supervised Learning）。顾名思义，半监督式学习就是说一部分数据有输出标签yn，而另一部分数据没有输出标签yn。在实际应用中，半监督式学习有时候是必须的，比如医药公司对某些药物进行检测，考虑到成本和实验人群限制等问题，只有一部分数据有输出标签yn。</p>
<p>监督式、非监督式、半监督式学习是机器学习领域三个主要类型。除此之外，还有一种非常重要的类型：增强学习（Reinforcement Learning）。增强学习中，我们给模型或系统一些输入，但是给不了我们希望的真实的输出y，根据模型的输出反馈，如果反馈结果良好，更接近真实输出，就给其正向激励，如果反馈结果不好，偏离真实输出，就给其反向激励。不断通过“反馈-修正”这种形式，一步一步让模型学习的更好，这就是增强学习的核心所在。增强学习可以类比成训练宠物的过程，比如我们要训练狗狗坐下，但是狗狗无法直接听懂我们的指令“sit down”。在训练过程中，我们给狗狗示意，如果它表现得好，我们就给他奖励，如果它做跟sit down完全无关的动作，我们就给它小小的惩罚。这样不断修正狗狗的动作，最终能让它按照我们的指令来行动。实际生活中，增强学习的例子也很多，比如根据用户点击、选择而不断改进的广告系统</p>
<p>简单总结一下，机器学习按照数据输出标签yn划分的话，包括监督式学习、非监督式学习、半监督式学习和增强学习等。其中，监督式学习应用最为广泛。</p>
<p><img data-src="./1890d66a62f112b767f018cde3e2e55c.jpg" alt="这里写图片描述"></p>
<h3><span id="三-learning-with-different-protocol-fxnyn"><strong>三、Learning with Different Protocol f(xn,yn)</strong></span></h3><p>按照不同的协议，机器学习可以分为三种类型：</p>
<ul>
<li>Batch Learning</li>
<li>Online</li>
<li>Active Learning</li>
</ul>
<p>batch learning是一种常见的类型。batch learning获得的训练数据D是一批的，即一次性拿到整个D，对其进行学习建模，得到我们最终的机器学习模型。batch learning在实际应用中最为广泛。</p>
<p>online是一种在线学习模型，数据是实时更新的，根据数据一个个进来，同步更新我们的算法。比如在线邮件过滤系统，根据一封一封邮件的内容，根据当前算法判断是否为垃圾邮件，再根据用户反馈，及时更新当前算法。这是一个动态的过程。之前我们介绍的PLA和增强学习都可以使用online模型。</p>
<p>active learning是近些年来新出现的一种机器学习类型，即让机器具备主动问问题的能力，例如手写数字识别，机器自己生成一个数字或者对它不确定的手写字主动提问。active learning优势之一是在获取样本label比较困难的时候，可以节约时间和成本，只对一些重要的label提出需求。</p>
<p>简单总结一下，按照不同的协议，机器学习可以分为batch, online, active。这三种学习类型分别可以类比为：填鸭式，老师教学以及主动问问题。</p>
<p><img data-src="./301228323e003e92233237706a958f91.jpg" alt="这里写图片描述"></p>
<h3><span id="四-learning-with-different-input-space-x"><strong>四、Learning with Different Input Space X</strong></span></h3><p>上面几部分介绍的机器学习分类都是根据输出来分类的，比如根据输出空间进行分类，根据输出y的标记进行分类，根据取得数据和标记的方法进行分类。这部分，我们将谈谈输入X有哪些类型。</p>
<p>输入X的第一种类型就是concrete features。比如说硬币分类问题中硬币的尺寸、重量等；比如疾病诊断中的病人信息等具体特征。concrete features对机器学习来说最容易理解和使用。</p>
<p>第二种类型是raw features。比如说手写数字识别中每个数字所在图片的mxn维像素值；比如语音信号的频谱等。raw features一般比较抽象，经常需要人或者机器来转换为其对应的concrete features，这个转换的过程就是Feature Transform。</p>
<p>第三种类型是abstract features。比如某购物网站做购买预测时，提供给参赛者的是抽象加密过的资料编号或者ID，这些特征X完全是抽象的，没有实际的物理含义。所以对于机器学习来说是比较困难的，需要对特征进行更多的转换和提取。</p>
<p>简单总结一下，根据输入X类型不同，可以分为concetet, raw, abstract。将一些抽象的特征转换为具体的特征，是机器学习过程中非常重要的一个环节。在《机器学习技法》课程中，我们再详细介绍。</p>
<p><img data-src="./5b8e649119d0311023e13eff815c3c2c.jpg" alt="这里写图片描述"></p>
<h3><span id="五-总结"><strong>五、总结：</strong></span></h3><p>本节课主要介绍了机器学习的类型，包括Out Space、Data Label、Protocol、Input Space四种类型。</p>
<p><img data-src="./bd9d6af0a6c24e051f85de8085dde493.jpg" alt="这里写图片描述"></p>
<p><strong><em>注明：\</em></strong></p>
<p>文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。</p>
]]></content>
      <categories>
        <category>机器学习基石</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石-2</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="2-learning-to-answer-yesno">2 — Learning to Answer Yes/No</span></h1><p>上节课，我们主要简述了机器学习的定义及其重要性，并用流程图的形式介绍了机器学习的整个过程：根据模型H，使用演算法A，在训练样本D上进行训练，得到最好的h，其对应的g就是我们最后需要的机器学习的模型函数，一般g接近于目标函数f。本节课将继续深入探讨机器学习问题，介绍感知机Perceptron模型，并推导课程的第一个机器学习算法：Perceptron Learning Algorithm（PLA）。</p>
<span id="more"></span>
<h3><span id="一-perceptron-hypothesis-set"><strong>一、Perceptron Hypothesis Set</strong></span></h3><p>引入这样一个例子：某银行要根据用户的年龄、性别、年收入等情况来判断是否给该用户发信用卡。现在有训练样本D，即之前用户的信息和是否发了信用卡。这是一个典型的机器学习问题，我们要根据D，通过A，在H中选择最好的h，得到g，接近目标函数f，也就是根据先验知识建立是否给用户发信用卡的模型。银行用这个模型对以后用户进行判断：发信用卡（+1），不发信用卡（-1）。</p>
<p>在这个机器学习的整个流程中，有一个部分非常重要：就是模型选择，即Hypothesis Set。选择什么样的模型，很大程度上会影响机器学习的效果和表现。下面介绍一个简单常用的Hypothesis Set：感知机（Perceptron）。</p>
<p>还是刚才银行是否给用户发信用卡的例子，我们把用户的个人信息作为特征向量x，令总共有d个特征，每个特征赋予不同的权重w，表示该特征对输出（是否发信用卡）的影响有多大。那所有特征的加权和的值与一个设定的阈值threshold进行比较：大于这个阈值，输出为+1，即发信用卡；小于这个阈值，输出为-1，即不发信用卡。感知机模型，就是当特征加权和与阈值的差大于或等于0，则输出h(x)=1；当特征加权和与阈值的差小于0，则输出h(x)=-1，而我们的目的就是计算出所有权值w和阈值threshold。</p>
<p><img data-src="./b82f5722a3ab38fa777a0941ce313102.jpg" alt></p>
<p>为了计算方便，通常我们将阈值threshold当做<img data-src="./80aba44293dd8bc07d580471772db0d3.jpg" alt>，引入一个<img data-src="./ba8e90ec3b50f66d895b239f68d3b97e.jpg" alt>的量与<img data-src=".//80aba44293dd8bc07d580471772db0d3.jpg" alt>相乘，这样就把threshold也转变成了权值<img data-src=".//80aba44293dd8bc07d580471772db0d3.jpg" alt>，简化了计算。h(x)的表达式做如下变换：</p>
<p><img data-src="./b0388ac66d4e814cf2ecc1c4aebc2799.jpg" alt></p>
<p>为了更清晰地说明感知机模型，我们假设Perceptrons在二维平面上，即<img data-src="./9da10bd554efbaa3d9f62efed8cb7834.jpg" alt>。其中，<img data-src=".//80aba44293dd8bc07d580471772db0d3.jpg" alt>是平面上一条分类直线，直线一侧是正类（+1），直线另一侧是负类（-1）。权重w不同，对应于平面上不同的直线。</p>
<p><img data-src="./6eb760b955af84cb1123dd680eb4b559.jpg" alt></p>
<p>那么，我们所说的Perceptron，在这个模型上就是一条直线，称之为linear(binary) classifiers。注意一下，感知器线性分类不限定在二维空间中，在3D中，线性分类用平面表示，在更高维度中，线性分类用超平面表示，即只要是形如<img data-src="./b060a4879c8127c91fe14a0a743ca23d.jpg" alt>的线性模型就都属于linear(binary) classifiers。</p>
<p>同时，需要注意的是，这里所说的linear(binary) classifiers是用简单的感知器模型建立的，线性分类问题还可以使用logistic regression来解决，后面将会介绍。</p>
<h3><span id="二-perceptron-learning-algorithmpla"><strong>二、Perceptron Learning Algorithm(PLA)</strong></span></h3><p>根据上一部分的介绍，我们已经知道了hypothesis set由许多条直线构成。接下来，我们的目的就是如何设计一个演算法A，来选择一个最好的直线，能将平面上所有的正类和负类完全分开，也就是找到最好的g，使<img data-src="./061263d047d98f81c1e18f8f49c57003.jpg" alt>。</p>
<p>如何找到这样一条最好的直线呢？我们可以使用逐点修正的思想，首先在平面上随意取一条直线，看看哪些点分类错误。然后开始对第一个错误点就行修正，即变换直线的位置，使这个错误点变成分类正确的点。接着，再对第二个、第三个等所有的错误分类点就行直线纠正，直到所有的点都完全分类正确了，就得到了最好的直线。这种“逐步修正”，就是PLA思想所在。</p>
<p><img data-src="./75217f1e29be523c4e5b655d738984a2.jpg" alt></p>
<p>下面介绍一下PLA是怎么做的。首先随机选择一条直线进行分类。然后找到第一个分类错误的点，如果这个点表示正类，被误分为负类，即<img data-src="./4042fc2c320d85292df45d0c2633965e.jpg" alt>，那表示w和x夹角大于90度，其中w是直线的法向量。所以，x被误分在直线的下侧（相对于法向量，法向量的方向即为正类所在的一侧），修正的方法就是使w和x夹角小于90度。通常做法是<img data-src="./cdb3c7bd482f1beb34c202eef937eefd.jpg" alt>，如图右上角所示，一次或多次更新后的<img data-src="./9cfd891e8acb93d51d15087897f73aa2.jpg" alt>与x夹角小于90度，能保证x位于直线的上侧，则对误分为负类的错误点完成了直线修正。</p>
<p>同理，如果是误分为正类的点，即<img data-src="./7e16316a1d9c7fd686cdb66b9f09f630.jpg" alt>，那表示w和x夹角小于90度，其中w是直线的法向量。所以，x被误分在直线的上侧，修正的方法就是使w和x夹角大于90度。通常做法是<img data-src="./25df598a47ca943cce43cee3f072d4e9.jpg" alt>，如图右下角所示，一次或多次更新后的<img data-src="./9cfd891e8acb93d51d15087897f73aa2.jpg" alt>与x夹角大于90度，能保证x位于直线的下侧，则对误分为正类的错误点也完成了直线修正。</p>
<p>按照这种思想，遇到个错误点就进行修正，不断迭代。要注意一点：每次修正直线，可能使之前分类正确的点变成错误点，这是可能发生的。但是没关系，不断迭代，不断修正，最终会将所有点完全正确分类（PLA前提是线性可分的）。这种做法的思想是“知错能改”，有句话形容它：“A fault confessed is half redressed.”</p>
<p>实际操作中，可以一个点一个点地遍历，发现分类错误的点就进行修正，直到所有点全部分类正确。这种被称为Cyclic PLA。</p>
<p><img data-src="./a01f86d78da3a4c18e65c580dcbc3034.jpg" alt></p>
<p>下面用图解的形式来介绍PLA的修正过程：</p>
<p><img data-src="./e0d499510e79ae414ba6d8fd0e2b8873.jpg" alt></p>
<p><img data-src="./4c2ee658095b1de81eef6462835ccff5.jpg" alt></p>
<p><img data-src="./eade122d2714fd8f022ed5750dac7ebb.jpg" alt></p>
<p><img data-src="./ee9dfb1122ece819e36dfa0dffa3d710.jpg" alt></p>
<p><img data-src="./0907de3645464656b10156121be5ca29.jpg" alt></p>
<p><img data-src="./3588fd87a025943f3a44dda267611783.jpg" alt></p>
<p><img data-src="./a0efb902fa72d856e691be2b58d367c8.jpg" alt></p>
<p><img data-src="./31868f4e7c73a3c6172e1feb72168f5f.jpg" alt></p>
<p><img data-src="./e54782823ec6e1465008d4c91cdc7924.jpg" alt></p>
<p><img data-src="./83392b3b4e2f3481d33b79efaed3ec11.jpg" alt></p>
<p><img data-src="./a7e3b39ad0a959c6a37bc3b4ab350504.jpg" alt></p>
<p>对PLA，我们需要考虑以下两个问题：</p>
<ul>
<li><p>PLA迭代一定会停下来吗？如果线性不可分怎么办？</p>
</li>
<li><p>PLA停下来的时候，是否能保证<img data-src="./4e89dc8628aa25992aee4c27f454472b.jpg" alt>？如果没有停下来，是否有<img data-src=".//4e89dc8628aa25992aee4c27f454472b.jpg" alt>？</p>
</li>
</ul>
<h3><span id="三-guarantee-of-pla"><strong>三、Guarantee of PLA</strong></span></h3><p>PLA什么时候会停下来呢？根据PLA的定义，当找到一条直线，能将所有平面上的点都分类正确，那么PLA就停止了。要达到这个终止条件，就必须保证D是线性可分（linear separable）。如果是非线性可分的，那么，PLA就不会停止。</p>
<p><img data-src="./eed8a5d3f418163842ee06008346de06.jpg" alt></p>
<p>对于线性可分的情况，如果有这样一条直线，能够将正类和负类完全分开，令这时候的目标权重为<img data-src="./40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>，则对每个点，必然满足<img data-src="./e70d3b173167e8a06cb87df08df81c73.jpg" alt>，即对任一点：</p>
<p><img data-src="./e13d51359e00687861a9c469e7e0f8d8.jpg" alt></p>
<p>PLA会对每次错误的点进行修正，更新权重<img data-src="./75cc738213b9d738d2f3b8b323d07aef.jpg" alt>的值，如果<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>与<img data-src="./40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>越来越接近，数学运算上就是内积越大，那表示<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>是在接近目标权重<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>，证明PLA是有学习效果的。所以，我们来计算<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>与<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>的内积：</p>
<p><img data-src="./522dc5f7b352e150c9704f00ad795cca.jpg" alt></p>
<p>从推导可以看出，<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>与<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>的内积跟<img data-src="./2a7c3c74c112ab824335ff317c785f4e.jpg" alt>与<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>的内积相比更大了。似乎说明了<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>更接近<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>，但是内积更大，可能是向量长度更大了，不一定是向量间角度更小。所以，下一步，我们还需要证明<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>与<img data-src=".//2a7c3c74c112ab824335ff317c785f4e.jpg" alt>向量长度的关系：</p>
<p><img data-src="./d316f70f72b7ea87e40817e2cd9f5543.jpg" alt></p>
<p><img data-src=".//2a7c3c74c112ab824335ff317c785f4e.jpg" alt>只会在分类错误的情况下更新，最终得到的<img data-src="./be9452610f340ddcd227d32452da883b.jpg" alt>相比<img data-src="./392d2051d8acd806804208c33704175a.jpg" alt>的增量值不超过<img data-src="./46294e55f4b6c554e691470ae7ec3d2a.jpg" alt>。也就是说，<img data-src=".//2a7c3c74c112ab824335ff317c785f4e.jpg" alt>的增长被限制了，<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>与<img data-src=".//2a7c3c74c112ab824335ff317c785f4e.jpg" alt>向量长度不会差别太大！</p>
<p>如果令初始权值<img data-src=".//80aba44293dd8bc07d580471772db0d3.jpg" alt>，那么经过T次错误修正后，有如下结论：</p>
<p>下面贴出来该结论的具体推导过程：</p>
<p><img data-src="./9499cd5bc28ac0c3d524f8115ef09a46.jpg" alt></p>
<p><img data-src="./182b2ba169926a57c9bb35d350c6d04f.jpg" alt></p>
<p>上述不等式左边其实是<img data-src="./2ed3b41c02e21f3224f54ab912153516.jpg" alt>与<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>夹角的余弦值，随着T增大，该余弦值越来越接近1，即<img data-src=".//2ed3b41c02e21f3224f54ab912153516.jpg" alt>与<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>越来越接近。同时，需要注意的是，<img data-src="./2b1582bb9dd36767edc8638d5142f4a6.jpg" alt>，也就是说，迭代次数T是有上界的。根据以上证明，我们最终得到的结论是：<img data-src=".//75cc738213b9d738d2f3b8b323d07aef.jpg" alt>与<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>的是随着迭代次数增加，逐渐接近的。而且，PLA最终会停下来（因为T有上界），实现对线性可分的数据集完全分类。</p>
<h3><span id="四-non-separable-data"><strong>四、Non-Separable Data</strong></span></h3><p>上一部分，我们证明了线性可分的情况下，PLA是可以停下来并正确分类的，但对于非线性可分的情况，<img data-src=".//40de538fbc9692d37d7d1b7ab8958efb.jpg" alt>实际上并不存在，那么之前的推导并不成立，PLA不一定会停下来。所以，PLA虽然实现简单，但也有缺点：</p>
<p><img data-src="./184006fbd0c94062a9bad5aecdb2b705.jpg" alt></p>
<p>对于非线性可分的情况，我们可以把它当成是数据集D中掺杂了一下noise，事实上，大多数情况下我们遇到的D，都或多或少地掺杂了noise。这时，机器学习流程是这样的：</p>
<p><img data-src="./5ca498908766c95678b857366c359ede.jpg" alt></p>
<p>在非线性情况下，我们可以把条件放松，即不苛求每个点都分类正确，而是容忍有错误点，取错误点的个数最少时的权重w：</p>
<p><img data-src="./459e9ae9fb763c5285e4b3d6e7017446.jpg" alt></p>
<p>事实证明，上面的解是NP-hard问题，难以求解。然而，我们可以对在线性可分类型中表现很好的PLA做个修改，把它应用到非线性可分类型中，获得近似最好的g。</p>
<p>修改后的PLA称为Packet Algorithm。它的算法流程与PLA基本类似，首先初始化权重<img data-src=".//80aba44293dd8bc07d580471772db0d3.jpg" alt>，计算出在这条初始化的直线中，分类错误点的个数。然后对错误点进行修正，更新w，得到一条新的直线，在计算其对应的分类错误的点的个数，并与之前错误点个数比较，取个数较小的直线作为我们当前选择的分类直线。之后，再经过n次迭代，不断比较当前分类错误点个数与之前最少的错误点个数比较，选择最小的值保存。直到迭代次数完成后，选取个数最少的直线对应的w，即为我们最终想要得到的权重值。</p>
<p><img data-src="./5d5060a872bbddfe2d5fb0263407ee05.jpg" alt></p>
<p>如何判断数据集D是不是线性可分？对于二维数据来说，通常还是通过肉眼观察来判断的。一般情况下，Pocket Algorithm要比PLA速度慢一些。</p>
<h3><span id="五-总结"><strong>五、总结</strong></span></h3><p>本节课主要介绍了线性感知机模型，以及解决这类感知机分类问题的简单算法：PLA。我们详细证明了对于线性可分问题，PLA可以停下来并实现完全正确分类。对于不是线性可分的问题，可以使用PLA的修正算法Pocket Algorithm来解决。</p>
<p><strong><em>注明：</em></strong></p>
<p>文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。</p>
]]></content>
      <categories>
        <category>机器学习基石</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石-1</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="1-the-learning-problem">1 — The Learning Problem</span></h1><p>最近在看NTU林轩田的《机器学习基石》课程，个人感觉讲的非常好。整个基石课程分成四个部分：</p>
<ul>
<li><p>When Can Machine Learn?</p>
</li>
<li><p>Why Can Machine Learn?</p>
</li>
<li><p>How Can Machine Learn?</p>
</li>
<li><p>How Can Machine Learn Better?</p>
</li>
</ul>
<p>每个部分由四节课组成，总共有16节课。那么，从这篇开始，我们将连续对这门课做课程笔记，共16篇，希望能对正在看这们课的童鞋有所帮助。下面开始第一节课的笔记：The Learning Problem。<br><span id="more"></span></p>
<h3><span id="一-what-is-machine-learning"><strong>一、What is Machine Learning</strong></span></h3><p>什么是“学习”？学习就是人类通过观察、积累经验，掌握某项技能或能力。就好像我们从小学习识别字母、认识汉字，就是学习的过程。而机器学习（Machine Learning），顾名思义，就是让机器（计算机）也能向人类一样，通过观察大量的数据和训练，发现事物规律，获得某种分析问题、解决问题的能力。</p>
<p><img data-src="./9dd2cad8a66f29e53a6318e40a7412ef.jpg" alt="这里写图片描述"></p>
<p>机器学习可以被定义为：Improving some performance measure with experence computed from data. 也就是机器从数据中总结经验，从数据中找出某种规律或者模型，并用它来解决实际问题。</p>
<p><img data-src="./6bfe4b629d4641ce715c2f2abf8a015d.jpg" alt="这里写图片描述"></p>
<p>什么情况下会使用机器学习来解决问题呢？其实，目前机器学习的应用非常广泛，基本上任何场合都能够看到它的身影。其应用场合大致可归纳为三个条件：</p>
<ul>
<li><p>事物本身存在某种潜在规律</p>
</li>
<li><p>某些问题难以使用普通编程解决</p>
</li>
<li><p>有大量的数据样本可供使用</p>
</li>
</ul>
<p><img data-src="./a592a711c257203636aa7cd6b10efcd7.jpg" alt="这里写图片描述"></p>
<h3><span id="二-applications-of-machine-learning"><strong>二、Applications of Machine Learning</strong></span></h3><p>机器学习在我们的衣、食、住、行、教育、娱乐等各个方面都有着广泛的应用，我们的生活处处都离不开机器学习。比如，打开购物网站，网站就会给我们自动推荐我们可能会喜欢的商品；电影频道会根据用户的浏览记录和观影记录，向不同用户推荐他们可能喜欢的电影等等，到处都有机器学习的影子。</p>
<h3><span id="三-components-of-machine-learning"><strong>三、Components of Machine Learning</strong></span></h3><p>本系列的课程对机器学习问题有一些基本的术语需要注意一下：</p>
<ul>
<li><p>输入x</p>
</li>
<li><p>输出y</p>
</li>
<li><p>目标函数f，即最接近实际样本分布的规律</p>
</li>
<li><p>训练样本data</p>
</li>
<li><p>假设hypothesis，一个机器学习模型对应了很多不同的hypothesis，通过演算法A，选择一个最佳的hypothesis对应的函数称为矩g，g能最好地表示事物的内在规律，也是我们最终想要得到的模型表达式。</p>
</li>
</ul>
<p><img data-src="./44da41b76a6ba9a827af7d7f41236640.jpg" alt="这里写图片描述"></p>
<p>实际中，机器学习的流程图可以表示为：</p>
<p><img data-src="./c4fa6c9095756476fa7259076381f958.jpg" alt="这里写图片描述"></p>
<p>对于理想的目标函数f，我们是不知道的，我们手上拿到的是一些训练样本D，假设是监督式学习，其中有输入x，也有输出y。机器学习的过程，就是根据先验知识选择模型，该模型对应的hypothesis set（用H表示），H中包含了许多不同的hypothesis，通过演算法A，在训练样本D上进行训练，选择出一个最好的hypothes，对应的函数表达式g就是我们最终要求的。一般情况下，g能最接近目标函数f，这样，机器学习的整个流程就完成了。</p>
<h3><span id="四-machine-learning-and-other-fields"><strong>四、Machine Learning and Other Fields</strong></span></h3><p>与机器学习相关的领域有：</p>
<ul>
<li><p>数据挖掘（Data Mining）</p>
</li>
<li><p>人工智能（Artificial Intelligence）</p>
</li>
<li><p>统计（Statistics）</p>
</li>
</ul>
<p>其实，机器学习与这三个领域是相通的，基本类似，但也不完全一样。机器学习是这三个领域中的有力工具，而同时，这三个领域也是机器学习可以广泛应用的领域，总得来说，他们之间没有十分明确的界线。</p>
<h3><span id="五-总结"><strong>五、总结</strong></span></h3><p>本节课主要介绍了什么是机器学习，什么样的场合下可以使用机器学习解决问题，然后用流程图的形式展示了机器学习的整个过程，最后把机器学习和数据挖掘、人工智能、统计这三个领域做个比较。本节课的内容主要是概述性的东西，比较简单，所以笔记也相对比较简略。</p>
<p>这里附上林轩田（Hsuan-Tien Lin）关于这门课的主页：<br><a href="http://www.csie.ntu.edu.tw/~htlin/">http://www.csie.ntu.edu.tw/~htlin/</a></p>
<p><strong><em>注明：</em></strong></p>
<p>文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。</p>
]]></content>
      <categories>
        <category>机器学习基石</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-16.ipython高级应用</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-16-ipython%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>第2章中，我们学习了IPython shell和Jupyter notebook的基础。本章中，我们会探索IPython更深层次的功能，可以从控制台或在jupyter使用。</p>
<span id="more"></span>
<h1><span id="b1-使用命令历史">B.1 使用命令历史</span></h1><p>Ipython维护了一个位于磁盘的小型数据库，用于保存执行的每条指令。它的用途有：</p>
<ul>
<li>只用最少的输入，就能搜索、补全和执行先前运行过的指令；</li>
<li>在不同session间保存命令历史；</li>
<li>将日志输入/输出历史到一个文件</li>
</ul>
<p>这些功能在shell中，要比notebook更为有用，因为notebook从设计上是将输入和输出的代码放到每个代码格子中。</p>
<h2><span id="搜索和重复使用命令历史">搜索和重复使用命令历史</span></h2><p>Ipython可以让你搜索和执行之前的代码或其他命令。这个功能非常有用，因为你可能需要重复执行同样的命令，例如%run命令，或其它代码。假设你必须要执行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In[<span class="number">7</span>]: %run first/second/third/data_script.py</span><br></pre></td></tr></table></figure></p>
<p>运行成功，然后检查结果，发现计算有错。解决完问题，然后修改了data_script.py，你就可以输入一些%run命令，然后按Ctrl+P或上箭头。这样就可以搜索历史命令，匹配输入字符的命令。多次按Ctrl+P或上箭头，会继续搜索命令。如果你要执行你想要执行的命令，不要害怕。你可以按下Ctrl-N或下箭头，向前移动历史命令。这样做了几次后，你可以不假思索地按下这些键！</p>
<p>Ctrl-R可以带来如同Unix风格shell（比如bash shell）的readline的部分增量搜索功能。在Windows上，readline功能是被IPython模仿的。要使用这个功能，先按Ctrl-R，然后输入一些包含于输入行的想要搜索的字符：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: a_command = foo(x, y, z)</span><br><span class="line"></span><br><span class="line">(reverse-i-search)`com<span class="string">&#x27;: a_command = foo(x, y, z)</span></span><br></pre></td></tr></table></figure></p>
<p>Ctrl-R会循环历史，找到匹配字符的每一行。</p>
<h2><span id="输入和输出变量">输入和输出变量</span></h2><p>忘记将函数调用的结果分配给变量是非常烦人的。IPython的一个session会在一个特殊变量，存储输入和输出Python对象的引用。前面两个输出会分别存储在 <em>（一个下划线）和 _</em>（两个下划线）变量：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: <span class="number">2</span> ** <span class="number">27</span></span><br><span class="line">Out[<span class="number">24</span>]: <span class="number">134217728</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: _</span><br><span class="line">Out[<span class="number">25</span>]: <span class="number">134217728</span></span><br></pre></td></tr></table></figure></p>
<p>输入变量是存储在名字类似_iX的变量中，X是输入行的编号。对于每个输入变量，都有一个对应的输出变量_X。因此在输入第27行之后，会有两个新变量_27 （输出）和_i27（输入）:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">26</span>]: foo = <span class="string">&#x27;bar&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: foo</span><br><span class="line">Out[<span class="number">27</span>]: <span class="string">&#x27;bar&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: _i27</span><br><span class="line">Out[<span class="number">28</span>]: <span class="string">u&#x27;foo&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: _27</span><br><span class="line">Out[<span class="number">29</span>]: <span class="string">&#x27;bar&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>因为输入变量是字符串，它们可以用Python的exec关键字再次执行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">30</span>]: <span class="built_in">exec</span>(_i27)</span><br></pre></td></tr></table></figure></p>
<p>这里，_i27是在In [27]输入的代码。</p>
<p>有几个魔术函数可以让你利用输入和输出历史。%hist可以打印所有或部分的输入历史，加上或不加上编号。%reset可以清理交互命名空间，或输入和输出缓存。%xdel魔术函数可以去除IPython中对一个特别对象的所有引用。对于关于这些魔术方法的更多内容，请查看文档。</p>
<blockquote>
<p>警告：当处理非常大的数据集时，要记住IPython的输入和输出的历史会造成被引用的对象不被垃圾回收（释放内存），即使你使用del关键字从交互命名空间删除变量。在这种情况下，小心使用xdel %和%reset可以帮助你避免陷入内存问题。</p>
</blockquote>
<h1><span id="b2-与操作系统交互">B.2 与操作系统交互</span></h1><p>IPython的另一个功能是无缝连接文件系统和操作系统。这意味着，在同时做其它事时，无需退出IPython，就可以像Windows或Unix使用命令行操作，包括shell命令、更改目录、用Python对象（列表或字符串）存储结果。它还有简单的命令别名和目录书签功能。</p>
<p>表B-1总结了调用shell命令的魔术函数和语法。我会在下面几节介绍这些功能。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-4da7ee14be2da211.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表B-1 IPython系统相关命令"></p>
<h2><span id="shell命令和别名">Shell命令和别名</span></h2><p>用叹号开始一行，是告诉IPython执行叹号后面的所有内容。这意味着你可以删除文件（取决于操作系统，用rm或del）、改变目录或执行任何其他命令。</p>
<p>通过给变量加上叹号，你可以在一个变量中存储命令的控制台输出。例如，在我联网的基于Linux的主机上，我可以获得IP地址为Python变量：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: ip_info = !ifconfig wlan0 | grep <span class="string">&quot;inet &quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: ip_info[<span class="number">0</span>].strip()</span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">&#x27;inet addr:10.0.0.11  Bcast:10.0.0.255  Mask:255.255.255.0&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>返回的Python对象ip_info实际上是一个自定义的列表类型，它包含着多种版本的控制台输出。</p>
<p>当使用！，IPython还可以替换定义在当前环境的Python值。要这么做，可以在变量名前面加上$符号：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">3</span>]: foo = <span class="string">&#x27;test*&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: !ls $foo</span><br><span class="line">test4.py  test.py  test.xml</span><br></pre></td></tr></table></figure></p>
<p>%alias魔术函数可以自定义shell命令的快捷方式。看一个简单的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: %alias ll ls -l</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: ll /usr</span><br><span class="line">total <span class="number">332</span></span><br><span class="line">drwxr-xr-x   <span class="number">2</span> root root  <span class="number">69632</span> <span class="number">2012</span>-01-<span class="number">29</span> <span class="number">20</span>:<span class="number">36</span> <span class="built_in">bin</span>/</span><br><span class="line">drwxr-xr-x   <span class="number">2</span> root root   <span class="number">4096</span> <span class="number">2010</span>-08-<span class="number">23</span> <span class="number">12</span>:05 games/</span><br><span class="line">drwxr-xr-x <span class="number">123</span> root root  <span class="number">20480</span> <span class="number">2011</span>-<span class="number">12</span>-<span class="number">26</span> <span class="number">18</span>:08 include/</span><br><span class="line">drwxr-xr-x <span class="number">265</span> root root <span class="number">126976</span> <span class="number">2012</span>-01-<span class="number">29</span> <span class="number">20</span>:<span class="number">36</span> lib/</span><br><span class="line">drwxr-xr-x  <span class="number">44</span> root root  <span class="number">69632</span> <span class="number">2011</span>-<span class="number">12</span>-<span class="number">26</span> <span class="number">18</span>:08 lib32/</span><br><span class="line">lrwxrwxrwx   <span class="number">1</span> root root      <span class="number">3</span> <span class="number">2010</span>-08-<span class="number">23</span> <span class="number">16</span>:02 lib64 -&gt; lib/</span><br><span class="line">drwxr-xr-x  <span class="number">15</span> root root   <span class="number">4096</span> <span class="number">2011</span>-<span class="number">10</span>-<span class="number">13</span> <span class="number">19</span>:03 local/</span><br><span class="line">drwxr-xr-x   <span class="number">2</span> root root  <span class="number">12288</span> <span class="number">2012</span>-01-<span class="number">12</span> 09:<span class="number">32</span> sbin/</span><br><span class="line">drwxr-xr-x <span class="number">387</span> root root  <span class="number">12288</span> <span class="number">2011</span>-<span class="number">11</span>-04 <span class="number">22</span>:<span class="number">53</span> share/</span><br><span class="line">drwxrwsr-x  <span class="number">24</span> root src    <span class="number">4096</span> <span class="number">2011</span>-07-<span class="number">17</span> <span class="number">18</span>:<span class="number">38</span> src/</span><br></pre></td></tr></table></figure></p>
<p>你可以执行多个命令，就像在命令行中一样，只需用分号隔开：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">558</span>]: %alias test_alias (cd examples; ls; cd ..)</span><br><span class="line"></span><br><span class="line">In [<span class="number">559</span>]: test_alias</span><br><span class="line">macrodata.csv  spx.csv	tips.csv</span><br></pre></td></tr></table></figure></p>
<p>当session结束，你定义的别名就会失效。要创建恒久的别名，需要使用配置。</p>
<h2><span id="目录书签系统">目录书签系统</span></h2><p>IPython有一个简单的目录书签系统，可以让你保存常用目录的别名，这样在跳来跳去的时候会非常方便。例如，假设你想创建一个书签，指向本书的补充内容：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">6</span>]: %bookmark py4da /home/wesm/code/pydata-book</span><br></pre></td></tr></table></figure></p>
<p>这么做之后，当使用%cd魔术命令，就可以使用定义的书签：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">7</span>]: cd py4da</span><br><span class="line">(bookmark:py4da) -&gt; /home/wesm/code/pydata-book</span><br><span class="line">/home/wesm/code/pydata-book</span><br></pre></td></tr></table></figure></p>
<p>如果书签的名字，与当前工作目录的一个目录重名，你可以使用-b标志来覆写，使用书签的位置。使用%bookmark的-l选项，可以列出所有的书签：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: %bookmark -l</span><br><span class="line">Current bookmarks:</span><br><span class="line">py4da -&gt; /home/wesm/code/pydata-book-source</span><br></pre></td></tr></table></figure></p>
<p>书签，和别名不同，在session之间是保持的。</p>
<h1><span id="b3-软件开发工具">B.3 软件开发工具</span></h1><p>除了作为优秀的交互式计算和数据探索环境，IPython也是有效的Python软件开发工具。在数据分析中，最重要的是要有正确的代码。幸运的是，IPython紧密集成了和加强了Python内置的pdb调试器。第二，需要快速的代码。对于这点，IPython有易于使用的代码计时和分析工具。我会详细介绍这些工具。</p>
<h2><span id="交互调试器">交互调试器</span></h2><p>IPython的调试器用tab补全、语法增强、逐行异常追踪增强了pdb。调试代码的最佳时间就是刚刚发生错误。异常发生之后就输入%debug，就启动了调试器，进入抛出异常的堆栈框架：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">2</span>]: run examples/ipython_bug.py</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AssertionError                            Traceback (most recent call last)</span><br><span class="line">/home/wesm/code/pydata-book/examples/ipython_bug.py <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">     <span class="number">13</span>     throws_an_exception()</span><br><span class="line">     <span class="number">14</span></span><br><span class="line">---&gt; <span class="number">15</span> calling_things()</span><br><span class="line"></span><br><span class="line">/home/wesm/code/pydata-book/examples/ipython_bug.py <span class="keyword">in</span> calling_things()</span><br><span class="line"><span class="number">11</span> <span class="function"><span class="keyword">def</span> <span class="title">calling_things</span>():</span></span><br><span class="line">     <span class="number">12</span>     works_fine()</span><br><span class="line">---&gt; <span class="number">13</span>     throws_an_exception()</span><br><span class="line">     <span class="number">14</span></span><br><span class="line">     <span class="number">15</span> calling_things()</span><br><span class="line"></span><br><span class="line">/home/wesm/code/pydata-book/examples/ipython_bug.py <span class="keyword">in</span> throws_an_exception()</span><br><span class="line">      <span class="number">7</span>     a = <span class="number">5</span></span><br><span class="line">      <span class="number">8</span>     b = <span class="number">6</span></span><br><span class="line">----&gt; <span class="number">9</span>     <span class="keyword">assert</span>(a + b == <span class="number">10</span>)</span><br><span class="line">     <span class="number">10</span></span><br><span class="line">     <span class="number">11</span> <span class="function"><span class="keyword">def</span> <span class="title">calling_things</span>():</span></span><br><span class="line"></span><br><span class="line">AssertionError:</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: %debug</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">9</span>)throws_an_exception()</span><br><span class="line">      <span class="number">8</span>     b = <span class="number">6</span></span><br><span class="line">----&gt; <span class="number">9</span>     <span class="keyword">assert</span>(a + b == <span class="number">10</span>)</span><br><span class="line">     <span class="number">10</span></span><br><span class="line"></span><br><span class="line">ipdb&gt;</span><br></pre></td></tr></table></figure>
<p>一旦进入调试器，你就可以执行任意的Python代码，在每个堆栈框架中检查所有的对象和数据（解释器会保持它们活跃）。默认是从错误发生的最低级开始。通过u（up）和d（down），你可以在不同等级的堆栈踪迹切换：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ipdb&gt; u</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">13</span>)calling_things()</span><br><span class="line">     <span class="number">12</span>     works_fine()</span><br><span class="line">---&gt; <span class="number">13</span>     throws_an_exception()</span><br><span class="line">     <span class="number">14</span></span><br></pre></td></tr></table></figure></p>
<p>执行%pdb命令，可以在发生任何异常时让IPython自动启动调试器，许多用户会发现这个功能非常好用。</p>
<p>用调试器帮助开发代码也很容易，特别是当你希望设置断点或在函数和脚本间移动，以检查每个阶段的状态。有多种方法可以实现。第一种是使用%run和-d，它会在执行传入脚本的任何代码之前调用调试器。你必须马上按s（step）以进入脚本：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: run -d examples/ipython_bug.py</span><br><span class="line">Breakpoint <span class="number">1</span> at /home/wesm/code/pydata-book/examples/ipython_bug.py:<span class="number">1</span></span><br><span class="line">NOTE: Enter <span class="string">&#x27;c&#x27;</span> at the ipdb&gt;  prompt to start your script.</span><br><span class="line">&gt; &lt;string&gt;(<span class="number">1</span>)&lt;module&gt;()</span><br><span class="line"></span><br><span class="line">ipdb&gt; s</span><br><span class="line">--Call--</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">1</span>)&lt;module&gt;()</span><br><span class="line"><span class="number">1</span>---&gt; <span class="number">1</span> <span class="function"><span class="keyword">def</span> <span class="title">works_fine</span>():</span></span><br><span class="line">      <span class="number">2</span>     a = <span class="number">5</span></span><br><span class="line">      <span class="number">3</span>     b = <span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<p>然后，你就可以决定如何工作。例如，在前面的异常，我们可以设置一个断点，就在调用works_fine之前，然后运行脚本，在遇到断点时按c（continue）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ipdb&gt; b <span class="number">12</span></span><br><span class="line">ipdb&gt; c</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">12</span>)calling_things()</span><br><span class="line">     <span class="number">11</span> <span class="function"><span class="keyword">def</span> <span class="title">calling_things</span>():</span></span><br><span class="line"><span class="number">2</span>--&gt; <span class="number">12</span>     works_fine()</span><br><span class="line">     <span class="number">13</span>     throws_an_exception()</span><br></pre></td></tr></table></figure></p>
<p>这时，你可以step进入works_fine()，或通过按n（next）执行works_fine()，进入下一行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ipdb&gt; n</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">13</span>)calling_things()</span><br><span class="line"><span class="number">2</span>    <span class="number">12</span>     works_fine()</span><br><span class="line">---&gt; <span class="number">13</span>     throws_an_exception()</span><br><span class="line">     <span class="number">14</span></span><br></pre></td></tr></table></figure></p>
<p>然后，我们可以进入throws_an_exception，到达发生错误的一行，查看变量。注意，调试器的命令是在变量名之前，在变量名前面加叹号！可以查看内容：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ipdb&gt; s</span><br><span class="line">--Call--</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">6</span>)throws_an_exception()</span><br><span class="line">      <span class="number">5</span></span><br><span class="line">----&gt; <span class="number">6</span> <span class="function"><span class="keyword">def</span> <span class="title">throws_an_exception</span>():</span></span><br><span class="line">      <span class="number">7</span>     a = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">ipdb&gt; n</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">7</span>)throws_an_exception()</span><br><span class="line">      <span class="number">6</span> <span class="function"><span class="keyword">def</span> <span class="title">throws_an_exception</span>():</span></span><br><span class="line">----&gt; <span class="number">7</span>     a = <span class="number">5</span></span><br><span class="line">      <span class="number">8</span>     b = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">ipdb&gt; n</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">8</span>)throws_an_exception()</span><br><span class="line">      <span class="number">7</span>     a = <span class="number">5</span></span><br><span class="line">----&gt; <span class="number">8</span>     b = <span class="number">6</span></span><br><span class="line">      <span class="number">9</span>     <span class="keyword">assert</span>(a + b == <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ipdb&gt; n</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">9</span>)throws_an_exception()</span><br><span class="line">      <span class="number">8</span>     b = <span class="number">6</span></span><br><span class="line">----&gt; <span class="number">9</span>     <span class="keyword">assert</span>(a + b == <span class="number">10</span>)</span><br><span class="line">     <span class="number">10</span></span><br><span class="line"></span><br><span class="line">ipdb&gt; !a</span><br><span class="line"><span class="number">5</span></span><br><span class="line">ipdb&gt; !b</span><br><span class="line"><span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<p>提高使用交互式调试器的熟练度需要练习和经验。表B-2，列出了所有调试器命令。如果你习惯了IDE，你可能觉得终端的调试器在一开始会不顺手，但会觉得越来越好用。一些Python的IDEs有很好的GUI调试器，选择顺手的就好。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-90a4b17e20b5b03a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表B-2 IPython调试器命令"></p>
<h2><span id="使用调试器的其它方式">使用调试器的其它方式</span></h2><p>还有一些其它工作可以用到调试器。第一个是使用特殊的set_trace函数（根据pdb.set_trace命名的），这是一个简装的断点。还有两种方法是你可能想用的（像我一样，将其添加到IPython的配置）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.core.debugger <span class="keyword">import</span> Pdb</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_trace</span>():</span></span><br><span class="line">    Pdb(color_scheme=<span class="string">&#x27;Linux&#x27;</span>).set_trace(sys._getframe().f_back)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">debug</span>(<span class="params">f, *args, **kwargs</span>):</span></span><br><span class="line">    pdb = Pdb(color_scheme=<span class="string">&#x27;Linux&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pdb.runcall(f, *args, **kwargs)</span><br></pre></td></tr></table></figure><br>第一个函数set_trace非常简单。如果你想暂时停下来进行仔细检查（比如发生异常之前），可以在代码的任何位置使用set_trace：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">7</span>]: run examples/ipython_bug.py</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">16</span>)calling_things()</span><br><span class="line">     <span class="number">15</span>     set_trace()</span><br><span class="line">---&gt; <span class="number">16</span>     throws_an_exception()</span><br><span class="line">     <span class="number">17</span></span><br></pre></td></tr></table></figure></p>
<p>按c（continue）可以让代码继续正常行进。</p>
<p>我们刚看的debug函数，可以让你方便的在调用任何函数时使用调试器。假设我们写了一个下面的函数，想逐步分析它的逻辑：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x, y, z=<span class="number">1</span></span>):</span></span><br><span class="line">    tmp = x + y</span><br><span class="line">    <span class="keyword">return</span> tmp / z</span><br></pre></td></tr></table></figure></p>
<p>普通地使用f，就会像f(1, 2, z=3)。而要想进入f，将f作为第一个参数传递给debug，再将位置和关键词参数传递给f：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">6</span>]: debug(f, <span class="number">1</span>, <span class="number">2</span>, z=<span class="number">3</span>)</span><br><span class="line">&gt; &lt;ipython-<span class="built_in">input</span>&gt;(<span class="number">2</span>)f()</span><br><span class="line">      <span class="number">1</span> <span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x, y, z</span>):</span></span><br><span class="line">----&gt; <span class="number">2</span>     tmp = x + y</span><br><span class="line">      <span class="number">3</span>     <span class="keyword">return</span> tmp / z</span><br><span class="line"></span><br><span class="line">ipdb&gt;</span><br></pre></td></tr></table></figure></p>
<p>这两个简单方法节省了我平时的大量时间。</p>
<p>最后，调试器可以和%run一起使用。脚本通过运行%run -d，就可以直接进入调试器，随意设置断点并启动脚本：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: %run -d examples/ipython_bug.py</span><br><span class="line">Breakpoint <span class="number">1</span> at /home/wesm/code/pydata-book/examples/ipython_bug.py:<span class="number">1</span></span><br><span class="line">NOTE: Enter <span class="string">&#x27;c&#x27;</span> at the ipdb&gt;  prompt to start your script.</span><br><span class="line">&gt; &lt;string&gt;(<span class="number">1</span>)&lt;module&gt;()</span><br><span class="line"></span><br><span class="line">ipdb&gt;</span><br></pre></td></tr></table></figure></p>
<p>加上-b和行号，可以预设一个断点：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">2</span>]: %run -d -b2 examples/ipython_bug.py</span><br><span class="line"></span><br><span class="line">Breakpoint <span class="number">1</span> at /home/wesm/code/pydata-book/examples/ipython_bug.py:<span class="number">2</span></span><br><span class="line">NOTE: Enter <span class="string">&#x27;c&#x27;</span> at the ipdb&gt;  prompt to start your script.</span><br><span class="line">&gt; &lt;string&gt;(<span class="number">1</span>)&lt;module&gt;()</span><br><span class="line"></span><br><span class="line">ipdb&gt; c</span><br><span class="line">&gt; /home/wesm/code/pydata-book/examples/ipython_bug.py(<span class="number">2</span>)works_fine()</span><br><span class="line">      <span class="number">1</span> <span class="function"><span class="keyword">def</span> <span class="title">works_fine</span>():</span></span><br><span class="line"><span class="number">1</span>---&gt; <span class="number">2</span>     a = <span class="number">5</span></span><br><span class="line">      <span class="number">3</span>     b = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">ipdb&gt;</span><br></pre></td></tr></table></figure></p>
<h2><span id="代码计时time-和-timeit">代码计时：%time 和 %timeit</span></h2><p>对于大型和长时间运行的数据分析应用，你可能希望测量不同组件或单独函数调用语句的执行时间。你可能想知道哪个函数占用的时间最长。幸运的是，IPython可以让你开发和测试代码时，很容易地获得这些信息。</p>
<p>手动用time模块和它的函数time.clock和time.time给代码计时，既单调又重复，因为必须要写一些无趣的模板化代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">    <span class="comment"># some code to run here</span></span><br><span class="line">elapsed_per = (time.time() - start) / iterations</span><br></pre></td></tr></table></figure></p>
<p>因为这是一个很普通的操作，IPython有两个魔术函数，%time和%timeit，可以自动化这个过程。</p>
<p>%time会运行一次语句，报告总共的执行时间。假设我们有一个大的字符串列表，我们想比较不同的可以挑选出特定开头字符串的方法。这里有一个含有600000字符串的列表，和两个方法，用以选出foo开头的字符串：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># a very large list of strings</span></span><br><span class="line">strings = [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;foobar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;qux&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;python&#x27;</span>, <span class="string">&#x27;Guido Van Rossum&#x27;</span>] * <span class="number">100000</span></span><br><span class="line"></span><br><span class="line">method1 = [x <span class="keyword">for</span> x <span class="keyword">in</span> strings <span class="keyword">if</span> x.startswith(<span class="string">&#x27;foo&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">method2 = [x <span class="keyword">for</span> x <span class="keyword">in</span> strings <span class="keyword">if</span> x[:<span class="number">3</span>] == <span class="string">&#x27;foo&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>看起来它们的性能应该是同级别的，但事实呢？用%time进行一下测量：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">561</span>]: %time method1 = [x <span class="keyword">for</span> x <span class="keyword">in</span> strings <span class="keyword">if</span> x.startswith(<span class="string">&#x27;foo&#x27;</span>)]</span><br><span class="line">CPU times: user <span class="number">0.19</span> s, sys: <span class="number">0.00</span> s, total: <span class="number">0.19</span> s</span><br><span class="line">Wall time: <span class="number">0.19</span> s</span><br><span class="line"></span><br><span class="line">In [<span class="number">562</span>]: %time method2 = [x <span class="keyword">for</span> x <span class="keyword">in</span> strings <span class="keyword">if</span> x[:<span class="number">3</span>] == <span class="string">&#x27;foo&#x27;</span>]</span><br><span class="line">CPU times: user <span class="number">0.09</span> s, sys: <span class="number">0.00</span> s, total: <span class="number">0.09</span> s</span><br><span class="line">Wall time: <span class="number">0.09</span> s</span><br></pre></td></tr></table></figure></p>
<p>Wall time（wall-clock time的简写）是主要关注的。第一个方法是第二个方法的两倍多，但是这种测量方法并不准确。如果用%time多次测量，你就会发现结果是变化的。要想更准确，可以使用%timeit魔术函数。给出任意一条语句，它能多次运行这条语句以得到一个更为准确的时间：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">563</span>]: %timeit [x <span class="keyword">for</span> x <span class="keyword">in</span> strings <span class="keyword">if</span> x.startswith(<span class="string">&#x27;foo&#x27;</span>)]</span><br><span class="line"><span class="number">10</span> loops, best of <span class="number">3</span>: <span class="number">159</span> ms per loop</span><br><span class="line"></span><br><span class="line">In [<span class="number">564</span>]: %timeit [x <span class="keyword">for</span> x <span class="keyword">in</span> strings <span class="keyword">if</span> x[:<span class="number">3</span>] == <span class="string">&#x27;foo&#x27;</span>]</span><br><span class="line"><span class="number">10</span> loops, best of <span class="number">3</span>: <span class="number">59.3</span> ms per loop</span><br></pre></td></tr></table></figure></p>
<p>这个例子说明了解Python标准库、NumPy、pandas和其它库的性能是很有价值的。在大型数据分析中，这些毫秒的时间就会累积起来！</p>
<p>%timeit特别适合分析执行时间短的语句和函数，即使是微秒或纳秒。这些时间可能看起来毫不重要，但是一个20微秒的函数执行1百万次就比一个5微秒的函数长15秒。在上一个例子中，我们可以直接比较两个字符串操作，以了解它们的性能特点：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">565</span>]: x = <span class="string">&#x27;foobar&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">566</span>]: y = <span class="string">&#x27;foo&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">567</span>]: %timeit x.startswith(y)</span><br><span class="line"><span class="number">1000000</span> loops, best of <span class="number">3</span>: <span class="number">267</span> ns per loop</span><br><span class="line"></span><br><span class="line">In [<span class="number">568</span>]: %timeit x[:<span class="number">3</span>] == y</span><br><span class="line"><span class="number">10000000</span> loops, best of <span class="number">3</span>: <span class="number">147</span> ns per loop</span><br></pre></td></tr></table></figure></p>
<h2><span id="基础分析prun和run-p">基础分析：%prun和%run -p</span></h2><p>分析代码与代码计时关系很紧密，除了它关注的是“时间花在了哪里”。Python主要的分析工具是cProfile模块，它并不局限于IPython。cProfile会执行一个程序或任意的代码块，并会跟踪每个函数执行的时间。</p>
<p>使用cProfile的通常方式是在命令行中运行一整段程序，输出每个函数的累积时间。假设我们有一个简单的在循环中进行线型代数运算的脚本（计算一系列的100×100矩阵的最大绝对特征值）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> eigvals</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_experiment</span>(<span class="params">niter=<span class="number">100</span></span>):</span></span><br><span class="line">    K = <span class="number">100</span></span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> xrange(niter):</span><br><span class="line">        mat = np.random.randn(K, K)</span><br><span class="line">        max_eigenvalue = np.<span class="built_in">abs</span>(eigvals(mat)).<span class="built_in">max</span>()</span><br><span class="line">        results.append(max_eigenvalue)</span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line">some_results = run_experiment()</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Largest one we saw: %s&#x27;</span> % np.<span class="built_in">max</span>(some_results)</span><br></pre></td></tr></table></figure></p>
<p>你可以用cProfile运行这个脚本，使用下面的命令行：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m cProfile cprof_example.py</span><br></pre></td></tr></table></figure></p>
<p>运行之后，你会发现输出是按函数名排序的。这样要看出谁耗费的时间多有点困难，最好用-s指定排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python -m cProfile -s cumulative cprof_example.py</span><br><span class="line">Largest one we saw: <span class="number">11.923204422</span></span><br><span class="line">    <span class="number">15116</span> function calls (<span class="number">14927</span> primitive calls) <span class="keyword">in</span> <span class="number">0.720</span> seconds</span><br><span class="line"></span><br><span class="line">Ordered by: cumulative time</span><br><span class="line"></span><br><span class="line">ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.721</span>    <span class="number">0.721</span> cprof_example.py:<span class="number">1</span>(&lt;module&gt;)</span><br><span class="line">   <span class="number">100</span>    <span class="number">0.003</span>    <span class="number">0.000</span>    <span class="number">0.586</span>    <span class="number">0.006</span> linalg.py:<span class="number">702</span>(eigvals)</span><br><span class="line">   <span class="number">200</span>    <span class="number">0.572</span>    <span class="number">0.003</span>    <span class="number">0.572</span>    <span class="number">0.003</span> &#123;numpy.linalg.lapack_lite.dgeev&#125;</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.002</span>    <span class="number">0.002</span>    <span class="number">0.075</span>    <span class="number">0.075</span> __init__.py:<span class="number">106</span>(&lt;module&gt;)</span><br><span class="line">   <span class="number">100</span>    <span class="number">0.059</span>    <span class="number">0.001</span>    <span class="number">0.059</span>    <span class="number">0.001</span> &#123;method <span class="string">&#x27;randn&#x27;</span>)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.044</span>    <span class="number">0.044</span> add_newdocs.py:<span class="number">9</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">2</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.037</span>    <span class="number">0.019</span> __init__.py:<span class="number">1</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">2</span>    <span class="number">0.003</span>    <span class="number">0.002</span>    <span class="number">0.030</span>    <span class="number">0.015</span> __init__.py:<span class="number">2</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.030</span>    <span class="number">0.030</span> type_check.py:<span class="number">3</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.021</span>    <span class="number">0.021</span> __init__.py:<span class="number">15</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.013</span>    <span class="number">0.013</span>    <span class="number">0.013</span>    <span class="number">0.013</span> numeric.py:<span class="number">1</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.009</span>    <span class="number">0.009</span> __init__.py:<span class="number">6</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.008</span>    <span class="number">0.008</span> __init__.py:<span class="number">45</span>(&lt;module&gt;)</span><br><span class="line">   <span class="number">262</span>    <span class="number">0.005</span>    <span class="number">0.000</span>    <span class="number">0.007</span>    <span class="number">0.000</span> function_base.py:<span class="number">3178</span>(add_newdoc)</span><br><span class="line">   <span class="number">100</span>    <span class="number">0.003</span>    <span class="number">0.000</span>    <span class="number">0.005</span>    <span class="number">0.000</span> linalg.py:<span class="number">162</span>(_assertFinite)</span><br></pre></td></tr></table></figure></p>
<p>只显示出前15行。扫描cumtime列，可以容易地看出每个函数用了多少时间。如果一个函数调用了其它函数，计时并不会停止。cProfile会记录每个函数的起始和结束时间，使用它们进行计时。</p>
<p>除了在命令行中使用，cProfile也可以在程序中使用，分析任意代码块，而不必运行新进程。Ipython的%prun和%run -p，有便捷的接口实现这个功能。%prun使用类似cProfile的命令行选项，但是可以分析任意Python语句，而不用整个py文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">4</span>]: %prun -l <span class="number">7</span> -s cumulative run_experiment()</span><br><span class="line">         <span class="number">4203</span> function calls <span class="keyword">in</span> <span class="number">0.643</span> seconds</span><br><span class="line"></span><br><span class="line">Ordered by: cumulative time</span><br><span class="line"><span class="type">List</span> reduced <span class="keyword">from</span> <span class="number">32</span> to <span class="number">7</span> due to restriction &lt;<span class="number">7</span>&gt;</span><br><span class="line">ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.643</span>    <span class="number">0.643</span> &lt;string&gt;:<span class="number">1</span>(&lt;module&gt;)</span><br><span class="line">     <span class="number">1</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.643</span>    <span class="number">0.643</span> cprof_example.py:<span class="number">4</span>(run_experiment)</span><br><span class="line">   <span class="number">100</span>    <span class="number">0.003</span>    <span class="number">0.000</span>    <span class="number">0.583</span>    <span class="number">0.006</span> linalg.py:<span class="number">702</span>(eigvals)</span><br><span class="line">   <span class="number">200</span>    <span class="number">0.569</span>    <span class="number">0.003</span>    <span class="number">0.569</span>    <span class="number">0.003</span> &#123;numpy.linalg.lapack_lite.dgeev&#125;</span><br><span class="line">   <span class="number">100</span>    <span class="number">0.058</span>    <span class="number">0.001</span>    <span class="number">0.058</span>    <span class="number">0.001</span> &#123;method <span class="string">&#x27;randn&#x27;</span>&#125;</span><br><span class="line">   <span class="number">100</span>    <span class="number">0.003</span>    <span class="number">0.000</span>    <span class="number">0.005</span>    <span class="number">0.000</span> linalg.py:<span class="number">162</span>(_assertFinite)</span><br><span class="line">   <span class="number">200</span>    <span class="number">0.002</span>    <span class="number">0.000</span>    <span class="number">0.002</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;all&#x27;</span> of <span class="string">&#x27;numpy.ndarray&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>相似的，调用<code>%run -p -s cumulative cprof_example.py</code>有和命令行相似的作用，只是你不用离开Ipython。</p>
<p>在Jupyter notebook中，你可以使用%%prun魔术方法（两个%）来分析一整段代码。这会弹出一个带有分析输出的独立窗口。便于快速回答一些问题，比如“为什么这段代码用了这么长时间”？</p>
<p>使用IPython或Jupyter，还有一些其它工具可以让分析工作更便于理解。其中之一是SnakeViz（<a href="https://github.com/jiffyclub/snakeviz/），它会使用d3.js产生一个分析结果的交互可视化界面。">https://github.com/jiffyclub/snakeviz/），它会使用d3.js产生一个分析结果的交互可视化界面。</a></p>
<h2><span id="逐行分析函数">逐行分析函数</span></h2><p>有些情况下，用%prun（或其它基于cProfile的分析方法）得到的信息，不能获得函数执行时间的整个过程，或者结果过于复杂，加上函数名，很难进行解读。对于这种情况，有一个小库叫做line_profiler（可以通过PyPI或包管理工具获得）。它包含IPython插件，可以启用一个新的魔术函数%lprun，可以对一个函数或多个函数进行逐行分析。你可以通过修改IPython配置（查看IPython文档或本章后面的配置小节）加入下面这行，启用这个插件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># A list of dotted module names of IPython extensions to load.</span></span><br><span class="line">c.TerminalIPythonApp.extensions = [<span class="string">&#x27;line_profiler&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>你还可以运行命令：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%load_ext line_profiler</span><br></pre></td></tr></table></figure></p>
<p>line_profiler也可以在程序中使用（查看完整文档），但是在IPython中使用是最为强大的。假设你有一个带有下面代码的模块prof_mod，做一些NumPy数组操作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> randn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_and_sum</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    added = x + y</span><br><span class="line">    summed = added.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> summed</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call_function</span>():</span></span><br><span class="line">    x = randn(<span class="number">1000</span>, <span class="number">1000</span>)</span><br><span class="line">    y = randn(<span class="number">1000</span>, <span class="number">1000</span>)</span><br><span class="line">    <span class="keyword">return</span> add_and_sum(x, y)</span><br></pre></td></tr></table></figure></p>
<p>如果想了解add_and_sum函数的性能，%prun可以给出下面内容：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">569</span>]: %run prof_mod</span><br><span class="line"></span><br><span class="line">In [<span class="number">570</span>]: x = randn(<span class="number">3000</span>, <span class="number">3000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">571</span>]: y = randn(<span class="number">3000</span>, <span class="number">3000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">572</span>]: %prun add_and_sum(x, y)</span><br><span class="line">         <span class="number">4</span> function calls <span class="keyword">in</span> <span class="number">0.049</span> seconds</span><br><span class="line">   Ordered by: internal time</span><br><span class="line">   ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.036</span>    <span class="number">0.036</span>    <span class="number">0.046</span>    <span class="number">0.046</span> prof_mod.py:<span class="number">3</span>(add_and_sum)</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.009</span>    <span class="number">0.009</span>    <span class="number">0.009</span>    <span class="number">0.009</span> &#123;method <span class="string">&#x27;sum&#x27;</span> of <span class="string">&#x27;numpy.ndarray&#x27;</span>&#125;</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.003</span>    <span class="number">0.003</span>    <span class="number">0.049</span>    <span class="number">0.049</span> &lt;string&gt;:<span class="number">1</span>(&lt;module&gt;)</span><br></pre></td></tr></table></figure></p>
<p>上面的做法启发性不大。激活了IPython插件line_profiler，新的命令%lprun就能用了。使用中的不同点是，我们必须告诉%lprun要分析的函数是哪个。语法是：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%lprun -f func1 -f func2 statement_to_profile</span><br></pre></td></tr></table></figure></p>
<p>我们想分析add_and_sum，运行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">573</span>]: %lprun -f add_and_sum add_and_sum(x, y)</span><br><span class="line">Timer unit: <span class="number">1e-06</span> s</span><br><span class="line">File: prof_mod.py</span><br><span class="line">Function: add_and_sum at line <span class="number">3</span></span><br><span class="line">Total time: <span class="number">0.045936</span> s</span><br><span class="line">Line <span class="comment">#      Hits         Time  Per Hit   % Time  Line Contents</span></span><br><span class="line">==============================================================</span><br><span class="line">     <span class="number">3</span>                                           <span class="function"><span class="keyword">def</span> <span class="title">add_and_sum</span>(<span class="params">x, y</span>):</span></span><br><span class="line">     <span class="number">4</span>         <span class="number">1</span>        <span class="number">36510</span>  <span class="number">36510.0</span>     <span class="number">79.5</span>      added = x + y</span><br><span class="line">     <span class="number">5</span>         <span class="number">1</span>         <span class="number">9425</span>   <span class="number">9425.0</span>     <span class="number">20.5</span>      summed = added.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">     <span class="number">6</span>         <span class="number">1</span>            <span class="number">1</span>      <span class="number">1.0</span>      <span class="number">0.0</span>      <span class="keyword">return</span> summed</span><br></pre></td></tr></table></figure></p>
<p>这样就容易诠释了。我们分析了和代码语句中一样的函数。看之前的模块代码，我们可以调用call_function并对它和add_and_sum进行分析，得到一个完整的代码性能概括：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">574</span>]: %lprun -f add_and_sum -f call_function call_function()</span><br><span class="line">Timer unit: <span class="number">1e-06</span> s</span><br><span class="line">File: prof_mod.py</span><br><span class="line">Function: add_and_sum at line <span class="number">3</span></span><br><span class="line">Total time: <span class="number">0.005526</span> s</span><br><span class="line">Line <span class="comment">#      Hits         Time  Per Hit   % Time  Line Contents</span></span><br><span class="line">==============================================================</span><br><span class="line">     <span class="number">3</span>                                           <span class="function"><span class="keyword">def</span> <span class="title">add_and_sum</span>(<span class="params">x, y</span>):</span></span><br><span class="line">     <span class="number">4</span>         <span class="number">1</span>         <span class="number">4375</span>   <span class="number">4375.0</span>     <span class="number">79.2</span>      added = x + y</span><br><span class="line">     <span class="number">5</span>         <span class="number">1</span>         <span class="number">1149</span>   <span class="number">1149.0</span>     <span class="number">20.8</span>      summed = added.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">     <span class="number">6</span>         <span class="number">1</span>            <span class="number">2</span>      <span class="number">2.0</span>      <span class="number">0.0</span>      <span class="keyword">return</span> summed</span><br><span class="line">File: prof_mod.py</span><br><span class="line">Function: call_function at line <span class="number">8</span></span><br><span class="line">Total time: <span class="number">0.121016</span> s</span><br><span class="line">Line <span class="comment">#      Hits         Time  Per Hit   % Time  Line Contents</span></span><br><span class="line">==============================================================</span><br><span class="line">     <span class="number">8</span>                                           <span class="function"><span class="keyword">def</span> <span class="title">call_function</span>():</span></span><br><span class="line">     <span class="number">9</span>         <span class="number">1</span>        <span class="number">57169</span>  <span class="number">57169.0</span>     <span class="number">47.2</span>      x = randn(<span class="number">1000</span>, <span class="number">1000</span>)</span><br><span class="line">    <span class="number">10</span>         <span class="number">1</span>        <span class="number">58304</span>  <span class="number">58304.0</span>     <span class="number">48.2</span>      y = randn(<span class="number">1000</span>, <span class="number">1000</span>)</span><br><span class="line">    <span class="number">11</span>         <span class="number">1</span>         <span class="number">5543</span>   <span class="number">5543.0</span>      <span class="number">4.6</span>      <span class="keyword">return</span> add_and_sum(x, y)</span><br></pre></td></tr></table></figure></p>
<p>我的经验是用%prun (cProfile)进行宏观分析，%lprun (line_profiler)做微观分析。最好对这两个工具都了解清楚。</p>
<blockquote>
<p>笔记：使用%lprun必须要指明函数名的原因是追踪每行的执行时间的损耗过多。追踪无用的函数会显著地改变结果。</p>
</blockquote>
<h1><span id="b4-使用ipython高效开发的技巧">B.4 使用IPython高效开发的技巧</span></h1><p>方便快捷地写代码、调试和使用是每个人的目标。除了代码风格，流程细节（比如代码重载）也需要一些调整。</p>
<p>因此，这一节的内容更像是门艺术而不是科学，还需要你不断的试验，以达成高效。最终，你要能结构优化代码，并且能省时省力地检查程序或函数的结果。我发现用IPython设计的软件比起命令行，要更适合工作。尤其是当发生错误时，你需要检查自己或别人写的数月或数年前写的代码的错误。</p>
<h2><span id="重载模块依赖">重载模块依赖</span></h2><p>在Python中，当你输入import some_lib，some_lib中的代码就会被执行，所有的变量、函数和定义的引入，就会被存入到新创建的some_lib模块命名空间。当下一次输入some_lib，就会得到一个已存在的模块命名空间的引用。潜在的问题是当你%run一个脚本，它依赖于另一个模块，而这个模块做过修改，就会产生问题。假设我在test_script.py中有如下代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> some_lib</span><br><span class="line"></span><br><span class="line">x = <span class="number">5</span></span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">result = some_lib.get_answer(x, y)</span><br></pre></td></tr></table></figure></p>
<p>如果你运行过了%run test_script.py，然后修改了some_lib.py，下一次再执行%run test_script.py，还会得到旧版本的some_lib.py，这是因为Python模块系统的“一次加载”机制。这一点区分了Python和其它数据分析环境，比如MATLAB，它会自动传播代码修改。解决这个问题，有多种方法。第一种是在标准库importlib模块中使用reload函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> some_lib</span><br><span class="line"><span class="keyword">import</span> importlib</span><br><span class="line"></span><br><span class="line">importlib.reload(some_lib)</span><br></pre></td></tr></table></figure></p>
<p>这可以保证每次运行test_script.py时可以加载最新的some_lib.py。很明显，如果依赖更深，在各处都使用reload是非常麻烦的。对于这个问题，IPython有一个特殊的dreload函数（它不是魔术函数）重载深层的模块。如果我运行过some_lib.py，然后输入dreload(some_lib)，就会尝试重载some_lib和它的依赖。不过，这个方法不适用于所有场景，但比重启IPython强多了。</p>
<h2><span id="代码设计技巧">代码设计技巧</span></h2><p>对于这单，没有简单的对策，但是有一些原则，是我在工作中发现很好用的。</p>
<h2><span id="保持相关对象和数据活跃">保持相关对象和数据活跃</span></h2><p>为命令行写一个下面示例中的程序是很少见的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> my_functions <span class="keyword">import</span> g</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> g(x + y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    x = <span class="number">6</span></span><br><span class="line">    y = <span class="number">7.5</span></span><br><span class="line">    result = x + y</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<p>在IPython中运行这个程序会发生问题，你发现是什么了吗？运行之后，任何定义在main函数中的结果和对象都不能在IPython中被访问到。更好的方法是将main中的代码直接在模块的命名空间中执行（或者在<code>__name__ == &#39;__main__&#39;:</code>中，如果你想让这个模块可以被引用）。这样，当你%rundiamante，就可以查看所有定义在main中的变量。这等价于在Jupyter notebook的代码格中定义一个顶级变量。</p>
<h2><span id="扁平优于嵌套">扁平优于嵌套</span></h2><p>深层嵌套的代码总让我联想到洋葱皮。当测试或调试一个函数时，你需要剥多少层洋葱皮才能到达目标代码呢？“扁平优于嵌套”是Python之禅的一部分，它也适用于交互式代码开发。尽量将函数和类去耦合和模块化，有利于测试（如果你是在写单元测试）、调试和交互式使用。</p>
<h2><span id="克服对大文件的恐惧">克服对大文件的恐惧</span></h2><p>如果你之前是写JAVA（或者其它类似的语言），你可能被告知要让文件简短。在多数语言中，这都是合理的建议：太长会让人感觉是坏代码，意味着重构和重组是必要的。但是，在用IPython开发时，运行10个相关联的小文件（小于100行），比起两个或三个长文件，会让你更头疼。更少的文件意味着重载更少的模块和更少的编辑时在文件中跳转。我发现维护大模块，每个模块都是紧密组织的，会更实用和Pythonic。经过方案迭代，有时会将大文件分解成小文件。</p>
<p>我不建议极端化这条建议，那样会形成一个单独的超大文件。找到一个合理和直观的大型代码模块库和封装结构往往需要一点工作，但这在团队工作中非常重要。每个模块都应该结构紧密，并且应该能直观地找到负责每个功能领域功能和类。</p>
<h1><span id="b5-ipython高级功能">B.5 IPython高级功能</span></h1><p>要全面地使用IPython系统需要用另一种稍微不同的方式写代码，或深入IPython的配置。</p>
<h2><span id="让类是对ipython友好的">让类是对IPython友好的</span></h2><p>IPython会尽可能地在控制台美化展示每个字符串。对于许多对象，比如字典、列表和元组，内置的pprint模块可以用来美化格式。但是，在用户定义的类中，你必自己生成字符串。假设有一个下面的简单的类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Message</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, msg</span>):</span></span><br><span class="line">        self.msg = msg</span><br></pre></td></tr></table></figure></p>
<p>如果这么写，就会发现默认的输出不够美观：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">576</span>]: x = Message(<span class="string">&#x27;I have a secret&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">577</span>]: x</span><br><span class="line">Out[<span class="number">577</span>]: &lt;__main__.Message instance at <span class="number">0x60ebbd8</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p>IPython会接收<strong>repr</strong>魔术方法返回的字符串（通过output = repr(obj)），并在控制台打印出来。因此，我们可以添加一个简单的<strong>repr</strong>方法到前面的类中，以得到一个更有用的输出：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Message</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, msg</span>):</span></span><br><span class="line">        self.msg = msg</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Message: %s&#x27;</span> % self.msg</span><br><span class="line">In [<span class="number">579</span>]: x = Message(<span class="string">&#x27;I have a secret&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">580</span>]: x</span><br><span class="line">Out[<span class="number">580</span>]: Message: I have a secret</span><br></pre></td></tr></table></figure></p>
<h2><span id="文件和配置">文件和配置</span></h2><p>通过扩展配置系统，大多数IPython和Jupyter notebook的外观（颜色、提示符、行间距等等）和动作都是可以配置的。通过配置，你可以做到：</p>
<ul>
<li>改变颜色主题</li>
<li>改变输入和输出提示符，或删除输出之后、输入之前的空行</li>
<li>执行任意Python语句（例如，引入总是要使用的代码或者每次加载IPython都要运行的内容）</li>
<li>启用IPython总是要运行的插件，比如line_profiler中的%lprun魔术函数</li>
<li>启用Jupyter插件</li>
<li>定义自己的魔术函数或系统别名</li>
</ul>
<p>IPython的配置存储在特殊的ipython_config.py文件中，它通常是在用户home目录的.ipython/文件夹中。配置是通过一个特殊文件。当你启动IPython，就会默认加载这个存储在profile_default文件夹中的默认文件。因此，在我的Linux系统，完整的IPython配置文件路径是：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/home/wesm/.ipython/profile_default/ipython_config.py</span><br></pre></td></tr></table></figure></p>
<p>要启动这个文件，运行下面的命令：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ipython profile create</span><br></pre></td></tr></table></figure></p>
<p>这个文件中的内容留给读者自己探索。这个文件有注释，解释了每个配置选项的作用。另一点，可以有多个配置文件。假设你想要另一个IPython配置文件，专门是为另一个应用或项目的。创建一个新的配置文件很简单，如下所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ipython profile create secret_project</span><br></pre></td></tr></table></figure></p>
<p>做完之后，在新创建的profile_secret_project目录便捷配置文件，然后如下启动IPython：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ ipython --profile=secret_project</span><br><span class="line">Python <span class="number">3.5</span><span class="number">.1</span> | packaged by conda-forge | (default, May <span class="number">20</span> <span class="number">2016</span>, 05:<span class="number">22</span>:<span class="number">56</span>)</span><br><span class="line"><span class="type">Type</span> <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line"></span><br><span class="line">IPython <span class="number">5.1</span><span class="number">.0</span> -- An enhanced Interactive Python.</span><br><span class="line">?         -&gt; Introduction <span class="keyword">and</span> overview of IPython<span class="string">&#x27;s features.</span></span><br><span class="line"><span class="string">%quickref -&gt; Quick reference.</span></span><br><span class="line"><span class="string">help      -&gt; Python&#x27;</span>s own <span class="built_in">help</span> system.</span><br><span class="line"><span class="built_in">object</span>?   -&gt; Details about <span class="string">&#x27;object&#x27;</span>, use <span class="string">&#x27;object??&#x27;</span> <span class="keyword">for</span> extra details.</span><br><span class="line"></span><br><span class="line">IPython profile: secret_project</span><br></pre></td></tr></table></figure></p>
<p>和之前一样，IPython的文档是一个极好的学习配置文件的资源。</p>
<p>配置Jupyter有些不同，因为你可以使用除了Python的其它语言。要创建一个类似的Jupyter配置文件，运行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure></p>
<p>这样会在home目录的.jupyter/jupyter_notebook_config.py创建配置文件。编辑完之后，可以将它重命名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ mv ~/.jupyter/jupyter_notebook_config.py ~/.jupyter/my_custom_config.py</span><br></pre></td></tr></table></figure></p>
<p>打开Jupyter之后，你可以添加—config参数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">jupyter notebook --config=~/.jupyter/my_custom_config.py</span><br></pre></td></tr></table></figure></p>
<h1><span id="b6-总结">B.6 总结</span></h1><p>学习过本书中的代码案例，你的Python技能得到了一定的提升，我建议你持续学习IPython和Jupyter。因为这两个项目的设计初衷就是提高生产率的，你可能还会发现一些工具，可以让你更便捷地使用Python和计算库。</p>
<p>你可以在nbviewer（<a href="https://nbviewer.jupyter.org/）上找到更多有趣的Jupyter">https://nbviewer.jupyter.org/）上找到更多有趣的Jupyter</a> notebooks。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>ipython</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-15.numpy高级应用</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-15-numpy%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在这篇附录中，我会深入NumPy库的数组计算。这会包括ndarray更内部的细节，和更高级的数组操作和算法。</p>
<span id="more"></span>
<p>本章包括了一些杂乱的章节，不需要仔细研究。</p>
<h1><span id="a1-ndarray对象的内部机理">A.1 ndarray对象的内部机理</span></h1><p>NumPy的ndarray提供了一种将同质数据块（可以是连续或跨越）解释为多维数组对象的方式。正如你之前所看到的那样，数据类型（dtype）决定了数据的解释方式，比如浮点数、整数、布尔值等。</p>
<p>ndarray如此强大的部分原因是所有数组对象都是数据块的一个跨度视图（strided view）。你可能想知道数组视图arr[::2,::-1]不复制任何数据的原因是什么。简单地说，ndarray不只是一块内存和一个dtype，它还有跨度信息，这使得数组能以各种步幅（step size）在内存中移动。更准确地讲，ndarray内部由以下内容组成：</p>
<ul>
<li>一个指向数据（内存或内存映射文件中的一块数据）的指针。</li>
<li>数据类型或dtype，描述在数组中的固定大小值的格子。</li>
<li>一个表示数组形状（shape）的元组。</li>
<li>一个跨度元组（stride），其中的整数指的是为了前进到当前维度下一个元素需要“跨过”的字节数。</li>
</ul>
<p>图A-1简单地说明了ndarray的内部结构。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/7178691-43452f2f413e5094.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-1 Numpy的ndarray对象"></p>
<p>例如，一个10×5的数组，其形状为(10,5)：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: np.ones((<span class="number">10</span>, <span class="number">5</span>)).shape</span><br><span class="line">Out[<span class="number">10</span>]: (<span class="number">10</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure></p>
<p>一个典型的（C顺序，稍后将详细讲解）3×4×5的float64（8个字节）数组，其跨度为(160,40,8) —— 知道跨度是非常有用的，通常，跨度在一个轴上越大，沿这个轴进行计算的开销就越大：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">11</span>]: np.ones((<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>), dtype=np.float64).strides</span><br><span class="line">Out[<span class="number">11</span>]: (<span class="number">160</span>, <span class="number">40</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure></p>
<p>虽然NumPy用户很少会对数组的跨度信息感兴趣，但它们却是构建非复制式数组视图的重要因素。跨度甚至可以是负数，这样会使数组在内存中后向移动，比如在切片obj[::-1]或obj[:,::-1]中就是这样的。</p>
<h2><span id="numpy数据类型体系">NumPy数据类型体系</span></h2><p>你可能偶尔需要检查数组中所包含的是否是整数、浮点数、字符串或Python对象。因为浮点数的种类很多（从float16到float128），判断dtype是否属于某个大类的工作非常繁琐。幸运的是，dtype都有一个超类（比如np.integer和np.floating），它们可以跟np.issubdtype函数结合使用：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: ints = np.ones(<span class="number">10</span>, dtype=np.uint16)</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: floats = np.ones(<span class="number">10</span>, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: np.issubdtype(ints.dtype, np.integer)</span><br><span class="line">Out[<span class="number">14</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: np.issubdtype(floats.dtype, np.floating)</span><br><span class="line">Out[<span class="number">15</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure></p>
<p>调用dtype的mro方法即可查看其所有的父类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: np.float64.mro()</span><br><span class="line">Out[<span class="number">16</span>]:</span><br><span class="line">[numpy.float64,</span><br><span class="line"> numpy.floating,</span><br><span class="line"> numpy.inexact,</span><br><span class="line"> numpy.number,</span><br><span class="line"> numpy.generic,</span><br><span class="line"> <span class="built_in">float</span>,</span><br><span class="line"> <span class="built_in">object</span>]</span><br></pre></td></tr></table></figure></p>
<p>然后得到：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: np.issubdtype(ints.dtype, np.number)</span><br><span class="line">Out[<span class="number">17</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure></p>
<p>大部分NumPy用户完全不需要了解这些知识，但是这些知识偶尔还是能派上用场的。图A-2说明了dtype体系以及父子类关系。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-b8996bf943a06ab9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-2 NumPy的dtype体系"></p>
<h1><span id="a2-高级数组操作">A.2 高级数组操作</span></h1><p>除花式索引、切片、布尔条件取子集等操作之外，数组的操作方式还有很多。虽然pandas中的高级函数可以处理数据分析工作中的许多重型任务，但有时你还是需要编写一些在现有库中找不到的数据算法。</p>
<h2><span id="数组重塑">数组重塑</span></h2><p>多数情况下，你可以无需复制任何数据，就将数组从一个形状转换为另一个形状。只需向数组的实例方法reshape传入一个表示新形状的元组即可实现该目的。例如，假设有一个一维数组，我们希望将其重新排列为一个矩阵（结果见图A-3）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: arr = np.arange(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: arr</span><br><span class="line">Out[<span class="number">19</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: arr.reshape((<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>]])</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-95bbca6d8d04e4c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-3 按C顺序（按行）和按Fortran顺序（按列）进行重塑"></p>
<p>多维数组也能被重塑：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: arr.reshape((<span class="number">4</span>, <span class="number">2</span>)).reshape((<span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]])</span><br></pre></td></tr></table></figure></p>
<p>作为参数的形状的其中一维可以是－1，它表示该维度的大小由数据本身推断而来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">22</span>]: arr = np.arange(<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: arr.reshape((<span class="number">5</span>, -<span class="number">1</span>))</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">       [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">       [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">       [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]])</span><br></pre></td></tr></table></figure></p>
<p>与reshape将一维数组转换为多维数组的运算过程相反的运算通常称为扁平化（flattening）或散开（raveling）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: arr = np.arange(<span class="number">15</span>).reshape((<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: arr</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">       [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">       [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">       [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: arr.ravel()</span><br><span class="line">Out[<span class="number">29</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>])</span><br></pre></td></tr></table></figure></p>
<p>如果结果中的值与原始数组相同，ravel不会产生源数据的副本。flatten方法的行为类似于ravel，只不过它总是返回数据的副本：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">30</span>]: arr.flatten()</span><br><span class="line">Out[<span class="number">30</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>])</span><br></pre></td></tr></table></figure></p>
<p>数组可以被重塑或散开为别的顺序。这对NumPy新手来说是一个比较微妙的问题，所以在下一小节中我们将专门讲解这个问题。</p>
<h2><span id="c和fortran顺序">C和Fortran顺序</span></h2><p>NumPy允许你更为灵活地控制数据在内存中的布局。默认情况下，NumPy数组是按行优先顺序创建的。在空间方面，这就意味着，对于一个二维数组，每行中的数据项是被存放在相邻内存位置上的。另一种顺序是列优先顺序，它意味着每列中的数据项是被存放在相邻内存位置上的。</p>
<p>由于一些历史原因，行和列优先顺序又分别称为C和Fortran顺序。在FORTRAN 77中，矩阵全都是列优先的。</p>
<p>像reshape和reval这样的函数，都可以接受一个表示数组数据存放顺序的order参数。一般可以是’C’或’F’（还有’A’和’K’等不常用的选项，具体请参考NumPy的文档）。图A-3对此进行了说明：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">31</span>]: arr = np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: arr</span><br><span class="line">Out[<span class="number">32</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">       [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: arr.ravel()</span><br><span class="line">Out[<span class="number">33</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: arr.ravel(<span class="string">&#x27;F&#x27;</span>)</span><br><span class="line">Out[<span class="number">34</span>]: array([ <span class="number">0</span>,  <span class="number">4</span>,  <span class="number">8</span>,  <span class="number">1</span>,  <span class="number">5</span>,  <span class="number">9</span>,  <span class="number">2</span>,  <span class="number">6</span>, <span class="number">10</span>,  <span class="number">3</span>,  <span class="number">7</span>, <span class="number">11</span>])</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-f486e7c41d7e0eec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-3 按C（行优先）或Fortran（列优先）顺序进行重塑"></p>
<p>二维或更高维数组的重塑过程比较令人费解（见图A-3）。C和Fortran顺序的关键区别就是维度的行进顺序：</p>
<ul>
<li>C/行优先顺序：先经过更高的维度（例如，轴1会先于轴0被处理）。</li>
<li>Fortran/列优先顺序：后经过更高的维度（例如，轴0会先于轴1被处理）。</li>
</ul>
<h2><span id="数组的合并和拆分">数组的合并和拆分</span></h2><p>numpy.concatenate可以按指定轴将一个由数组组成的序列（如元组、列表等）连接到一起：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: arr1 = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: arr2 = np.array([[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: np.concatenate([arr1, arr2], axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>],</span><br><span class="line">       [ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">       [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: np.concatenate([arr1, arr2], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">38</span>]: </span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br></pre></td></tr></table></figure></p>
<p>对于常见的连接操作，NumPy提供了一些比较方便的方法（如vstack和hstack）。因此，上面的运算还可以表达为：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: np.vstack((arr1, arr2))</span><br><span class="line">Out[<span class="number">39</span>]: </span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>],</span><br><span class="line">       [ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">       [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: np.hstack((arr1, arr2))</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">[ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br></pre></td></tr></table></figure></p>
<p>与此相反，split用于将一个数组沿指定轴拆分为多个数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: arr = np.random.randn(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: arr</span><br><span class="line">Out[<span class="number">42</span>]: </span><br><span class="line">array([[-<span class="number">0.2047</span>,  <span class="number">0.4789</span>],</span><br><span class="line">       [-<span class="number">0.5194</span>, -<span class="number">0.5557</span>],</span><br><span class="line">       [ <span class="number">1.9658</span>,  <span class="number">1.3934</span>],</span><br><span class="line">       [ <span class="number">0.0929</span>,  <span class="number">0.2817</span>],</span><br><span class="line">       [ <span class="number">0.769</span> ,  <span class="number">1.2464</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: first, second, third = np.split(arr, [<span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: first</span><br><span class="line">Out[<span class="number">44</span>]: array([[-<span class="number">0.2047</span>,  <span class="number">0.4789</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: second</span><br><span class="line">Out[<span class="number">45</span>]: </span><br><span class="line">array([[-<span class="number">0.5194</span>, -<span class="number">0.5557</span>],</span><br><span class="line">       [ <span class="number">1.9658</span>,  <span class="number">1.3934</span>]])</span><br><span class="line">In [<span class="number">46</span>]: third</span><br><span class="line">Out[<span class="number">46</span>]: </span><br><span class="line">array([[ <span class="number">0.0929</span>,  <span class="number">0.2817</span>],</span><br><span class="line">       [ <span class="number">0.769</span> ,  <span class="number">1.2464</span>]])</span><br></pre></td></tr></table></figure></p>
<p>传入到np.split的值[1,3]指示在哪个索引处分割数组。</p>
<p>表A-1中列出了所有关于数组连接和拆分的函数，其中有些是专门为了方便常见的连接运算而提供的。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c597246722a6bb01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表A-1 数组连接函数"></p>
<h2><span id="堆叠辅助类r和c">堆叠辅助类：r<em>和c</em></span></h2><p>NumPy命名空间中有两个特殊的对象——r<em>和c</em>，它们可以使数组的堆叠操作更为简洁：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: arr = np.arange(<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: arr1 = arr.reshape((<span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: arr2 = np.random.randn(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: np.r_[arr1, arr2]</span><br><span class="line">Out[<span class="number">50</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>    ,  <span class="number">1.</span>    ],</span><br><span class="line">       [ <span class="number">2.</span>    ,  <span class="number">3.</span>    ],</span><br><span class="line">       [ <span class="number">4.</span>    ,  <span class="number">5.</span>    ],</span><br><span class="line">       [ <span class="number">1.0072</span>, -<span class="number">1.2962</span>],</span><br><span class="line">       [ <span class="number">0.275</span> ,  <span class="number">0.2289</span>],</span><br><span class="line">       [ <span class="number">1.3529</span>,  <span class="number">0.8864</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: np.c_[np.r_[arr1, arr2], arr]</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>    ,  <span class="number">1.</span>    ,  <span class="number">0.</span>    ],</span><br><span class="line">       [ <span class="number">2.</span>    ,  <span class="number">3.</span>    ,  <span class="number">1.</span>    ],</span><br><span class="line">       [ <span class="number">4.</span>    ,  <span class="number">5.</span>    ,  <span class="number">2.</span>    ],</span><br><span class="line">       [ <span class="number">1.0072</span>, -<span class="number">1.2962</span>,  <span class="number">3.</span>    ],</span><br><span class="line">       [ <span class="number">0.275</span> ,  <span class="number">0.2289</span>,  <span class="number">4.</span>    ],</span><br><span class="line">       [ <span class="number">1.3529</span>,  <span class="number">0.8864</span>,  <span class="number">5.</span>    ]])</span><br></pre></td></tr></table></figure></p>
<p>它还可以将切片转换成数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">52</span>]: np.c_[<span class="number">1</span>:<span class="number">6</span>, -<span class="number">10</span>:-<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">52</span>]: </span><br><span class="line">array([[  <span class="number">1</span>, -<span class="number">10</span>],</span><br><span class="line">       [  <span class="number">2</span>,  -<span class="number">9</span>],</span><br><span class="line">       [  <span class="number">3</span>,  -<span class="number">8</span>],</span><br><span class="line">       [  <span class="number">4</span>,  -<span class="number">7</span>],</span><br><span class="line">       [  <span class="number">5</span>,  -<span class="number">6</span>]])</span><br></pre></td></tr></table></figure></p>
<p>r<em>和c</em>的具体功能请参考其文档。</p>
<h2><span id="元素的重复操作tile和repeat">元素的重复操作：tile和repeat</span></h2><p>对数组进行重复以产生更大数组的工具主要是repeat和tile这两个函数。repeat会将数组中的各个元素重复一定次数，从而产生一个更大的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">53</span>]: arr = np.arange(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: arr</span><br><span class="line">Out[<span class="number">54</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: arr.repeat(<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">55</span>]: array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：跟其他流行的数组编程语言（如MATLAB）不同，NumPy中很少需要对数组进行重复（replicate）。这主要是因为广播（broadcasting，我们将在下一节中讲解该技术）能更好地满足该需求。</p>
</blockquote>
<p>默认情况下，如果传入的是一个整数，则各元素就都会重复那么多次。如果传入的是一组整数，则各元素就可以重复不同的次数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: arr.repeat([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">Out[<span class="number">56</span>]: array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure></p>
<p>对于多维数组，还可以让它们的元素沿指定轴重复：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: arr = np.random.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: arr</span><br><span class="line">Out[<span class="number">58</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: arr.repeat(<span class="number">2</span>, axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">59</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br></pre></td></tr></table></figure></p>
<p>注意，如果没有设置轴向，则数组会被扁平化，这可能不会是你想要的结果。同样，在对多维进行重复时，也可以传入一组整数，这样就会使各切片重复不同的次数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: arr.repeat([<span class="number">2</span>, <span class="number">3</span>], axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">60</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: arr.repeat([<span class="number">2</span>, <span class="number">3</span>], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">61</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>, -<span class="number">0.3718</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> ,  <span class="number">1.669</span> , -<span class="number">0.4386</span>, -<span class="number">0.4386</span>, -<span class="number">0.4386</span>]])</span><br></pre></td></tr></table></figure></p>
<p>tile的功能是沿指定轴向堆叠数组的副本。你可以形象地将其想象成“铺瓷砖”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">62</span>]: arr</span><br><span class="line">Out[<span class="number">62</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: np.tile(arr, <span class="number">2</span>)</span><br><span class="line">Out[<span class="number">63</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>,  <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br></pre></td></tr></table></figure></p>
<p>第二个参数是瓷砖的数量。对于标量，瓷砖是水平铺设的，而不是垂直铺设。它可以是一个表示“铺设”布局的元组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: arr</span><br><span class="line">Out[<span class="number">64</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: np.tile(arr, (<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">Out[<span class="number">65</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>],</span><br><span class="line">       [-<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: np.tile(arr, (<span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">Out[<span class="number">66</span>]: </span><br><span class="line">array([[-<span class="number">2.0016</span>, -<span class="number">0.3718</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>,  <span class="number">1.669</span> , -<span class="number">0.4386</span>],</span><br><span class="line">       [-<span class="number">2.0016</span>, -<span class="number">0.3718</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>,  <span class="number">1.669</span> , -<span class="number">0.4386</span>],</span><br><span class="line">       [-<span class="number">2.0016</span>, -<span class="number">0.3718</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>,  <span class="number">1.669</span> , -<span class="number">0.4386</span>]])</span><br></pre></td></tr></table></figure></p>
<h2><span id="花式索引的等价函数take和put">花式索引的等价函数：take和put</span></h2><p>在第4章中我们讲过，获取和设置数组子集的一个办法是通过整数数组使用花式索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">67</span>]: arr = np.arange(<span class="number">10</span>) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">68</span>]: inds = [<span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: arr[inds]</span><br><span class="line">Out[<span class="number">69</span>]: array([<span class="number">700</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">600</span>])</span><br></pre></td></tr></table></figure></p>
<p>ndarray还有其它方法用于获取单个轴向上的选区：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">70</span>]: arr.take(inds)</span><br><span class="line">Out[<span class="number">70</span>]: array([<span class="number">700</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">600</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: arr.put(inds, <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: arr</span><br><span class="line">Out[<span class="number">72</span>]: array([  <span class="number">0</span>,  <span class="number">42</span>,  <span class="number">42</span>, <span class="number">300</span>, <span class="number">400</span>, <span class="number">500</span>,  <span class="number">42</span>,  <span class="number">42</span>,<span class="number">800</span>, <span class="number">900</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">73</span>]: arr.put(inds, [<span class="number">40</span>, <span class="number">41</span>, <span class="number">42</span>, <span class="number">43</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: arr</span><br><span class="line">Out[<span class="number">74</span>]: array([  <span class="number">0</span>,  <span class="number">41</span>,  <span class="number">42</span>, <span class="number">300</span>, <span class="number">400</span>, <span class="number">500</span>,  <span class="number">43</span>,  <span class="number">40</span>, <span class="number">800</span>, <span class="number">900</span>])</span><br></pre></td></tr></table></figure></p>
<p>要在其它轴上使用take，只需传入axis关键字即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: inds = [<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: arr = np.random.randn(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: arr</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">array([[-<span class="number">0.5397</span>,  <span class="number">0.477</span> ,  <span class="number">3.2489</span>, -<span class="number">1.0212</span>],</span><br><span class="line">       [-<span class="number">0.5771</span>,  <span class="number">0.1241</span>,  <span class="number">0.3026</span>,  <span class="number">0.5238</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: arr.take(inds, axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line">array([[ <span class="number">3.2489</span>, -<span class="number">0.5397</span>,  <span class="number">3.2489</span>,  <span class="number">0.477</span> ],</span><br><span class="line">       [ <span class="number">0.3026</span>, -<span class="number">0.5771</span>,  <span class="number">0.3026</span>,  <span class="number">0.1241</span>]])</span><br></pre></td></tr></table></figure></p>
<p>put不接受axis参数，它只会在数组的扁平化版本（一维，C顺序）上进行索引。因此，在需要用其他轴向的索引设置元素时，最好还是使用花式索引。</p>
<h1><span id="a3-广播">A.3 广播</span></h1><p>广播（broadcasting）指的是不同形状的数组之间的算术运算的执行方式。它是一种非常强大的功能，但也容易令人误解，即使是经验丰富的老手也是如此。将标量值跟数组合并时就会发生最简单的广播：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">79</span>]: arr = np.arange(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: arr</span><br><span class="line">Out[<span class="number">80</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: arr * <span class="number">4</span></span><br><span class="line">Out[<span class="number">81</span>]: array([ <span class="number">0</span>,  <span class="number">4</span>,  <span class="number">8</span>, <span class="number">12</span>, <span class="number">16</span>])</span><br></pre></td></tr></table></figure></p>
<p>这里我们说：在这个乘法运算中，标量值4被广播到了其他所有的元素上。</p>
<p>看一个例子，我们可以通过减去列平均值的方式对数组的每一列进行距平化处理。这个问题解决起来非常简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: arr = np.random.randn(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: arr.mean(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">83</span>]: array([-<span class="number">0.3928</span>, -<span class="number">0.3824</span>, -<span class="number">0.8768</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: demeaned = arr - arr.mean(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: demeaned</span><br><span class="line">Out[<span class="number">85</span>]: </span><br><span class="line">array([[ <span class="number">0.3937</span>,  <span class="number">1.7263</span>,  <span class="number">0.1633</span>],</span><br><span class="line">       [-<span class="number">0.4384</span>, -<span class="number">1.9878</span>, -<span class="number">0.9839</span>],</span><br><span class="line">       [-<span class="number">0.468</span> ,  <span class="number">0.9426</span>, -<span class="number">0.3891</span>],</span><br><span class="line">       [ <span class="number">0.5126</span>, -<span class="number">0.6811</span>,  <span class="number">1.2097</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: demeaned.mean(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">86</span>]: array([-<span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">0.</span>])</span><br></pre></td></tr></table></figure></p>
<p>图A-4形象地展示了该过程。用广播的方式对行进行距平化处理会稍微麻烦一些。幸运的是，只要遵循一定的规则，低维度的值是可以被广播到数组的任意维度的（比如对二维数组各列减去行平均值）。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-6aaf022ab88452a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-4 一维数组在轴0上的广播"></p>
<p>于是就得到了：</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-fcaba8455960862a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>虽然我是一名经验丰富的NumPy老手，但经常还是得停下来画张图并想想广播的原则。再来看一下最后那个例子，假设你希望对各行减去那个平均值。由于arr.mean(0)的长度为3，所以它可以在0轴向上进行广播：因为arr的后缘维度是3，所以它们是兼容的。根据该原则，要在1轴向上做减法（即各行减去行平均值），较小的那个数组的形状必须是(4,1)：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: arr</span><br><span class="line">Out[<span class="number">87</span>]: </span><br><span class="line">array([[ <span class="number">0.0009</span>,  <span class="number">1.3438</span>, -<span class="number">0.7135</span>],</span><br><span class="line">       [-<span class="number">0.8312</span>, -<span class="number">2.3702</span>, -<span class="number">1.8608</span>],</span><br><span class="line">       [-<span class="number">0.8608</span>,  <span class="number">0.5601</span>, -<span class="number">1.2659</span>],</span><br><span class="line">       [ <span class="number">0.1198</span>, -<span class="number">1.0635</span>,  <span class="number">0.3329</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: row_means = arr.mean(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: row_means.shape</span><br><span class="line">Out[<span class="number">89</span>]: (<span class="number">4</span>,)</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: row_means.reshape((<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">array([[ <span class="number">0.2104</span>],</span><br><span class="line">       [-<span class="number">1.6874</span>],</span><br><span class="line">       [-<span class="number">0.5222</span>],</span><br><span class="line">       [-<span class="number">0.2036</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">91</span>]: demeaned = arr - row_means.reshape((<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: demeaned.mean(<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">92</span>]: array([ <span class="number">0.</span>, -<span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>])</span><br></pre></td></tr></table></figure></p>
<p>图A-5说明了该运算的过程。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-9b0310d6773c3d38.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-5 二维数组在轴1上的广播"></p>
<p>图A-6展示了另外一种情况，这次是在一个三维数组上沿0轴向加上一个二维数组。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-965eb28b60046cd9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-6 三维数组在轴0上的广播"></p>
<h2><span id="沿其它轴向广播">沿其它轴向广播</span></h2><p>高维度数组的广播似乎更难以理解，而实际上它也是遵循广播原则的。如果不然，你就会得到下面这样一个错误：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">93</span>]: arr - arr.mean(<span class="number">1</span>)</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">ValueError                                Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">93</span>-7b87b85a20b2&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> arr - arr.mean(<span class="number">1</span>)</span><br><span class="line">ValueError: operands could <span class="keyword">not</span> be broadcast together <span class="keyword">with</span> shapes (<span class="number">4</span>,<span class="number">3</span>) (<span class="number">4</span>,)</span><br></pre></td></tr></table></figure></p>
<p>人们经常需要通过算术运算过程将较低维度的数组在除0轴以外的其他轴向上广播。根据广播的原则，较小数组的“广播维”必须为1。在上面那个行距平化的例子中，这就意味着要将行平均值的形状变成(4,1)而不是(4,)：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: arr - arr.mean(<span class="number">1</span>).reshape((<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">Out[<span class="number">94</span>]: </span><br><span class="line">array([[-<span class="number">0.2095</span>,  <span class="number">1.1334</span>, -<span class="number">0.9239</span>],</span><br><span class="line">       [ <span class="number">0.8562</span>, -<span class="number">0.6828</span>, -<span class="number">0.1734</span>],</span><br><span class="line">       [-<span class="number">0.3386</span>,  <span class="number">1.0823</span>, -<span class="number">0.7438</span>],</span><br><span class="line">       [ <span class="number">0.3234</span>, -<span class="number">0.8599</span>,  <span class="number">0.5365</span>]])</span><br></pre></td></tr></table></figure></p>
<p>对于三维的情况，在三维中的任何一维上广播其实也就是将数据重塑为兼容的形状而已。图A-7说明了要在三维数组各维度上广播的形状需求。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-b40936aab8e757d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-7：能在该三维数组上广播的二维数组的形状"></p>
<p>于是就有了一个非常普遍的问题（尤其是在通用算法中），即专门为了广播而添加一个长度为1的新轴。虽然reshape是一个办法，但插入轴需要构造一个表示新形状的元组。这是一个很郁闷的过程。因此，NumPy数组提供了一种通过索引机制插入轴的特殊语法。下面这段代码通过特殊的np.newaxis属性以及“全”切片来插入新轴：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: arr = np.zeros((<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: arr_3d = arr[:, np.newaxis, :]</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: arr_3d.shape</span><br><span class="line">Out[<span class="number">97</span>]: (<span class="number">4</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: arr_1d = np.random.normal(size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: arr_1d[:, np.newaxis]</span><br><span class="line">Out[<span class="number">99</span>]: </span><br><span class="line">array([[-<span class="number">2.3594</span>],</span><br><span class="line">       [-<span class="number">0.1995</span>],</span><br><span class="line">       [-<span class="number">1.542</span> ]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: arr_1d[np.newaxis, :]</span><br><span class="line">Out[<span class="number">100</span>]: array([[-<span class="number">2.3594</span>, -<span class="number">0.1995</span>, -<span class="number">1.542</span> ]])</span><br></pre></td></tr></table></figure></p>
<p>因此，如果我们有一个三维数组，并希望对轴2进行距平化，那么只需要编写下面这样的代码就可以了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">101</span>]: arr = np.random.randn(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: depth_means = arr.mean(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: depth_means</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">array([[-<span class="number">0.4735</span>,  <span class="number">0.3971</span>, -<span class="number">0.0228</span>,  <span class="number">0.2001</span>],</span><br><span class="line">       [-<span class="number">0.3521</span>, -<span class="number">0.281</span> , -<span class="number">0.071</span> , -<span class="number">0.1586</span>],</span><br><span class="line">       [ <span class="number">0.6245</span>,  <span class="number">0.6047</span>,  <span class="number">0.4396</span>, -<span class="number">0.2846</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">104</span>]: depth_means.shape</span><br><span class="line">Out[<span class="number">104</span>]: (<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: demeaned = arr - depth_means[:, :, np.newaxis]</span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: demeaned.mean(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">106</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">0.</span>, -<span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>, -<span class="number">0.</span>, -<span class="number">0.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>有些读者可能会想，在对指定轴进行距平化时，有没有一种既通用又不牺牲性能的方法呢？实际上是有的，但需要一些索引方面的技巧：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">demean_axis</span>(<span class="params">arr, axis=<span class="number">0</span></span>):</span></span><br><span class="line">    means = arr.mean(axis)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># This generalizes things like [:, :, np.newaxis] to N dimensions</span></span><br><span class="line">    indexer = [<span class="built_in">slice</span>(<span class="literal">None</span>)] * arr.ndim</span><br><span class="line">    indexer[axis] = np.newaxis</span><br><span class="line">    <span class="keyword">return</span> arr - means[indexer]</span><br></pre></td></tr></table></figure></p>
<h2><span id="通过广播设置数组的值">通过广播设置数组的值</span></h2><p>算术运算所遵循的广播原则同样也适用于通过索引机制设置数组值的操作。对于最简单的情况，我们可以这样做：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">107</span>]: arr = np.zeros((<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">108</span>]: arr[:] = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: arr</span><br><span class="line">Out[<span class="number">109</span>]: </span><br><span class="line">array([[ <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>],</span><br><span class="line">       [ <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>],</span><br><span class="line">       [ <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>],</span><br><span class="line">       [ <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>但是，假设我们想要用一个一维数组来设置目标数组的各列，只要保证形状兼容就可以了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">110</span>]: col = np.array([<span class="number">1.28</span>, -<span class="number">0.42</span>, <span class="number">0.44</span>, <span class="number">1.6</span>])</span><br><span class="line">In [<span class="number">111</span>]: arr[:] = col[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: arr</span><br><span class="line">Out[<span class="number">112</span>]: </span><br><span class="line">array([[ <span class="number">1.28</span>,  <span class="number">1.28</span>,  <span class="number">1.28</span>],</span><br><span class="line">       [-<span class="number">0.42</span>, -<span class="number">0.42</span>, -<span class="number">0.42</span>],</span><br><span class="line">       [ <span class="number">0.44</span>,  <span class="number">0.44</span>,  <span class="number">0.44</span>],</span><br><span class="line">       [ <span class="number">1.6</span> ,  <span class="number">1.6</span> ,  <span class="number">1.6</span> ]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: arr[:<span class="number">2</span>] = [[-<span class="number">1.37</span>], [<span class="number">0.509</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: arr</span><br><span class="line">Out[<span class="number">114</span>]: </span><br><span class="line">array([[-<span class="number">1.37</span> , -<span class="number">1.37</span> , -<span class="number">1.37</span> ],</span><br><span class="line">       [ <span class="number">0.509</span>,  <span class="number">0.509</span>,  <span class="number">0.509</span>],</span><br><span class="line">       [ <span class="number">0.44</span> ,  <span class="number">0.44</span> ,  <span class="number">0.44</span> ],</span><br><span class="line">       [ <span class="number">1.6</span>  ,  <span class="number">1.6</span>  ,  <span class="number">1.6</span>  ]])</span><br></pre></td></tr></table></figure></p>
<h1><span id="a4-ufunc高级应用">A.4 ufunc高级应用</span></h1><p>虽然许多NumPy用户只会用到通用函数所提供的快速的元素级运算，但通用函数实际上还有一些高级用法能使我们丢开循环而编写出更为简洁的代码。</p>
<h2><span id="ufunc实例方法">ufunc实例方法</span></h2><p>NumPy的各个二元ufunc都有一些用于执行特定矢量化运算的特殊方法。表A-2汇总了这些方法，下面我将通过几个具体的例子对它们进行说明。</p>
<p>reduce接受一个数组参数，并通过一系列的二元运算对其值进行聚合（可指明轴向）。例如，我们可以用np.add.reduce对数组中各个元素进行求和：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">115</span>]: arr = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: np.add.reduce(arr)</span><br><span class="line">Out[<span class="number">116</span>]: <span class="number">45</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">117</span>]: arr.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">117</span>]: <span class="number">45</span></span><br></pre></td></tr></table></figure></p>
<p>起始值取决于ufunc（对于add的情况，就是0）。如果设置了轴号，约简运算就会沿该轴向执行。这就使你能用一种比较简洁的方式得到某些问题的答案。在下面这个例子中，我们用np.logical_and检查数组各行中的值是否是有序的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">118</span>]: np.random.seed(<span class="number">12346</span>)  <span class="comment"># for reproducibility</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: arr = np.random.randn(<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">120</span>]: arr[::<span class="number">2</span>].sort(<span class="number">1</span>) <span class="comment"># sort a few rows</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: arr[:, :-<span class="number">1</span>] &lt; arr[:, <span class="number">1</span>:]</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line">array([[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">       [<span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">       [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">       [ <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">       [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>]], dtype=<span class="built_in">bool</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: np.logical_and.reduce(arr[:, :-<span class="number">1</span>] &lt; arr[:, <span class="number">1</span>:], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">122</span>]: array([ <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>], dtype=<span class="built_in">bool</span>)</span><br></pre></td></tr></table></figure></p>
<p>注意，logical_and.reduce跟all方法是等价的。</p>
<p>ccumulate跟reduce的关系就像cumsum跟sum的关系那样。它产生一个跟原数组大小相同的中间“累计”值数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">123</span>]: arr = np.arange(<span class="number">15</span>).reshape((<span class="number">3</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: np.add.accumulate(arr, axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">124</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">3</span>,  <span class="number">6</span>, <span class="number">10</span>],</span><br><span class="line">       [ <span class="number">5</span>, <span class="number">11</span>, <span class="number">18</span>, <span class="number">26</span>, <span class="number">35</span>],</span><br><span class="line">       [<span class="number">10</span>, <span class="number">21</span>, <span class="number">33</span>, <span class="number">46</span>, <span class="number">60</span>]])</span><br></pre></td></tr></table></figure></p>
<p>outer用于计算两个数组的叉积：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">125</span>]: arr = np.arange(<span class="number">3</span>).repeat([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">126</span>]: arr</span><br><span class="line">Out[<span class="number">126</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">127</span>]: np.multiply.outer(arr, np.arange(<span class="number">5</span>))</span><br><span class="line">Out[<span class="number">127</span>]: </span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]])</span><br></pre></td></tr></table></figure></p>
<p>outer输出结果的维度是两个输入数据的维度之和：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">128</span>]: x, y = np.random.randn(<span class="number">3</span>, <span class="number">4</span>), np.random.randn(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: result = np.subtract.outer(x, y)</span><br><span class="line"></span><br><span class="line">In [<span class="number">130</span>]: result.shape</span><br><span class="line">Out[<span class="number">130</span>]: (<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure></p>
<p>最后一个方法reduceat用于计算“局部约简”，其实就是一个对数据各切片进行聚合的groupby运算。它接受一组用于指示如何对值进行拆分和聚合的“面元边界”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">131</span>]: arr = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: np.add.reduceat(arr, [<span class="number">0</span>, <span class="number">5</span>, <span class="number">8</span>])</span><br><span class="line">Out[<span class="number">132</span>]: array([<span class="number">10</span>, <span class="number">18</span>, <span class="number">17</span>])</span><br></pre></td></tr></table></figure></p>
<p>最终结果是在arr[0:5]、arr[5:8]以及arr[8:]上执行的约简。跟其他方法一样，这里也可以传入一个axis参数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">133</span>]: arr = np.multiply.outer(np.arange(<span class="number">4</span>), np.arange(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: arr</span><br><span class="line">Out[<span class="number">134</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">2</span>,  <span class="number">4</span>,  <span class="number">6</span>,  <span class="number">8</span>],</span><br><span class="line">       [ <span class="number">0</span>,  <span class="number">3</span>,  <span class="number">6</span>,  <span class="number">9</span>, <span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">135</span>]: np.add.reduceat(arr, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">135</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">1</span>,  <span class="number">5</span>,  <span class="number">4</span>],</span><br><span class="line">       [ <span class="number">2</span>, <span class="number">10</span>,  <span class="number">8</span>],</span><br><span class="line">       [ <span class="number">3</span>, <span class="number">15</span>, <span class="number">12</span>]])</span><br></pre></td></tr></table></figure></p>
<p>表A-2总结了部分的ufunc方法。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c997bd45000f7b72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表A ufunc方法"></p>
<h2><span id="编写新的ufunc">编写新的ufunc</span></h2><p>有多种方法可以让你编写自己的NumPy ufuncs。最常见的是使用NumPy C API，但它超越了本书的范围。在本节，我们讲纯粹的Python ufunc。</p>
<p>numpy.frompyfunc接受一个Python函数以及两个分别表示输入输出参数数量的参数。例如，下面是一个能够实现元素级加法的简单函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">136</span>]: <span class="function"><span class="keyword">def</span> <span class="title">add_elements</span>(<span class="params">x, y</span>):</span></span><br><span class="line">   .....:     <span class="keyword">return</span> x + y</span><br><span class="line"></span><br><span class="line">In [<span class="number">137</span>]: add_them = np.frompyfunc(add_elements, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">138</span>]: add_them(np.arange(<span class="number">8</span>), np.arange(<span class="number">8</span>))</span><br><span class="line">Out[<span class="number">138</span>]: array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">14</span>], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure></p>
<p>用frompyfunc创建的函数总是返回Python对象数组，这一点很不方便。幸运的是，还有另一个办法，即numpy.vectorize。虽然没有frompyfunc那么强大，但可以让你指定输出类型：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">139</span>]: add_them = np.vectorize(add_elements, otypes=[np.float64])</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: add_them(np.arange(<span class="number">8</span>), np.arange(<span class="number">8</span>))</span><br><span class="line">Out[<span class="number">140</span>]: array([  <span class="number">0.</span>,   <span class="number">2.</span>,   <span class="number">4.</span>,   <span class="number">6.</span>,   <span class="number">8.</span>,  <span class="number">10.</span>,  <span class="number">12.</span>,  <span class="number">14.</span>])</span><br></pre></td></tr></table></figure></p>
<p>虽然这两个函数提供了一种创建ufunc型函数的手段，但它们非常慢，因为它们在计算每个元素时都要执行一次Python函数调用，这就会比NumPy自带的基于C的ufunc慢很多：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">141</span>]: arr = np.random.randn(<span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">142</span>]: %timeit add_them(arr, arr)</span><br><span class="line"><span class="number">4.12</span> ms +- <span class="number">182</span> us per loop (mean +- std. dev. of <span class="number">7</span> runs, <span class="number">100</span> loops each)</span><br><span class="line"></span><br><span class="line">In [<span class="number">143</span>]: %timeit np.add(arr, arr)</span><br><span class="line"><span class="number">6.89</span> us +- <span class="number">504</span> ns per loop (mean +- std. dev. of <span class="number">7</span> runs, <span class="number">100000</span> loops each)</span><br></pre></td></tr></table></figure></p>
<p>本章的后面，我会介绍使用Numba（<a href="http://numba.pydata.org/），创建快速Python">http://numba.pydata.org/），创建快速Python</a> ufuncs。</p>
<h1><span id="a5-结构化和记录式数组">A.5 结构化和记录式数组</span></h1><p>你可能已经注意到了，到目前为止我们所讨论的ndarray都是一种同质数据容器，也就是说，在它所表示的内存块中，各元素占用的字节数相同（具体根据dtype而定）。从表面上看，它似乎不能用于表示异质或表格型的数据。结构化数组是一种特殊的ndarray，其中的各个元素可以被看做C语言中的结构体（struct，这就是“结构化”的由来）或SQL表中带有多个命名字段的行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">144</span>]: dtype = [(<span class="string">&#x27;x&#x27;</span>, np.float64), (<span class="string">&#x27;y&#x27;</span>, np.int32)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">145</span>]: sarr = np.array([(<span class="number">1.5</span>, <span class="number">6</span>), (np.pi, -<span class="number">2</span>)], dtype=dtype)</span><br><span class="line"></span><br><span class="line">In [<span class="number">146</span>]: sarr</span><br><span class="line">Out[<span class="number">146</span>]: </span><br><span class="line">array([( <span class="number">1.5</span>   ,  <span class="number">6</span>), ( <span class="number">3.1416</span>, -<span class="number">2</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;f8&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>)])</span><br></pre></td></tr></table></figure></p>
<p>定义结构化dtype（请参考NumPy的在线文档）的方式有很多。最典型的办法是元组列表，各元组的格式为(field_name,field_data_type)。这样，数组的元素就成了元组式的对象，该对象中各个元素可以像字典那样进行访问：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">147</span>]: sarr[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">147</span>]: ( <span class="number">1.5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: sarr[<span class="number">0</span>][<span class="string">&#x27;y&#x27;</span>]</span><br><span class="line">Out[<span class="number">148</span>]: <span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<p>字段名保存在dtype.names属性中。在访问结构化数组的某个字段时，返回的是该数据的视图，所以不会发生数据复制：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">149</span>]: sarr[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">Out[<span class="number">149</span>]: array([ <span class="number">1.5</span>   ,  <span class="number">3.1416</span>])</span><br></pre></td></tr></table></figure></p>
<h2><span id="嵌套dtype和多维字段">嵌套dtype和多维字段</span></h2><p>在定义结构化dtype时，你可以再设置一个形状（可以是一个整数，也可以是一个元组）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">150</span>]: dtype = [(<span class="string">&#x27;x&#x27;</span>, np.int64, <span class="number">3</span>), (<span class="string">&#x27;y&#x27;</span>, np.int32)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">151</span>]: arr = np.zeros(<span class="number">4</span>, dtype=dtype)</span><br><span class="line"></span><br><span class="line">In [<span class="number">152</span>]: arr</span><br><span class="line">Out[<span class="number">152</span>]: </span><br><span class="line">array([([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="number">0</span>), ([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="number">0</span>), ([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="number">0</span>), ([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="number">0</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>, (<span class="number">3</span>,)), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>)])</span><br></pre></td></tr></table></figure></p>
<p>在这种情况下，各个记录的x字段所表示的是一个长度为3的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">153</span>]: arr[<span class="number">0</span>][<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">Out[<span class="number">153</span>]: array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<p>这样，访问arr[‘x’]即可得到一个二维数组，而不是前面那个例子中的一维数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">154</span>]: arr[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">Out[<span class="number">154</span>]: </span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure></p>
<p>这就使你能用单个数组的内存块存放复杂的嵌套结构。你还可以嵌套dtype，作出更复杂的结构。下面是一个简单的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">155</span>]: dtype = [(<span class="string">&#x27;x&#x27;</span>, [(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;f8&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>)]), (<span class="string">&#x27;y&#x27;</span>, np.int32)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">156</span>]: data = np.array([((<span class="number">1</span>, <span class="number">2</span>), <span class="number">5</span>), ((<span class="number">3</span>, <span class="number">4</span>), <span class="number">6</span>)], dtype=dtype)</span><br><span class="line"></span><br><span class="line">In [<span class="number">157</span>]: data[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">Out[<span class="number">157</span>]: </span><br><span class="line">array([( <span class="number">1.</span>,  <span class="number">2.</span>), ( <span class="number">3.</span>,  <span class="number">4.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;&lt;f8&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br><span class="line"></span><br><span class="line">In [<span class="number">158</span>]: data[<span class="string">&#x27;y&#x27;</span>]</span><br><span class="line">Out[<span class="number">158</span>]: array([<span class="number">5</span>, <span class="number">6</span>], dtype=int32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">159</span>]: data[<span class="string">&#x27;x&#x27;</span>][<span class="string">&#x27;a&#x27;</span>]</span><br><span class="line">Out[<span class="number">159</span>]: array([ <span class="number">1.</span>,  <span class="number">3.</span>])</span><br></pre></td></tr></table></figure></p>
<p>pandas的DataFrame并不直接支持该功能，但它的分层索引机制跟这个差不多。</p>
<h2><span id="为什么要用结构化数组">为什么要用结构化数组</span></h2><p>跟pandas的DataFrame相比，NumPy的结构化数组是一种相对较低级的工具。它可以将单个内存块解释为带有任意复杂嵌套列的表格型结构。由于数组中的每个元素在内存中都被表示为固定的字节数，所以结构化数组能够提供非常快速高效的磁盘数据读写（包括内存映像）、网络传输等功能。</p>
<p>结构化数组的另一个常见用法是，将数据文件写成定长记录字节流，这是C和C++代码中常见的数据序列化手段（业界许多历史系统中都能找得到）。只要知道文件的格式（记录的大小、元素的顺序、字节数以及数据类型等），就可以用np.fromfile将数据读入内存。这种用法超出了本书的范围，知道这点就可以了。</p>
<h1><span id="a6-更多有关排序的话题">A.6 更多有关排序的话题</span></h1><p>跟Python内置的列表一样，ndarray的sort实例方法也是就地排序。也就是说，数组内容的重新排列是不会产生新数组的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">160</span>]: arr = np.random.randn(<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">161</span>]: arr.sort()</span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: arr</span><br><span class="line">Out[<span class="number">162</span>]: array([-<span class="number">1.082</span> ,  <span class="number">0.3759</span>,  <span class="number">0.8014</span>,  <span class="number">1.1397</span>,  <span class="number">1.2888</span>,  <span class="number">1.8413</span>])</span><br></pre></td></tr></table></figure></p>
<p>在对数组进行就地排序时要注意一点，如果目标数组只是一个视图，则原始数组将会被修改：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">163</span>]: arr = np.random.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">164</span>]: arr</span><br><span class="line">Out[<span class="number">164</span>]: </span><br><span class="line">array([[-<span class="number">0.3318</span>, -<span class="number">1.4711</span>,  <span class="number">0.8705</span>, -<span class="number">0.0847</span>, -<span class="number">1.1329</span>],</span><br><span class="line">       [-<span class="number">1.0111</span>, -<span class="number">0.3436</span>,  <span class="number">2.1714</span>,  <span class="number">0.1234</span>, -<span class="number">0.0189</span>],</span><br><span class="line">       [ <span class="number">0.1773</span>,  <span class="number">0.7424</span>,  <span class="number">0.8548</span>,  <span class="number">1.038</span> , -<span class="number">0.329</span> ]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">165</span>]: arr[:, <span class="number">0</span>].sort()  <span class="comment"># Sort first column values in-place</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">166</span>]: arr</span><br><span class="line">Out[<span class="number">166</span>]: </span><br><span class="line">array([[-<span class="number">1.0111</span>, -<span class="number">1.4711</span>,  <span class="number">0.8705</span>, -<span class="number">0.0847</span>, -<span class="number">1.1329</span>],</span><br><span class="line">       [-<span class="number">0.3318</span>, -<span class="number">0.3436</span>,  <span class="number">2.1714</span>,  <span class="number">0.1234</span>, -<span class="number">0.0189</span>],</span><br><span class="line">       [ <span class="number">0.1773</span>,  <span class="number">0.7424</span>,  <span class="number">0.8548</span>,  <span class="number">1.038</span> , -<span class="number">0.329</span> ]])</span><br></pre></td></tr></table></figure></p>
<p>相反，numpy.sort会为原数组创建一个已排序副本。另外，它所接受的参数（比如kind）跟ndarray.sort一样：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">167</span>]: arr = np.random.randn(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">168</span>]: arr</span><br><span class="line">Out[<span class="number">168</span>]: array([-<span class="number">1.1181</span>, -<span class="number">0.2415</span>, -<span class="number">2.0051</span>,  <span class="number">0.7379</span>, -<span class="number">1.0614</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: np.sort(arr)</span><br><span class="line">Out[<span class="number">169</span>]: array([-<span class="number">2.0051</span>, -<span class="number">1.1181</span>, -<span class="number">1.0614</span>, -<span class="number">0.2415</span>,  <span class="number">0.7379</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">170</span>]: arr</span><br><span class="line">Out[<span class="number">170</span>]: array([-<span class="number">1.1181</span>, -<span class="number">0.2415</span>, -<span class="number">2.0051</span>,  <span class="number">0.7379</span>, -<span class="number">1.0614</span>])</span><br></pre></td></tr></table></figure></p>
<p>这两个排序方法都可以接受一个axis参数，以便沿指定轴向对各块数据进行单独排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">171</span>]: arr = np.random.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">172</span>]: arr</span><br><span class="line">Out[<span class="number">172</span>]: </span><br><span class="line">array([[ <span class="number">0.5955</span>, -<span class="number">0.2682</span>,  <span class="number">1.3389</span>, -<span class="number">0.1872</span>,  <span class="number">0.9111</span>],</span><br><span class="line">       [-<span class="number">0.3215</span>,  <span class="number">1.0054</span>, -<span class="number">0.5168</span>,  <span class="number">1.1925</span>, -<span class="number">0.1989</span>],</span><br><span class="line">       [ <span class="number">0.3969</span>, -<span class="number">1.7638</span>,  <span class="number">0.6071</span>, -<span class="number">0.2222</span>, -<span class="number">0.2171</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">173</span>]: arr.sort(axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">174</span>]: arr</span><br><span class="line">Out[<span class="number">174</span>]: </span><br><span class="line">array([[-<span class="number">0.2682</span>, -<span class="number">0.1872</span>,  <span class="number">0.5955</span>,  <span class="number">0.9111</span>,  <span class="number">1.3389</span>],</span><br><span class="line">       [-<span class="number">0.5168</span>, -<span class="number">0.3215</span>, -<span class="number">0.1989</span>,  <span class="number">1.0054</span>,  <span class="number">1.1925</span>],</span><br><span class="line">       [-<span class="number">1.7638</span>, -<span class="number">0.2222</span>, -<span class="number">0.2171</span>,  <span class="number">0.3969</span>,  <span class="number">0.6071</span>]])</span><br></pre></td></tr></table></figure></p>
<p>你可能注意到了，这两个排序方法都不可以被设置为降序。其实这也无所谓，因为数组切片会产生视图（也就是说，不会产生副本，也不需要任何其他的计算工作）。许多Python用户都很熟悉一个有关列表的小技巧：values[::-1]可以返回一个反序的列表。对ndarray也是如此：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">175</span>]: arr[:, ::-<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">175</span>]: </span><br><span class="line">array([[ <span class="number">1.3389</span>,  <span class="number">0.9111</span>,  <span class="number">0.5955</span>, -<span class="number">0.1872</span>, -<span class="number">0.2682</span>],</span><br><span class="line">       [ <span class="number">1.1925</span>,  <span class="number">1.0054</span>, -<span class="number">0.1989</span>, -<span class="number">0.3215</span>, -<span class="number">0.5168</span>],</span><br><span class="line">       [ <span class="number">0.6071</span>,  <span class="number">0.3969</span>, -<span class="number">0.2171</span>, -<span class="number">0.2222</span>, -<span class="number">1.7638</span>]])</span><br></pre></td></tr></table></figure></p>
<h2><span id="间接排序argsort和lexsort">间接排序：argsort和lexsort</span></h2><p>在数据分析工作中，常常需要根据一个或多个键对数据集进行排序。例如，一个有关学生信息的数据表可能需要以姓和名进行排序（先姓后名）。这就是间接排序的一个例子，如果你阅读过有关pandas的章节，那就已经见过不少高级例子了。给定一个或多个键，你就可以得到一个由整数组成的索引数组（我亲切地称之为索引器），其中的索引值说明了数据在新顺序下的位置。argsort和numpy.lexsort就是实现该功能的两个主要方法。下面是一个简单的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">176</span>]: values = np.array([<span class="number">5</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">177</span>]: indexer = values.argsort()</span><br><span class="line"></span><br><span class="line">In [<span class="number">178</span>]: indexer</span><br><span class="line">Out[<span class="number">178</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">179</span>]: values[indexer]</span><br><span class="line">Out[<span class="number">179</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure></p>
<p>一个更复杂的例子，下面这段代码根据数组的第一行对其进行排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">180</span>]: arr = np.random.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">181</span>]: arr[<span class="number">0</span>] = values</span><br><span class="line"></span><br><span class="line">In [<span class="number">182</span>]: arr</span><br><span class="line">Out[<span class="number">182</span>]: </span><br><span class="line">array([[ <span class="number">5.</span>    ,  <span class="number">0.</span>    ,  <span class="number">1.</span>    ,  <span class="number">3.</span>    ,  <span class="number">2.</span>    ],</span><br><span class="line">       [-<span class="number">0.3636</span>, -<span class="number">0.1378</span>,  <span class="number">2.1777</span>, -<span class="number">0.4728</span>,  <span class="number">0.8356</span>],</span><br><span class="line">       [-<span class="number">0.2089</span>,  <span class="number">0.2316</span>,  <span class="number">0.728</span> , -<span class="number">1.3918</span>,  <span class="number">1.9956</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">183</span>]: arr[:, arr[<span class="number">0</span>].argsort()]</span><br><span class="line">Out[<span class="number">183</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>    ,  <span class="number">1.</span>    ,  <span class="number">2.</span>    ,  <span class="number">3.</span>    ,  <span class="number">5.</span>    ],</span><br><span class="line">       [-<span class="number">0.1378</span>,  <span class="number">2.1777</span>,  <span class="number">0.8356</span>, -<span class="number">0.4728</span>, -<span class="number">0.3636</span>],</span><br><span class="line">       [ <span class="number">0.2316</span>,  <span class="number">0.728</span> ,  <span class="number">1.9956</span>, -<span class="number">1.3918</span>, -<span class="number">0.2089</span>]])</span><br></pre></td></tr></table></figure></p>
<p>lexsort跟argsort差不多，只不过它可以一次性对多个键数组执行间接排序（字典序）。假设我们想对一些以姓和名标识的数据进行排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">184</span>]: first_name = np.array([<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Jane&#x27;</span>, <span class="string">&#x27;Steve&#x27;</span>, <span class="string">&#x27;Bill&#x27;</span>, <span class="string">&#x27;Barbara&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">185</span>]: last_name = np.array([<span class="string">&#x27;Jones&#x27;</span>, <span class="string">&#x27;Arnold&#x27;</span>, <span class="string">&#x27;Arnold&#x27;</span>, <span class="string">&#x27;Jones&#x27;</span>, <span class="string">&#x27;Walters&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">186</span>]: sorter = np.lexsort((first_name, last_name))</span><br><span class="line"></span><br><span class="line">In [<span class="number">187</span>]: sorter</span><br><span class="line">Out[<span class="number">187</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">188</span>]: <span class="built_in">zip</span>(last_name[sorter], first_name[sorter])</span><br><span class="line">Out[<span class="number">188</span>]: &lt;<span class="built_in">zip</span> at <span class="number">0x7fa203eda1c8</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p>刚开始使用lexsort的时候可能会比较容易头晕，这是因为键的应用顺序是从最后一个传入的算起的。不难看出，last_name是先于first_name被应用的。</p>
<blockquote>
<p>笔记：Series和DataFrame的sort_index以及Series的order方法就是通过这些函数的变体（它们还必须考虑缺失值）实现的。</p>
</blockquote>
<h2><span id="其他排序算法">其他排序算法</span></h2><p>稳定的（stable）排序算法会保持等价元素的相对位置。对于相对位置具有实际意义的那些间接排序而言，这一点非常重要：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">189</span>]: values = np.array([<span class="string">&#x27;2:first&#x27;</span>, <span class="string">&#x27;2:second&#x27;</span>, <span class="string">&#x27;1:first&#x27;</span>, <span class="string">&#x27;1:second&#x27;</span>,</span><br><span class="line">.....:                    <span class="string">&#x27;1:third&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">190</span>]: key = np.array([<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">191</span>]: indexer = key.argsort(kind=<span class="string">&#x27;mergesort&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">192</span>]: indexer</span><br><span class="line">Out[<span class="number">192</span>]: array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">193</span>]: values.take(indexer)</span><br><span class="line">Out[<span class="number">193</span>]: </span><br><span class="line">array([<span class="string">&#x27;1:first&#x27;</span>, <span class="string">&#x27;1:second&#x27;</span>, <span class="string">&#x27;1:third&#x27;</span>, <span class="string">&#x27;2:first&#x27;</span>, <span class="string">&#x27;2:second&#x27;</span>],</span><br><span class="line">      dtype=<span class="string">&#x27;&lt;U8&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>mergesort（合并排序）是唯一的稳定排序，它保证有O(n log n)的性能（空间复杂度），但是其平均性能比默认的quicksort（快速排序）要差。表A-3列出了可用的排序算法及其相关的性能指标。大部分用户完全不需要知道这些东西，但了解一下总是好的。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-970f54f58b6b3356.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表A-3 数组排序算法"></p>
<h2><span id="部分排序数组">部分排序数组</span></h2><p>排序的目的之一可能是确定数组中最大或最小的元素。NumPy有两个优化方法，numpy.partition和np.argpartition，可以在第k个最小元素划分的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">194</span>]: np.random.seed(<span class="number">12345</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">195</span>]: arr = np.random.randn(<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">196</span>]: arr</span><br><span class="line">Out[<span class="number">196</span>]: </span><br><span class="line">array([-<span class="number">0.2047</span>,  <span class="number">0.4789</span>, -<span class="number">0.5194</span>, -<span class="number">0.5557</span>,  <span class="number">1.9658</span>,  <span class="number">1.3934</span>,  <span class="number">0.0929</span>,</span><br><span class="line">        <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">1.2464</span>,  <span class="number">1.0072</span>, -<span class="number">1.2962</span>,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>,</span><br><span class="line">        <span class="number">1.3529</span>,  <span class="number">0.8864</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>,  <span class="number">1.669</span> , -<span class="number">0.4386</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">197</span>]: np.partition(arr, <span class="number">3</span>)</span><br><span class="line">Out[<span class="number">197</span>]: </span><br><span class="line">array([-<span class="number">2.0016</span>, -<span class="number">1.2962</span>, -<span class="number">0.5557</span>, -<span class="number">0.5194</span>, -<span class="number">0.3718</span>, -<span class="number">0.4386</span>, -<span class="number">0.2047</span>,</span><br><span class="line">        <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">0.4789</span>,  <span class="number">1.0072</span>,  <span class="number">0.0929</span>,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>,</span><br><span class="line">        <span class="number">1.3529</span>,  <span class="number">0.8864</span>,  <span class="number">1.3934</span>,  <span class="number">1.9658</span>,  <span class="number">1.669</span> ,  <span class="number">1.2464</span>])</span><br></pre></td></tr></table></figure></p>
<p>当你调用partition(arr, 3)，结果中的头三个元素是最小的三个，没有特定的顺序。numpy.argpartition与numpy.argsort相似，会返回索引，重排数据为等价的顺序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">198</span>]: indices = np.argpartition(arr, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">199</span>]: indices</span><br><span class="line">Out[<span class="number">199</span>]: </span><br><span class="line">array([<span class="number">16</span>, <span class="number">11</span>,  <span class="number">3</span>,  <span class="number">2</span>, <span class="number">17</span>, <span class="number">19</span>,  <span class="number">0</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">1</span>, <span class="number">10</span>,  <span class="number">6</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>,  <span class="number">5</span>,</span><br><span class="line">        <span class="number">4</span>, <span class="number">18</span>,  <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">200</span>]: arr.take(indices)</span><br><span class="line">Out[<span class="number">200</span>]: </span><br><span class="line">array([-<span class="number">2.0016</span>, -<span class="number">1.2962</span>, -<span class="number">0.5557</span>, -<span class="number">0.5194</span>, -<span class="number">0.3718</span>, -<span class="number">0.4386</span>, -<span class="number">0.2047</span>,</span><br><span class="line">        <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">0.4789</span>,  <span class="number">1.0072</span>,  <span class="number">0.0929</span>,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>,</span><br><span class="line">        <span class="number">1.3529</span>,  <span class="number">0.8864</span>,  <span class="number">1.3934</span>,  <span class="number">1.9658</span>,  <span class="number">1.669</span> ,  <span class="number">1.2464</span>])</span><br></pre></td></tr></table></figure></p>
<h2><span id="numpysearchsorted在有序数组中查找元素">numpy.searchsorted：在有序数组中查找元素</span></h2><p>searchsorted是一个在有序数组上执行二分查找的数组方法，只要将值插入到它返回的那个位置就能维持数组的有序性：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">201</span>]: arr = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">12</span>, <span class="number">15</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">202</span>]: arr.searchsorted(<span class="number">9</span>)</span><br><span class="line">Out[<span class="number">202</span>]: <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<p>你可以传入一组值就能得到一组索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">203</span>]: arr.searchsorted([<span class="number">0</span>, <span class="number">8</span>, <span class="number">11</span>, <span class="number">16</span>])</span><br><span class="line">Out[<span class="number">203</span>]: array([<span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure></p>
<p>从上面的结果中可以看出，对于元素0，searchsorted会返回0。这是因为其默认行为是返回相等值组的左侧索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">204</span>]: arr = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">205</span>]: arr.searchsorted([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">Out[<span class="number">205</span>]: array([<span class="number">0</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">206</span>]: arr.searchsorted([<span class="number">0</span>, <span class="number">1</span>], side=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">Out[<span class="number">206</span>]: array([<span class="number">3</span>, <span class="number">7</span>])</span><br></pre></td></tr></table></figure></p>
<p>再来看searchsorted的另一个用法，假设我们有一个数据数组（其中的值在0到10000之间），还有一个表示“面元边界”的数组，我们希望用它将数据数组拆分开：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">207</span>]: data = np.floor(np.random.uniform(<span class="number">0</span>, <span class="number">10000</span>, size=<span class="number">50</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">208</span>]: bins = np.array([<span class="number">0</span>, <span class="number">100</span>, <span class="number">1000</span>, <span class="number">5000</span>, <span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">209</span>]: data</span><br><span class="line">Out[<span class="number">209</span>]: </span><br><span class="line">array([ <span class="number">9940.</span>,  <span class="number">6768.</span>,  <span class="number">7908.</span>,  <span class="number">1709.</span>,   <span class="number">268.</span>,  <span class="number">8003.</span>, <span class="number">9037.</span>,   <span class="number">246.</span>,</span><br><span class="line">        <span class="number">4917.</span>,  <span class="number">5262.</span>,  <span class="number">5963.</span>,   <span class="number">519.</span>,  <span class="number">8950.</span>,  <span class="number">7282.</span>,  <span class="number">8183.</span>,  <span class="number">5002.</span>,</span><br><span class="line">        <span class="number">8101.</span>,   <span class="number">959.</span>,  <span class="number">2189.</span>,  <span class="number">2587.</span>,  <span class="number">4681.</span>,  <span class="number">4593.</span>,  <span class="number">7095.</span>,  <span class="number">1780.</span>,</span><br><span class="line">        <span class="number">5314.</span>,  <span class="number">1677.</span>,  <span class="number">7688.</span>,  <span class="number">9281.</span>,  <span class="number">6094.</span>,  <span class="number">1501.</span>,  <span class="number">4896.</span>,  <span class="number">3773.</span>,</span><br><span class="line">        <span class="number">8486.</span>,  <span class="number">9110.</span>,  <span class="number">3838.</span>,  <span class="number">3154.</span>,  <span class="number">5683.</span>,  <span class="number">1878.</span>,  <span class="number">1258.</span>,  <span class="number">6875.</span>,</span><br><span class="line">        <span class="number">7996.</span>,  <span class="number">5735.</span>,  <span class="number">9732.</span>,  <span class="number">6340.</span>,  <span class="number">8884.</span>,  <span class="number">4954.</span>,  <span class="number">3516.</span>,  <span class="number">7142.</span>,</span><br><span class="line">        <span class="number">5039.</span>,  <span class="number">2256.</span>])</span><br></pre></td></tr></table></figure></p>
<p>然后，为了得到各数据点所属区间的编号（其中1表示面元[0,100)），我们可以直接使用searchsorted：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">210</span>]: labels = bins.searchsorted(data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">211</span>]: labels</span><br><span class="line">Out[<span class="number">211</span>]: </span><br><span class="line">array([<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>,</span><br><span class="line">       <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>,</span><br><span class="line">       <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure></p>
<p>通过pandas的groupby使用该结果即可非常轻松地对原数据集进行拆分：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">212</span>]: pd.Series(data).groupby(labels).mean()</span><br><span class="line">Out[<span class="number">212</span>]: </span><br><span class="line"><span class="number">2</span>     <span class="number">498.000000</span></span><br><span class="line"><span class="number">3</span>    <span class="number">3064.277778</span></span><br><span class="line"><span class="number">4</span>    <span class="number">7389.035714</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<h1><span id="a7-用numba编写快速numpy函数">A.7 用Numba编写快速NumPy函数</span></h1><p>Numba是一个开源项目，它可以利用CPUs、GPUs或其它硬件为类似NumPy的数据创建快速函数。它使用了LLVM项目（<a href="http://llvm.org/），将Python代码转换为机器代码。">http://llvm.org/），将Python代码转换为机器代码。</a></p>
<p>为了介绍Numba，来考虑一个纯粹的Python函数，它使用for循环计算表达式(x - y).mean()：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_distance</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    nx = <span class="built_in">len</span>(x)</span><br><span class="line">    result = <span class="number">0.0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nx):</span><br><span class="line">        result += x[i] - y[i]</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result / count</span><br></pre></td></tr></table></figure></p>
<p>这个函数很慢：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">209</span>]: x = np.random.randn(<span class="number">10000000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">210</span>]: y = np.random.randn(<span class="number">10000000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">211</span>]: %timeit mean_distance(x, y)</span><br><span class="line"><span class="number">1</span> loop, best of <span class="number">3</span>: <span class="number">2</span> s per loop</span><br><span class="line"></span><br><span class="line">In [<span class="number">212</span>]: %timeit (x - y).mean()</span><br><span class="line"><span class="number">100</span> loops, best of <span class="number">3</span>: <span class="number">14.7</span> ms per loop</span><br></pre></td></tr></table></figure></p>
<p>NumPy的版本要比它快过100倍。我们可以转换这个函数为编译的Numba函数，使用numba.jit函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">213</span>]: <span class="keyword">import</span> numba <span class="keyword">as</span> nb</span><br><span class="line"></span><br><span class="line">In [<span class="number">214</span>]: numba_mean_distance = nb.jit(mean_distance)</span><br></pre></td></tr></table></figure></p>
<p>也可以写成装饰器：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@nb.jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_distance</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    nx = <span class="built_in">len</span>(x)</span><br><span class="line">    result = <span class="number">0.0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nx):</span><br><span class="line">        result += x[i] - y[i]</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result / count</span><br></pre></td></tr></table></figure></p>
<p>它要比矢量化的NumPy快：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">215</span>]: %timeit numba_mean_distance(x, y)</span><br><span class="line"><span class="number">100</span> loops, best of <span class="number">3</span>: <span class="number">10.3</span> ms per loop</span><br></pre></td></tr></table></figure></p>
<p>Numba不能编译Python代码，但它支持纯Python写的一个部分，可以编写数值算法。</p>
<p>Numba是一个深厚的库，支持多种硬件、编译模式和用户插件。它还可以编译NumPy Python API的一部分，而不用for循环。Numba也可以识别可以便以为机器编码的结构体，但是若调用CPython API，它就不知道如何编译。Numba的jit函数有一个选项，nopython=True，它限制了可以被转换为Python代码的代码，这些代码可以编译为LLVM，但没有任何Python C API调用。jit(nopython=True)有一个简短的别名numba.njit。</p>
<p>前面的例子，我们还可以这样写：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> float64, njit</span><br><span class="line"></span><br><span class="line"><span class="meta">@njit(<span class="params">float64(<span class="params">float64[:], float64[:]</span>)</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_distance</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (x - y).mean()</span><br></pre></td></tr></table></figure></p>
<p>我建议你学习Numba的线上文档（<a href="http://numba.pydata.org/）。下一节介绍一个创建自定义Numpy">http://numba.pydata.org/）。下一节介绍一个创建自定义Numpy</a> ufunc对象的例子。</p>
<h2><span id="用numba创建自定义numpyufunc对象">用Numba创建自定义numpy.ufunc对象</span></h2><p>numba.vectorize创建了一个编译的NumPy ufunc，它与内置的ufunc很像。考虑一个numpy.add的Python例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> vectorize</span><br><span class="line"></span><br><span class="line"><span class="meta">@vectorize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nb_add</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x + y</span><br></pre></td></tr></table></figure></p>
<p>现在有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: x = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: nb_add(x, x)</span><br><span class="line">Out[<span class="number">14</span>]: array([  <span class="number">0.</span>,   <span class="number">2.</span>,   <span class="number">4.</span>,   <span class="number">6.</span>,   <span class="number">8.</span>,  <span class="number">10.</span>,  <span class="number">12.</span>,  <span class="number">14.</span>,  <span class="number">16.</span>,  <span class="number">18.</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: nb_add.accumulate(x, <span class="number">0</span>)</span><br><span class="line">Out[<span class="number">15</span>]: array([  <span class="number">0.</span>,   <span class="number">1.</span>,   <span class="number">3.</span>,   <span class="number">6.</span>,  <span class="number">10.</span>,  <span class="number">15.</span>,  <span class="number">21.</span>,  <span class="number">28.</span>,  <span class="number">36.</span>,  <span class="number">45.</span>])</span><br></pre></td></tr></table></figure></p>
<h1><span id="a8-高级数组输入输出">A.8 高级数组输入输出</span></h1><p>我在第4章中讲过，np.save和np.load可用于读写磁盘上以二进制格式存储的数组。其实还有一些工具可用于更为复杂的场景。尤其是内存映像（memory map），它使你能处理在内存中放不下的数据集。</p>
<h2><span id="内存映像文件">内存映像文件</span></h2><p>内存映像文件是一种将磁盘上的非常大的二进制数据文件当做内存中的数组进行处理的方式。NumPy实现了一个类似于ndarray的memmap对象，它允许将大文件分成小段进行读写，而不是一次性将整个数组读入内存。另外，memmap也拥有跟普通数组一样的方法，因此，基本上只要是能用于ndarray的算法就也能用于memmap。</p>
<p>要创建一个内存映像，可以使用函数np.memmap并传入一个文件路径、数据类型、形状以及文件模式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">214</span>]: mmap = np.memmap(<span class="string">&#x27;mymmap&#x27;</span>, dtype=<span class="string">&#x27;float64&#x27;</span>, mode=<span class="string">&#x27;w+&#x27;</span>,</span><br><span class="line">   .....:                  shape=(<span class="number">10000</span>, <span class="number">10000</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">215</span>]: mmap</span><br><span class="line">Out[<span class="number">215</span>]: </span><br><span class="line">memmap([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, ...,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, ...,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, ...,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        ..., </span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, ...,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, ...,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>, ...,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>对memmap切片将会返回磁盘上的数据的视图：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">216</span>]: section = mmap[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure></p>
<p>如果将数据赋值给这些视图：数据会先被缓存在内存中（就像是Python的文件对象），调用flush即可将其写入磁盘：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">217</span>]: section[:] = np.random.randn(<span class="number">5</span>, <span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">218</span>]: mmap.flush()</span><br><span class="line"></span><br><span class="line">In [<span class="number">219</span>]: mmap</span><br><span class="line">Out[<span class="number">219</span>]: </span><br><span class="line">memmap([[ <span class="number">0.7584</span>, -<span class="number">0.6605</span>,  <span class="number">0.8626</span>, ...,  <span class="number">0.6046</span>, -<span class="number">0.6212</span>,  <span class="number">2.0542</span>],</span><br><span class="line">        [-<span class="number">1.2113</span>, -<span class="number">1.0375</span>,  <span class="number">0.7093</span>, ..., -<span class="number">1.4117</span>, -<span class="number">0.1719</span>, -<span class="number">0.8957</span>],</span><br><span class="line">        [-<span class="number">0.1419</span>, -<span class="number">0.3375</span>,  <span class="number">0.4329</span>, ...,  <span class="number">1.2914</span>, -<span class="number">0.752</span> , -<span class="number">0.44</span>  ],</span><br><span class="line">        ..., </span><br><span class="line">        [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    , ...,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ],</span><br><span class="line">        [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    , ...,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ],</span><br><span class="line">        [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    , ...,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">220</span>]: <span class="keyword">del</span> mmap</span><br></pre></td></tr></table></figure></p>
<p>只要某个内存映像超出了作用域，它就会被垃圾回收器回收，之前对其所做的任何修改都会被写入磁盘。当打开一个已经存在的内存映像时，仍然需要指明数据类型和形状，因为磁盘上的那个文件只是一块二进制数据而已，没有任何元数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">221</span>]: mmap = np.memmap(<span class="string">&#x27;mymmap&#x27;</span>, dtype=<span class="string">&#x27;float64&#x27;</span>, shape=(<span class="number">10000</span>, <span class="number">10000</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">222</span>]: mmap</span><br><span class="line">Out[<span class="number">222</span>]: </span><br><span class="line">memmap([[ <span class="number">0.7584</span>, -<span class="number">0.6605</span>,  <span class="number">0.8626</span>, ...,  <span class="number">0.6046</span>, -<span class="number">0.6212</span>,  <span class="number">2.0542</span>],</span><br><span class="line">        [-<span class="number">1.2113</span>, -<span class="number">1.0375</span>,  <span class="number">0.7093</span>, ..., -<span class="number">1.4117</span>, -<span class="number">0.1719</span>, -<span class="number">0.8957</span>],</span><br><span class="line">        [-<span class="number">0.1419</span>, -<span class="number">0.3375</span>,  <span class="number">0.4329</span>, ...,  <span class="number">1.2914</span>, -<span class="number">0.752</span> , -<span class="number">0.44</span>  ],</span><br><span class="line">        ..., </span><br><span class="line">        [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    , ...,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ],</span><br><span class="line">        [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    , ...,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ],</span><br><span class="line">        [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    , ...,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ]])</span><br></pre></td></tr></table></figure></p>
<p>内存映像可以使用前面介绍的结构化或嵌套dtype。</p>
<h2><span id="hdf5及其他数组存储方式">HDF5及其他数组存储方式</span></h2><p>PyTables和h5py这两个Python项目可以将NumPy的数组数据存储为高效且可压缩的HDF5格式（HDF意思是“层次化数据格式”）。你可以安全地将好几百GB甚至TB的数据存储为HDF5格式。要学习Python使用HDF5，请参考pandas线上文档。</p>
<h1><span id="a9-性能建议">A.9 性能建议</span></h1><p>使用NumPy的代码的性能一般都很不错，因为数组运算一般都比纯Python循环快得多。下面大致列出了一些需要注意的事项：</p>
<ul>
<li>将Python循环和条件逻辑转换为数组运算和布尔数组运算。</li>
<li>尽量使用广播。</li>
<li>避免复制数据，尽量使用数组视图（即切片）。</li>
<li>利用ufunc及其各种方法。</li>
</ul>
<p>如果单用NumPy无论如何都达不到所需的性能指标，就可以考虑一下用C、Fortran或Cython（等下会稍微介绍一下）来编写代码。我自己在工作中经常会用到Cython（<a href="http://cython.org），因为它不用花费我太多精力就能得到C语言那样的性能。">http://cython.org），因为它不用花费我太多精力就能得到C语言那样的性能。</a></p>
<h2><span id="连续内存的重要性">连续内存的重要性</span></h2><p>虽然这个话题有点超出本书的范围，但还是要提一下，因为在某些应用场景中，数组的内存布局可以对计算速度造成极大的影响。这是因为性能差别在一定程度上跟CPU的高速缓存（cache）体系有关。运算过程中访问连续内存块（例如，对以C顺序存储的数组的行求和）一般是最快的，因为内存子系统会将适当的内存块缓存到超高速的L1或L2CPU Cache中。此外，NumPy的C语言基础代码（某些）对连续存储的情况进行了优化处理，这样就能避免一些跨越式的内存访问。</p>
<p>一个数组的内存布局是连续的，就是说元素是以它们在数组中出现的顺序（即Fortran型（列优先）或C型（行优先））存储在内存中的。默认情况下，NumPy数组是以C型连续的方式创建的。列优先的数组（比如C型连续数组的转置）也被称为Fortran型连续。通过ndarray的flags属性即可查看这些信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">225</span>]: arr_c = np.ones((<span class="number">1000</span>, <span class="number">1000</span>), order=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">226</span>]: arr_f = np.ones((<span class="number">1000</span>, <span class="number">1000</span>), order=<span class="string">&#x27;F&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">227</span>]: arr_c.flags</span><br><span class="line"></span><br><span class="line">Out[<span class="number">227</span>]: </span><br><span class="line">  C_CONTIGUOUS : <span class="literal">True</span></span><br><span class="line">  F_CONTIGUOUS : <span class="literal">False</span></span><br><span class="line">  OWNDATA : <span class="literal">True</span></span><br><span class="line">  WRITEABLE : <span class="literal">True</span></span><br><span class="line">  ALIGNED : <span class="literal">True</span></span><br><span class="line">  UPDATEIFCOPY : <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">228</span>]: arr_f.flags</span><br><span class="line">Out[<span class="number">228</span>]: </span><br><span class="line">  C_CONTIGUOUS : <span class="literal">False</span></span><br><span class="line">  F_CONTIGUOUS : <span class="literal">True</span></span><br><span class="line">  OWNDATA : <span class="literal">True</span></span><br><span class="line">  WRITEABLE : <span class="literal">True</span></span><br><span class="line">  ALIGNED : <span class="literal">True</span></span><br><span class="line">  UPDATEIFCOPY : <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">229</span>]: arr_f.flags.f_contiguous</span><br><span class="line">Out[<span class="number">229</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure></p>
<p>在这个例子中，对两个数组的行进行求和计算，理论上说，arr_c会比arr_f快，因为arr_c的行在内存中是连续的。我们可以在IPython中用%timeit来确认一下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">230</span>]: %timeit arr_c.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line"><span class="number">784</span> us +- <span class="number">10.4</span> us per loop (mean +- std. dev. of <span class="number">7</span> runs, <span class="number">1000</span> loops each)</span><br><span class="line"></span><br><span class="line">In [<span class="number">231</span>]: %timeit arr_f.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line"><span class="number">934</span> us +- <span class="number">29</span> us per loop (mean +- std. dev. of <span class="number">7</span> runs, <span class="number">1000</span> loops each)</span><br></pre></td></tr></table></figure></p>
<p>如果想从NumPy中提升性能，这里就应该是下手的地方。如果数组的内存顺序不符合你的要求，使用copy并传入’C’或’F’即可解决该问题：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">232</span>]: arr_f.copy(<span class="string">&#x27;C&#x27;</span>).flags</span><br><span class="line">Out[<span class="number">232</span>]: </span><br><span class="line">  C_CONTIGUOUS : <span class="literal">True</span></span><br><span class="line">  F_CONTIGUOUS : <span class="literal">False</span></span><br><span class="line">  OWNDATA : <span class="literal">True</span></span><br><span class="line">  WRITEABLE : <span class="literal">True</span></span><br><span class="line">  ALIGNED : <span class="literal">True</span></span><br><span class="line">  UPDATEIFCOPY : <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>注意，在构造数组的视图时，其结果不一定是连续的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">233</span>]: arr_c[:<span class="number">50</span>].flags.contiguous</span><br><span class="line">Out[<span class="number">233</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">234</span>]: arr_c[:, :<span class="number">50</span>].flags</span><br><span class="line">Out[<span class="number">234</span>]: </span><br><span class="line">  C_CONTIGUOUS : <span class="literal">False</span></span><br><span class="line">  F_CONTIGUOUS : <span class="literal">False</span></span><br><span class="line">  OWNDATA : <span class="literal">False</span></span><br><span class="line">  WRITEABLE : <span class="literal">True</span></span><br><span class="line">  ALIGNED : <span class="literal">True</span></span><br><span class="line">  UPDATEIFCOPY : <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-14.数据分析案例</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-14-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>本书正文的最后一章，我们来看一些真实世界的数据集。对于每个数据集，我们会用之前介绍的方法，从原始数据中提取有意义的内容。展示的方法适用于其它数据集，也包括你的。本章包含了一些各种各样的案例数据集，可以用来练习。</p>
<span id="more"></span>
<p>案例数据集可以在Github仓库找到，见第一章。</p>
<h1><span id="141-来自bitly的usagov数据">14.1 来自Bitly的USA.gov数据</span></h1><p>2011年，URL缩短服务Bitly跟美国政府网站USA.gov合作，提供了一份从生成.gov或.mil短链接的用户那里收集来的匿名数据。在2011年，除实时数据之外，还可以下载文本文件形式的每小时快照。写作此书时（2017年），这项服务已经关闭，但我们保存一份数据用于本书的案例。</p>
<p>以每小时快照为例，文件中各行的格式为JSON（即JavaScript Object Notation，这是一种常用的Web数据格式）。例如，如果我们只读取某个文件中的第一行，那么所看到的结果应该是下面这样：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: path = <span class="string">&#x27;datasets/bitly_usagov/example.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: <span class="built_in">open</span>(path).readline()</span><br><span class="line">Out[<span class="number">6</span>]: <span class="string">&#x27;&#123; &quot;a&quot;: &quot;Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11</span></span><br><span class="line"><span class="string">(KHTML, like Gecko) Chrome\\/17.0.963.78 Safari\\/535.11&quot;, &quot;c&quot;: &quot;US&quot;, &quot;nk&quot;: 1,</span></span><br><span class="line"><span class="string">&quot;tz&quot;: &quot;America\\/New_York&quot;, &quot;gr&quot;: &quot;MA&quot;, &quot;g&quot;: &quot;A6qOVH&quot;, &quot;h&quot;: &quot;wfLQtf&quot;, &quot;l&quot;:</span></span><br><span class="line"><span class="string">&quot;orofrog&quot;, &quot;al&quot;: &quot;en-US,en;q=0.8&quot;, &quot;hh&quot;: &quot;1.usa.gov&quot;, &quot;r&quot;:</span></span><br><span class="line"><span class="string">&quot;http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf&quot;, &quot;u&quot;:</span></span><br><span class="line"><span class="string">&quot;http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991&quot;, &quot;t&quot;: 1331923247, &quot;hc&quot;:</span></span><br><span class="line"><span class="string">1331822918, &quot;cy&quot;: &quot;Danvers&quot;, &quot;ll&quot;: [ 42.576698, -70.954903 ] &#125;\n&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>Python有内置或第三方模块可以将JSON字符串转换成Python字典对象。这里，我将使用json模块及其loads函数逐行加载已经下载好的数据文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">path = <span class="string">&#x27;datasets/bitly_usagov/example.txt&#x27;</span></span><br><span class="line">records = [json.loads(line) <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(path)]</span><br></pre></td></tr></table></figure></p>
<p>现在，records对象就成为一组Python字典了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: records[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">18</span>]:</span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko)</span></span><br><span class="line"><span class="string">Chrome/17.0.963.78 Safari/535.11&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;al&#x27;</span>: <span class="string">&#x27;en-US,en;q=0.8&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;c&#x27;</span>: <span class="string">&#x27;US&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;cy&#x27;</span>: <span class="string">&#x27;Danvers&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;g&#x27;</span>: <span class="string">&#x27;A6qOVH&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;gr&#x27;</span>: <span class="string">&#x27;MA&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;h&#x27;</span>: <span class="string">&#x27;wfLQtf&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;hc&#x27;</span>: <span class="number">1331822918</span>,</span><br><span class="line"> <span class="string">&#x27;hh&#x27;</span>: <span class="string">&#x27;1.usa.gov&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;l&#x27;</span>: <span class="string">&#x27;orofrog&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ll&#x27;</span>: [<span class="number">42.576698</span>, -<span class="number">70.954903</span>],</span><br><span class="line"> <span class="string">&#x27;nk&#x27;</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">&#x27;r&#x27;</span>: <span class="string">&#x27;http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;t&#x27;</span>: <span class="number">1331923247</span>,</span><br><span class="line"> <span class="string">&#x27;tz&#x27;</span>: <span class="string">&#x27;America/New_York&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;u&#x27;</span>: <span class="string">&#x27;http://www.ncbi.nlm.nih.gov/pubmed/22415991&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h2><span id="用纯python代码对时区进行计数">用纯Python代码对时区进行计数</span></h2><p>假设我们想要知道该数据集中最常出现的是哪个时区（即tz字段），得到答案的办法有很多。首先，我们用列表推导式取出一组时区：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: time_zones = [rec[<span class="string">&#x27;tz&#x27;</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records]</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">KeyError                                  Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">12</span>-db4fbd348da9&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> time_zones = [rec[<span class="string">&#x27;tz&#x27;</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records]</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">12</span>-db4fbd348da9&gt; <span class="keyword">in</span> &lt;listcomp&gt;(<span class="number">.0</span>)</span><br><span class="line">----&gt; <span class="number">1</span> time_zones = [rec[<span class="string">&#x27;tz&#x27;</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records]</span><br><span class="line">KeyError: <span class="string">&#x27;tz&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>晕！原来并不是所有记录都有时区字段。这个好办，只需在列表推导式末尾加上一个if ‘tz’in rec判断即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: time_zones = [rec[<span class="string">&#x27;tz&#x27;</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records <span class="keyword">if</span> <span class="string">&#x27;tz&#x27;</span> <span class="keyword">in</span> rec]</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: time_zones[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">[<span class="string">&#x27;America/New_York&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;America/Denver&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;America/New_York&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;America/Sao_Paulo&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;America/New_York&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;America/New_York&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Europe/Warsaw&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>只看前10个时区，我们发现有些是未知的（即空的）。虽然可以将它们过滤掉，但现在暂时先留着。接下来，为了对时区进行计数，这里介绍两个办法：一个较难（只使用标准Python库），另一个较简单（使用pandas）。计数的办法之一是在遍历时区的过程中将计数值保存在字典中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_counts</span>(<span class="params">sequence</span>):</span></span><br><span class="line">    counts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> sequence:</span><br><span class="line">        <span class="keyword">if</span> x <span class="keyword">in</span> counts:</span><br><span class="line">            counts[x] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            counts[x] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> counts</span><br></pre></td></tr></table></figure></p>
<p>如果使用Python标准库的更高级工具，那么你可能会将代码写得更简洁一些：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_counts2</span>(<span class="params">sequence</span>):</span></span><br><span class="line">    counts = defaultdict(<span class="built_in">int</span>) <span class="comment"># values will initialize to 0</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> sequence:</span><br><span class="line">        counts[x] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> counts</span><br></pre></td></tr></table></figure></p>
<p>我将逻辑写到函数中是为了获得更高的复用性。要用它对时区进行处理，只需将time_zones传入即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: counts = get_counts(time_zones)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: counts[<span class="string">&#x27;America/New_York&#x27;</span>]</span><br><span class="line">Out[<span class="number">18</span>]: <span class="number">1251</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: <span class="built_in">len</span>(time_zones)</span><br><span class="line">Out[<span class="number">19</span>]: <span class="number">3440</span></span><br></pre></td></tr></table></figure></p>
<p>如果想要得到前10位的时区及其计数值，我们需要用到一些有关字典的处理技巧：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_counts</span>(<span class="params">count_dict, n=<span class="number">10</span></span>):</span></span><br><span class="line">    value_key_pairs = [(count, tz) <span class="keyword">for</span> tz, count <span class="keyword">in</span> count_dict.items()]</span><br><span class="line">    value_key_pairs.sort()</span><br><span class="line">    <span class="keyword">return</span> value_key_pairs[-n:]</span><br></pre></td></tr></table></figure></p>
<p>然后有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: top_counts(counts)</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">[(<span class="number">33</span>, <span class="string">&#x27;America/Sao_Paulo&#x27;</span>),</span><br><span class="line"> (<span class="number">35</span>, <span class="string">&#x27;Europe/Madrid&#x27;</span>),</span><br><span class="line">(<span class="number">36</span>, <span class="string">&#x27;Pacific/Honolulu&#x27;</span>),</span><br><span class="line"> (<span class="number">37</span>, <span class="string">&#x27;Asia/Tokyo&#x27;</span>),</span><br><span class="line"> (<span class="number">74</span>, <span class="string">&#x27;Europe/London&#x27;</span>),</span><br><span class="line"> (<span class="number">191</span>, <span class="string">&#x27;America/Denver&#x27;</span>),</span><br><span class="line"> (<span class="number">382</span>, <span class="string">&#x27;America/Los_Angeles&#x27;</span>),</span><br><span class="line"> (<span class="number">400</span>, <span class="string">&#x27;America/Chicago&#x27;</span>),</span><br><span class="line"> (<span class="number">521</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line"> (<span class="number">1251</span>, <span class="string">&#x27;America/New_York&#x27;</span>)]</span><br></pre></td></tr></table></figure></p>
<p>如果你搜索Python的标准库，你能找到collections.Counter类，它可以使这项工作更简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">22</span>]: <span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: counts = Counter(time_zones)</span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: counts.most_common(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">[(<span class="string">&#x27;America/New_York&#x27;</span>, <span class="number">1251</span>),</span><br><span class="line"> (<span class="string">&#x27;&#x27;</span>, <span class="number">521</span>),</span><br><span class="line"> (<span class="string">&#x27;America/Chicago&#x27;</span>, <span class="number">400</span>),</span><br><span class="line"> (<span class="string">&#x27;America/Los_Angeles&#x27;</span>, <span class="number">382</span>),</span><br><span class="line"> (<span class="string">&#x27;America/Denver&#x27;</span>, <span class="number">191</span>),</span><br><span class="line"> (<span class="string">&#x27;Europe/London&#x27;</span>, <span class="number">74</span>),</span><br><span class="line"> (<span class="string">&#x27;Asia/Tokyo&#x27;</span>, <span class="number">37</span>),</span><br><span class="line"> (<span class="string">&#x27;Pacific/Honolulu&#x27;</span>, <span class="number">36</span>),</span><br><span class="line"> (<span class="string">&#x27;Europe/Madrid&#x27;</span>, <span class="number">35</span>),</span><br><span class="line"> (<span class="string">&#x27;America/Sao_Paulo&#x27;</span>, <span class="number">33</span>)]</span><br></pre></td></tr></table></figure></p>
<h2><span id="用pandas对时区进行计数">用pandas对时区进行计数</span></h2><p>从原始记录的集合创建DateFrame，与将记录列表传递到pandas.DataFrame一样简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">25</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: frame = pd.DataFrame(records)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: frame.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">3560</span> entries, <span class="number">0</span> to <span class="number">3559</span></span><br><span class="line">Data columns (total <span class="number">18</span> columns):</span><br><span class="line">_heartbeat_    <span class="number">120</span> non-null float64</span><br><span class="line">a              <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">al             <span class="number">3094</span> non-null <span class="built_in">object</span></span><br><span class="line">c              <span class="number">2919</span> non-null <span class="built_in">object</span></span><br><span class="line">cy             <span class="number">2919</span> non-null <span class="built_in">object</span></span><br><span class="line">g              <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">gr             <span class="number">2919</span> non-null <span class="built_in">object</span></span><br><span class="line">h              <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">hc             <span class="number">3440</span> non-null float64</span><br><span class="line">hh             <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">kw             <span class="number">93</span> non-null <span class="built_in">object</span></span><br><span class="line">l              <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">ll             <span class="number">2919</span> non-null <span class="built_in">object</span></span><br><span class="line">nk             <span class="number">3440</span> non-null float64</span><br><span class="line">r              <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">t              <span class="number">3440</span> non-null float64</span><br><span class="line">tz             <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">u              <span class="number">3440</span> non-null <span class="built_in">object</span></span><br><span class="line">dtypes: float64(<span class="number">4</span>), <span class="built_in">object</span>(<span class="number">14</span>)</span><br><span class="line">memory usage: <span class="number">500.7</span>+ KB</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: frame[<span class="string">&#x27;tz&#x27;</span>][:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line"><span class="number">0</span>     America/New_York</span><br><span class="line"><span class="number">1</span>       America/Denver</span><br><span class="line"><span class="number">2</span>     America/New_York</span><br><span class="line"><span class="number">3</span>    America/Sao_Paulo</span><br><span class="line"><span class="number">4</span>     America/New_York</span><br><span class="line"><span class="number">5</span>     America/New_York</span><br><span class="line"><span class="number">6</span>        Europe/Warsaw</span><br><span class="line"><span class="number">7</span>                     </span><br><span class="line"><span class="number">8</span>                     </span><br><span class="line"><span class="number">9</span>                     </span><br><span class="line">Name: tz, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>这里frame的输出形式是摘要视图（summary view），主要用于较大的DataFrame对象。我们然后可以对Series使用value_counts方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: tz_counts = frame[<span class="string">&#x27;tz&#x27;</span>].value_counts()</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: tz_counts[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">30</span>]: </span><br><span class="line">America/New_York       <span class="number">1251</span></span><br><span class="line">                        <span class="number">521</span></span><br><span class="line">America/Chicago         <span class="number">400</span></span><br><span class="line">America/Los_Angeles     <span class="number">382</span></span><br><span class="line">America/Denver          <span class="number">191</span></span><br><span class="line">Europe/London            <span class="number">74</span></span><br><span class="line">Asia/Tokyo               <span class="number">37</span></span><br><span class="line">Pacific/Honolulu         <span class="number">36</span></span><br><span class="line">Europe/Madrid            <span class="number">35</span></span><br><span class="line">America/Sao_Paulo        <span class="number">33</span></span><br><span class="line">Name: tz, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>我们可以用matplotlib可视化这个数据。为此，我们先给记录中未知或缺失的时区填上一个替代值。fillna函数可以替换缺失值（NA），而未知值（空字符串）则可以通过布尔型数组索引加以替换：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">31</span>]: clean_tz = frame[<span class="string">&#x27;tz&#x27;</span>].fillna(<span class="string">&#x27;Missing&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: clean_tz[clean_tz == <span class="string">&#x27;&#x27;</span>] = <span class="string">&#x27;Unknown&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: tz_counts = clean_tz.value_counts()</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: tz_counts[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">34</span>]: </span><br><span class="line">America/New_York       <span class="number">1251</span></span><br><span class="line">Unknown                 <span class="number">521</span></span><br><span class="line">America/Chicago         <span class="number">400</span></span><br><span class="line">America/Los_Angeles     <span class="number">382</span></span><br><span class="line">America/Denver          <span class="number">191</span></span><br><span class="line">Missing                 <span class="number">120</span></span><br><span class="line">Europe/London            <span class="number">74</span></span><br><span class="line">Asia/Tokyo               <span class="number">37</span></span><br><span class="line">Pacific/Honolulu         <span class="number">36</span></span><br><span class="line">Europe/Madrid            <span class="number">35</span></span><br><span class="line">Name: tz, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>此时，我们可以用seaborn包创建水平柱状图（结果见图14-1）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">36</span>]: <span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: subset = tz_counts[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: sns.barplot(y=subset.index, x=subset.values)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-aa267c1d399a78f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-1 usa.gov示例数据中最常出现的时区"></p>
<p>a字段含有执行URL短缩操作的浏览器、设备、应用程序的相关信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: frame[<span class="string">&#x27;a&#x27;</span>][<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">39</span>]: <span class="string">&#x27;GoogleMaps/RochesterNY&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: frame[<span class="string">&#x27;a&#x27;</span>][<span class="number">50</span>]</span><br><span class="line">Out[<span class="number">40</span>]: <span class="string">&#x27;Mozilla/5.0 (Windows NT 5.1; rv:10.0.2)</span></span><br><span class="line"><span class="string">Gecko/20100101 Firefox/10.0.2&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: frame[<span class="string">&#x27;a&#x27;</span>][<span class="number">51</span>][:<span class="number">50</span>]  <span class="comment"># long line</span></span><br><span class="line">Out[<span class="number">41</span>]: <span class="string">&#x27;Mozilla/5.0 (Linux; U; Android 2.2.2; en-us; LG-P9&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>将这些”agent”字符串中的所有信息都解析出来是一件挺郁闷的工作。一种策略是将这种字符串的第一节（与浏览器大致对应）分离出来并得到另外一份用户行为摘要：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">42</span>]: results = pd.Series([x.split()[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> frame.a.dropna()])</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: results[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line"><span class="number">0</span>               Mozilla/<span class="number">5.0</span></span><br><span class="line"><span class="number">1</span>    GoogleMaps/RochesterNY</span><br><span class="line"><span class="number">2</span>               Mozilla/<span class="number">4.0</span></span><br><span class="line"><span class="number">3</span>               Mozilla/<span class="number">5.0</span></span><br><span class="line"><span class="number">4</span>               Mozilla/<span class="number">5.0</span></span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: results.value_counts()[:<span class="number">8</span>]</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line">Mozilla/<span class="number">5.0</span>                 <span class="number">2594</span></span><br><span class="line">Mozilla/<span class="number">4.0</span>                  <span class="number">601</span></span><br><span class="line">GoogleMaps/RochesterNY       <span class="number">121</span></span><br><span class="line">Opera/<span class="number">9.80</span>                    <span class="number">34</span></span><br><span class="line">TEST_INTERNET_AGENT           <span class="number">24</span></span><br><span class="line">GoogleProducer                <span class="number">21</span></span><br><span class="line">Mozilla/<span class="number">6.0</span>                    <span class="number">5</span></span><br><span class="line">BlackBerry8520/<span class="number">5.0</span><span class="number">.0</span><span class="number">.681</span>       <span class="number">4</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>现在，假设你想按Windows和非Windows用户对时区统计信息进行分解。为了简单起见，我们假定只要agent字符串中含有”Windows”就认为该用户为Windows用户。由于有的agent缺失，所以首先将它们从数据中移除：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: cframe = frame[frame.a.notnull()]</span><br></pre></td></tr></table></figure></p>
<p>然后计算出各行是否含有Windows的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: cframe[<span class="string">&#x27;os&#x27;</span>] = np.where(cframe[<span class="string">&#x27;a&#x27;</span>].<span class="built_in">str</span>.contains(<span class="string">&#x27;Windows&#x27;</span>),</span><br><span class="line">   ....:                         <span class="string">&#x27;Windows&#x27;</span>, <span class="string">&#x27;Not Windows&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: cframe[<span class="string">&#x27;os&#x27;</span>][:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">48</span>]: </span><br><span class="line"><span class="number">0</span>        Windows</span><br><span class="line"><span class="number">1</span>    Not Windows</span><br><span class="line"><span class="number">2</span>        Windows</span><br><span class="line"><span class="number">3</span>    Not Windows</span><br><span class="line"><span class="number">4</span>        Windows</span><br><span class="line">Name: os, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>接下来就可以根据时区和新得到的操作系统列表对数据进行分组了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: by_tz_os = cframe.groupby([<span class="string">&#x27;tz&#x27;</span>, <span class="string">&#x27;os&#x27;</span>])</span><br></pre></td></tr></table></figure></p>
<p>分组计数，类似于value_counts函数，可以用size来计算。并利用unstack对计数结果进行重塑：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: agg_counts = by_tz_os.size().unstack().fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: agg_counts[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">os                              Not Windows  Windows</span><br><span class="line">tz                                                  </span><br><span class="line">                                      <span class="number">245.0</span>    <span class="number">276.0</span></span><br><span class="line">Africa/Cairo                            <span class="number">0.0</span>      <span class="number">3.0</span></span><br><span class="line">Africa/Casablanca                       <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">Africa/Ceuta                            <span class="number">0.0</span>      <span class="number">2.0</span></span><br><span class="line">Africa/Johannesburg                     <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">Africa/Lusaka                           <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">America/Anchorage                       <span class="number">4.0</span>      <span class="number">1.0</span></span><br><span class="line">America/Argentina/Buenos_Aires          <span class="number">1.0</span>      <span class="number">0.0</span></span><br><span class="line">America/Argentina/Cordoba               <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">America/Argentina/Mendoza               <span class="number">0.0</span>      <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<p>最后，我们来选取最常出现的时区。为了达到这个目的，我根据agg_counts中的行数构造了一个间接索引数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use to sort in ascending order</span></span><br><span class="line">In [<span class="number">52</span>]: indexer = agg_counts.<span class="built_in">sum</span>(<span class="number">1</span>).argsort()</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: indexer[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">tz</span><br><span class="line">                                  <span class="number">24</span></span><br><span class="line">Africa/Cairo                      <span class="number">20</span></span><br><span class="line">Africa/Casablanca                 <span class="number">21</span></span><br><span class="line">Africa/Ceuta                      <span class="number">92</span></span><br><span class="line">Africa/Johannesburg               <span class="number">87</span></span><br><span class="line">Africa/Lusaka                     <span class="number">53</span></span><br><span class="line">America/Anchorage                 <span class="number">54</span></span><br><span class="line">America/Argentina/Buenos_Aires    <span class="number">57</span></span><br><span class="line">America/Argentina/Cordoba         <span class="number">26</span></span><br><span class="line">America/Argentina/Mendoza         <span class="number">55</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>然后我通过take按照这个顺序截取了最后10行最大值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">54</span>]: count_subset = agg_counts.take(indexer[-<span class="number">10</span>:])</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: count_subset</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line">os                   Not Windows  Windows</span><br><span class="line">tz                                       </span><br><span class="line">America/Sao_Paulo           <span class="number">13.0</span>     <span class="number">20.0</span></span><br><span class="line">Europe/Madrid               <span class="number">16.0</span>     <span class="number">19.0</span></span><br><span class="line">Pacific/Honolulu             <span class="number">0.0</span>     <span class="number">36.0</span></span><br><span class="line">Asia/Tokyo                   <span class="number">2.0</span>     <span class="number">35.0</span></span><br><span class="line">Europe/London               <span class="number">43.0</span>     <span class="number">31.0</span></span><br><span class="line">America/Denver             <span class="number">132.0</span>     <span class="number">59.0</span></span><br><span class="line">America/Los_Angeles        <span class="number">130.0</span>    <span class="number">252.0</span></span><br><span class="line">America/Chicago            <span class="number">115.0</span>    <span class="number">285.0</span></span><br><span class="line">                           <span class="number">245.0</span>    <span class="number">276.0</span></span><br><span class="line">America/New_York           <span class="number">339.0</span>    <span class="number">912.0</span></span><br></pre></td></tr></table></figure></p>
<p>pandas有一个简便方法nlargest，可以做同样的工作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: agg_counts.<span class="built_in">sum</span>(<span class="number">1</span>).nlargest(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">56</span>]: </span><br><span class="line">tz</span><br><span class="line">America/New_York       <span class="number">1251.0</span></span><br><span class="line">                        <span class="number">521.0</span></span><br><span class="line">America/Chicago         <span class="number">400.0</span></span><br><span class="line">America/Los_Angeles     <span class="number">382.0</span></span><br><span class="line">America/Denver          <span class="number">191.0</span></span><br><span class="line">Europe/London            <span class="number">74.0</span></span><br><span class="line">Asia/Tokyo               <span class="number">37.0</span></span><br><span class="line">Pacific/Honolulu         <span class="number">36.0</span></span><br><span class="line">Europe/Madrid            <span class="number">35.0</span></span><br><span class="line">America/Sao_Paulo        <span class="number">33.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>然后，如这段代码所示，可以用柱状图表示。我传递一个额外参数到seaborn的barpolt函数，来画一个堆积条形图（见图14-2）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Rearrange the data for plotting</span></span><br><span class="line">In [<span class="number">58</span>]: count_subset = count_subset.stack()</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: count_subset.name = <span class="string">&#x27;total&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: count_subset = count_subset.reset_index()</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: count_subset[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">61</span>]: </span><br><span class="line">                  tz           os  total</span><br><span class="line"><span class="number">0</span>  America/Sao_Paulo  Not Windows   <span class="number">13.0</span></span><br><span class="line"><span class="number">1</span>  America/Sao_Paulo      Windows   <span class="number">20.0</span></span><br><span class="line"><span class="number">2</span>      Europe/Madrid  Not Windows   <span class="number">16.0</span></span><br><span class="line"><span class="number">3</span>      Europe/Madrid      Windows   <span class="number">19.0</span></span><br><span class="line"><span class="number">4</span>   Pacific/Honolulu  Not Windows    <span class="number">0.0</span></span><br><span class="line"><span class="number">5</span>   Pacific/Honolulu      Windows   <span class="number">36.0</span></span><br><span class="line"><span class="number">6</span>         Asia/Tokyo  Not Windows    <span class="number">2.0</span></span><br><span class="line"><span class="number">7</span>         Asia/Tokyo      Windows   <span class="number">35.0</span></span><br><span class="line"><span class="number">8</span>      Europe/London  Not Windows   <span class="number">43.0</span></span><br><span class="line"><span class="number">9</span>      Europe/London      Windows   <span class="number">31.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: sns.barplot(x=<span class="string">&#x27;total&#x27;</span>, y=<span class="string">&#x27;tz&#x27;</span>, hue=<span class="string">&#x27;os&#x27;</span>,  data=count_subset)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-053612a5655b68d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-2 最常出现时区的Windows和非Windows用户"></p>
<p>这张图不容易看出Windows用户在小分组中的相对比例，因此标准化分组百分比之和为1：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">norm_total</span>(<span class="params">group</span>):</span></span><br><span class="line">    group[<span class="string">&#x27;normed_total&#x27;</span>] = group.total / group.total.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> group</span><br><span class="line"></span><br><span class="line">results = count_subset.groupby(<span class="string">&#x27;tz&#x27;</span>).apply(norm_total)</span><br></pre></td></tr></table></figure></p>
<p>再次画图，见图14-3：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">65</span>]: sns.barplot(x=<span class="string">&#x27;normed_total&#x27;</span>, y=<span class="string">&#x27;tz&#x27;</span>, hue=<span class="string">&#x27;os&#x27;</span>,  data=results)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-60ee355801daf412.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-3 最常出现时区的Windows和非Windows用户的百分比"></p>
<p>我们还可以用groupby的transform方法，更高效的计算标准化的和：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: g = count_subset.groupby(<span class="string">&#x27;tz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: results2 = count_subset.total / g.total.transform(<span class="string">&#x27;sum&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h1><span id="142-movielens-1m数据集">14.2 MovieLens 1M数据集</span></h1><p><a href="http://www.grouplens.org/node/73">GroupLens Research</a>采集了一组从20世纪90年末到21世纪初由MovieLens用户提供的电影评分数据。这些数据中包括电影评分、电影元数据（风格类型和年代）以及关于用户的人口统计学数据（年龄、邮编、性别和职业等）。基于机器学习算法的推荐系统一般都会对此类数据感兴趣。虽然我不会在本书中详细介绍机器学习技术，但我会告诉你如何对这种数据进行切片切块以满足实际需求。</p>
<p>MovieLens 1M数据集含有来自6000名用户对4000部电影的100万条评分数据。它分为三个表：评分、用户信息和电影信息。将该数据从zip文件中解压出来之后，可以通过pandas.read_table将各个表分别读到一个pandas DataFrame对象中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make display smaller</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">unames = [<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;zip&#x27;</span>]</span><br><span class="line">users = pd.read_table(<span class="string">&#x27;datasets/movielens/users.dat&#x27;</span>, sep=<span class="string">&#x27;::&#x27;</span>,</span><br><span class="line">                      header=<span class="literal">None</span>, names=unames)</span><br><span class="line"></span><br><span class="line">rnames = [<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;movie_id&#x27;</span>, <span class="string">&#x27;rating&#x27;</span>, <span class="string">&#x27;timestamp&#x27;</span>]</span><br><span class="line">ratings = pd.read_table(<span class="string">&#x27;datasets/movielens/ratings.dat&#x27;</span>, sep=<span class="string">&#x27;::&#x27;</span>,</span><br><span class="line">                        header=<span class="literal">None</span>, names=rnames)</span><br><span class="line">mnames = [<span class="string">&#x27;movie_id&#x27;</span>, <span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;genres&#x27;</span>]</span><br><span class="line">movies = pd.read_table(<span class="string">&#x27;datasets/movielens/movies.dat&#x27;</span>, sep=<span class="string">&#x27;::&#x27;</span>,</span><br><span class="line">                       header=<span class="literal">None</span>, names=mnames)</span><br></pre></td></tr></table></figure></p>
<p>利用Python的切片语法，通过查看每个DataFrame的前几行即可验证数据加载工作是否一切顺利：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: users[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">69</span>]: </span><br><span class="line">   user_id gender  age  occupation    <span class="built_in">zip</span></span><br><span class="line"><span class="number">0</span>        <span class="number">1</span>      F    <span class="number">1</span>          <span class="number">10</span>  <span class="number">48067</span></span><br><span class="line"><span class="number">1</span>        <span class="number">2</span>      M   <span class="number">56</span>          <span class="number">16</span>  <span class="number">70072</span></span><br><span class="line"><span class="number">2</span>        <span class="number">3</span>      M   <span class="number">25</span>          <span class="number">15</span>  <span class="number">55117</span></span><br><span class="line"><span class="number">3</span>        <span class="number">4</span>      M   <span class="number">45</span>           <span class="number">7</span>  02460</span><br><span class="line"><span class="number">4</span>        <span class="number">5</span>      M   <span class="number">25</span>          <span class="number">20</span>  <span class="number">55455</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: ratings[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line">   user_id  movie_id  rating  timestamp</span><br><span class="line"><span class="number">0</span>        <span class="number">1</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978300760</span></span><br><span class="line"><span class="number">1</span>        <span class="number">1</span>       <span class="number">661</span>       <span class="number">3</span>  <span class="number">978302109</span></span><br><span class="line"><span class="number">2</span>        <span class="number">1</span>       <span class="number">914</span>       <span class="number">3</span>  <span class="number">978301968</span></span><br><span class="line"><span class="number">3</span>        <span class="number">1</span>      <span class="number">3408</span>       <span class="number">4</span>  <span class="number">978300275</span></span><br><span class="line"><span class="number">4</span>        <span class="number">1</span>      <span class="number">2355</span>       <span class="number">5</span>  <span class="number">978824291</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: movies[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line">   movie_id                               title                        genres</span><br><span class="line"><span class="number">0</span>         <span class="number">1</span>                    Toy Story (<span class="number">1995</span>)   Animation|Children<span class="string">&#x27;s|Comedy</span></span><br><span class="line"><span class="string">1         2                      Jumanji (1995)  Adventure|Children&#x27;</span>s|Fantasy</span><br><span class="line"><span class="number">2</span>         <span class="number">3</span>             Grumpier Old Men (<span class="number">1995</span>)                Comedy|Romance</span><br><span class="line"><span class="number">3</span>         <span class="number">4</span>            Waiting to Exhale (<span class="number">1995</span>)                  Comedy|Drama</span><br><span class="line"><span class="number">4</span>         <span class="number">5</span>  Father of the Bride Part II (<span class="number">1995</span>)                        Comedy</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: ratings</span><br><span class="line">Out[<span class="number">72</span>]: </span><br><span class="line">         user_id  movie_id  rating  timestamp</span><br><span class="line"><span class="number">0</span>              <span class="number">1</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978300760</span></span><br><span class="line"><span class="number">1</span>              <span class="number">1</span>       <span class="number">661</span>       <span class="number">3</span>  <span class="number">978302109</span></span><br><span class="line"><span class="number">2</span>              <span class="number">1</span>       <span class="number">914</span>       <span class="number">3</span>  <span class="number">978301968</span></span><br><span class="line"><span class="number">3</span>              <span class="number">1</span>      <span class="number">3408</span>       <span class="number">4</span>  <span class="number">978300275</span></span><br><span class="line"><span class="number">4</span>              <span class="number">1</span>      <span class="number">2355</span>       <span class="number">5</span>  <span class="number">978824291</span></span><br><span class="line"><span class="meta">... </span>         ...       ...     ...        ...</span><br><span class="line"><span class="number">1000204</span>     <span class="number">6040</span>      <span class="number">1091</span>       <span class="number">1</span>  <span class="number">956716541</span></span><br><span class="line"><span class="number">1000205</span>     <span class="number">6040</span>      <span class="number">1094</span>       <span class="number">5</span>  <span class="number">956704887</span></span><br><span class="line"><span class="number">1000206</span>     <span class="number">6040</span>       <span class="number">562</span>       <span class="number">5</span>  <span class="number">956704746</span></span><br><span class="line"><span class="number">1000207</span>     <span class="number">6040</span>      <span class="number">1096</span>       <span class="number">4</span>  <span class="number">956715648</span></span><br><span class="line"><span class="number">1000208</span>     <span class="number">6040</span>      <span class="number">1097</span>       <span class="number">4</span>  <span class="number">956715569</span></span><br><span class="line">[<span class="number">1000209</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>注意，其中的年龄和职业是以编码形式给出的，它们的具体含义请参考该数据集的README文件。分析散布在三个表中的数据可不是一件轻松的事情。假设我们想要根据性别和年龄计算某部电影的平均得分，如果将所有数据都合并到一个表中的话问题就简单多了。我们先用pandas的merge函数将ratings跟users合并到一起，然后再将movies也合并进去。pandas会根据列名的重叠情况推断出哪些列是合并（或连接）键：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: data = pd.merge(pd.merge(ratings, users), movies)</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: data</span><br><span class="line">Out[<span class="number">74</span>]: </span><br><span class="line">         user_id  movie_id  rating  timestamp gender  age  occupation    <span class="built_in">zip</span>  \</span><br><span class="line"><span class="number">0</span>              <span class="number">1</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978300760</span>      F    <span class="number">1</span>          <span class="number">10</span>  <span class="number">48067</span>   </span><br><span class="line"><span class="number">1</span>              <span class="number">2</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978298413</span>      M   <span class="number">56</span>          <span class="number">16</span>  <span class="number">70072</span>   </span><br><span class="line"><span class="number">2</span>             <span class="number">12</span>      <span class="number">1193</span>       <span class="number">4</span>  <span class="number">978220179</span>      M   <span class="number">25</span>          <span class="number">12</span>  <span class="number">32793</span>   </span><br><span class="line"><span class="number">3</span>             <span class="number">15</span>      <span class="number">1193</span>       <span class="number">4</span>  <span class="number">978199279</span>      M   <span class="number">25</span>           <span class="number">7</span>  <span class="number">22903</span>   </span><br><span class="line"><span class="number">4</span>             <span class="number">17</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978158471</span>      M   <span class="number">50</span>           <span class="number">1</span>  <span class="number">95350</span>   </span><br><span class="line"><span class="meta">... </span>         ...       ...     ...        ...    ...  ...         ...    ...   </span><br><span class="line"><span class="number">1000204</span>     <span class="number">5949</span>      <span class="number">2198</span>       <span class="number">5</span>  <span class="number">958846401</span>      M   <span class="number">18</span>          <span class="number">17</span>  <span class="number">47901</span></span><br><span class="line"><span class="number">1000205</span>     <span class="number">5675</span>      <span class="number">2703</span>       <span class="number">3</span>  <span class="number">976029116</span>      M   <span class="number">35</span>          <span class="number">14</span>  <span class="number">30030</span>   </span><br><span class="line"><span class="number">1000206</span>     <span class="number">5780</span>      <span class="number">2845</span>       <span class="number">1</span>  <span class="number">958153068</span>      M   <span class="number">18</span>          <span class="number">17</span>  <span class="number">92886</span>   </span><br><span class="line"><span class="number">1000207</span>     <span class="number">5851</span>      <span class="number">3607</span>       <span class="number">5</span>  <span class="number">957756608</span>      F   <span class="number">18</span>          <span class="number">20</span>  <span class="number">55410</span>   </span><br><span class="line"><span class="number">1000208</span>     <span class="number">5938</span>      <span class="number">2909</span>       <span class="number">4</span>  <span class="number">957273353</span>      M   <span class="number">25</span>           <span class="number">1</span>  <span class="number">35401</span>   </span><br><span class="line">                                               title                genres  </span><br><span class="line"><span class="number">0</span>             One Flew Over the Cuckoo<span class="string">&#x27;s Nest (1975)                 Drama  </span></span><br><span class="line"><span class="string">1             One Flew Over the Cuckoo&#x27;</span>s Nest (<span class="number">1975</span>)                 Drama  </span><br><span class="line"><span class="number">2</span>             One Flew Over the Cuckoo<span class="string">&#x27;s Nest (1975)                 Drama  </span></span><br><span class="line"><span class="string">3             One Flew Over the Cuckoo&#x27;</span>s Nest (<span class="number">1975</span>)                 Drama  </span><br><span class="line"><span class="number">4</span>             One Flew Over the Cuckoo<span class="string">&#x27;s Nest (1975)                 Drama  </span></span><br><span class="line"><span class="string">...                                              ...                   ...  </span></span><br><span class="line"><span class="string">1000204                           Modulations (1998)           Documentary  </span></span><br><span class="line"><span class="string">1000205                        Broken Vessels (1998)                 Drama  </span></span><br><span class="line"><span class="string">1000206                            White Boys (1999)                 Drama  </span></span><br><span class="line"><span class="string">1000207                     One Little Indian (1973)  Comedy|Drama|Western  </span></span><br><span class="line"><span class="string">1000208  Five Wives, Three Secretaries and Me (1998)           Documentary  </span></span><br><span class="line"><span class="string">[1000209 rows x 10 columns]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [75]: data.iloc[0]</span></span><br><span class="line"><span class="string">Out[75]: </span></span><br><span class="line"><span class="string">user_id                                            1</span></span><br><span class="line"><span class="string">movie_id                                        1193</span></span><br><span class="line"><span class="string">rating                                             5</span></span><br><span class="line"><span class="string">timestamp                                  978300760</span></span><br><span class="line"><span class="string">gender                                             F</span></span><br><span class="line"><span class="string">age                                                1</span></span><br><span class="line"><span class="string">occupation                                        10</span></span><br><span class="line"><span class="string">zip                                            48067</span></span><br><span class="line"><span class="string">title         One Flew Over the Cuckoo&#x27;</span>s Nest (<span class="number">1975</span>)</span><br><span class="line">genres                                         Drama</span><br><span class="line">Name: <span class="number">0</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>为了按性别计算每部电影的平均得分，我们可以使用pivot_table方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: mean_ratings = data.pivot_table(<span class="string">&#x27;rating&#x27;</span>, index=<span class="string">&#x27;title&#x27;</span>,</span><br><span class="line">   ....:                                 columns=<span class="string">&#x27;gender&#x27;</span>, aggfunc=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: mean_ratings[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">gender                                F         M</span><br><span class="line">title                                            </span><br><span class="line">$<span class="number">1</span>,<span class="number">000</span>,<span class="number">000</span> Duck (<span class="number">1971</span>)         <span class="number">3.375000</span>  <span class="number">2.761905</span></span><br><span class="line"><span class="string">&#x27;Night Mother (1986)           3.388889  3.352941</span></span><br><span class="line"><span class="string">&#x27;</span>Til There Was You (<span class="number">1997</span>)      <span class="number">2.675676</span>  <span class="number">2.733333</span></span><br><span class="line"><span class="string">&#x27;burbs, The (1989)             2.793478  2.962085</span></span><br><span class="line"><span class="string">...And Justice for All (1979)  3.828571  3.689024</span></span><br></pre></td></tr></table></figure></p>
<p>该操作产生了另一个DataFrame，其内容为电影平均得分，行标为电影名称（索引），列标为性别。现在，我打算过滤掉评分数据不够250条的电影（随便选的一个数字）。为了达到这个目的，我先对title进行分组，然后利用size()得到一个含有各电影分组大小的Series对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">78</span>]: ratings_by_title = data.groupby(<span class="string">&#x27;title&#x27;</span>).size()</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: ratings_by_title[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line">title</span><br><span class="line">$<span class="number">1</span>,<span class="number">000</span>,<span class="number">000</span> Duck (<span class="number">1971</span>)                <span class="number">37</span></span><br><span class="line"><span class="string">&#x27;Night Mother (1986)                  70</span></span><br><span class="line"><span class="string">&#x27;</span>Til There Was You (<span class="number">1997</span>)             <span class="number">52</span></span><br><span class="line"><span class="string">&#x27;burbs, The (1989)                   303</span></span><br><span class="line"><span class="string">...And Justice for All (1979)        199</span></span><br><span class="line"><span class="string">1-900 (1994)                           2</span></span><br><span class="line"><span class="string">10 Things I Hate About You (1999)    700</span></span><br><span class="line"><span class="string">101 Dalmatians (1961)                565</span></span><br><span class="line"><span class="string">101 Dalmatians (1996)                364</span></span><br><span class="line"><span class="string">12 Angry Men (1957)                  616</span></span><br><span class="line"><span class="string">dtype: int64</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [80]: active_titles = ratings_by_title.index[ratings_by_title &gt;= 250]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [81]: active_titles</span></span><br><span class="line"><span class="string">Out[81]: </span></span><br><span class="line"><span class="string">Index([&#x27;</span><span class="string">&#x27;burbs, The (1989)&#x27;</span>, <span class="string">&#x27;10 Things I Hate About You (1999)&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;101 Dalmatians (1961)&#x27;</span>, <span class="string">&#x27;101 Dalmatians (1996)&#x27;</span>, <span class="string">&#x27;12 Angry Men (1957)&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;13th Warrior, The (1999)&#x27;</span>, <span class="string">&#x27;2 Days in the Valley (1996)&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;20,000 Leagues Under the Sea (1954)&#x27;</span>, <span class="string">&#x27;2001: A Space Odyssey (1968)&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;2010 (1984)&#x27;</span>,</span><br><span class="line">       ...</span><br><span class="line"><span class="string">&#x27;X-Men (2000)&#x27;</span>, <span class="string">&#x27;Year of Living Dangerously (1982)&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Yellow Submarine (1968)&#x27;</span>, <span class="string">&#x27;You&#x27;</span>ve Got Mail (<span class="number">1998</span>)<span class="string">&#x27;,</span></span><br><span class="line"><span class="string">       &#x27;</span>Young Frankenstein (<span class="number">1974</span>)<span class="string">&#x27;, &#x27;</span>Young Guns (<span class="number">1988</span>)<span class="string">&#x27;,</span></span><br><span class="line"><span class="string">       &#x27;</span>Young Guns II (<span class="number">1990</span>)<span class="string">&#x27;, &#x27;</span>Young Sherlock Holmes (<span class="number">1985</span>)<span class="string">&#x27;,</span></span><br><span class="line"><span class="string">       &#x27;</span>Zero Effect (<span class="number">1998</span>)<span class="string">&#x27;, &#x27;</span>eXistenZ (<span class="number">1999</span>)<span class="string">&#x27;],</span></span><br><span class="line"><span class="string">      dtype=&#x27;</span><span class="built_in">object</span><span class="string">&#x27;, name=&#x27;</span>title<span class="string">&#x27;, length=1216)</span></span><br></pre></td></tr></table></figure></p>
<p>标题索引中含有评分数据大于250条的电影名称，然后我们就可以据此从前面的mean_ratings中选取所需的行了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Select rows on the index</span></span><br><span class="line">In [<span class="number">82</span>]: mean_ratings = mean_ratings.loc[active_titles]</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: mean_ratings</span><br><span class="line">Out[<span class="number">83</span>]: </span><br><span class="line">gender                                    F         M</span><br><span class="line">title                                                </span><br><span class="line"><span class="string">&#x27;burbs, The (1989)                 2.793478  2.962085</span></span><br><span class="line"><span class="string">10 Things I Hate About You (1999)  3.646552  3.311966</span></span><br><span class="line"><span class="string">101 Dalmatians (1961)              3.791444  3.500000</span></span><br><span class="line"><span class="string">101 Dalmatians (1996)              3.240000  2.911215</span></span><br><span class="line"><span class="string">12 Angry Men (1957)                4.184397  4.328421</span></span><br><span class="line"><span class="string">...                                     ...       ...</span></span><br><span class="line"><span class="string">Young Guns (1988)                  3.371795  3.425620</span></span><br><span class="line"><span class="string">Young Guns II (1990)               2.934783  2.904025</span></span><br><span class="line"><span class="string">Young Sherlock Holmes (1985)       3.514706  3.363344</span></span><br><span class="line"><span class="string">Zero Effect (1998)                 3.864407  3.723140</span></span><br><span class="line"><span class="string">eXistenZ (1999)                    3.098592  3.289086</span></span><br><span class="line"><span class="string">[1216 rows x 2 columns]</span></span><br></pre></td></tr></table></figure></p>
<p>为了了解女性观众最喜欢的电影，我们可以对F列降序排列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: top_female_ratings = mean_ratings.sort_values(by=<span class="string">&#x27;F&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: top_female_ratings[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line">gender                                                     F         M</span><br><span class="line">title                                                                 </span><br><span class="line">Close Shave, A (<span class="number">1995</span>)                               <span class="number">4.644444</span>  <span class="number">4.473795</span></span><br><span class="line">Wrong Trousers, The (<span class="number">1993</span>)                          <span class="number">4.588235</span>  <span class="number">4.478261</span></span><br><span class="line">Sunset Blvd. (a.k.a. Sunset Boulevard) (<span class="number">1950</span>)       <span class="number">4.572650</span>  <span class="number">4.464589</span></span><br><span class="line">Wallace &amp; Gromit: The Best of Aardman Animation...  <span class="number">4.563107</span>  <span class="number">4.385075</span></span><br><span class="line">Schindle<span class="string">r&#x27;s List (1993)                             4.562602  4.491415</span></span><br><span class="line"><span class="string">Shawshank Redemption, The (1994)                    4.539075  4.560625</span></span><br><span class="line"><span class="string">Grand Day Out, A (1992)                             4.537879  4.293255</span></span><br><span class="line"><span class="string">To Kill a Mockingbird (1962)                        4.536667  4.372611</span></span><br><span class="line"><span class="string">Creature Comforts (1990)                            4.513889  4.272277</span></span><br><span class="line"><span class="string">Usual Suspects, The (1995)                          4.513317  4.518248</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="计算评分分歧">计算评分分歧</span></h2><p>假设我们想要找出男性和女性观众分歧最大的电影。一个办法是给mean_ratings加上一个用于存放平均得分之差的列，并对其进行排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: mean_ratings[<span class="string">&#x27;diff&#x27;</span>] = mean_ratings[<span class="string">&#x27;M&#x27;</span>] - mean_ratings[<span class="string">&#x27;F&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>按”diff”排序即可得到分歧最大且女性观众更喜欢的电影：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">88</span>]: sorted_by_diff = mean_ratings.sort_values(by=<span class="string">&#x27;diff&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: sorted_by_diff[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">89</span>]: </span><br><span class="line">gender                                        F         M      diff</span><br><span class="line">title                                                              </span><br><span class="line">Dirty Dancing (<span class="number">1987</span>)                   <span class="number">3.790378</span>  <span class="number">2.959596</span> -<span class="number">0.830782</span></span><br><span class="line">Jumpin<span class="string">&#x27; Jack Flash (1986)              3.254717  2.578358 -0.676359</span></span><br><span class="line"><span class="string">Grease (1978)                          3.975265  3.367041 -0.608224</span></span><br><span class="line"><span class="string">Little Women (1994)                    3.870588  3.321739 -0.548849</span></span><br><span class="line"><span class="string">Steel Magnolias (1989)                 3.901734  3.365957 -0.535777</span></span><br><span class="line"><span class="string">Anastasia (1997)                       3.800000  3.281609 -0.518391</span></span><br><span class="line"><span class="string">Rocky Horror Picture Show, The (1975)  3.673016  3.160131 -0.512885</span></span><br><span class="line"><span class="string">Color Purple, The (1985)               4.158192  3.659341 -0.498851</span></span><br><span class="line"><span class="string">Age of Innocence, The (1993)           3.827068  3.339506 -0.487561</span></span><br><span class="line"><span class="string">Free Willy (1993)                      2.921348  2.438776 -0.482573</span></span><br></pre></td></tr></table></figure></p>
<p>对排序结果反序并取出前10行，得到的则是男性观众更喜欢的电影：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reverse order of rows, take first 10 rows</span></span><br><span class="line">In [<span class="number">90</span>]: sorted_by_diff[::-<span class="number">1</span>][:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">gender                                         F         M      diff</span><br><span class="line">title                                                               </span><br><span class="line">Good, The Bad <span class="keyword">and</span> The Ugly, The (<span class="number">1966</span>)  <span class="number">3.494949</span>  <span class="number">4.221300</span>  <span class="number">0.726351</span></span><br><span class="line">Kentucky Fried Movie, The (<span class="number">1977</span>)        <span class="number">2.878788</span>  <span class="number">3.555147</span>  <span class="number">0.676359</span></span><br><span class="line">Dumb &amp; Dumber (<span class="number">1994</span>)                    <span class="number">2.697987</span>  <span class="number">3.336595</span>  <span class="number">0.638608</span></span><br><span class="line">Longest Day, The (<span class="number">1962</span>)                 <span class="number">3.411765</span>  <span class="number">4.031447</span>  <span class="number">0.619682</span></span><br><span class="line">Cable Guy, The (<span class="number">1996</span>)                   <span class="number">2.250000</span>  <span class="number">2.863787</span>  <span class="number">0.613787</span></span><br><span class="line">Evil Dead II (Dead By Dawn) (<span class="number">1987</span>)      <span class="number">3.297297</span>  <span class="number">3.909283</span>  <span class="number">0.611985</span></span><br><span class="line">Hidden, The (<span class="number">1987</span>)                      <span class="number">3.137931</span>  <span class="number">3.745098</span>  <span class="number">0.607167</span></span><br><span class="line">Rocky III (<span class="number">1982</span>)                        <span class="number">2.361702</span>  <span class="number">2.943503</span>  <span class="number">0.581801</span></span><br><span class="line">Caddyshack (<span class="number">1980</span>)                       <span class="number">3.396135</span>  <span class="number">3.969737</span>  <span class="number">0.573602</span></span><br><span class="line">For a Few Dollars More (<span class="number">1965</span>)           <span class="number">3.409091</span>  <span class="number">3.953795</span>  <span class="number">0.544704</span></span><br></pre></td></tr></table></figure></p>
<p>如果只是想要找出分歧最大的电影（不考虑性别因素），则可以计算得分数据的方差或标准差：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Standard deviation of rating grouped by title</span></span><br><span class="line">In [<span class="number">91</span>]: rating_std_by_title = data.groupby(<span class="string">&#x27;title&#x27;</span>)[<span class="string">&#x27;rating&#x27;</span>].std()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter down to active_titles</span></span><br><span class="line">In [<span class="number">92</span>]: rating_std_by_title = rating_std_by_title.loc[active_titles]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Order Series by value in descending order</span></span><br><span class="line">In [<span class="number">93</span>]: rating_std_by_title.sort_values(ascending=<span class="literal">False</span>)[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line">title</span><br><span class="line">Dumb &amp; Dumber (<span class="number">1994</span>)                     <span class="number">1.321333</span></span><br><span class="line">Blair Witch Project, The (<span class="number">1999</span>)          <span class="number">1.316368</span></span><br><span class="line">Natural Born Killers (<span class="number">1994</span>)              <span class="number">1.307198</span></span><br><span class="line">Tank Girl (<span class="number">1995</span>)                         <span class="number">1.277695</span></span><br><span class="line">Rocky Horror Picture Show, The (<span class="number">1975</span>)    <span class="number">1.260177</span></span><br><span class="line">Eyes Wide Shut (<span class="number">1999</span>)                    <span class="number">1.259624</span></span><br><span class="line">Evita (<span class="number">1996</span>)                             <span class="number">1.253631</span></span><br><span class="line">Billy Madison (<span class="number">1995</span>)                     <span class="number">1.249970</span></span><br><span class="line">Fear <span class="keyword">and</span> Loathing <span class="keyword">in</span> Las Vegas (<span class="number">1998</span>)    <span class="number">1.246408</span></span><br><span class="line">Bicentennial Man (<span class="number">1999</span>)                  <span class="number">1.245533</span></span><br><span class="line">Name: rating, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>可能你已经注意到了，电影分类是以竖线（|）分隔的字符串形式给出的。如果想对电影分类进行分析的话，就需要先将其转换成更有用的形式才行。</p>
<h1><span id="143-1880-2010年间全美婴儿姓名">14.3 1880-2010年间全美婴儿姓名</span></h1><p>美国社会保障总署（SSA）提供了一份从1880年到现在的婴儿名字频率数据。Hadley Wickham（许多流行R包的作者）经常用这份数据来演示R的数据处理功能。</p>
<p>我们要做一些数据规整才能加载这个数据集，这么做就会产生一个如下的DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">4</span>]: names.head(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">4</span>]:</span><br><span class="line">        name sex  births  year</span><br><span class="line"><span class="number">0</span>       Mary   F    <span class="number">7065</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">1</span>       Anna   F    <span class="number">2604</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">2</span>       Emma   F    <span class="number">2003</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">3</span>  Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">4</span>     Minnie   F    <span class="number">1746</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">5</span>   Margaret   F    <span class="number">1578</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">6</span>        Ida   F    <span class="number">1472</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">7</span>      Alice   F    <span class="number">1414</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">8</span>     Bertha   F    <span class="number">1320</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">9</span>      Sarah   F    <span class="number">1288</span>  <span class="number">1880</span></span><br></pre></td></tr></table></figure></p>
<p>你可以用这个数据集做很多事，例如：</p>
<ul>
<li>计算指定名字（可以是你自己的，也可以是别人的）的年度比例。</li>
<li>计算某个名字的相对排名。</li>
<li>计算各年度最流行的名字，以及增长或减少最快的名字。</li>
<li>分析名字趋势：元音、辅音、长度、总体多样性、拼写变化、首尾字母等。</li>
<li>分析外源性趋势：圣经中的名字、名人、人口结构变化等。</li>
</ul>
<p>利用前面介绍过的那些工具，这些分析工作都能很轻松地完成，我会讲解其中的一些。</p>
<p>到编写本书时为止，美国社会保障总署将该数据库按年度制成了多个数据文件，其中给出了每个性别/名字组合的出生总数。这些文件的原始档案可以在这里获取：<a href="http://www.ssa.gov/oact/babynames/limits.html">http://www.ssa.gov/oact/babynames/limits.html</a>。</p>
<p>如果你在阅读本书的时候这个页面已经不见了，也可以用搜索引擎找找。</p>
<p>下载”National data”文件names.zip，解压后的目录中含有一组文件（如yob1880.txt）。我用UNIX的head命令查看了其中一个文件的前10行（在Windows上，你可以用more命令，或直接在文本编辑器中打开）：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [94]: !head -n 10 datasets/babynames/yob1880.txt</span><br><span class="line">Mary,F,7065</span><br><span class="line">Anna,F,2604</span><br><span class="line">Emma,F,2003</span><br><span class="line">Elizabeth,F,1939</span><br><span class="line">Minnie,F,1746</span><br><span class="line">Margaret,F,1578</span><br><span class="line">Ida,F,1472</span><br><span class="line">Alice,F,1414</span><br><span class="line">Bertha,F,1320</span><br><span class="line">Sarah,F,1288</span><br></pre></td></tr></table></figure></p>
<p>由于这是一个非常标准的以逗号隔开的格式，所以可以用pandas.read_csv将其加载到DataFrame中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: names1880 =</span><br><span class="line">pd.read_csv(<span class="string">&#x27;datasets/babynames/yob1880.txt&#x27;</span>,</span><br><span class="line">   ....:                         names=[<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;births&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: names1880</span><br><span class="line">Out[<span class="number">97</span>]: </span><br><span class="line">           name sex  births</span><br><span class="line"><span class="number">0</span>          Mary   F    <span class="number">7065</span></span><br><span class="line"><span class="number">1</span>          Anna   F    <span class="number">2604</span></span><br><span class="line"><span class="number">2</span>          Emma   F    <span class="number">2003</span></span><br><span class="line"><span class="number">3</span>     Elizabeth   F    <span class="number">1939</span></span><br><span class="line"><span class="number">4</span>        Minnie   F    <span class="number">1746</span></span><br><span class="line"><span class="meta">... </span>        ...  ..     ...</span><br><span class="line"><span class="number">1995</span>     Woodie   M       <span class="number">5</span></span><br><span class="line"><span class="number">1996</span>     Worthy   M       <span class="number">5</span></span><br><span class="line"><span class="number">1997</span>     Wright   M       <span class="number">5</span></span><br><span class="line"><span class="number">1998</span>       York   M       <span class="number">5</span></span><br><span class="line"><span class="number">1999</span>  Zachariah   M       <span class="number">5</span></span><br><span class="line">[<span class="number">2000</span> rows x <span class="number">3</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>这些文件中仅含有当年出现超过5次的名字。为了简单起见，我们可以用births列的sex分组小计表示该年度的births总计：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">98</span>]: names1880.groupby(<span class="string">&#x27;sex&#x27;</span>).births.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">98</span>]: </span><br><span class="line">sex</span><br><span class="line">F     <span class="number">90993</span></span><br><span class="line">M    <span class="number">110493</span></span><br><span class="line">Name: births, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>由于该数据集按年度被分隔成了多个文件，所以第一件事情就是要将所有数据都组装到一个DataFrame里面，并加上一个year字段。使用pandas.concat即可达到这个目的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">years = <span class="built_in">range</span>(<span class="number">1880</span>, <span class="number">2011</span>)</span><br><span class="line"></span><br><span class="line">pieces = []</span><br><span class="line">columns = [<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;births&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> years:</span><br><span class="line">    path = <span class="string">&#x27;datasets/babynames/yob%d.txt&#x27;</span> % year</span><br><span class="line">    frame = pd.read_csv(path, names=columns)</span><br><span class="line"></span><br><span class="line">    frame[<span class="string">&#x27;year&#x27;</span>] = year</span><br><span class="line">    pieces.append(frame)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Concatenate everything into a single DataFrame</span></span><br><span class="line">names = pd.concat(pieces, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意几件事情。第一，concat默认是按行将多个DataFrame组合到一起的；第二，必须指定ignore_index=True，因为我们不希望保留read_csv所返回的原始行号。现在我们得到了一个非常大的DataFrame，它含有全部的名字数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">100</span>]: names</span><br><span class="line">Out[<span class="number">100</span>]: </span><br><span class="line">              name sex  births  year</span><br><span class="line"><span class="number">0</span>             Mary   F    <span class="number">7065</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">1</span>             Anna   F    <span class="number">2604</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">2</span>             Emma   F    <span class="number">2003</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">3</span>        Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">4</span>           Minnie   F    <span class="number">1746</span>  <span class="number">1880</span></span><br><span class="line"><span class="meta">... </span>           ...  ..     ...   ...</span><br><span class="line"><span class="number">1690779</span>    Zymaire   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690780</span>     Zyonne   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690781</span>  Zyquarius   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690782</span>      Zyran   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690783</span>      Zzyzx   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line">[<span class="number">1690784</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>有了这些数据之后，我们就可以利用groupby或pivot_table在year和sex级别上对其进行聚合了，如图14-4所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">101</span>]: total_births = names.pivot_table(<span class="string">&#x27;births&#x27;</span>, index=<span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">   .....:                                  columns=<span class="string">&#x27;sex&#x27;</span>, aggfunc=<span class="built_in">sum</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: total_births.tail()</span><br><span class="line">Out[<span class="number">102</span>]: </span><br><span class="line">sex         F        M</span><br><span class="line">year                  </span><br><span class="line"><span class="number">2006</span>  <span class="number">1896468</span>  <span class="number">2050234</span></span><br><span class="line"><span class="number">2007</span>  <span class="number">1916888</span>  <span class="number">2069242</span></span><br><span class="line"><span class="number">2008</span>  <span class="number">1883645</span>  <span class="number">2032310</span></span><br><span class="line"><span class="number">2009</span>  <span class="number">1827643</span>  <span class="number">1973359</span></span><br><span class="line"><span class="number">2010</span>  <span class="number">1759010</span>  <span class="number">1898382</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: total_births.plot(title=<span class="string">&#x27;Total births by sex and year&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-7643b150d88aae11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-4 按性别和年度统计的总出生数"></p>
<p>下面我们来插入一个prop列，用于存放指定名字的婴儿数相对于总出生数的比例。prop值为0.02表示每100名婴儿中有2名取了当前这个名字。因此，我们先按year和sex分组，然后再将新列加到各个分组上：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_prop</span>(<span class="params">group</span>):</span></span><br><span class="line">    group[<span class="string">&#x27;prop&#x27;</span>] = group.births / group.births.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> group</span><br><span class="line">names = names.groupby([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>]).apply(add_prop)</span><br></pre></td></tr></table></figure></p>
<p>现在，完整的数据集就有了下面这些列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">105</span>]: names</span><br><span class="line">Out[<span class="number">105</span>]: </span><br><span class="line">              name sex  births  year      prop</span><br><span class="line"><span class="number">0</span>             Mary   F    <span class="number">7065</span>  <span class="number">1880</span>  <span class="number">0.077643</span></span><br><span class="line"><span class="number">1</span>             Anna   F    <span class="number">2604</span>  <span class="number">1880</span>  <span class="number">0.028618</span></span><br><span class="line"><span class="number">2</span>             Emma   F    <span class="number">2003</span>  <span class="number">1880</span>  <span class="number">0.022013</span></span><br><span class="line"><span class="number">3</span>        Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span>  <span class="number">0.021309</span></span><br><span class="line"><span class="number">4</span>           Minnie   F    <span class="number">1746</span>  <span class="number">1880</span>  <span class="number">0.019188</span></span><br><span class="line"><span class="meta">... </span>           ...  ..     ...   ...       ...</span><br><span class="line"><span class="number">1690779</span>    Zymaire   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690780</span>     Zyonne   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690781</span>  Zyquarius   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690782</span>      Zyran   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690783</span>      Zzyzx   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line">[<span class="number">1690784</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>在执行这样的分组处理时，一般都应该做一些有效性检查，比如验证所有分组的prop的总和是否为1：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">106</span>]: names.groupby([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>]).prop.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">106</span>]: </span><br><span class="line">year  sex</span><br><span class="line"><span class="number">1880</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line"><span class="number">1881</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line"><span class="number">1882</span>  F      <span class="number">1.0</span></span><br><span class="line">            ... </span><br><span class="line"><span class="number">2008</span>  M      <span class="number">1.0</span></span><br><span class="line"><span class="number">2009</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line"><span class="number">2010</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line">Name: prop, Length: <span class="number">262</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>工作完成。为了便于实现更进一步的分析，我需要取出该数据的一个子集：每对sex/year组合的前1000个名字。这又是一个分组操作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_top1000</span>(<span class="params">group</span>):</span></span><br><span class="line">    <span class="keyword">return</span> group.sort_values(by=<span class="string">&#x27;births&#x27;</span>, ascending=<span class="literal">False</span>)[:<span class="number">1000</span>]</span><br><span class="line">grouped = names.groupby([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>])</span><br><span class="line">top1000 = grouped.apply(get_top1000)</span><br><span class="line"><span class="comment"># Drop the group index, not needed</span></span><br><span class="line">top1000.reset_index(inplace=<span class="literal">True</span>, drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果你喜欢DIY的话，也可以这样：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pieces = []</span><br><span class="line"><span class="keyword">for</span> year, group <span class="keyword">in</span> names.groupby([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>]):</span><br><span class="line">    pieces.append(group.sort_values(by=<span class="string">&#x27;births&#x27;</span>, ascending=<span class="literal">False</span>)[:<span class="number">1000</span>])</span><br><span class="line">top1000 = pd.concat(pieces, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在的结果数据集就小多了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: top1000</span><br><span class="line">Out[<span class="number">108</span>]: </span><br><span class="line">             name sex  births  year      prop</span><br><span class="line"><span class="number">0</span>            Mary   F    <span class="number">7065</span>  <span class="number">1880</span>  <span class="number">0.077643</span></span><br><span class="line"><span class="number">1</span>            Anna   F    <span class="number">2604</span>  <span class="number">1880</span>  <span class="number">0.028618</span></span><br><span class="line"><span class="number">2</span>            Emma   F    <span class="number">2003</span>  <span class="number">1880</span>  <span class="number">0.022013</span></span><br><span class="line"><span class="number">3</span>       Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span>  <span class="number">0.021309</span></span><br><span class="line"><span class="number">4</span>          Minnie   F    <span class="number">1746</span>  <span class="number">1880</span>  <span class="number">0.019188</span></span><br><span class="line"><span class="meta">... </span>          ...  ..     ...   ...       ...</span><br><span class="line"><span class="number">261872</span>     Camilo   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261873</span>     Destin   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261874</span>     Jaquan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261875</span>     Jaydan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261876</span>     Maxton   M     <span class="number">193</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line">[<span class="number">261877</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>接下来的数据分析工作就针对这个top1000数据集了。</p>
<h2><span id="分析命名趋势">分析命名趋势</span></h2><p>有了完整的数据集和刚才生成的top1000数据集，我们就可以开始分析各种命名趋势了。首先将前1000个名字分为男女两个部分：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">109</span>]: boys = top1000[top1000.sex == <span class="string">&#x27;M&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: girls = top1000[top1000.sex == <span class="string">&#x27;F&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>这是两个简单的时间序列，只需稍作整理即可绘制出相应的图表（比如每年叫做John和Mary的婴儿数）。我们先生成一张按year和name统计的总出生数透视表：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">111</span>]: total_births = top1000.pivot_table(<span class="string">&#x27;births&#x27;</span>, index=<span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">   .....:                                    columns=<span class="string">&#x27;name&#x27;</span>,</span><br><span class="line">   .....:                                    aggfunc=<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在，我们用DataFrame的plot方法绘制几个名字的曲线图（见图14-5）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">112</span>]: total_births.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">Int64Index</span>:</span> <span class="number">131</span> entries, <span class="number">1880</span> to <span class="number">2010</span></span><br><span class="line">Columns: <span class="number">6868</span> entries, Aaden to Zuri</span><br><span class="line">dtypes: float64(<span class="number">6868</span>)</span><br><span class="line">memory usage: <span class="number">6.9</span> MB</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: subset = total_births[[<span class="string">&#x27;John&#x27;</span>, <span class="string">&#x27;Harry&#x27;</span>, <span class="string">&#x27;Mary&#x27;</span>, <span class="string">&#x27;Marilyn&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: subset.plot(subplots=<span class="literal">True</span>, figsize=(<span class="number">12</span>, <span class="number">10</span>), grid=<span class="literal">False</span>,</span><br><span class="line">   .....:             title=<span class="string">&quot;Number of births per year&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-33f0f97656367a53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-5 几个男孩和女孩名字随时间变化的使用数量"></p>
<p>从图中可以看出，这几个名字在美国人民的心目中已经风光不再了。但事实并非如此简单，我们在下一节中就能知道是怎么一回事了。</p>
<h2><span id="评估命名多样性的增长">评估命名多样性的增长</span></h2><p>一种解释是父母愿意给小孩起常见的名字越来越少。这个假设可以从数据中得到验证。一个办法是计算最流行的1000个名字所占的比例，我按year和sex进行聚合并绘图（见图14-6）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">116</span>]: table = top1000.pivot_table(<span class="string">&#x27;prop&#x27;</span>, index=<span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">   .....:                             columns=<span class="string">&#x27;sex&#x27;</span>, aggfunc=<span class="built_in">sum</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">117</span>]: table.plot(title=<span class="string">&#x27;Sum of table1000.prop by year and sex&#x27;</span>,</span><br><span class="line">   .....:            yticks=np.linspace(<span class="number">0</span>, <span class="number">1.2</span>, <span class="number">13</span>), xticks=<span class="built_in">range</span>(<span class="number">1880</span>, <span class="number">2020</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-63e1ddc326a033b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-6 分性别统计的前1000个名字在总出生人数中的比例"></p>
<p>从图中可以看出，名字的多样性确实出现了增长（前1000项的比例降低）。另一个办法是计算占总出生人数前50%的不同名字的数量，这个数字不太好计算。我们只考虑2010年男孩的名字：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">118</span>]: df = boys[boys.year == <span class="number">2010</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: df</span><br><span class="line">Out[<span class="number">119</span>]: </span><br><span class="line">           name sex  births  year      prop</span><br><span class="line"><span class="number">260877</span>    Jacob   M   <span class="number">21875</span>  <span class="number">2010</span>  <span class="number">0.011523</span></span><br><span class="line"><span class="number">260878</span>    Ethan   M   <span class="number">17866</span>  <span class="number">2010</span>  <span class="number">0.009411</span></span><br><span class="line"><span class="number">260879</span>  Michael   M   <span class="number">17133</span>  <span class="number">2010</span>  <span class="number">0.009025</span></span><br><span class="line"><span class="number">260880</span>   Jayden   M   <span class="number">17030</span>  <span class="number">2010</span>  <span class="number">0.008971</span></span><br><span class="line"><span class="number">260881</span>  William   M   <span class="number">16870</span>  <span class="number">2010</span>  <span class="number">0.008887</span></span><br><span class="line"><span class="meta">... </span>        ...  ..     ...   ...       ...</span><br><span class="line"><span class="number">261872</span>   Camilo   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261873</span>   Destin   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261874</span>   Jaquan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261875</span>   Jaydan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261876</span>   Maxton   M     <span class="number">193</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line">[<span class="number">1000</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>在对prop降序排列之后，我们想知道前面多少个名字的人数加起来才够50%。虽然编写一个for循环确实也能达到目的，但NumPy有一种更聪明的矢量方式。先计算prop的累计和cumsum，然后再通过searchsorted方法找出0.5应该被插入在哪个位置才能保证不破坏顺序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">120</span>]: prop_cumsum = df.sort_values(by=<span class="string">&#x27;prop&#x27;</span>, ascending=<span class="literal">False</span>).prop.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: prop_cumsum[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line"><span class="number">260877</span>    <span class="number">0.011523</span></span><br><span class="line"><span class="number">260878</span>    <span class="number">0.020934</span></span><br><span class="line"><span class="number">260879</span>    <span class="number">0.029959</span></span><br><span class="line"><span class="number">260880</span>    <span class="number">0.038930</span></span><br><span class="line"><span class="number">260881</span>    <span class="number">0.047817</span></span><br><span class="line"><span class="number">260882</span>    <span class="number">0.056579</span></span><br><span class="line"><span class="number">260883</span>    <span class="number">0.065155</span></span><br><span class="line"><span class="number">260884</span>    <span class="number">0.073414</span></span><br><span class="line"><span class="number">260885</span>    <span class="number">0.081528</span></span><br><span class="line"><span class="number">260886</span>    <span class="number">0.089621</span></span><br><span class="line">Name: prop, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: prop_cumsum.values.searchsorted(<span class="number">0.5</span>)</span><br><span class="line">Out[<span class="number">122</span>]: <span class="number">116</span></span><br></pre></td></tr></table></figure></p>
<p>由于数组索引是从0开始的，因此我们要给这个结果加1，即最终结果为117。拿1900年的数据来做个比较，这个数字要小得多：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">123</span>]: df = boys[boys.year == <span class="number">1900</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: in1900 = df.sort_values(by=<span class="string">&#x27;prop&#x27;</span>, ascending=<span class="literal">False</span>).prop.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: in1900.values.searchsorted(<span class="number">0.5</span>) + <span class="number">1</span></span><br><span class="line">Out[<span class="number">125</span>]: <span class="number">25</span></span><br></pre></td></tr></table></figure></p>
<p>现在就可以对所有year/sex组合执行这个计算了。按这两个字段进行groupby处理，然后用一个函数计算各分组的这个值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_quantile_count</span>(<span class="params">group, q=<span class="number">0.5</span></span>):</span></span><br><span class="line">    group = group.sort_values(by=<span class="string">&#x27;prop&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> group.prop.cumsum().values.searchsorted(q) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">diversity = top1000.groupby([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>]).apply(get_quantile_count)</span><br><span class="line">diversity = diversity.unstack(<span class="string">&#x27;sex&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在，diversity这个DataFrame拥有两个时间序列（每个性别各一个，按年度索引）。通过IPython，你可以查看其内容，还可以像之前那样绘制图表（如图14-7所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">128</span>]: diversity.head()</span><br><span class="line">Out[<span class="number">128</span>]: </span><br><span class="line">sex    F   M</span><br><span class="line">year        </span><br><span class="line"><span class="number">1880</span>  <span class="number">38</span>  <span class="number">14</span></span><br><span class="line"><span class="number">1881</span>  <span class="number">38</span>  <span class="number">14</span></span><br><span class="line"><span class="number">1882</span>  <span class="number">38</span>  <span class="number">15</span></span><br><span class="line"><span class="number">1883</span>  <span class="number">39</span>  <span class="number">15</span></span><br><span class="line"><span class="number">1884</span>  <span class="number">39</span>  <span class="number">16</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: diversity.plot(title=<span class="string">&quot;Number of popular names in top 50%&quot;</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-574b53a383cad681.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-7 按年度统计的密度表"></p>
<p>从图中可以看出，女孩名字的多样性总是比男孩的高，而且还在变得越来越高。读者们可以自己分析一下具体是什么在驱动这个多样性（比如拼写形式的变化）。</p>
<h2><span id="最后一个字母的变革">“最后一个字母”的变革</span></h2><p>2007年，一名婴儿姓名研究人员Laura Wattenberg在她自己的网站上指出（<a href="http://www.babynamewizard.com）：近百年来，男孩名字在最后一个字母上的分布发生了显著的变化。为了了解具体的情况，我首先将全部出生数据在年度、性别以及末字母上进行了聚合：">http://www.babynamewizard.com）：近百年来，男孩名字在最后一个字母上的分布发生了显著的变化。为了了解具体的情况，我首先将全部出生数据在年度、性别以及末字母上进行了聚合：</a><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># extract last letter from name column</span></span><br><span class="line">get_last_letter = <span class="keyword">lambda</span> x: x[-<span class="number">1</span>]</span><br><span class="line">last_letters = names.name.<span class="built_in">map</span>(get_last_letter)</span><br><span class="line">last_letters.name = <span class="string">&#x27;last_letter&#x27;</span></span><br><span class="line"></span><br><span class="line">table = names.pivot_table(<span class="string">&#x27;births&#x27;</span>, index=last_letters,</span><br><span class="line">                          columns=[<span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;year&#x27;</span>], aggfunc=<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure></p>
<p>然后，我选出具有一定代表性的三年，并输出前面几行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">131</span>]: subtable = table.reindex(columns=[<span class="number">1910</span>, <span class="number">1960</span>, <span class="number">2010</span>], level=<span class="string">&#x27;year&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: subtable.head()</span><br><span class="line">Out[<span class="number">132</span>]: </span><br><span class="line">sex                 F                            M                    </span><br><span class="line">year             <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span>     <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span></span><br><span class="line">last_letter                                                           </span><br><span class="line">a            <span class="number">108376.0</span>  <span class="number">691247.0</span>  <span class="number">670605.0</span>    <span class="number">977.0</span>    <span class="number">5204.0</span>   <span class="number">28438.0</span></span><br><span class="line">b                 NaN     <span class="number">694.0</span>     <span class="number">450.0</span>    <span class="number">411.0</span>    <span class="number">3912.0</span>   <span class="number">38859.0</span></span><br><span class="line">c                 <span class="number">5.0</span>      <span class="number">49.0</span>     <span class="number">946.0</span>    <span class="number">482.0</span>   <span class="number">15476.0</span>   <span class="number">23125.0</span></span><br><span class="line">d              <span class="number">6750.0</span>    <span class="number">3729.0</span>    <span class="number">2607.0</span>  <span class="number">22111.0</span>  <span class="number">262112.0</span>   <span class="number">44398.0</span></span><br><span class="line">e            <span class="number">133569.0</span>  <span class="number">435013.0</span>  <span class="number">313833.0</span>  <span class="number">28655.0</span>  <span class="number">178823.0</span>  <span class="number">129012.0</span></span><br></pre></td></tr></table></figure></p>
<p>接下来我们需要按总出生数对该表进行规范化处理，以便计算出各性别各末字母占总出生人数的比例：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">133</span>]: subtable.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">sex  year</span><br><span class="line">F    <span class="number">1910</span>     <span class="number">396416.0</span></span><br><span class="line">     <span class="number">1960</span>    <span class="number">2022062.0</span></span><br><span class="line">     <span class="number">2010</span>    <span class="number">1759010.0</span></span><br><span class="line">M    <span class="number">1910</span>     <span class="number">194198.0</span></span><br><span class="line">     <span class="number">1960</span>    <span class="number">2132588.0</span></span><br><span class="line"><span class="number">2010</span>    <span class="number">1898382.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: letter_prop = subtable / subtable.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">In [<span class="number">135</span>]: letter_prop</span><br><span class="line">Out[<span class="number">135</span>]: </span><br><span class="line">sex                 F                             M                    </span><br><span class="line">year             <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span>      <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span></span><br><span class="line">last_letter                                                            </span><br><span class="line">a            <span class="number">0.273390</span>  <span class="number">0.341853</span>  <span class="number">0.381240</span>  <span class="number">0.005031</span>  <span class="number">0.002440</span>  <span class="number">0.014980</span></span><br><span class="line">b                 NaN  <span class="number">0.000343</span>  <span class="number">0.000256</span>  <span class="number">0.002116</span>  <span class="number">0.001834</span>  <span class="number">0.020470</span></span><br><span class="line">c            <span class="number">0.000013</span>  <span class="number">0.000024</span>  <span class="number">0.000538</span>  <span class="number">0.002482</span>  <span class="number">0.007257</span>  <span class="number">0.012181</span></span><br><span class="line">d            <span class="number">0.017028</span>  <span class="number">0.001844</span>  <span class="number">0.001482</span>  <span class="number">0.113858</span>  <span class="number">0.122908</span>  <span class="number">0.023387</span></span><br><span class="line">e            <span class="number">0.336941</span>  <span class="number">0.215133</span>  <span class="number">0.178415</span>  <span class="number">0.147556</span>  <span class="number">0.083853</span>  <span class="number">0.067959</span></span><br><span class="line"><span class="meta">... </span>              ...       ...       ...       ...       ...       ...</span><br><span class="line">v                 NaN  <span class="number">0.000060</span>  <span class="number">0.000117</span>  <span class="number">0.000113</span></span><br><span class="line"><span class="number">0.000037</span>  <span class="number">0.001434</span></span><br><span class="line">w            <span class="number">0.000020</span>  <span class="number">0.000031</span>  <span class="number">0.001182</span>  <span class="number">0.006329</span>  <span class="number">0.007711</span>  <span class="number">0.016148</span></span><br><span class="line">x            <span class="number">0.000015</span>  <span class="number">0.000037</span>  <span class="number">0.000727</span>  <span class="number">0.003965</span>  <span class="number">0.001851</span>  <span class="number">0.008614</span></span><br><span class="line">y            <span class="number">0.110972</span>  <span class="number">0.152569</span>  <span class="number">0.116828</span>  <span class="number">0.077349</span>  <span class="number">0.160987</span>  <span class="number">0.058168</span></span><br><span class="line">z            <span class="number">0.002439</span>  <span class="number">0.000659</span>  <span class="number">0.000704</span>  <span class="number">0.000170</span>  <span class="number">0.000184</span>  <span class="number">0.001831</span></span><br><span class="line">[<span class="number">26</span> rows x <span class="number">6</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>有了这个字母比例数据之后，就可以生成一张各年度各性别的条形图了，如图14-8所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">letter_prop[<span class="string">&#x27;M&#x27;</span>].plot(kind=<span class="string">&#x27;bar&#x27;</span>, rot=<span class="number">0</span>, ax=axes[<span class="number">0</span>], title=<span class="string">&#x27;Male&#x27;</span>)</span><br><span class="line">letter_prop[<span class="string">&#x27;F&#x27;</span>].plot(kind=<span class="string">&#x27;bar&#x27;</span>, rot=<span class="number">0</span>, ax=axes[<span class="number">1</span>], title=<span class="string">&#x27;Female&#x27;</span>,</span><br><span class="line">                      legend=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-67686f38e66ef5f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-8 男孩女孩名字中各个末字母的比例"></p>
<p>可以看出，从20世纪60年代开始，以字母”n”结尾的男孩名字出现了显著的增长。回到之前创建的那个完整表，按年度和性别对其进行规范化处理，并在男孩名字中选取几个字母，最后进行转置以便将各个列做成一个时间序列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">138</span>]: letter_prop = table / table.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">In [<span class="number">139</span>]: dny_ts = letter_prop.loc[[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;y&#x27;</span>], <span class="string">&#x27;M&#x27;</span>].T</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: dny_ts.head()</span><br><span class="line">Out[<span class="number">140</span>]: </span><br><span class="line">last_letter         d         n         y</span><br><span class="line">year                                     </span><br><span class="line"><span class="number">1880</span>         <span class="number">0.083055</span>  <span class="number">0.153213</span>  <span class="number">0.075760</span></span><br><span class="line"><span class="number">1881</span>         <span class="number">0.083247</span>  <span class="number">0.153214</span>  <span class="number">0.077451</span></span><br><span class="line"><span class="number">1882</span>         <span class="number">0.085340</span>  <span class="number">0.149560</span>  <span class="number">0.077537</span></span><br><span class="line"><span class="number">1883</span>         <span class="number">0.084066</span>  <span class="number">0.151646</span>  <span class="number">0.079144</span></span><br><span class="line"><span class="number">1884</span>         <span class="number">0.086120</span>  <span class="number">0.149915</span>  <span class="number">0.080405</span></span><br></pre></td></tr></table></figure></p>
<p>有了这个时间序列的DataFrame之后，就可以通过其plot方法绘制出一张趋势图了（如图14-9所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">143</span>]: dny_ts.plot()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-51c431b2490424c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-9 各年出生的男孩中名字以d/n/y结尾的人数比例"></p>
<h2><span id="变成女孩名字的男孩名字以及相反的情况">变成女孩名字的男孩名字（以及相反的情况）</span></h2><p>另一个有趣的趋势是，早年流行于男孩的名字近年来“变性了”，例如Lesley或Leslie。回到top1000数据集，找出其中以”lesl”开头的一组名字：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">144</span>]: all_names = pd.Series(top1000.name.unique())</span><br><span class="line"></span><br><span class="line">In [<span class="number">145</span>]: lesley_like = all_names[all_names.<span class="built_in">str</span>.lower().<span class="built_in">str</span>.contains(<span class="string">&#x27;lesl&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">146</span>]: lesley_like</span><br><span class="line">Out[<span class="number">146</span>]: </span><br><span class="line"><span class="number">632</span>     Leslie</span><br><span class="line"><span class="number">2294</span>    Lesley</span><br><span class="line"><span class="number">4262</span>    Leslee</span><br><span class="line"><span class="number">4728</span>     Lesli</span><br><span class="line"><span class="number">6103</span>     Lesly</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure>
<p>然后利用这个结果过滤其他的名字，并按名字分组计算出生数以查看相对频率：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">147</span>]: filtered = top1000[top1000.name.isin(lesley_like)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: filtered.groupby(<span class="string">&#x27;name&#x27;</span>).births.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">148</span>]: </span><br><span class="line">name</span><br><span class="line">Leslee      <span class="number">1082</span></span><br><span class="line">Lesley     <span class="number">35022</span></span><br><span class="line">Lesli        <span class="number">929</span></span><br><span class="line">Leslie    <span class="number">370429</span></span><br><span class="line">Lesly      <span class="number">10067</span></span><br><span class="line">Name: births, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>接下来，我们按性别和年度进行聚合，并按年度进行规范化处理：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">149</span>]: table = filtered.pivot_table(<span class="string">&#x27;births&#x27;</span>, index=<span class="string">&#x27;year&#x27;</span>,</span><br><span class="line">   .....:                              columns=<span class="string">&#x27;sex&#x27;</span>, aggfunc=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">150</span>]: table = table.div(table.<span class="built_in">sum</span>(<span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">151</span>]: table.tail()</span><br><span class="line">Out[<span class="number">151</span>]: </span><br><span class="line">sex     F   M</span><br><span class="line">year         </span><br><span class="line"><span class="number">2006</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2007</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2008</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2009</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2010</span>  <span class="number">1.0</span> NaN</span><br></pre></td></tr></table></figure></p>
<p>最后，就可以轻松绘制一张分性别的年度曲线图了（如图2-10所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">153</span>]: table.plot(style=&#123;<span class="string">&#x27;M&#x27;</span>: <span class="string">&#x27;k-&#x27;</span>, <span class="string">&#x27;F&#x27;</span>: <span class="string">&#x27;k--&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-b99d98f8bb5fc695.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-10 各年度使用“Lesley型”名字的男女比例"></p>
<h1><span id="144-usda食品数据库">14.4 USDA食品数据库</span></h1><p>美国农业部（USDA）制作了一份有关食物营养信息的数据库。Ashley Williams制作了该数据的JSON版（<a href="http://ashleyw.co.uk/project/food-nutrient-database）。其中的记录如下所示：">http://ashleyw.co.uk/project/food-nutrient-database）。其中的记录如下所示：</a><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;id&quot;</span>: <span class="number">21441</span>,</span><br><span class="line">  <span class="string">&quot;description&quot;</span>: <span class="string">&quot;KENTUCKY FRIED CHICKEN, Fried Chicken, EXTRA CRISPY,</span></span><br><span class="line"><span class="string">Wing, meat and skin with breading&quot;</span>,</span><br><span class="line">  <span class="string">&quot;tags&quot;</span>: [<span class="string">&quot;KFC&quot;</span>],</span><br><span class="line">  <span class="string">&quot;manufacturer&quot;</span>: <span class="string">&quot;Kentucky Fried Chicken&quot;</span>,</span><br><span class="line"><span class="string">&quot;group&quot;</span>: <span class="string">&quot;Fast Foods&quot;</span>,</span><br><span class="line">  <span class="string">&quot;portions&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;amount&quot;</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="string">&quot;unit&quot;</span>: <span class="string">&quot;wing, with skin&quot;</span>,</span><br><span class="line">      <span class="string">&quot;grams&quot;</span>: <span class="number">68.0</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;nutrients&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;value&quot;</span>: <span class="number">20.8</span>,</span><br><span class="line">      <span class="string">&quot;units&quot;</span>: <span class="string">&quot;g&quot;</span>,</span><br><span class="line">      <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Protein&quot;</span>,</span><br><span class="line">      <span class="string">&quot;group&quot;</span>: <span class="string">&quot;Composition&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>每种食物都带有若干标识性属性以及两个有关营养成分和分量的列表。这种形式的数据不是很适合分析工作，因此我们需要做一些规整化以使其具有更好用的形式。</p>
<p>从上面列举的那个网址下载并解压数据之后，你可以用任何喜欢的JSON库将其加载到Python中。我用的是Python内置的json模块：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">154</span>]: <span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">In [<span class="number">155</span>]: db = json.load(<span class="built_in">open</span>(<span class="string">&#x27;datasets/usda_food/database.json&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">156</span>]: <span class="built_in">len</span>(db)</span><br><span class="line">Out[<span class="number">156</span>]: <span class="number">6636</span></span><br></pre></td></tr></table></figure></p>
<p>db中的每个条目都是一个含有某种食物全部数据的字典。nutrients字段是一个字典列表，其中的每个字典对应一种营养成分：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">157</span>]: db[<span class="number">0</span>].keys()</span><br><span class="line">Out[<span class="number">157</span>]: dict_keys([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;description&#x27;</span>, <span class="string">&#x27;tags&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>, <span class="string">&#x27;group&#x27;</span>, <span class="string">&#x27;porti</span></span><br><span class="line"><span class="string">ons&#x27;</span>, <span class="string">&#x27;nutrients&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">158</span>]: db[<span class="number">0</span>][<span class="string">&#x27;nutrients&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">158</span>]: </span><br><span class="line">&#123;<span class="string">&#x27;description&#x27;</span>: <span class="string">&#x27;Protein&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;group&#x27;</span>: <span class="string">&#x27;Composition&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;units&#x27;</span>: <span class="string">&#x27;g&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;value&#x27;</span>: <span class="number">25.18</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">159</span>]: nutrients = pd.DataFrame(db[<span class="number">0</span>][<span class="string">&#x27;nutrients&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">160</span>]: nutrients[:<span class="number">7</span>]</span><br><span class="line">Out[<span class="number">160</span>]: </span><br><span class="line">                   description        group units    value</span><br><span class="line"><span class="number">0</span>                      Protein  Composition     g    <span class="number">25.18</span></span><br><span class="line"><span class="number">1</span>            Total lipid (fat)  Composition     g    <span class="number">29.20</span></span><br><span class="line"><span class="number">2</span>  Carbohydrate, by difference  Composition     g     <span class="number">3.06</span></span><br><span class="line"><span class="number">3</span>                          Ash        Other     g     <span class="number">3.28</span></span><br><span class="line"><span class="number">4</span>                       Energy       Energy  kcal   <span class="number">376.00</span></span><br><span class="line"><span class="number">5</span>                        Water  Composition     g    <span class="number">39.28</span></span><br><span class="line"><span class="number">6</span>                       Energy       Energy    kJ  <span class="number">1573.00</span></span><br></pre></td></tr></table></figure></p>
<p>在将字典列表转换为DataFrame时，可以只抽取其中的一部分字段。这里，我们将取出食物的名称、分类、编号以及制造商等信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">161</span>]: info_keys = [<span class="string">&#x27;description&#x27;</span>, <span class="string">&#x27;group&#x27;</span>, <span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: info = pd.DataFrame(db, columns=info_keys)</span><br><span class="line"></span><br><span class="line">In [<span class="number">163</span>]: info[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">163</span>]: </span><br><span class="line">                          description                   group    <span class="built_in">id</span>  \</span><br><span class="line"><span class="number">0</span>                     Cheese, caraway  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1008</span>   </span><br><span class="line"><span class="number">1</span>                     Cheese, cheddar  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1009</span></span><br><span class="line"><span class="number">2</span>                        Cheese, edam  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1018</span>   </span><br><span class="line"><span class="number">3</span>                        Cheese, feta  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1019</span>   </span><br><span class="line"><span class="number">4</span>  Cheese, mozzarella, part skim milk  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1028</span>   </span><br><span class="line">  manufacturer  </span><br><span class="line"><span class="number">0</span>               </span><br><span class="line"><span class="number">1</span>               </span><br><span class="line"><span class="number">2</span>               </span><br><span class="line"><span class="number">3</span>               </span><br><span class="line"><span class="number">4</span>               </span><br><span class="line"></span><br><span class="line">In [<span class="number">164</span>]: info.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">6636</span> entries, <span class="number">0</span> to <span class="number">6635</span></span><br><span class="line">Data columns (total <span class="number">4</span> columns):</span><br><span class="line">description     <span class="number">6636</span> non-null <span class="built_in">object</span></span><br><span class="line">group           <span class="number">6636</span> non-null <span class="built_in">object</span></span><br><span class="line"><span class="built_in">id</span>              <span class="number">6636</span> non-null int64</span><br><span class="line">manufacturer    <span class="number">5195</span> non-null <span class="built_in">object</span></span><br><span class="line">dtypes: int64(<span class="number">1</span>), <span class="built_in">object</span>(<span class="number">3</span>)</span><br><span class="line">memory usage: <span class="number">207.5</span>+ KB</span><br></pre></td></tr></table></figure>
<p>通过value_counts，你可以查看食物类别的分布情况：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">165</span>]: pd.value_counts(info.group)[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">165</span>]: </span><br><span class="line">Vegetables <span class="keyword">and</span> Vegetable Products    <span class="number">812</span></span><br><span class="line">Beef Products                        <span class="number">618</span></span><br><span class="line">Baked Products                       <span class="number">496</span></span><br><span class="line">Breakfast Cereals                    <span class="number">403</span></span><br><span class="line">Fast Foods                           <span class="number">365</span></span><br><span class="line">Legumes <span class="keyword">and</span> Legume Products          <span class="number">365</span></span><br><span class="line">Lamb, Veal, <span class="keyword">and</span> Game Products        <span class="number">345</span></span><br><span class="line">Sweets                               <span class="number">341</span></span><br><span class="line">Pork Products                        <span class="number">328</span></span><br><span class="line">Fruits <span class="keyword">and</span> Fruit Juices              <span class="number">328</span></span><br><span class="line">Name: group, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>现在，为了对全部营养数据做一些分析，最简单的办法是将所有食物的营养成分整合到一个大表中。我们分几个步骤来实现该目的。首先，将各食物的营养成分列表转换为一个DataFrame，并添加一个表示编号的列，然后将该DataFrame添加到一个列表中。最后通过concat将这些东西连接起来就可以了：</p>
<p>顺利的话，nutrients的结果是：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">167</span>]: nutrients</span><br><span class="line">Out[<span class="number">167</span>]: </span><br><span class="line">                               description        group units    value     <span class="built_in">id</span></span><br><span class="line"><span class="number">0</span>                                  Protein  Composition     g   <span class="number">25.180</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">1</span>                        Total lipid (fat)  Composition     g   <span class="number">29.200</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">2</span>              Carbohydrate, by difference  Composition     g    <span class="number">3.060</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">3</span>                                      Ash        Other     g    <span class="number">3.280</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">4</span>                                   Energy       Energy  kcal  <span class="number">376.000</span>   <span class="number">1008</span></span><br><span class="line"><span class="meta">... </span>                                   ...          ...</span><br><span class="line"><span class="meta">... </span>     ...    ...</span><br><span class="line"><span class="number">389350</span>                 Vitamin B-<span class="number">12</span>, added     Vitamins   mcg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389351</span>                         Cholesterol        Other    mg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389352</span>        Fatty acids, total saturated        Other     g    <span class="number">0.072</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389353</span>  Fatty acids, total monounsaturated        Other     g    <span class="number">0.028</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389354</span>  Fatty acids, total polyunsaturated        Other     g    <span class="number">0.041</span>  <span class="number">43546</span></span><br><span class="line">[<span class="number">389355</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>我发现这个DataFrame中无论如何都会有一些重复项，所以直接丢弃就可以了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">168</span>]: nutrients.duplicated().<span class="built_in">sum</span>()  <span class="comment"># number of duplicates</span></span><br><span class="line">Out[<span class="number">168</span>]: <span class="number">14179</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: nutrients = nutrients.drop_duplicates()</span><br></pre></td></tr></table></figure></p>
<p>由于两个DataFrame对象中都有”group”和”description”，所以为了明确到底谁是谁，我们需要对它们进行重命名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">170</span>]: col_mapping = &#123;<span class="string">&#x27;description&#x27;</span> : <span class="string">&#x27;food&#x27;</span>,</span><br><span class="line">   .....:                <span class="string">&#x27;group&#x27;</span>       : <span class="string">&#x27;fgroup&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">171</span>]: info = info.rename(columns=col_mapping, copy=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">172</span>]: info.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">6636</span> entries, <span class="number">0</span> to <span class="number">6635</span></span><br><span class="line">Data columns (total <span class="number">4</span> columns):</span><br><span class="line">food            <span class="number">6636</span> non-null <span class="built_in">object</span></span><br><span class="line">fgroup          <span class="number">6636</span> non-null <span class="built_in">object</span></span><br><span class="line"><span class="built_in">id</span>              <span class="number">6636</span> non-null int64</span><br><span class="line">manufacturer    <span class="number">5195</span> non-null <span class="built_in">object</span></span><br><span class="line">dtypes: int64(<span class="number">1</span>), <span class="built_in">object</span>(<span class="number">3</span>)</span><br><span class="line">memory usage: <span class="number">207.5</span>+ KB</span><br><span class="line"></span><br><span class="line">In [<span class="number">173</span>]: col_mapping = &#123;<span class="string">&#x27;description&#x27;</span> : <span class="string">&#x27;nutrient&#x27;</span>,</span><br><span class="line">   .....:                <span class="string">&#x27;group&#x27;</span> : <span class="string">&#x27;nutgroup&#x27;</span>&#125;</span><br><span class="line">In [<span class="number">174</span>]: nutrients = nutrients.rename(columns=col_mapping, copy=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">175</span>]: nutrients</span><br><span class="line">Out[<span class="number">175</span>]: </span><br><span class="line">                                  nutrient     nutgroup units    value     <span class="built_in">id</span></span><br><span class="line"><span class="number">0</span>                                  Protein  Composition     g   <span class="number">25.180</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">1</span>                        Total lipid (fat)  Composition     g   <span class="number">29.200</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">2</span>              Carbohydrate, by difference  Composition     g    <span class="number">3.060</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">3</span>                                      Ash        Other     g    <span class="number">3.280</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">4</span>                                   Energy       Energy  kcal  <span class="number">376.000</span>   <span class="number">1008</span></span><br><span class="line"><span class="meta">... </span>                                   ...          ...   ...      ...    ...</span><br><span class="line"><span class="number">389350</span>                 Vitamin B-<span class="number">12</span>, added     Vitamins   mcg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389351</span>                         Cholesterol        Other    mg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389352</span>        Fatty acids, total saturated        Other     g    <span class="number">0.072</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389353</span>  Fatty acids, total monounsaturated        Other     g    <span class="number">0.028</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389354</span>  Fatty acids, total polyunsaturated        Other     g    <span class="number">0.041</span>  <span class="number">43546</span></span><br><span class="line">[<span class="number">375176</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>做完这些，就可以将info跟nutrients合并起来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">176</span>]: ndata = pd.merge(nutrients, info, on=<span class="string">&#x27;id&#x27;</span>, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">177</span>]: ndata.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">Int64Index</span>:</span> <span class="number">375176</span> entries, <span class="number">0</span> to <span class="number">375175</span></span><br><span class="line">Data columns (total <span class="number">8</span> columns):</span><br><span class="line">nutrient        <span class="number">375176</span> non-null <span class="built_in">object</span></span><br><span class="line">nutgroup        <span class="number">375176</span> non-null <span class="built_in">object</span></span><br><span class="line">units           <span class="number">375176</span> non-null <span class="built_in">object</span></span><br><span class="line">value           <span class="number">375176</span> non-null float64</span><br><span class="line"><span class="built_in">id</span>              <span class="number">375176</span> non-null int64</span><br><span class="line">food            <span class="number">375176</span> non-null <span class="built_in">object</span></span><br><span class="line">fgroup          <span class="number">375176</span> non-null <span class="built_in">object</span></span><br><span class="line">manufacturer    <span class="number">293054</span> non-null <span class="built_in">object</span></span><br><span class="line">dtypes: float64(<span class="number">1</span>), int64(<span class="number">1</span>), <span class="built_in">object</span>(<span class="number">6</span>)</span><br><span class="line">memory usage: <span class="number">25.8</span>+ MB</span><br><span class="line"></span><br><span class="line">In [<span class="number">178</span>]: ndata.iloc[<span class="number">30000</span>]</span><br><span class="line">Out[<span class="number">178</span>]: </span><br><span class="line">nutrient                                       Glycine</span><br><span class="line">nutgroup                                   Amino Acids</span><br><span class="line">units                                                g</span><br><span class="line">value                                             <span class="number">0.04</span></span><br><span class="line"><span class="built_in">id</span>                                                <span class="number">6158</span></span><br><span class="line">food            Soup, tomato bisque, canned, condensed</span><br><span class="line">fgroup                      Soups, Sauces, <span class="keyword">and</span> Gravies</span><br><span class="line">manufacturer                                          </span><br><span class="line">Name: <span class="number">30000</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>我们现在可以根据食物分类和营养类型画出一张中位值图（如图14-11所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">180</span>]: result = ndata.groupby([<span class="string">&#x27;nutrient&#x27;</span>, <span class="string">&#x27;fgroup&#x27;</span>])[<span class="string">&#x27;value&#x27;</span>].quantile(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">181</span>]: result[<span class="string">&#x27;Zinc, Zn&#x27;</span>].sort_values().plot(kind=<span class="string">&#x27;barh&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-99b176d022a444c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片14-11 根据营养分类得出的锌中位值"></p>
<p>只要稍微动一动脑子，就可以发现各营养成分最为丰富的食物是什么了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">by_nutrient = ndata.groupby([<span class="string">&#x27;nutgroup&#x27;</span>, <span class="string">&#x27;nutrient&#x27;</span>])</span><br><span class="line"></span><br><span class="line">get_maximum = <span class="keyword">lambda</span> x: x.loc[x.value.idxmax()]</span><br><span class="line">get_minimum = <span class="keyword">lambda</span> x: x.loc[x.value.idxmin()]</span><br><span class="line"></span><br><span class="line">max_foods = by_nutrient.apply(get_maximum)[[<span class="string">&#x27;value&#x27;</span>, <span class="string">&#x27;food&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># make the food a little smaller</span></span><br><span class="line">max_foods.food = max_foods.food.<span class="built_in">str</span>[:<span class="number">50</span>]</span><br></pre></td></tr></table></figure></p>
<p>由于得到的DataFrame很大，所以不方便在书里面全部打印出来。这里只给出”Amino Acids”营养分组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">183</span>]: max_foods.loc[<span class="string">&#x27;Amino Acids&#x27;</span>][<span class="string">&#x27;food&#x27;</span>]</span><br><span class="line">Out[<span class="number">183</span>]: </span><br><span class="line">nutrient</span><br><span class="line">Alanine                          Gelatins, dry powder, unsweetened</span><br><span class="line">Arginine                              Seeds, sesame flour, low-fat</span><br><span class="line">Aspartic acid                                  Soy protein isolate</span><br><span class="line">Cystine               Seeds, cottonseed flour, low fat (glandless)</span><br><span class="line">Glutamic acid                                  Soy protein isolate</span><br><span class="line">                                       ...                        </span><br><span class="line">Serine           Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Threonine        Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Tryptophan        Sea lion, Steller, meat <span class="keyword">with</span> fat (Alaska Native)</span><br><span class="line">Tyrosine         Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Valine           Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Name: food, Length: <span class="number">19</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="145-2012联邦选举委员会数据库">14.5 2012联邦选举委员会数据库</span></h1><p>美国联邦选举委员会发布了有关政治竞选赞助方面的数据。其中包括赞助者的姓名、职业、雇主、地址以及出资额等信息。我们对2012年美国总统大选的数据集比较感兴趣（<a href="http://www.fec.gov/disclosurep/PDownload.do）。我在2012年6月下载的数据集是一个150MB的CSV文件（P00000001-ALL.csv），我们先用pandas.read_csv将其加载进来：">http://www.fec.gov/disclosurep/PDownload.do）。我在2012年6月下载的数据集是一个150MB的CSV文件（P00000001-ALL.csv），我们先用pandas.read_csv将其加载进来：</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">184</span>]: fec = pd.read_csv(<span class="string">&#x27;datasets/fec/P00000001-ALL.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">185</span>]: fec.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">1001731</span> entries, <span class="number">0</span> to <span class="number">1001730</span></span><br><span class="line">Data columns (total <span class="number">16</span> columns):</span><br><span class="line">cmte_id              <span class="number">1001731</span> non-null <span class="built_in">object</span></span><br><span class="line">cand_id              <span class="number">1001731</span> non-null <span class="built_in">object</span></span><br><span class="line">cand_nm              <span class="number">1001731</span> non-null <span class="built_in">object</span></span><br><span class="line">contbr_nm            <span class="number">1001731</span> non-null <span class="built_in">object</span></span><br><span class="line">contbr_city          <span class="number">1001712</span> non-null <span class="built_in">object</span></span><br><span class="line">contbr_st            <span class="number">1001727</span> non-null <span class="built_in">object</span></span><br><span class="line">contbr_zip           <span class="number">1001620</span> non-null <span class="built_in">object</span></span><br><span class="line">contbr_employer      <span class="number">988002</span> non-null <span class="built_in">object</span></span><br><span class="line">contbr_occupation    <span class="number">993301</span> non-null <span class="built_in">object</span></span><br><span class="line">contb_receipt_amt    <span class="number">1001731</span> non-null float64</span><br><span class="line">contb_receipt_dt     <span class="number">1001731</span> non-null <span class="built_in">object</span></span><br><span class="line">receipt_desc         <span class="number">14166</span> non-null <span class="built_in">object</span></span><br><span class="line">memo_cd              <span class="number">92482</span> non-null <span class="built_in">object</span></span><br><span class="line">memo_text            <span class="number">97770</span> non-null <span class="built_in">object</span></span><br><span class="line">form_tp              <span class="number">1001731</span> non-null <span class="built_in">object</span></span><br><span class="line">file_num             <span class="number">1001731</span> non-null int64</span><br><span class="line">dtypes: float64(<span class="number">1</span>), int64(<span class="number">1</span>), <span class="built_in">object</span>(<span class="number">14</span>)</span><br><span class="line">memory usage: <span class="number">122.3</span>+ MB</span><br></pre></td></tr></table></figure>
<p>该DataFrame中的记录如下所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">186</span>]: fec.iloc[<span class="number">123456</span>]</span><br><span class="line">Out[<span class="number">186</span>]: </span><br><span class="line">cmte_id             C00431445</span><br><span class="line">cand_id             P80003338</span><br><span class="line">cand_nm         Obama, Barack</span><br><span class="line">contbr_nm         ELLMAN, IRA</span><br><span class="line">contbr_city             TEMPE</span><br><span class="line">                    ...      </span><br><span class="line">receipt_desc              NaN</span><br><span class="line">memo_cd                   NaN</span><br><span class="line">memo_text                 NaN</span><br><span class="line">form_tp                 SA17A</span><br><span class="line">file_num               <span class="number">772372</span></span><br><span class="line">Name: <span class="number">123456</span>, Length: <span class="number">16</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>你可能已经想出了许多办法从这些竞选赞助数据中抽取有关赞助人和赞助模式的统计信息。我将在接下来的内容中介绍几种不同的分析工作（运用到目前为止已经学到的方法）。</p>
<p>不难看出，该数据中没有党派信息，因此最好把它加进去。通过unique，你可以获取全部的候选人名单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">187</span>]: unique_cands = fec.cand_nm.unique()</span><br><span class="line"></span><br><span class="line">In [<span class="number">188</span>]: unique_cands</span><br><span class="line">Out[<span class="number">188</span>]: </span><br><span class="line">array([<span class="string">&#x27;Bachmann, Michelle&#x27;</span>, <span class="string">&#x27;Romney, Mitt&#x27;</span>, <span class="string">&#x27;Obama, Barack&#x27;</span>,</span><br><span class="line">       <span class="string">&quot;Roemer, Charles E. &#x27;Buddy&#x27; III&quot;</span>, <span class="string">&#x27;Pawlenty, Timothy&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Johnson, Gary Earl&#x27;</span>, <span class="string">&#x27;Paul, Ron&#x27;</span>, <span class="string">&#x27;Santorum, Rick&#x27;</span>, <span class="string">&#x27;Cain, Herman&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Gingrich, Newt&#x27;</span>, <span class="string">&#x27;McCotter, Thaddeus G&#x27;</span>, <span class="string">&#x27;Huntsman, Jon&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Perry, Rick&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">189</span>]: unique_cands[<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">189</span>]: <span class="string">&#x27;Obama, Barack&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>指明党派信息的方法之一是使用字典：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parties = &#123;<span class="string">&#x27;Bachmann, Michelle&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Cain, Herman&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Gingrich, Newt&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Huntsman, Jon&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Johnson, Gary Earl&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;McCotter, Thaddeus G&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Obama, Barack&#x27;</span>: <span class="string">&#x27;Democrat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Paul, Ron&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Pawlenty, Timothy&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Perry, Rick&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&quot;Roemer, Charles E. &#x27;Buddy&#x27; III&quot;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Romney, Mitt&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;Santorum, Rick&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>现在，通过这个映射以及Series对象的map方法，你可以根据候选人姓名得到一组党派信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">191</span>]: fec.cand_nm[<span class="number">123456</span>:<span class="number">123461</span>]</span><br><span class="line">Out[<span class="number">191</span>]: </span><br><span class="line"><span class="number">123456</span>    Obama, Barack</span><br><span class="line"><span class="number">123457</span>    Obama, Barack</span><br><span class="line"><span class="number">123458</span>    Obama, Barack</span><br><span class="line"><span class="number">123459</span>    Obama, Barack</span><br><span class="line"><span class="number">123460</span>    Obama, Barack</span><br><span class="line">Name: cand_nm, dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">192</span>]: fec.cand_nm[<span class="number">123456</span>:<span class="number">123461</span>].<span class="built_in">map</span>(parties)</span><br><span class="line">Out[<span class="number">192</span>]: </span><br><span class="line"><span class="number">123456</span>    Democrat</span><br><span class="line"><span class="number">123457</span>    Democrat</span><br><span class="line"><span class="number">123458</span>    Democrat</span><br><span class="line"><span class="number">123459</span>    Democrat</span><br><span class="line"><span class="number">123460</span>    Democrat</span><br><span class="line">Name: cand_nm, dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add it as a column</span></span><br><span class="line">In [<span class="number">193</span>]: fec[<span class="string">&#x27;party&#x27;</span>] = fec.cand_nm.<span class="built_in">map</span>(parties)</span><br><span class="line"></span><br><span class="line">In [<span class="number">194</span>]: fec[<span class="string">&#x27;party&#x27;</span>].value_counts()</span><br><span class="line">Out[<span class="number">194</span>]: </span><br><span class="line">Democrat      <span class="number">593746</span></span><br><span class="line">Republican    <span class="number">407985</span></span><br><span class="line">Name: party, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>这里有两个需要注意的地方。第一，该数据既包括赞助也包括退款（负的出资额）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">195</span>]: (fec.contb_receipt_amt &gt; <span class="number">0</span>).value_counts()</span><br><span class="line">Out[<span class="number">195</span>]: </span><br><span class="line"><span class="literal">True</span>     <span class="number">991475</span></span><br><span class="line"><span class="literal">False</span>     <span class="number">10256</span></span><br><span class="line">Name: contb_receipt_amt, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>为了简化分析过程，我限定该数据集只能有正的出资额：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">196</span>]: fec = fec[fec.contb_receipt_amt &gt; <span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>由于Barack Obama和Mitt Romney是最主要的两名候选人，所以我还专门准备了一个子集，只包含针对他们两人的竞选活动的赞助信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">197</span>]: fec_mrbo = fec[fec.cand_nm.isin([<span class="string">&#x27;Obama, Barack&#x27;</span>,<span class="string">&#x27;Romney, Mitt&#x27;</span>])]</span><br></pre></td></tr></table></figure></p>
<h2><span id="根据职业和雇主统计赞助信息">根据职业和雇主统计赞助信息</span></h2><p>基于职业的赞助信息统计是另一种经常被研究的统计任务。例如，律师们更倾向于资助民主党，而企业主则更倾向于资助共和党。你可以不相信我，自己看那些数据就知道了。首先，根据职业计算出资总额，这很简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">198</span>]: fec.contbr_occupation.value_counts()[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">198</span>]: </span><br><span class="line">RETIRED                                   <span class="number">233990</span></span><br><span class="line">INFORMATION REQUESTED                      <span class="number">35107</span></span><br><span class="line">ATTORNEY                                   <span class="number">34286</span></span><br><span class="line">HOMEMAKER                                  <span class="number">29931</span></span><br><span class="line">PHYSICIAN                                  <span class="number">23432</span></span><br><span class="line">INFORMATION REQUESTED PER BEST EFFORTS     <span class="number">21138</span></span><br><span class="line">ENGINEER                                   <span class="number">14334</span></span><br><span class="line">TEACHER                                    <span class="number">13990</span></span><br><span class="line">CONSULTANT                                 <span class="number">13273</span></span><br><span class="line">PROFESSOR                                  <span class="number">12555</span></span><br><span class="line">Name: contbr_occupation, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>不难看出，许多职业都涉及相同的基本工作类型，或者同一样东西有多种变体。下面的代码片段可以清理一些这样的数据（将一个职业信息映射到另一个）。注意，这里巧妙地利用了dict.get，它允许没有映射关系的职业也能“通过”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">occ_mapping = &#123;</span><br><span class="line">   <span class="string">&#x27;INFORMATION REQUESTED PER BEST EFFORTS&#x27;</span> : <span class="string">&#x27;NOT PROVIDED&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;INFORMATION REQUESTED&#x27;</span> : <span class="string">&#x27;NOT PROVIDED&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;INFORMATION REQUESTED (BEST EFFORTS)&#x27;</span> : <span class="string">&#x27;NOT PROVIDED&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;C.E.O.&#x27;</span>: <span class="string">&#x27;CEO&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># If no mapping provided, return x</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: occ_mapping.get(x, x)</span><br><span class="line">fec.contbr_occupation = fec.contbr_occupation.<span class="built_in">map</span>(f)</span><br></pre></td></tr></table></figure></p>
<p>我对雇主信息也进行了同样的处理：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">emp_mapping = &#123;</span><br><span class="line">   <span class="string">&#x27;INFORMATION REQUESTED PER BEST EFFORTS&#x27;</span> : <span class="string">&#x27;NOT PROVIDED&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;INFORMATION REQUESTED&#x27;</span> : <span class="string">&#x27;NOT PROVIDED&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;SELF&#x27;</span> : <span class="string">&#x27;SELF-EMPLOYED&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;SELF EMPLOYED&#x27;</span> : <span class="string">&#x27;SELF-EMPLOYED&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># If no mapping provided, return x</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: emp_mapping.get(x, x)</span><br><span class="line">fec.contbr_employer = fec.contbr_employer.<span class="built_in">map</span>(f)</span><br></pre></td></tr></table></figure></p>
<p>现在，你可以通过pivot_table根据党派和职业对数据进行聚合，然后过滤掉总出资额不足200万美元的数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">201</span>]: by_occupation = fec.pivot_table(<span class="string">&#x27;contb_receipt_amt&#x27;</span>,</span><br><span class="line">   .....:                                 index=<span class="string">&#x27;contbr_occupation&#x27;</span>,</span><br><span class="line">   .....:                                 columns=<span class="string">&#x27;party&#x27;</span>, aggfunc=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">202</span>]: over_2mm = by_occupation[by_occupation.<span class="built_in">sum</span>(<span class="number">1</span>) &gt; <span class="number">2000000</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">203</span>]: over_2mm</span><br><span class="line">Out[<span class="number">203</span>]: </span><br><span class="line">party                 Democrat    Republican</span><br><span class="line">contbr_occupation                           </span><br><span class="line">ATTORNEY           <span class="number">11141982.97</span>  <span class="number">7.477194e+06</span></span><br><span class="line">CEO                 <span class="number">2074974.79</span>  <span class="number">4.211041e+06</span></span><br><span class="line">CONSULTANT          <span class="number">2459912.71</span>  <span class="number">2.544725e+06</span></span><br><span class="line">ENGINEER             <span class="number">951525.55</span>  <span class="number">1.818374e+06</span></span><br><span class="line">EXECUTIVE           <span class="number">1355161.05</span>  <span class="number">4.138850e+06</span></span><br><span class="line"><span class="meta">... </span>                       ...           ...</span><br><span class="line">PRESIDENT           <span class="number">1878509.95</span>  <span class="number">4.720924e+06</span></span><br><span class="line">PROFESSOR           <span class="number">2165071.08</span>  <span class="number">2.967027e+05</span></span><br><span class="line">REAL ESTATE          <span class="number">528902.09</span>  <span class="number">1.625902e+06</span></span><br><span class="line">RETIRED            <span class="number">25305116.38</span>  <span class="number">2.356124e+07</span></span><br><span class="line">SELF-EMPLOYED        <span class="number">672393.40</span>  <span class="number">1.640253e+06</span></span><br><span class="line">[<span class="number">17</span> rows x <span class="number">2</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>把这些数据做成柱状图看起来会更加清楚（’barh’表示水平柱状图，如图14-12所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">205</span>]: over_2mm.plot(kind=<span class="string">&#x27;barh&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-d2254e547c6ce537.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-12 对各党派总出资额最高的职业"></p>
<p>你可能还想了解一下对Obama和Romney总出资额最高的职业和企业。为此，我们先对候选人进行分组，然后使用本章前面介绍的类似top的方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_top_amounts</span>(<span class="params">group, key, n=<span class="number">5</span></span>):</span></span><br><span class="line">    totals = group.groupby(key)[<span class="string">&#x27;contb_receipt_amt&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> totals.nlargest(n)</span><br></pre></td></tr></table></figure></p>
<p>然后根据职业和雇主进行聚合：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">207</span>]: grouped = fec_mrbo.groupby(<span class="string">&#x27;cand_nm&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">208</span>]: grouped.apply(get_top_amounts, <span class="string">&#x27;contbr_occupation&#x27;</span>, n=<span class="number">7</span>)</span><br><span class="line">Out[<span class="number">208</span>]: </span><br><span class="line">cand_nm        contbr_occupation    </span><br><span class="line">Obama, Barack  RETIRED                  <span class="number">25305116.38</span></span><br><span class="line">               ATTORNEY                 <span class="number">11141982.97</span></span><br><span class="line">               INFORMATION REQUESTED     <span class="number">4866973.96</span></span><br><span class="line">               HOMEMAKER                 <span class="number">4248875.80</span></span><br><span class="line">               PHYSICIAN                 <span class="number">3735124.94</span></span><br><span class="line">                                           ...     </span><br><span class="line">Romney, Mitt   HOMEMAKER                 <span class="number">8147446.22</span></span><br><span class="line">               ATTORNEY                  <span class="number">5364718.82</span></span><br><span class="line">               PRESIDENT                 <span class="number">2491244.89</span></span><br><span class="line">               EXECUTIVE                 <span class="number">2300947.03</span></span><br><span class="line">               C.E.O.                    <span class="number">1968386.11</span></span><br><span class="line">Name: contb_receipt_amt, Length: <span class="number">14</span>, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">209</span>]: grouped.apply(get_top_amounts, <span class="string">&#x27;contbr_employer&#x27;</span>, n=<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">209</span>]: </span><br><span class="line">cand_nm        contbr_employer      </span><br><span class="line">Obama, Barack  RETIRED                  <span class="number">22694358.85</span></span><br><span class="line">               SELF-EMPLOYED            <span class="number">17080985.96</span></span><br><span class="line">               NOT EMPLOYED              <span class="number">8586308.70</span></span><br><span class="line">               INFORMATION REQUESTED     <span class="number">5053480.37</span></span><br><span class="line">               HOMEMAKER                 <span class="number">2605408.54</span></span><br><span class="line">                                           ...     </span><br><span class="line">Romney, Mitt   CREDIT SUISSE              <span class="number">281150.00</span></span><br><span class="line">               MORGAN STANLEY             <span class="number">267266.00</span></span><br><span class="line">               GOLDMAN SACH &amp; CO.         <span class="number">238250.00</span></span><br><span class="line">               BARCLAYS CAPITAL           <span class="number">162750.00</span></span><br><span class="line">               H.I.G. CAPITAL             <span class="number">139500.00</span></span><br><span class="line">Name: contb_receipt_amt, Length: <span class="number">20</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="对出资额分组">对出资额分组</span></h2><p>还可以对该数据做另一种非常实用的分析：利用cut函数根据出资额的大小将数据离散化到多个面元中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">210</span>]: bins = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>, <span class="number">10000</span>,</span><br><span class="line">   .....:                  <span class="number">100000</span>, <span class="number">1000000</span>, <span class="number">10000000</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">211</span>]: labels = pd.cut(fec_mrbo.contb_receipt_amt, bins)</span><br><span class="line"></span><br><span class="line">In [<span class="number">212</span>]: labels</span><br><span class="line">Out[<span class="number">212</span>]: </span><br><span class="line"><span class="number">411</span>         (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">412</span>       (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line"><span class="number">413</span>       (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line"><span class="number">414</span>         (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">415</span>         (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line">             ...     </span><br><span class="line"><span class="number">701381</span>      (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">701382</span>    (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line"><span class="number">701383</span>        (<span class="number">1</span>, <span class="number">10</span>]</span><br><span class="line"><span class="number">701384</span>      (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">701385</span>    (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line">Name: contb_receipt_amt, Length: <span class="number">694282</span>, dtype: category</span><br><span class="line">Categories (<span class="number">8</span>, interval[int64]): [(<span class="number">0</span>, <span class="number">1</span>] &lt; (<span class="number">1</span>, <span class="number">10</span>] &lt; (<span class="number">10</span>, <span class="number">100</span>] &lt; (<span class="number">100</span>, <span class="number">1000</span>] &lt; (<span class="number">1</span></span><br><span class="line"><span class="number">000</span>, <span class="number">10000</span>] &lt;</span><br><span class="line">                                  (<span class="number">10000</span>, <span class="number">100000</span>] &lt; (<span class="number">100000</span>, <span class="number">1000000</span>] &lt; (<span class="number">1000000</span>,</span><br><span class="line"> <span class="number">10000000</span>]]</span><br></pre></td></tr></table></figure></p>
<p>现在可以根据候选人姓名以及面元标签对奥巴马和罗姆尼数据进行分组，以得到一个柱状图：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">213</span>]: grouped = fec_mrbo.groupby([<span class="string">&#x27;cand_nm&#x27;</span>, labels])</span><br><span class="line"></span><br><span class="line">In [<span class="number">214</span>]: grouped.size().unstack(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">214</span>]: </span><br><span class="line">cand_nm              Obama, Barack  Romney, Mitt</span><br><span class="line">contb_receipt_amt                               </span><br><span class="line">(<span class="number">0</span>, <span class="number">1</span>]                       <span class="number">493.0</span>          <span class="number">77.0</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">10</span>]                    <span class="number">40070.0</span>        <span class="number">3681.0</span></span><br><span class="line">(<span class="number">10</span>, <span class="number">100</span>]                 <span class="number">372280.0</span>       <span class="number">31853.0</span></span><br><span class="line">(<span class="number">100</span>, <span class="number">1000</span>]               <span class="number">153991.0</span>       <span class="number">43357.0</span></span><br><span class="line">(<span class="number">1000</span>, <span class="number">10000</span>]              <span class="number">22284.0</span>       <span class="number">26186.0</span></span><br><span class="line">(<span class="number">10000</span>, <span class="number">100000</span>]                <span class="number">2.0</span>           <span class="number">1.0</span></span><br><span class="line">(<span class="number">100000</span>, <span class="number">1000000</span>]              <span class="number">3.0</span>           NaN</span><br><span class="line">(<span class="number">1000000</span>, <span class="number">10000000</span>]            <span class="number">4.0</span>           NaN</span><br></pre></td></tr></table></figure></p>
<p>从这个数据中可以看出，在小额赞助方面，Obama获得的数量比Romney多得多。你还可以对出资额求和并在面元内规格化，以便图形化显示两位候选人各种赞助额度的比例（见图14-13）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">216</span>]: bucket_sums = grouped.contb_receipt_amt.<span class="built_in">sum</span>().unstack(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">217</span>]: normed_sums = bucket_sums.div(bucket_sums.<span class="built_in">sum</span>(axis=<span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">218</span>]: normed_sums</span><br><span class="line">Out[<span class="number">218</span>]: </span><br><span class="line">cand_nm              Obama, Barack  Romney, Mitt</span><br><span class="line">contb_receipt_amt                               </span><br><span class="line">(<span class="number">0</span>, <span class="number">1</span>]                    <span class="number">0.805182</span>      <span class="number">0.194818</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">10</span>]                   <span class="number">0.918767</span>      <span class="number">0.081233</span></span><br><span class="line">(<span class="number">10</span>, <span class="number">100</span>]                 <span class="number">0.910769</span>      <span class="number">0.089231</span></span><br><span class="line">(<span class="number">100</span>, <span class="number">1000</span>]               <span class="number">0.710176</span>      <span class="number">0.289824</span></span><br><span class="line">(<span class="number">1000</span>, <span class="number">10000</span>]             <span class="number">0.447326</span>      <span class="number">0.552674</span></span><br><span class="line">(<span class="number">10000</span>, <span class="number">100000</span>]           <span class="number">0.823120</span>      <span class="number">0.176880</span></span><br><span class="line">(<span class="number">100000</span>, <span class="number">1000000</span>]         <span class="number">1.000000</span>           NaN</span><br><span class="line">(<span class="number">1000000</span>, <span class="number">10000000</span>]       <span class="number">1.000000</span>           NaN</span><br><span class="line"></span><br><span class="line">In [<span class="number">219</span>]: normed_sums[:-<span class="number">2</span>].plot(kind=<span class="string">&#x27;barh&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-77e8c8d3c784692b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-13 两位候选人收到的各种捐赠额度的总额比例"></p>
<p>我排除了两个最大的面元，因为这些不是由个人捐赠的。</p>
<p>还可以对该分析过程做许多的提炼和改进。比如说，可以根据赞助人的姓名和邮编对数据进行聚合，以便找出哪些人进行了多次小额捐款，哪些人又进行了一次或多次大额捐款。我强烈建议你下载这些数据并自己摸索一下。</p>
<h2><span id="根据州统计赞助信息">根据州统计赞助信息</span></h2><p>根据候选人和州对数据进行聚合是常规操作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">220</span>]: grouped = fec_mrbo.groupby([<span class="string">&#x27;cand_nm&#x27;</span>, <span class="string">&#x27;contbr_st&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">221</span>]: totals = grouped.contb_receipt_amt.<span class="built_in">sum</span>().unstack(<span class="number">0</span>).fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">222</span>]: totals = totals[totals.<span class="built_in">sum</span>(<span class="number">1</span>) &gt; <span class="number">100000</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">223</span>]: totals[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">223</span>]: </span><br><span class="line">cand_nm    Obama, Barack  Romney, Mitt</span><br><span class="line">contbr_st                             </span><br><span class="line">AK             <span class="number">281840.15</span>      <span class="number">86204.24</span></span><br><span class="line">AL             <span class="number">543123.48</span>     <span class="number">527303.51</span></span><br><span class="line">AR             <span class="number">359247.28</span>     <span class="number">105556.00</span></span><br><span class="line">AZ            <span class="number">1506476.98</span>    <span class="number">1888436.23</span></span><br><span class="line">CA           <span class="number">23824984.24</span>   <span class="number">11237636.60</span></span><br><span class="line">CO            <span class="number">2132429.49</span>    <span class="number">1506714.12</span></span><br><span class="line">CT            <span class="number">2068291.26</span>    <span class="number">3499475.45</span></span><br><span class="line">DC            <span class="number">4373538.80</span>    <span class="number">1025137.50</span></span><br><span class="line">DE             <span class="number">336669.14</span>      <span class="number">82712.00</span></span><br><span class="line">FL            <span class="number">7318178.58</span>    <span class="number">8338458.81</span></span><br></pre></td></tr></table></figure></p>
<p>如果对各行除以总赞助额，就会得到各候选人在各州的总赞助额比例：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">224</span>]: percent = totals.div(totals.<span class="built_in">sum</span>(<span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">225</span>]: percent[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">225</span>]: </span><br><span class="line">cand_nm    Obama, Barack  Romney, Mitt</span><br><span class="line">contbr_st                             </span><br><span class="line">AK              <span class="number">0.765778</span>      <span class="number">0.234222</span></span><br><span class="line">AL              <span class="number">0.507390</span>      <span class="number">0.492610</span></span><br><span class="line">AR              <span class="number">0.772902</span>      <span class="number">0.227098</span></span><br><span class="line">AZ              <span class="number">0.443745</span>      <span class="number">0.556255</span></span><br><span class="line">CA              <span class="number">0.679498</span>      <span class="number">0.320502</span></span><br><span class="line">CO              <span class="number">0.585970</span>      <span class="number">0.414030</span></span><br><span class="line">CT              <span class="number">0.371476</span>      <span class="number">0.628524</span></span><br><span class="line">DC              <span class="number">0.810113</span>      <span class="number">0.189887</span></span><br><span class="line">DE              <span class="number">0.802776</span>      <span class="number">0.197224</span></span><br><span class="line">FL              <span class="number">0.467417</span>      <span class="number">0.532583</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="146-总结">14.6 总结</span></h1><p>我们已经完成了正文的最后一章。附录中有一些额外的内容，可能对你有用。</p>
<p>本书第一版出版已经有5年了，Python已经成为了一个流行的、广泛使用的数据分析语言。你从本书中学到的方法，在相当长的一段时间都是可用的。我希望本书介绍的工具和库对你的工作有用。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-13.建模库</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-13-%E5%BB%BA%E6%A8%A1%E5%BA%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>本书中，我已经介绍了Python数据分析的编程基础。因为数据分析师和科学家总是在数据规整和准备上花费大量时间，这本书的重点在于掌握这些功能。</p>
<span id="more"></span>
<p>开发模型选用什么库取决于应用本身。许多统计问题可以用简单方法解决，比如普通的最小二乘回归，其它问题可能需要复杂的机器学习方法。幸运的是，Python已经成为了运用这些分析方法的语言之一，因此读完此书，你可以探索许多工具。</p>
<p>本章中，我会回顾一些pandas的特点，在你胶着于pandas数据规整和模型拟合和评分时，它们可能派上用场。然后我会简短介绍两个流行的建模工具，statsmodels和scikit-learn。这二者每个都值得再写一本书，我就不做全面的介绍，而是建议你学习两个项目的线上文档和其它基于Python的数据科学、统计和机器学习的书籍。</p>
<h1><span id="131-pandas与模型代码的接口">13.1 pandas与模型代码的接口</span></h1><p>模型开发的通常工作流是使用pandas进行数据加载和清洗，然后切换到建模库进行建模。开发模型的重要一环是机器学习中的“特征工程”。它可以描述从原始数据集中提取信息的任何数据转换或分析，这些数据集可能在建模中有用。本书中学习的数据聚合和GroupBy工具常用于特征工程中。</p>
<p>优秀的特征工程超出了本书的范围，我会尽量直白地介绍一些用于数据操作和建模切换的方法。</p>
<p>pandas与其它分析库通常是靠NumPy的数组联系起来的。将DataFrame转换为NumPy数组，可以使用.values属性：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: data = pd.DataFrame(&#123;</span><br><span class="line">   ....:     <span class="string">&#x27;x0&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;x1&#x27;</span>: [<span class="number">0.01</span>, -<span class="number">0.01</span>, <span class="number">0.25</span>, -<span class="number">4.1</span>, <span class="number">0.</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;y&#x27;</span>: [-<span class="number">1.5</span>, <span class="number">0.</span>, <span class="number">3.6</span>, <span class="number">1.3</span>, -<span class="number">2.</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: data</span><br><span class="line">Out[<span class="number">13</span>]: </span><br><span class="line">   x0    x1    y</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>  <span class="number">0.01</span> -<span class="number">1.5</span></span><br><span class="line"><span class="number">1</span>   <span class="number">2</span> -<span class="number">0.01</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>  <span class="number">0.25</span>  <span class="number">3.6</span></span><br><span class="line"><span class="number">3</span>   <span class="number">4</span> -<span class="number">4.10</span>  <span class="number">1.3</span></span><br><span class="line"><span class="number">4</span>   <span class="number">5</span>  <span class="number">0.00</span> -<span class="number">2.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: data.columns</span><br><span class="line">Out[<span class="number">14</span>]: Index([<span class="string">&#x27;x0&#x27;</span>, <span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;y&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: data.values</span><br><span class="line">Out[<span class="number">15</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>  ,  <span class="number">0.01</span>, -<span class="number">1.5</span> ],</span><br><span class="line">       [ <span class="number">2.</span>  , -<span class="number">0.01</span>,  <span class="number">0.</span>  ],</span><br><span class="line">       [ <span class="number">3.</span>  ,  <span class="number">0.25</span>,  <span class="number">3.6</span> ],</span><br><span class="line">       [ <span class="number">4.</span>  , -<span class="number">4.1</span> ,  <span class="number">1.3</span> ],</span><br><span class="line">       [ <span class="number">5.</span>  ,  <span class="number">0.</span>  , -<span class="number">2.</span>  ]])</span><br></pre></td></tr></table></figure></p>
<p>要转换回DataFrame，可以传递一个二维ndarray，可带有列名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: df2 = pd.DataFrame(data.values, columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: df2</span><br><span class="line">Out[<span class="number">17</span>]: </span><br><span class="line">   one   two  three</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">0.01</span>   -<span class="number">1.5</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2.0</span> -<span class="number">0.01</span>    <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3.0</span>  <span class="number">0.25</span>    <span class="number">3.6</span></span><br><span class="line"><span class="number">3</span>  <span class="number">4.0</span> -<span class="number">4.10</span>    <span class="number">1.3</span></span><br><span class="line"><span class="number">4</span>  <span class="number">5.0</span>  <span class="number">0.00</span>   -<span class="number">2.0</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：最好当数据是均匀的时候使用.values属性。例如，全是数值类型。如果数据是不均匀的，结果会是Python对象的ndarray：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;In [<span class="number">18</span>]: df3 = data.copy()</span><br><span class="line"></span><br><span class="line">&gt;In [<span class="number">19</span>]: df3[<span class="string">&#x27;strings&#x27;</span>] = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>]</span><br><span class="line"></span><br><span class="line">&gt;In [<span class="number">20</span>]: df3</span><br><span class="line">&gt;Out[<span class="number">20</span>]: </span><br><span class="line">  x0    x1    y strings</span><br><span class="line">&gt;<span class="number">0</span>   <span class="number">1</span>  <span class="number">0.01</span> -<span class="number">1.5</span>       a</span><br><span class="line">&gt;<span class="number">1</span>   <span class="number">2</span> -<span class="number">0.01</span>  <span class="number">0.0</span>       b</span><br><span class="line">&gt;<span class="number">2</span>   <span class="number">3</span>  <span class="number">0.25</span>  <span class="number">3.6</span>       c</span><br><span class="line">&gt;<span class="number">3</span>   <span class="number">4</span> -<span class="number">4.10</span>  <span class="number">1.3</span>       d</span><br><span class="line">&gt;<span class="number">4</span>   <span class="number">5</span>  <span class="number">0.00</span> -<span class="number">2.0</span>       e</span><br><span class="line"></span><br><span class="line">&gt;In [<span class="number">21</span>]: df3.values</span><br><span class="line">&gt;Out[<span class="number">21</span>]: </span><br><span class="line">&gt;array([[<span class="number">1</span>, <span class="number">0.01</span>, -<span class="number">1.5</span>, <span class="string">&#x27;a&#x27;</span>],</span><br><span class="line">      [<span class="number">2</span>, -<span class="number">0.01</span>, <span class="number">0.0</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">      [<span class="number">3</span>, <span class="number">0.25</span>, <span class="number">3.6</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">      [<span class="number">4</span>, -<span class="number">4.1</span>, <span class="number">1.3</span>, <span class="string">&#x27;d&#x27;</span>],</span><br><span class="line">      [<span class="number">5</span>, <span class="number">0.0</span>, -<span class="number">2.0</span>, <span class="string">&#x27;e&#x27;</span>]], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>对于一些模型，你可能只想使用列的子集。我建议你使用loc，用values作索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">22</span>]: model_cols = [<span class="string">&#x27;x0&#x27;</span>, <span class="string">&#x27;x1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: data.loc[:, model_cols].values</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>  ,  <span class="number">0.01</span>],</span><br><span class="line">       [ <span class="number">2.</span>  , -<span class="number">0.01</span>],</span><br><span class="line">       [ <span class="number">3.</span>  ,  <span class="number">0.25</span>],</span><br><span class="line">       [ <span class="number">4.</span>  , -<span class="number">4.1</span> ],</span><br><span class="line">       [ <span class="number">5.</span>  ,  <span class="number">0.</span>  ]])</span><br></pre></td></tr></table></figure></p>
<p>一些库原生支持pandas，会自动完成工作：从DataFrame转换到NumPy，将模型的参数名添加到输出表的列或Series。其它情况，你可以手工进行“元数据管理”。</p>
<p>在第12章，我们学习了pandas的Categorical类型和pandas.get_dummies函数。假设数据集中有一个非数值列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: data[<span class="string">&#x27;category&#x27;</span>] = pd.Categorical([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">   ....:                                   categories=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: data</span><br><span class="line">Out[<span class="number">25</span>]: </span><br><span class="line">   x0    x1    y category</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>  <span class="number">0.01</span> -<span class="number">1.5</span>        a</span><br><span class="line"><span class="number">1</span>   <span class="number">2</span> -<span class="number">0.01</span>  <span class="number">0.0</span>        b</span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>  <span class="number">0.25</span>  <span class="number">3.6</span>        a</span><br><span class="line"><span class="number">3</span>   <span class="number">4</span> -<span class="number">4.10</span>  <span class="number">1.3</span>        a</span><br><span class="line"><span class="number">4</span>   <span class="number">5</span>  <span class="number">0.00</span> -<span class="number">2.0</span>        b</span><br></pre></td></tr></table></figure></p>
<p>如果我们想替换category列为虚变量，我们可以创建虚变量，删除category列，然后添加到结果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">26</span>]: dummies = pd.get_dummies(data.category, prefix=<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: data_with_dummies = data.drop(<span class="string">&#x27;category&#x27;</span>, axis=<span class="number">1</span>).join(dummies)</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: data_with_dummies</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">   x0    x1    y  category_a  category_b</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>  <span class="number">0.01</span> -<span class="number">1.5</span>           <span class="number">1</span>           <span class="number">0</span></span><br><span class="line"><span class="number">1</span>   <span class="number">2</span> -<span class="number">0.01</span>  <span class="number">0.0</span>           <span class="number">0</span>           <span class="number">1</span></span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>  <span class="number">0.25</span>  <span class="number">3.6</span>           <span class="number">1</span>           <span class="number">0</span></span><br><span class="line"><span class="number">3</span>   <span class="number">4</span> -<span class="number">4.10</span>  <span class="number">1.3</span>           <span class="number">1</span>           <span class="number">0</span></span><br><span class="line"><span class="number">4</span>   <span class="number">5</span>  <span class="number">0.00</span> -<span class="number">2.0</span>           <span class="number">0</span>           <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>用虚变量拟合某些统计模型会有一些细微差别。当你不只有数字列时，使用Patsy（下一节的主题）可能更简单，更不容易出错。</p>
<h1><span id="132-用patsy创建模型描述">13.2 用Patsy创建模型描述</span></h1><p>Patsy是Python的一个库，使用简短的字符串“公式语法”描述统计模型（尤其是线性模型），可能是受到了R和S统计编程语言的公式语法的启发。</p>
<p>Patsy适合描述statsmodels的线性模型，因此我会关注于它的主要特点，让你尽快掌握。Patsy的公式是一个特殊的字符串语法，如下所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y ~ x0 + x1</span><br></pre></td></tr></table></figure></p>
<p>a+b不是将a与b相加的意思，而是为模型创建的设计矩阵。patsy.dmatrices函数接收一个公式字符串和一个数据集（可以是DataFrame或数组的字典），为线性模型创建设计矩阵：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: data = pd.DataFrame(&#123;</span><br><span class="line">   ....:     <span class="string">&#x27;x0&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;x1&#x27;</span>: [<span class="number">0.01</span>, -<span class="number">0.01</span>, <span class="number">0.25</span>, -<span class="number">4.1</span>, <span class="number">0.</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;y&#x27;</span>: [-<span class="number">1.5</span>, <span class="number">0.</span>, <span class="number">3.6</span>, <span class="number">1.3</span>, -<span class="number">2.</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: data</span><br><span class="line">Out[<span class="number">30</span>]: </span><br><span class="line">   x0    x1    y</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>  <span class="number">0.01</span> -<span class="number">1.5</span></span><br><span class="line"><span class="number">1</span>   <span class="number">2</span> -<span class="number">0.01</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>  <span class="number">0.25</span>  <span class="number">3.6</span></span><br><span class="line"><span class="number">3</span>   <span class="number">4</span> -<span class="number">4.10</span>  <span class="number">1.3</span></span><br><span class="line"><span class="number">4</span>   <span class="number">5</span>  <span class="number">0.00</span> -<span class="number">2.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: <span class="keyword">import</span> patsy</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;y ~ x0 + x1&#x27;</span>, data)</span><br></pre></td></tr></table></figure></p>
<p>现在有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: y</span><br><span class="line">Out[<span class="number">33</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">     y</span><br><span class="line">  -<span class="number">1.5</span></span><br><span class="line">   <span class="number">0.0</span></span><br><span class="line">   <span class="number">3.6</span></span><br><span class="line">   <span class="number">1.3</span></span><br><span class="line">  -<span class="number">2.0</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;y&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: X</span><br><span class="line">Out[<span class="number">34</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">  Intercept  x0     x1</span><br><span class="line">          <span class="number">1</span>   <span class="number">1</span>   <span class="number">0.01</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">2</span>  -<span class="number">0.01</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">3</span>   <span class="number">0.25</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">4</span>  -<span class="number">4.10</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">5</span>   <span class="number">0.00</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;x0&#x27;</span> (column <span class="number">1</span>)</span><br><span class="line">    <span class="string">&#x27;x1&#x27;</span> (column <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>这些Patsy的DesignMatrix实例是NumPy的ndarray，带有附加元数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: np.asarray(y)</span><br><span class="line">Out[<span class="number">35</span>]: </span><br><span class="line">array([[-<span class="number">1.5</span>],</span><br><span class="line">       [ <span class="number">0.</span> ],</span><br><span class="line">       [ <span class="number">3.6</span>],</span><br><span class="line">       [ <span class="number">1.3</span>],</span><br><span class="line">       [-<span class="number">2.</span> ]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: np.asarray(X)</span><br><span class="line">Out[<span class="number">36</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>  ,  <span class="number">1.</span>  ,  <span class="number">0.01</span>],</span><br><span class="line">       [ <span class="number">1.</span>  ,  <span class="number">2.</span>  , -<span class="number">0.01</span>],</span><br><span class="line">       [ <span class="number">1.</span>  ,  <span class="number">3.</span>  ,  <span class="number">0.25</span>],</span><br><span class="line">       [ <span class="number">1.</span>  ,  <span class="number">4.</span>  , -<span class="number">4.1</span> ],</span><br><span class="line">       [ <span class="number">1.</span>  ,  <span class="number">5.</span>  ,  <span class="number">0.</span>  ]])</span><br></pre></td></tr></table></figure></p>
<p>你可能想Intercept是哪里来的。这是线性模型（比如普通最小二乘回归）的惯例用法。添加 +0 到模型可以不显示intercept：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">37</span>]: patsy.dmatrices(<span class="string">&#x27;y ~ x0 + x1 + 0&#x27;</span>, data)[<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">  x0     x1</span><br><span class="line">   <span class="number">1</span>   <span class="number">0.01</span></span><br><span class="line">   <span class="number">2</span>  -<span class="number">0.01</span></span><br><span class="line">   <span class="number">3</span>   <span class="number">0.25</span></span><br><span class="line">   <span class="number">4</span>  -<span class="number">4.10</span></span><br><span class="line">   <span class="number">5</span>   <span class="number">0.00</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;x0&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;x1&#x27;</span> (column <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>Patsy对象可以直接传递到算法（比如numpy.linalg.lstsq）中，它执行普通最小二乘回归：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">38</span>]: coef, resid, _, _ = np.linalg.lstsq(X, y)</span><br></pre></td></tr></table></figure></p>
<p>模型的元数据保留在design_info属性中，因此你可以重新附加列名到拟合系数，以获得一个Series，例如：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: coef</span><br><span class="line">Out[<span class="number">39</span>]: </span><br><span class="line">array([[ <span class="number">0.3129</span>],</span><br><span class="line">       [-<span class="number">0.0791</span>],</span><br><span class="line">       [-<span class="number">0.2655</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: coef = pd.Series(coef.squeeze(), index=X.design_info.column_names)</span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: coef</span><br><span class="line">Out[<span class="number">41</span>]: </span><br><span class="line">Intercept    <span class="number">0.312910</span></span><br><span class="line">x0          -<span class="number">0.079106</span></span><br><span class="line">x1          -<span class="number">0.265464</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="用patsy公式进行数据转换">用Patsy公式进行数据转换</span></h2><p>你可以将Python代码与patsy公式结合。在评估公式时，库将尝试查找在封闭作用域内使用的函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">42</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;y ~ x0 + np.log(np.abs(x1) + 1)&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: X</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">  Intercept  x0  np.log(np.<span class="built_in">abs</span>(x1) + <span class="number">1</span>)</span><br><span class="line">          <span class="number">1</span>   <span class="number">1</span>                 <span class="number">0.00995</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">2</span>                 <span class="number">0.00995</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">3</span>                 <span class="number">0.22314</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">4</span>                 <span class="number">1.62924</span></span><br><span class="line">          <span class="number">1</span>   <span class="number">5</span>                 <span class="number">0.00000</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;x0&#x27;</span> (column <span class="number">1</span>)</span><br><span class="line">    <span class="string">&#x27;np.log(np.abs(x1) + 1)&#x27;</span> (column <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>常见的变量转换包括标准化（平均值为0，方差为1）和中心化（减去平均值）。Patsy有内置的函数进行这样的工作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;y ~ standardize(x0) + center(x1)&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: X</span><br><span class="line">Out[<span class="number">45</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">  Intercept  standardize(x0)  center(x1)</span><br><span class="line">          <span class="number">1</span>         -<span class="number">1.41421</span>        <span class="number">0.78</span></span><br><span class="line">          <span class="number">1</span>         -<span class="number">0.70711</span>        <span class="number">0.76</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0.00000</span>        <span class="number">1.02</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0.70711</span>       -<span class="number">3.33</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1.41421</span>        <span class="number">0.77</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;standardize(x0)&#x27;</span> (column <span class="number">1</span>)</span><br><span class="line">    <span class="string">&#x27;center(x1)&#x27;</span> (column <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>作为建模的一步，你可能拟合模型到一个数据集，然后用另一个数据集评估模型。另一个数据集可能是剩余的部分或是新数据。当执行中心化和标准化转变，用新数据进行预测要格外小心。因为你必须使用平均值或标准差转换新数据集，这也称作状态转换。</p>
<p>patsy.build_design_matrices函数可以使用原始样本数据集的保存信息，来转换新数据，：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">46</span>]: new_data = pd.DataFrame(&#123;</span><br><span class="line">   ....:     <span class="string">&#x27;x0&#x27;</span>: [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;x1&#x27;</span>: [<span class="number">3.1</span>, -<span class="number">0.5</span>, <span class="number">0</span>, <span class="number">2.3</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;y&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: new_X = patsy.build_design_matrices([X.design_info], new_data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: new_X</span><br><span class="line">Out[<span class="number">48</span>]: </span><br><span class="line">[DesignMatrix <span class="keyword">with</span> shape (<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">   Intercept  standardize(x0)  center(x1)</span><br><span class="line">           <span class="number">1</span>          <span class="number">2.12132</span>        <span class="number">3.87</span></span><br><span class="line">           <span class="number">1</span>          <span class="number">2.82843</span>        <span class="number">0.27</span></span><br><span class="line">           <span class="number">1</span>          <span class="number">3.53553</span>        <span class="number">0.77</span></span><br><span class="line">           <span class="number">1</span>          <span class="number">4.24264</span>        <span class="number">3.07</span></span><br><span class="line">   Terms:</span><br><span class="line">     <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">     <span class="string">&#x27;standardize(x0)&#x27;</span> (column <span class="number">1</span>)</span><br><span class="line">     <span class="string">&#x27;center(x1)&#x27;</span> (column <span class="number">2</span>)]</span><br></pre></td></tr></table></figure></p>
<p>因为Patsy中的加号不是加法的意义，当你按照名称将数据集的列相加时，你必须用特殊I函数将它们封装起来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;y ~ I(x0 + x1)&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: X</span><br><span class="line">Out[<span class="number">50</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">  Intercept  I(x0 + x1)</span><br><span class="line">          <span class="number">1</span>        <span class="number">1.01</span></span><br><span class="line">          <span class="number">1</span>        <span class="number">1.99</span></span><br><span class="line">          <span class="number">1</span>        <span class="number">3.25</span></span><br><span class="line">          <span class="number">1</span>       -<span class="number">0.10</span></span><br><span class="line">          <span class="number">1</span>        <span class="number">5.00</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;I(x0 + x1)&#x27;</span> (column <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>Patsy的patsy.builtins模块还有一些其它的内置转换。请查看线上文档。</p>
<p>分类数据有一个特殊的转换类，下面进行讲解。</p>
<h2><span id="分类数据和patsy">分类数据和Patsy</span></h2><p>非数值数据可以用多种方式转换为模型设计矩阵。完整的讲解超出了本书范围，最好和统计课一起学习。</p>
<p>当你在Patsy公式中使用非数值数据，它们会默认转换为虚变量。如果有截距，会去掉一个，避免共线性：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: data = pd.DataFrame(&#123;</span><br><span class="line">   ....:     <span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;key2&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;v1&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">   ....:     <span class="string">&#x27;v2&#x27;</span>: [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">2.5</span>, -<span class="number">0.5</span>, <span class="number">4.0</span>, -<span class="number">1.2</span>, <span class="number">0.2</span>, -<span class="number">1.7</span>]</span><br><span class="line">   ....: &#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;v2 ~ key1&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: X</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">8</span>, <span class="number">2</span>)</span><br><span class="line">  Intercept  key1[T.b]</span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;key1&#x27;</span> (column <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果你从模型中忽略截距，每个分类值的列都会包括在设计矩阵的模型中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">54</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;v2 ~ key1 + 0&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: X</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">8</span>, <span class="number">2</span>)</span><br><span class="line">  key1[a]  key1[b]</span><br><span class="line">        <span class="number">1</span>        <span class="number">0</span></span><br><span class="line">        <span class="number">1</span>        <span class="number">0</span></span><br><span class="line">        <span class="number">0</span>        <span class="number">1</span></span><br><span class="line">        <span class="number">0</span>        <span class="number">1</span></span><br><span class="line">        <span class="number">1</span>        <span class="number">0</span></span><br><span class="line">        <span class="number">0</span>        <span class="number">1</span></span><br><span class="line">        <span class="number">1</span>        <span class="number">0</span></span><br><span class="line">        <span class="number">0</span>        <span class="number">1</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;key1&#x27;</span> (columns <span class="number">0</span>:<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>使用C函数，数值列可以截取为分类量：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;v2 ~ C(key2)&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: X</span><br><span class="line">Out[<span class="number">57</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">8</span>, <span class="number">2</span>)</span><br><span class="line">  Intercept  C(key2)[T<span class="number">.1</span>]</span><br><span class="line">          <span class="number">1</span>             <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>             <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>             <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>             <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>             <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>             <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>             <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>             <span class="number">0</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;C(key2)&#x27;</span> (column <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>当你在模型中使用多个分类名，事情就会变复杂，因为会包括key1:key2形式的相交部分，它可以用在方差（ANOVA）模型分析中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">58</span>]: data[<span class="string">&#x27;key2&#x27;</span>] = data[<span class="string">&#x27;key2&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="number">0</span>: <span class="string">&#x27;zero&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;one&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: data</span><br><span class="line">Out[<span class="number">59</span>]: </span><br><span class="line">  key1  key2  v1   v2</span><br><span class="line"><span class="number">0</span>    a  zero   <span class="number">1</span> -<span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    a   one   <span class="number">2</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>    b  zero   <span class="number">3</span>  <span class="number">2.5</span></span><br><span class="line"><span class="number">3</span>    b   one   <span class="number">4</span> -<span class="number">0.5</span></span><br><span class="line"><span class="number">4</span>    a  zero   <span class="number">5</span>  <span class="number">4.0</span></span><br><span class="line"><span class="number">5</span>    b   one   <span class="number">6</span> -<span class="number">1.2</span></span><br><span class="line"><span class="number">6</span>    a  zero   <span class="number">7</span>  <span class="number">0.2</span></span><br><span class="line"><span class="number">7</span>    b  zero   <span class="number">8</span> -<span class="number">1.7</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;v2 ~ key1 + key2&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: X</span><br><span class="line">Out[<span class="number">61</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">8</span>, <span class="number">3</span>)</span><br><span class="line">  Intercept  key1[T.b]  key2[T.zero]</span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">1</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;key1&#x27;</span> (column <span class="number">1</span>)</span><br><span class="line">    <span class="string">&#x27;key2&#x27;</span> (column <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: y, X = patsy.dmatrices(<span class="string">&#x27;v2 ~ key1 + key2 + key1:key2&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: X</span><br><span class="line">Out[<span class="number">63</span>]: </span><br><span class="line">DesignMatrix <span class="keyword">with</span> shape (<span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line">  Intercept  key1[T.b]  key2[T.zero]</span><br><span class="line">key1[T.b]:key2[T.zero]</span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">1</span>                       <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">0</span>                       <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">1</span>                       <span class="number">1</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">0</span>                       <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">1</span>                       <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">0</span>                       <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">0</span>             <span class="number">1</span>                       <span class="number">0</span></span><br><span class="line">          <span class="number">1</span>          <span class="number">1</span>             <span class="number">1</span>                       <span class="number">1</span></span><br><span class="line">  Terms:</span><br><span class="line">    <span class="string">&#x27;Intercept&#x27;</span> (column <span class="number">0</span>)</span><br><span class="line">    <span class="string">&#x27;key1&#x27;</span> (column <span class="number">1</span>)</span><br><span class="line">    <span class="string">&#x27;key2&#x27;</span> (column <span class="number">2</span>)</span><br><span class="line">    <span class="string">&#x27;key1:key2&#x27;</span> (column <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p>Patsy提供转换分类数据的其它方法，包括以特定顺序转换。请参阅线上文档。</p>
<h1><span id="133-statsmodels介绍">13.3 statsmodels介绍</span></h1><p>statsmodels是Python进行拟合多种统计模型、进行统计试验和数据探索可视化的库。Statsmodels包含许多经典的统计方法，但没有贝叶斯方法和机器学习模型。</p>
<p>statsmodels包含的模型有：</p>
<ul>
<li>线性模型，广义线性模型和健壮线性模型</li>
<li>线性混合效应模型</li>
<li>方差（ANOVA）方法分析</li>
<li>时间序列过程和状态空间模型</li>
<li>广义矩估计</li>
</ul>
<p>下面，我会使用一些基本的statsmodels工具，探索Patsy公式和pandasDataFrame对象如何使用模型接口。</p>
<h2><span id="估计线性模型">估计线性模型</span></h2><p>statsmodels有多种线性回归模型，包括从基本（比如普通最小二乘）到复杂（比如迭代加权最小二乘法）的。</p>
<p>statsmodels的线性模型有两种不同的接口：基于数组和基于公式。它们可以通过API模块引入：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> smf</span><br></pre></td></tr></table></figure></p>
<p>为了展示它们的使用方法，我们从一些随机数据生成一个线性模型：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dnorm</span>(<span class="params">mean, variance, size=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(size, <span class="built_in">int</span>):</span><br><span class="line">        size = size,</span><br><span class="line">    <span class="keyword">return</span> mean + np.sqrt(variance) * np.random.randn(*size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># For reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">12345</span>)</span><br><span class="line"></span><br><span class="line">N = <span class="number">100</span></span><br><span class="line">X = np.c_[dnorm(<span class="number">0</span>, <span class="number">0.4</span>, size=N),</span><br><span class="line">          dnorm(<span class="number">0</span>, <span class="number">0.6</span>, size=N),</span><br><span class="line">          dnorm(<span class="number">0</span>, <span class="number">0.2</span>, size=N)]</span><br><span class="line">eps = dnorm(<span class="number">0</span>, <span class="number">0.1</span>, size=N)</span><br><span class="line">beta = [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]</span><br><span class="line"></span><br><span class="line">y = np.dot(X, beta) + eps</span><br></pre></td></tr></table></figure></p>
<p>这里，我使用了“真实”模型和可知参数beta。此时，dnorm可用来生成正态分布数据，带有特定均值和方差。现在有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: X[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">66</span>]: </span><br><span class="line">array([[-<span class="number">0.1295</span>, -<span class="number">1.2128</span>,  <span class="number">0.5042</span>],</span><br><span class="line">       [ <span class="number">0.3029</span>, -<span class="number">0.4357</span>, -<span class="number">0.2542</span>],</span><br><span class="line">       [-<span class="number">0.3285</span>, -<span class="number">0.0253</span>,  <span class="number">0.1384</span>],</span><br><span class="line">       [-<span class="number">0.3515</span>, -<span class="number">0.7196</span>, -<span class="number">0.2582</span>],</span><br><span class="line">       [ <span class="number">1.2433</span>, -<span class="number">0.3738</span>, -<span class="number">0.5226</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: y[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">67</span>]: array([ <span class="number">0.4279</span>, -<span class="number">0.6735</span>, -<span class="number">0.0909</span>, -<span class="number">0.4895</span>,-<span class="number">0.1289</span>])</span><br></pre></td></tr></table></figure></p>
<p>像之前Patsy看到的，线性模型通常要拟合一个截距。sm.add_constant函数可以添加一个截距的列到现存的矩阵：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: X_model = sm.add_constant(X)</span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: X_model[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">69</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>    , -<span class="number">0.1295</span>, -<span class="number">1.2128</span>,  <span class="number">0.5042</span>],</span><br><span class="line">       [ <span class="number">1.</span>    ,  <span class="number">0.3029</span>, -<span class="number">0.4357</span>, -<span class="number">0.2542</span>],</span><br><span class="line">       [ <span class="number">1.</span>    , -<span class="number">0.3285</span>, -<span class="number">0.0253</span>,  <span class="number">0.1384</span>],</span><br><span class="line">       [ <span class="number">1.</span>    , -<span class="number">0.3515</span>, -<span class="number">0.7196</span>, -<span class="number">0.2582</span>],</span><br><span class="line">       [ <span class="number">1.</span>    ,  <span class="number">1.2433</span>, -<span class="number">0.3738</span>, -<span class="number">0.5226</span>]])</span><br></pre></td></tr></table></figure></p>
<p>sm.OLS类可以拟合一个普通最小二乘回归：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">70</span>]: model = sm.OLS(y, X)</span><br></pre></td></tr></table></figure></p>
<p>这个模型的fit方法返回了一个回归结果对象，它包含估计的模型参数和其它内容：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">71</span>]: results = model.fit()</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: results.params</span><br><span class="line">Out[<span class="number">72</span>]: array([ <span class="number">0.1783</span>,  <span class="number">0.223</span> ,  <span class="number">0.501</span> ])</span><br></pre></td></tr></table></figure></p>
<p>对结果使用summary方法可以打印模型的详细诊断结果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: <span class="built_in">print</span>(results.summary())</span><br><span class="line">OLS Regression Results                            </span><br><span class="line">==============================================================================</span><br><span class="line">Dep. Variable:                      y   R-squared:                       <span class="number">0.430</span></span><br><span class="line">Model:                            OLS   Adj. R-squared:                  <span class="number">0.413</span></span><br><span class="line">Method:                 Least Squares   F-statistic:                     <span class="number">24.42</span></span><br><span class="line">Date:                Mon, <span class="number">25</span> Sep <span class="number">2017</span>   Prob (F-statistic):           <span class="number">7.44e-12</span></span><br><span class="line">Time:                        <span class="number">14</span>:06:<span class="number">15</span>   Log-Likelihood:                -<span class="number">34.305</span></span><br><span class="line">No. Observations:                 <span class="number">100</span>   AIC:                             <span class="number">74.61</span></span><br><span class="line">Df Residuals:                      <span class="number">97</span>   BIC:                             <span class="number">82.42</span></span><br><span class="line">Df Model:                           <span class="number">3</span>                                         </span><br><span class="line">Covariance <span class="type">Type</span>:            nonrobust                                         </span><br><span class="line">==============================================================================</span><br><span class="line">                 coef    std err          t      P&gt;|t|      [<span class="number">0.025</span>      <span class="number">0.975</span>]</span><br><span class="line">------------------------------------------------------------------------------</span><br><span class="line">x1             <span class="number">0.1783</span>      <span class="number">0.053</span>      <span class="number">3.364</span>      <span class="number">0.001</span>       <span class="number">0.073</span>       <span class="number">0.283</span></span><br><span class="line">x2             <span class="number">0.2230</span>      <span class="number">0.046</span>      <span class="number">4.818</span>      <span class="number">0.000</span>       <span class="number">0.131</span>       <span class="number">0.315</span></span><br><span class="line">x3             <span class="number">0.5010</span>      <span class="number">0.080</span>      <span class="number">6.237</span>      <span class="number">0.000</span>       <span class="number">0.342</span>       <span class="number">0.660</span></span><br><span class="line">==============================================================================</span><br><span class="line">Omnibus:                        <span class="number">4.662</span>   Durbin-Watson:                   <span class="number">2.201</span></span><br><span class="line">Prob(Omnibus):                  <span class="number">0.097</span>   Jarque-Bera (JB):                <span class="number">4.098</span></span><br><span class="line">Skew:                           <span class="number">0.481</span>   Prob(JB):                        <span class="number">0.129</span></span><br><span class="line">Kurtosis:                       <span class="number">3.243</span>   Cond. No.</span><br><span class="line"><span class="number">1.74</span></span><br><span class="line">==============================================================================</span><br><span class="line">Warnings:</span><br><span class="line">[<span class="number">1</span>] Standard Errors assume that the covariance matrix of the errors <span class="keyword">is</span> correctly </span><br><span class="line">specified.</span><br></pre></td></tr></table></figure></p>
<p>这里的参数名为通用名x1, x2等等。假设所有的模型参数都在一个DataFrame中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: data = pd.DataFrame(X, columns=[<span class="string">&#x27;col0&#x27;</span>, <span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">75</span>]: data[<span class="string">&#x27;y&#x27;</span>] = y</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: data[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">76</span>]: </span><br><span class="line">       col0      col1      col2         y</span><br><span class="line"><span class="number">0</span> -<span class="number">0.129468</span> -<span class="number">1.212753</span>  <span class="number">0.504225</span>  <span class="number">0.427863</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.302910</span> -<span class="number">0.435742</span> -<span class="number">0.254180</span> -<span class="number">0.673480</span></span><br><span class="line"><span class="number">2</span> -<span class="number">0.328522</span> -<span class="number">0.025302</span>  <span class="number">0.138351</span> -<span class="number">0.090878</span></span><br><span class="line"><span class="number">3</span> -<span class="number">0.351475</span> -<span class="number">0.719605</span> -<span class="number">0.258215</span> -<span class="number">0.489494</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.243269</span> -<span class="number">0.373799</span> -<span class="number">0.522629</span> -<span class="number">0.128941</span></span><br></pre></td></tr></table></figure></p>
<p>现在，我们使用statsmodels的公式API和Patsy的公式字符串：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">77</span>]: results = smf.ols(<span class="string">&#x27;y ~ col0 + col1 + col2&#x27;</span>, data=data).fit()</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: results.params</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line">Intercept    <span class="number">0.033559</span></span><br><span class="line">col0         <span class="number">0.176149</span></span><br><span class="line">col1         <span class="number">0.224826</span></span><br><span class="line">col2         <span class="number">0.514808</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: results.tvalues</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line">Intercept    <span class="number">0.952188</span></span><br><span class="line">col0         <span class="number">3.319754</span></span><br><span class="line">col1         <span class="number">4.850730</span></span><br><span class="line">col2         <span class="number">6.303971</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>观察下statsmodels是如何返回Series结果的，附带有DataFrame的列名。当使用公式和pandas对象时，我们不需要使用add_constant。</p>
<p>给出一个样本外数据，你可以根据估计的模型参数计算预测值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">80</span>]: results.predict(data[:<span class="number">5</span>])</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line"><span class="number">0</span>   -<span class="number">0.002327</span></span><br><span class="line"><span class="number">1</span>   -<span class="number">0.141904</span></span><br><span class="line"><span class="number">2</span>    <span class="number">0.041226</span></span><br><span class="line"><span class="number">3</span>   -<span class="number">0.323070</span></span><br><span class="line"><span class="number">4</span>   -<span class="number">0.100535</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>statsmodels的线性模型结果还有其它的分析、诊断和可视化工具。除了普通最小二乘模型，还有其它的线性模型。</p>
<h2><span id="估计时间序列过程">估计时间序列过程</span></h2><p>statsmodels的另一模型类是进行时间序列分析，包括自回归过程、卡尔曼滤波和其它态空间模型，和多元自回归模型。</p>
<p>用自回归结构和噪声来模拟一些时间序列数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">init_x = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">values = [init_x, init_x]</span><br><span class="line">N = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">b0 = <span class="number">0.8</span></span><br><span class="line">b1 = -<span class="number">0.4</span></span><br><span class="line">noise = dnorm(<span class="number">0</span>, <span class="number">0.1</span>, N)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">    new_x = values[-<span class="number">1</span>] * b0 + values[-<span class="number">2</span>] * b1 + noise[i]</span><br><span class="line">    values.append(new_x)</span><br></pre></td></tr></table></figure></p>
<p>这个数据有AR(2)结构（两个延迟），参数是0.8和-0.4。拟合AR模型时，你可能不知道滞后项的个数，因此可以用较多的滞后量来拟合这个模型：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: MAXLAGS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: model = sm.tsa.AR(values)</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: results = model.fit(MAXLAGS)</span><br></pre></td></tr></table></figure></p>
<p>结果中的估计参数首先是截距，其次是前两个参数的估计值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: results.params</span><br><span class="line">Out[<span class="number">85</span>]: array([-<span class="number">0.0062</span>,  <span class="number">0.7845</span>, -<span class="number">0.4085</span>, -<span class="number">0.0136</span>,  <span class="number">0.015</span> ,  <span class="number">0.0143</span>])</span><br></pre></td></tr></table></figure></p>
<p>更多的细节以及如何解释结果超出了本书的范围，可以通过statsmodels文档学习更多。</p>
<h1><span id="134-scikit-learn介绍">13.4 scikit-learn介绍</span></h1><p>scikit-learn是一个广泛使用、用途多样的Python机器学习库。它包含多种标准监督和非监督机器学习方法和模型选择和评估、数据转换、数据加载和模型持久化工具。这些模型可以用于分类、聚合、预测和其它任务。</p>
<p>机器学习方面的学习和应用scikit-learn和TensorFlow解决实际问题的线上和纸质资料很多。本节中，我会简要介绍scikit-learn API的风格。</p>
<p>写作此书的时候，scikit-learn并没有和pandas深度结合，但是有些第三方包在开发中。尽管如此，pandas非常适合在模型拟合前处理数据集。</p>
<p>举个例子，我用一个Kaggle竞赛的经典数据集，关于泰坦尼克号乘客的生还率。我们用pandas加载测试和训练数据集：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">86</span>]: train = pd.read_csv(<span class="string">&#x27;datasets/titanic/train.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: test = pd.read_csv(<span class="string">&#x27;datasets/titanic/test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: train[:<span class="number">4</span>]</span><br><span class="line">Out[<span class="number">88</span>]: </span><br><span class="line">   PassengerId  Survived  Pclass  \</span><br><span class="line"><span class="number">0</span>            <span class="number">1</span>         <span class="number">0</span>       <span class="number">3</span>   </span><br><span class="line"><span class="number">1</span>            <span class="number">2</span>         <span class="number">1</span>       <span class="number">1</span>   </span><br><span class="line"><span class="number">2</span>            <span class="number">3</span>         <span class="number">1</span>       <span class="number">3</span>   </span><br><span class="line"><span class="number">3</span>            <span class="number">4</span>         <span class="number">1</span>       <span class="number">1</span>   </span><br><span class="line">                                                Name     Sex   Age  SibSp  \</span><br><span class="line"><span class="number">0</span>                            Braund, Mr. Owen Harris    male  <span class="number">22.0</span>      <span class="number">1</span>   </span><br><span class="line"><span class="number">1</span>  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  <span class="number">38.0</span>      <span class="number">1</span>   </span><br><span class="line"><span class="number">2</span>                             Heikkinen, Miss. Laina  female  <span class="number">26.0</span>      <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  <span class="number">35.0</span>      <span class="number">1</span>   </span><br><span class="line">   Parch            Ticket     Fare Cabin Embarked  </span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>         A/<span class="number">5</span> <span class="number">21171</span>   <span class="number">7.2500</span>   NaN        S  </span><br><span class="line"><span class="number">1</span>      <span class="number">0</span>          PC <span class="number">17599</span>  <span class="number">71.2833</span>   C85        C  </span><br><span class="line"><span class="number">2</span>      <span class="number">0</span>  STON/O2. <span class="number">3101282</span>   <span class="number">7.9250</span>   NaN        S  </span><br><span class="line"><span class="number">3</span>      <span class="number">0</span>            <span class="number">113803</span>  <span class="number">53.1000</span>  C123        S</span><br></pre></td></tr></table></figure></p>
<p>statsmodels和scikit-learn通常不能接收缺失数据，因此我们要查看列是否包含缺失值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">89</span>]: train.isnull().<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">89</span>]: </span><br><span class="line">PassengerId      <span class="number">0</span></span><br><span class="line">Survived         <span class="number">0</span></span><br><span class="line">Pclass           <span class="number">0</span></span><br><span class="line">Name             <span class="number">0</span></span><br><span class="line">Sex              <span class="number">0</span></span><br><span class="line">Age            <span class="number">177</span></span><br><span class="line">SibSp            <span class="number">0</span></span><br><span class="line">Parch            <span class="number">0</span></span><br><span class="line">Ticket           <span class="number">0</span></span><br><span class="line">Fare             <span class="number">0</span></span><br><span class="line">Cabin          <span class="number">687</span></span><br><span class="line">Embarked         <span class="number">2</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: test.isnull().<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">PassengerId      <span class="number">0</span></span><br><span class="line">Pclass           <span class="number">0</span></span><br><span class="line">Name             <span class="number">0</span></span><br><span class="line">Sex              <span class="number">0</span></span><br><span class="line">Age             <span class="number">86</span></span><br><span class="line">SibSp            <span class="number">0</span></span><br><span class="line">Parch            <span class="number">0</span></span><br><span class="line">Ticket           <span class="number">0</span></span><br><span class="line">Fare             <span class="number">1</span></span><br><span class="line">Cabin          <span class="number">327</span></span><br><span class="line">Embarked         <span class="number">0</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>在统计和机器学习的例子中，根据数据中的特征，一个典型的任务是预测乘客能否生还。模型现在训练数据集中拟合，然后用样本外测试数据集评估。</p>
<p>我想用年龄作为预测值，但是它包含缺失值。缺失数据补全的方法有多种，我用的是一种简单方法，用训练数据集的中位数补全两个表的空值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: impute_value = train[<span class="string">&#x27;Age&#x27;</span>].median()</span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: train[<span class="string">&#x27;Age&#x27;</span>] = train[<span class="string">&#x27;Age&#x27;</span>].fillna(impute_value)</span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: test[<span class="string">&#x27;Age&#x27;</span>] = test[<span class="string">&#x27;Age&#x27;</span>].fillna(impute_value)</span><br></pre></td></tr></table></figure></p>
<p>现在我们需要指定模型。我增加了一个列IsFemale，作为“Sex”列的编码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: train[<span class="string">&#x27;IsFemale&#x27;</span>] = (train[<span class="string">&#x27;Sex&#x27;</span>] == <span class="string">&#x27;female&#x27;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">95</span>]: test[<span class="string">&#x27;IsFemale&#x27;</span>] = (test[<span class="string">&#x27;Sex&#x27;</span>] == <span class="string">&#x27;female&#x27;</span>).astype(<span class="built_in">int</span>)</span><br></pre></td></tr></table></figure></p>
<p>然后，我们确定一些模型变量，并创建NumPy数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: predictors = [<span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;IsFemale&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: X_train = train[predictors].values</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: X_test = test[predictors].values</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: y_train = train[<span class="string">&#x27;Survived&#x27;</span>].values</span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: X_train[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">100</span>]: </span><br><span class="line">array([[  <span class="number">3.</span>,   <span class="number">0.</span>,  <span class="number">22.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">1.</span>,  <span class="number">38.</span>],</span><br><span class="line">       [  <span class="number">3.</span>,   <span class="number">1.</span>,  <span class="number">26.</span>],</span><br><span class="line">       [  <span class="number">1.</span>,   <span class="number">1.</span>,  <span class="number">35.</span>],</span><br><span class="line">       [  <span class="number">3.</span>,   <span class="number">0.</span>,  <span class="number">35.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">101</span>]: y_train[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">101</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<p>我不能保证这是一个好模型，但它的特征都符合。我们用scikit-learn的LogisticRegression模型，创建一个模型实例：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: model = LogisticRegression()</span><br></pre></td></tr></table></figure></p>
<p>与statsmodels类似，我们可以用模型的fit方法，将它拟合到训练数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">104</span>]: model.fit(X_train, y_train)</span><br><span class="line">Out[<span class="number">104</span>]: </span><br><span class="line">LogisticRegression(C=<span class="number">1.0</span>, class_weight=<span class="literal">None</span>, dual=<span class="literal">False</span>, fit_intercept=<span class="literal">True</span>,</span><br><span class="line">          intercept_scaling=<span class="number">1</span>, max_iter=<span class="number">100</span>, multi_class=<span class="string">&#x27;ovr&#x27;</span>, n_jobs=<span class="number">1</span>,</span><br><span class="line">          penalty=<span class="string">&#x27;l2&#x27;</span>, random_state=<span class="literal">None</span>, solver=<span class="string">&#x27;liblinear&#x27;</span>, tol=<span class="number">0.0001</span>,</span><br><span class="line">          verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在，我们可以用model.predict，对测试数据进行预测：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">105</span>]: y_predict = model.predict(X_test)</span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: y_predict[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">106</span>]: array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<p>如果你有测试数据集的真是值，你可以计算准确率或其它错误度量值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(y_true == y_predict).mean()</span><br></pre></td></tr></table></figure></p>
<p>在实际中，模型训练经常有许多额外的复杂因素。许多模型有可以调节的参数，有些方法（比如交叉验证）可以用来进行参数调节，避免对训练数据过拟合。这通常可以提高预测性或对新数据的健壮性。</p>
<p>交叉验证通过分割训练数据来模拟样本外预测。基于模型的精度得分（比如均方差），可以对模型参数进行网格搜索。有些模型，如logistic回归，有内置的交叉验证的估计类。例如，logisticregressioncv类可以用一个参数指定网格搜索对模型的正则化参数C的粒度：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">107</span>]: <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegressionCV</span><br><span class="line"></span><br><span class="line">In [<span class="number">108</span>]: model_cv = LogisticRegressionCV(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: model_cv.fit(X_train, y_train)</span><br><span class="line">Out[<span class="number">109</span>]: </span><br><span class="line">LogisticRegressionCV(Cs=<span class="number">10</span>, class_weight=<span class="literal">None</span>, cv=<span class="literal">None</span>, dual=<span class="literal">False</span>,</span><br><span class="line">           fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1.0</span>, max_iter=<span class="number">100</span>,</span><br><span class="line">           multi_class=<span class="string">&#x27;ovr&#x27;</span>, n_jobs=<span class="number">1</span>, penalty=<span class="string">&#x27;l2&#x27;</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">           refit=<span class="literal">True</span>, scoring=<span class="literal">None</span>, solver=<span class="string">&#x27;lbfgs&#x27;</span>, tol=<span class="number">0.0001</span>, verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>要手动进行交叉验证，你可以使用cross_val_score帮助函数，它可以处理数据分割。例如，要交叉验证我们的带有四个不重叠训练数据的模型，可以这样做：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">110</span>]: <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line">In [<span class="number">111</span>]: model = LogisticRegression(C=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: scores = cross_val_score(model, X_train, y_train, cv=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: scores</span><br><span class="line">Out[<span class="number">113</span>]: array([ <span class="number">0.7723</span>,  <span class="number">0.8027</span>,  <span class="number">0.7703</span>,  <span class="number">0.7883</span>])</span><br></pre></td></tr></table></figure></p>
<p>默认的评分指标取决于模型本身，但是可以明确指定一个评分。交叉验证过的模型需要更长时间来训练，但会有更高的模型性能。</p>
<h1><span id="135-继续学习">13.5 继续学习</span></h1><p>我只是介绍了一些Python建模库的表面内容，现在有越来越多的框架用于各种统计和机器学习，它们都是用Python或Python用户界面实现的。</p>
<p>这本书的重点是数据规整，有其它的书是关注建模和数据科学工具的。其中优秀的有：</p>
<ul>
<li>Andreas Mueller and Sarah Guido (O’Reilly)的 《Introduction to Machine Learning with Python》</li>
<li>Jake VanderPlas (O’Reilly)的 《Python Data Science Handbook》</li>
<li>Joel Grus (O’Reilly) 的 《Data Science from Scratch: First Principles》</li>
<li>Sebastian Raschka (Packt Publishing) 的《Python Machine Learning》</li>
<li>Aurélien Géron (O’Reilly) 的《Hands-On Machine Learning with Scikit-Learn and TensorFlow》</li>
</ul>
<p>虽然书是学习的好资源，但是随着底层开源软件的发展，书的内容会过时。最好是不断熟悉各种统计和机器学习框架的文档，学习最新的功能和API。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>python库</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-12.pandas高级应用</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-12-pandas%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>前面的章节关注于不同类型的数据规整流程和NumPy、pandas与其它库的特点。随着时间的发展，pandas发展出了更多适合高级用户的功能。本章就要深入学习pandas的高级功能。</p>
<span id="more"></span>
<h1><span id="121-分类数据">12.1 分类数据</span></h1><p>这一节介绍的是pandas的分类类型。我会向你展示通过使用它，提高性能和内存的使用率。我还会介绍一些在统计和机器学习中使用分类数据的工具。</p>
<h2><span id="背景和目的">背景和目的</span></h2><p>表中的一列通常会有重复的包含不同值的小集合的情况。我们已经学过了unique和value_counts，它们可以从数组提取出不同的值，并分别计算频率：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np; <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: values = pd.Series([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>,</span><br><span class="line">   ....:                     <span class="string">&#x27;apple&#x27;</span>] * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: values</span><br><span class="line">Out[<span class="number">12</span>]: </span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">1</span>    orange</span><br><span class="line"><span class="number">2</span>     apple</span><br><span class="line"><span class="number">3</span>     apple</span><br><span class="line"><span class="number">4</span>     apple</span><br><span class="line"><span class="number">5</span>    orange</span><br><span class="line"><span class="number">6</span>     apple</span><br><span class="line"><span class="number">7</span>     apple</span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: pd.unique(values)</span><br><span class="line">Out[<span class="number">13</span>]: array([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: pd.value_counts(values)</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">apple     <span class="number">6</span></span><br><span class="line">orange    <span class="number">2</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>许多数据系统（数据仓库、统计计算或其它应用）都发展出了特定的表征重复值的方法，以进行高效的存储和计算。在数据仓库中，最好的方法是使用所谓的包含不同值的维表(Dimension Table)，将主要的参数存储为引用维表整数键：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: values = pd.Series([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>] * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: dim = pd.Series([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: values</span><br><span class="line">Out[<span class="number">17</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1</span></span><br><span class="line"><span class="number">2</span>    <span class="number">0</span></span><br><span class="line"><span class="number">3</span>    <span class="number">0</span></span><br><span class="line"><span class="number">4</span>    <span class="number">0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">1</span></span><br><span class="line"><span class="number">6</span>    <span class="number">0</span></span><br><span class="line"><span class="number">7</span>    <span class="number">0</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: dim</span><br><span class="line">Out[<span class="number">18</span>]: </span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">1</span>    orange</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>可以使用take方法存储原始的字符串Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">19</span>]: dim.take(values)</span><br><span class="line">Out[<span class="number">19</span>]: </span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">1</span>    orange</span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">1</span>    orange</span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>这种用整数表示的方法称为分类或字典编码表示法。不同值得数组称为分类、字典或数据级。本书中，我们使用分类的说法。表示分类的整数值称为分类编码或简单地称为编码。</p>
<p>分类表示可以在进行分析时大大的提高性能。你也可以在保持编码不变的情况下，对分类进行转换。一些相对简单的转变例子包括：</p>
<ul>
<li>重命名分类。</li>
<li>加入一个新的分类，不改变已经存在的分类的顺序或位置。</li>
</ul>
<h2><span id="pandas的分类类型">pandas的分类类型</span></h2><p>pandas有一个特殊的分类类型，用于保存使用整数分类表示法的数据。看一个之前的Series例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">20</span>]: fruits = [<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>] * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: N = <span class="built_in">len</span>(fruits)</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;fruit&#x27;</span>: fruits,</span><br><span class="line">   ....:                    <span class="string">&#x27;basket_id&#x27;</span>: np.arange(N),</span><br><span class="line">   ....:                    <span class="string">&#x27;count&#x27;</span>: np.random.randint(<span class="number">3</span>, <span class="number">15</span>, size=N),</span><br><span class="line">   ....:                    <span class="string">&#x27;weight&#x27;</span>: np.random.uniform(<span class="number">0</span>, <span class="number">4</span>, size=N)&#125;,</span><br><span class="line">   ....:                   columns=[<span class="string">&#x27;basket_id&#x27;</span>, <span class="string">&#x27;fruit&#x27;</span>, <span class="string">&#x27;count&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: df</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line">   basket_id   fruit  count    weight</span><br><span class="line"><span class="number">0</span>          <span class="number">0</span>   apple      <span class="number">5</span>  <span class="number">3.858058</span></span><br><span class="line"><span class="number">1</span>          <span class="number">1</span>  orange      <span class="number">8</span>  <span class="number">2.612708</span></span><br><span class="line"><span class="number">2</span>          <span class="number">2</span>   apple      <span class="number">4</span>  <span class="number">2.995627</span></span><br><span class="line"><span class="number">3</span>          <span class="number">3</span>   apple      <span class="number">7</span>  <span class="number">2.614279</span></span><br><span class="line"><span class="number">4</span>          <span class="number">4</span>   apple     <span class="number">12</span>  <span class="number">2.990859</span></span><br><span class="line"><span class="number">5</span>          <span class="number">5</span>  orange      <span class="number">8</span>  <span class="number">3.845227</span></span><br><span class="line"><span class="number">6</span>          <span class="number">6</span>   apple      <span class="number">5</span>  <span class="number">0.033553</span></span><br><span class="line"><span class="number">7</span>          <span class="number">7</span>   apple      <span class="number">4</span>  <span class="number">0.425778</span></span><br></pre></td></tr></table></figure></p>
<p>这里，df[‘fruit’]是一个Python字符串对象的数组。我们可以通过调用它，将它转变为分类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: fruit_cat = df[<span class="string">&#x27;fruit&#x27;</span>].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: fruit_cat</span><br><span class="line">Out[<span class="number">25</span>]: </span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">1</span>    orange</span><br><span class="line"><span class="number">2</span>     apple</span><br><span class="line"><span class="number">3</span>     apple</span><br><span class="line"><span class="number">4</span>     apple</span><br><span class="line"><span class="number">5</span>    orange</span><br><span class="line"><span class="number">6</span>     apple</span><br><span class="line"><span class="number">7</span>     apple</span><br><span class="line">Name: fruit, dtype: category</span><br><span class="line">Categories (<span class="number">2</span>, <span class="built_in">object</span>): [apple, orange]</span><br></pre></td></tr></table></figure></p>
<p>fruit_cat的值不是NumPy数组，而是一个pandas.Categorical实例：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">26</span>]: c = fruit_cat.values</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: <span class="built_in">type</span>(c)</span><br><span class="line">Out[<span class="number">27</span>]: pandas.core.categorical.Categorical</span><br></pre></td></tr></table></figure></p>
<p>分类对象有categories和codes属性：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">28</span>]: c.categories</span><br><span class="line">Out[<span class="number">28</span>]: Index([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: c.codes</span><br><span class="line">Out[<span class="number">29</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], dtype=int8)</span><br></pre></td></tr></table></figure></p>
<p>你可将DataFrame的列通过分配转换结果，转换为分类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">30</span>]: df[<span class="string">&#x27;fruit&#x27;</span>] = df[<span class="string">&#x27;fruit&#x27;</span>].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: df.fruit</span><br><span class="line">Out[<span class="number">31</span>]:</span><br><span class="line"><span class="number">0</span>     apple</span><br><span class="line"><span class="number">1</span>    orange</span><br><span class="line"><span class="number">2</span>     apple</span><br><span class="line"><span class="number">3</span>     apple</span><br><span class="line"><span class="number">4</span>     apple</span><br><span class="line"><span class="number">5</span>    orange</span><br><span class="line"><span class="number">6</span>     apple</span><br><span class="line"><span class="number">7</span>     apple</span><br><span class="line">Name: fruit, dtype: category</span><br><span class="line">Categories (<span class="number">2</span>, <span class="built_in">object</span>): [apple, orange]</span><br></pre></td></tr></table></figure></p>
<p>你还可以从其它Python序列直接创建pandas.Categorical：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: my_categories = pd.Categorical([<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: my_categories</span><br><span class="line">Out[<span class="number">33</span>]: </span><br><span class="line">[foo, bar, baz, foo, bar]</span><br><span class="line">Categories (<span class="number">3</span>, <span class="built_in">object</span>): [bar, baz, foo]</span><br></pre></td></tr></table></figure></p>
<p>如果你已经从其它源获得了分类编码，你还可以使用from_codes构造器：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: categories = [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: codes = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: my_cats_2 = pd.Categorical.from_codes(codes, categories)</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: my_cats_2</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">[foo, bar, baz, foo, foo, bar]</span><br><span class="line">Categories (<span class="number">3</span>, <span class="built_in">object</span>): [foo, bar, baz]</span><br></pre></td></tr></table></figure></p>
<p>与显示指定不同，分类变换不认定指定的分类顺序。因此取决于输入数据的顺序，categories数组的顺序会不同。当使用from_codes或其它的构造器时，你可以指定分类一个有意义的顺序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">38</span>]: ordered_cat = pd.Categorical.from_codes(codes, categories,</span><br><span class="line">   ....:                                         ordered=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: ordered_cat</span><br><span class="line">Out[<span class="number">39</span>]: </span><br><span class="line">[foo, bar, baz, foo, foo, bar]</span><br><span class="line">Categories (<span class="number">3</span>, <span class="built_in">object</span>): [foo &lt; bar &lt; baz]</span><br></pre></td></tr></table></figure></p>
<p>输出[foo &lt; bar &lt; baz]指明‘foo’位于‘bar’的前面，以此类推。无序的分类实例可以通过as_ordered排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">40</span>]: my_cats_2.as_ordered()</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">[foo, bar, baz, foo, foo, bar]</span><br><span class="line">Categories (<span class="number">3</span>, <span class="built_in">object</span>): [foo &lt; bar &lt; baz]</span><br></pre></td></tr></table></figure></p>
<p>最后要注意，分类数据不需要字符串，尽管我仅仅展示了字符串的例子。分类数组可以包括任意不可变类型。</p>
<h2><span id="用分类进行计算">用分类进行计算</span></h2><p>与非编码版本（比如字符串数组）相比，使用pandas的Categorical有些类似。某些pandas组件，比如groupby函数，更适合进行分类。还有一些函数可以使用有序标志位。</p>
<p>来看一些随机的数值数据，使用pandas.qcut面元函数。它会返回pandas.Categorical，我们之前使用过pandas.cut，但没解释分类是如何工作的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: np.random.seed(<span class="number">12345</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: draws = np.random.randn(<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: draws[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">43</span>]: array([-<span class="number">0.2047</span>,  <span class="number">0.4789</span>, -<span class="number">0.5194</span>, -<span class="number">0.5557</span>,  <span class="number">1.9658</span>])</span><br></pre></td></tr></table></figure></p>
<p>计算这个数据的分位面元，提取一些统计信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: bins = pd.qcut(draws, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: bins</span><br><span class="line">Out[<span class="number">45</span>]: </span><br><span class="line">[(-<span class="number">0.684</span>, -<span class="number">0.0101</span>], (-<span class="number">0.0101</span>, <span class="number">0.63</span>], (-<span class="number">0.684</span>, -<span class="number">0.0101</span>], (-<span class="number">0.684</span>, -<span class="number">0.0101</span>], (<span class="number">0.63</span>,</span><br><span class="line"> <span class="number">3.928</span>], ..., (-<span class="number">0.0101</span>, <span class="number">0.63</span>], (-<span class="number">0.684</span>, -<span class="number">0.0101</span>], (-<span class="number">2.95</span>, -<span class="number">0.684</span>], (-<span class="number">0.0101</span>, <span class="number">0.63</span></span><br><span class="line">], (<span class="number">0.63</span>, <span class="number">3.928</span>]]</span><br><span class="line">Length: <span class="number">1000</span></span><br><span class="line">Categories (<span class="number">4</span>, interval[float64]): [(-<span class="number">2.95</span>, -<span class="number">0.684</span>] &lt; (-<span class="number">0.684</span>, -<span class="number">0.0101</span>] &lt; (-<span class="number">0.010</span></span><br><span class="line"><span class="number">1</span>, <span class="number">0.63</span>] &lt;</span><br><span class="line">                                    (<span class="number">0.63</span>, <span class="number">3.928</span>]]</span><br></pre></td></tr></table></figure></p>
<p>虽然有用，确切的样本分位数与分位的名称相比，不利于生成汇总。我们可以使用labels参数qcut，实现目的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">46</span>]: bins = pd.qcut(draws, <span class="number">4</span>, labels=[<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>, <span class="string">&#x27;Q3&#x27;</span>, <span class="string">&#x27;Q4&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: bins</span><br><span class="line">Out[<span class="number">47</span>]: </span><br><span class="line">[Q2, Q3, Q2, Q2, Q4, ..., Q3, Q2, Q1, Q3, Q4]</span><br><span class="line">Length: <span class="number">1000</span></span><br><span class="line">Categories (<span class="number">4</span>, <span class="built_in">object</span>): [Q1 &lt; Q2 &lt; Q3 &lt; Q4]</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: bins.codes[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">48</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>], dtype=int8)</span><br></pre></td></tr></table></figure></p>
<p>加上标签的面元分类不包含数据面元边界的信息，因此可以使用groupby提取一些汇总信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: bins = pd.Series(bins, name=<span class="string">&#x27;quartile&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: results = (pd.Series(draws)</span><br><span class="line">   ....:            .groupby(bins)</span><br><span class="line">   ....:            .agg([<span class="string">&#x27;count&#x27;</span>, <span class="string">&#x27;min&#x27;</span>, <span class="string">&#x27;max&#x27;</span>])</span><br><span class="line">   ....:            .reset_index())</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: results</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">  quartile  count       <span class="built_in">min</span>       <span class="built_in">max</span></span><br><span class="line"><span class="number">0</span>       Q1    <span class="number">250</span> -<span class="number">2.949343</span> -<span class="number">0.685484</span></span><br><span class="line"><span class="number">1</span>       Q2    <span class="number">250</span> -<span class="number">0.683066</span> -<span class="number">0.010115</span></span><br><span class="line"><span class="number">2</span>       Q3    <span class="number">250</span> -<span class="number">0.010032</span>  <span class="number">0.628894</span></span><br><span class="line"><span class="number">3</span>       Q4    <span class="number">250</span>  <span class="number">0.634238</span>  <span class="number">3.927528</span></span><br></pre></td></tr></table></figure></p>
<p>分位数列保存了原始的面元分类信息，包括排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">52</span>]: results[<span class="string">&#x27;quartile&#x27;</span>]</span><br><span class="line">Out[<span class="number">52</span>]:</span><br><span class="line"><span class="number">0</span>    Q1</span><br><span class="line"><span class="number">1</span>    Q2</span><br><span class="line"><span class="number">2</span>    Q3</span><br><span class="line"><span class="number">3</span>    Q4</span><br><span class="line">Name: quartile, dtype: category</span><br><span class="line">Categories (<span class="number">4</span>, <span class="built_in">object</span>): [Q1 &lt; Q2 &lt; Q3 &lt; Q4]</span><br></pre></td></tr></table></figure></p>
<h2><span id="用分类提高性能">用分类提高性能</span></h2><p>如果你是在一个特定数据集上做大量分析，将其转换为分类可以极大地提高效率。DataFrame列的分类使用的内存通常少的多。来看一些包含一千万元素的Series，和一些不同的分类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">53</span>]: N = <span class="number">10000000</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: draws = pd.Series(np.random.randn(N))</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: labels = pd.Series([<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;qux&#x27;</span>] * (N // <span class="number">4</span>))</span><br></pre></td></tr></table></figure></p>
<p>现在，将标签转换为分类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: categories = labels.astype(<span class="string">&#x27;category&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>这时，可以看到标签使用的内存远比分类多：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: labels.memory_usage()</span><br><span class="line">Out[<span class="number">57</span>]: <span class="number">80000080</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: categories.memory_usage()</span><br><span class="line">Out[<span class="number">58</span>]: <span class="number">10000272</span></span><br></pre></td></tr></table></figure></p>
<p>转换为分类不是没有代价的，但这是一次性的代价：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">59</span>]: %time _ = labels.astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">CPU times: user <span class="number">490</span> ms, sys: <span class="number">240</span> ms, total: <span class="number">730</span> ms</span><br><span class="line">Wall time: <span class="number">726</span> ms</span><br></pre></td></tr></table></figure></p>
<p>GroupBy使用分类操作明显更快，是因为底层的算法使用整数编码数组，而不是字符串数组。</p>
<h2><span id="分类方法">分类方法</span></h2><p>包含分类数据的Series有一些特殊的方法，类似于Series.str字符串方法。它还提供了方便的分类和编码的使用方法。看下面的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: s = pd.Series([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>] * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: cat_s = s.astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: cat_s</span><br><span class="line">Out[<span class="number">62</span>]: </span><br><span class="line"><span class="number">0</span>    a</span><br><span class="line"><span class="number">1</span>    b</span><br><span class="line"><span class="number">2</span>    c</span><br><span class="line"><span class="number">3</span>    d</span><br><span class="line"><span class="number">4</span>    a</span><br><span class="line"><span class="number">5</span>    b</span><br><span class="line"><span class="number">6</span>    c</span><br><span class="line"><span class="number">7</span>    d</span><br><span class="line">dtype: category</span><br><span class="line">Categories (<span class="number">4</span>, <span class="built_in">object</span>): [a, b, c, d]</span><br></pre></td></tr></table></figure></p>
<p>特别的cat属性提供了分类方法的入口：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">63</span>]: cat_s.cat.codes</span><br><span class="line">Out[<span class="number">63</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1</span></span><br><span class="line"><span class="number">2</span>    <span class="number">2</span></span><br><span class="line"><span class="number">3</span>    <span class="number">3</span></span><br><span class="line"><span class="number">4</span>    <span class="number">0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">1</span></span><br><span class="line"><span class="number">6</span>    <span class="number">2</span></span><br><span class="line"><span class="number">7</span>    <span class="number">3</span></span><br><span class="line">dtype: int8</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: cat_s.cat.categories</span><br><span class="line">Out[<span class="number">64</span>]: Index([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>假设我们知道这个数据的实际分类集，超出了数据中的四个值。我们可以使用set_categories方法改变它们：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">65</span>]: actual_categories = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: cat_s2 = cat_s.cat.set_categories(actual_categories)</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: cat_s2</span><br><span class="line">Out[<span class="number">67</span>]: </span><br><span class="line"><span class="number">0</span>    a</span><br><span class="line"><span class="number">1</span>    b</span><br><span class="line"><span class="number">2</span>    c</span><br><span class="line"><span class="number">3</span>    d</span><br><span class="line"><span class="number">4</span>    a</span><br><span class="line"><span class="number">5</span>    b</span><br><span class="line"><span class="number">6</span>    c</span><br><span class="line"><span class="number">7</span>    d</span><br><span class="line">dtype: category</span><br><span class="line">Categories (<span class="number">5</span>, <span class="built_in">object</span>): [a, b, c, d, e]</span><br></pre></td></tr></table></figure></p>
<p>虽然数据看起来没变，新的分类将反映在它们的操作中。例如，如果有的话，value_counts表示分类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: cat_s.value_counts()</span><br><span class="line">Out[<span class="number">68</span>]: </span><br><span class="line">d    <span class="number">2</span></span><br><span class="line">c    <span class="number">2</span></span><br><span class="line">b    <span class="number">2</span></span><br><span class="line">a    <span class="number">2</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: cat_s2.value_counts()</span><br><span class="line">Out[<span class="number">69</span>]: </span><br><span class="line">d    <span class="number">2</span></span><br><span class="line">c    <span class="number">2</span></span><br><span class="line">b    <span class="number">2</span></span><br><span class="line">a    <span class="number">2</span></span><br><span class="line">e    <span class="number">0</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>在大数据集中，分类经常作为节省内存和高性能的便捷工具。过滤完大DataFrame或Series之后，许多分类可能不会出现在数据中。我们可以使用remove_unused_categories方法删除没看到的分类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">70</span>]: cat_s3 = cat_s[cat_s.isin([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])]</span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: cat_s3</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line"><span class="number">0</span>    a</span><br><span class="line"><span class="number">1</span>    b</span><br><span class="line"><span class="number">4</span>    a</span><br><span class="line"><span class="number">5</span>    b</span><br><span class="line">dtype: category</span><br><span class="line">Categories (<span class="number">4</span>, <span class="built_in">object</span>): [a, b, c, d]</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: cat_s3.cat.remove_unused_categories()</span><br><span class="line">Out[<span class="number">72</span>]: </span><br><span class="line"><span class="number">0</span>    a</span><br><span class="line"><span class="number">1</span>    b</span><br><span class="line"><span class="number">4</span>    a</span><br><span class="line"><span class="number">5</span>    b</span><br><span class="line">dtype: category</span><br><span class="line">Categories (<span class="number">2</span>, <span class="built_in">object</span>): [a, b]</span><br></pre></td></tr></table></figure></p>
<p>表12-1列出了可用的分类方法。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-6c602152c2bba658.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表12-1 pandas的Series的分类方法"></p>
<h2><span id="为建模创建虚拟变量">为建模创建虚拟变量</span></h2><p>当你使用统计或机器学习工具时，通常会将分类数据转换为虚拟变量，也称为one-hot编码。这包括创建一个不同类别的列的DataFrame；这些列包含给定分类的1s，其它为0。</p>
<p>看前面的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: cat_s = pd.Series([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>] * <span class="number">2</span>, dtype=<span class="string">&#x27;category&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>前面的第7章提到过，pandas.get_dummies函数可以转换这个分类数据为包含虚拟变量的DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: pd.get_dummies(cat_s)</span><br><span class="line">Out[<span class="number">74</span>]: </span><br><span class="line">   a  b  c  d</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">6</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span></span><br><span class="line"><span class="number">7</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="122-groupby高级应用">12.2 GroupBy高级应用</span></h1><p>尽管我们在第10章已经深度学习了Series和DataFrame的Groupby方法，还有一些方法也是很有用的。</p>
<h2><span id="分组转换和解封groupby">分组转换和“解封”GroupBy</span></h2><p>在第10章，我们在分组操作中学习了apply方法，进行转换。还有另一个transform方法，它与apply很像，但是对使用的函数有一定限制：</p>
<ul>
<li>它可以产生向分组形状广播标量值</li>
<li>它可以产生一个和输入组形状相同的对象</li>
<li>它不能修改输入</li>
</ul>
<p>来看一个简单的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>] * <span class="number">4</span>,</span><br><span class="line">   ....:                    <span class="string">&#x27;value&#x27;</span>: np.arange(<span class="number">12.</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: df</span><br><span class="line">Out[<span class="number">76</span>]: </span><br><span class="line">   key  value</span><br><span class="line"><span class="number">0</span>    a    <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>    b    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>    c    <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>    a    <span class="number">3.0</span></span><br><span class="line"><span class="number">4</span>    b    <span class="number">4.0</span></span><br><span class="line"><span class="number">5</span>    c    <span class="number">5.0</span></span><br><span class="line"><span class="number">6</span>    a    <span class="number">6.0</span></span><br><span class="line"><span class="number">7</span>    b    <span class="number">7.0</span></span><br><span class="line"><span class="number">8</span>    c    <span class="number">8.0</span></span><br><span class="line"><span class="number">9</span>    a    <span class="number">9.0</span></span><br><span class="line"><span class="number">10</span>   b   <span class="number">10.0</span></span><br><span class="line"><span class="number">11</span>   c   <span class="number">11.0</span></span><br></pre></td></tr></table></figure></p>
<p>按键进行分组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">77</span>]: g = df.groupby(<span class="string">&#x27;key&#x27;</span>).value</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: g.mean()</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line">key</span><br><span class="line">a    <span class="number">4.5</span></span><br><span class="line">b    <span class="number">5.5</span></span><br><span class="line">c    <span class="number">6.5</span></span><br><span class="line">Name: value, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>假设我们想产生一个和df[‘value’]形状相同的Series，但值替换为按键分组的平均值。我们可以传递函数lambda x: x.mean()进行转换：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">79</span>]: g.transform(<span class="keyword">lambda</span> x: x.mean())</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line"><span class="number">0</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">1</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">2</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">3</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">4</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">5</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">6</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">7</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">8</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">9</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">10</span>    <span class="number">5.5</span></span><br><span class="line"><span class="number">11</span>    <span class="number">6.5</span></span><br><span class="line">Name: value, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>对于内置的聚合函数，我们可以传递一个字符串假名作为GroupBy的agg方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">80</span>]: g.transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line"><span class="number">0</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">1</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">2</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">3</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">4</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">5</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">6</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">7</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">8</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">9</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">10</span>    <span class="number">5.5</span></span><br><span class="line"><span class="number">11</span>    <span class="number">6.5</span></span><br><span class="line">Name: value, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>与apply类似，transform的函数会返回Series，但是结果必须与输入大小相同。举个例子，我们可以用lambda函数将每个分组乘以2：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">81</span>]: g.transform(<span class="keyword">lambda</span> x: x * <span class="number">2</span>)</span><br><span class="line">Out[<span class="number">81</span>]: </span><br><span class="line"><span class="number">0</span>      <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>      <span class="number">2.0</span></span><br><span class="line"><span class="number">2</span>      <span class="number">4.0</span></span><br><span class="line"><span class="number">3</span>      <span class="number">6.0</span></span><br><span class="line"><span class="number">4</span>      <span class="number">8.0</span></span><br><span class="line"><span class="number">5</span>     <span class="number">10.0</span></span><br><span class="line"><span class="number">6</span>     <span class="number">12.0</span></span><br><span class="line"><span class="number">7</span>     <span class="number">14.0</span></span><br><span class="line"><span class="number">8</span>     <span class="number">16.0</span></span><br><span class="line"><span class="number">9</span>     <span class="number">18.0</span></span><br><span class="line"><span class="number">10</span>    <span class="number">20.0</span></span><br><span class="line"><span class="number">11</span>    <span class="number">22.0</span></span><br><span class="line">Name: value, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>再举一个复杂的例子，我们可以计算每个分组的降序排名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: g.transform(<span class="keyword">lambda</span> x: x.rank(ascending=<span class="literal">False</span>))</span><br><span class="line">Out[<span class="number">82</span>]: </span><br><span class="line"><span class="number">0</span>     <span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>     <span class="number">4.0</span></span><br><span class="line"><span class="number">2</span>     <span class="number">4.0</span></span><br><span class="line"><span class="number">3</span>     <span class="number">3.0</span></span><br><span class="line"><span class="number">4</span>     <span class="number">3.0</span></span><br><span class="line"><span class="number">5</span>     <span class="number">3.0</span></span><br><span class="line"><span class="number">6</span>     <span class="number">2.0</span></span><br><span class="line"><span class="number">7</span>     <span class="number">2.0</span></span><br><span class="line"><span class="number">8</span>     <span class="number">2.0</span></span><br><span class="line"><span class="number">9</span>     <span class="number">1.0</span></span><br><span class="line"><span class="number">10</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">11</span>    <span class="number">1.0</span></span><br><span class="line">Name: value, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>看一个由简单聚合构造的的分组转换函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (x - x.mean()) / x.std()</span><br></pre></td></tr></table></figure></p>
<p>我们用transform或apply可以获得等价的结果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">84</span>]: g.transform(normalize)</span><br><span class="line">Out[<span class="number">84</span>]: </span><br><span class="line"><span class="number">0</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">1</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">2</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">3</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">4</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">5</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">6</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">7</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">8</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">9</span>     <span class="number">1.161895</span></span><br><span class="line"><span class="number">10</span>    <span class="number">1.161895</span></span><br><span class="line"><span class="number">11</span>    <span class="number">1.161895</span></span><br><span class="line">Name: value, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: g.apply(normalize)</span><br><span class="line">Out[<span class="number">85</span>]: </span><br><span class="line"><span class="number">0</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">1</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">2</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">3</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">4</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">5</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">6</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">7</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">8</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">9</span>     <span class="number">1.161895</span></span><br><span class="line"><span class="number">10</span>    <span class="number">1.161895</span></span><br><span class="line"><span class="number">11</span>    <span class="number">1.161895</span></span><br><span class="line">Name: value, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>内置的聚合函数，比如mean或sum，通常比apply函数快，也比transform快。这允许我们进行一个所谓的解封（unwrapped）分组操作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">86</span>]: g.transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line"><span class="number">0</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">1</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">2</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">3</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">4</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">5</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">6</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">7</span>     <span class="number">5.5</span></span><br><span class="line"><span class="number">8</span>     <span class="number">6.5</span></span><br><span class="line"><span class="number">9</span>     <span class="number">4.5</span></span><br><span class="line"><span class="number">10</span>    <span class="number">5.5</span></span><br><span class="line"><span class="number">11</span>    <span class="number">6.5</span></span><br><span class="line">Name: value, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: normalized = (df[<span class="string">&#x27;value&#x27;</span>] - g.transform(<span class="string">&#x27;mean&#x27;</span>)) / g.transform(<span class="string">&#x27;std&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: normalized</span><br><span class="line">Out[<span class="number">88</span>]: </span><br><span class="line"><span class="number">0</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">1</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">2</span>    -<span class="number">1.161895</span></span><br><span class="line"><span class="number">3</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">4</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">5</span>    -<span class="number">0.387298</span></span><br><span class="line"><span class="number">6</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">7</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">8</span>     <span class="number">0.387298</span></span><br><span class="line"><span class="number">9</span>     <span class="number">1.161895</span></span><br><span class="line"><span class="number">10</span>    <span class="number">1.161895</span></span><br><span class="line"><span class="number">11</span>    <span class="number">1.161895</span></span><br><span class="line">Name: value, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>解封分组操作可能包括多个分组聚合，但是矢量化操作还是会带来收益。</p>
<h2><span id="分组的时间重采样">分组的时间重采样</span></h2><p>对于时间序列数据，resample方法从语义上是一个基于内在时间的分组操作。下面是一个示例表：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">89</span>]: N = <span class="number">15</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: times = pd.date_range(<span class="string">&#x27;2017-05-20 00:00&#x27;</span>, freq=<span class="string">&#x27;1min&#x27;</span>, periods=N)</span><br><span class="line"></span><br><span class="line">In [<span class="number">91</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;time&#x27;</span>: times,</span><br><span class="line">   ....:                    <span class="string">&#x27;value&#x27;</span>: np.arange(N)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: df</span><br><span class="line">Out[<span class="number">92</span>]: </span><br><span class="line">                  time  value</span><br><span class="line"><span class="number">0</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>      <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:01:<span class="number">00</span>      <span class="number">1</span></span><br><span class="line"><span class="number">2</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:02:<span class="number">00</span>      <span class="number">2</span></span><br><span class="line"><span class="number">3</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:03:<span class="number">00</span>      <span class="number">3</span></span><br><span class="line"><span class="number">4</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:04:<span class="number">00</span>      <span class="number">4</span></span><br><span class="line"><span class="number">5</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>      <span class="number">5</span></span><br><span class="line"><span class="number">6</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:06:<span class="number">00</span>      <span class="number">6</span></span><br><span class="line"><span class="number">7</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:07:<span class="number">00</span>      <span class="number">7</span></span><br><span class="line"><span class="number">8</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:08:<span class="number">00</span>      <span class="number">8</span></span><br><span class="line"><span class="number">9</span>  <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:09:<span class="number">00</span>      <span class="number">9</span></span><br><span class="line"><span class="number">10</span> <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>     <span class="number">10</span></span><br><span class="line"><span class="number">11</span> <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">11</span>:<span class="number">00</span>     <span class="number">11</span></span><br><span class="line"><span class="number">12</span> <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">12</span>:<span class="number">00</span>     <span class="number">12</span></span><br><span class="line"><span class="number">13</span> <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">13</span>:<span class="number">00</span>     <span class="number">13</span></span><br><span class="line"><span class="number">14</span> <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">14</span>:<span class="number">00</span>     <span class="number">14</span></span><br></pre></td></tr></table></figure></p>
<p>这里，我们可以用time作为索引，然后重采样：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">93</span>]: df.set_index(<span class="string">&#x27;time&#x27;</span>).resample(<span class="string">&#x27;5min&#x27;</span>).count()</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line">                     value</span><br><span class="line">time                      </span><br><span class="line"><span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>      <span class="number">5</span></span><br><span class="line"><span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>      <span class="number">5</span></span><br><span class="line"><span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>      <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p>假设DataFrame包含多个时间序列，用一个额外的分组键的列进行标记：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: df2 = pd.DataFrame(&#123;<span class="string">&#x27;time&#x27;</span>: times.repeat(<span class="number">3</span>),</span><br><span class="line">   ....:                     <span class="string">&#x27;key&#x27;</span>: np.tile([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], N),</span><br><span class="line">   ....:                     <span class="string">&#x27;value&#x27;</span>: np.arange(N * <span class="number">3.</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">95</span>]: df2[:<span class="number">7</span>]</span><br><span class="line">Out[<span class="number">95</span>]: </span><br><span class="line">  key                time  value</span><br><span class="line"><span class="number">0</span>   a <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>   b <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>   c <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>   a <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:01:<span class="number">00</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">4</span>   b <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:01:<span class="number">00</span>    <span class="number">4.0</span></span><br><span class="line"><span class="number">5</span>   c <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:01:<span class="number">00</span>    <span class="number">5.0</span></span><br><span class="line"><span class="number">6</span>   a <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:02:<span class="number">00</span>    <span class="number">6.0</span></span><br></pre></td></tr></table></figure></p>
<p>要对每个key值进行相同的重采样，我们引入pandas.TimeGrouper对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: time_key = pd.TimeGrouper(<span class="string">&#x27;5min&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>我们然后设定时间索引，用key和time_key分组，然后聚合：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">97</span>]: resampled = (df2.set_index(<span class="string">&#x27;time&#x27;</span>)</span><br><span class="line">   ....:              .groupby([<span class="string">&#x27;key&#x27;</span>, time_key])</span><br><span class="line">   ....:              .<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: resampled</span><br><span class="line">Out[<span class="number">98</span>]: </span><br><span class="line">                         value</span><br><span class="line">key time                      </span><br><span class="line">a   <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>   <span class="number">30.0</span></span><br><span class="line">    <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>  <span class="number">105.0</span></span><br><span class="line">    <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>  <span class="number">180.0</span></span><br><span class="line">b   <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>   <span class="number">35.0</span></span><br><span class="line">    <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>  <span class="number">110.0</span></span><br><span class="line">    <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>  <span class="number">185.0</span></span><br><span class="line">c   <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>   <span class="number">40.0</span></span><br><span class="line">    <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>  <span class="number">115.0</span></span><br><span class="line">    <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>  <span class="number">190.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: resampled.reset_index()</span><br><span class="line">Out[<span class="number">99</span>]:</span><br><span class="line">key                time  value</span><br><span class="line"><span class="number">0</span>   a <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>   <span class="number">30.0</span></span><br><span class="line"><span class="number">1</span>   a <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>  <span class="number">105.0</span></span><br><span class="line"><span class="number">2</span>   a <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>  <span class="number">180.0</span></span><br><span class="line"><span class="number">3</span>   b <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>   <span class="number">35.0</span></span><br><span class="line"><span class="number">4</span>   b <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>  <span class="number">110.0</span></span><br><span class="line"><span class="number">5</span>   b <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>  <span class="number">185.0</span></span><br><span class="line"><span class="number">6</span>   c <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>   <span class="number">40.0</span></span><br><span class="line"><span class="number">7</span>   c <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:05:<span class="number">00</span>  <span class="number">115.0</span></span><br><span class="line"><span class="number">8</span>   c <span class="number">2017</span>-05-<span class="number">20</span> <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>  <span class="number">190.0</span></span><br></pre></td></tr></table></figure></p>
<p>使用TimeGrouper的限制是时间必须是Series或DataFrame的索引。</p>
<h1><span id="123-链式编程技术">12.3 链式编程技术</span></h1><p>当对数据集进行一系列变换时，你可能发现创建的多个临时变量其实并没有在分析中用到。看下面的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = load_data()</span><br><span class="line">df2 = df[df[<span class="string">&#x27;col2&#x27;</span>] &lt; <span class="number">0</span>]</span><br><span class="line">df2[<span class="string">&#x27;col1_demeaned&#x27;</span>] = df2[<span class="string">&#x27;col1&#x27;</span>] - df2[<span class="string">&#x27;col1&#x27;</span>].mean()</span><br><span class="line">result = df2.groupby(<span class="string">&#x27;key&#x27;</span>).col1_demeaned.std()</span><br></pre></td></tr></table></figure></p>
<p>虽然这里没有使用真实的数据，这个例子却指出了一些新方法。首先，DataFrame.assign方法是一个df[k] = v形式的函数式的列分配方法。它不是就地修改对象，而是返回新的修改过的DataFrame。因此，下面的语句是等价的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Usual non-functional way</span></span><br><span class="line">df2 = df.copy()</span><br><span class="line">df2[<span class="string">&#x27;k&#x27;</span>] = v</span><br><span class="line"></span><br><span class="line"><span class="comment"># Functional assign way</span></span><br><span class="line">df2 = df.assign(k=v)</span><br></pre></td></tr></table></figure></p>
<p>就地分配可能会比assign快，但是assign可以方便地进行链式编程：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = (df2.assign(col1_demeaned=df2.col1 - df2.col2.mean())</span><br><span class="line">          .groupby(<span class="string">&#x27;key&#x27;</span>)</span><br><span class="line">          .col1_demeaned.std())</span><br></pre></td></tr></table></figure></p>
<p>我使用外括号，这样便于添加换行符。</p>
<p>使用链式编程时要注意，你可能会需要涉及临时对象。在前面的例子中，我们不能使用load_data的结果，直到它被赋值给临时变量df。为了这么做，assign和许多其它pandas函数可以接收类似函数的参数，即可调用对象（callable）。为了展示可调用对象，看一个前面例子的片段：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = load_data()</span><br><span class="line">df2 = df[df[<span class="string">&#x27;col2&#x27;</span>] &lt; <span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>它可以重写为：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = (load_data()</span><br><span class="line">      [<span class="keyword">lambda</span> x: x[<span class="string">&#x27;col2&#x27;</span>] &lt; <span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<p>这里，load_data的结果没有赋值给某个变量，因此传递到[ ]的函数在这一步被绑定到了对象。</p>
<p>我们可以把整个过程写为一个单链表达式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = (load_data()</span><br><span class="line">          [<span class="keyword">lambda</span> x: x.col2 &lt; <span class="number">0</span>]</span><br><span class="line">          .assign(col1_demeaned=<span class="keyword">lambda</span> x: x.col1 - x.col1.mean())</span><br><span class="line">          .groupby(<span class="string">&#x27;key&#x27;</span>)</span><br><span class="line">          .col1_demeaned.std())</span><br></pre></td></tr></table></figure></p>
<p>是否将代码写成这种形式只是习惯而已，将它分开成若干步可以提高可读性。</p>
<h2><span id="管道方法">管道方法</span></h2><p>你可以用Python内置的pandas函数和方法，用带有可调用对象的链式编程做许多工作。但是，有时你需要使用自己的函数，或是第三方库的函数。这时就要用到管道方法。</p>
<p>看下面的函数调用：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = f(df, arg1=v1)</span><br><span class="line">b = g(a, v2, arg3=v3)</span><br><span class="line">c = h(b, arg4=v4)</span><br></pre></td></tr></table></figure></p>
<p>当使用接收、返回Series或DataFrame对象的函数式，你可以调用pipe将其重写：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = (df.pipe(f, arg1=v1)</span><br><span class="line">          .pipe(g, v2, arg3=v3)</span><br><span class="line">          .pipe(h, arg4=v4))</span><br></pre></td></tr></table></figure></p>
<p>f(df)和df.pipe(f)是等价的，但是pipe使得链式声明更容易。</p>
<p>pipe的另一个有用的地方是提炼操作为可复用的函数。看一个从列减去分组方法的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = df.groupby([<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])</span><br><span class="line">df[<span class="string">&#x27;col1&#x27;</span>] = df[<span class="string">&#x27;col1&#x27;</span>] - g.transform(<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>假设你想转换多列，并修改分组的键。另外，你想用链式编程做这个转换。下面就是一个方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">group_demean</span>(<span class="params">df, by, cols</span>):</span></span><br><span class="line">    result = df.copy()</span><br><span class="line">    g = df.groupby(by)</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> cols:</span><br><span class="line">        result[c] = df[c] - g[c].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<p>然后可以写为：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = (df[df.col1 &lt; <span class="number">0</span>]</span><br><span class="line">          .pipe(group_demean, [<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>], [<span class="string">&#x27;col1&#x27;</span>]))</span><br></pre></td></tr></table></figure></p>
<h1><span id="124-总结">12.4 总结</span></h1><p>和其它许多开源项目一样，pandas仍然在不断的变化和进步中。和本书中其它地方一样，这里的重点是放在接下来几年不会发生什么改变且稳定的功能。</p>
<p>为了深入学习pandas的知识，我建议你学习官方文档，并阅读开发团队发布的文档更新。我们还邀请你加入pandas的开发工作：修改bug、创建新功能、完善文档。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-11.时间序列</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-11-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>时间序列（time series）数据是一种重要的结构化数据形式，应用于多个领域，包括金融学、经济学、生态学、神经科学、物理学等。在多个时间点观察或测量到的任何事物都可以形成一段时间序列。很多时间序列是固定频率的，也就是说，数据点是根据某种规律定期出现的（比如每15秒、每5分钟、每月出现一次）。时间序列也可以是不定期的，没有固定的时间单位或单位之间的偏移量。时间序列数据的意义取决于具体的应用场景，主要有以下几种：</p>
<span id="more"></span>
<ul>
<li>时间戳（timestamp），特定的时刻。</li>
<li>固定时期（period），如2007年1月或2010年全年。</li>
<li>时间间隔（interval），由起始和结束时间戳表示。时期（period）可以被看做间隔（interval）的特例。</li>
<li>实验或过程时间，每个时间点都是相对于特定起始时间的一个度量。例如，从放入烤箱时起，每秒钟饼干的直径。</li>
</ul>
<p>本章主要讲解前3种时间序列。许多技术都可用于处理实验型时间序列，其索引可能是一个整数或浮点数（表示从实验开始算起已经过去的时间）。最简单也最常见的时间序列都是用时间戳进行索引的。</p>
<blockquote>
<p>提示：pandas也支持基于timedeltas的指数，它可以有效代表实验或经过的时间。这本书不涉及timedelta指数，但你可以学习pandas的文档（<a href="http://pandas.pydata.org/）。">http://pandas.pydata.org/）。</a></p>
</blockquote>
<p>pandas提供了许多内置的时间序列处理工具和数据算法。因此，你可以高效处理非常大的时间序列，轻松地进行切片/切块、聚合、对定期/不定期的时间序列进行重采样等。有些工具特别适合金融和经济应用，你当然也可以用它们来分析服务器日志数据。</p>
<h1><span id="111-日期和时间数据类型及工具">11.1 日期和时间数据类型及工具</span></h1><p>Python标准库包含用于日期（date）和时间（time）数据的数据类型，而且还有日历方面的功能。我们主要会用到datetime、time以及calendar模块。datetime.datetime（也可以简写为datetime）是用得最多的数据类型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: <span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: now = datetime.now()</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: now</span><br><span class="line">Out[<span class="number">12</span>]: datetime.datetime(<span class="number">2017</span>, <span class="number">9</span>, <span class="number">25</span>, <span class="number">14</span>, <span class="number">5</span>, <span class="number">52</span>, <span class="number">72973</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: now.year, now.month, now.day</span><br><span class="line">Out[<span class="number">13</span>]: (<span class="number">2017</span>, <span class="number">9</span>, <span class="number">25</span>)</span><br></pre></td></tr></table></figure>
<p>datetime以毫秒形式存储日期和时间。timedelta表示两个datetime对象之间的时间差：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">14</span>]: delta = datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">7</span>) - datetime(<span class="number">2008</span>, <span class="number">6</span>, <span class="number">24</span>, <span class="number">8</span>, <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: delta</span><br><span class="line">Out[<span class="number">15</span>]: datetime.timedelta(<span class="number">926</span>, <span class="number">56700</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: delta.days</span><br><span class="line">Out[<span class="number">16</span>]: <span class="number">926</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: delta.seconds</span><br><span class="line">Out[<span class="number">17</span>]: <span class="number">56700</span></span><br></pre></td></tr></table></figure>
<p>可以给datetime对象加上（或减去）一个或多个timedelta，这样会产生一个新对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: <span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: start = datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: start + timedelta(<span class="number">12</span>)</span><br><span class="line">Out[<span class="number">20</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">19</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: start - <span class="number">2</span> * timedelta(<span class="number">12</span>)</span><br><span class="line">Out[<span class="number">21</span>]: datetime.datetime(<span class="number">2010</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>datetime模块中的数据类型参见表10-1。虽然本章主要讲的是pandas数据类型和高级时间序列处理，但你肯定会在Python的其他地方遇到有关datetime的数据类型。</p>
<p>表11-1 datetime模块中的数据类型</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-4af261a305a70aeb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>tzinfo  存储时区信息的基本类型</p>
<h2><span id="字符串和datetime的相互转换">字符串和datetime的相互转换</span></h2><p>利用str或strftime方法（传入一个格式化字符串），datetime对象和pandas的Timestamp对象（稍后就会介绍）可以被格式化为字符串：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">22</span>]: stamp = datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: <span class="built_in">str</span>(stamp)</span><br><span class="line">Out[<span class="number">23</span>]: <span class="string">&#x27;2011-01-03 00:00:00&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: stamp.strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">Out[<span class="number">24</span>]: <span class="string">&#x27;2011-01-03&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>表11-2列出了全部的格式化编码。</p>
<p>表11-2 datetime格式定义（兼容ISO C89）</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-50c751823754df58.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-de0181e1f6b45eaf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>datetime.strptime可以用这些格式化编码将字符串转换为日期：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">25</span>]: value = <span class="string">&#x27;2011-01-03&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: datetime.strptime(value, <span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">Out[<span class="number">26</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: datestrs = [<span class="string">&#x27;7/6/2011&#x27;</span>, <span class="string">&#x27;8/6/2011&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: [datetime.strptime(x, <span class="string">&#x27;%m/%d/%Y&#x27;</span>) <span class="keyword">for</span> x <span class="keyword">in</span> datestrs]</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">[datetime.datetime(<span class="number">2011</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line"> datetime.datetime(<span class="number">2011</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>)]</span><br></pre></td></tr></table></figure></p>
<p>datetime.strptime是通过已知格式进行日期解析的最佳方式。但是每次都要编写格式定义是很麻烦的事情，尤其是对于一些常见的日期格式。这种情况下，你可以用dateutil这个第三方包中的parser.parse方法（pandas中已经自动安装好了）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: <span class="keyword">from</span> dateutil.parser <span class="keyword">import</span> parse</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: parse(<span class="string">&#x27;2011-01-03&#x27;</span>)</span><br><span class="line">Out[<span class="number">30</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><br>dateutil可以解析几乎所有人类能够理解的日期表示形式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">31</span>]: parse(<span class="string">&#x27;Jan 31, 1997 10:45 PM&#x27;</span>)</span><br><span class="line">Out[<span class="number">31</span>]: datetime.datetime(<span class="number">1997</span>, <span class="number">1</span>, <span class="number">31</span>, <span class="number">22</span>, <span class="number">45</span>)</span><br></pre></td></tr></table></figure>
<p>在国际通用的格式中，日出现在月的前面很普遍，传入dayfirst=True即可解决这个问题：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: parse(<span class="string">&#x27;6/12/2011&#x27;</span>, dayfirst=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">32</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">12</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>pandas通常是用于处理成组日期的，不管这些日期是DataFrame的轴索引还是列。to_datetime方法可以解析多种不同的日期表示形式。对标准日期格式（如ISO8601）的解析非常快：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: datestrs = [<span class="string">&#x27;2011-07-06 12:00:00&#x27;</span>, <span class="string">&#x27;2011-08-06 00:00:00&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: pd.to_datetime(datestrs)</span><br><span class="line">Out[<span class="number">34</span>]: DatetimeIndex([<span class="string">&#x27;2011-07-06 12:00:00&#x27;</span>, <span class="string">&#x27;2011-08-06 00:00:00&#x27;</span>], dtype=<span class="string">&#x27;dat</span></span><br><span class="line"><span class="string">etime64[ns]&#x27;</span>, freq=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>它还可以处理缺失值（None、空字符串等）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: idx = pd.to_datetime(datestrs + [<span class="literal">None</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: idx</span><br><span class="line">Out[<span class="number">36</span>]: DatetimeIndex([<span class="string">&#x27;2011-07-06 12:00:00&#x27;</span>, <span class="string">&#x27;2011-08-06 00:00:00&#x27;</span>, <span class="string">&#x27;NaT&#x27;</span>], dty</span><br><span class="line">pe=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: idx[<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">37</span>]: NaT</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: pd.isnull(idx)</span><br><span class="line">Out[<span class="number">38</span>]: array([<span class="literal">False</span>, <span class="literal">False</span>,  <span class="literal">True</span>], dtype=<span class="built_in">bool</span>)</span><br></pre></td></tr></table></figure></p>
<p>NaT（Not a Time）是pandas中时间戳数据的null值。</p>
<blockquote>
<p>注意：dateutil.parser是一个实用但不完美的工具。比如说，它会把一些原本不是日期的字符串认作是日期（比如”42”会被解析为2042年的今天）。</p>
</blockquote>
<p>datetime对象还有一些特定于当前环境（位于不同国家或使用不同语言的系统）的格式化选项。例如，德语或法语系统所用的月份简写就与英语系统所用的不同。表11-3进行了总结。</p>
<p>表11-3 特定于当前环境的日期格式</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-cf0119398273e2b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h1><span id="112-时间序列基础">11.2 时间序列基础</span></h1><p>pandas最基本的时间序列类型就是以时间戳（通常以Python字符串或datatime对象表示）为索引的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: <span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: dates = [datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">2</span>), datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">5</span>),</span><br><span class="line">   ....:          datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">7</span>), datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">8</span>),</span><br><span class="line">   ....:          datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">10</span>), datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">12</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: ts = pd.Series(np.random.randn(<span class="number">6</span>), index=dates)</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: ts</span><br><span class="line">Out[<span class="number">42</span>]: </span><br><span class="line"><span class="number">2011</span>-01-02   -<span class="number">0.204708</span></span><br><span class="line"><span class="number">2011</span>-01-05    <span class="number">0.478943</span></span><br><span class="line"><span class="number">2011</span>-01-07   -<span class="number">0.519439</span></span><br><span class="line"><span class="number">2011</span>-01-08   -<span class="number">0.555730</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">10</span>    <span class="number">1.965781</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">12</span>    <span class="number">1.393406</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这些datetime对象实际上是被放在一个DatetimeIndex中的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">43</span>]: ts.index</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2011-01-02&#x27;</span>, <span class="string">&#x27;2011-01-05&#x27;</span>, <span class="string">&#x27;2011-01-07&#x27;</span>, <span class="string">&#x27;2011-01-08&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2011-01-10&#x27;</span>, <span class="string">&#x27;2011-01-12&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure></p>
<p>跟其他Series一样，不同索引的时间序列之间的算术运算会自动按日期对齐：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: ts + ts[::<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line"><span class="number">2011</span>-01-02   -<span class="number">0.409415</span></span><br><span class="line"><span class="number">2011</span>-01-05         NaN</span><br><span class="line"><span class="number">2011</span>-01-07   -<span class="number">1.038877</span></span><br><span class="line"><span class="number">2011</span>-01-08         NaN</span><br><span class="line"><span class="number">2011</span>-01-<span class="number">10</span>    <span class="number">3.931561</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">12</span>         NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>ts[::2] 是每隔两个取一个。</p>
<p>pandas用NumPy的datetime64数据类型以纳秒形式存储时间戳：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: ts.index.dtype</span><br><span class="line">Out[<span class="number">45</span>]: dtype(<span class="string">&#x27;&lt;M8[ns]&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>DatetimeIndex中的各个标量值是pandas的Timestamp对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">46</span>]: stamp = ts.index[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: stamp</span><br><span class="line">Out[<span class="number">47</span>]: Timestamp(<span class="string">&#x27;2011-01-02 00:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>只要有需要，TimeStamp可以随时自动转换为datetime对象。此外，它还可以存储频率信息（如果有的话），且知道如何执行时区转换以及其他操作。稍后将对此进行详细讲解。</p>
<h2><span id="索引-选取-子集构造">索引、选取、子集构造</span></h2><p>当你根据标签索引选取数据时，时间序列和其它的pandas.Series很像：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: stamp = ts.index[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: ts[stamp]</span><br><span class="line">Out[<span class="number">49</span>]: -<span class="number">0.51943871505673811</span></span><br></pre></td></tr></table></figure></p>
<p>还有一种更为方便的用法：传入一个可以被解释为日期的字符串：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: ts[<span class="string">&#x27;1/10/2011&#x27;</span>]</span><br><span class="line">Out[<span class="number">50</span>]: <span class="number">1.9657805725027142</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: ts[<span class="string">&#x27;20110110&#x27;</span>]</span><br><span class="line">Out[<span class="number">51</span>]: <span class="number">1.9657805725027142</span></span><br></pre></td></tr></table></figure></p>
<p>对于较长的时间序列，只需传入“年”或“年月”即可轻松选取数据的切片：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">52</span>]: longer_ts = pd.Series(np.random.randn(<span class="number">1000</span>),</span><br><span class="line">   ....:                       index=pd.date_range(<span class="string">&#x27;1/1/2000&#x27;</span>, periods=<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: longer_ts</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line"><span class="number">2000</span>-01-01    <span class="number">0.092908</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">0.281746</span></span><br><span class="line"><span class="number">2000</span>-01-03    <span class="number">0.769023</span></span><br><span class="line"><span class="number">2000</span>-01-04    <span class="number">1.246435</span></span><br><span class="line"><span class="number">2000</span>-01-05    <span class="number">1.007189</span></span><br><span class="line"><span class="number">2000</span>-01-06   -<span class="number">1.296221</span></span><br><span class="line"><span class="number">2000</span>-01-07    <span class="number">0.274992</span></span><br><span class="line"><span class="number">2000</span>-01-08    <span class="number">0.228913</span></span><br><span class="line"><span class="number">2000</span>-01-09    <span class="number">1.352917</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">10</span>    <span class="number">0.886429</span></span><br><span class="line">                ...   </span><br><span class="line"><span class="number">2002</span>-09-<span class="number">17</span>   -<span class="number">0.139298</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">18</span>   -<span class="number">1.159926</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">19</span>    <span class="number">0.618965</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">20</span>    <span class="number">1.373890</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">21</span>   -<span class="number">0.983505</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">22</span>    <span class="number">0.930944</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">23</span>   -<span class="number">0.811676</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">24</span>   -<span class="number">1.830156</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">25</span>   -<span class="number">0.138730</span></span><br><span class="line"><span class="number">2002</span>-09-<span class="number">26</span>    <span class="number">0.334088</span></span><br><span class="line">Freq: D, Length: <span class="number">1000</span>, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: longer_ts[<span class="string">&#x27;2001&#x27;</span>]</span><br><span class="line">Out[<span class="number">54</span>]: </span><br><span class="line"><span class="number">2001</span>-01-01    <span class="number">1.599534</span></span><br><span class="line"><span class="number">2001</span>-01-02    <span class="number">0.474071</span></span><br><span class="line"><span class="number">2001</span>-01-03    <span class="number">0.151326</span></span><br><span class="line"><span class="number">2001</span>-01-04   -<span class="number">0.542173</span></span><br><span class="line"><span class="number">2001</span>-01-05   -<span class="number">0.475496</span></span><br><span class="line"><span class="number">2001</span>-01-06    <span class="number">0.106403</span></span><br><span class="line"><span class="number">2001</span>-01-07   -<span class="number">1.308228</span></span><br><span class="line"><span class="number">2001</span>-01-08    <span class="number">2.173185</span></span><br><span class="line"><span class="number">2001</span>-01-09    <span class="number">0.564561</span></span><br><span class="line"><span class="number">2001</span>-01-<span class="number">10</span>   -<span class="number">0.190481</span></span><br><span class="line">                ...   </span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">22</span>    <span class="number">0.000369</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">23</span>    <span class="number">0.900885</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">24</span>   -<span class="number">0.454869</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">25</span>   -<span class="number">0.864547</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">26</span>    <span class="number">1.129120</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">27</span>    <span class="number">0.057874</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">28</span>   -<span class="number">0.433739</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">29</span>    <span class="number">0.092698</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">30</span>   -<span class="number">1.397820</span></span><br><span class="line"><span class="number">2001</span>-<span class="number">12</span>-<span class="number">31</span>    <span class="number">1.457823</span></span><br><span class="line">Freq: D, Length: <span class="number">365</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这里，字符串“2001”被解释成年，并根据它选取时间区间。指定月也同样奏效：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">55</span>]: longer_ts[<span class="string">&#x27;2001-05&#x27;</span>]</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line"><span class="number">2001</span>-05-01   -<span class="number">0.622547</span></span><br><span class="line"><span class="number">2001</span>-05-02    <span class="number">0.936289</span></span><br><span class="line"><span class="number">2001</span>-05-03    <span class="number">0.750018</span></span><br><span class="line"><span class="number">2001</span>-05-04   -<span class="number">0.056715</span></span><br><span class="line"><span class="number">2001</span>-05-05    <span class="number">2.300675</span></span><br><span class="line"><span class="number">2001</span>-05-06    <span class="number">0.569497</span></span><br><span class="line"><span class="number">2001</span>-05-07    <span class="number">1.489410</span></span><br><span class="line"><span class="number">2001</span>-05-08    <span class="number">1.264250</span></span><br><span class="line"><span class="number">2001</span>-05-09   -<span class="number">0.761837</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">10</span>   -<span class="number">0.331617</span></span><br><span class="line">                ...   </span><br><span class="line"><span class="number">2001</span>-05-<span class="number">22</span>    <span class="number">0.503699</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">23</span>   -<span class="number">1.387874</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">24</span>    <span class="number">0.204851</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">25</span>    <span class="number">0.603705</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">26</span>    <span class="number">0.545680</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">27</span>    <span class="number">0.235477</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">28</span>    <span class="number">0.111835</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">29</span>   -<span class="number">1.251504</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">30</span>   -<span class="number">2.949343</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">31</span>    <span class="number">0.634634</span></span><br><span class="line">Freq: D, Length: <span class="number">31</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>datetime对象也可以进行切片：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: ts[datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">7</span>):]</span><br><span class="line">Out[<span class="number">56</span>]: </span><br><span class="line"><span class="number">2011</span>-01-07   -<span class="number">0.519439</span></span><br><span class="line"><span class="number">2011</span>-01-08   -<span class="number">0.555730</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">10</span>    <span class="number">1.965781</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">12</span>    <span class="number">1.393406</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>由于大部分时间序列数据都是按照时间先后排序的，因此你也可以用不存在于该时间序列中的时间戳对其进行切片（即范围查询）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: ts</span><br><span class="line">Out[<span class="number">57</span>]: </span><br><span class="line"><span class="number">2011</span>-01-02   -<span class="number">0.204708</span></span><br><span class="line"><span class="number">2011</span>-01-05    <span class="number">0.478943</span></span><br><span class="line"><span class="number">2011</span>-01-07   -<span class="number">0.519439</span></span><br><span class="line"><span class="number">2011</span>-01-08   -<span class="number">0.555730</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">10</span>    <span class="number">1.965781</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">12</span>    <span class="number">1.393406</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: ts[<span class="string">&#x27;1/6/2011&#x27;</span>:<span class="string">&#x27;1/11/2011&#x27;</span>]</span><br><span class="line">Out[<span class="number">58</span>]: </span><br><span class="line"><span class="number">2011</span>-01-07   -<span class="number">0.519439</span></span><br><span class="line"><span class="number">2011</span>-01-08   -<span class="number">0.555730</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">10</span>    <span class="number">1.965781</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>跟之前一样，你可以传入字符串日期、datetime或Timestamp。注意，这样切片所产生的是原时间序列的视图，跟NumPy数组的切片运算是一样的。</p>
<p>这意味着，没有数据被复制，对切片进行修改会反映到原始数据上。</p>
<p>此外，还有一个等价的实例方法也可以截取两个日期之间TimeSeries：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">59</span>]: ts.truncate(after=<span class="string">&#x27;1/9/2011&#x27;</span>)</span><br><span class="line">Out[<span class="number">59</span>]: </span><br><span class="line"><span class="number">2011</span>-01-02   -<span class="number">0.204708</span></span><br><span class="line"><span class="number">2011</span>-01-05    <span class="number">0.478943</span></span><br><span class="line"><span class="number">2011</span>-01-07   -<span class="number">0.519439</span></span><br><span class="line"><span class="number">2011</span>-01-08   -<span class="number">0.555730</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>面这些操作对DataFrame也有效。例如，对DataFrame的行进行索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: dates = pd.date_range(<span class="string">&#x27;1/1/2000&#x27;</span>, periods=<span class="number">100</span>, freq=<span class="string">&#x27;W-WED&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: long_df = pd.DataFrame(np.random.randn(<span class="number">100</span>, <span class="number">4</span>),</span><br><span class="line">   ....:                        index=dates,</span><br><span class="line">   ....:                        columns=[<span class="string">&#x27;Colorado&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>,</span><br><span class="line">   ....:                                 <span class="string">&#x27;New York&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: long_df.loc[<span class="string">&#x27;5-2001&#x27;</span>]</span><br><span class="line">Out[<span class="number">62</span>]: </span><br><span class="line">            Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2001</span>-05-02 -<span class="number">0.006045</span>  <span class="number">0.490094</span> -<span class="number">0.277186</span> -<span class="number">0.707213</span></span><br><span class="line"><span class="number">2001</span>-05-09 -<span class="number">0.560107</span>  <span class="number">2.735527</span>  <span class="number">0.927335</span>  <span class="number">1.513906</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">16</span>  <span class="number">0.538600</span>  <span class="number">1.273768</span>  <span class="number">0.667876</span> -<span class="number">0.969206</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">23</span>  <span class="number">1.676091</span> -<span class="number">0.817649</span>  <span class="number">0.050188</span>  <span class="number">1.951312</span></span><br><span class="line"><span class="number">2001</span>-05-<span class="number">30</span>  <span class="number">3.260383</span>  <span class="number">0.963301</span>  <span class="number">1.201206</span> -<span class="number">1.852001</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="带有重复索引的时间序列">带有重复索引的时间序列</span></h2><p>在某些应用场景中，可能会存在多个观测数据落在同一个时间点上的情况。下面就是一个例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">63</span>]: dates = pd.DatetimeIndex([<span class="string">&#x27;1/1/2000&#x27;</span>, <span class="string">&#x27;1/2/2000&#x27;</span>, <span class="string">&#x27;1/2/2000&#x27;</span>,</span><br><span class="line">   ....:                           <span class="string">&#x27;1/2/2000&#x27;</span>, <span class="string">&#x27;1/3/2000&#x27;</span>])</span><br><span class="line">In [<span class="number">64</span>]: dup_ts = pd.Series(np.arange(<span class="number">5</span>), index=dates)</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: dup_ts</span><br><span class="line">Out[<span class="number">65</span>]: </span><br><span class="line"><span class="number">2000</span>-01-01    <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">1</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">2</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">3</span></span><br><span class="line"><span class="number">2000</span>-01-03    <span class="number">4</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>通过检查索引的is_unique属性，我们就可以知道它是不是唯一的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: dup_ts.index.is_unique</span><br><span class="line">Out[<span class="number">66</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>对这个时间序列进行索引，要么产生标量值，要么产生切片，具体要看所选的时间点是否重复：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">67</span>]: dup_ts[<span class="string">&#x27;1/3/2000&#x27;</span>]  <span class="comment"># not duplicated</span></span><br><span class="line">Out[<span class="number">67</span>]: <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">68</span>]: dup_ts[<span class="string">&#x27;1/2/2000&#x27;</span>]  <span class="comment"># duplicated</span></span><br><span class="line">Out[<span class="number">68</span>]: </span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">1</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">2</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">3</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>假设你想要对具有非唯一时间戳的数据进行聚合。一个办法是使用groupby，并传入level=0：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: grouped = dup_ts.groupby(level=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: grouped.mean()</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line"><span class="number">2000</span>-01-01    <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">2</span></span><br><span class="line"><span class="number">2000</span>-01-03    <span class="number">4</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: grouped.count()</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line"><span class="number">2000</span>-01-01    <span class="number">1</span></span><br><span class="line"><span class="number">2000</span>-01-02    <span class="number">3</span></span><br><span class="line"><span class="number">2000</span>-01-03    <span class="number">1</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<h1><span id="113-日期的范围-频率以及移动">11.3 日期的范围、频率以及移动</span></h1><p>pandas中的原生时间序列一般被认为是不规则的，也就是说，它们没有固定的频率。对于大部分应用程序而言，这是无所谓的。但是，它常常需要以某种相对固定的频率进行分析，比如每日、每月、每15分钟等（这样自然会在时间序列中引入缺失值）。幸运的是，pandas有一整套标准时间序列频率以及用于重采样、频率推断、生成固定频率日期范围的工具。例如，我们可以将之前那个时间序列转换为一个具有固定频率（每日）的时间序列，只需调用resample即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">72</span>]: ts</span><br><span class="line">Out[<span class="number">72</span>]: </span><br><span class="line"><span class="number">2011</span>-01-02   -<span class="number">0.204708</span></span><br><span class="line"><span class="number">2011</span>-01-05    <span class="number">0.478943</span></span><br><span class="line"><span class="number">2011</span>-01-07   -<span class="number">0.519439</span></span><br><span class="line"><span class="number">2011</span>-01-08   -<span class="number">0.555730</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">10</span>    <span class="number">1.965781</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">12</span>    <span class="number">1.393406</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">73</span>]: resampler = ts.resample(<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>字符串“D”是每天的意思。</p>
<p>频率的转换（或重采样）是一个比较大的主题，稍后将专门用一节来进行讨论（11.6小节）。这里，我将告诉你如何使用基本的频率和它的倍数。</p>
<h2><span id="生成日期范围">生成日期范围</span></h2><p>虽然我之前用的时候没有明说，但你可能已经猜到pandas.date_range可用于根据指定的频率生成指定长度的DatetimeIndex：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: index = pd.date_range(<span class="string">&#x27;2012-04-01&#x27;</span>, <span class="string">&#x27;2012-06-01&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">75</span>]: index</span><br><span class="line">Out[<span class="number">75</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-04-01&#x27;</span>, <span class="string">&#x27;2012-04-02&#x27;</span>, <span class="string">&#x27;2012-04-03&#x27;</span>, <span class="string">&#x27;2012-04-04&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-05&#x27;</span>, <span class="string">&#x27;2012-04-06&#x27;</span>, <span class="string">&#x27;2012-04-07&#x27;</span>, <span class="string">&#x27;2012-04-08&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-09&#x27;</span>, <span class="string">&#x27;2012-04-10&#x27;</span>, <span class="string">&#x27;2012-04-11&#x27;</span>, <span class="string">&#x27;2012-04-12&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-13&#x27;</span>, <span class="string">&#x27;2012-04-14&#x27;</span>, <span class="string">&#x27;2012-04-15&#x27;</span>, <span class="string">&#x27;2012-04-16&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-17&#x27;</span>, <span class="string">&#x27;2012-04-18&#x27;</span>, <span class="string">&#x27;2012-04-19&#x27;</span>, <span class="string">&#x27;2012-04-20&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-21&#x27;</span>, <span class="string">&#x27;2012-04-22&#x27;</span>, <span class="string">&#x27;2012-04-23&#x27;</span>, <span class="string">&#x27;2012-04-24&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-25&#x27;</span>, <span class="string">&#x27;2012-04-26&#x27;</span>, <span class="string">&#x27;2012-04-27&#x27;</span>, <span class="string">&#x27;2012-04-28&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-29&#x27;</span>, <span class="string">&#x27;2012-04-30&#x27;</span>, <span class="string">&#x27;2012-05-01&#x27;</span>, <span class="string">&#x27;2012-05-02&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-03&#x27;</span>, <span class="string">&#x27;2012-05-04&#x27;</span>, <span class="string">&#x27;2012-05-05&#x27;</span>, <span class="string">&#x27;2012-05-06&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-07&#x27;</span>, <span class="string">&#x27;2012-05-08&#x27;</span>, <span class="string">&#x27;2012-05-09&#x27;</span>, <span class="string">&#x27;2012-05-10&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-11&#x27;</span>, <span class="string">&#x27;2012-05-12&#x27;</span>, <span class="string">&#x27;2012-05-13&#x27;</span>, <span class="string">&#x27;2012-05-14&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-15&#x27;</span>, <span class="string">&#x27;2012-05-16&#x27;</span>, <span class="string">&#x27;2012-05-17&#x27;</span>, <span class="string">&#x27;2012-05-18&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-19&#x27;</span>, <span class="string">&#x27;2012-05-20&#x27;</span>, <span class="string">&#x27;2012-05-21&#x27;</span>, <span class="string">&#x27;2012-05-22&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-23&#x27;</span>, <span class="string">&#x27;2012-05-24&#x27;</span>, <span class="string">&#x27;2012-05-25&#x27;</span>, <span class="string">&#x27;2012-05-26&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-27&#x27;</span>, <span class="string">&#x27;2012-05-28&#x27;</span>, <span class="string">&#x27;2012-05-29&#x27;</span>, <span class="string">&#x27;2012-05-30&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-31&#x27;</span>, <span class="string">&#x27;2012-06-01&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>默认情况下，date_range会产生按天计算的时间点。如果只传入起始或结束日期，那就还得传入一个表示一段时间的数字：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: pd.date_range(start=<span class="string">&#x27;2012-04-01&#x27;</span>, periods=<span class="number">20</span>)</span><br><span class="line">Out[<span class="number">76</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-04-01&#x27;</span>, <span class="string">&#x27;2012-04-02&#x27;</span>, <span class="string">&#x27;2012-04-03&#x27;</span>, <span class="string">&#x27;2012-04-04&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-05&#x27;</span>, <span class="string">&#x27;2012-04-06&#x27;</span>, <span class="string">&#x27;2012-04-07&#x27;</span>, <span class="string">&#x27;2012-04-08&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-09&#x27;</span>, <span class="string">&#x27;2012-04-10&#x27;</span>, <span class="string">&#x27;2012-04-11&#x27;</span>, <span class="string">&#x27;2012-04-12&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-13&#x27;</span>, <span class="string">&#x27;2012-04-14&#x27;</span>, <span class="string">&#x27;2012-04-15&#x27;</span>, <span class="string">&#x27;2012-04-16&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-04-17&#x27;</span>, <span class="string">&#x27;2012-04-18&#x27;</span>, <span class="string">&#x27;2012-04-19&#x27;</span>, <span class="string">&#x27;2012-04-20&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: pd.date_range(end=<span class="string">&#x27;2012-06-01&#x27;</span>, periods=<span class="number">20</span>)</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-05-13&#x27;</span>, <span class="string">&#x27;2012-05-14&#x27;</span>, <span class="string">&#x27;2012-05-15&#x27;</span>, <span class="string">&#x27;2012-05-16&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-17&#x27;</span>, <span class="string">&#x27;2012-05-18&#x27;</span>, <span class="string">&#x27;2012-05-19&#x27;</span>, <span class="string">&#x27;2012-05-20&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-21&#x27;</span>, <span class="string">&#x27;2012-05-22&#x27;</span>, <span class="string">&#x27;2012-05-23&#x27;</span>, <span class="string">&#x27;2012-05-24&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-25&#x27;</span>, <span class="string">&#x27;2012-05-26&#x27;</span>, <span class="string">&#x27;2012-05-27&#x27;</span>,<span class="string">&#x27;2012-05-28&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-29&#x27;</span>, <span class="string">&#x27;2012-05-30&#x27;</span>, <span class="string">&#x27;2012-05-31&#x27;</span>, <span class="string">&#x27;2012-06-01&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>起始和结束日期定义了日期索引的严格边界。例如，如果你想要生成一个由每月最后一个工作日组成的日期索引，可以传入”BM”频率（表示business end of month，表11-4是频率列表），这样就只会包含时间间隔内（或刚好在边界上的）符合频率要求的日期：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">78</span>]: pd.date_range(<span class="string">&#x27;2000-01-01&#x27;</span>, <span class="string">&#x27;2000-12-01&#x27;</span>, freq=<span class="string">&#x27;BM&#x27;</span>)</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2000-01-31&#x27;</span>, <span class="string">&#x27;2000-02-29&#x27;</span>, <span class="string">&#x27;2000-03-31&#x27;</span>, <span class="string">&#x27;2000-04-28&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-05-31&#x27;</span>, <span class="string">&#x27;2000-06-30&#x27;</span>, <span class="string">&#x27;2000-07-31&#x27;</span>, <span class="string">&#x27;2000-08-31&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-09-29&#x27;</span>, <span class="string">&#x27;2000-10-31&#x27;</span>, <span class="string">&#x27;2000-11-30&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;BM&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>表11-4 基本的时间序列频率（不完整）</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c8614ddbd10793ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-8da46ba96544b071.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-3ca410609195edc4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>date_range默认会保留起始和结束时间戳的时间信息（如果有的话）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">79</span>]: pd.date_range(<span class="string">&#x27;2012-05-02 12:56:31&#x27;</span>, periods=<span class="number">5</span>)</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-05-02 12:56:31&#x27;</span>, <span class="string">&#x27;2012-05-03 12:56:31&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-04 12:56:31&#x27;</span>, <span class="string">&#x27;2012-05-05 12:56:31&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-06 12:56:31&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>有时，虽然起始和结束日期带有时间信息，但你希望产生一组被规范化（normalize）到午夜的时间戳。normalize选项即可实现该功能：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">80</span>]: pd.date_range(<span class="string">&#x27;2012-05-02 12:56:31&#x27;</span>, periods=<span class="number">5</span>, normalize=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-05-02&#x27;</span>, <span class="string">&#x27;2012-05-03&#x27;</span>, <span class="string">&#x27;2012-05-04&#x27;</span>, <span class="string">&#x27;2012-05-05&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-05-06&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2><span id="频率和日期偏移量">频率和日期偏移量</span></h2><p>pandas中的频率是由一个基础频率（base frequency）和一个乘数组成的。基础频率通常以一个字符串别名表示，比如”M”表示每月，”H”表示每小时。对于每个基础频率，都有一个被称为日期偏移量（date offset）的对象与之对应。例如，按小时计算的频率可以用Hour类表示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">81</span>]: <span class="keyword">from</span> pandas.tseries.offsets <span class="keyword">import</span> Hour, Minute</span><br><span class="line"></span><br><span class="line">In [<span class="number">82</span>]: hour = Hour()</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: hour</span><br><span class="line">Out[<span class="number">83</span>]: &lt;Hour&gt;</span><br></pre></td></tr></table></figure></p>
<p>传入一个整数即可定义偏移量的倍数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">84</span>]: four_hours = Hour(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: four_hours</span><br><span class="line">Out[<span class="number">85</span>]: &lt;<span class="number">4</span> * Hours&gt;</span><br></pre></td></tr></table></figure></p>
<p>一般来说，无需明确创建这样的对象，只需使用诸如”H”或”4H”这样的字符串别名即可。在基础频率前面放上一个整数即可创建倍数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">86</span>]: pd.date_range(<span class="string">&#x27;2000-01-01&#x27;</span>, <span class="string">&#x27;2000-01-03 23:59&#x27;</span>, freq=<span class="string">&#x27;4h&#x27;</span>)</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2000-01-01 00:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 04:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-01 08:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 12:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-01 16:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 20:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-02 00:00:00&#x27;</span>, <span class="string">&#x27;2000-01-02 04:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-02 08:00:00&#x27;</span>, <span class="string">&#x27;2000-01-02 12:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-02 16:00:00&#x27;</span>, <span class="string">&#x27;2000-01-02 20:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-03 00:00:00&#x27;</span>, <span class="string">&#x27;2000-01-03 04:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-03 08:00:00&#x27;</span>, <span class="string">&#x27;2000-01-03 12:00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-03 16:00:00&#x27;</span>, <span class="string">&#x27;2000-01-03 20:00:00&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;4H&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>大部分偏移量对象都可通过加法进行连接：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: Hour(<span class="number">2</span>) + Minute(<span class="number">30</span>)</span><br><span class="line">Out[<span class="number">87</span>]: &lt;<span class="number">150</span> * Minutes&gt;</span><br></pre></td></tr></table></figure></p>
<p>同理，你也可以传入频率字符串（如”2h30min”），这种字符串可以被高效地解析为等效的表达式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">88</span>]: pd.date_range(<span class="string">&#x27;2000-01-01&#x27;</span>, periods=<span class="number">10</span>, freq=<span class="string">&#x27;1h30min&#x27;</span>)</span><br><span class="line">Out[<span class="number">88</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2000-01-01 00:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 01:30:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-01 03:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 04:30:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-01 06:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 07:30:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-01 09:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 10:30:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2000-01-01 12:00:00&#x27;</span>, <span class="string">&#x27;2000-01-01 13:30:00&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns]&#x27;</span>, freq=<span class="string">&#x27;90T&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>有些频率所描述的时间点并不是均匀分隔的。例如，”M”（日历月末）和”BM”（每月最后一个工作日）就取决于每月的天数，对于后者，还要考虑月末是不是周末。由于没有更好的术语，我将这些称为锚点偏移量（anchored offset）。</p>
<p>表11-4列出了pandas中的频率代码和日期偏移量类。</p>
<blockquote>
<p>笔记：用户可以根据实际需求自定义一些频率类以便提供pandas所没有的日期逻辑，但具体的细节超出了本书的范围。             </p>
</blockquote>
<p>表11-4 时间序列的基础频率</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-ff139312cd972204.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-adfa57a998c0296e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-d09e577a10d0e6eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h2><span id="wom日期">WOM日期</span></h2><p>WOM（Week Of Month）是一种非常实用的频率类，它以WOM开头。它使你能获得诸如“每月第3个星期五”之类的日期：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">89</span>]: rng = pd.date_range(<span class="string">&#x27;2012-01-01&#x27;</span>, <span class="string">&#x27;2012-09-01&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: <span class="built_in">list</span>(rng)</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">[Timestamp(<span class="string">&#x27;2012-01-20 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>),</span><br><span class="line"> Timestamp(<span class="string">&#x27;2012-02-17 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>),</span><br><span class="line"> Timestamp(<span class="string">&#x27;2012-03-16 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>),</span><br><span class="line"> Timestamp(<span class="string">&#x27;2012-04-20 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>),</span><br><span class="line"> Timestamp(<span class="string">&#x27;2012-05-18 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>),</span><br><span class="line"> Timestamp(<span class="string">&#x27;2012-06-15 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>),</span><br><span class="line"> Timestamp(<span class="string">&#x27;2012-07-20 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>),</span><br><span class="line"> Timestamp(<span class="string">&#x27;2012-08-17 00:00:00&#x27;</span>, freq=<span class="string">&#x27;WOM-3FRI&#x27;</span>)]</span><br></pre></td></tr></table></figure></p>
<h2><span id="移动超前和滞后数据">移动（超前和滞后）数据</span></h2><p>移动（shifting）指的是沿着时间轴将数据前移或后移。Series和DataFrame都有一个shift方法用于执行单纯的前移或后移操作，保持索引不变：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: ts = pd.Series(np.random.randn(<span class="number">4</span>),</span><br><span class="line">   ....:                index=pd.date_range(<span class="string">&#x27;1/1/2000&#x27;</span>, periods=<span class="number">4</span>, freq=<span class="string">&#x27;M&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: ts</span><br><span class="line">Out[<span class="number">92</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.066748</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span>    <span class="number">0.838639</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>   -<span class="number">0.117388</span></span><br><span class="line"><span class="number">2000</span>-04-<span class="number">30</span>   -<span class="number">0.517795</span></span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: ts.shift(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>         NaN</span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span>         NaN</span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>   -<span class="number">0.066748</span></span><br><span class="line"><span class="number">2000</span>-04-<span class="number">30</span>    <span class="number">0.838639</span></span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">94</span>]: ts.shift(-<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">94</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.117388</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span>   -<span class="number">0.517795</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>         NaN</span><br><span class="line"><span class="number">2000</span>-04-<span class="number">30</span>         NaN</span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>当我们这样进行移动时，就会在时间序列的前面或后面产生缺失数据。</p>
<p>shift通常用于计算一个时间序列或多个时间序列（如DataFrame的列）中的百分比变化。可以这样表达：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts / ts.shift(<span class="number">1</span>) - <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>由于单纯的移位操作不会修改索引，所以部分数据会被丢弃。因此，如果频率已知，则可以将其传给shift以便实现对时间戳进行位移而不是对数据进行简单位移：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: ts.shift(<span class="number">2</span>, freq=<span class="string">&#x27;M&#x27;</span>)</span><br><span class="line">Out[<span class="number">95</span>]: </span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>   -<span class="number">0.066748</span></span><br><span class="line"><span class="number">2000</span>-04-<span class="number">30</span>    <span class="number">0.838639</span></span><br><span class="line"><span class="number">2000</span>-05-<span class="number">31</span>   -<span class="number">0.117388</span></span><br><span class="line"><span class="number">2000</span>-06-<span class="number">30</span>   -<span class="number">0.517795</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这里还可以使用其他频率，于是你就能非常灵活地对数据进行超前和滞后处理了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: ts.shift(<span class="number">3</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">Out[<span class="number">96</span>]: </span><br><span class="line"><span class="number">2000</span>-02-03   -<span class="number">0.066748</span></span><br><span class="line"><span class="number">2000</span>-03-03    <span class="number">0.838639</span></span><br><span class="line"><span class="number">2000</span>-04-03   -<span class="number">0.117388</span></span><br><span class="line"><span class="number">2000</span>-05-03   -<span class="number">0.517795</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: ts.shift(<span class="number">1</span>, freq=<span class="string">&#x27;90T&#x27;</span>)</span><br><span class="line">Out[<span class="number">97</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span> 01:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.066748</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span> 01:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.838639</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span> 01:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.117388</span></span><br><span class="line"><span class="number">2000</span>-04-<span class="number">30</span> 01:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.517795</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="通过偏移量对日期进行位移">通过偏移量对日期进行位移</span></h2><p>pandas的日期偏移量还可以用在datetime或Timestamp对象上：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">98</span>]: <span class="keyword">from</span> pandas.tseries.offsets <span class="keyword">import</span> Day, MonthEnd</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: now = datetime(<span class="number">2011</span>, <span class="number">11</span>, <span class="number">17</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: now + <span class="number">3</span> * Day()</span><br><span class="line">Out[<span class="number">100</span>]: Timestamp(<span class="string">&#x27;2011-11-20 00:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果加的是锚点偏移量（比如MonthEnd），第一次增量会将原日期向前滚动到符合频率规则的下一个日期：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">101</span>]: now + MonthEnd()</span><br><span class="line">Out[<span class="number">101</span>]: Timestamp(<span class="string">&#x27;2011-11-30 00:00:00&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: now + MonthEnd(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">102</span>]: Timestamp(<span class="string">&#x27;2011-12-31 00:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>通过锚点偏移量的rollforward和rollback方法，可明确地将日期向前或向后“滚动”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">103</span>]: offset = MonthEnd()</span><br><span class="line"></span><br><span class="line">In [<span class="number">104</span>]: offset.rollforward(now)</span><br><span class="line">Out[<span class="number">104</span>]: Timestamp(<span class="string">&#x27;2011-11-30 00:00:00&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: offset.rollback(now)</span><br><span class="line">Out[<span class="number">105</span>]: Timestamp(<span class="string">&#x27;2011-10-31 00:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>日期偏移量还有一个巧妙的用法，即结合groupby使用这两个“滚动”方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">106</span>]: ts = pd.Series(np.random.randn(<span class="number">20</span>),</span><br><span class="line">   .....:                index=pd.date_range(<span class="string">&#x27;1/15/2000&#x27;</span>, periods=<span class="number">20</span>, freq=<span class="string">&#x27;4d&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">107</span>]: ts</span><br><span class="line">Out[<span class="number">107</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">15</span>   -<span class="number">0.116696</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">19</span>    <span class="number">2.389645</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">23</span>   -<span class="number">0.932454</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">27</span>   -<span class="number">0.229331</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">1.140330</span></span><br><span class="line"><span class="number">2000</span>-02-04    <span class="number">0.439920</span></span><br><span class="line"><span class="number">2000</span>-02-08   -<span class="number">0.823758</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">12</span>   -<span class="number">0.520930</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">16</span>    <span class="number">0.350282</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">20</span>    <span class="number">0.204395</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">24</span>    <span class="number">0.133445</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">28</span>    <span class="number">0.327905</span></span><br><span class="line"><span class="number">2000</span>-03-03    <span class="number">0.072153</span></span><br><span class="line"><span class="number">2000</span>-03-07    <span class="number">0.131678</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">11</span>   -<span class="number">1.297459</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">15</span>    <span class="number">0.997747</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">19</span>    <span class="number">0.870955</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">23</span>   -<span class="number">0.991253</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">27</span>    <span class="number">0.151699</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>    <span class="number">1.266151</span></span><br><span class="line">Freq: 4D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">108</span>]: ts.groupby(offset.rollforward).mean()</span><br><span class="line">Out[<span class="number">108</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.005833</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span>    <span class="number">0.015894</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>    <span class="number">0.150209</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>当然，更简单、更快速地实现该功能的办法是使用resample（11.6小节将对此进行详细介绍）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">109</span>]: ts.resample(<span class="string">&#x27;M&#x27;</span>).mean()</span><br><span class="line">Out[<span class="number">109</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.005833</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span>    <span class="number">0.015894</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>    <span class="number">0.150209</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<h1><span id="114-时区处理">11.4 时区处理</span></h1><p>时间序列处理工作中最让人不爽的就是对时区的处理。许多人都选择以协调世界时（UTC，它是格林尼治标准时间（Greenwich Mean Time）的接替者，目前已经是国际标准了）来处理时间序列。时区是以UTC偏移量的形式表示的。例如，夏令时期间，纽约比UTC慢4小时，而在全年其他时间则比UTC慢5小时。</p>
<p>在Python中，时区信息来自第三方库pytz，它使Python可以使用Olson数据库（汇编了世界时区信息）。这对历史数据非常重要，这是因为由于各地政府的各种突发奇想，夏令时转变日期（甚至UTC偏移量）已经发生过多次改变了。就拿美国来说，DST转变时间自1900年以来就改变过多次！</p>
<p>有关pytz库的更多信息，请查阅其文档。就本书而言，由于pandas包装了pytz的功能，因此你可以不用记忆其API，只要记得时区的名称即可。时区名可以在shell中看到，也可以通过文档查看：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">110</span>]: <span class="keyword">import</span> pytz</span><br><span class="line"></span><br><span class="line">In [<span class="number">111</span>]: pytz.common_timezones[-<span class="number">5</span>:]</span><br><span class="line">Out[<span class="number">111</span>]: [<span class="string">&#x27;US/Eastern&#x27;</span>, <span class="string">&#x27;US/Hawaii&#x27;</span>, <span class="string">&#x27;US/Mountain&#x27;</span>, <span class="string">&#x27;US/Pacific&#x27;</span>, <span class="string">&#x27;UTC&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>要从pytz中获取时区对象，使用pytz.timezone即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">112</span>]: tz = pytz.timezone(<span class="string">&#x27;America/New_York&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: tz</span><br><span class="line">Out[<span class="number">113</span>]: &lt;DstTzInfo <span class="string">&#x27;America/New_York&#x27;</span> LMT-<span class="number">1</span> day, <span class="number">19</span>:04:<span class="number">00</span> STD&gt;</span><br></pre></td></tr></table></figure></p>
<p>pandas中的方法既可以接受时区名也可以接受这些对象。</p>
<h1><span id="时区本地化和转换">时区本地化和转换</span></h1><p>默认情况下，pandas中的时间序列是单纯的时区。看看下面这个时间序列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">114</span>]: rng = pd.date_range(<span class="string">&#x27;3/9/2012 9:30&#x27;</span>, periods=<span class="number">6</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">115</span>]: ts = pd.Series(np.random.randn(<span class="built_in">len</span>(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: ts</span><br><span class="line">Out[<span class="number">116</span>]: </span><br><span class="line"><span class="number">2012</span>-03-09 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.202469</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">10</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.050718</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">11</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.639869</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">12</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.597594</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">13</span> 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.797246</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">14</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.472879</span></span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>其索引的tz字段为None：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: <span class="built_in">print</span>(ts.index.tz)</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></table></figure></p>
<p>可以用时区集生成日期范围：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">118</span>]: pd.date_range(<span class="string">&#x27;3/9/2012 9:30&#x27;</span>, periods=<span class="number">10</span>, freq=<span class="string">&#x27;D&#x27;</span>, tz=<span class="string">&#x27;UTC&#x27;</span>)</span><br><span class="line">Out[<span class="number">118</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-03-09 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-10 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-11 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-12 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-13 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-14 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-15 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-16 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-17 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-18 09:30:00+00:00&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns, UTC]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>从单纯到本地化的转换是通过tz_localize方法处理的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">119</span>]: ts</span><br><span class="line">Out[<span class="number">119</span>]: </span><br><span class="line"><span class="number">2012</span>-03-09 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.202469</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">10</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.050718</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">11</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.639869</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">12</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.597594</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">13</span> 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.797246</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">14</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.472879</span></span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">120</span>]: ts_utc = ts.tz_localize(<span class="string">&#x27;UTC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: ts_utc</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line"><span class="number">2012</span>-03-09 09:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>   -<span class="number">0.202469</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">10</span> 09:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.050718</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">11</span> 09:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.639869</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">12</span> 09:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.597594</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">13</span> 09:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>   -<span class="number">0.797246</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">14</span> 09:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.472879</span></span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: ts_utc.index</span><br><span class="line">Out[<span class="number">122</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-03-09 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-10 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-11 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-12 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-13 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-14 09:30:00+00:00&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns, UTC]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>一旦时间序列被本地化到某个特定时区，就可以用tz_convert将其转换到别的时区了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">123</span>]: ts_utc.tz_convert(<span class="string">&#x27;America/New_York&#x27;</span>)</span><br><span class="line">Out[<span class="number">123</span>]: </span><br><span class="line"><span class="number">2012</span>-03-09 04:<span class="number">30</span>:<span class="number">00</span>-05:<span class="number">00</span>   -<span class="number">0.202469</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">10</span> 04:<span class="number">30</span>:<span class="number">00</span>-05:<span class="number">00</span>    <span class="number">0.050718</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">11</span> 05:<span class="number">30</span>:<span class="number">00</span>-04:<span class="number">00</span>    <span class="number">0.639869</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">12</span> 05:<span class="number">30</span>:<span class="number">00</span>-04:<span class="number">00</span>    <span class="number">0.597594</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">13</span> 05:<span class="number">30</span>:<span class="number">00</span>-04:<span class="number">00</span>   -<span class="number">0.797246</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">14</span> 05:<span class="number">30</span>:<span class="number">00</span>-04:<span class="number">00</span>    <span class="number">0.472879</span></span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>对于上面这种时间序列（它跨越了美国东部时区的夏令时转变期），我们可以将其本地化到EST，然后转换为UTC或柏林时间：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">124</span>]: ts_eastern = ts.tz_localize(<span class="string">&#x27;America/New_York&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: ts_eastern.tz_convert(<span class="string">&#x27;UTC&#x27;</span>)</span><br><span class="line">Out[<span class="number">125</span>]: </span><br><span class="line"><span class="number">2012</span>-03-09 <span class="number">14</span>:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>   -<span class="number">0.202469</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">10</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.050718</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">11</span> <span class="number">13</span>:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.639869</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">12</span> <span class="number">13</span>:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.597594</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">13</span> <span class="number">13</span>:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>   -<span class="number">0.797246</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">14</span> <span class="number">13</span>:<span class="number">30</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.472879</span></span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">126</span>]: ts_eastern.tz_convert(<span class="string">&#x27;Europe/Berlin&#x27;</span>)</span><br><span class="line">Out[<span class="number">126</span>]: </span><br><span class="line"><span class="number">2012</span>-03-09 <span class="number">15</span>:<span class="number">30</span>:<span class="number">00</span>+01:<span class="number">00</span>   -<span class="number">0.202469</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">10</span> <span class="number">15</span>:<span class="number">30</span>:<span class="number">00</span>+01:<span class="number">00</span>    <span class="number">0.050718</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">11</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">00</span>+01:<span class="number">00</span>    <span class="number">0.639869</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">12</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">00</span>+01:<span class="number">00</span>    <span class="number">0.597594</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">13</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">00</span>+01:<span class="number">00</span>   -<span class="number">0.797246</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">14</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">00</span>+01:<span class="number">00</span>    <span class="number">0.472879</span></span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>tz_localize和tz_convert也是DatetimeIndex的实例方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">127</span>]: ts.index.tz_localize(<span class="string">&#x27;Asia/Shanghai&#x27;</span>)</span><br><span class="line">Out[<span class="number">127</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-03-09 09:30:00+08:00&#x27;</span>, <span class="string">&#x27;2012-03-10 09:30:00+08:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-11 09:30:00+08:00&#x27;</span>, <span class="string">&#x27;2012-03-12 09:30:00+08:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-13 09:30:00+08:00&#x27;</span>, <span class="string">&#x27;2012-03-14 09:30:00+08:00&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns, Asia/Shanghai]&#x27;</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：对单纯时间戳的本地化操作还会检查夏令时转变期附近容易混淆或不存在的时间。</p>
</blockquote>
<h2><span id="操作时区意识型timestamp对象">操作时区意识型Timestamp对象</span></h2><p>跟时间序列和日期范围差不多，独立的Timestamp对象也能被从单纯型（naive）本地化为时区意识型（time zone-aware），并从一个时区转换到另一个时区：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">128</span>]: stamp = pd.Timestamp(<span class="string">&#x27;2011-03-12 04:00&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: stamp_utc = stamp.tz_localize(<span class="string">&#x27;utc&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">130</span>]: stamp_utc.tz_convert(<span class="string">&#x27;America/New_York&#x27;</span>)</span><br><span class="line">Out[<span class="number">130</span>]: Timestamp(<span class="string">&#x27;2011-03-11 23:00:00-0500&#x27;</span>, tz=<span class="string">&#x27;America/New_York&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>在创建Timestamp时，还可以传入一个时区信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">131</span>]: stamp_moscow = pd.Timestamp(<span class="string">&#x27;2011-03-12 04:00&#x27;</span>, tz=<span class="string">&#x27;Europe/Moscow&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: stamp_moscow</span><br><span class="line">Out[<span class="number">132</span>]: Timestamp(<span class="string">&#x27;2011-03-12 04:00:00+0300&#x27;</span>, tz=<span class="string">&#x27;Europe/Moscow&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>时区意识型Timestamp对象在内部保存了一个UTC时间戳值（自UNIX纪元（1970年1月1日）算起的纳秒数）。这个UTC值在时区转换过程中是不会发生变化的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">133</span>]: stamp_utc.value</span><br><span class="line">Out[<span class="number">133</span>]: <span class="number">1299902400000000000</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: stamp_utc.tz_convert(<span class="string">&#x27;America/New_York&#x27;</span>).value</span><br><span class="line">Out[<span class="number">134</span>]: <span class="number">1299902400000000000</span></span><br></pre></td></tr></table></figure></p>
<p>当使用pandas的DateOffset对象执行时间算术运算时，运算过程会自动关注是否存在夏令时转变期。这里，我们创建了在DST转变之前的时间戳。首先，来看夏令时转变前的30分钟：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">135</span>]: <span class="keyword">from</span> pandas.tseries.offsets <span class="keyword">import</span> Hour</span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: stamp = pd.Timestamp(<span class="string">&#x27;2012-03-12 01:30&#x27;</span>, tz=<span class="string">&#x27;US/Eastern&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">137</span>]: stamp</span><br><span class="line">Out[<span class="number">137</span>]: Timestamp(<span class="string">&#x27;2012-03-12 01:30:00-0400&#x27;</span>, tz=<span class="string">&#x27;US/Eastern&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">138</span>]: stamp + Hour()</span><br><span class="line">Out[<span class="number">138</span>]: Timestamp(<span class="string">&#x27;2012-03-12 02:30:00-0400&#x27;</span>, tz=<span class="string">&#x27;US/Eastern&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>然后，夏令时转变前90分钟：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">139</span>]: stamp = pd.Timestamp(<span class="string">&#x27;2012-11-04 00:30&#x27;</span>, tz=<span class="string">&#x27;US/Eastern&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: stamp</span><br><span class="line">Out[<span class="number">140</span>]: Timestamp(<span class="string">&#x27;2012-11-04 00:30:00-0400&#x27;</span>, tz=<span class="string">&#x27;US/Eastern&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">141</span>]: stamp + <span class="number">2</span> * Hour()</span><br><span class="line">Out[<span class="number">141</span>]: Timestamp(<span class="string">&#x27;2012-11-04 01:30:00-0500&#x27;</span>, tz=<span class="string">&#x27;US/Eastern&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2><span id="不同时区之间的运算">不同时区之间的运算</span></h2><p>如果两个时间序列的时区不同，在将它们合并到一起时，最终结果就会是UTC。由于时间戳其实是以UTC存储的，所以这是一个很简单的运算，并不需要发生任何转换：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">142</span>]: rng = pd.date_range(<span class="string">&#x27;3/7/2012 9:30&#x27;</span>, periods=<span class="number">10</span>, freq=<span class="string">&#x27;B&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">143</span>]: ts = pd.Series(np.random.randn(<span class="built_in">len</span>(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">144</span>]: ts</span><br><span class="line">Out[<span class="number">144</span>]: </span><br><span class="line"><span class="number">2012</span>-03-07 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.522356</span></span><br><span class="line"><span class="number">2012</span>-03-08 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.546348</span></span><br><span class="line"><span class="number">2012</span>-03-09 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.733537</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">12</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">1.302736</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">13</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.022199</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">14</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.364287</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">15</span> 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.922839</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">16</span> 09:<span class="number">30</span>:<span class="number">00</span>    <span class="number">0.312656</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">19</span> 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">1.128497</span></span><br><span class="line"><span class="number">2012</span>-03-<span class="number">20</span> 09:<span class="number">30</span>:<span class="number">00</span>   -<span class="number">0.333488</span></span><br><span class="line">Freq: B, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">145</span>]: ts1 = ts[:<span class="number">7</span>].tz_localize(<span class="string">&#x27;Europe/London&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">146</span>]: ts2 = ts1[<span class="number">2</span>:].tz_convert(<span class="string">&#x27;Europe/Moscow&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">147</span>]: result = ts1 + ts2</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: result.index</span><br><span class="line">Out[<span class="number">148</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">&#x27;2012-03-07 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-08 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-09 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-12 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-13 09:30:00+00:00&#x27;</span>, <span class="string">&#x27;2012-03-14 09:30:00+00:00&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;2012-03-15 09:30:00+00:00&#x27;</span>],</span><br><span class="line">              dtype=<span class="string">&#x27;datetime64[ns, UTC]&#x27;</span>, freq=<span class="string">&#x27;B&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h1><span id="115-时期及其算术运算">11.5 时期及其算术运算</span></h1><p>时期（period）表示的是时间区间，比如数日、数月、数季、数年等。Period类所表示的就是这种数据类型，其构造函数需要用到一个字符串或整数，以及表11-4中的频率：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">149</span>]: p = pd.Period(<span class="number">2007</span>, freq=<span class="string">&#x27;A-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">150</span>]: p</span><br><span class="line">Out[<span class="number">150</span>]: Period(<span class="string">&#x27;2007&#x27;</span>, <span class="string">&#x27;A-DEC&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>这里，这个Period对象表示的是从2007年1月1日到2007年12月31日之间的整段时间。只需对Period对象加上或减去一个整数即可达到根据其频率进行位移的效果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">151</span>]: p + <span class="number">5</span></span><br><span class="line">Out[<span class="number">151</span>]: Period(<span class="string">&#x27;2012&#x27;</span>, <span class="string">&#x27;A-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">152</span>]: p - <span class="number">2</span></span><br><span class="line">Out[<span class="number">152</span>]: Period(<span class="string">&#x27;2005&#x27;</span>, <span class="string">&#x27;A-DEC&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果两个Period对象拥有相同的频率，则它们的差就是它们之间的单位数量：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">153</span>]: pd.Period(<span class="string">&#x27;2014&#x27;</span>, freq=<span class="string">&#x27;A-DEC&#x27;</span>) - p</span><br><span class="line">Out[<span class="number">153</span>]: <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<p>period_range函数可用于创建规则的时期范围：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">154</span>]: rng = pd.period_range(<span class="string">&#x27;2000-01-01&#x27;</span>, <span class="string">&#x27;2000-06-30&#x27;</span>, freq=<span class="string">&#x27;M&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">155</span>]: rng</span><br><span class="line">Out[<span class="number">155</span>]: PeriodIndex([<span class="string">&#x27;2000-01&#x27;</span>, <span class="string">&#x27;2000-02&#x27;</span>, <span class="string">&#x27;2000-03&#x27;</span>, <span class="string">&#x27;2000-04&#x27;</span>, <span class="string">&#x27;2000-05&#x27;</span>, <span class="string">&#x27;20</span></span><br><span class="line"><span class="string">00-06&#x27;</span>], dtype=<span class="string">&#x27;period[M]&#x27;</span>, freq=<span class="string">&#x27;M&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>PeriodIndex类保存了一组Period，它可以在任何pandas数据结构中被用作轴索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">156</span>]: pd.Series(np.random.randn(<span class="number">6</span>), index=rng)</span><br><span class="line">Out[<span class="number">156</span>]: </span><br><span class="line"><span class="number">2000</span>-01   -<span class="number">0.514551</span></span><br><span class="line"><span class="number">2000</span>-02   -<span class="number">0.559782</span></span><br><span class="line"><span class="number">2000</span>-03   -<span class="number">0.783408</span></span><br><span class="line"><span class="number">2000</span>-04   -<span class="number">1.797685</span></span><br><span class="line"><span class="number">2000</span>-05   -<span class="number">0.172670</span></span><br><span class="line"><span class="number">2000</span>-06    <span class="number">0.680215</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>如果你有一个字符串数组，你也可以使用PeriodIndex类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">157</span>]: values = [<span class="string">&#x27;2001Q3&#x27;</span>, <span class="string">&#x27;2002Q2&#x27;</span>, <span class="string">&#x27;2003Q1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">158</span>]: index = pd.PeriodIndex(values, freq=<span class="string">&#x27;Q-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">159</span>]: index</span><br><span class="line">Out[<span class="number">159</span>]: PeriodIndex([<span class="string">&#x27;2001Q3&#x27;</span>, <span class="string">&#x27;2002Q2&#x27;</span>, <span class="string">&#x27;2003Q1&#x27;</span>], dtype=<span class="string">&#x27;period[Q-DEC]&#x27;</span>, freq</span><br><span class="line">=<span class="string">&#x27;Q-DEC&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2><span id="时期的频率转换">时期的频率转换</span></h2><p>Period和PeriodIndex对象都可以通过其asfreq方法被转换成别的频率。假设我们有一个年度时期，希望将其转换为当年年初或年末的一个月度时期。该任务非常简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">160</span>]: p = pd.Period(<span class="string">&#x27;2007&#x27;</span>, freq=<span class="string">&#x27;A-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">161</span>]: p</span><br><span class="line">Out[<span class="number">161</span>]: Period(<span class="string">&#x27;2007&#x27;</span>, <span class="string">&#x27;A-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: p.asfreq(<span class="string">&#x27;M&#x27;</span>, how=<span class="string">&#x27;start&#x27;</span>)</span><br><span class="line">Out[<span class="number">162</span>]: Period(<span class="string">&#x27;2007-01&#x27;</span>, <span class="string">&#x27;M&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">163</span>]: p.asfreq(<span class="string">&#x27;M&#x27;</span>, how=<span class="string">&#x27;end&#x27;</span>)</span><br><span class="line">Out[<span class="number">163</span>]: Period(<span class="string">&#x27;2007-12&#x27;</span>, <span class="string">&#x27;M&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>你可以将Period(‘2007’,’A-DEC’)看做一个被划分为多个月度时期的时间段中的游标。图11-1对此进行了说明。对于一个不以12月结束的财政年度，月度子时期的归属情况就不一样了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">164</span>]: p = pd.Period(<span class="string">&#x27;2007&#x27;</span>, freq=<span class="string">&#x27;A-JUN&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">165</span>]: p</span><br><span class="line">Out[<span class="number">165</span>]: Period(<span class="string">&#x27;2007&#x27;</span>, <span class="string">&#x27;A-JUN&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">166</span>]: p.asfreq(<span class="string">&#x27;M&#x27;</span>, <span class="string">&#x27;start&#x27;</span>)</span><br><span class="line">Out[<span class="number">166</span>]: Period(<span class="string">&#x27;2006-07&#x27;</span>, <span class="string">&#x27;M&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">167</span>]: p.asfreq(<span class="string">&#x27;M&#x27;</span>, <span class="string">&#x27;end&#x27;</span>)</span><br><span class="line">Out[<span class="number">167</span>]: Period(<span class="string">&#x27;2007-06&#x27;</span>, <span class="string">&#x27;M&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-d201200d0e65676f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-1 Period频率转换示例"></p>
<p>在将高频率转换为低频率时，超时期（superperiod）是由子时期（subperiod）所属的位置决定的。例如，在A-JUN频率中，月份“2007年8月”实际上是属于周期“2008年”的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">168</span>]: p = pd.Period(<span class="string">&#x27;Aug-2007&#x27;</span>, <span class="string">&#x27;M&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: p.asfreq(<span class="string">&#x27;A-JUN&#x27;</span>)</span><br><span class="line">Out[<span class="number">169</span>]: Period(<span class="string">&#x27;2008&#x27;</span>, <span class="string">&#x27;A-JUN&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>完整的PeriodIndex或TimeSeries的频率转换方式也是如此：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">170</span>]: rng = pd.period_range(<span class="string">&#x27;2006&#x27;</span>, <span class="string">&#x27;2009&#x27;</span>, freq=<span class="string">&#x27;A-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">171</span>]: ts = pd.Series(np.random.randn(<span class="built_in">len</span>(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">172</span>]: ts</span><br><span class="line">Out[<span class="number">172</span>]: </span><br><span class="line"><span class="number">2006</span>    <span class="number">1.607578</span></span><br><span class="line"><span class="number">2007</span>    <span class="number">0.200381</span></span><br><span class="line"><span class="number">2008</span>   -<span class="number">0.834068</span></span><br><span class="line"><span class="number">2009</span>   -<span class="number">0.302988</span></span><br><span class="line">Freq: A-DEC, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">173</span>]: ts.asfreq(<span class="string">&#x27;M&#x27;</span>, how=<span class="string">&#x27;start&#x27;</span>)</span><br><span class="line">Out[<span class="number">173</span>]: </span><br><span class="line"><span class="number">2006</span>-01    <span class="number">1.607578</span></span><br><span class="line"><span class="number">2007</span>-01    <span class="number">0.200381</span></span><br><span class="line"><span class="number">2008</span>-01   -<span class="number">0.834068</span></span><br><span class="line"><span class="number">2009</span>-01   -<span class="number">0.302988</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这里，根据年度时期的第一个月，每年的时期被取代为每月的时期。如果我们想要每年的最后一个工作日，我们可以使用“B”频率，并指明想要该时期的末尾：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">174</span>]: ts.asfreq(<span class="string">&#x27;B&#x27;</span>, how=<span class="string">&#x27;end&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Out[<span class="number">174</span>]: </span><br><span class="line"><span class="number">2006</span>-<span class="number">12</span>-<span class="number">29</span>    <span class="number">1.607578</span></span><br><span class="line"><span class="number">2007</span>-<span class="number">12</span>-<span class="number">31</span>    <span class="number">0.200381</span></span><br><span class="line"><span class="number">2008</span>-<span class="number">12</span>-<span class="number">31</span>   -<span class="number">0.834068</span></span><br><span class="line"><span class="number">2009</span>-<span class="number">12</span>-<span class="number">31</span>   -<span class="number">0.302988</span></span><br><span class="line">Freq: B, dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="按季度计算的时期频率">按季度计算的时期频率</span></h2><p>季度型数据在会计、金融等领域中很常见。许多季度型数据都会涉及“财年末”的概念，通常是一年12个月中某月的最后一个日历日或工作日。就这一点来说，时期”2012Q4”根据财年末的不同会有不同的含义。pandas支持12种可能的季度型频率，即Q-JAN到Q-DEC：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">175</span>]: p = pd.Period(<span class="string">&#x27;2012Q4&#x27;</span>, freq=<span class="string">&#x27;Q-JAN&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">176</span>]: p</span><br><span class="line">Out[<span class="number">176</span>]: Period(<span class="string">&#x27;2012Q4&#x27;</span>, <span class="string">&#x27;Q-JAN&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>在以1月结束的财年中，2012Q4是从11月到1月（将其转换为日型频率就明白了）。图11-2对此进行了说明：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">177</span>]: p.asfreq(<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;start&#x27;</span>)</span><br><span class="line">Out[<span class="number">177</span>]: Period(<span class="string">&#x27;2011-11-01&#x27;</span>, <span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">178</span>]: p.asfreq(<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;end&#x27;</span>)</span><br><span class="line">Out[<span class="number">178</span>]: Period(<span class="string">&#x27;2012-01-31&#x27;</span>, <span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-e2e1d52c9766f6ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11.2 不同季度型频率之间的转换"></p>
<p>因此，Period之间的算术运算会非常简单。例如，要获取该季度倒数第二个工作日下午4点的时间戳，你可以这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">179</span>]: p4pm = (p.asfreq(<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;e&#x27;</span>) - <span class="number">1</span>).asfreq(<span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27;s&#x27;</span>) + <span class="number">16</span> * <span class="number">60</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">180</span>]: p4pm</span><br><span class="line">Out[<span class="number">180</span>]: Period(<span class="string">&#x27;2012-01-30 16:00&#x27;</span>, <span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">181</span>]: p4pm.to_timestamp()</span><br><span class="line">Out[<span class="number">181</span>]: Timestamp(<span class="string">&#x27;2012-01-30 16:00:00&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>period_range可用于生成季度型范围。季度型范围的算术运算也跟上面是一样的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">182</span>]: rng = pd.period_range(<span class="string">&#x27;2011Q3&#x27;</span>, <span class="string">&#x27;2012Q4&#x27;</span>, freq=<span class="string">&#x27;Q-JAN&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">183</span>]: ts = pd.Series(np.arange(<span class="built_in">len</span>(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">184</span>]: ts</span><br><span class="line">Out[<span class="number">184</span>]: </span><br><span class="line">2011Q3    <span class="number">0</span></span><br><span class="line">2011Q4    <span class="number">1</span></span><br><span class="line">2012Q1    <span class="number">2</span></span><br><span class="line">2012Q2    <span class="number">3</span></span><br><span class="line">2012Q3    <span class="number">4</span></span><br><span class="line">2012Q4    <span class="number">5</span></span><br><span class="line">Freq: Q-JAN, dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">185</span>]: new_rng = (rng.asfreq(<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;e&#x27;</span>) - <span class="number">1</span>).asfreq(<span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27;s&#x27;</span>) + <span class="number">16</span> * <span class="number">60</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">186</span>]: ts.index = new_rng.to_timestamp()</span><br><span class="line"></span><br><span class="line">In [<span class="number">187</span>]: ts</span><br><span class="line">Out[<span class="number">187</span>]:</span><br><span class="line"><span class="number">2010</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">16</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">0</span></span><br><span class="line"><span class="number">2011</span>-01-<span class="number">28</span> <span class="number">16</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">1</span></span><br><span class="line"><span class="number">2011</span>-04-<span class="number">28</span> <span class="number">16</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">2</span></span><br><span class="line"><span class="number">2011</span>-07-<span class="number">28</span> <span class="number">16</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">3</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">16</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">4</span></span><br><span class="line"><span class="number">2012</span>-01-<span class="number">30</span> <span class="number">16</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">5</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<h2><span id="将timestamp转换为period及其反向过程">将Timestamp转换为Period（及其反向过程）</span></h2><p>通过使用to_period方法，可以将由时间戳索引的Series和DataFrame对象转换为以时期索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">188</span>]: rng = pd.date_range(<span class="string">&#x27;2000-01-01&#x27;</span>, periods=<span class="number">3</span>, freq=<span class="string">&#x27;M&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">189</span>]: ts = pd.Series(np.random.randn(<span class="number">3</span>), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">190</span>]: ts</span><br><span class="line">Out[<span class="number">190</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>    <span class="number">1.663261</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span>   -<span class="number">0.996206</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>    <span class="number">1.521760</span></span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">191</span>]: pts = ts.to_period()</span><br><span class="line"></span><br><span class="line">In [<span class="number">192</span>]: pts</span><br><span class="line">Out[<span class="number">192</span>]: </span><br><span class="line"><span class="number">2000</span>-01    <span class="number">1.663261</span></span><br><span class="line"><span class="number">2000</span>-02   -<span class="number">0.996206</span></span><br><span class="line"><span class="number">2000</span>-03    <span class="number">1.521760</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure>
<p>由于时期指的是非重叠时间区间，因此对于给定的频率，一个时间戳只能属于一个时期。新PeriodIndex的频率默认是从时间戳推断而来的，你也可以指定任何别的频率。结果中允许存在重复时期：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">193</span>]: rng = pd.date_range(<span class="string">&#x27;1/29/2000&#x27;</span>, periods=<span class="number">6</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">194</span>]: ts2 = pd.Series(np.random.randn(<span class="number">6</span>), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">195</span>]: ts2</span><br><span class="line">Out[<span class="number">195</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">29</span>    <span class="number">0.244175</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">30</span>    <span class="number">0.423331</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.654040</span></span><br><span class="line"><span class="number">2000</span>-02-01    <span class="number">2.089154</span></span><br><span class="line"><span class="number">2000</span>-02-02   -<span class="number">0.060220</span></span><br><span class="line"><span class="number">2000</span>-02-03   -<span class="number">0.167933</span></span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">196</span>]: ts2.to_period(<span class="string">&#x27;M&#x27;</span>)</span><br><span class="line">Out[<span class="number">196</span>]: </span><br><span class="line"><span class="number">2000</span>-01    <span class="number">0.244175</span></span><br><span class="line"><span class="number">2000</span>-01    <span class="number">0.423331</span></span><br><span class="line"><span class="number">2000</span>-01   -<span class="number">0.654040</span></span><br><span class="line"><span class="number">2000</span>-02    <span class="number">2.089154</span></span><br><span class="line"><span class="number">2000</span>-02   -<span class="number">0.060220</span></span><br><span class="line"><span class="number">2000</span>-02   -<span class="number">0.167933</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>要转换回时间戳，使用to_timestamp即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">197</span>]: pts = ts2.to_period()</span><br><span class="line"></span><br><span class="line">In [<span class="number">198</span>]: pts</span><br><span class="line">Out[<span class="number">198</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">29</span>    <span class="number">0.244175</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">30</span>    <span class="number">0.423331</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.654040</span></span><br><span class="line"><span class="number">2000</span>-02-01    <span class="number">2.089154</span></span><br><span class="line"><span class="number">2000</span>-02-02   -<span class="number">0.060220</span></span><br><span class="line"><span class="number">2000</span>-02-03   -<span class="number">0.167933</span></span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">199</span>]: pts.to_timestamp(how=<span class="string">&#x27;end&#x27;</span>)</span><br><span class="line">Out[<span class="number">199</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">29</span>    <span class="number">0.244175</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">30</span>    <span class="number">0.423331</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.654040</span></span><br><span class="line"><span class="number">2000</span>-02-01    <span class="number">2.089154</span></span><br><span class="line"><span class="number">2000</span>-02-02   -<span class="number">0.060220</span></span><br><span class="line"><span class="number">2000</span>-02-03   -<span class="number">0.167933</span></span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<h2><span id="通过数组创建periodindex">通过数组创建PeriodIndex</span></h2><p>固定频率的数据集通常会将时间信息分开存放在多个列中。例如，在下面这个宏观经济数据集中，年度和季度就分别存放在不同的列中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">200</span>]: data = pd.read_csv(<span class="string">&#x27;examples/macrodata.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">201</span>]: data.head(<span class="number">5</span>)</span><br><span class="line">Out[<span class="number">201</span>]: </span><br><span class="line">     year  quarter   realgdp  realcons  realinv  realgovt  realdpi    cpi  \</span><br><span class="line"><span class="number">0</span>  <span class="number">1959.0</span>      <span class="number">1.0</span>  <span class="number">2710.349</span>    <span class="number">1707.4</span>  <span class="number">286.898</span>   <span class="number">470.045</span>   <span class="number">1886.9</span>  <span class="number">28.98</span>   </span><br><span class="line"><span class="number">1</span>  <span class="number">1959.0</span>      <span class="number">2.0</span>  <span class="number">2778.801</span>    <span class="number">1733.7</span>  <span class="number">310.859</span>   <span class="number">481.301</span>   <span class="number">1919.7</span>  <span class="number">29.15</span>   </span><br><span class="line"><span class="number">2</span>  <span class="number">1959.0</span>      <span class="number">3.0</span>  <span class="number">2775.488</span>    <span class="number">1751.8</span>  <span class="number">289.226</span>   <span class="number">491.260</span>   <span class="number">1916.4</span>  <span class="number">29.35</span>   </span><br><span class="line"><span class="number">3</span>  <span class="number">1959.0</span>      <span class="number">4.0</span>  <span class="number">2785.204</span>    <span class="number">1753.7</span>  <span class="number">299.356</span>   <span class="number">484.052</span>   <span class="number">1931.3</span>  <span class="number">29.37</span>   </span><br><span class="line"><span class="number">4</span>  <span class="number">1960.0</span>      <span class="number">1.0</span>  <span class="number">2847.699</span>    <span class="number">1770.5</span>  <span class="number">331.722</span>   <span class="number">462.199</span>   <span class="number">1955.5</span>  <span class="number">29.54</span>   </span><br><span class="line">      m1  tbilrate  unemp      pop  infl  realint  </span><br><span class="line"><span class="number">0</span>  <span class="number">139.7</span>      <span class="number">2.82</span>    <span class="number">5.8</span>  <span class="number">177.146</span>  <span class="number">0.00</span>     <span class="number">0.00</span>  </span><br><span class="line"><span class="number">1</span>  <span class="number">141.7</span>      <span class="number">3.08</span>    <span class="number">5.1</span>  <span class="number">177.830</span>  <span class="number">2.34</span>     <span class="number">0.74</span>  </span><br><span class="line"><span class="number">2</span>  <span class="number">140.5</span>      <span class="number">3.82</span>    <span class="number">5.3</span>  <span class="number">178.657</span>  <span class="number">2.74</span>     <span class="number">1.09</span>  </span><br><span class="line"><span class="number">3</span>  <span class="number">140.0</span>      <span class="number">4.33</span>    <span class="number">5.6</span>  <span class="number">179.386</span>  <span class="number">0.27</span>     <span class="number">4.06</span>  </span><br><span class="line"><span class="number">4</span>  <span class="number">139.6</span>      <span class="number">3.50</span>    <span class="number">5.2</span>  <span class="number">180.007</span>  <span class="number">2.31</span>     <span class="number">1.19</span>  </span><br><span class="line"></span><br><span class="line">In [<span class="number">202</span>]: data.year</span><br><span class="line">Out[<span class="number">202</span>]: </span><br><span class="line"><span class="number">0</span>      <span class="number">1959.0</span></span><br><span class="line"><span class="number">1</span>      <span class="number">1959.0</span></span><br><span class="line"><span class="number">2</span>      <span class="number">1959.0</span></span><br><span class="line"><span class="number">3</span>      <span class="number">1959.0</span></span><br><span class="line"><span class="number">4</span>      <span class="number">1960.0</span></span><br><span class="line"><span class="number">5</span>      <span class="number">1960.0</span></span><br><span class="line"><span class="number">6</span>      <span class="number">1960.0</span></span><br><span class="line"><span class="number">7</span>      <span class="number">1960.0</span></span><br><span class="line"><span class="number">8</span>      <span class="number">1961.0</span></span><br><span class="line"><span class="number">9</span>      <span class="number">1961.0</span></span><br><span class="line">        ...  </span><br><span class="line"><span class="number">193</span>    <span class="number">2007.0</span></span><br><span class="line"><span class="number">194</span>    <span class="number">2007.0</span></span><br><span class="line"><span class="number">195</span>    <span class="number">2007.0</span></span><br><span class="line"><span class="number">196</span>    <span class="number">2008.0</span></span><br><span class="line"><span class="number">197</span>    <span class="number">2008.0</span></span><br><span class="line"><span class="number">198</span>    <span class="number">2008.0</span></span><br><span class="line"><span class="number">199</span>    <span class="number">2008.0</span></span><br><span class="line"><span class="number">200</span>    <span class="number">2009.0</span></span><br><span class="line"><span class="number">201</span>    <span class="number">2009.0</span></span><br><span class="line"><span class="number">202</span>    <span class="number">2009.0</span></span><br><span class="line">Name: year, Length: <span class="number">203</span>, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">203</span>]: data.quarter</span><br><span class="line">Out[<span class="number">203</span>]: </span><br><span class="line"><span class="number">0</span>      <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>      <span class="number">2.0</span></span><br><span class="line"><span class="number">2</span>      <span class="number">3.0</span></span><br><span class="line"><span class="number">3</span>      <span class="number">4.0</span></span><br><span class="line"><span class="number">4</span>      <span class="number">1.0</span></span><br><span class="line"><span class="number">5</span>      <span class="number">2.0</span></span><br><span class="line"><span class="number">6</span>      <span class="number">3.0</span></span><br><span class="line"><span class="number">7</span>      <span class="number">4.0</span></span><br><span class="line"><span class="number">8</span>      <span class="number">1.0</span></span><br><span class="line"><span class="number">9</span>      <span class="number">2.0</span></span><br><span class="line">      ... </span><br><span class="line"><span class="number">193</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">194</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">195</span>    <span class="number">4.0</span></span><br><span class="line"><span class="number">196</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">197</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">198</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">199</span>    <span class="number">4.0</span></span><br><span class="line"><span class="number">200</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">201</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">202</span>    <span class="number">3.0</span></span><br><span class="line">Name: quarter, Length: <span class="number">203</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>通过将这些数组以及一个频率传入PeriodIndex，就可以将它们合并成DataFrame的一个索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">204</span>]: index = pd.PeriodIndex(year=data.year, quarter=data.quarter,</span><br><span class="line">   .....:                        freq=<span class="string">&#x27;Q-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">205</span>]: index</span><br><span class="line">Out[<span class="number">205</span>]: </span><br><span class="line">PeriodIndex([<span class="string">&#x27;1959Q1&#x27;</span>, <span class="string">&#x27;1959Q2&#x27;</span>, <span class="string">&#x27;1959Q3&#x27;</span>, <span class="string">&#x27;1959Q4&#x27;</span>, <span class="string">&#x27;1960Q1&#x27;</span>, <span class="string">&#x27;1960Q2&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;1960Q3&#x27;</span>, <span class="string">&#x27;1960Q4&#x27;</span>, <span class="string">&#x27;1961Q1&#x27;</span>, <span class="string">&#x27;1961Q2&#x27;</span>,</span><br><span class="line">             ...</span><br><span class="line">             <span class="string">&#x27;2007Q2&#x27;</span>, <span class="string">&#x27;2007Q3&#x27;</span>, <span class="string">&#x27;2007Q4&#x27;</span>, <span class="string">&#x27;2008Q1&#x27;</span>, <span class="string">&#x27;2008Q2&#x27;</span>, <span class="string">&#x27;2008Q3&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;2008Q4&#x27;</span>, <span class="string">&#x27;2009Q1&#x27;</span>, <span class="string">&#x27;2009Q2&#x27;</span>, <span class="string">&#x27;2009Q3&#x27;</span>],</span><br><span class="line">            dtype=<span class="string">&#x27;period[Q-DEC]&#x27;</span>, length=<span class="number">203</span>, freq=<span class="string">&#x27;Q-DEC&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">206</span>]: data.index = index</span><br><span class="line"></span><br><span class="line">In [<span class="number">207</span>]: data.infl</span><br><span class="line">Out[<span class="number">207</span>]: </span><br><span class="line">1959Q1    <span class="number">0.00</span></span><br><span class="line">1959Q2    <span class="number">2.34</span></span><br><span class="line">1959Q3    <span class="number">2.74</span></span><br><span class="line">1959Q4    <span class="number">0.27</span></span><br><span class="line">1960Q1    <span class="number">2.31</span></span><br><span class="line">1960Q2    <span class="number">0.14</span></span><br><span class="line">1960Q3    <span class="number">2.70</span></span><br><span class="line">1960Q4    <span class="number">1.21</span></span><br><span class="line">1961Q1   -<span class="number">0.40</span></span><br><span class="line">1961Q2    <span class="number">1.47</span></span><br><span class="line">          ... </span><br><span class="line">2007Q2    <span class="number">2.75</span></span><br><span class="line">2007Q3    <span class="number">3.45</span></span><br><span class="line">2007Q4    <span class="number">6.38</span></span><br><span class="line">2008Q1    <span class="number">2.82</span></span><br><span class="line">2008Q2    <span class="number">8.53</span></span><br><span class="line">2008Q3   -<span class="number">3.16</span></span><br><span class="line">2008Q4   -<span class="number">8.79</span></span><br><span class="line">2009Q1    <span class="number">0.94</span></span><br><span class="line">2009Q2    <span class="number">3.37</span></span><br><span class="line">2009Q3    <span class="number">3.56</span></span><br><span class="line">Freq: Q-DEC, Name: infl, Length: <span class="number">203</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<h1><span id="116-重采样及频率转换">11.6 重采样及频率转换</span></h1><p>重采样（resampling）指的是将时间序列从一个频率转换到另一个频率的处理过程。将高频率数据聚合到低频率称为降采样（downsampling），而将低频率数据转换到高频率则称为升采样（upsampling）。并不是所有的重采样都能被划分到这两个大类中。例如，将W-WED（每周三）转换为W-FRI既不是降采样也不是升采样。</p>
<p>pandas对象都带有一个resample方法，它是各种频率转换工作的主力函数。resample有一个类似于groupby的API，调用resample可以分组数据，然后会调用一个聚合函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">208</span>]: rng = pd.date_range(<span class="string">&#x27;2000-01-01&#x27;</span>, periods=<span class="number">100</span>, freq=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">209</span>]: ts = pd.Series(np.random.randn(<span class="built_in">len</span>(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">210</span>]: ts</span><br><span class="line">Out[<span class="number">210</span>]: </span><br><span class="line"><span class="number">2000</span>-01-01    <span class="number">0.631634</span></span><br><span class="line"><span class="number">2000</span>-01-02   -<span class="number">1.594313</span></span><br><span class="line"><span class="number">2000</span>-01-03   -<span class="number">1.519937</span></span><br><span class="line"><span class="number">2000</span>-01-04    <span class="number">1.108752</span></span><br><span class="line"><span class="number">2000</span>-01-05    <span class="number">1.255853</span></span><br><span class="line"><span class="number">2000</span>-01-06   -<span class="number">0.024330</span></span><br><span class="line"><span class="number">2000</span>-01-07   -<span class="number">2.047939</span></span><br><span class="line"><span class="number">2000</span>-01-08   -<span class="number">0.272657</span></span><br><span class="line"><span class="number">2000</span>-01-09   -<span class="number">1.692615</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">10</span>    <span class="number">1.423830</span></span><br><span class="line">                ...   </span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>   -<span class="number">0.007852</span></span><br><span class="line"><span class="number">2000</span>-04-01   -<span class="number">1.638806</span></span><br><span class="line"><span class="number">2000</span>-04-02    <span class="number">1.401227</span></span><br><span class="line"><span class="number">2000</span>-04-03    <span class="number">1.758539</span></span><br><span class="line"><span class="number">2000</span>-04-04    <span class="number">0.628932</span></span><br><span class="line"><span class="number">2000</span>-04-05   -<span class="number">0.423776</span></span><br><span class="line"><span class="number">2000</span>-04-06    <span class="number">0.789740</span></span><br><span class="line"><span class="number">2000</span>-04-07    <span class="number">0.937568</span></span><br><span class="line"><span class="number">2000</span>-04-08   -<span class="number">2.253294</span></span><br><span class="line"><span class="number">2000</span>-04-09   -<span class="number">1.772919</span></span><br><span class="line">Freq: D, Length: <span class="number">100</span>, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">211</span>]: ts.resample(<span class="string">&#x27;M&#x27;</span>).mean()</span><br><span class="line">Out[<span class="number">211</span>]: </span><br><span class="line"><span class="number">2000</span>-01-<span class="number">31</span>   -<span class="number">0.165893</span></span><br><span class="line"><span class="number">2000</span>-02-<span class="number">29</span>    <span class="number">0.078606</span></span><br><span class="line"><span class="number">2000</span>-03-<span class="number">31</span>    <span class="number">0.223811</span></span><br><span class="line"><span class="number">2000</span>-04-<span class="number">30</span>   -<span class="number">0.063643</span></span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">212</span>]: ts.resample(<span class="string">&#x27;M&#x27;</span>, kind=<span class="string">&#x27;period&#x27;</span>).mean()</span><br><span class="line">Out[<span class="number">212</span>]: </span><br><span class="line"><span class="number">2000</span>-01   -<span class="number">0.165893</span></span><br><span class="line"><span class="number">2000</span>-02    <span class="number">0.078606</span></span><br><span class="line"><span class="number">2000</span>-03    <span class="number">0.223811</span></span><br><span class="line"><span class="number">2000</span>-04   -<span class="number">0.063643</span></span><br><span class="line">Freq: M, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>resample是一个灵活高效的方法，可用于处理非常大的时间序列。我将通过一系列的示例说明其用法。表11-5总结它的一些选项。</p>
<p>表11-5 resample方法的参数<br><img data-src="https://upload-images.jianshu.io/upload_images/7178691-b40a57086c904e83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h2><span id="降采样">降采样</span></h2><p>将数据聚合到规律的低频率是一件非常普通的时间序列处理任务。待聚合的数据不必拥有固定的频率，期望的频率会自动定义聚合的面元边界，这些面元用于将时间序列拆分为多个片段。例如，要转换到月度频率（’M’或’BM’），数据需要被划分到多个单月时间段中。各时间段都是半开放的。一个数据点只能属于一个时间段，所有时间段的并集必须能组成整个时间帧。在用resample对数据进行降采样时，需要考虑两样东西：</p>
<ul>
<li>各区间哪边是闭合的。</li>
<li>如何标记各个聚合面元，用区间的开头还是末尾。</li>
</ul>
<p>为了说明，我们来看一些“1分钟”数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">213</span>]: rng = pd.date_range(<span class="string">&#x27;2000-01-01&#x27;</span>, periods=<span class="number">12</span>, freq=<span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">214</span>]: ts = pd.Series(np.arange(<span class="number">12</span>), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">215</span>]: ts</span><br><span class="line">Out[<span class="number">215</span>]: </span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>     <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:01:<span class="number">00</span>     <span class="number">1</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:02:<span class="number">00</span>     <span class="number">2</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:03:<span class="number">00</span>     <span class="number">3</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:04:<span class="number">00</span>     <span class="number">4</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:05:<span class="number">00</span>     <span class="number">5</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:06:<span class="number">00</span>     <span class="number">6</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:07:<span class="number">00</span>     <span class="number">7</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:08:<span class="number">00</span>     <span class="number">8</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:09:<span class="number">00</span>     <span class="number">9</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>    <span class="number">10</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">11</span>:<span class="number">00</span>    <span class="number">11</span></span><br><span class="line">Freq: T, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>假设你想要通过求和的方式将这些数据聚合到“5分钟”块中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">216</span>]: ts.resample(<span class="string">&#x27;5min&#x27;</span>, closed=<span class="string">&#x27;right&#x27;</span>).<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">216</span>]: </span><br><span class="line"><span class="number">1999</span>-<span class="number">12</span>-<span class="number">31</span> <span class="number">23</span>:<span class="number">55</span>:<span class="number">00</span>     <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">15</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:05:<span class="number">00</span>    <span class="number">40</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>    <span class="number">11</span></span><br><span class="line">Freq: 5T, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>传入的频率将会以“5分钟”的增量定义面元边界。默认情况下，面元的右边界是包含的，因此00:00到00:05的区间中是包含00:05的。传入closed=’left’会让区间以左边界闭合：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">217</span>]: ts.resample(<span class="string">&#x27;5min&#x27;</span>, closed=<span class="string">&#x27;right&#x27;</span>).<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">217</span>]: </span><br><span class="line"><span class="number">1999</span>-<span class="number">12</span>-<span class="number">31</span> <span class="number">23</span>:<span class="number">55</span>:<span class="number">00</span>     <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>    <span class="number">15</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:05:<span class="number">00</span>    <span class="number">40</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>    <span class="number">11</span></span><br><span class="line">Freq: 5T, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>如你所见，最终的时间序列是以各面元右边界的时间戳进行标记的。传入label=’right’即可用面元的邮编界对其进行标记：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">218</span>]: ts.resample(<span class="string">&#x27;5min&#x27;</span>, closed=<span class="string">&#x27;right&#x27;</span>, label=<span class="string">&#x27;right&#x27;</span>).<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">218</span>]: </span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>     <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:05:<span class="number">00</span>    <span class="number">15</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>    <span class="number">40</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">15</span>:<span class="number">00</span>    <span class="number">11</span></span><br><span class="line">Freq: 5T, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>图11-3说明了“1分钟”数据被转换为“5分钟”数据的处理过程。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-7a77f47844f2ee8c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-3 各种closed、label约定的“5分钟”重采样演示"></p>
<p>最后，你可能希望对结果索引做一些位移，比如从右边界减去一秒以便更容易明白该时间戳到底表示的是哪个区间。只需通过loffset设置一个字符串或日期偏移量即可实现这个目的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">219</span>]: ts.resample(<span class="string">&#x27;5min&#x27;</span>, closed=<span class="string">&#x27;right&#x27;</span>,</span><br><span class="line">   .....:             label=<span class="string">&#x27;right&#x27;</span>, loffset=<span class="string">&#x27;-1s&#x27;</span>).<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">219</span>]: </span><br><span class="line"><span class="number">1999</span>-<span class="number">12</span>-<span class="number">31</span> <span class="number">23</span>:<span class="number">59</span>:<span class="number">59</span>     <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:04:<span class="number">59</span>    <span class="number">15</span></span><br><span class="line">In [<span class="number">219</span>]: ts.resample(<span class="string">&#x27;5min&#x27;</span>, closed=<span class="string">&#x27;right&#x27;</span>,</span><br><span class="line">   .....:             label=<span class="string">&#x27;right&#x27;</span>, loffset=<span class="string">&#x27;-1s&#x27;</span>).<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">219</span>]: </span><br><span class="line"><span class="number">1999</span>-<span class="number">12</span>-<span class="number">31</span> <span class="number">23</span>:<span class="number">59</span>:<span class="number">59</span>     <span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:04:<span class="number">59</span>    <span class="number">15</span></span><br></pre></td></tr></table></figure></p>
<p>此外，也可以通过调用结果对象的shift方法来实现该目的，这样就不需要设置loffset了。</p>
<h2><span id="ohlc重采样">OHLC重采样</span></h2><p>金融领域中有一种无所不在的时间序列聚合方式，即计算各面元的四个值：第一个值（open，开盘）、最后一个值（close，收盘）、最大值（high，最高）以及最小值（low，最低）。传入how=’ohlc’即可得到一个含有这四种聚合值的DataFrame。整个过程很高效，只需一次扫描即可计算出结果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">220</span>]: ts.resample(<span class="string">&#x27;5min&#x27;</span>).ohlc()</span><br><span class="line">Out[<span class="number">220</span>]: </span><br><span class="line">                     <span class="built_in">open</span>  high  low  close</span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>     <span class="number">0</span>     <span class="number">4</span>    <span class="number">0</span>      <span class="number">4</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:05:<span class="number">00</span>     <span class="number">5</span>     <span class="number">9</span>    <span class="number">5</span>      <span class="number">9</span></span><br><span class="line"><span class="number">2000</span>-01-01 <span class="number">00</span>:<span class="number">10</span>:<span class="number">00</span>    <span class="number">10</span>    <span class="number">11</span>   <span class="number">10</span>     <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="升采样和插值">升采样和插值</span></h2><p>在将数据从低频率转换到高频率时，就不需要聚合了。我们来看一个带有一些周型数据的DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">221</span>]: frame = pd.DataFrame(np.random.randn(<span class="number">2</span>, <span class="number">4</span>),</span><br><span class="line">   .....:                      index=pd.date_range(<span class="string">&#x27;1/1/2000&#x27;</span>, periods=<span class="number">2</span>,</span><br><span class="line">   .....:                                          freq=<span class="string">&#x27;W-WED&#x27;</span>),</span><br><span class="line">   .....:                      columns=[<span class="string">&#x27;Colorado&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">222</span>]: frame</span><br><span class="line">Out[<span class="number">222</span>]: </span><br><span class="line">            Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2000</span>-01-05 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">12</span> -<span class="number">0.046662</span>  <span class="number">0.927238</span>  <span class="number">0.482284</span> -<span class="number">0.867130</span></span><br></pre></td></tr></table></figure></p>
<p>当你对这个数据进行聚合，每组只有一个值，这样就会引入缺失值。我们使用asfreq方法转换成高频，不经过聚合：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">223</span>]: df_daily = frame.resample(<span class="string">&#x27;D&#x27;</span>).asfreq()</span><br><span class="line"></span><br><span class="line">In [<span class="number">224</span>]: df_daily</span><br><span class="line">Out[<span class="number">224</span>]: </span><br><span class="line">            Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2000</span>-01-05 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-06       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-07       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-08       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-09       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-<span class="number">10</span>       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-<span class="number">11</span>       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-<span class="number">12</span> -<span class="number">0.046662</span>  <span class="number">0.927238</span>  <span class="number">0.482284</span> -<span class="number">0.867130</span></span><br></pre></td></tr></table></figure></p>
<p>假设你想要用前面的周型值填充“非星期三”。resampling的填充和插值方式跟fillna和reindex的一样：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">225</span>]: frame.resample(<span class="string">&#x27;D&#x27;</span>).ffill()</span><br><span class="line">Out[<span class="number">225</span>]: </span><br><span class="line">            Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2000</span>-01-05 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-06 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-07 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-08 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-09 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">10</span> -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">11</span> -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">12</span> -<span class="number">0.046662</span>  <span class="number">0.927238</span>  <span class="number">0.482284</span> -<span class="number">0.867130</span></span><br></pre></td></tr></table></figure></p>
<p>同样，这里也可以只填充指定的时期数（目的是限制前面的观测值的持续使用距离）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">226</span>]: frame.resample(<span class="string">&#x27;D&#x27;</span>).ffill(limit=<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">226</span>]:</span><br><span class="line">            Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2000</span>-01-05 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-06 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-07 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-08       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-09       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-<span class="number">10</span>       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-<span class="number">11</span>       NaN       NaN       NaN       NaN</span><br><span class="line"><span class="number">2000</span>-01-<span class="number">12</span> -<span class="number">0.046662</span>  <span class="number">0.927238</span>  <span class="number">0.482284</span> -<span class="number">0.867130</span></span><br></pre></td></tr></table></figure></p>
<p>注意，新的日期索引完全没必要跟旧的重叠：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">227</span>]: frame.resample(<span class="string">&#x27;W-THU&#x27;</span>).ffill()</span><br><span class="line">Out[<span class="number">227</span>]: </span><br><span class="line">            Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2000</span>-01-06 -<span class="number">0.896431</span>  <span class="number">0.677263</span>  <span class="number">0.036503</span>  <span class="number">0.087102</span></span><br><span class="line"><span class="number">2000</span>-01-<span class="number">13</span> -<span class="number">0.046662</span>  <span class="number">0.927238</span>  <span class="number">0.482284</span> -<span class="number">0.867130</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="通过时期进行重采样">通过时期进行重采样</span></h2><p>对那些使用时期索引的数据进行重采样与时间戳很像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">228</span>]: frame = pd.DataFrame(np.random.randn(<span class="number">24</span>, <span class="number">4</span>),</span><br><span class="line">   .....:                      index=pd.period_range(<span class="string">&#x27;1-2000&#x27;</span>, <span class="string">&#x27;12-2001&#x27;</span>,</span><br><span class="line">   .....:                                            freq=<span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">   .....:                      columns=[<span class="string">&#x27;Colorado&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">229</span>]: frame[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">229</span>]: </span><br><span class="line">         Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2000</span>-01  <span class="number">0.493841</span> -<span class="number">0.155434</span>  <span class="number">1.397286</span>  <span class="number">1.507055</span></span><br><span class="line"><span class="number">2000</span>-02 -<span class="number">1.179442</span>  <span class="number">0.443171</span>  <span class="number">1.395676</span> -<span class="number">0.529658</span></span><br><span class="line"><span class="number">2000</span>-03  <span class="number">0.787358</span>  <span class="number">0.248845</span>  <span class="number">0.743239</span>  <span class="number">1.267746</span></span><br><span class="line"><span class="number">2000</span>-04  <span class="number">1.302395</span> -<span class="number">0.272154</span> -<span class="number">0.051532</span> -<span class="number">0.467740</span></span><br><span class="line"><span class="number">2000</span>-05 -<span class="number">1.040816</span>  <span class="number">0.426419</span>  <span class="number">0.312945</span> -<span class="number">1.115689</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">230</span>]: annual_frame = frame.resample(<span class="string">&#x27;A-DEC&#x27;</span>).mean()</span><br><span class="line"></span><br><span class="line">In [<span class="number">231</span>]: annual_frame</span><br><span class="line">Out[<span class="number">231</span>]: </span><br><span class="line">      Colorado     Texas  New York      Ohio</span><br><span class="line"><span class="number">2000</span>  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line"><span class="number">2001</span>  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br></pre></td></tr></table></figure>
<p>升采样要稍微麻烦一些，因为你必须决定在新频率中各区间的哪端用于放置原来的值，就像asfreq方法那样。convention参数默认为’start’，也可设置为’end’：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Q-DEC: Quarterly, year ending in December</span></span><br><span class="line">In [<span class="number">232</span>]: annual_frame.resample(<span class="string">&#x27;Q-DEC&#x27;</span>).ffill()</span><br><span class="line">Out[<span class="number">232</span>]: </span><br><span class="line">        Colorado     Texas  New York      Ohio</span><br><span class="line">2000Q1  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2000Q2  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2000Q3  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2000Q4  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q1  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br><span class="line">2001Q2  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br><span class="line">2001Q3  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br><span class="line">2001Q4  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">233</span>]: annual_frame.resample(<span class="string">&#x27;Q-DEC&#x27;</span>, convention=<span class="string">&#x27;end&#x27;</span>).ffill()</span><br><span class="line">Out[<span class="number">233</span>]: </span><br><span class="line">        Colorado     Texas  New York      Ohio</span><br><span class="line">2000Q4  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q1  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q2  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q3  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q4  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br></pre></td></tr></table></figure>
<p>由于时期指的是时间区间，所以升采样和降采样的规则就比较严格：</p>
<ul>
<li>在降采样中，目标频率必须是源频率的子时期（subperiod）。</li>
<li>在升采样中，目标频率必须是源频率的超时期（superperiod）。</li>
</ul>
<p>如果不满足这些条件，就会引发异常。这主要影响的是按季、年、周计算的频率。例如，由Q-MAR定义的时间区间只能升采样为A-MAR、A-JUN、A-SEP、A-DEC等：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">234</span>]: annual_frame.resample(<span class="string">&#x27;Q-MAR&#x27;</span>).ffill()</span><br><span class="line">Out[<span class="number">234</span>]: </span><br><span class="line">        Colorado     Texas  New York      Ohio</span><br><span class="line">2000Q4  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q1  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q2  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q3  <span class="number">0.556703</span>  <span class="number">0.016631</span>  <span class="number">0.111873</span> -<span class="number">0.027445</span></span><br><span class="line">2001Q4  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br><span class="line">2002Q1  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br><span class="line">2002Q2  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br><span class="line">2002Q3  <span class="number">0.046303</span>  <span class="number">0.163344</span>  <span class="number">0.251503</span> -<span class="number">0.157276</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="117-移动窗口函数">11.7 移动窗口函数</span></h1><p>在移动窗口（可以带有指数衰减权数）上计算的各种统计函数也是一类常见于时间序列的数组变换。这样可以圆滑噪音数据或断裂数据。我将它们称为移动窗口函数（moving window function），其中还包括那些窗口不定长的函数（如指数加权移动平均）。跟其他统计函数一样，移动窗口函数也会自动排除缺失值。</p>
<p>开始之前，我们加载一些时间序列数据，将其重采样为工作日频率：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">235</span>]: close_px_all = pd.read_csv(<span class="string">&#x27;examples/stock_px_2.csv&#x27;</span>,</span><br><span class="line">   .....:                            parse_dates=<span class="literal">True</span>, index_col=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">236</span>]: close_px = close_px_all[[<span class="string">&#x27;AAPL&#x27;</span>, <span class="string">&#x27;MSFT&#x27;</span>, <span class="string">&#x27;XOM&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">237</span>]: close_px = close_px.resample(<span class="string">&#x27;B&#x27;</span>).ffill()</span><br></pre></td></tr></table></figure></p>
<p>现在引入rolling运算符，它与resample和groupby很像。可以在TimeSeries或DataFrame以及一个window（表示期数，见图11-4）上调用它：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">238</span>]: close_px.AAPL.plot()</span><br><span class="line">Out[<span class="number">238</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x7f2f2570cf98</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">239</span>]: close_px.AAPL.rolling(<span class="number">250</span>).mean().plot()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-3327483eab730b09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-4 苹果公司股价的250日均线"></p>
<p>表达式rolling(250)与groupby很像，但不是对其进行分组，而是创建一个按照250天分组的滑动窗口对象。然后，我们就得到了苹果公司股价的250天的移动窗口。</p>
<p>默认情况下，rolling函数需要窗口中所有的值为非NA值。可以修改该行为以解决缺失数据的问题。其实，在时间序列开始处尚不足窗口期的那些数据就是个特例（见图11-5）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">241</span>]: appl_std250 = close_px.AAPL.rolling(<span class="number">250</span>, min_periods=<span class="number">10</span>).std()</span><br><span class="line"></span><br><span class="line">In [<span class="number">242</span>]: appl_std250[<span class="number">5</span>:<span class="number">12</span>]</span><br><span class="line">Out[<span class="number">242</span>]: </span><br><span class="line"><span class="number">2003</span>-01-09         NaN</span><br><span class="line"><span class="number">2003</span>-01-<span class="number">10</span>         NaN</span><br><span class="line"><span class="number">2003</span>-01-<span class="number">13</span>         NaN</span><br><span class="line"><span class="number">2003</span>-01-<span class="number">14</span>         NaN</span><br><span class="line"><span class="number">2003</span>-01-<span class="number">15</span>    <span class="number">0.077496</span></span><br><span class="line"><span class="number">2003</span>-01-<span class="number">16</span>    <span class="number">0.074760</span></span><br><span class="line"><span class="number">2003</span>-01-<span class="number">17</span>    <span class="number">0.112368</span></span><br><span class="line">Freq: B, Name: AAPL, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">243</span>]: appl_std250.plot()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-15f565bed1ccad09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-5 苹果公司250日每日回报标准差"></p>
<p>要计算扩展窗口平均（expanding window mean），可以使用expanding而不是rolling。“扩展”意味着，从时间序列的起始处开始窗口，增加窗口直到它超过所有的序列。apple_std250时间序列的扩展窗口平均如下所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">244</span>]: expanding_mean = appl_std250.expanding().mean()</span><br></pre></td></tr></table></figure></p>
<p>对DataFrame调用rolling_mean（以及与之类似的函数）会将转换应用到所有的列上（见图11-6）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">246</span>]: close_px.rolling(<span class="number">60</span>).mean().plot(logy=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-979f748052b2279f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-6 各股价60日均线（对数Y轴）"></p>
<p>rolling函数也可以接受一个指定固定大小时间补偿字符串，而不是一组时期。这样可以方便处理不规律的时间序列。这些字符串也可以传递给resample。例如，我们可以计算20天的滚动均值，如下所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">247</span>]: close_px.rolling(<span class="string">&#x27;20D&#x27;</span>).mean()</span><br><span class="line">Out[<span class="number">247</span>]:</span><br><span class="line">                  AAPL       MSFT        XOM</span><br><span class="line"><span class="number">2003</span>-01-02    <span class="number">7.400000</span>  <span class="number">21.110000</span>  <span class="number">29.220000</span></span><br><span class="line"><span class="number">2003</span>-01-03    <span class="number">7.425000</span>  <span class="number">21.125000</span>  <span class="number">29.230000</span></span><br><span class="line"><span class="number">2003</span>-01-06    <span class="number">7.433333</span>  <span class="number">21.256667</span>  <span class="number">29.473333</span></span><br><span class="line"><span class="number">2003</span>-01-07    <span class="number">7.432500</span>  <span class="number">21.425000</span>  <span class="number">29.342500</span></span><br><span class="line"><span class="number">2003</span>-01-08    <span class="number">7.402000</span>  <span class="number">21.402000</span>  <span class="number">29.240000</span></span><br><span class="line"><span class="number">2003</span>-01-09    <span class="number">7.391667</span>  <span class="number">21.490000</span>  <span class="number">29.273333</span></span><br><span class="line"><span class="number">2003</span>-01-<span class="number">10</span>    <span class="number">7.387143</span>  <span class="number">21.558571</span>  <span class="number">29.238571</span></span><br><span class="line"><span class="number">2003</span>-01-<span class="number">13</span>    <span class="number">7.378750</span>  <span class="number">21.633750</span>  <span class="number">29.197500</span></span><br><span class="line"><span class="number">2003</span>-01-<span class="number">14</span>    <span class="number">7.370000</span>  <span class="number">21.717778</span>  <span class="number">29.194444</span></span><br><span class="line"><span class="number">2003</span>-01-<span class="number">15</span>    <span class="number">7.355000</span>  <span class="number">21.757000</span>  <span class="number">29.152000</span></span><br><span class="line"><span class="meta">... </span>               ...        ...        ...</span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-03  <span class="number">398.002143</span>  <span class="number">25.890714</span>  <span class="number">72.413571</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-04  <span class="number">396.802143</span>  <span class="number">25.807857</span>  <span class="number">72.427143</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-05  <span class="number">395.751429</span>  <span class="number">25.729286</span>  <span class="number">72.422857</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-06  <span class="number">394.099286</span>  <span class="number">25.673571</span>  <span class="number">72.375714</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-07  <span class="number">392.479333</span>  <span class="number">25.712000</span>  <span class="number">72.454667</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">10</span>  <span class="number">389.351429</span>  <span class="number">25.602143</span>  <span class="number">72.527857</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">11</span>  <span class="number">388.505000</span>  <span class="number">25.674286</span>  <span class="number">72.835000</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">12</span>  <span class="number">388.531429</span>  <span class="number">25.810000</span>  <span class="number">73.400714</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">13</span>  <span class="number">388.826429</span>  <span class="number">25.961429</span>  <span class="number">73.905000</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">14</span>  <span class="number">391.038000</span>  <span class="number">26.048667</span>  <span class="number">74.185333</span></span><br><span class="line">[<span class="number">2292</span> rows x <span class="number">3</span> columns]</span><br></pre></td></tr></table></figure></p>
<h2><span id="指数加权函数">指数加权函数</span></h2><p>另一种使用固定大小窗口及相等权数观测值的办法是，定义一个衰减因子（decay factor）常量，以便使近期的观测值拥有更大的权数。衰减因子的定义方式有很多，比较流行的是使用时间间隔（span），它可以使结果兼容于窗口大小等于时间间隔的简单移动窗口（simple moving window）函数。</p>
<p>由于指数加权统计会赋予近期的观测值更大的权数，因此相对于等权统计，它能“适应”更快的变化。</p>
<p>除了rolling和expanding，pandas还有ewm运算符。下面这个例子对比了苹果公司股价的30日移动平均和span=30的指数加权移动平均（如图11-7所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">249</span>]: aapl_px = close_px.AAPL[<span class="string">&#x27;2006&#x27;</span>:<span class="string">&#x27;2007&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">250</span>]: ma60 = aapl_px.rolling(<span class="number">30</span>, min_periods=<span class="number">20</span>).mean()</span><br><span class="line"></span><br><span class="line">In [<span class="number">251</span>]: ewma60 = aapl_px.ewm(span=<span class="number">30</span>).mean()</span><br><span class="line"></span><br><span class="line">In [<span class="number">252</span>]: ma60.plot(style=<span class="string">&#x27;k--&#x27;</span>, label=<span class="string">&#x27;Simple MA&#x27;</span>)</span><br><span class="line">Out[<span class="number">252</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x7f2f252161d0</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">253</span>]: ewma60.plot(style=<span class="string">&#x27;k-&#x27;</span>, label=<span class="string">&#x27;EW MA&#x27;</span>)</span><br><span class="line">Out[<span class="number">253</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x7f2f252161d0</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">254</span>]: plt.legend()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-dae48defe3749fad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-7 简单移动平均与指数加权移动平均"></p>
<h2><span id="二元移动窗口函数">二元移动窗口函数</span></h2><p>有些统计运算（如相关系数和协方差）需要在两个时间序列上执行。例如，金融分析师常常对某只股票对某个参考指数（如标准普尔500指数）的相关系数感兴趣。要进行说明，我们先计算我们感兴趣的时间序列的百分数变化：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">256</span>]: spx_px = close_px_all[<span class="string">&#x27;SPX&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">257</span>]: spx_rets = spx_px.pct_change()</span><br><span class="line"></span><br><span class="line">In [<span class="number">258</span>]: returns = close_px.pct_change()</span><br></pre></td></tr></table></figure></p>
<p>调用rolling之后，corr聚合函数开始计算与spx_rets滚动相关系数（结果见图11-8）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">259</span>]: corr = returns.AAPL.rolling(<span class="number">125</span>, min_periods=<span class="number">100</span>).corr(spx_rets)</span><br><span class="line"></span><br><span class="line">In [<span class="number">260</span>]: corr.plot()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-e81e0f602b4db0ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-8 AAPL 6个月的回报与标准普尔500指数的相关系数"></p>
<p>假设你想要一次性计算多只股票与标准普尔500指数的相关系数。虽然编写一个循环并新建一个DataFrame不是什么难事，但比较啰嗦。其实，只需传入一个TimeSeries和一个DataFrame，rolling_corr就会自动计算TimeSeries（本例中就是spx_rets）与DataFrame各列的相关系数。结果如图11-9所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">262</span>]: corr = returns.rolling(<span class="number">125</span>, min_periods=<span class="number">100</span>).corr(spx_rets)</span><br><span class="line"></span><br><span class="line">In [<span class="number">263</span>]: corr.plot()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-0a54a028a62b9b50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-9 3只股票6个月的回报与标准普尔500指数的相关系数"></p>
<h2><span id="用户定义的移动窗口函数">用户定义的移动窗口函数</span></h2><p>rolling_apply函数使你能够在移动窗口上应用自己设计的数组函数。唯一要求的就是：该函数要能从数组的各个片段中产生单个值（即约简）。比如说，当我们用rolling(…).quantile(q)计算样本分位数时，可能对样本中特定值的百分等级感兴趣。scipy.stats.percentileofscore函数就能达到这个目的（结果见图11-10）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">265</span>]: <span class="keyword">from</span> scipy.stats <span class="keyword">import</span> percentileofscore</span><br><span class="line"></span><br><span class="line">In [<span class="number">266</span>]: score_at_2percent = <span class="keyword">lambda</span> x: percentileofscore(x, <span class="number">0.02</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">267</span>]: result = returns.AAPL.rolling(<span class="number">250</span>).apply(score_at_2percent)</span><br><span class="line"></span><br><span class="line">In [<span class="number">268</span>]: result.plot()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-af49e84a90c23c1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图11-10 AAPL 2%回报率的百分等级（一年窗口期）"></p>
<p>如果你没安装SciPy，可以使用conda或pip安装。</p>
<h1><span id="118-总结">11.8 总结</span></h1><p>与前面章节接触的数据相比，时间序列数据要求不同类型的分析和数据转换工具。</p>
<p>在接下来的章节中，我们将学习一些高级的pandas方法和如何开始使用建模库statsmodels和scikit-learn。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-10.数据聚合和分组计算</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-10-%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88%E5%92%8C%E5%88%86%E7%BB%84%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>对数据集进行分组并对各组应用一个函数（无论是聚合还是转换），通常是数据分析工作中的重要环节。在将数据集加载、融合、准备好之后，通常就是计算分组统计或生成透视表。pandas提供了一个灵活高效的gruopby功能，它使你能以一种自然的方式对数据集进行切片、切块、摘要等操作。</p>
<span id="more"></span>
<p>关系型数据库和SQL（Structured Query Language，结构化查询语言）能够如此流行的原因之一就是其能够方便地对数据进行连接、过滤、转换和聚合。但是，像SQL这样的查询语言所能执行的分组运算的种类很有限。在本章中你将会看到，由于Python和pandas强大的表达能力，我们可以执行复杂得多的分组运算（利用任何可以接受pandas对象或NumPy数组的函数）。在本章中，你将会学到：</p>
<ul>
<li>使用一个或多个键（形式可以是函数、数组或DataFrame列名）分割pandas对象。</li>
<li>计算分组的概述统计，比如数量、平均值或标准差，或是用户定义的函数。</li>
<li>应用组内转换或其他运算，如规格化、线性回归、排名或选取子集等。</li>
<li>计算透视表或交叉表。</li>
<li>执行分位数分析以及其它统计分组分析。</li>
</ul>
<blockquote>
<p>笔记：对时间序列数据的聚合（groupby的特殊用法之一）也称作重采样（resampling），本书将在第11章中单独对其进行讲解。</p>
</blockquote>
<h1><span id="101-groupby机制">10.1 GroupBy机制</span></h1><p>Hadley Wickham（许多热门R语言包的作者）创造了一个用于表示分组运算的术语”split-apply-combine”（拆分－应用－合并）。第一个阶段，pandas对象（无论是Series、DataFrame还是其他的）中的数据会根据你所提供的一个或多个键被拆分（split）为多组。拆分操作是在对象的特定轴上执行的。例如，DataFrame可以在其行（axis=0）或列（axis=1）上进行分组。然后，将一个函数应用（apply）到各个分组并产生一个新值。最后，所有这些函数的执行结果会被合并（combine）到最终的结果对象中。结果对象的形式一般取决于数据上所执行的操作。图10-1大致说明了一个简单的分组聚合过程。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-e5c671e09ecf94be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图10-1 分组聚合演示"></p>
<p>分组键可以有多种形式，且类型不必相同：</p>
<ul>
<li>列表或数组，其长度与待分组的轴一样。</li>
<li>表示DataFrame某个列名的值。</li>
<li>字典或Series，给出待分组轴上的值与分组名之间的对应关系。</li>
<li>函数，用于处理轴索引或索引中的各个标签。</li>
</ul>
<p>注意，后三种都只是快捷方式而已，其最终目的仍然是产生一组用于拆分对象的值。如果觉得这些东西看起来很抽象，不用担心，我将在本章中给出大量有关于此的示例。首先来看看下面这个非常简单的表格型数据集（以DataFrame的形式）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span> : [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>],</span><br><span class="line">   ....:                    <span class="string">&#x27;key2&#x27;</span> : [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;one&#x27;</span>],</span><br><span class="line">   ....:                    <span class="string">&#x27;data1&#x27;</span> : np.random.randn(<span class="number">5</span>),</span><br><span class="line">   ....:                    <span class="string">&#x27;data2&#x27;</span> : np.random.randn(<span class="number">5</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: df</span><br><span class="line">Out[<span class="number">11</span>]: </span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">1.393406</span>    a  one</span><br><span class="line"><span class="number">1</span>  <span class="number">0.478943</span>  <span class="number">0.092908</span>    a  two</span><br><span class="line"><span class="number">2</span> -<span class="number">0.519439</span>  <span class="number">0.281746</span>    b  one</span><br><span class="line"><span class="number">3</span> -<span class="number">0.555730</span>  <span class="number">0.769023</span>    b  two</span><br><span class="line"><span class="number">4</span>  <span class="number">1.965781</span>  <span class="number">1.246435</span>    a  one</span><br></pre></td></tr></table></figure>
<p>假设你想要按key1进行分组，并计算data1列的平均值。实现该功能的方式有很多，而我们这里要用的是：访问data1，并根据key1调用groupby：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: grouped = df[<span class="string">&#x27;data1&#x27;</span>].groupby(df[<span class="string">&#x27;key1&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: grouped</span><br><span class="line">Out[<span class="number">13</span>]: &lt;pandas.core.groupby.SeriesGroupBy <span class="built_in">object</span> at <span class="number">0x7faa31537390</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p>变量grouped是一个GroupBy对象。它实际上还没有进行任何计算，只是含有一些有关分组键df[‘key1’]的中间数据而已。换句话说，该对象已经有了接下来对各分组执行运算所需的一切信息。例如，我们可以调用GroupBy的mean方法来计算分组平均值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">14</span>]: grouped.mean()</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">key1</span><br><span class="line">a    <span class="number">0.746672</span></span><br><span class="line">b   -<span class="number">0.537585</span></span><br><span class="line">Name: data1, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>稍后我将详细讲解.mean()的调用过程。这里最重要的是，数据（Series）根据分组键进行了聚合，产生了一个新的Series，其索引为key1列中的唯一值。之所以结果中索引的名称为key1，是因为原始DataFrame的列df[‘key1’]就叫这个名字。</p>
<p>如果我们一次传入多个数组的列表，就会得到不同的结果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: means = df[<span class="string">&#x27;data1&#x27;</span>].groupby([df[<span class="string">&#x27;key1&#x27;</span>], df[<span class="string">&#x27;key2&#x27;</span>]]).mean()</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: means</span><br><span class="line">Out[<span class="number">16</span>]: </span><br><span class="line">key1  key2</span><br><span class="line">a     one     <span class="number">0.880536</span></span><br><span class="line">      two     <span class="number">0.478943</span></span><br><span class="line">b     one    -<span class="number">0.519439</span></span><br><span class="line">      two    -<span class="number">0.555730</span></span><br><span class="line">Name: data1, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这里，我通过两个键对数据进行了分组，得到的Series具有一个层次化索引（由唯一的键对组成）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: means.unstack()</span><br><span class="line">Out[<span class="number">17</span>]: </span><br><span class="line">key2       one       two</span><br><span class="line">key1                    </span><br><span class="line">a     <span class="number">0.880536</span>  <span class="number">0.478943</span></span><br><span class="line">b    -<span class="number">0.519439</span> -<span class="number">0.555730</span></span><br></pre></td></tr></table></figure></p>
<p>在这个例子中，分组键均为Series。实际上，分组键可以是任何长度适当的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: states = np.array([<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;California&#x27;</span>, <span class="string">&#x27;California&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: years = np.array([<span class="number">2005</span>, <span class="number">2005</span>, <span class="number">2006</span>, <span class="number">2005</span>, <span class="number">2006</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: df[<span class="string">&#x27;data1&#x27;</span>].groupby([states, years]).mean()</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">California  <span class="number">2005</span>    <span class="number">0.478943</span></span><br><span class="line">            <span class="number">2006</span>   -<span class="number">0.519439</span></span><br><span class="line">Ohio        <span class="number">2005</span>   -<span class="number">0.380219</span></span><br><span class="line">            <span class="number">2006</span>    <span class="number">1.965781</span></span><br><span class="line">Name: data1, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>通常，分组信息就位于相同的要处理DataFrame中。这里，你还可以将列名（可以是字符串、数字或其他Python对象）用作分组键：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: df.groupby(<span class="string">&#x27;key1&#x27;</span>).mean()</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">         data1     data2</span><br><span class="line">key1</span><br><span class="line">a     <span class="number">0.746672</span>  <span class="number">0.910916</span></span><br><span class="line">b    -<span class="number">0.537585</span>  <span class="number">0.525384</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: df.groupby([<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>]).mean()</span><br><span class="line">Out[<span class="number">22</span>]: </span><br><span class="line">              data1     data2</span><br><span class="line">key1 key2                    </span><br><span class="line">a    one   <span class="number">0.880536</span>  <span class="number">1.319920</span></span><br><span class="line">     two   <span class="number">0.478943</span>  <span class="number">0.092908</span></span><br><span class="line">b    one  -<span class="number">0.519439</span>  <span class="number">0.281746</span></span><br><span class="line">     two  -<span class="number">0.555730</span>  <span class="number">0.769023</span></span><br></pre></td></tr></table></figure></p>
<p>你可能已经注意到了，第一个例子在执行df.groupby(‘key1’).mean()时，结果中没有key2列。这是因为df[‘key2’]不是数值数据（俗称“麻烦列”），所以被从结果中排除了。默认情况下，所有数值列都会被聚合，虽然有时可能会被过滤为一个子集，稍后就会碰到。</p>
<p>无论你准备拿groupby做什么，都有可能会用到GroupBy的size方法，它可以返回一个含有分组大小的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">23</span>]: df.groupby([<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>]).size()</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line">key1  key2</span><br><span class="line">a     one     <span class="number">2</span></span><br><span class="line">      two     <span class="number">1</span></span><br><span class="line">b     one     <span class="number">1</span></span><br><span class="line">      two     <span class="number">1</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>注意，任何分组关键词中的缺失值，都会被从结果中除去。</p>
<h2><span id="对分组进行迭代">对分组进行迭代</span></h2><p>GroupBy对象支持迭代，可以产生一组二元元组（由分组名和数据块组成）。看下面的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: <span class="keyword">for</span> name, group <span class="keyword">in</span> df.groupby(<span class="string">&#x27;key1&#x27;</span>):</span><br><span class="line">   ....:     <span class="built_in">print</span>(name)</span><br><span class="line">   ....:     <span class="built_in">print</span>(group)</span><br><span class="line">   ....:</span><br><span class="line">a</span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">1.393406</span>    a  one</span><br><span class="line"><span class="number">1</span>  <span class="number">0.478943</span>  <span class="number">0.092908</span>    a  two</span><br><span class="line"><span class="number">4</span>  <span class="number">1.965781</span>  <span class="number">1.246435</span>    a  one</span><br><span class="line">b</span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">2</span> -<span class="number">0.519439</span>  <span class="number">0.281746</span>    b  one</span><br><span class="line"><span class="number">3</span> -<span class="number">0.555730</span>  <span class="number">0.769023</span>    b  two</span><br></pre></td></tr></table></figure></p>
<p>对于多重键的情况，元组的第一个元素将会是由键值组成的元组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">25</span>]: <span class="keyword">for</span> (k1, k2), group <span class="keyword">in</span> df.groupby([<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>]):</span><br><span class="line">   ....:     <span class="built_in">print</span>((k1, k2))</span><br><span class="line">   ....:     <span class="built_in">print</span>(group)</span><br><span class="line">   ....:</span><br><span class="line">(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;one&#x27;</span>)</span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">1.393406</span>    a  one</span><br><span class="line"><span class="number">4</span>  <span class="number">1.965781</span>  <span class="number">1.246435</span>    a  one</span><br><span class="line">(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;two&#x27;</span>)</span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">1</span>  <span class="number">0.478943</span>  <span class="number">0.092908</span>    a  two</span><br><span class="line">(<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;one&#x27;</span>)</span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">2</span> -<span class="number">0.519439</span>  <span class="number">0.281746</span>    b  one</span><br><span class="line">(<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;two&#x27;</span>)</span><br><span class="line">     data1     data2 key1 key2</span><br><span class="line"><span class="number">3</span> -<span class="number">0.55573</span>  <span class="number">0.769023</span>    b  two</span><br></pre></td></tr></table></figure></p>
<p>当然，你可以对这些数据片段做任何操作。有一个你可能会觉得有用的运算：将这些数据片段做成一个字典：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">26</span>]: pieces = <span class="built_in">dict</span>(<span class="built_in">list</span>(df.groupby(<span class="string">&#x27;key1&#x27;</span>)))</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: pieces[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">Out[<span class="number">27</span>]: </span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">2</span> -<span class="number">0.519439</span>  <span class="number">0.281746</span>    b  one</span><br><span class="line"><span class="number">3</span> -<span class="number">0.555730</span>  <span class="number">0.769023</span>    b  two</span><br></pre></td></tr></table></figure></p>
<p>groupby默认是在axis=0上进行分组的，通过设置也可以在其他任何轴上进行分组。拿上面例子中的df来说，我们可以根据dtype对列进行分组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">28</span>]: df.dtypes</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">data1    float64</span><br><span class="line">data2    float64</span><br><span class="line">key1      <span class="built_in">object</span></span><br><span class="line">key2      <span class="built_in">object</span></span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: grouped = df.groupby(df.dtypes, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>可以如下打印分组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">30</span>]: <span class="keyword">for</span> dtype, group <span class="keyword">in</span> grouped:</span><br><span class="line">   ....:     <span class="built_in">print</span>(dtype)</span><br><span class="line">   ....:     <span class="built_in">print</span>(group)</span><br><span class="line">   ....:</span><br><span class="line">float64</span><br><span class="line">      data1     data2</span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">1.393406</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.478943</span>  <span class="number">0.092908</span></span><br><span class="line"><span class="number">2</span> -<span class="number">0.519439</span>  <span class="number">0.281746</span></span><br><span class="line"><span class="number">3</span> -<span class="number">0.555730</span>  <span class="number">0.769023</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.965781</span>  <span class="number">1.246435</span></span><br><span class="line"><span class="built_in">object</span></span><br><span class="line">  key1 key2</span><br><span class="line"><span class="number">0</span>    a  one</span><br><span class="line"><span class="number">1</span>    a  two</span><br><span class="line"><span class="number">2</span>    b  one</span><br><span class="line"><span class="number">3</span>    b  two</span><br><span class="line"><span class="number">4</span>    a  one</span><br></pre></td></tr></table></figure></p>
<h2><span id="选取一列或列的子集">选取一列或列的子集</span></h2><p>对于由DataFrame产生的GroupBy对象，如果用一个（单个字符串）或一组（字符串数组）列名对其进行索引，就能实现选取部分列进行聚合的目的。也就是说：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.groupby(<span class="string">&#x27;key1&#x27;</span>)[<span class="string">&#x27;data1&#x27;</span>]</span><br><span class="line">df.groupby(<span class="string">&#x27;key1&#x27;</span>)[[<span class="string">&#x27;data2&#x27;</span>]]</span><br></pre></td></tr></table></figure></p>
<p>是以下代码的语法糖：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;data1&#x27;</span>].groupby(df[<span class="string">&#x27;key1&#x27;</span>])</span><br><span class="line">df[[<span class="string">&#x27;data2&#x27;</span>]].groupby(df[<span class="string">&#x27;key1&#x27;</span>])</span><br></pre></td></tr></table></figure></p>
<p>尤其对于大数据集，很可能只需要对部分列进行聚合。例如，在前面那个数据集中，如果只需计算data2列的平均值并以DataFrame形式得到结果，可以这样写：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">31</span>]: df.groupby([<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])[[<span class="string">&#x27;data2&#x27;</span>]].mean()</span><br><span class="line">Out[<span class="number">31</span>]: </span><br><span class="line">              data2</span><br><span class="line">key1 key2          </span><br><span class="line">a    one   <span class="number">1.319920</span></span><br><span class="line">     two   <span class="number">0.092908</span></span><br><span class="line">b    one   <span class="number">0.281746</span></span><br><span class="line">     two   <span class="number">0.769023</span></span><br></pre></td></tr></table></figure></p>
<p>这种索引操作所返回的对象是一个已分组的DataFrame（如果传入的是列表或数组）或已分组的Series（如果传入的是标量形式的单个列名）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: s_grouped = df.groupby([<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])[<span class="string">&#x27;data2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: s_grouped</span><br><span class="line">Out[<span class="number">33</span>]: &lt;pandas.core.groupby.SeriesGroupBy <span class="built_in">object</span> at <span class="number">0x7faa30c78da0</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: s_grouped.mean()</span><br><span class="line">Out[<span class="number">34</span>]: </span><br><span class="line">key1  key2</span><br><span class="line">a     one     <span class="number">1.319920</span></span><br><span class="line">      two     <span class="number">0.092908</span></span><br><span class="line">b     one     <span class="number">0.281746</span></span><br><span class="line">      two     <span class="number">0.769023</span></span><br><span class="line">Name: data2, dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="通过字典或series进行分组">通过字典或Series进行分组</span></h2><p>除数组以外，分组信息还可以其他形式存在。来看另一个示例DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: people = pd.DataFrame(np.random.randn(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">   ....:                       columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>],</span><br><span class="line">   ....:                       index=[<span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Steve&#x27;</span>, <span class="string">&#x27;Wes&#x27;</span>, <span class="string">&#x27;Jim&#x27;</span>, <span class="string">&#x27;Travis&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: people.iloc[<span class="number">2</span>:<span class="number">3</span>, [<span class="number">1</span>, <span class="number">2</span>]] = np.nan <span class="comment"># Add a few NA values</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: people</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">               a         b         c         d         e</span><br><span class="line">Joe     <span class="number">1.007189</span> -<span class="number">1.296221</span>  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line">Steve   <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span></span><br><span class="line">Wes    -<span class="number">0.539741</span>       NaN       NaN -<span class="number">1.021228</span> -<span class="number">0.577087</span></span><br><span class="line">Jim     <span class="number">0.124121</span>  <span class="number">0.302614</span>  <span class="number">0.523772</span>  <span class="number">0.000940</span>  <span class="number">1.343810</span></span><br><span class="line">Travis -<span class="number">0.713544</span> -<span class="number">0.831154</span> -<span class="number">2.370232</span> -<span class="number">1.860761</span> -<span class="number">0.860757</span></span><br></pre></td></tr></table></figure></p>
<p>现在，假设已知列的分组关系，并希望根据分组计算列的和：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">38</span>]: mapping = &#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;c&#x27;</span>: <span class="string">&#x27;blue&#x27;</span>,</span><br><span class="line">   ....:            <span class="string">&#x27;d&#x27;</span>: <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;e&#x27;</span>: <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;f&#x27;</span> : <span class="string">&#x27;orange&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>现在，你可以将这个字典传给groupby，来构造数组，但我们可以直接传递字典（我包含了键“f”来强调，存在未使用的分组键是可以的）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: by_column = people.groupby(mapping, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: by_column.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">            blue       red</span><br><span class="line">Joe     <span class="number">0.503905</span>  <span class="number">1.063885</span></span><br><span class="line">Steve   <span class="number">1.297183</span> -<span class="number">1.553778</span></span><br><span class="line">Wes    -<span class="number">1.021228</span> -<span class="number">1.116829</span></span><br><span class="line">Jim     <span class="number">0.524712</span>  <span class="number">1.770545</span></span><br><span class="line">Travis -<span class="number">4.230992</span> -<span class="number">2.405455</span></span><br></pre></td></tr></table></figure></p>
<p>Series也有同样的功能，它可以被看做一个固定大小的映射：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: map_series = pd.Series(mapping)</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: map_series</span><br><span class="line">Out[<span class="number">42</span>]: </span><br><span class="line">a       red</span><br><span class="line">b       red</span><br><span class="line">c      blue</span><br><span class="line">d      blue</span><br><span class="line">e       red</span><br><span class="line">f    orange</span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: people.groupby(map_series, axis=<span class="number">1</span>).count()</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line">        blue  red</span><br><span class="line">Joe        <span class="number">2</span>    <span class="number">3</span></span><br><span class="line">Steve      <span class="number">2</span>    <span class="number">3</span></span><br><span class="line">Wes        <span class="number">1</span>    <span class="number">2</span></span><br><span class="line">Jim        <span class="number">2</span>    <span class="number">3</span></span><br><span class="line">Travis     <span class="number">2</span>    <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="通过函数进行分组">通过函数进行分组</span></h2><p>比起使用字典或Series，使用Python函数是一种更原生的方法定义分组映射。任何被当做分组键的函数都会在各个索引值上被调用一次，其返回值就会被用作分组名称。具体点说，以上一小节的示例DataFrame为例，其索引值为人的名字。你可以计算一个字符串长度的数组，更简单的方法是传入len函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: people.groupby(<span class="built_in">len</span>).<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line">          a         b         c         d         e</span><br><span class="line"><span class="number">3</span>  <span class="number">0.591569</span> -<span class="number">0.993608</span>  <span class="number">0.798764</span> -<span class="number">0.791374</span>  <span class="number">2.119639</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span></span><br><span class="line"><span class="number">6</span> -<span class="number">0.713544</span> -<span class="number">0.831154</span> -<span class="number">2.370232</span> -<span class="number">1.860761</span> -<span class="number">0.860757</span></span><br></pre></td></tr></table></figure></p>
<p>将函数跟数组、列表、字典、Series混合使用也不是问题，因为任何东西在内部都会被转换为数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: key_list = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;two&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: people.groupby([<span class="built_in">len</span>, key_list]).<span class="built_in">min</span>()</span><br><span class="line">Out[<span class="number">46</span>]: </span><br><span class="line">              a         b         c         d         e</span><br><span class="line"><span class="number">3</span> one -<span class="number">0.539741</span> -<span class="number">1.296221</span>  <span class="number">0.274992</span> -<span class="number">1.021228</span> -<span class="number">0.577087</span></span><br><span class="line">  two  <span class="number">0.124121</span>  <span class="number">0.302614</span>  <span class="number">0.523772</span>  <span class="number">0.000940</span>  <span class="number">1.343810</span></span><br><span class="line"><span class="number">5</span> one  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span></span><br><span class="line"><span class="number">6</span> two -<span class="number">0.713544</span> -<span class="number">0.831154</span> -<span class="number">2.370232</span> -<span class="number">1.860761</span> -<span class="number">0.860757</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="根据索引级别分组">根据索引级别分组</span></h2><p>层次化索引数据集最方便的地方就在于它能够根据轴索引的一个级别进行聚合：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: columns = pd.MultiIndex.from_arrays([[<span class="string">&#x27;US&#x27;</span>, <span class="string">&#x27;US&#x27;</span>, <span class="string">&#x27;US&#x27;</span>, <span class="string">&#x27;JP&#x27;</span>, <span class="string">&#x27;JP&#x27;</span>],</span><br><span class="line">   ....:                                     [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">3</span>]],</span><br><span class="line">   ....:                                     names=[<span class="string">&#x27;cty&#x27;</span>, <span class="string">&#x27;tenor&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: hier_df = pd.DataFrame(np.random.randn(<span class="number">4</span>, <span class="number">5</span>), columns=columns)</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: hier_df</span><br><span class="line">Out[<span class="number">49</span>]: </span><br><span class="line">cty          US                            JP          </span><br><span class="line">tenor         <span class="number">1</span>         <span class="number">3</span>         <span class="number">5</span>         <span class="number">1</span>         <span class="number">3</span></span><br><span class="line"><span class="number">0</span>      <span class="number">0.560145</span> -<span class="number">1.265934</span>  <span class="number">0.119827</span> -<span class="number">1.063512</span>  <span class="number">0.332883</span></span><br><span class="line"><span class="number">1</span>     -<span class="number">2.359419</span> -<span class="number">0.199543</span> -<span class="number">1.541996</span> -<span class="number">0.970736</span> -<span class="number">1.307030</span></span><br><span class="line"><span class="number">2</span>      <span class="number">0.286350</span>  <span class="number">0.377984</span> -<span class="number">0.753887</span>  <span class="number">0.331286</span>  <span class="number">1.349742</span></span><br><span class="line"><span class="number">3</span>      <span class="number">0.069877</span>  <span class="number">0.246674</span> -<span class="number">0.011862</span>  <span class="number">1.004812</span>  <span class="number">1.327195</span></span><br></pre></td></tr></table></figure></p>
<p>要根据级别分组，使用level关键字传递级别序号或名字：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: hier_df.groupby(level=<span class="string">&#x27;cty&#x27;</span>, axis=<span class="number">1</span>).count()</span><br><span class="line">Out[<span class="number">50</span>]: </span><br><span class="line">cty  JP  US</span><br><span class="line"><span class="number">0</span>     <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"><span class="number">1</span>     <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"><span class="number">2</span>     <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"><span class="number">3</span>     <span class="number">2</span>   <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="102-数据聚合">10.2 数据聚合</span></h1><p>聚合指的是任何能够从数组产生标量值的数据转换过程。之前的例子已经用过一些，比如mean、count、min以及sum等。你可能想知道在GroupBy对象上调用mean()时究竟发生了什么。许多常见的聚合运算（如表10-1所示）都有进行优化。然而，除了这些方法，你还可以使用其它的。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-ba8de524e08b1b6f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表10-1 经过优化的groupby方法"></p>
<p>你可以使用自己发明的聚合运算，还可以调用分组对象上已经定义好的任何方法。例如，quantile可以计算Series或DataFrame列的样本分位数。</p>
<p>虽然quantile并没有明确地实现于GroupBy，但它是一个Series方法，所以这里是能用的。实际上，GroupBy会高效地对Series进行切片，然后对各片调用piece.quantile(0.9)，最后将这些结果组装成最终结果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: df</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">      data1     data2 key1 key2</span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">1.393406</span>    a  one</span><br><span class="line"><span class="number">1</span>  <span class="number">0.478943</span>  <span class="number">0.092908</span>    a  two</span><br><span class="line"><span class="number">2</span> -<span class="number">0.519439</span>  <span class="number">0.281746</span>    b  one</span><br><span class="line"><span class="number">3</span> -<span class="number">0.555730</span>  <span class="number">0.769023</span>    b  two</span><br><span class="line"><span class="number">4</span>  <span class="number">1.965781</span>  <span class="number">1.246435</span>    a  one</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: grouped = df.groupby(<span class="string">&#x27;key1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: grouped[<span class="string">&#x27;data1&#x27;</span>].quantile(<span class="number">0.9</span>)</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">key1</span><br><span class="line">a    <span class="number">1.668413</span></span><br><span class="line">b   -<span class="number">0.523068</span></span><br><span class="line">Name: data1, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>如果要使用你自己的聚合函数，只需将其传入aggregate或agg方法即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">54</span>]: <span class="function"><span class="keyword">def</span> <span class="title">peak_to_peak</span>(<span class="params">arr</span>):</span></span><br><span class="line">   ....:     <span class="keyword">return</span> arr.<span class="built_in">max</span>() - arr.<span class="built_in">min</span>()</span><br><span class="line">In [<span class="number">55</span>]: grouped.agg(peak_to_peak)</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line">         data1     data2</span><br><span class="line">key1                    </span><br><span class="line">a     <span class="number">2.170488</span>  <span class="number">1.300498</span></span><br><span class="line">b     <span class="number">0.036292</span>  <span class="number">0.487276</span></span><br></pre></td></tr></table></figure></p>
<p>你可能注意到注意，有些方法（如describe）也是可以用在这里的，即使严格来讲，它们并非聚合运算：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: grouped.describe()</span><br><span class="line">Out[<span class="number">56</span>]: </span><br><span class="line">     data1                                                              \</span><br><span class="line">     count      mean       std       <span class="built_in">min</span>       <span class="number">25</span>%       <span class="number">50</span>%       <span class="number">75</span>%   </span><br><span class="line">key1                                                                     </span><br><span class="line">a      <span class="number">3.0</span>  <span class="number">0.746672</span>  <span class="number">1.109736</span> -<span class="number">0.204708</span>  <span class="number">0.137118</span>  <span class="number">0.478943</span>  <span class="number">1.222362</span>   </span><br><span class="line">b      <span class="number">2.0</span> -<span class="number">0.537585</span>  <span class="number">0.025662</span> -<span class="number">0.555730</span> -<span class="number">0.546657</span> -<span class="number">0.537585</span> -<span class="number">0.528512</span>   </span><br><span class="line">               data2                                                    \</span><br><span class="line"><span class="built_in">max</span> count      mean       std       <span class="built_in">min</span>       <span class="number">25</span>%       <span class="number">50</span>%   </span><br><span class="line">key1                                                                     </span><br><span class="line">a     <span class="number">1.965781</span>   <span class="number">3.0</span>  <span class="number">0.910916</span>  <span class="number">0.712217</span>  <span class="number">0.092908</span>  <span class="number">0.669671</span>  <span class="number">1.246435</span>   </span><br><span class="line">b    -<span class="number">0.519439</span>   <span class="number">2.0</span>  <span class="number">0.525384</span>  <span class="number">0.344556</span>  <span class="number">0.281746</span>  <span class="number">0.403565</span>  <span class="number">0.525384</span>   </span><br><span class="line">                          </span><br><span class="line">           <span class="number">75</span>%       <span class="built_in">max</span>  </span><br><span class="line">key1                      </span><br><span class="line">a     <span class="number">1.319920</span>  <span class="number">1.393406</span>  </span><br><span class="line">b     <span class="number">0.647203</span>  <span class="number">0.769023</span></span><br></pre></td></tr></table></figure></p>
<p>在后面的10.3节，我将详细说明这到底是怎么回事。</p>
<blockquote>
<p>笔记：自定义聚合函数要比表10-1中那些经过优化的函数慢得多。这是因为在构造中间分组数据块时存在非常大的开销（函数调用、数据重排等）。</p>
</blockquote>
<h2><span id="面向列的多函数应用">面向列的多函数应用</span></h2><p>回到前面小费的例子。使用read_csv导入数据之后，我们添加了一个小费百分比的列tip_pct：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: tips = pd.read_csv(<span class="string">&#x27;examples/tips.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add tip percentage of total bill</span></span><br><span class="line">In [<span class="number">58</span>]: tips[<span class="string">&#x27;tip_pct&#x27;</span>] = tips[<span class="string">&#x27;tip&#x27;</span>] / tips[<span class="string">&#x27;total_bill&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: tips[:<span class="number">6</span>]</span><br><span class="line">Out[<span class="number">59</span>]: </span><br><span class="line">   total_bill   tip smoker  day    time  size   tip_pct</span><br><span class="line"><span class="number">0</span>       <span class="number">16.99</span>  <span class="number">1.01</span>     No  Sun  Dinner     <span class="number">2</span>  <span class="number">0.059447</span></span><br><span class="line"><span class="number">1</span>       <span class="number">10.34</span>  <span class="number">1.66</span>     No  Sun  Dinner     <span class="number">3</span>  <span class="number">0.160542</span></span><br><span class="line"><span class="number">2</span>       <span class="number">21.01</span>  <span class="number">3.50</span>     No  Sun  Dinner     <span class="number">3</span>  <span class="number">0.166587</span></span><br><span class="line"><span class="number">3</span>       <span class="number">23.68</span>  <span class="number">3.31</span>     No  Sun  Dinner     <span class="number">2</span>  <span class="number">0.139780</span></span><br><span class="line"><span class="number">4</span>       <span class="number">24.59</span>  <span class="number">3.61</span>     No  Sun  Dinner     <span class="number">4</span>  <span class="number">0.146808</span></span><br><span class="line"><span class="number">5</span>       <span class="number">25.29</span>  <span class="number">4.71</span>     No  Sun  Dinner     <span class="number">4</span>  <span class="number">0.186240</span></span><br></pre></td></tr></table></figure></p>
<p>你已经看到，对Series或DataFrame列的聚合运算其实就是使用aggregate（使用自定义函数）或调用诸如mean、std之类的方法。然而，你可能希望对不同的列使用不同的聚合函数，或一次应用多个函数。其实这也好办，我将通过一些示例来进行讲解。首先，我根据天和smoker对tips进行分组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: grouped = tips.groupby([<span class="string">&#x27;day&#x27;</span>, <span class="string">&#x27;smoker&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>注意，对于表10-1中的那些描述统计，可以将函数名以字符串的形式传入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">61</span>]: grouped_pct = grouped[<span class="string">&#x27;tip_pct&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: grouped_pct.agg(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">Out[<span class="number">62</span>]: </span><br><span class="line">day   smoker</span><br><span class="line">Fri   No        <span class="number">0.151650</span></span><br><span class="line">      Yes       <span class="number">0.174783</span></span><br><span class="line">Sat   No        <span class="number">0.158048</span></span><br><span class="line">      Yes       <span class="number">0.147906</span></span><br><span class="line">Sun   No        <span class="number">0.160113</span></span><br><span class="line">      Yes       <span class="number">0.187250</span></span><br><span class="line">Thur  No        <span class="number">0.160298</span></span><br><span class="line">      Yes       <span class="number">0.163863</span></span><br><span class="line">Name: tip_pct, dtype: float64</span><br></pre></td></tr></table></figure>
<p>如果传入一组函数或函数名，得到的DataFrame的列就会以相应的函数命名：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">63</span>]: grouped_pct.agg([<span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;std&#x27;</span>, peak_to_peak])</span><br><span class="line">Out[<span class="number">63</span>]: </span><br><span class="line">                 mean       std  peak_to_peak</span><br><span class="line">day  smoker                                  </span><br><span class="line">Fri  No      <span class="number">0.151650</span>  <span class="number">0.028123</span>      <span class="number">0.067349</span></span><br><span class="line">     Yes     <span class="number">0.174783</span>  <span class="number">0.051293</span>      <span class="number">0.159925</span></span><br><span class="line">Sat  No      <span class="number">0.158048</span>  <span class="number">0.039767</span>      <span class="number">0.235193</span></span><br><span class="line">     Yes     <span class="number">0.147906</span>  <span class="number">0.061375</span>      <span class="number">0.290095</span></span><br><span class="line">Sun  No      <span class="number">0.160113</span>  <span class="number">0.042347</span>      <span class="number">0.193226</span></span><br><span class="line">     Yes     <span class="number">0.187250</span>  <span class="number">0.154134</span>      <span class="number">0.644685</span></span><br><span class="line">Thur No      <span class="number">0.160298</span>  <span class="number">0.038774</span>      <span class="number">0.193350</span></span><br><span class="line">     Yes     <span class="number">0.163863</span>  <span class="number">0.039389</span>      <span class="number">0.151240</span></span><br></pre></td></tr></table></figure>
<p>这里，我们传递了一组聚合函数进行聚合，独立对数据分组进行评估。</p>
<p>你并非一定要接受GroupBy自动给出的那些列名，特别是lambda函数，它们的名称是’<lambda>‘，这样的辨识度就很低了（通过函数的<strong>name</strong>属性看看就知道了）。因此，如果传入的是一个由(name,function)元组组成的列表，则各元组的第一个元素就会被用作DataFrame的列名（可以将这种二元元组列表看做一个有序映射）：</lambda></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: grouped_pct.agg([(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, np.std)])</span><br><span class="line">Out[<span class="number">64</span>]: </span><br><span class="line">                  foo       bar</span><br><span class="line">day  smoker                    </span><br><span class="line">Fri  No      <span class="number">0.151650</span>  <span class="number">0.028123</span></span><br><span class="line">     Yes     <span class="number">0.174783</span>  <span class="number">0.051293</span></span><br><span class="line">Sat  No      <span class="number">0.158048</span>  <span class="number">0.039767</span></span><br><span class="line">     Yes     <span class="number">0.147906</span>  <span class="number">0.061375</span></span><br><span class="line">Sun  No      <span class="number">0.160113</span>  <span class="number">0.042347</span></span><br><span class="line">     Yes     <span class="number">0.187250</span>  <span class="number">0.154134</span></span><br><span class="line">Thur No      <span class="number">0.160298</span>  <span class="number">0.038774</span></span><br><span class="line">     Yes     <span class="number">0.163863</span>  <span class="number">0.039389</span></span><br></pre></td></tr></table></figure>
<p>对于DataFrame，你还有更多选择，你可以定义一组应用于全部列的一组函数，或不同的列应用不同的函数。假设我们想要对tip_pct和total_bill列计算三个统计信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">65</span>]: functions = [<span class="string">&#x27;count&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;max&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: result = grouped[<span class="string">&#x27;tip_pct&#x27;</span>, <span class="string">&#x27;total_bill&#x27;</span>].agg(functions)</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: result</span><br><span class="line">Out[<span class="number">67</span>]: </span><br><span class="line">            tip_pct                     total_bill                  </span><br><span class="line">              count      mean       <span class="built_in">max</span>      count       mean    <span class="built_in">max</span></span><br><span class="line">day  smoker                                                         </span><br><span class="line">Fri  No           <span class="number">4</span>  <span class="number">0.151650</span>  <span class="number">0.187735</span>          <span class="number">4</span>  <span class="number">18.420000</span>  <span class="number">22.75</span></span><br><span class="line">     Yes         <span class="number">15</span>  <span class="number">0.174783</span>  <span class="number">0.263480</span>         <span class="number">15</span>  <span class="number">16.813333</span>  <span class="number">40.17</span></span><br><span class="line">Sat  No          <span class="number">45</span>  <span class="number">0.158048</span>  <span class="number">0.291990</span>         <span class="number">45</span>  <span class="number">19.661778</span>  <span class="number">48.33</span></span><br><span class="line">     Yes         <span class="number">42</span>  <span class="number">0.147906</span>  <span class="number">0.325733</span>         <span class="number">42</span>  <span class="number">21.276667</span>  <span class="number">50.81</span></span><br><span class="line">Sun  No          <span class="number">57</span>  <span class="number">0.160113</span>  <span class="number">0.252672</span>         <span class="number">57</span>  <span class="number">20.506667</span>  <span class="number">48.17</span></span><br><span class="line">     Yes         <span class="number">19</span>  <span class="number">0.187250</span>  <span class="number">0.710345</span>         <span class="number">19</span>  <span class="number">24.120000</span>  <span class="number">45.35</span></span><br><span class="line">Thur No          <span class="number">45</span>  <span class="number">0.160298</span>  <span class="number">0.266312</span>         <span class="number">45</span>  <span class="number">17.113111</span>  <span class="number">41.19</span></span><br><span class="line">     Yes         <span class="number">17</span>  <span class="number">0.163863</span>  <span class="number">0.241255</span>         <span class="number">17</span>  <span class="number">19.190588</span>  <span class="number">43.11</span></span><br></pre></td></tr></table></figure>
<p>如你所见，结果DataFrame拥有层次化的列，这相当于分别对各列进行聚合，然后用concat将结果组装到一起，使用列名用作keys参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: result[<span class="string">&#x27;tip_pct&#x27;</span>]</span><br><span class="line">Out[<span class="number">68</span>]: </span><br><span class="line">             count      mean       <span class="built_in">max</span></span><br><span class="line">day  smoker                           </span><br><span class="line">Fri  No          <span class="number">4</span>  <span class="number">0.151650</span>  <span class="number">0.187735</span></span><br><span class="line">     Yes        <span class="number">15</span>  <span class="number">0.174783</span>  <span class="number">0.263480</span></span><br><span class="line">Sat  No         <span class="number">45</span>  <span class="number">0.158048</span>  <span class="number">0.291990</span></span><br><span class="line">     Yes        <span class="number">42</span>  <span class="number">0.147906</span>  <span class="number">0.325733</span></span><br><span class="line">Sun  No         <span class="number">57</span>  <span class="number">0.160113</span>  <span class="number">0.252672</span></span><br><span class="line">     Yes        <span class="number">19</span>  <span class="number">0.187250</span>  <span class="number">0.710345</span></span><br><span class="line">Thur No         <span class="number">45</span>  <span class="number">0.160298</span>  <span class="number">0.266312</span></span><br><span class="line">     Yes        <span class="number">17</span>  <span class="number">0.163863</span>  <span class="number">0.241255</span></span><br></pre></td></tr></table></figure>
<p>跟前面一样，这里也可以传入带有自定义名称的一组元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: ftuples = [(<span class="string">&#x27;Durchschnitt&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>),(<span class="string">&#x27;Abweichung&#x27;</span>, np.var)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: grouped[<span class="string">&#x27;tip_pct&#x27;</span>, <span class="string">&#x27;total_bill&#x27;</span>].agg(ftuples)</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line">                 tip_pct              total_bill            </span><br><span class="line">            Durchschnitt Abweichung Durchschnitt  Abweichung</span><br><span class="line">day  smoker                                                 </span><br><span class="line">Fri  No         <span class="number">0.151650</span>   <span class="number">0.000791</span>    <span class="number">18.420000</span>   <span class="number">25.596333</span></span><br><span class="line">     Yes        <span class="number">0.174783</span>   <span class="number">0.002631</span>    <span class="number">16.813333</span>   <span class="number">82.562438</span></span><br><span class="line">Sat  No         <span class="number">0.158048</span>   <span class="number">0.001581</span>    <span class="number">19.661778</span>   <span class="number">79.908965</span></span><br><span class="line">     Yes        <span class="number">0.147906</span>   <span class="number">0.003767</span>    <span class="number">21.276667</span>  <span class="number">101.387535</span></span><br><span class="line">Sun  No         <span class="number">0.160113</span>   <span class="number">0.001793</span>    <span class="number">20.506667</span>   <span class="number">66.099980</span></span><br><span class="line">     Yes        <span class="number">0.187250</span>   <span class="number">0.023757</span>    <span class="number">24.120000</span>  <span class="number">109.046044</span></span><br><span class="line">Thur No         <span class="number">0.160298</span>   <span class="number">0.001503</span>    <span class="number">17.113111</span>   <span class="number">59.625081</span></span><br><span class="line">     Yes        <span class="number">0.163863</span>   <span class="number">0.001551</span>    <span class="number">19.190588</span>   <span class="number">69.808518</span></span><br></pre></td></tr></table></figure>
<p>现在，假设你想要对一个列或不同的列应用不同的函数。具体的办法是向agg传入一个从列名映射到函数的字典：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">71</span>]: grouped.agg(&#123;<span class="string">&#x27;tip&#x27;</span> : np.<span class="built_in">max</span>, <span class="string">&#x27;size&#x27;</span> : <span class="string">&#x27;sum&#x27;</span>&#125;)</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line">               tip  size</span><br><span class="line">day  smoker             </span><br><span class="line">Fri  No       <span class="number">3.50</span>     <span class="number">9</span></span><br><span class="line">     Yes      <span class="number">4.73</span>    <span class="number">31</span></span><br><span class="line">Sat  No       <span class="number">9.00</span>   <span class="number">115</span></span><br><span class="line">     Yes     <span class="number">10.00</span>   <span class="number">104</span></span><br><span class="line">Sun  No       <span class="number">6.00</span>   <span class="number">167</span></span><br><span class="line">     Yes      <span class="number">6.50</span>    <span class="number">49</span></span><br><span class="line">Thur No       <span class="number">6.70</span>   <span class="number">112</span></span><br><span class="line">     Yes      <span class="number">5.00</span>    <span class="number">40</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: grouped.agg(&#123;<span class="string">&#x27;tip_pct&#x27;</span> : [<span class="string">&#x27;min&#x27;</span>, <span class="string">&#x27;max&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;std&#x27;</span>],</span><br><span class="line">   ....:              <span class="string">&#x27;size&#x27;</span> : <span class="string">&#x27;sum&#x27;</span>&#125;)</span><br><span class="line">Out[<span class="number">72</span>]: </span><br><span class="line">              tip_pct                               size</span><br><span class="line">                  <span class="built_in">min</span>       <span class="built_in">max</span>      mean       std  <span class="built_in">sum</span></span><br><span class="line">day  smoker                                             </span><br><span class="line">Fri  No      <span class="number">0.120385</span>  <span class="number">0.187735</span>  <span class="number">0.151650</span>  <span class="number">0.028123</span>    <span class="number">9</span></span><br><span class="line">     Yes     <span class="number">0.103555</span>  <span class="number">0.263480</span>  <span class="number">0.174783</span>  <span class="number">0.051293</span>   <span class="number">31</span></span><br><span class="line">Sat  No      <span class="number">0.056797</span>  <span class="number">0.291990</span>  <span class="number">0.158048</span>  <span class="number">0.039767</span>  <span class="number">115</span></span><br><span class="line">     Yes     <span class="number">0.035638</span>  <span class="number">0.325733</span>  <span class="number">0.147906</span>  <span class="number">0.061375</span>  <span class="number">104</span></span><br><span class="line">Sun  No      <span class="number">0.059447</span>  <span class="number">0.252672</span>  <span class="number">0.160113</span>  <span class="number">0.042347</span>  <span class="number">167</span></span><br><span class="line">     Yes     <span class="number">0.065660</span>  <span class="number">0.710345</span>  <span class="number">0.187250</span>  <span class="number">0.154134</span>   <span class="number">49</span></span><br><span class="line">Thur No      <span class="number">0.072961</span>  <span class="number">0.266312</span>  <span class="number">0.160298</span>  <span class="number">0.038774</span>  <span class="number">112</span></span><br><span class="line">     Yes     <span class="number">0.090014</span>  <span class="number">0.241255</span>  <span class="number">0.163863</span>  <span class="number">0.039389</span>   <span class="number">40</span></span><br></pre></td></tr></table></figure>
<p>只有将多个函数应用到至少一列时，DataFrame才会拥有层次化的列。</p>
<h2><span id="以没有行索引的形式返回聚合数据">以“没有行索引”的形式返回聚合数据</span></h2><p>到目前为止，所有示例中的聚合数据都有由唯一的分组键组成的索引（可能还是层次化的）。由于并不总是需要如此，所以你可以向groupby传入as_index=False以禁用该功能：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: tips.groupby([<span class="string">&#x27;day&#x27;</span>, <span class="string">&#x27;smoker&#x27;</span>], as_index=<span class="literal">False</span>).mean()</span><br><span class="line">Out[<span class="number">73</span>]: </span><br><span class="line">    day smoker  total_bill       tip      size   tip_pct</span><br><span class="line"><span class="number">0</span>   Fri     No   <span class="number">18.420000</span>  <span class="number">2.812500</span>  <span class="number">2.250000</span>  <span class="number">0.151650</span></span><br><span class="line"><span class="number">1</span>   Fri    Yes   <span class="number">16.813333</span>  <span class="number">2.714000</span>  <span class="number">2.066667</span>  <span class="number">0.174783</span></span><br><span class="line"><span class="number">2</span>   Sat     No   <span class="number">19.661778</span>  <span class="number">3.102889</span>  <span class="number">2.555556</span>  <span class="number">0.158048</span></span><br><span class="line"><span class="number">3</span>   Sat    Yes   <span class="number">21.276667</span>  <span class="number">2.875476</span>  <span class="number">2.476190</span>  <span class="number">0.147906</span></span><br><span class="line"><span class="number">4</span>   Sun     No   <span class="number">20.506667</span>  <span class="number">3.167895</span>  <span class="number">2.929825</span>  <span class="number">0.160113</span></span><br><span class="line"><span class="number">5</span>   Sun    Yes   <span class="number">24.120000</span>  <span class="number">3.516842</span>  <span class="number">2.578947</span>  <span class="number">0.187250</span></span><br><span class="line"><span class="number">6</span>  Thur     No   <span class="number">17.113111</span>  <span class="number">2.673778</span>  <span class="number">2.488889</span>  <span class="number">0.160298</span></span><br><span class="line"><span class="number">7</span>  Thur    Yes   <span class="number">19.190588</span>  <span class="number">3.030000</span>  <span class="number">2.352941</span>  <span class="number">0.163863</span></span><br></pre></td></tr></table></figure>
<p>当然，对结果调用reset_index也能得到这种形式的结果。使用as_index=False方法可以避免一些不必要的计算。</p>
<h1><span id="103-apply一般性的拆分-应用-合并">10.3 apply：一般性的“拆分－应用－合并”</span></h1><p>最通用的GroupBy方法是apply，本节剩余部分将重点讲解它。如图10-2所示，apply会将待处理的对象拆分成多个片段，然后对各片段调用传入的函数，最后尝试将各片段组合到一起。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-7e8bb217f599b4ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图10-2 分组聚合示例"></p>
<p>回到之前那个小费数据集，假设你想要根据分组选出最高的5个tip_pct值。首先，编写一个选取指定列具有最大值的行的函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: <span class="function"><span class="keyword">def</span> <span class="title">top</span>(<span class="params">df, n=<span class="number">5</span>, column=<span class="string">&#x27;tip_pct&#x27;</span></span>):</span></span><br><span class="line">   ....:     <span class="keyword">return</span> df.sort_values(by=column)[-n:]</span><br><span class="line"></span><br><span class="line">In [<span class="number">75</span>]: top(tips, n=<span class="number">6</span>)</span><br><span class="line">Out[<span class="number">75</span>]: </span><br><span class="line">     total_bill   tip smoker  day    time  size   tip_pct</span><br><span class="line"><span class="number">109</span>       <span class="number">14.31</span>  <span class="number">4.00</span>    Yes  Sat  Dinner     <span class="number">2</span>  <span class="number">0.279525</span></span><br><span class="line"><span class="number">183</span>       <span class="number">23.17</span>  <span class="number">6.50</span>    Yes  Sun  Dinner     <span class="number">4</span>  <span class="number">0.280535</span></span><br><span class="line"><span class="number">232</span>       <span class="number">11.61</span>  <span class="number">3.39</span>     No  Sat  Dinner     <span class="number">2</span>  <span class="number">0.291990</span></span><br><span class="line"><span class="number">67</span>         <span class="number">3.07</span>  <span class="number">1.00</span>    Yes  Sat  Dinner     <span class="number">1</span>  <span class="number">0.325733</span></span><br><span class="line"><span class="number">178</span>        <span class="number">9.60</span>  <span class="number">4.00</span>    Yes  Sun  Dinner     <span class="number">2</span>  <span class="number">0.416667</span></span><br><span class="line"><span class="number">172</span>        <span class="number">7.25</span>  <span class="number">5.15</span>    Yes  Sun  Dinner     <span class="number">2</span>  <span class="number">0.710345</span></span><br></pre></td></tr></table></figure></p>
<p>现在，如果对smoker分组并用该函数调用apply，就会得到：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: tips.groupby(<span class="string">&#x27;smoker&#x27;</span>).apply(top)</span><br><span class="line">Out[<span class="number">76</span>]: </span><br><span class="line">            total_bill   tip smoker   day    time  size   tip_pct</span><br><span class="line">smoker                                                           </span><br><span class="line">No     <span class="number">88</span>        <span class="number">24.71</span>  <span class="number">5.85</span>     No  Thur   Lunch     <span class="number">2</span>  <span class="number">0.236746</span></span><br><span class="line">       <span class="number">185</span>       <span class="number">20.69</span>  <span class="number">5.00</span>     No   Sun  Dinner     <span class="number">5</span>  <span class="number">0.241663</span></span><br><span class="line">       <span class="number">51</span>        <span class="number">10.29</span>  <span class="number">2.60</span>     No   Sun  Dinner     <span class="number">2</span>  <span class="number">0.252672</span></span><br><span class="line">       <span class="number">149</span>        <span class="number">7.51</span>  <span class="number">2.00</span>     No  Thur   Lunch     <span class="number">2</span>  <span class="number">0.266312</span></span><br><span class="line">       <span class="number">232</span>       <span class="number">11.61</span>  <span class="number">3.39</span>     No   Sat  Dinner     <span class="number">2</span>  <span class="number">0.291990</span></span><br><span class="line">Yes    <span class="number">109</span>       <span class="number">14.31</span>  <span class="number">4.00</span>    Yes   Sat  Dinner     <span class="number">2</span>  <span class="number">0.279525</span></span><br><span class="line">       <span class="number">183</span>       <span class="number">23.17</span>  <span class="number">6.50</span>    Yes   Sun  Dinner     <span class="number">4</span>  <span class="number">0.280535</span></span><br><span class="line">       <span class="number">67</span>         <span class="number">3.07</span>  <span class="number">1.00</span>    Yes   Sat  Dinner     <span class="number">1</span>  <span class="number">0.325733</span></span><br><span class="line">       <span class="number">178</span>        <span class="number">9.60</span>  <span class="number">4.00</span>    Yes   Sun  Dinner     <span class="number">2</span>  <span class="number">0.416667</span></span><br><span class="line">       <span class="number">172</span>        <span class="number">7.25</span>  <span class="number">5.15</span>    Yes   Sun  Dinner     <span class="number">2</span>  <span class="number">0.710345</span></span><br></pre></td></tr></table></figure></p>
<p>这里发生了什么？top函数在DataFrame的各个片段上调用，然后结果由pandas.concat组装到一起，并以分组名称进行了标记。于是，最终结果就有了一个层次化索引，其内层索引值来自原DataFrame。</p>
<p>如果传给apply的函数能够接受其他参数或关键字，则可以将这些内容放在函数名后面一并传入：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">77</span>]: tips.groupby([<span class="string">&#x27;smoker&#x27;</span>, <span class="string">&#x27;day&#x27;</span>]).apply(top, n=<span class="number">1</span>, column=<span class="string">&#x27;total_bill&#x27;</span>)</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">                 total_bill    tip smoker   day    time  size   tip_pct</span><br><span class="line">smoker day                                                             </span><br><span class="line">No     Fri  <span class="number">94</span>        <span class="number">22.75</span>   <span class="number">3.25</span>     No   Fri  Dinner     <span class="number">2</span>  <span class="number">0.142857</span></span><br><span class="line">       Sat  <span class="number">212</span>       <span class="number">48.33</span>   <span class="number">9.00</span>     No   Sat  Dinner     <span class="number">4</span>  <span class="number">0.186220</span></span><br><span class="line">       Sun  <span class="number">156</span>       <span class="number">48.17</span>   <span class="number">5.00</span>     No   Sun  Dinner     <span class="number">6</span>  <span class="number">0.103799</span></span><br><span class="line">       Thur <span class="number">142</span>       <span class="number">41.19</span>   <span class="number">5.00</span>     No  Thur   Lunch     <span class="number">5</span>  <span class="number">0.121389</span></span><br><span class="line">Yes    Fri  <span class="number">95</span>        <span class="number">40.17</span>   <span class="number">4.73</span>    Yes   Fri  Dinner     <span class="number">4</span>  <span class="number">0.117750</span></span><br><span class="line">       Sat  <span class="number">170</span>       <span class="number">50.81</span>  <span class="number">10.00</span>    Yes   Sat  Dinner     <span class="number">3</span>  <span class="number">0.196812</span></span><br><span class="line">       Sun  <span class="number">182</span>       <span class="number">45.35</span>   <span class="number">3.50</span>    Yes   Sun  Dinner     <span class="number">3</span>  <span class="number">0.077178</span></span><br><span class="line">       Thur <span class="number">197</span>       <span class="number">43.11</span>   <span class="number">5.00</span>    Yes  Thur   Lunch     <span class="number">4</span>  <span class="number">0.115982</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：除这些基本用法之外，能否充分发挥apply的威力很大程度上取决于你的创造力。传入的那个函数能做什么全由你说了算，它只需返回一个pandas对象或标量值即可。本章后续部分的示例主要用于讲解如何利用groupby解决各种各样的问题。</p>
</blockquote>
<p>可能你已经想起来了，之前我在GroupBy对象上调用过describe：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">78</span>]: result = tips.groupby(<span class="string">&#x27;smoker&#x27;</span>)[<span class="string">&#x27;tip_pct&#x27;</span>].describe()</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: result</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line">        count      mean       std       <span class="built_in">min</span>       <span class="number">25</span>%       <span class="number">50</span>%       <span class="number">75</span>%  \</span><br><span class="line">smoker                                                                      </span><br><span class="line">No      <span class="number">151.0</span>  <span class="number">0.159328</span>  <span class="number">0.039910</span>  <span class="number">0.056797</span>  <span class="number">0.136906</span>  <span class="number">0.155625</span>  <span class="number">0.185014</span>   </span><br><span class="line">Yes      <span class="number">93.0</span>  <span class="number">0.163196</span>  <span class="number">0.085119</span>  <span class="number">0.035638</span>  <span class="number">0.106771</span>  <span class="number">0.153846</span>  <span class="number">0.195059</span>   </span><br><span class="line">             <span class="built_in">max</span>  </span><br><span class="line">smoker</span><br><span class="line"></span><br><span class="line">No      <span class="number">0.291990</span>  </span><br><span class="line">Yes     <span class="number">0.710345</span>  </span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: result.unstack(<span class="string">&#x27;smoker&#x27;</span>)</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line">       smoker</span><br><span class="line">count  No        <span class="number">151.000000</span></span><br><span class="line">       Yes        <span class="number">93.000000</span></span><br><span class="line">mean   No          <span class="number">0.159328</span></span><br><span class="line">       Yes         <span class="number">0.163196</span></span><br><span class="line">std    No          <span class="number">0.039910</span></span><br><span class="line">       Yes         <span class="number">0.085119</span></span><br><span class="line"><span class="built_in">min</span>    No          <span class="number">0.056797</span></span><br><span class="line">       Yes         <span class="number">0.035638</span></span><br><span class="line"><span class="number">25</span>%    No          <span class="number">0.136906</span></span><br><span class="line">       Yes         <span class="number">0.106771</span></span><br><span class="line"><span class="number">50</span>%    No          <span class="number">0.155625</span></span><br><span class="line">       Yes         <span class="number">0.153846</span></span><br><span class="line"><span class="number">75</span>%    No          <span class="number">0.185014</span></span><br><span class="line">       Yes         <span class="number">0.195059</span></span><br><span class="line"><span class="built_in">max</span>    No          <span class="number">0.291990</span></span><br><span class="line">       Yes         <span class="number">0.710345</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>在GroupBy中，当你调用诸如describe之类的方法时，实际上只是应用了下面两条代码的快捷方式而已：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f = <span class="keyword">lambda</span> x: x.describe()</span><br><span class="line">grouped.apply(f)</span><br></pre></td></tr></table></figure></p>
<h2><span id="禁止分组键">禁止分组键</span></h2><p>从上面的例子中可以看出，分组键会跟原始对象的索引共同构成结果对象中的层次化索引。将group_keys=False传入groupby即可禁止该效果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">81</span>]: tips.groupby(<span class="string">&#x27;smoker&#x27;</span>, group_keys=<span class="literal">False</span>).apply(top)</span><br><span class="line">Out[<span class="number">81</span>]: </span><br><span class="line">     total_bill   tip smoker   day    time  size   tip_pct</span><br><span class="line"><span class="number">88</span>        <span class="number">24.71</span>  <span class="number">5.85</span>     No  Thur   Lunch     <span class="number">2</span>  <span class="number">0.236746</span></span><br><span class="line"><span class="number">185</span>       <span class="number">20.69</span>  <span class="number">5.00</span>     No   Sun  Dinner     <span class="number">5</span>  <span class="number">0.241663</span></span><br><span class="line"><span class="number">51</span>        <span class="number">10.29</span>  <span class="number">2.60</span>     No   Sun  Dinner     <span class="number">2</span>  <span class="number">0.252672</span></span><br><span class="line"><span class="number">149</span>        <span class="number">7.51</span>  <span class="number">2.00</span>     No  Thur   Lunch     <span class="number">2</span>  <span class="number">0.266312</span></span><br><span class="line"><span class="number">232</span>       <span class="number">11.61</span>  <span class="number">3.39</span>     No   Sat  Dinner     <span class="number">2</span>  <span class="number">0.291990</span></span><br><span class="line"><span class="number">109</span>       <span class="number">14.31</span>  <span class="number">4.00</span>    Yes   Sat  Dinner     <span class="number">2</span>  <span class="number">0.279525</span></span><br><span class="line"><span class="number">183</span>       <span class="number">23.17</span>  <span class="number">6.50</span>    Yes   Sun  Dinner     <span class="number">4</span>  <span class="number">0.280535</span></span><br><span class="line"><span class="number">67</span>         <span class="number">3.07</span>  <span class="number">1.00</span>    Yes   Sat  Dinner     <span class="number">1</span>  <span class="number">0.325733</span></span><br><span class="line"><span class="number">178</span>        <span class="number">9.60</span>  <span class="number">4.00</span>    Yes   Sun  Dinner     <span class="number">2</span>  <span class="number">0.416667</span></span><br><span class="line"><span class="number">172</span>        <span class="number">7.25</span>  <span class="number">5.15</span>    Yes   Sun  Dinner     <span class="number">2</span>  <span class="number">0.710345</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="分位数和桶分析">分位数和桶分析</span></h2><p>我曾在第8章中讲过，pandas有一些能根据指定面元或样本分位数将数据拆分成多块的工具（比如cut和qcut）。将这些函数跟groupby结合起来，就能非常轻松地实现对数据集的桶（bucket）或分位数（quantile）分析了。以下面这个简单的随机数据集为例，我们利用cut将其装入长度相等的桶中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: frame = pd.DataFrame(&#123;<span class="string">&#x27;data1&#x27;</span>: np.random.randn(<span class="number">1000</span>),</span><br><span class="line">   ....:                       <span class="string">&#x27;data2&#x27;</span>: np.random.randn(<span class="number">1000</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: quartiles = pd.cut(frame.data1, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: quartiles[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">84</span>]: </span><br><span class="line"><span class="number">0</span>     (-<span class="number">1.23</span>, <span class="number">0.489</span>]</span><br><span class="line"><span class="number">1</span>    (-<span class="number">2.956</span>, -<span class="number">1.23</span>]</span><br><span class="line"><span class="number">2</span>     (-<span class="number">1.23</span>, <span class="number">0.489</span>]</span><br><span class="line"><span class="number">3</span>     (<span class="number">0.489</span>, <span class="number">2.208</span>]</span><br><span class="line"><span class="number">4</span>     (-<span class="number">1.23</span>, <span class="number">0.489</span>]</span><br><span class="line"><span class="number">5</span>     (<span class="number">0.489</span>, <span class="number">2.208</span>]</span><br><span class="line"><span class="number">6</span>     (-<span class="number">1.23</span>, <span class="number">0.489</span>]</span><br><span class="line"><span class="number">7</span>     (-<span class="number">1.23</span>, <span class="number">0.489</span>]</span><br><span class="line"><span class="number">8</span>     (<span class="number">0.489</span>, <span class="number">2.208</span>]</span><br><span class="line"><span class="number">9</span>     (<span class="number">0.489</span>, <span class="number">2.208</span>]</span><br><span class="line">Name: data1, dtype: category</span><br><span class="line">Categories (<span class="number">4</span>, interval[float64]): [(-<span class="number">2.956</span>, -<span class="number">1.23</span>] &lt; (-<span class="number">1.23</span>, <span class="number">0.489</span>] &lt; (<span class="number">0.489</span>, <span class="number">2.</span></span><br><span class="line"><span class="number">208</span>] &lt; (<span class="number">2.208</span>, <span class="number">3.928</span>]]</span><br></pre></td></tr></table></figure></p>
<p>由cut返回的Categorical对象可直接传递到groupby。因此，我们可以像下面这样对data2列做一些统计计算：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: <span class="function"><span class="keyword">def</span> <span class="title">get_stats</span>(<span class="params">group</span>):</span></span><br><span class="line">   ....:     <span class="keyword">return</span> &#123;<span class="string">&#x27;min&#x27;</span>: group.<span class="built_in">min</span>(), <span class="string">&#x27;max&#x27;</span>: group.<span class="built_in">max</span>(),</span><br><span class="line">   ....:             <span class="string">&#x27;count&#x27;</span>: group.count(), <span class="string">&#x27;mean&#x27;</span>: group.mean()&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: grouped = frame.data2.groupby(quartiles)</span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: grouped.apply(get_stats).unstack()</span><br><span class="line">Out[<span class="number">87</span>]: </span><br><span class="line">                 count       <span class="built_in">max</span>      mean       <span class="built_in">min</span></span><br><span class="line">data1                                               </span><br><span class="line">(-<span class="number">2.956</span>, -<span class="number">1.23</span>]   <span class="number">95.0</span>  <span class="number">1.670835</span> -<span class="number">0.039521</span> -<span class="number">3.399312</span></span><br><span class="line">(-<span class="number">1.23</span>, <span class="number">0.489</span>]   <span class="number">598.0</span>  <span class="number">3.260383</span> -<span class="number">0.002051</span> -<span class="number">2.989741</span></span><br><span class="line">(<span class="number">0.489</span>, <span class="number">2.208</span>]   <span class="number">297.0</span>  <span class="number">2.954439</span>  <span class="number">0.081822</span> -<span class="number">3.745356</span></span><br><span class="line">(<span class="number">2.208</span>, <span class="number">3.928</span>]    <span class="number">10.0</span>  <span class="number">1.765640</span>  <span class="number">0.024750</span> -<span class="number">1.929776</span></span><br></pre></td></tr></table></figure></p>
<p>这些都是长度相等的桶。要根据样本分位数得到大小相等的桶，使用qcut即可。传入labels=False即可只获取分位数的编号：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Return quantile numbers</span></span><br><span class="line">In [<span class="number">88</span>]: grouping = pd.qcut(frame.data1, <span class="number">10</span>, labels=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: grouped = frame.data2.groupby(grouping)</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: grouped.apply(get_stats).unstack()</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">       count       <span class="built_in">max</span>      mean       <span class="built_in">min</span></span><br><span class="line">data1                                     </span><br><span class="line"><span class="number">0</span>      <span class="number">100.0</span>  <span class="number">1.670835</span> -<span class="number">0.049902</span> -<span class="number">3.399312</span></span><br><span class="line"><span class="number">1</span>      <span class="number">100.0</span>  <span class="number">2.628441</span>  <span class="number">0.030989</span> -<span class="number">1.950098</span></span><br><span class="line"><span class="number">2</span>      <span class="number">100.0</span>  <span class="number">2.527939</span> -<span class="number">0.067179</span> -<span class="number">2.925113</span></span><br><span class="line"><span class="number">3</span>      <span class="number">100.0</span>  <span class="number">3.260383</span>  <span class="number">0.065713</span> -<span class="number">2.315555</span></span><br><span class="line"><span class="number">4</span>      <span class="number">100.0</span>  <span class="number">2.074345</span> -<span class="number">0.111653</span> -<span class="number">2.047939</span></span><br><span class="line"><span class="number">5</span>      <span class="number">100.0</span>  <span class="number">2.184810</span>  <span class="number">0.052130</span> -<span class="number">2.989741</span></span><br><span class="line"><span class="number">6</span>      <span class="number">100.0</span>  <span class="number">2.458842</span> -<span class="number">0.021489</span> -<span class="number">2.223506</span></span><br><span class="line"><span class="number">7</span>      <span class="number">100.0</span>  <span class="number">2.954439</span> -<span class="number">0.026459</span> -<span class="number">3.056990</span></span><br><span class="line"><span class="number">8</span>      <span class="number">100.0</span>  <span class="number">2.735527</span>  <span class="number">0.103406</span> -<span class="number">3.745356</span></span><br><span class="line"><span class="number">9</span>      <span class="number">100.0</span>  <span class="number">2.377020</span>  <span class="number">0.220122</span> -<span class="number">2.064111</span></span><br></pre></td></tr></table></figure></p>
<p>我们会在第12章详细讲解pandas的Categorical类型。</p>
<h2><span id="示例用特定于分组的值填充缺失值">示例：用特定于分组的值填充缺失值</span></h2><p>对于缺失数据的清理工作，有时你会用dropna将其替换掉，而有时则可能会希望用一个固定值或由数据集本身所衍生出来的值去填充NA值。这时就得使用fillna这个工具了。在下面这个例子中，我用平均值去填充NA值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: s = pd.Series(np.random.randn(<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: s[::<span class="number">2</span>] = np.nan</span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: s</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line"><span class="number">0</span>         NaN</span><br><span class="line"><span class="number">1</span>   -<span class="number">0.125921</span></span><br><span class="line"><span class="number">2</span>         NaN</span><br><span class="line"><span class="number">3</span>   -<span class="number">0.884475</span></span><br><span class="line"><span class="number">4</span>         NaN</span><br><span class="line"><span class="number">5</span>    <span class="number">0.227290</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">94</span>]: s.fillna(s.mean())</span><br><span class="line">Out[<span class="number">94</span>]: </span><br><span class="line"><span class="number">0</span>   -<span class="number">0.261035</span></span><br><span class="line"><span class="number">1</span>   -<span class="number">0.125921</span></span><br><span class="line"><span class="number">2</span>   -<span class="number">0.261035</span></span><br><span class="line"><span class="number">3</span>   -<span class="number">0.884475</span></span><br><span class="line"><span class="number">4</span>   -<span class="number">0.261035</span></span><br><span class="line"><span class="number">5</span>    <span class="number">0.227290</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>假设你需要对不同的分组填充不同的值。一种方法是将数据分组，并使用apply和一个能够对各数据块调用fillna的函数即可。下面是一些有关美国几个州的示例数据，这些州又被分为东部和西部：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: states = [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>, <span class="string">&#x27;Vermont&#x27;</span>, <span class="string">&#x27;Florida&#x27;</span>,</span><br><span class="line">   ....:           <span class="string">&#x27;Oregon&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;California&#x27;</span>, <span class="string">&#x27;Idaho&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: group_key = [<span class="string">&#x27;East&#x27;</span>] * <span class="number">4</span> + [<span class="string">&#x27;West&#x27;</span>] * <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: data = pd.Series(np.random.randn(<span class="number">8</span>), index=states)</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: data</span><br><span class="line">Out[<span class="number">98</span>]: </span><br><span class="line">Ohio          <span class="number">0.922264</span></span><br><span class="line">New York     -<span class="number">2.153545</span></span><br><span class="line">Vermont      -<span class="number">0.365757</span></span><br><span class="line">Florida      -<span class="number">0.375842</span></span><br><span class="line">Oregon        <span class="number">0.329939</span></span><br><span class="line">Nevada        <span class="number">0.981994</span></span><br><span class="line">California    <span class="number">1.105913</span></span><br><span class="line">Idaho        -<span class="number">1.613716</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>[‘East’] * 4产生了一个列表，包括了[‘East’]中元素的四个拷贝。将这些列表串联起来。</p>
<p>将一些值设为缺失：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">99</span>]: data[[<span class="string">&#x27;Vermont&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Idaho&#x27;</span>]] = np.nan</span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: data</span><br><span class="line">Out[<span class="number">100</span>]: </span><br><span class="line">Ohio          <span class="number">0.922264</span></span><br><span class="line">New York     -<span class="number">2.153545</span></span><br><span class="line">Vermont            NaN</span><br><span class="line">Florida      -<span class="number">0.375842</span></span><br><span class="line">Oregon        <span class="number">0.329939</span></span><br><span class="line">Nevada             NaN</span><br><span class="line">California    <span class="number">1.105913</span></span><br><span class="line">Idaho              NaN</span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">101</span>]: data.groupby(group_key).mean()</span><br><span class="line">Out[<span class="number">101</span>]: </span><br><span class="line">East   -<span class="number">0.535707</span></span><br><span class="line">West    <span class="number">0.717926</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>我们可以用分组平均值去填充NA值:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: fill_mean = <span class="keyword">lambda</span> g: g.fillna(g.mean())</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: data.groupby(group_key).apply(fill_mean)</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">Ohio          <span class="number">0.922264</span></span><br><span class="line">New York     -<span class="number">2.153545</span></span><br><span class="line">Vermont      -<span class="number">0.535707</span></span><br><span class="line">Florida      -<span class="number">0.375842</span></span><br><span class="line">Oregon        <span class="number">0.329939</span></span><br><span class="line">Nevada        <span class="number">0.717926</span></span><br><span class="line">California    <span class="number">1.105913</span></span><br><span class="line">Idaho         <span class="number">0.717926</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>另外，也可以在代码中预定义各组的填充值。由于分组具有一个name属性，所以我们可以拿来用一下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">104</span>]: fill_values = &#123;<span class="string">&#x27;East&#x27;</span>: <span class="number">0.5</span>, <span class="string">&#x27;West&#x27;</span>: -<span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: fill_func = <span class="keyword">lambda</span> g: g.fillna(fill_values[g.name])</span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: data.groupby(group_key).apply(fill_func)</span><br><span class="line">Out[<span class="number">106</span>]: </span><br><span class="line">Ohio          <span class="number">0.922264</span></span><br><span class="line">New York     -<span class="number">2.153545</span></span><br><span class="line">Vermont       <span class="number">0.500000</span></span><br><span class="line">Florida      -<span class="number">0.375842</span></span><br><span class="line">Oregon        <span class="number">0.329939</span></span><br><span class="line">Nevada       -<span class="number">1.000000</span></span><br><span class="line">California    <span class="number">1.105913</span></span><br><span class="line">Idaho        -<span class="number">1.000000</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="示例随机采样和排列">示例：随机采样和排列</span></h2><p>假设你想要从一个大数据集中随机抽取（进行替换或不替换）样本以进行蒙特卡罗模拟（Monte Carlo simulation）或其他分析工作。“抽取”的方式有很多，这里使用的方法是对Series使用sample方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Hearts, Spades, Clubs, Diamonds</span></span><br><span class="line">suits = [<span class="string">&#x27;H&#x27;</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>]</span><br><span class="line">card_val = (<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)) + [<span class="number">10</span>] * <span class="number">3</span>) * <span class="number">4</span></span><br><span class="line">base_names = [<span class="string">&#x27;A&#x27;</span>] + <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">2</span>, <span class="number">11</span>)) + [<span class="string">&#x27;J&#x27;</span>, <span class="string">&#x27;K&#x27;</span>, <span class="string">&#x27;Q&#x27;</span>]</span><br><span class="line">cards = []</span><br><span class="line"><span class="keyword">for</span> suit <span class="keyword">in</span> [<span class="string">&#x27;H&#x27;</span>, <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>]:</span><br><span class="line">    cards.extend(<span class="built_in">str</span>(num) + suit <span class="keyword">for</span> num <span class="keyword">in</span> base_names)</span><br><span class="line"></span><br><span class="line">deck = pd.Series(card_val, index=cards)</span><br></pre></td></tr></table></figure></p>
<p>现在我有了一个长度为52的Series，其索引包括牌名，值则是21点或其他游戏中用于计分的点数（为了简单起见，我当A的点数为1）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: deck[:<span class="number">13</span>]</span><br><span class="line">Out[<span class="number">108</span>]: </span><br><span class="line">AH      <span class="number">1</span></span><br><span class="line">2H      <span class="number">2</span></span><br><span class="line">3H      <span class="number">3</span></span><br><span class="line">4H      <span class="number">4</span></span><br><span class="line">5H      <span class="number">5</span></span><br><span class="line">6H      <span class="number">6</span></span><br><span class="line">7H      <span class="number">7</span></span><br><span class="line">8H      <span class="number">8</span></span><br><span class="line">9H      <span class="number">9</span></span><br><span class="line">10H    <span class="number">10</span></span><br><span class="line">JH     <span class="number">10</span></span><br><span class="line">KH     <span class="number">10</span></span><br><span class="line">QH     <span class="number">10</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>现在，根据我上面所讲的，从整副牌中抽出5张，代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">109</span>]: <span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">deck, n=<span class="number">5</span></span>):</span></span><br><span class="line">   .....:     <span class="keyword">return</span> deck.sample(n)</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: draw(deck)</span><br><span class="line">Out[<span class="number">110</span>]: </span><br><span class="line">AD     <span class="number">1</span></span><br><span class="line">8C     <span class="number">8</span></span><br><span class="line">5H     <span class="number">5</span></span><br><span class="line">KC    <span class="number">10</span></span><br><span class="line">2C     <span class="number">2</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>假设你想要从每种花色中随机抽取两张牌。由于花色是牌名的最后一个字符，所以我们可以据此进行分组，并使用apply：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">111</span>]: get_suit = <span class="keyword">lambda</span> card: card[-<span class="number">1</span>] <span class="comment"># last letter is suit</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: deck.groupby(get_suit).apply(draw, n=<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">112</span>]: </span><br><span class="line">C  2C     <span class="number">2</span></span><br><span class="line">   3C     <span class="number">3</span></span><br><span class="line">D  KD    <span class="number">10</span></span><br><span class="line">   8D     <span class="number">8</span></span><br><span class="line">H  KH    <span class="number">10</span></span><br><span class="line">   3H     <span class="number">3</span></span><br><span class="line">S  2S     <span class="number">2</span></span><br><span class="line">   4S     <span class="number">4</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>或者，也可以这样写：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">113</span>]: deck.groupby(get_suit, group_keys=<span class="literal">False</span>).apply(draw, n=<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">113</span>]: </span><br><span class="line">KC    <span class="number">10</span></span><br><span class="line">JC    <span class="number">10</span></span><br><span class="line">AD     <span class="number">1</span></span><br><span class="line">5D     <span class="number">5</span></span><br><span class="line">5H     <span class="number">5</span></span><br><span class="line">6H     <span class="number">6</span></span><br><span class="line">7S     <span class="number">7</span></span><br><span class="line">KS    <span class="number">10</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<h2><span id="示例分组加权平均数和相关系数">示例：分组加权平均数和相关系数</span></h2><p>根据groupby的“拆分－应用－合并”范式，可以进行DataFrame的列与列之间或两个Series之间的运算（比如分组加权平均）。以下面这个数据集为例，它含有分组键、值以及一些权重值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">114</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;category&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>,</span><br><span class="line">   .....:                                 <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">   .....:                    <span class="string">&#x27;data&#x27;</span>: np.random.randn(<span class="number">8</span>),</span><br><span class="line">   .....:                    <span class="string">&#x27;weights&#x27;</span>: np.random.rand(<span class="number">8</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">115</span>]: df</span><br><span class="line">Out[<span class="number">115</span>]: </span><br><span class="line">  category      data   weights</span><br><span class="line"><span class="number">0</span>        a  <span class="number">1.561587</span>  <span class="number">0.957515</span></span><br><span class="line"><span class="number">1</span>        a  <span class="number">1.219984</span>  <span class="number">0.347267</span></span><br><span class="line"><span class="number">2</span>        a -<span class="number">0.482239</span>  <span class="number">0.581362</span></span><br><span class="line"><span class="number">3</span>        a  <span class="number">0.315667</span>  <span class="number">0.217091</span></span><br><span class="line"><span class="number">4</span>        b -<span class="number">0.047852</span>  <span class="number">0.894406</span></span><br><span class="line"><span class="number">5</span>        b -<span class="number">0.454145</span>  <span class="number">0.918564</span></span><br><span class="line"><span class="number">6</span>        b -<span class="number">0.556774</span>  <span class="number">0.277825</span></span><br><span class="line"><span class="number">7</span>        b  <span class="number">0.253321</span>  <span class="number">0.955905</span></span><br></pre></td></tr></table></figure></p>
<p>然后可以利用category计算分组加权平均数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">116</span>]: grouped = df.groupby(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">117</span>]: get_wavg = <span class="keyword">lambda</span> g: np.average(g[<span class="string">&#x27;data&#x27;</span>], weights=g[<span class="string">&#x27;weights&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: grouped.apply(get_wavg)</span><br><span class="line">Out[<span class="number">118</span>]:</span><br><span class="line">category</span><br><span class="line">a    <span class="number">0.811643</span></span><br><span class="line">b   -<span class="number">0.122262</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>另一个例子，考虑一个来自Yahoo!Finance的数据集，其中含有几只股票和标准普尔500指数（符号SPX）的收盘价：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">119</span>]: close_px = pd.read_csv(<span class="string">&#x27;examples/stock_px_2.csv&#x27;</span>, parse_dates=<span class="literal">True</span>,</span><br><span class="line">   .....:                        index_col=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">120</span>]: close_px.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">DatetimeIndex</span>:</span> <span class="number">2214</span> entries, <span class="number">2003</span>-01-02 to <span class="number">2011</span>-<span class="number">10</span>-<span class="number">14</span></span><br><span class="line">Data columns (total <span class="number">4</span> columns):</span><br><span class="line">AAPL    <span class="number">2214</span> non-null float64</span><br><span class="line">MSFT    <span class="number">2214</span> non-null float64</span><br><span class="line">XOM     <span class="number">2214</span> non-null float64</span><br><span class="line">SPX     <span class="number">2214</span> non-null float64</span><br><span class="line">dtypes: float64(<span class="number">4</span>)</span><br><span class="line">memory usage: <span class="number">86.5</span> KB</span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: close_px[-<span class="number">4</span>:]</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line">              AAPL   MSFT    XOM      SPX</span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">11</span>  <span class="number">400.29</span>  <span class="number">27.00</span>  <span class="number">76.27</span>  <span class="number">1195.54</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">12</span>  <span class="number">402.19</span>  <span class="number">26.96</span>  <span class="number">77.16</span>  <span class="number">1207.25</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">13</span>  <span class="number">408.43</span>  <span class="number">27.18</span>  <span class="number">76.37</span>  <span class="number">1203.66</span></span><br><span class="line"><span class="number">2011</span>-<span class="number">10</span>-<span class="number">14</span>  <span class="number">422.00</span>  <span class="number">27.27</span>  <span class="number">78.11</span>  <span class="number">1224.58</span></span><br></pre></td></tr></table></figure></p>
<p>来做一个比较有趣的任务：计算一个由日收益率（通过百分数变化计算）与SPX之间的年度相关系数组成的DataFrame。下面是一个实现办法，我们先创建一个函数，用它计算每列和SPX列的成对相关系数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">122</span>]: spx_corr = <span class="keyword">lambda</span> x: x.corrwith(x[<span class="string">&#x27;SPX&#x27;</span>])</span><br></pre></td></tr></table></figure></p>
<p>接下来，我们使用pct_change计算close_px的百分比变化：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">123</span>]: rets = close_px.pct_change().dropna()</span><br></pre></td></tr></table></figure></p>
<p>最后，我们用年对百分比变化进行分组，可以用一个一行的函数，从每行的标签返回每个datetime标签的year属性：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">124</span>]: get_year = <span class="keyword">lambda</span> x: x.year</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: by_year = rets.groupby(get_year)</span><br><span class="line"></span><br><span class="line">In [<span class="number">126</span>]: by_year.apply(spx_corr)</span><br><span class="line">Out[<span class="number">126</span>]: </span><br><span class="line">          AAPL      MSFT       XOM  SPX</span><br><span class="line"><span class="number">2003</span>  <span class="number">0.541124</span>  <span class="number">0.745174</span>  <span class="number">0.661265</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2004</span>  <span class="number">0.374283</span>  <span class="number">0.588531</span>  <span class="number">0.557742</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2005</span>  <span class="number">0.467540</span>  <span class="number">0.562374</span>  <span class="number">0.631010</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2006</span>  <span class="number">0.428267</span>  <span class="number">0.406126</span>  <span class="number">0.518514</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2007</span>  <span class="number">0.508118</span>  <span class="number">0.658770</span>  <span class="number">0.786264</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2008</span>  <span class="number">0.681434</span>  <span class="number">0.804626</span>  <span class="number">0.828303</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2009</span>  <span class="number">0.707103</span>  <span class="number">0.654902</span>  <span class="number">0.797921</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2010</span>  <span class="number">0.710105</span>  <span class="number">0.730118</span>  <span class="number">0.839057</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2011</span>  <span class="number">0.691931</span>  <span class="number">0.800996</span>  <span class="number">0.859975</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<p>当然，你还可以计算列与列之间的相关系数。这里，我们计算Apple和Microsoft的年相关系数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">127</span>]: by_year.apply(<span class="keyword">lambda</span> g: g[<span class="string">&#x27;AAPL&#x27;</span>].corr(g[<span class="string">&#x27;MSFT&#x27;</span>]))</span><br><span class="line">Out[<span class="number">127</span>]: </span><br><span class="line"><span class="number">2003</span>    <span class="number">0.480868</span></span><br><span class="line"><span class="number">2004</span>    <span class="number">0.259024</span></span><br><span class="line"><span class="number">2005</span>    <span class="number">0.300093</span></span><br><span class="line"><span class="number">2006</span>    <span class="number">0.161735</span></span><br><span class="line"><span class="number">2007</span>    <span class="number">0.417738</span></span><br><span class="line"><span class="number">2008</span>    <span class="number">0.611901</span></span><br><span class="line"><span class="number">2009</span>    <span class="number">0.432738</span></span><br><span class="line"><span class="number">2010</span>    <span class="number">0.571946</span></span><br><span class="line"><span class="number">2011</span>    <span class="number">0.581987</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="示例组级别的线性回归">示例：组级别的线性回归</span></h2><p>顺着上一个例子继续，你可以用groupby执行更为复杂的分组统计分析，只要函数返回的是pandas对象或标量值即可。例如，我可以定义下面这个regress函数（利用statsmodels计量经济学库）对各数据块执行普通最小二乘法（Ordinary Least Squares，OLS）回归：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">regress</span>(<span class="params">data, yvar, xvars</span>):</span></span><br><span class="line">    Y = data[yvar]</span><br><span class="line">    X = data[xvars]</span><br><span class="line">    X[<span class="string">&#x27;intercept&#x27;</span>] = <span class="number">1.</span></span><br><span class="line">    result = sm.OLS(Y, X).fit()</span><br><span class="line">    <span class="keyword">return</span> result.params</span><br></pre></td></tr></table></figure></p>
<p>现在，为了按年计算AAPL对SPX收益率的线性回归，执行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">129</span>]: by_year.apply(regress, <span class="string">&#x27;AAPL&#x27;</span>, [<span class="string">&#x27;SPX&#x27;</span>])</span><br><span class="line">Out[<span class="number">129</span>]: </span><br><span class="line">           SPX  intercept</span><br><span class="line"><span class="number">2003</span>  <span class="number">1.195406</span>   <span class="number">0.000710</span></span><br><span class="line"><span class="number">2004</span>  <span class="number">1.363463</span>   <span class="number">0.004201</span></span><br><span class="line"><span class="number">2005</span>  <span class="number">1.766415</span>   <span class="number">0.003246</span></span><br><span class="line"><span class="number">2006</span>  <span class="number">1.645496</span>   <span class="number">0.000080</span></span><br><span class="line"><span class="number">2007</span>  <span class="number">1.198761</span>   <span class="number">0.003438</span></span><br><span class="line"><span class="number">2008</span>  <span class="number">0.968016</span>  -<span class="number">0.001110</span></span><br><span class="line"><span class="number">2009</span>  <span class="number">0.879103</span>   <span class="number">0.002954</span></span><br><span class="line"><span class="number">2010</span>  <span class="number">1.052608</span>   <span class="number">0.001261</span></span><br><span class="line"><span class="number">2011</span>  <span class="number">0.806605</span>   <span class="number">0.001514</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="104-透视表和交叉表">10.4 透视表和交叉表</span></h1><p>透视表（pivot table）是各种电子表格程序和其他数据分析软件中一种常见的数据汇总工具。它根据一个或多个键对数据进行聚合，并根据行和列上的分组键将数据分配到各个矩形区域中。在Python和pandas中，可以通过本章所介绍的groupby功能以及（能够利用层次化索引的）重塑运算制作透视表。DataFrame有一个pivot_table方法，此外还有一个顶级的pandas.pivot_table函数。除能为groupby提供便利之外，pivot_table还可以添加分项小计，也叫做margins。</p>
<p>回到小费数据集，假设我想要根据day和smoker计算分组平均数（pivot_table的默认聚合类型），并将day和smoker放到行上：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">130</span>]: tips.pivot_table(index=[<span class="string">&#x27;day&#x27;</span>, <span class="string">&#x27;smoker&#x27;</span>])</span><br><span class="line">Out[<span class="number">130</span>]: </span><br><span class="line">                 size       tip   tip_pct  total_bill</span><br><span class="line">day  smoker                                          </span><br><span class="line">Fri  No      <span class="number">2.250000</span>  <span class="number">2.812500</span>  <span class="number">0.151650</span>   <span class="number">18.420000</span></span><br><span class="line">     Yes     <span class="number">2.066667</span>  <span class="number">2.714000</span>  <span class="number">0.174783</span>   <span class="number">16.813333</span></span><br><span class="line">Sat  No      <span class="number">2.555556</span>  <span class="number">3.102889</span>  <span class="number">0.158048</span>   <span class="number">19.661778</span></span><br><span class="line">     Yes     <span class="number">2.476190</span>  <span class="number">2.875476</span>  <span class="number">0.147906</span>   <span class="number">21.276667</span></span><br><span class="line">Sun  No      <span class="number">2.929825</span>  <span class="number">3.167895</span>  <span class="number">0.160113</span>   <span class="number">20.506667</span></span><br><span class="line">     Yes     <span class="number">2.578947</span>  <span class="number">3.516842</span>  <span class="number">0.187250</span>   <span class="number">24.120000</span></span><br><span class="line">Thur No      <span class="number">2.488889</span>  <span class="number">2.673778</span>  <span class="number">0.160298</span>   <span class="number">17.113111</span></span><br><span class="line">     Yes     <span class="number">2.352941</span>  <span class="number">3.030000</span>  <span class="number">0.163863</span>   <span class="number">19.190588</span></span><br></pre></td></tr></table></figure></p>
<p>可以用groupby直接来做。现在，假设我们只想聚合tip_pct和size，而且想根据time进行分组。我将smoker放到列上，把day放到行上：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">131</span>]: tips.pivot_table([<span class="string">&#x27;tip_pct&#x27;</span>, <span class="string">&#x27;size&#x27;</span>], index=[<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;day&#x27;</span>],</span><br><span class="line">   .....:                  columns=<span class="string">&#x27;smoker&#x27;</span>)</span><br><span class="line">Out[<span class="number">131</span>]: </span><br><span class="line">                 size             tip_pct          </span><br><span class="line">smoker             No       Yes        No       Yes</span><br><span class="line">time   day                                         </span><br><span class="line">Dinner Fri   <span class="number">2.000000</span>  <span class="number">2.222222</span>  <span class="number">0.139622</span>  <span class="number">0.165347</span></span><br><span class="line">       Sat   <span class="number">2.555556</span>  <span class="number">2.476190</span>  <span class="number">0.158048</span>  <span class="number">0.147906</span></span><br><span class="line">       Sun   <span class="number">2.929825</span>  <span class="number">2.578947</span>  <span class="number">0.160113</span>  <span class="number">0.187250</span></span><br><span class="line">       Thur  <span class="number">2.000000</span>       NaN  <span class="number">0.159744</span>       NaN</span><br><span class="line">Lunch  Fri   <span class="number">3.000000</span>  <span class="number">1.833333</span>  <span class="number">0.187735</span>  <span class="number">0.188937</span></span><br><span class="line">       Thur  <span class="number">2.500000</span>  <span class="number">2.352941</span>  <span class="number">0.160311</span>  <span class="number">0.163863</span></span><br></pre></td></tr></table></figure></p>
<p>还可以对这个表作进一步的处理，传入margins=True添加分项小计。这将会添加标签为All的行和列，其值对应于单个等级中所有数据的分组统计：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">132</span>]: tips.pivot_table([<span class="string">&#x27;tip_pct&#x27;</span>, <span class="string">&#x27;size&#x27;</span>], index=[<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;day&#x27;</span>],</span><br><span class="line">   .....:                  columns=<span class="string">&#x27;smoker&#x27;</span>, margins=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">132</span>]: </span><br><span class="line">                 size                       tip_pct                    </span><br><span class="line">smoker             No       Yes       All        No       Yes       All</span><br><span class="line">time   day                                                             </span><br><span class="line">Dinner Fri   <span class="number">2.000000</span>  <span class="number">2.222222</span>  <span class="number">2.166667</span>  <span class="number">0.139622</span>  <span class="number">0.165347</span>  <span class="number">0.158916</span></span><br><span class="line">       Sat   <span class="number">2.555556</span>  <span class="number">2.476190</span>  <span class="number">2.517241</span>  <span class="number">0.158048</span>  <span class="number">0.147906</span>  <span class="number">0.153152</span></span><br><span class="line">       Sun   <span class="number">2.929825</span>  <span class="number">2.578947</span>  <span class="number">2.842105</span>  <span class="number">0.160113</span>  <span class="number">0.187250</span>  <span class="number">0.166897</span></span><br><span class="line">       Thur  <span class="number">2.000000</span>       NaN  <span class="number">2.000000</span>  <span class="number">0.159744</span>       NaN  <span class="number">0.159744</span></span><br><span class="line">Lunch  Fri   <span class="number">3.000000</span>  <span class="number">1.833333</span>  <span class="number">2.000000</span>  <span class="number">0.187735</span>  <span class="number">0.188937</span>  <span class="number">0.188765</span></span><br><span class="line">       Thur  <span class="number">2.500000</span>  <span class="number">2.352941</span>  <span class="number">2.459016</span>  <span class="number">0.160311</span>  <span class="number">0.163863</span>  <span class="number">0.161301</span></span><br><span class="line">All          <span class="number">2.668874</span>  <span class="number">2.408602</span>  <span class="number">2.569672</span>  <span class="number">0.159328</span>  <span class="number">0.163196</span>  <span class="number">0.160803</span></span><br></pre></td></tr></table></figure></p>
<p>这里，All值为平均数：不单独考虑烟民与非烟民（All列），不单独考虑行分组两个级别中的任何单项（All行）。</p>
<p>要使用其他的聚合函数，将其传给aggfunc即可。例如，使用count或len可以得到有关分组大小的交叉表（计数或频率）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">133</span>]: tips.pivot_table(<span class="string">&#x27;tip_pct&#x27;</span>, index=[<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;smoker&#x27;</span>], columns=<span class="string">&#x27;day&#x27;</span>,</span><br><span class="line">   .....:                  aggfunc=<span class="built_in">len</span>, margins=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">day             Fri   Sat   Sun  Thur    All</span><br><span class="line">time   smoker                               </span><br><span class="line">Dinner No       <span class="number">3.0</span>  <span class="number">45.0</span>  <span class="number">57.0</span>   <span class="number">1.0</span>  <span class="number">106.0</span></span><br><span class="line">       Yes      <span class="number">9.0</span>  <span class="number">42.0</span>  <span class="number">19.0</span>   NaN   <span class="number">70.0</span></span><br><span class="line">Lunch  No       <span class="number">1.0</span>   NaN   NaN  <span class="number">44.0</span>   <span class="number">45.0</span></span><br><span class="line">       Yes      <span class="number">6.0</span>   NaN   NaN  <span class="number">17.0</span>   <span class="number">23.0</span></span><br><span class="line">All            <span class="number">19.0</span>  <span class="number">87.0</span>  <span class="number">76.0</span>  <span class="number">62.0</span>  <span class="number">244.0</span></span><br></pre></td></tr></table></figure></p>
<p>如果存在空的组合（也就是NA），你可能会希望设置一个fill_value：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">134</span>]: tips.pivot_table(<span class="string">&#x27;tip_pct&#x27;</span>, index=[<span class="string">&#x27;time&#x27;</span>, <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;smoker&#x27;</span>],</span><br><span class="line">   .....:                  columns=<span class="string">&#x27;day&#x27;</span>, aggfunc=<span class="string">&#x27;mean&#x27;</span>, fill_value=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">134</span>]: </span><br><span class="line">day                      Fri       Sat       Sun      Thur</span><br><span class="line">time   size smoker                                        </span><br><span class="line">Dinner <span class="number">1</span>    No      <span class="number">0.000000</span>  <span class="number">0.137931</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span></span><br><span class="line">            Yes     <span class="number">0.000000</span>  <span class="number">0.325733</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span></span><br><span class="line">       <span class="number">2</span>    No      <span class="number">0.139622</span>  <span class="number">0.162705</span>  <span class="number">0.168859</span>  <span class="number">0.159744</span></span><br><span class="line">            Yes     <span class="number">0.171297</span>  <span class="number">0.148668</span>  <span class="number">0.207893</span>  <span class="number">0.000000</span></span><br><span class="line">       <span class="number">3</span>    No      <span class="number">0.000000</span>  <span class="number">0.154661</span>  <span class="number">0.152663</span>  <span class="number">0.000000</span></span><br><span class="line">            Yes     <span class="number">0.000000</span>  <span class="number">0.144995</span>  <span class="number">0.152660</span>  <span class="number">0.000000</span></span><br><span class="line">       <span class="number">4</span>    No      <span class="number">0.000000</span>  <span class="number">0.150096</span>  <span class="number">0.148143</span>  <span class="number">0.000000</span></span><br><span class="line">            Yes     <span class="number">0.117750</span>  <span class="number">0.124515</span>  <span class="number">0.193370</span>  <span class="number">0.000000</span></span><br><span class="line">       <span class="number">5</span>    No      <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.206928</span>  <span class="number">0.000000</span></span><br><span class="line">Yes     <span class="number">0.000000</span>  <span class="number">0.106572</span>  <span class="number">0.065660</span>  <span class="number">0.000000</span></span><br><span class="line"><span class="meta">... </span>                     ...       ...       ...       ...</span><br><span class="line">Lunch  <span class="number">1</span>    No      <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.181728</span></span><br><span class="line">            Yes     <span class="number">0.223776</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span></span><br><span class="line">       <span class="number">2</span>    No      <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.166005</span></span><br><span class="line">            Yes     <span class="number">0.181969</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.158843</span></span><br><span class="line">       <span class="number">3</span>    No      <span class="number">0.187735</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.084246</span></span><br><span class="line">            Yes     <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.204952</span></span><br><span class="line">       <span class="number">4</span>    No      <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.138919</span></span><br><span class="line">            Yes     <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.155410</span></span><br><span class="line">       <span class="number">5</span>    No      <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.121389</span></span><br><span class="line">       <span class="number">6</span>    No      <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.173706</span></span><br><span class="line">[<span class="number">21</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>pivot_table的参数说明请参见表10-2。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c9e01844c4803a42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表10-2 pivot_table的选项"></p>
<h2><span id="交叉表crosstab">交叉表：crosstab</span></h2><p>交叉表（cross-tabulation，简称crosstab）是一种用于计算分组频率的特殊透视表。看下面的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">138</span>]: data</span><br><span class="line">Out[<span class="number">138</span>]:</span><br><span class="line">   Sample Nationality    Handedness</span><br><span class="line"><span class="number">0</span>       <span class="number">1</span>         USA  Right-handed</span><br><span class="line"><span class="number">1</span>       <span class="number">2</span>       Japan   Left-handed</span><br><span class="line"><span class="number">2</span>       <span class="number">3</span>         USA  Right-handed</span><br><span class="line"><span class="number">3</span>       <span class="number">4</span>       Japan  Right-handed</span><br><span class="line"><span class="number">4</span>       <span class="number">5</span>       Japan   Left-handed</span><br><span class="line"><span class="number">5</span>       <span class="number">6</span>       Japan  Right-handed</span><br><span class="line"><span class="number">6</span>       <span class="number">7</span>         USA  Right-handed</span><br><span class="line"><span class="number">7</span>       <span class="number">8</span>         USA   Left-handed</span><br><span class="line"><span class="number">8</span>       <span class="number">9</span>       Japan  Right-handed</span><br><span class="line"><span class="number">9</span>      <span class="number">10</span>         USA  Right-handed</span><br></pre></td></tr></table></figure></p>
<p>作为调查分析的一部分，我们可能想要根据国籍和用手习惯对这段数据进行统计汇总。虽然可以用pivot_table实现该功能，但是pandas.crosstab函数会更方便：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">139</span>]: pd.crosstab(data.Nationality, data.Handedness, margins=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">139</span>]: </span><br><span class="line">Handedness   Left-handed  Right-handed  All</span><br><span class="line">Nationality</span><br><span class="line">Japan                  <span class="number">2</span>             <span class="number">3</span>    <span class="number">5</span></span><br><span class="line">USA                    <span class="number">1</span>             <span class="number">4</span>    <span class="number">5</span></span><br><span class="line">All                    <span class="number">3</span>             <span class="number">7</span>   <span class="number">10</span></span><br></pre></td></tr></table></figure></p>
<p>crosstab的前两个参数可以是数组或Series，或是数组列表。就像小费数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">140</span>]: pd.crosstab([tips.time, tips.day], tips.smoker, margins=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">140</span>]: </span><br><span class="line">smoker        No  Yes  All</span><br><span class="line">time   day                </span><br><span class="line">Dinner Fri     <span class="number">3</span>    <span class="number">9</span>   <span class="number">12</span></span><br><span class="line">       Sat    <span class="number">45</span>   <span class="number">42</span>   <span class="number">87</span></span><br><span class="line">       Sun    <span class="number">57</span>   <span class="number">19</span>   <span class="number">76</span></span><br><span class="line">       Thur    <span class="number">1</span>    <span class="number">0</span>    <span class="number">1</span></span><br><span class="line">Lunch  Fri     <span class="number">1</span>    <span class="number">6</span>    <span class="number">7</span></span><br><span class="line">       Thur   <span class="number">44</span>   <span class="number">17</span>   <span class="number">61</span></span><br><span class="line">All          <span class="number">151</span>   <span class="number">93</span>  <span class="number">244</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="105-总结">10.5 总结</span></h1><p>掌握pandas数据分组工具既有助于数据清理，也有助于建模或统计分析工作。在第14章，我们会看几个例子，对真实数据使用groupby。</p>
<p>在下一章，我们将关注时间序列数据。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-9.可视化</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-9-%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>信息可视化（也叫绘图）是数据分析中最重要的工作之一。它可能是探索过程的一部分，例如，帮助我们找出异常值、必要的数据转换、得出有关模型的idea等。另外，做一个可交互的数据可视化也许是工作的最终目标。Python有许多库进行静态或动态的数据可视化，但我这里重要关注于matplotlib（<a href="http://matplotlib.org/）和基于它的库。">http://matplotlib.org/）和基于它的库。</a></p>
<span id="more"></span>
<p>matplotlib是一个用于创建出版质量图表的桌面绘图包（主要是2D方面）。该项目是由John Hunter于2002年启动的，其目的是为Python构建一个MATLAB式的绘图接口。matplotlib和IPython社区进行合作，简化了从IPython shell（包括现在的Jupyter notebook）进行交互式绘图。matplotlib支持各种操作系统上许多不同的GUI后端，而且还能将图片导出为各种常见的矢量（vector）和光栅（raster）图：PDF、SVG、JPG、PNG、BMP、GIF等。除了几张，本书中的大部分图都是用它生成的。</p>
<p>随着时间的发展，matplotlib衍生出了多个数据可视化的工具集，它们使用matplotlib作为底层。其中之一是seaborn（<a href="http://seaborn.pydata.org/），本章后面会学习它。">http://seaborn.pydata.org/），本章后面会学习它。</a></p>
<p>学习本章代码案例的最简单方法是在Jupyter notebook进行交互式绘图。在Jupyter notebook中执行下面的语句：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib notebook</span><br></pre></td></tr></table></figure></p>
<h1><span id="91-matplotlib-api入门">9.1 matplotlib API入门</span></h1><p> matplotlib的通常引入约定是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">11</span>]: <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p>在Jupyter中运行%matplotlib notebook（或在IPython中运行%matplotlib），就可以创建一个简单的图形。如果一切设置正确，会看到图9-1：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: data = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: data</span><br><span class="line">Out[<span class="number">14</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: plt.plot(data)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-7032e333a6ecdd37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-1 简单的线图"></p>
<p>虽然seaborn这样的库和pandas的内置绘图函数能够处理许多普通的绘图任务，但如果需要自定义一些高级功能的话就必须学习matplotlib API。</p>
<blockquote>
<p>笔记：虽然本书没有详细地讨论matplotlib的各种功能，但足以将你引入门。matplotlib的示例库和文档是学习高级特性的最好资源。</p>
</blockquote>
<h2><span id="figure和subplot">Figure和Subplot</span></h2><p>matplotlib的图像都位于Figure对象中。你可以用plt.figure创建一个新的Figure：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: fig = plt.figure()</span><br></pre></td></tr></table></figure>
<p>如果用的是IPython，这时会弹出一个空窗口，但在Jupyter中，必须再输入更多命令才能看到。plt.figure有一些选项，特别是figsize，它用于确保当图片保存到磁盘时具有一定的大小和纵横比。</p>
<p>不能通过空Figure绘图。必须用add_subplot创建一个或多个subplot才行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: ax1 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>这条代码的意思是：图像应该是2×2的（即最多4张图），且当前选中的是4个subplot中的第一个（编号从1开始）。如果再把后面两个subplot也创建出来，最终得到的图像如图9-2所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: ax2 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: ax3 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-b8cff158e64eae74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-2 带有三个subplot的Figure"></p>
<blockquote>
<p>提示：使用Jupyter notebook有一点不同，即每个小窗重新执行后，图形会被重置。因此，对于复杂的图形，，你必须将所有的绘图命令存在一个小窗里。</p>
</blockquote>
<p>这里，我们运行同一个小窗里的所有命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">ax3 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>如果这时执行一条绘图命令（如plt.plot([1.5, 3.5, -2, 1.6])），matplotlib就会在最后一个用过的subplot（如果没有则创建一个）上进行绘制，隐藏创建figure和subplot的过程。因此，如果我们执行下列命令，你就会得到如图9-3所示的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">20</span>]: plt.plot(np.random.randn(<span class="number">50</span>).cumsum(), <span class="string">&#x27;k--&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-7bcbd5e56fdbbd92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-3 绘制一次之后的图像"></p>
<p>“k—“是一个线型选项，用于告诉matplotlib绘制黑色虚线图。上面那些由fig.add_subplot所返回的对象是AxesSubplot对象，直接调用它们的实例方法就可以在其它空着的格子里面画图了，如图9-4所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: ax1.hist(np.random.randn(<span class="number">100</span>), bins=<span class="number">20</span>, color=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: ax2.scatter(np.arange(<span class="number">30</span>), np.arange(<span class="number">30</span>) + <span class="number">3</span> * np.random.randn(<span class="number">30</span>))</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-2297bcaf355db24c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-4 继续绘制两次之后的图像"></p>
<p>你可以在matplotlib的文档中找到各种图表类型。</p>
<p>创建包含subplot网格的figure是一个非常常见的任务，matplotlib有一个更为方便的方法plt.subplots，它可以创建一个新的Figure，并返回一个含有已创建的subplot对象的NumPy数组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: axes</span><br><span class="line">Out[<span class="number">25</span>]: </span><br><span class="line">array([[&lt;matplotlib.axes._subplots.AxesSubplot <span class="built_in">object</span> at <span class="number">0x7fb626374048</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot <span class="built_in">object</span> at <span class="number">0x7fb62625db00</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot <span class="built_in">object</span> at <span class="number">0x7fb6262f6c88</span>&gt;],</span><br><span class="line">       [&lt;matplotlib.axes._subplots.AxesSubplot <span class="built_in">object</span> at <span class="number">0x7fb6261a36a0</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot <span class="built_in">object</span> at <span class="number">0x7fb626181860</span>&gt;,</span><br><span class="line">        &lt;matplotlib.axes._subplots.AxesSubplot <span class="built_in">object</span> at <span class="number">0x7fb6260fd4e0</span>&gt;]], dtype</span><br><span class="line">=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure>
<p>这是非常实用的，因为可以轻松地对axes数组进行索引，就好像是一个二维数组一样，例如axes[0,1]。你还可以通过sharex和sharey指定subplot应该具有相同的X轴或Y轴。在比较相同范围的数据时，这也是非常实用的，否则，matplotlib会自动缩放各图表的界限。有关该方法的更多信息，请参见表9-1。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-88bb55faca7d01ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-1 pyplot.subplots的选项"></p>
<h2><span id="调整subplot周围的间距">调整subplot周围的间距</span></h2><p>默认情况下，matplotlib会在subplot外围留下一定的边距，并在subplot之间留下一定的间距。间距跟图像的高度和宽度有关，因此，如果你调整了图像大小（不管是编程还是手工），间距也会自动调整。利用Figure的subplots_adjust方法可以轻而易举地修改间距，此外，它也是个顶级函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">subplots_adjust(left=<span class="literal">None</span>, bottom=<span class="literal">None</span>, right=<span class="literal">None</span>, top=<span class="literal">None</span>,</span><br><span class="line">                wspace=<span class="literal">None</span>, hspace=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>wspace和hspace用于控制宽度和高度的百分比，可以用作subplot之间的间距。下面是一个简单的例子，其中我将间距收缩到了0（如图9-5所示）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        axes[i, j].hist(np.random.randn(<span class="number">500</span>), bins=<span class="number">50</span>, color=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0</span>, hspace=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-80be7ffc3dec88a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-5 各subplot之间没有间距"></p>
<p>不难看出，其中的轴标签重叠了。matplotlib不会检查标签是否重叠，所以对于这种情况，你只能自己设定刻度位置和刻度标签。后面几节将会详细介绍该内容。</p>
<h2><span id="颜色-标记和线型">颜色、标记和线型</span></h2><p>matplotlib的plot函数接受一组X和Y坐标，还可以接受一个表示颜色和线型的字符串缩写。例如，要根据x和y绘制绿色虚线，你可以执行如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.plot(x, y, <span class="string">&#x27;g--&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这种在一个字符串中指定颜色和线型的方式非常方便。在实际中，如果你是用代码绘图，你可能不想通过处理字符串来获得想要的格式。通过下面这种更为明确的方式也能得到同样的效果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.plot(x, y, linestyle=<span class="string">&#x27;--&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>常用的颜色可以使用颜色缩写，你也可以指定颜色码（例如，’#CECECE’）。你可以通过查看plot的文档字符串查看所有线型的合集（在IPython和Jupyter中使用plot?）。</p>
<p>线图可以使用标记强调数据点。因为matplotlib可以创建连续线图，在点之间进行插值，因此有时可能不太容易看出真实数据点的位置。标记也可以放到格式字符串中，但标记类型和线型必须放在颜色后面（见图9-6）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">30</span>]: <span class="keyword">from</span> numpy.random <span class="keyword">import</span> randn</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: plt.plot(randn(<span class="number">30</span>).cumsum(), <span class="string">&#x27;ko--&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-404d816f3e1d6621.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-6 带有标记的线型图示例"></p>
<p>还可以将其写成更为明确的形式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot(randn(<span class="number">30</span>).cumsum(), color=<span class="string">&#x27;k&#x27;</span>, linestyle=<span class="string">&#x27;dashed&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>在线型图中，非实际数据点默认是按线性方式插值的。可以通过drawstyle选项修改（见图9-7）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: data = np.random.randn(<span class="number">30</span>).cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: plt.plot(data, <span class="string">&#x27;k--&#x27;</span>, label=<span class="string">&#x27;Default&#x27;</span>)</span><br><span class="line">Out[<span class="number">34</span>]: [&lt;matplotlib.lines.Line2D at <span class="number">0x7fb624d86160</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: plt.plot(data, <span class="string">&#x27;k-&#x27;</span>, drawstyle=<span class="string">&#x27;steps-post&#x27;</span>, label=<span class="string">&#x27;steps-post&#x27;</span>)</span><br><span class="line">Out[<span class="number">35</span>]: [&lt;matplotlib.lines.Line2D at <span class="number">0x7fb624d869e8</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-3ec7642e1a592f08.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-7 不同drawstyle选项的线型图"></p>
<p>你可能注意到运行上面代码时有输出<matplotlib.lines.line2d at ...>。matplotlib会返回引用了新添加的子组件的对象。大多数时候，你可以放心地忽略这些输出。这里，因为我们传递了label参数到plot，我们可以创建一个plot图例，指明每条使用plt.legend的线。</matplotlib.lines.line2d></p>
<blockquote>
<p>笔记：你必须调用plt.legend（或使用ax.legend，如果引用了轴的话）来创建图例，无论你绘图时是否传递label标签选项。</p>
</blockquote>
<h2><span id="刻度-标签和图例">刻度、标签和图例</span></h2><p>对于大多数的图表装饰项，其主要实现方式有二：使用过程型的pyplot接口（例如，matplotlib.pyplot）以及更为面向对象的原生matplotlib API。</p>
<p>pyplot接口的设计目的就是交互式使用，含有诸如xlim、xticks和xticklabels之类的方法。它们分别控制图表的范围、刻度位置、刻度标签等。其使用方式有以下两种：</p>
<ul>
<li>调用时不带参数，则返回当前的参数值（例如，plt.xlim()返回当前的X轴绘图范围）。</li>
<li>调用时带参数，则设置参数值（例如，plt.xlim([0,10])会将X轴的范围设置为0到10）。</li>
</ul>
<p>所有这些方法都是对当前或最近创建的AxesSubplot起作用的。它们各自对应subplot对象上的两个方法，以xlim为例，就是ax.get_xlim和ax.set_xlim。我更喜欢使用subplot的实例方法（因为我喜欢明确的事情，而且在处理多个subplot时这样也更清楚一些）。当然你完全可以选择自己觉得方便的那个。</p>
<h2><span id="设置标题-轴标签-刻度以及刻度标签">设置标题、轴标签、刻度以及刻度标签</span></h2><p>为了说明自定义轴，我将创建一个简单的图像并绘制一段随机漫步（如图9-8所示）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">37</span>]: fig = plt.figure()</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: ax.plot(np.random.randn(<span class="number">1000</span>).cumsum())</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-caf9300dacb61fa4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-8 用于演示xticks的简单线型图（带有标签）"></p>
<p>要改变x轴刻度，最简单的办法是使用set_xticks和set_xticklabels。前者告诉matplotlib要将刻度放在数据范围中的哪些位置，默认情况下，这些位置也就是刻度标签。但我们可以通过set_xticklabels将任何其他的值用作标签：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">40</span>]: ticks = ax.set_xticks([<span class="number">0</span>, <span class="number">250</span>, <span class="number">500</span>, <span class="number">750</span>, <span class="number">1000</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: labels = ax.set_xticklabels([<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>, <span class="string">&#x27;five&#x27;</span>],</span><br><span class="line">   ....:                             rotation=<span class="number">30</span>, fontsize=<span class="string">&#x27;small&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>rotation选项设定x刻度标签倾斜30度。最后，再用set_xlabel为X轴设置一个名称，并用set_title设置一个标题（见图9-9的结果）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">42</span>]: ax.set_title(<span class="string">&#x27;My first matplotlib plot&#x27;</span>)</span><br><span class="line">Out[<span class="number">42</span>]: &lt;matplotlib.text.Text at <span class="number">0x7fb624d055f8</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: ax.set_xlabel(<span class="string">&#x27;Stages&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-741f968323bd818f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-9 用于演示xticks的简单线型图"></p>
<p>Y轴的修改方式与此类似，只需将上述代码中的x替换为y即可。轴的类有集合方法，可以批量设定绘图选项。前面的例子，也可以写为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">props = &#123;</span><br><span class="line">    <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;My first matplotlib plot&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;xlabel&#x27;</span>: <span class="string">&#x27;Stages&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">ax.<span class="built_in">set</span>(**props)</span><br></pre></td></tr></table></figure>
<h2><span id="添加图例">添加图例</span></h2><p>图例（legend）是另一种用于标识图表元素的重要工具。添加图例的方式有多种。最简单的是在添加subplot的时候传入label参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: <span class="keyword">from</span> numpy.random <span class="keyword">import</span> randn</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: fig = plt.figure(); ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: ax.plot(randn(<span class="number">1000</span>).cumsum(), <span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;one&#x27;</span>)</span><br><span class="line">Out[<span class="number">46</span>]: [&lt;matplotlib.lines.Line2D at <span class="number">0x7fb624bdf860</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: ax.plot(randn(<span class="number">1000</span>).cumsum(), <span class="string">&#x27;k--&#x27;</span>, label=<span class="string">&#x27;two&#x27;</span>)</span><br><span class="line">Out[<span class="number">47</span>]: [&lt;matplotlib.lines.Line2D at <span class="number">0x7fb624be90f0</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: ax.plot(randn(<span class="number">1000</span>).cumsum(), <span class="string">&#x27;k.&#x27;</span>, label=<span class="string">&#x27;three&#x27;</span>)</span><br><span class="line">Out[<span class="number">48</span>]: [&lt;matplotlib.lines.Line2D at <span class="number">0x7fb624be9160</span>&gt;]</span><br></pre></td></tr></table></figure>
<p>在此之后，你可以调用ax.legend()或plt.legend()来自动创建图例（结果见图9-10）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: ax.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-651ff89750c0a89b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-10 带有三条线以及图例的简单线型图"></p>
<p>legend方法有几个其它的loc位置参数选项。请查看文档字符串（使用ax.legend?）。</p>
<p>loc告诉matplotlib要将图例放在哪。如果你不是吹毛求疵的话，”best”是不错的选择，因为它会选择最不碍事的位置。要从图例中去除一个或多个元素，不传入label或传入label=’<em>nolegend</em>‘即可。（中文第一版这里把best错写成了beat）</p>
<h2><span id="注解以及在subplot上绘图">注解以及在Subplot上绘图</span></h2><p>除标准的绘图类型，你可能还希望绘制一些子集的注解，可能是文本、箭头或其他图形等。注解和文字可以通过text、arrow和annotate函数进行添加。text可以将文本绘制在图表的指定坐标(x,y)，还可以加上一些自定义格式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.text(x, y, <span class="string">&#x27;Hello world!&#x27;</span>,</span><br><span class="line">        family=<span class="string">&#x27;monospace&#x27;</span>, fontsize=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>注解中可以既含有文本也含有箭头。例如，我们根据最近的标准普尔500指数价格（来自Yahoo!Finance）绘制一张曲线图，并标出2008年到2009年金融危机期间的一些重要日期。你可以在Jupyter notebook的一个小窗中试验这段代码（图9-11是结果）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;examples/spx.csv&#x27;</span>, index_col=<span class="number">0</span>, parse_dates=<span class="literal">True</span>)</span><br><span class="line">spx = data[<span class="string">&#x27;SPX&#x27;</span>]</span><br><span class="line"></span><br><span class="line">spx.plot(ax=ax, style=<span class="string">&#x27;k-&#x27;</span>)</span><br><span class="line"></span><br><span class="line">crisis_data = [</span><br><span class="line">    (datetime(<span class="number">2007</span>, <span class="number">10</span>, <span class="number">11</span>), <span class="string">&#x27;Peak of bull market&#x27;</span>),</span><br><span class="line">    (datetime(<span class="number">2008</span>, <span class="number">3</span>, <span class="number">12</span>), <span class="string">&#x27;Bear Stearns Fails&#x27;</span>),</span><br><span class="line">    (datetime(<span class="number">2008</span>, <span class="number">9</span>, <span class="number">15</span>), <span class="string">&#x27;Lehman Bankruptcy&#x27;</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date, label <span class="keyword">in</span> crisis_data:</span><br><span class="line">    ax.annotate(label, xy=(date, spx.asof(date) + <span class="number">75</span>),</span><br><span class="line">                xytext=(date, spx.asof(date) + <span class="number">225</span>),</span><br><span class="line">                arrowprops=<span class="built_in">dict</span>(facecolor=<span class="string">&#x27;black&#x27;</span>, headwidth=<span class="number">4</span>, width=<span class="number">2</span>,</span><br><span class="line">                                headlength=<span class="number">4</span>),</span><br><span class="line">                horizontalalignment=<span class="string">&#x27;left&#x27;</span>, verticalalignment=<span class="string">&#x27;top&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Zoom in on 2007-2010</span></span><br><span class="line">ax.set_xlim([<span class="string">&#x27;1/1/2007&#x27;</span>, <span class="string">&#x27;1/1/2011&#x27;</span>])</span><br><span class="line">ax.set_ylim([<span class="number">600</span>, <span class="number">1800</span>])</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&#x27;Important dates in the 2008-2009 financial crisis&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-3127eaa51f5e4c2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-11 2008-2009年金融危机期间的重要日期"></p>
<p>这张图中有几个重要的点要强调：ax.annotate方法可以在指定的x和y坐标轴绘制标签。我们使用set_xlim和set_ylim人工设定起始和结束边界，而不使用matplotlib的默认方法。最后，用ax.set_title添加图标标题。</p>
<p>更多有关注解的示例，请访问matplotlib的在线示例库。</p>
<p>图形的绘制要麻烦一些。matplotlib有一些表示常见图形的对象。这些对象被称为块（patch）。其中有些（如Rectangle和Circle），可以在matplotlib.pyplot中找到，但完整集合位于matplotlib.patches。</p>
<p>要在图表中添加一个图形，你需要创建一个块对象shp，然后通过ax.add_patch(shp)将其添加到subplot中（如图9-12所示）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">rect = plt.Rectangle((<span class="number">0.2</span>, <span class="number">0.75</span>), <span class="number">0.4</span>, <span class="number">0.15</span>, color=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">circ = plt.Circle((<span class="number">0.7</span>, <span class="number">0.2</span>), <span class="number">0.15</span>, color=<span class="string">&#x27;b&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">pgon = plt.Polygon([[<span class="number">0.15</span>, <span class="number">0.15</span>], [<span class="number">0.35</span>, <span class="number">0.4</span>], [<span class="number">0.2</span>, <span class="number">0.6</span>]],</span><br><span class="line">                   color=<span class="string">&#x27;g&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">ax.add_patch(rect)</span><br><span class="line">ax.add_patch(circ)</span><br><span class="line">ax.add_patch(pgon)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-1f8a3d7a3a02d7d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-12 由三个块图形组成的图"></p>
<p>如果查看许多常见图表对象的具体实现代码，你就会发现它们其实就是由块patch组装而成的。</p>
<h2><span id="将图表保存到文件">将图表保存到文件</span></h2><p>利用plt.savefig可以将当前图表保存到文件。该方法相当于Figure对象的实例方法savefig。例如，要将图表保存为SVG文件，你只需输入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.savefig(<span class="string">&#x27;figpath.svg&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>文件类型是通过文件扩展名推断出来的。因此，如果你使用的是.pdf，就会得到一个PDF文件。我在发布图片时最常用到两个重要的选项是dpi（控制“每英寸点数”分辨率）和bbox_inches（可以剪除当前图表周围的空白部分）。要得到一张带有最小白边且分辨率为400DPI的PNG图片，你可以：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.savefig(<span class="string">&#x27;figpath.png&#x27;</span>, dpi=<span class="number">400</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>savefig并非一定要写入磁盘，也可以写入任何文件型的对象，比如BytesIO：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line">buffer = BytesIO()</span><br><span class="line">plt.savefig(buffer)</span><br><span class="line">plot_data = buffer.getvalue()</span><br></pre></td></tr></table></figure>
<p>表9-2列出了savefig的其它选项。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-4bee796bf7262423.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-2 Figure.savefig的选项"></p>
<h2><span id="matplotlib配置">matplotlib配置</span></h2><p>matplotlib自带一些配色方案，以及为生成出版质量的图片而设定的默认配置信息。幸运的是，几乎所有默认行为都能通过一组全局参数进行自定义，它们可以管理图像大小、subplot边距、配色方案、字体大小、网格类型等。一种Python编程方式配置系统的方法是使用rc方法。例如，要将全局的图像默认大小设置为10×10，你可以执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.rc(<span class="string">&#x27;figure&#x27;</span>, figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>rc的第一个参数是希望自定义的对象，如’figure’、’axes’、’xtick’、’ytick’、’grid’、’legend’等。其后可以跟上一系列的关键字参数。一个简单的办法是将这些选项写成一个字典：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">font_options = &#123;<span class="string">&#x27;family&#x27;</span> : <span class="string">&#x27;monospace&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;weight&#x27;</span> : <span class="string">&#x27;bold&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;size&#x27;</span>   : <span class="string">&#x27;small&#x27;</span>&#125;</span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, **font_options)</span><br></pre></td></tr></table></figure>
<p>要了解全部的自定义选项，请查阅matplotlib的配置文件matplotlibrc（位于matplotlib/mpl-data目录中）。如果对该文件进行了自定义，并将其放在你自己的.matplotlibrc目录中，则每次使用matplotlib时就会加载该文件。</p>
<p>下一节，我们会看到，seaborn包有若干内置的绘图主题或类型，它们使用了matplotlib的内部配置。</p>
<h1><span id="92-使用pandas和seaborn绘图">9.2 使用pandas和seaborn绘图</span></h1><p>matplotlib实际上是一种比较低级的工具。要绘制一张图表，你组装一些基本组件就行：数据展示（即图表类型：线型图、柱状图、盒形图、散布图、等值线图等）、图例、标题、刻度标签以及其他注解型信息。</p>
<p>在pandas中，我们有多列数据，还有行和列标签。pandas自身就有内置的方法，用于简化从DataFrame和Series绘制图形。另一个库seaborn（<a href="https://seaborn.pydata.org/），由Michael">https://seaborn.pydata.org/），由Michael</a> Waskom创建的静态图形库。Seaborn简化了许多常见可视类型的创建。</p>
<blockquote>
<p>提示：引入seaborn会修改matplotlib默认的颜色方案和绘图类型，以提高可读性和美观度。即使你不使用seaborn API，你可能也会引入seaborn，作为提高美观度和绘制常见matplotlib图形的简化方法。</p>
</blockquote>
<h2><span id="线型图">线型图</span></h2><p>Series和DataFrame都有一个用于生成各类图表的plot方法。默认情况下，它们所生成的是线型图（如图9-13所示）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: s = pd.Series(np.random.randn(<span class="number">10</span>).cumsum(), index=np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: s.plot()</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-f28e5ab2ac94c7a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-13 简单的Series图表示例"></p>
<p>该Series对象的索引会被传给matplotlib，并用以绘制X轴。可以通过use_index=False禁用该功能。X轴的刻度和界限可以通过xticks和xlim选项进行调节，Y轴就用yticks和ylim。plot参数的完整列表请参见表9-3。我只会讲解其中几个，剩下的就留给读者自己去研究了。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-6d9fbf863c09370a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-44e50562aeb5eb49.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-3 Series.plot方法的参数"></p>
<p>pandas的大部分绘图方法都有一个可选的ax参数，它可以是一个matplotlib的subplot对象。这使你能够在网格布局中更为灵活地处理subplot的位置。</p>
<p>DataFrame的plot方法会在一个subplot中为各列绘制一条线，并自动创建图例（如图9-14所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">62</span>]: df = pd.DataFrame(np.random.randn(<span class="number">10</span>, <span class="number">4</span>).cumsum(<span class="number">0</span>),</span><br><span class="line">   ....:                   columns=[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>],</span><br><span class="line">   ....:                   index=np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: df.plot()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-a1234d5e5ee41a40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-14 简单的DataFrame绘图"></p>
<p>plot属性包含一批不同绘图类型的方法。例如，df.plot()等价于df.plot.line()。后面会学习这些方法。</p>
<blockquote>
<p>笔记：plot的其他关键字参数会被传给相应的matplotlib绘图函数，所以要更深入地自定义图表，就必须学习更多有关matplotlib API的知识。</p>
</blockquote>
<p>DataFrame还有一些用于对列进行灵活处理的选项，例如，是要将所有列都绘制到一个subplot中还是创建各自的subplot。详细信息请参见表9-4。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-96651ecaa90f1c68.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-4 专用于DataFrame的plot参数"></p>
<blockquote>
<p>注意： 有关时间序列的绘图，请见第11章。</p>
</blockquote>
<h2><span id="柱状图">柱状图</span></h2><p>plot.bar()和plot.barh()分别绘制水平和垂直的柱状图。这时，Series和DataFrame的索引将会被用作X（bar）或Y（barh）刻度（如图9-15所示）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: data = pd.Series(np.random.rand(<span class="number">16</span>), index=<span class="built_in">list</span>(<span class="string">&#x27;abcdefghijklmnop&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: data.plot.bar(ax=axes[<span class="number">0</span>], color=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">Out[<span class="number">66</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x7fb62493d470</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: data.plot.barh(ax=axes[<span class="number">1</span>], color=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-cd54c7ccfa3f0687.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-15 水平和垂直的柱状图"></p>
<p>color=’k’和alpha=0.7设定了图形的颜色为黑色，并使用部分的填充透明度。对于DataFrame，柱状图会将每一行的值分为一组，并排显示，如图9-16所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: df = pd.DataFrame(np.random.rand(<span class="number">6</span>, <span class="number">4</span>),</span><br><span class="line">   ....:                   index=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>, <span class="string">&#x27;five&#x27;</span>, <span class="string">&#x27;six&#x27;</span>],</span><br><span class="line">   ....:                   columns=pd.Index([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>], name=<span class="string">&#x27;Genus&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: df</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line">Genus         A         B         C         D</span><br><span class="line">one    <span class="number">0.370670</span>  <span class="number">0.602792</span>  <span class="number">0.229159</span>  <span class="number">0.486744</span></span><br><span class="line">two    <span class="number">0.420082</span>  <span class="number">0.571653</span>  <span class="number">0.049024</span>  <span class="number">0.880592</span></span><br><span class="line">three  <span class="number">0.814568</span>  <span class="number">0.277160</span>  <span class="number">0.880316</span>  <span class="number">0.431326</span></span><br><span class="line">four   <span class="number">0.374020</span>  <span class="number">0.899420</span>  <span class="number">0.460304</span>  <span class="number">0.100843</span></span><br><span class="line">five   <span class="number">0.433270</span>  <span class="number">0.125107</span>  <span class="number">0.494675</span>  <span class="number">0.961825</span></span><br><span class="line">six    <span class="number">0.601648</span>  <span class="number">0.478576</span>  <span class="number">0.205690</span>  <span class="number">0.560547</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: df.plot.bar()</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-bfc141acb37d99b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-16 DataFrame的柱状图"></p>
<p>注意，DataFrame各列的名称”Genus”被用作了图例的标题。</p>
<p>设置stacked=True即可为DataFrame生成堆积柱状图，这样每行的值就会被堆积在一起（如图9-17所示）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: df.plot.barh(stacked=<span class="literal">True</span>, alpha=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c19e4246eb897978.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-17 DataFrame的堆积柱状图"></p>
<blockquote>
<p>笔记：柱状图有一个非常不错的用法：利用value_counts图形化显示Series中各值的出现频率，比如s.value_counts().plot.bar()。</p>
</blockquote>
<p>再以本书前面用过的那个有关小费的数据集为例，假设我们想要做一张堆积柱状图以展示每天各种聚会规模的数据点的百分比。我用read_csv将数据加载进来，然后根据日期和聚会规模创建一张交叉表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: tips = pd.read_csv(<span class="string">&#x27;examples/tips.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: party_counts = pd.crosstab(tips[<span class="string">&#x27;day&#x27;</span>], tips[<span class="string">&#x27;size&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: party_counts</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">size  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span></span><br><span class="line">day                      </span><br><span class="line">Fri   <span class="number">1</span>  <span class="number">16</span>   <span class="number">1</span>   <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line">Sat   <span class="number">2</span>  <span class="number">53</span>  <span class="number">18</span>  <span class="number">13</span>  <span class="number">1</span>  <span class="number">0</span></span><br><span class="line">Sun   <span class="number">0</span>  <span class="number">39</span>  <span class="number">15</span>  <span class="number">18</span>  <span class="number">3</span>  <span class="number">1</span></span><br><span class="line">Thur  <span class="number">1</span>  <span class="number">48</span>   <span class="number">4</span>   <span class="number">5</span>  <span class="number">1</span>  <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Not many 1- and 6-person parties</span></span><br><span class="line">In [<span class="number">78</span>]: party_counts = party_counts.loc[:, <span class="number">2</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p>然后进行规格化，使得各行的和为1，并生成图表（如图9-18所示）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Normalize to sum to 1</span></span><br><span class="line">In [<span class="number">79</span>]: party_pcts = party_counts.div(party_counts.<span class="built_in">sum</span>(<span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: party_pcts</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line">size         <span class="number">2</span>         <span class="number">3</span>         <span class="number">4</span>         <span class="number">5</span></span><br><span class="line">day                                         </span><br><span class="line">Fri   <span class="number">0.888889</span>  <span class="number">0.055556</span>  <span class="number">0.055556</span>  <span class="number">0.000000</span></span><br><span class="line">Sat   <span class="number">0.623529</span>  <span class="number">0.211765</span>  <span class="number">0.152941</span>  <span class="number">0.011765</span></span><br><span class="line">Sun   <span class="number">0.520000</span>  <span class="number">0.200000</span>  <span class="number">0.240000</span>  <span class="number">0.040000</span></span><br><span class="line">Thur  <span class="number">0.827586</span>  <span class="number">0.068966</span>  <span class="number">0.086207</span>  <span class="number">0.017241</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: party_pcts.plot.bar()</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-2918f67936823834.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-18 每天各种聚会规模的比例"></p>
<p>于是，通过该数据集就可以看出，聚会规模在周末会变大。</p>
<p>对于在绘制一个图形之前，需要进行合计的数据，使用seaborn可以减少工作量。用seaborn来看每天的小费比例（图9-19是结果）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">83</span>]: <span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: tips[<span class="string">&#x27;tip_pct&#x27;</span>] = tips[<span class="string">&#x27;tip&#x27;</span>] / (tips[<span class="string">&#x27;total_bill&#x27;</span>] - tips[<span class="string">&#x27;tip&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: tips.head()</span><br><span class="line">Out[<span class="number">85</span>]: </span><br><span class="line">   total_bill   tip smoker  day    time  size   tip_pct</span><br><span class="line"><span class="number">0</span>       <span class="number">16.99</span>  <span class="number">1.01</span>     No  Sun  Dinner     <span class="number">2</span>  <span class="number">0.063204</span></span><br><span class="line"><span class="number">1</span>       <span class="number">10.34</span>  <span class="number">1.66</span>     No  Sun  Dinner     <span class="number">3</span>  <span class="number">0.191244</span></span><br><span class="line"><span class="number">2</span>       <span class="number">21.01</span>  <span class="number">3.50</span>     No  Sun  Dinner     <span class="number">3</span>  <span class="number">0.199886</span></span><br><span class="line"><span class="number">3</span>       <span class="number">23.68</span>  <span class="number">3.31</span>     No  Sun  Dinner     <span class="number">2</span>  <span class="number">0.162494</span></span><br><span class="line"><span class="number">4</span>       <span class="number">24.59</span>  <span class="number">3.61</span>     No  Sun  Dinner     <span class="number">4</span>  <span class="number">0.172069</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: sns.barplot(x=<span class="string">&#x27;tip_pct&#x27;</span>, y=<span class="string">&#x27;day&#x27;</span>, data=tips, orient=<span class="string">&#x27;h&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c33e8b3add99904b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-19 小费的每日比例，带有误差条"></p>
<p>seaborn的绘制函数使用data参数，它可能是pandas的DataFrame。其它的参数是关于列的名字。因为一天的每个值有多次观察，柱状图的值是tip_pct的平均值。绘制在柱状图上的黑线代表95%置信区间（可以通过可选参数配置）。</p>
<p>seaborn.barplot有颜色选项，使我们能够通过一个额外的值设置（见图9-20）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">88</span>]: sns.barplot(x=<span class="string">&#x27;tip_pct&#x27;</span>, y=<span class="string">&#x27;day&#x27;</span>, hue=<span class="string">&#x27;time&#x27;</span>, data=tips, orient=<span class="string">&#x27;h&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-06abe2f070222115.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-20 根据天和时间的小费比例"></p>
<p>注意，seaborn已经自动修改了图形的美观度：默认调色板，图形背景和网格线的颜色。你可以用seaborn.set在不同的图形外观之间切换：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">90</span>]: sns.<span class="built_in">set</span>(style=<span class="string">&quot;whitegrid&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2><span id="直方图和密度图">直方图和密度图</span></h2><p>直方图（histogram）是一种可以对值频率进行离散化显示的柱状图。数据点被拆分到离散的、间隔均匀的面元中，绘制的是各面元中数据点的数量。再以前面那个小费数据为例，通过在Series使用plot.hist方法，我们可以生成一张“小费占消费总额百分比”的直方图（如图9-21所示）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">92</span>]: tips[<span class="string">&#x27;tip_pct&#x27;</span>].plot.hist(bins=<span class="number">50</span>)</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-255279376f7649a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-21 小费百分比的直方图"></p>
<p>与此相关的一种图表类型是密度图，它是通过计算“可能会产生观测数据的连续概率分布的估计”而产生的。一般的过程是将该分布近似为一组核（即诸如正态分布之类的较为简单的分布）。因此，密度图也被称作KDE（Kernel Density Estimate，核密度估计）图。使用plot.kde和标准混合正态分布估计即可生成一张密度图（见图9-22）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: tips[<span class="string">&#x27;tip_pct&#x27;</span>].plot.density()</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-ee929d033159516a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-22  小费百分比的密度图"></p>
<p>seaborn的distplot方法绘制直方图和密度图更加简单，还可以同时画出直方图和连续密度估计图。作为例子，考虑一个双峰分布，由两个不同的标准正态分布组成（见图9-23）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: comp1 = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size=<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: comp2 = np.random.normal(<span class="number">10</span>, <span class="number">2</span>, size=<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: values = pd.Series(np.concatenate([comp1, comp2]))</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: sns.distplot(values, bins=<span class="number">100</span>, color=<span class="string">&#x27;k&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-975f04d750c4efe2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-23 标准混合密度估计的标准直方图"></p>
<h2><span id="散布图或点图">散布图或点图</span></h2><p>点图或散布图是观察两个一维数据序列之间的关系的有效手段。在下面这个例子中，我加载了来自statsmodels项目的macrodata数据集，选择了几个变量，然后计算对数差：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">100</span>]: macro = pd.read_csv(<span class="string">&#x27;examples/macrodata.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">101</span>]: data = macro[[<span class="string">&#x27;cpi&#x27;</span>, <span class="string">&#x27;m1&#x27;</span>, <span class="string">&#x27;tbilrate&#x27;</span>, <span class="string">&#x27;unemp&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: trans_data = np.log(data).diff().dropna()</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: trans_data[-<span class="number">5</span>:]</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">          cpi        m1  tbilrate     unemp</span><br><span class="line"><span class="number">198</span> -<span class="number">0.007904</span>  <span class="number">0.045361</span> -<span class="number">0.396881</span>  <span class="number">0.105361</span></span><br><span class="line"><span class="number">199</span> -<span class="number">0.021979</span>  <span class="number">0.066753</span> -<span class="number">2.277267</span>  <span class="number">0.139762</span></span><br><span class="line"><span class="number">200</span>  <span class="number">0.002340</span>  <span class="number">0.010286</span>  <span class="number">0.606136</span>  <span class="number">0.160343</span></span><br><span class="line"><span class="number">201</span>  <span class="number">0.008419</span>  <span class="number">0.037461</span> -<span class="number">0.200671</span>  <span class="number">0.127339</span></span><br><span class="line"><span class="number">202</span>  <span class="number">0.008894</span>  <span class="number">0.012202</span> -<span class="number">0.405465</span>  <span class="number">0.042560</span></span><br></pre></td></tr></table></figure>
<p>然后可以使用seaborn的regplot方法，它可以做一个散布图，并加上一条线性回归的线（见图9-24）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">105</span>]: sns.regplot(<span class="string">&#x27;m1&#x27;</span>, <span class="string">&#x27;unemp&#x27;</span>, data=trans_data)</span><br><span class="line">Out[<span class="number">105</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x7fb613720be0</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: plt.title(<span class="string">&#x27;Changes in log %s versus log %s&#x27;</span> % (<span class="string">&#x27;m1&#x27;</span>, <span class="string">&#x27;unemp&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-2133d20739478a80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-24 seaborn的回归/散布图"></p>
<p>在探索式数据分析工作中，同时观察一组变量的散布图是很有意义的，这也被称为散布图矩阵（scatter plot matrix）。纯手工创建这样的图表很费工夫，所以seaborn提供了一个便捷的pairplot函数，它支持在对角线上放置每个变量的直方图或密度估计（见图9-25）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">107</span>]: sns.pairplot(trans_data, diag_kind=<span class="string">&#x27;kde&#x27;</span>, plot_kws=&#123;<span class="string">&#x27;alpha&#x27;</span>: <span class="number">0.2</span>&#125;)</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-20aa530a44e06f61.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-25 statsmodels macro data的散布图矩阵"></p>
<p>你可能注意到了plot_kws参数。它可以让我们传递配置选项到非对角线元素上的图形使用。对于更详细的配置选项，可以查阅seaborn.pairplot文档字符串。</p>
<h2><span id="分面网格facet-grid和类型数据">分面网格（facet grid）和类型数据</span></h2><p>要是数据集有额外的分组维度呢？有多个分类变量的数据可视化的一种方法是使用小面网格。seaborn有一个有用的内置函数factorplot，可以简化制作多种分面图（见图9-26）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: sns.factorplot(x=<span class="string">&#x27;day&#x27;</span>, y=<span class="string">&#x27;tip_pct&#x27;</span>, hue=<span class="string">&#x27;time&#x27;</span>, col=<span class="string">&#x27;smoker&#x27;</span>,</span><br><span class="line">  .....:                kind=<span class="string">&#x27;bar&#x27;</span>, data=tips[tips.tip_pct &lt; <span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-737ba19a0cbdd46f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-26 按照天/时间/吸烟者的小费百分比"></p>
<p>除了在分面中用不同的颜色按时间分组，我们还可以通过给每个时间值添加一行来扩展分面网格：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">109</span>]: sns.factorplot(x=<span class="string">&#x27;day&#x27;</span>, y=<span class="string">&#x27;tip_pct&#x27;</span>, row=<span class="string">&#x27;time&#x27;</span>,</span><br><span class="line">   .....:                col=<span class="string">&#x27;smoker&#x27;</span>,</span><br><span class="line">   .....:                kind=<span class="string">&#x27;bar&#x27;</span>, data=tips[tips.tip_pct &lt; <span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-4e52192441c609f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-27 按天的tip_pct，通过time/smoker分面"></p>
<p>factorplot支持其它的绘图类型，你可能会用到。例如，盒图（它可以显示中位数，四分位数，和异常值）就是一个有用的可视化类型（见图9-28）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">110</span>]: sns.factorplot(x=<span class="string">&#x27;tip_pct&#x27;</span>, y=<span class="string">&#x27;day&#x27;</span>, kind=<span class="string">&#x27;box&#x27;</span>,</span><br><span class="line">   .....:                data=tips[tips.tip_pct &lt; <span class="number">0.5</span>])</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-356fb27a7c658920.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-28 按天的tip_pct的盒图"></p>
<p>使用更通用的seaborn.FacetGrid类，你可以创建自己的分面网格。请查阅seaborn的文档（<a href="https://seaborn.pydata.org/）。">https://seaborn.pydata.org/）。</a></p>
<h1><span id="93-其它的python可视化工具">9.3 其它的Python可视化工具</span></h1><p>与其它开源库类似，Python创建图形的方式非常多（根本罗列不完）。自从2010年，许多开发工作都集中在创建交互式图形以便在Web上发布。利用工具如Boken（<a href="https://bokeh.pydata.org/en/latest/）和Plotly（https://github.com/plotly/plotly.py），现在可以创建动态交互图形，用于网页浏览器。">https://bokeh.pydata.org/en/latest/）和Plotly（https://github.com/plotly/plotly.py），现在可以创建动态交互图形，用于网页浏览器。</a></p>
<p>对于创建用于打印或网页的静态图形，我建议默认使用matplotlib和附加的库，比如pandas和seaborn。对于其它数据可视化要求，学习其它的可用工具可能是有用的。我鼓励你探索绘图的生态系统，因为它将持续发展。</p>
<h1><span id="94-总结">9.4 总结</span></h1><p>本章的目的是熟悉一些基本的数据可视化操作，使用pandas，matplotlib，和seaborn。如果视觉显示数据分析的结果对你的工作很重要，我鼓励你寻求更多的资源来了解更高效的数据可视化。这是一个活跃的研究领域，你可以通过在线和纸质的形式学习许多优秀的资源。</p>
<p>下一章，我们将重点放在pandas的数据聚合和分组操作上。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-8.数据整合</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-8-%E6%95%B0%E6%8D%AE%E6%95%B4%E5%90%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在许多应用中，数据可能分散在许多文件或数据库中，存储的形式也不利于分析。本章关注可以聚合、合并、重塑数据的方法。</p>
<p>首先，我会介绍pandas的层次化索引，它广泛用于以上操作。然后，我深入介绍了一些特殊的数据操作。在第14章，你可以看到这些工具的多种应用。</p>
<span id="more"></span>
<h1><span id="81-层次化索引">8.1 层次化索引</span></h1><p>层次化索引（hierarchical indexing）是pandas的一项重要功能，它使你能在一个轴上拥有多个（两个以上）索引级别。抽象点说，它使你能以低维度形式处理高维度数据。我们先来看一个简单的例子：创建一个Series，并用一个由列表或数组组成的列表作为索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">9</span>]: data = pd.Series(np.random.randn(<span class="number">9</span>),</span><br><span class="line">   ...:                  index=[[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;d&#x27;</span>],</span><br><span class="line">   ...:                         [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: data</span><br><span class="line">Out[<span class="number">10</span>]: </span><br><span class="line">a  <span class="number">1</span>   -<span class="number">0.204708</span></span><br><span class="line">   <span class="number">2</span>    <span class="number">0.478943</span></span><br><span class="line">   <span class="number">3</span>   -<span class="number">0.519439</span></span><br><span class="line">b  <span class="number">1</span>   -<span class="number">0.555730</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">1.965781</span></span><br><span class="line">c  <span class="number">1</span>    <span class="number">1.393406</span></span><br><span class="line">   <span class="number">2</span>    <span class="number">0.092908</span></span><br><span class="line">d  <span class="number">2</span>    <span class="number">0.281746</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">0.769023</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>看到的结果是经过美化的带有MultiIndex索引的Series的格式。索引之间的“间隔”表示“直接使用上面的标签”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">11</span>]: data.index</span><br><span class="line">Out[<span class="number">11</span>]: </span><br><span class="line">MultiIndex(levels=[[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]],</span><br><span class="line">           labels=[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure></p>
<p>对于一个层次化索引的对象，可以使用所谓的部分索引，使用它选取数据子集的操作更简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: data[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">Out[<span class="number">12</span>]: </span><br><span class="line"><span class="number">1</span>   -<span class="number">0.555730</span></span><br><span class="line"><span class="number">3</span>    <span class="number">1.965781</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: data[<span class="string">&#x27;b&#x27;</span>:<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">Out[<span class="number">13</span>]: </span><br><span class="line">b  <span class="number">1</span>   -<span class="number">0.555730</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">1.965781</span></span><br><span class="line">c  <span class="number">1</span>    <span class="number">1.393406</span></span><br><span class="line">   <span class="number">2</span>    <span class="number">0.092908</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: data.loc[[<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;d&#x27;</span>]]</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">b  <span class="number">1</span>   -<span class="number">0.555730</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">1.965781</span></span><br><span class="line">d  <span class="number">2</span>    <span class="number">0.281746</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">0.769023</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>有时甚至还可以在“内层”中进行选取：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: data.loc[:, <span class="number">2</span>]</span><br><span class="line">Out[<span class="number">15</span>]: </span><br><span class="line">a    <span class="number">0.478943</span></span><br><span class="line">c    <span class="number">0.092908</span></span><br><span class="line">d    <span class="number">0.281746</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>层次化索引在数据重塑和基于分组的操作（如透视表生成）中扮演着重要的角色。例如，可以通过unstack方法将这段数据重新安排到一个DataFrame中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: data.unstack()</span><br><span class="line">Out[<span class="number">16</span>]: </span><br><span class="line">          <span class="number">1</span>         <span class="number">2</span>         <span class="number">3</span></span><br><span class="line">a -<span class="number">0.204708</span>  <span class="number">0.478943</span> -<span class="number">0.519439</span></span><br><span class="line">b -<span class="number">0.555730</span>       NaN  <span class="number">1.965781</span></span><br><span class="line">c  <span class="number">1.393406</span>  <span class="number">0.092908</span>       NaN</span><br><span class="line">d       NaN  <span class="number">0.281746</span>  <span class="number">0.769023</span></span><br></pre></td></tr></table></figure></p>
<p>unstack的逆运算是stack：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: data.unstack().stack()</span><br><span class="line">Out[<span class="number">17</span>]: </span><br><span class="line">a  <span class="number">1</span>   -<span class="number">0.204708</span></span><br><span class="line">   <span class="number">2</span>    <span class="number">0.478943</span></span><br><span class="line">   <span class="number">3</span>   -<span class="number">0.519439</span></span><br><span class="line">b  <span class="number">1</span>   -<span class="number">0.555730</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">1.965781</span></span><br><span class="line">c  <span class="number">1</span>    <span class="number">1.393406</span></span><br><span class="line">   <span class="number">2</span>    <span class="number">0.092908</span></span><br><span class="line">d  <span class="number">2</span>    <span class="number">0.281746</span></span><br><span class="line">   <span class="number">3</span>    <span class="number">0.769023</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>stack和unstack将在本章后面详细讲解。</p>
<p>对于一个DataFrame，每条轴都可以有分层索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: frame = pd.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">4</span>, <span class="number">3</span>)),</span><br><span class="line">   ....:                      index=[[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>]],</span><br><span class="line">   ....:                      columns=[[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Colorado&#x27;</span>],</span><br><span class="line">   ....:                               [<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: frame</span><br><span class="line">Out[<span class="number">19</span>]: </span><br><span class="line">     Ohio     Colorado</span><br><span class="line">    Green Red    Green</span><br><span class="line">a <span class="number">1</span>     <span class="number">0</span>   <span class="number">1</span>        <span class="number">2</span></span><br><span class="line">  <span class="number">2</span>     <span class="number">3</span>   <span class="number">4</span>        <span class="number">5</span></span><br><span class="line">b <span class="number">1</span>     <span class="number">6</span>   <span class="number">7</span>        <span class="number">8</span></span><br><span class="line">  <span class="number">2</span>     <span class="number">9</span>  <span class="number">10</span>       <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<p>各层都可以有名字（可以是字符串，也可以是别的Python对象）。如果指定了名称，它们就会显示在控制台输出中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">20</span>]: frame.index.names = [<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: frame.columns.names = [<span class="string">&#x27;state&#x27;</span>, <span class="string">&#x27;color&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: frame</span><br><span class="line">Out[<span class="number">22</span>]: </span><br><span class="line">state      Ohio     Colorado</span><br><span class="line">color     Green Red    Green</span><br><span class="line">key1 key2                   </span><br><span class="line">a    <span class="number">1</span>        <span class="number">0</span>   <span class="number">1</span>        <span class="number">2</span></span><br><span class="line">     <span class="number">2</span>        <span class="number">3</span>   <span class="number">4</span>        <span class="number">5</span></span><br><span class="line">b    <span class="number">1</span>        <span class="number">6</span>   <span class="number">7</span>        <span class="number">8</span></span><br><span class="line">     <span class="number">2</span>        <span class="number">9</span>  <span class="number">10</span>       <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：小心区分索引名state、color与行标签。</p>
</blockquote>
<p>有了部分列索引，因此可以轻松选取列分组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">23</span>]: frame[<span class="string">&#x27;Ohio&#x27;</span>]</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line">color      Green  Red</span><br><span class="line">key1 key2            </span><br><span class="line">a    <span class="number">1</span>         <span class="number">0</span>    <span class="number">1</span></span><br><span class="line">     <span class="number">2</span>         <span class="number">3</span>    <span class="number">4</span></span><br><span class="line">b    <span class="number">1</span>         <span class="number">6</span>    <span class="number">7</span></span><br><span class="line">     <span class="number">2</span>         <span class="number">9</span>   <span class="number">10</span></span><br></pre></td></tr></table></figure></p>
<p>可以单独创建MultiIndex然后复用。上面那个DataFrame中的（带有分级名称）列可以这样创建：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MultiIndex.from_arrays([[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Colorado&#x27;</span>], [<span class="string">&#x27;Green&#x27;</span>, <span class="string">&#x27;Red&#x27;</span>, <span class="string">&#x27;Green&#x27;</span>]],</span><br><span class="line">                       names=[<span class="string">&#x27;state&#x27;</span>, <span class="string">&#x27;color&#x27;</span>])</span><br></pre></td></tr></table></figure></p>
<h2><span id="重排与分级排序">重排与分级排序</span></h2><p>有时，你需要重新调整某条轴上各级别的顺序，或根据指定级别上的值对数据进行排序。swaplevel接受两个级别编号或名称，并返回一个互换了级别的新对象（但数据不会发生变化）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: frame.swaplevel(<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>)</span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">state      Ohio     Colorado</span><br><span class="line">color     Green Red    Green</span><br><span class="line">key2 key1                   </span><br><span class="line"><span class="number">1</span>    a        <span class="number">0</span>   <span class="number">1</span>        <span class="number">2</span></span><br><span class="line"><span class="number">2</span>    a        <span class="number">3</span>   <span class="number">4</span>        <span class="number">5</span></span><br><span class="line"><span class="number">1</span>    b        <span class="number">6</span>   <span class="number">7</span>        <span class="number">8</span></span><br><span class="line"><span class="number">2</span>    b        <span class="number">9</span>  <span class="number">10</span>       <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<p>而sort_index则根据单个级别中的值对数据进行排序。交换级别时，常常也会用到sort_index，这样最终结果就是按照指定顺序进行字母排序了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">25</span>]: frame.sort_index(level=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">25</span>]: </span><br><span class="line">state      Ohio     Colorado</span><br><span class="line">color     Green Red    Green</span><br><span class="line">key1 key2                   </span><br><span class="line">a    <span class="number">1</span>        <span class="number">0</span>   <span class="number">1</span>        <span class="number">2</span></span><br><span class="line">b    <span class="number">1</span>        <span class="number">6</span>   <span class="number">7</span>        <span class="number">8</span></span><br><span class="line">a    <span class="number">2</span>        <span class="number">3</span>   <span class="number">4</span>        <span class="number">5</span></span><br><span class="line">b    <span class="number">2</span>        <span class="number">9</span>  <span class="number">10</span>       <span class="number">11</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: frame.swaplevel(<span class="number">0</span>, <span class="number">1</span>).sort_index(level=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">26</span>]: </span><br><span class="line">state      Ohio     Colorado</span><br><span class="line">color     Green Red    Green</span><br><span class="line">key2 key1                   </span><br><span class="line"><span class="number">1</span>    a        <span class="number">0</span>   <span class="number">1</span>        <span class="number">2</span></span><br><span class="line">     b        <span class="number">6</span>   <span class="number">7</span>        <span class="number">8</span></span><br><span class="line"><span class="number">2</span>    a        <span class="number">3</span>   <span class="number">4</span>        <span class="number">5</span></span><br><span class="line">     b        <span class="number">9</span>  <span class="number">10</span>       <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="根据级别汇总统计">根据级别汇总统计</span></h2><p>许多对DataFrame和Series的描述和汇总统计都有一个level选项，它用于指定在某条轴上求和的级别。再以上面那个DataFrame为例，我们可以根据行或列上的级别来进行求和：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: frame.<span class="built_in">sum</span>(level=<span class="string">&#x27;key2&#x27;</span>)</span><br><span class="line">Out[<span class="number">27</span>]: </span><br><span class="line">state  Ohio     Colorado</span><br><span class="line">color Green Red    Green</span><br><span class="line">key2                    </span><br><span class="line"><span class="number">1</span>         <span class="number">6</span>   <span class="number">8</span>       <span class="number">10</span></span><br><span class="line"><span class="number">2</span>        <span class="number">12</span>  <span class="number">14</span>       <span class="number">16</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: frame.<span class="built_in">sum</span>(level=<span class="string">&#x27;color&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">color      Green  Red</span><br><span class="line">key1 key2            </span><br><span class="line">a    <span class="number">1</span>         <span class="number">2</span>    <span class="number">1</span></span><br><span class="line">     <span class="number">2</span>         <span class="number">8</span>    <span class="number">4</span></span><br><span class="line">b    <span class="number">1</span>        <span class="number">14</span>    <span class="number">7</span></span><br><span class="line">     <span class="number">2</span>        <span class="number">20</span>   <span class="number">10</span></span><br></pre></td></tr></table></figure></p>
<p>这其实是利用了pandas的groupby功能，本书稍后将对其进行详细讲解。</p>
<h2><span id="使用dataframe的列进行索引">使用DataFrame的列进行索引</span></h2><p>人们经常想要将DataFrame的一个或多个列当做行索引来用，或者可能希望将行索引变成DataFrame的列。以下面这个DataFrame为例：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: frame = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="built_in">range</span>(<span class="number">7</span>), <span class="string">&#x27;b&#x27;</span>: <span class="built_in">range</span>(<span class="number">7</span>, <span class="number">0</span>, -<span class="number">1</span>),</span><br><span class="line">   ....:                       <span class="string">&#x27;c&#x27;</span>: [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;two&#x27;</span>,</span><br><span class="line">   ....:                             <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;two&#x27;</span>],</span><br><span class="line">   ....:                       <span class="string">&#x27;d&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: frame</span><br><span class="line">Out[<span class="number">30</span>]: </span><br><span class="line">   a  b    c  d</span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">7</span>  one  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1</span>  <span class="number">6</span>  one  <span class="number">1</span></span><br><span class="line"><span class="number">2</span>  <span class="number">2</span>  <span class="number">5</span>  one  <span class="number">2</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>  <span class="number">4</span>  two  <span class="number">0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">4</span>  <span class="number">3</span>  two  <span class="number">1</span></span><br><span class="line"><span class="number">5</span>  <span class="number">5</span>  <span class="number">2</span>  two  <span class="number">2</span></span><br><span class="line"><span class="number">6</span>  <span class="number">6</span>  <span class="number">1</span>  two  <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<p>DataFrame的set_index函数会将其一个或多个列转换为行索引，并创建一个新的DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">31</span>]: frame2 = frame.set_index([<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: frame2</span><br><span class="line">Out[<span class="number">32</span>]: </span><br><span class="line">       a  b</span><br><span class="line">c   d      </span><br><span class="line">one <span class="number">0</span>  <span class="number">0</span>  <span class="number">7</span></span><br><span class="line">    <span class="number">1</span>  <span class="number">1</span>  <span class="number">6</span></span><br><span class="line">    <span class="number">2</span>  <span class="number">2</span>  <span class="number">5</span></span><br><span class="line">two <span class="number">0</span>  <span class="number">3</span>  <span class="number">4</span></span><br><span class="line">    <span class="number">1</span>  <span class="number">4</span>  <span class="number">3</span></span><br><span class="line">    <span class="number">2</span>  <span class="number">5</span>  <span class="number">2</span></span><br><span class="line">    <span class="number">3</span>  <span class="number">6</span>  <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>默认情况下，那些列会从DataFrame中移除，但也可以将其保留下来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: frame.set_index([<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], drop=<span class="literal">False</span>)</span><br><span class="line">Out[<span class="number">33</span>]: </span><br><span class="line">       a  b    c  d</span><br><span class="line">c   d              </span><br><span class="line">one <span class="number">0</span>  <span class="number">0</span>  <span class="number">7</span>  one  <span class="number">0</span></span><br><span class="line">    <span class="number">1</span>  <span class="number">1</span>  <span class="number">6</span>  one  <span class="number">1</span></span><br><span class="line">    <span class="number">2</span>  <span class="number">2</span>  <span class="number">5</span>  one  <span class="number">2</span></span><br><span class="line">two <span class="number">0</span>  <span class="number">3</span>  <span class="number">4</span>  two  <span class="number">0</span></span><br><span class="line">    <span class="number">1</span>  <span class="number">4</span>  <span class="number">3</span>  two  <span class="number">1</span></span><br><span class="line">    <span class="number">2</span>  <span class="number">5</span>  <span class="number">2</span>  two  <span class="number">2</span></span><br><span class="line">    <span class="number">3</span>  <span class="number">6</span>  <span class="number">1</span>  two  <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<p>reset_index的功能跟set_index刚好相反，层次化索引的级别会被转移到列里面：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: frame2.reset_index()</span><br><span class="line">Out[<span class="number">34</span>]:</span><br><span class="line">c  d  a  b</span><br><span class="line"><span class="number">0</span>  one  <span class="number">0</span>  <span class="number">0</span>  <span class="number">7</span></span><br><span class="line"><span class="number">1</span>  one  <span class="number">1</span>  <span class="number">1</span>  <span class="number">6</span></span><br><span class="line"><span class="number">2</span>  one  <span class="number">2</span>  <span class="number">2</span>  <span class="number">5</span></span><br><span class="line"><span class="number">3</span>  two  <span class="number">0</span>  <span class="number">3</span>  <span class="number">4</span></span><br><span class="line"><span class="number">4</span>  two  <span class="number">1</span>  <span class="number">4</span>  <span class="number">3</span></span><br><span class="line"><span class="number">5</span>  two  <span class="number">2</span>  <span class="number">5</span>  <span class="number">2</span></span><br><span class="line"><span class="number">6</span>  two  <span class="number">3</span>  <span class="number">6</span>  <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="82-合并数据集">8.2 合并数据集</span></h1><p>pandas对象中的数据可以通过一些方式进行合并：</p>
<ul>
<li>pandas.merge可根据一个或多个键将不同DataFrame中的行连接起来。SQL或其他关系型数据库的用户对此应该会比较熟悉，因为它实现的就是数据库的join操作。</li>
<li>pandas.concat可以沿着一条轴将多个对象堆叠到一起。</li>
<li>实例方法combine_first可以将重复数据拼接在一起，用一个对象中的值填充另一个对象中的缺失值。</li>
</ul>
<p>我将分别对它们进行讲解，并给出一些例子。本书剩余部分的示例中将经常用到它们。</p>
<h2><span id="数据库风格的dataframe合并">数据库风格的DataFrame合并</span></h2><p>数据集的合并（merge）或连接（join）运算是通过一个或多个键将行连接起来的。这些运算是关系型数据库（基于SQL）的核心。pandas的merge函数是对数据应用这些算法的主要切入点。</p>
<p>以一个简单的例子开始：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: df1 = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">   ....:                     <span class="string">&#x27;data1&#x27;</span>: <span class="built_in">range</span>(<span class="number">7</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: df2 = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;d&#x27;</span>],</span><br><span class="line">   ....:                     <span class="string">&#x27;data2&#x27;</span>: <span class="built_in">range</span>(<span class="number">3</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: df1</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">   data1 key</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>   b</span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>   b</span><br><span class="line"><span class="number">2</span>      <span class="number">2</span>   a</span><br><span class="line"><span class="number">3</span>      <span class="number">3</span>   c</span><br><span class="line"><span class="number">4</span>      <span class="number">4</span>   a</span><br><span class="line"><span class="number">5</span>      <span class="number">5</span>   a</span><br><span class="line"><span class="number">6</span>      <span class="number">6</span>   b</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: df2</span><br><span class="line">Out[<span class="number">38</span>]: </span><br><span class="line">   data2 key</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>   a</span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>   b</span><br><span class="line"><span class="number">2</span>      <span class="number">2</span>   d</span><br></pre></td></tr></table></figure></p>
<p>这是一种多对一的合并。df1中的数据有多个被标记为a和b的行，而df2中key列的每个值则仅对应一行。对这些对象调用merge即可得到：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: pd.merge(df1, df2)</span><br><span class="line">Out[<span class="number">39</span>]: </span><br><span class="line">   data1 key  data2</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">2</span>      <span class="number">6</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">3</span>      <span class="number">2</span>   a      <span class="number">0</span></span><br><span class="line"><span class="number">4</span>      <span class="number">4</span>   a      <span class="number">0</span></span><br><span class="line"><span class="number">5</span>      <span class="number">5</span>   a      <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>注意，我并没有指明要用哪个列进行连接。如果没有指定，merge就会将重叠列的列名当做键。不过，最好明确指定一下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">40</span>]: pd.merge(df1, df2, on=<span class="string">&#x27;key&#x27;</span>)</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">   data1 key  data2</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">2</span>      <span class="number">6</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">3</span>      <span class="number">2</span>   a      <span class="number">0</span></span><br><span class="line"><span class="number">4</span>      <span class="number">4</span>   a      <span class="number">0</span></span><br><span class="line"><span class="number">5</span>      <span class="number">5</span>   a      <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>如果两个对象的列名不同，也可以分别进行指定：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: df3 = pd.DataFrame(&#123;<span class="string">&#x27;lkey&#x27;</span>: [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">   ....:                     <span class="string">&#x27;data1&#x27;</span>: <span class="built_in">range</span>(<span class="number">7</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: df4 = pd.DataFrame(&#123;<span class="string">&#x27;rkey&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;d&#x27;</span>],</span><br><span class="line">   ....:                     <span class="string">&#x27;data2&#x27;</span>: <span class="built_in">range</span>(<span class="number">3</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: pd.merge(df3, df4, left_on=<span class="string">&#x27;lkey&#x27;</span>, right_on=<span class="string">&#x27;rkey&#x27;</span>)</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line">   data1 lkey  data2 rkey</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>    b      <span class="number">1</span>    b</span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>    b      <span class="number">1</span>    b</span><br><span class="line"><span class="number">2</span>      <span class="number">6</span>    b      <span class="number">1</span>    b</span><br><span class="line"><span class="number">3</span>      <span class="number">2</span>    a      <span class="number">0</span>    a</span><br><span class="line"><span class="number">4</span>      <span class="number">4</span>    a      <span class="number">0</span>    a</span><br><span class="line"><span class="number">5</span>      <span class="number">5</span>    a      <span class="number">0</span>    a</span><br></pre></td></tr></table></figure></p>
<p>可能你已经注意到了，结果里面c和d以及与之相关的数据消失了。默认情况下，merge做的是“内连接”；结果中的键是交集。其他方式还有”left”、”right”以及”outer”。外连接求取的是键的并集，组合了左连接和右连接的效果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: pd.merge(df1, df2, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line">   data1 key  data2</span><br><span class="line"><span class="number">0</span>    <span class="number">0.0</span>   b    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1.0</span>   b    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">6.0</span>   b    <span class="number">1.0</span></span><br><span class="line"><span class="number">3</span>    <span class="number">2.0</span>   a    <span class="number">0.0</span></span><br><span class="line"><span class="number">4</span>    <span class="number">4.0</span>   a    <span class="number">0.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">5.0</span>   a    <span class="number">0.0</span></span><br><span class="line"><span class="number">6</span>    <span class="number">3.0</span>   c    NaN</span><br><span class="line"><span class="number">7</span>    NaN   d    <span class="number">2.0</span></span><br></pre></td></tr></table></figure></p>
<p>表8-1对这些选项进行了总结。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-e49b3341f4a3c90e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表8-1 不同的连接类型"></p>
<p>多对多的合并有些不直观。看下面的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: df1 = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">   ....:                     <span class="string">&#x27;data1&#x27;</span>: <span class="built_in">range</span>(<span class="number">6</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: df2 = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;d&#x27;</span>],</span><br><span class="line">   ....:                     <span class="string">&#x27;data2&#x27;</span>: <span class="built_in">range</span>(<span class="number">5</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: df1</span><br><span class="line">Out[<span class="number">47</span>]: </span><br><span class="line">   data1 key</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>   b</span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>   b</span><br><span class="line"><span class="number">2</span>      <span class="number">2</span>   a</span><br><span class="line"><span class="number">3</span>      <span class="number">3</span>   c</span><br><span class="line"><span class="number">4</span>      <span class="number">4</span>   a</span><br><span class="line"><span class="number">5</span>      <span class="number">5</span>   b</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: df2</span><br><span class="line">Out[<span class="number">48</span>]: </span><br><span class="line">   data2 key</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>   a</span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>   b</span><br><span class="line"><span class="number">2</span>      <span class="number">2</span>   a</span><br><span class="line"><span class="number">3</span>      <span class="number">3</span>   b</span><br><span class="line"><span class="number">4</span>      <span class="number">4</span>   d</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: pd.merge(df1, df2, on=<span class="string">&#x27;key&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">Out[<span class="number">49</span>]: </span><br><span class="line">    data1 key  data2</span><br><span class="line"><span class="number">0</span>       <span class="number">0</span>   b    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>       <span class="number">0</span>   b    <span class="number">3.0</span></span><br><span class="line"><span class="number">2</span>       <span class="number">1</span>   b    <span class="number">1.0</span></span><br><span class="line"><span class="number">3</span>       <span class="number">1</span>   b    <span class="number">3.0</span></span><br><span class="line"><span class="number">4</span>       <span class="number">2</span>   a    <span class="number">0.0</span></span><br><span class="line"><span class="number">5</span>       <span class="number">2</span>   a    <span class="number">2.0</span></span><br><span class="line"><span class="number">6</span>       <span class="number">3</span>   c    NaN</span><br><span class="line"><span class="number">7</span>       <span class="number">4</span>   a    <span class="number">0.0</span></span><br><span class="line"><span class="number">8</span>       <span class="number">4</span>   a    <span class="number">2.0</span></span><br><span class="line"><span class="number">9</span>       <span class="number">5</span>   b    <span class="number">1.0</span></span><br><span class="line"><span class="number">10</span>      <span class="number">5</span>   b    <span class="number">3.0</span></span><br></pre></td></tr></table></figure></p>
<p>多对多连接产生的是行的笛卡尔积。由于左边的DataFrame有3个”b”行，右边的有2个，所以最终结果中就有6个”b”行。连接方式只影响出现在结果中的不同的键的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: pd.merge(df1, df2, how=<span class="string">&#x27;inner&#x27;</span>)</span><br><span class="line">Out[<span class="number">50</span>]: </span><br><span class="line">   data1 key  data2</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">1</span>      <span class="number">0</span>   b      <span class="number">3</span></span><br><span class="line"><span class="number">2</span>      <span class="number">1</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">3</span>      <span class="number">1</span>   b      <span class="number">3</span></span><br><span class="line"><span class="number">4</span>      <span class="number">5</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">5</span>      <span class="number">5</span>   b      <span class="number">3</span></span><br><span class="line"><span class="number">6</span>      <span class="number">2</span>   a      <span class="number">0</span></span><br><span class="line"><span class="number">7</span>      <span class="number">2</span>   a      <span class="number">2</span></span><br><span class="line"><span class="number">8</span>      <span class="number">4</span>   a      <span class="number">0</span></span><br><span class="line"><span class="number">9</span>      <span class="number">4</span>   a      <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p>要根据多个键进行合并，传入一个由列名组成的列表即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: left = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>],</span><br><span class="line">   ....:                      <span class="string">&#x27;key2&#x27;</span>: [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;one&#x27;</span>],</span><br><span class="line">   ....:                      <span class="string">&#x27;lval&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: right = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>],</span><br><span class="line">   ....:                       <span class="string">&#x27;key2&#x27;</span>: [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>],</span><br><span class="line">   ....:                       <span class="string">&#x27;rval&#x27;</span>: [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: pd.merge(left, right, on=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>], how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">  key1 key2  lval  rval</span><br><span class="line"><span class="number">0</span>  foo  one   <span class="number">1.0</span>   <span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>  foo  one   <span class="number">1.0</span>   <span class="number">5.0</span></span><br><span class="line"><span class="number">2</span>  foo  two   <span class="number">2.0</span>   NaN</span><br><span class="line"><span class="number">3</span>  bar  one   <span class="number">3.0</span>   <span class="number">6.0</span></span><br><span class="line"><span class="number">4</span>  bar  two   NaN   <span class="number">7.0</span></span><br></pre></td></tr></table></figure></p>
<p>结果中会出现哪些键组合取决于所选的合并方式，你可以这样来理解：多个键形成一系列元组，并将其当做单个连接键（当然，实际上并不是这么回事）。</p>
<blockquote>
<p>注意：在进行列－列连接时，DataFrame对象中的索引会被丢弃。</p>
</blockquote>
<p>对于合并运算需要考虑的最后一个问题是对重复列名的处理。虽然你可以手工处理列名重叠的问题（查看前面介绍的重命名轴标签），但merge有一个更实用的suffixes选项，用于指定附加到左右两个DataFrame对象的重叠列名上的字符串：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">54</span>]: pd.merge(left, right, on=<span class="string">&#x27;key1&#x27;</span>)</span><br><span class="line">Out[<span class="number">54</span>]: </span><br><span class="line">  key1 key2_x  lval key2_y  rval</span><br><span class="line"><span class="number">0</span>  foo    one     <span class="number">1</span>    one     <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  foo    one     <span class="number">1</span>    one     <span class="number">5</span></span><br><span class="line"><span class="number">2</span>  foo    two     <span class="number">2</span>    one     <span class="number">4</span></span><br><span class="line"><span class="number">3</span>  foo    two     <span class="number">2</span>    one     <span class="number">5</span></span><br><span class="line"><span class="number">4</span>  bar    one     <span class="number">3</span>    one     <span class="number">6</span></span><br><span class="line"><span class="number">5</span>  bar    one     <span class="number">3</span>    two     <span class="number">7</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: pd.merge(left, right, on=<span class="string">&#x27;key1&#x27;</span>, suffixes=(<span class="string">&#x27;_left&#x27;</span>, <span class="string">&#x27;_right&#x27;</span>))</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line">  key1 key2_left  lval key2_right  rval</span><br><span class="line"><span class="number">0</span>  foo       one     <span class="number">1</span>        one     <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  foo       one     <span class="number">1</span>        one     <span class="number">5</span></span><br><span class="line"><span class="number">2</span>  foo       two     <span class="number">2</span>        one     <span class="number">4</span></span><br><span class="line"><span class="number">3</span>  foo       two     <span class="number">2</span>        one     <span class="number">5</span></span><br><span class="line"><span class="number">4</span>  bar       one     <span class="number">3</span>        one     <span class="number">6</span></span><br><span class="line"><span class="number">5</span>  bar       one     <span class="number">3</span>        two     <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<p>merge的参数请参见表8-2。使用DataFrame的行索引合并是下一节的主题。</p>
<p>表8-2 merge函数的参数</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-35ca716a4f1b8475.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c86672e733ceccd9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>indicator 添加特殊的列_merge，它可以指明每个行的来源，它的值有left_only、right_only或both，根据每行的合并数据的来源。</p>
<h2><span id="索引上的合并">索引上的合并</span></h2><p>有时候，DataFrame中的连接键位于其索引中。在这种情况下，你可以传入left_index=True或right_index=True（或两个都传）以说明索引应该被用作连接键：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: left1 = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">   ....:                       <span class="string">&#x27;value&#x27;</span>: <span class="built_in">range</span>(<span class="number">6</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: right1 = pd.DataFrame(&#123;<span class="string">&#x27;group_val&#x27;</span>: [<span class="number">3.5</span>, <span class="number">7</span>]&#125;, index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: left1</span><br><span class="line">Out[<span class="number">58</span>]:</span><br><span class="line"></span><br><span class="line">  key  value</span><br><span class="line"><span class="number">0</span>   a      <span class="number">0</span></span><br><span class="line"><span class="number">1</span>   b      <span class="number">1</span></span><br><span class="line"><span class="number">2</span>   a      <span class="number">2</span></span><br><span class="line"><span class="number">3</span>   a      <span class="number">3</span></span><br><span class="line"><span class="number">4</span>   b      <span class="number">4</span></span><br><span class="line"><span class="number">5</span>   c      <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: right1</span><br><span class="line">Out[<span class="number">59</span>]: </span><br><span class="line">   group_val</span><br><span class="line">a        <span class="number">3.5</span></span><br><span class="line">b        <span class="number">7.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: pd.merge(left1, right1, left_on=<span class="string">&#x27;key&#x27;</span>, right_index=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">60</span>]: </span><br><span class="line">  key  value  group_val</span><br><span class="line"><span class="number">0</span>   a      <span class="number">0</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">2</span>   a      <span class="number">2</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">3</span>   a      <span class="number">3</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">1</span>   b      <span class="number">1</span>        <span class="number">7.0</span></span><br><span class="line"><span class="number">4</span>   b      <span class="number">4</span>        <span class="number">7.0</span></span><br></pre></td></tr></table></figure></p>
<p>由于默认的merge方法是求取连接键的交集，因此你可以通过外连接的方式得到它们的并集：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">61</span>]: pd.merge(left1, right1, left_on=<span class="string">&#x27;key&#x27;</span>, right_index=<span class="literal">True</span>, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">61</span>]: </span><br><span class="line">  key  value  group_val</span><br><span class="line"><span class="number">0</span>   a      <span class="number">0</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">2</span>   a      <span class="number">2</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">3</span>   a      <span class="number">3</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">1</span>   b      <span class="number">1</span>        <span class="number">7.0</span></span><br><span class="line"><span class="number">4</span>   b      <span class="number">4</span>        <span class="number">7.0</span></span><br><span class="line"><span class="number">5</span>   c      <span class="number">5</span>        NaN</span><br></pre></td></tr></table></figure></p>
<p>对于层次化索引的数据，事情就有点复杂了，因为索引的合并默认是多键合并：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">62</span>]: lefth = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>,</span><br><span class="line">   ....:                                <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>],</span><br><span class="line">   ....:                       <span class="string">&#x27;key2&#x27;</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line">   ....:                       <span class="string">&#x27;data&#x27;</span>: np.arange(<span class="number">5.</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: righth = pd.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">6</span>, <span class="number">2</span>)),</span><br><span class="line">   ....:                       index=[[<span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>,</span><br><span class="line">   ....:                               <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>],</span><br><span class="line">   ....:                              [<span class="number">2001</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>]],</span><br><span class="line">   ....:                       columns=[<span class="string">&#x27;event1&#x27;</span>, <span class="string">&#x27;event2&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: lefth</span><br><span class="line">Out[<span class="number">64</span>]: </span><br><span class="line">   data    key1  key2</span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>    Ohio  <span class="number">2000</span></span><br><span class="line"><span class="number">1</span>   <span class="number">1.0</span>    Ohio  <span class="number">2001</span></span><br><span class="line"><span class="number">2</span>   <span class="number">2.0</span>    Ohio  <span class="number">2002</span></span><br><span class="line"><span class="number">3</span>   <span class="number">3.0</span>  Nevada  <span class="number">2001</span></span><br><span class="line"><span class="number">4</span>   <span class="number">4.0</span>  Nevada  <span class="number">2002</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: righth</span><br><span class="line">Out[<span class="number">65</span>]: </span><br><span class="line">             event1  event2</span><br><span class="line">Nevada <span class="number">2001</span>       <span class="number">0</span>       <span class="number">1</span></span><br><span class="line">       <span class="number">2000</span>       <span class="number">2</span>       <span class="number">3</span></span><br><span class="line">Ohio   <span class="number">2000</span>       <span class="number">4</span>       <span class="number">5</span></span><br><span class="line">       <span class="number">2000</span>       <span class="number">6</span>       <span class="number">7</span></span><br><span class="line">       <span class="number">2001</span>       <span class="number">8</span>       <span class="number">9</span></span><br><span class="line">       <span class="number">2002</span>      <span class="number">10</span>      <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<p>这种情况下，你必须以列表的形式指明用作合并键的多个列（注意用how=’outer’对重复索引值的处理）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: pd.merge(lefth, righth, left_on=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>], right_index=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">66</span>]: </span><br><span class="line">   data    key1  key2  event1  event2</span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>    Ohio  <span class="number">2000</span>       <span class="number">4</span>       <span class="number">5</span></span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>    Ohio  <span class="number">2000</span>       <span class="number">6</span>       <span class="number">7</span></span><br><span class="line"><span class="number">1</span>   <span class="number">1.0</span>    Ohio  <span class="number">2001</span>       <span class="number">8</span>       <span class="number">9</span></span><br><span class="line"><span class="number">2</span>   <span class="number">2.0</span>    Ohio  <span class="number">2002</span>      <span class="number">10</span>      <span class="number">11</span></span><br><span class="line"><span class="number">3</span>   <span class="number">3.0</span>  Nevada  <span class="number">2001</span>       <span class="number">0</span>       <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: pd.merge(lefth, righth, left_on=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>],</span><br><span class="line">   ....:          right_index=<span class="literal">True</span>, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">67</span>]: </span><br><span class="line">   data    key1  key2  event1  event2</span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>    Ohio  <span class="number">2000</span>     <span class="number">4.0</span>     <span class="number">5.0</span></span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>    Ohio  <span class="number">2000</span>     <span class="number">6.0</span>     <span class="number">7.0</span></span><br><span class="line"><span class="number">1</span>   <span class="number">1.0</span>    Ohio  <span class="number">2001</span>     <span class="number">8.0</span>     <span class="number">9.0</span></span><br><span class="line"><span class="number">2</span>   <span class="number">2.0</span>    Ohio  <span class="number">2002</span>    <span class="number">10.0</span>    <span class="number">11.0</span></span><br><span class="line"><span class="number">3</span>   <span class="number">3.0</span>  Nevada  <span class="number">2001</span>     <span class="number">0.0</span>     <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>   <span class="number">4.0</span>  Nevada  <span class="number">2002</span>     NaN     NaN</span><br><span class="line"><span class="number">4</span>   NaN  Nevada  <span class="number">2000</span>     <span class="number">2.0</span>     <span class="number">3.0</span></span><br></pre></td></tr></table></figure></p>
<p>同时使用合并双方的索引也没问题：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: left2 = pd.DataFrame([[<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">3.</span>, <span class="number">4.</span>], [<span class="number">5.</span>, <span class="number">6.</span>]],</span><br><span class="line">   ....:                      index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;e&#x27;</span>],</span><br><span class="line">   ....:                      columns=[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: right2 = pd.DataFrame([[<span class="number">7.</span>, <span class="number">8.</span>], [<span class="number">9.</span>, <span class="number">10.</span>], [<span class="number">11.</span>, <span class="number">12.</span>], [<span class="number">13</span>, <span class="number">14</span>]],</span><br><span class="line">   ....:                       index=[<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>],</span><br><span class="line">   ....:                       columns=[<span class="string">&#x27;Missouri&#x27;</span>, <span class="string">&#x27;Alabama&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: left2</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line">   Ohio  Nevada</span><br><span class="line">a   <span class="number">1.0</span>     <span class="number">2.0</span></span><br><span class="line">c   <span class="number">3.0</span>     <span class="number">4.0</span></span><br><span class="line">e   <span class="number">5.0</span>     <span class="number">6.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: right2</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line">   Missouri  Alabama</span><br><span class="line">b       <span class="number">7.0</span>      <span class="number">8.0</span></span><br><span class="line">c       <span class="number">9.0</span>     <span class="number">10.0</span></span><br><span class="line">d      <span class="number">11.0</span>     <span class="number">12.0</span></span><br><span class="line">e      <span class="number">13.0</span>     <span class="number">14.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: pd.merge(left2, right2, how=<span class="string">&#x27;outer&#x27;</span>, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">72</span>]: </span><br><span class="line">   Ohio  Nevada  Missouri  Alabama</span><br><span class="line">a   <span class="number">1.0</span>     <span class="number">2.0</span>       NaN      NaN</span><br><span class="line">b   NaN     NaN       <span class="number">7.0</span>      <span class="number">8.0</span></span><br><span class="line">c   <span class="number">3.0</span>     <span class="number">4.0</span>       <span class="number">9.0</span>     <span class="number">10.0</span></span><br><span class="line">d   NaN     NaN      <span class="number">11.0</span>     <span class="number">12.0</span></span><br><span class="line">e   <span class="number">5.0</span>     <span class="number">6.0</span>      <span class="number">13.0</span>     <span class="number">14.0</span></span><br></pre></td></tr></table></figure></p>
<p>DataFrame还有一个便捷的join实例方法，它能更为方便地实现按索引合并。它还可用于合并多个带有相同或相似索引的DataFrame对象，但要求没有重叠的列。在上面那个例子中，我们可以编写：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: left2.join(right2, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">73</span>]: </span><br><span class="line">   Ohio  Nevada  Missouri  Alabama</span><br><span class="line">a   <span class="number">1.0</span>     <span class="number">2.0</span>       NaN      NaN</span><br><span class="line">b   NaN     NaN       <span class="number">7.0</span>      <span class="number">8.0</span></span><br><span class="line">c   <span class="number">3.0</span>     <span class="number">4.0</span>       <span class="number">9.0</span>     <span class="number">10.0</span></span><br><span class="line">d   NaN     NaN      <span class="number">11.0</span>     <span class="number">12.0</span></span><br><span class="line">e   <span class="number">5.0</span>     <span class="number">6.0</span>      <span class="number">13.0</span>     <span class="number">14.0</span></span><br></pre></td></tr></table></figure></p>
<p>因为一些历史版本的遗留原因，DataFrame的join方法默认使用的是左连接，保留左边表的行索引。它还支持在调用的DataFrame的列上，连接传递的DataFrame索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: left1.join(right1, on=<span class="string">&#x27;key&#x27;</span>)</span><br><span class="line">Out[<span class="number">74</span>]: </span><br><span class="line">  key  value  group_val</span><br><span class="line"><span class="number">0</span>   a      <span class="number">0</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">1</span>   b      <span class="number">1</span>        <span class="number">7.0</span></span><br><span class="line"><span class="number">2</span>   a      <span class="number">2</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">3</span>   a      <span class="number">3</span>        <span class="number">3.5</span></span><br><span class="line"><span class="number">4</span>   b      <span class="number">4</span>        <span class="number">7.0</span></span><br><span class="line"><span class="number">5</span>   c      <span class="number">5</span>        NaN</span><br></pre></td></tr></table></figure></p>
<p>最后，对于简单的索引合并，你还可以向join传入一组DataFrame，下一节会介绍更为通用的concat函数，也能实现此功能：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: another = pd.DataFrame([[<span class="number">7.</span>, <span class="number">8.</span>], [<span class="number">9.</span>, <span class="number">10.</span>], [<span class="number">11.</span>, <span class="number">12.</span>], [<span class="number">16.</span>, <span class="number">17.</span>]],</span><br><span class="line">   ....:                        index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>],</span><br><span class="line">   ....:                        columns=[<span class="string">&#x27;New York&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Oregon&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: another</span><br><span class="line">Out[<span class="number">76</span>]: </span><br><span class="line">   New York  Oregon</span><br><span class="line">a       <span class="number">7.0</span>     <span class="number">8.0</span></span><br><span class="line">c       <span class="number">9.0</span>    <span class="number">10.0</span></span><br><span class="line">e      <span class="number">11.0</span>    <span class="number">12.0</span></span><br><span class="line">f      <span class="number">16.0</span>    <span class="number">17.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: left2.join([right2, another])</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">   Ohio  Nevada  Missouri  Alabama  New York  Oregon</span><br><span class="line">a   <span class="number">1.0</span>     <span class="number">2.0</span>       NaN      NaN       <span class="number">7.0</span>     <span class="number">8.0</span></span><br><span class="line">c   <span class="number">3.0</span>     <span class="number">4.0</span>       <span class="number">9.0</span>     <span class="number">10.0</span>       <span class="number">9.0</span>    <span class="number">10.0</span></span><br><span class="line">e   <span class="number">5.0</span>     <span class="number">6.0</span>      <span class="number">13.0</span>     <span class="number">14.0</span>      <span class="number">11.0</span>    <span class="number">12.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: left2.join([right2, another], how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line">   Ohio  Nevada  Missouri  Alabama  New York  Oregon</span><br><span class="line">a   <span class="number">1.0</span>     <span class="number">2.0</span>       NaN      NaN       <span class="number">7.0</span>     <span class="number">8.0</span></span><br><span class="line">b   NaN     NaN       <span class="number">7.0</span>      <span class="number">8.0</span>       NaN     NaN</span><br><span class="line">c   <span class="number">3.0</span>     <span class="number">4.0</span>       <span class="number">9.0</span>     <span class="number">10.0</span>       <span class="number">9.0</span>    <span class="number">10.0</span></span><br><span class="line">d   NaN     NaN      <span class="number">11.0</span>     <span class="number">12.0</span>       NaN     NaN</span><br><span class="line">e   <span class="number">5.0</span>     <span class="number">6.0</span>      <span class="number">13.0</span>     <span class="number">14.0</span>      <span class="number">11.0</span>    <span class="number">12.0</span></span><br><span class="line">f   NaN     NaN       NaN      NaN      <span class="number">16.0</span>    <span class="number">17.0</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="轴向连接">轴向连接</span></h2><p>另一种数据合并运算也被称作连接（concatenation）、绑定（binding）或堆叠（stacking）。NumPy的concatenation函数可以用NumPy数组来做：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">79</span>]: arr = np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: arr</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">       [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: np.concatenate([arr, arr], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">81</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">       [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]])</span><br></pre></td></tr></table></figure></p>
<p>对于pandas对象（如Series和DataFrame），带有标签的轴使你能够进一步推广数组的连接运算。具体点说，你还需要考虑以下这些东西：</p>
<ul>
<li>如果对象在其它轴上的索引不同，我们应该合并这些轴的不同元素还是只使用交集？</li>
<li>连接的数据集是否需要在结果对象中可识别？</li>
<li>连接轴中保存的数据是否需要保留？许多情况下，DataFrame默认的整数标签最好在连接时删掉。</li>
</ul>
<p>pandas的concat函数提供了一种能够解决这些问题的可靠方式。我将给出一些例子来讲解其使用方式。假设有三个没有重叠索引的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: s1 = pd.Series([<span class="number">0</span>, <span class="number">1</span>], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: s2 = pd.Series([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], index=[<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: s3 = pd.Series([<span class="number">5</span>, <span class="number">6</span>], index=[<span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;g&#x27;</span>])</span><br></pre></td></tr></table></figure></p>
<p>对这些对象调用concat可以将值和索引粘合在一起：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: pd.concat([s1, s2, s3])</span><br><span class="line">Out[<span class="number">85</span>]: </span><br><span class="line">a    <span class="number">0</span></span><br><span class="line">b    <span class="number">1</span></span><br><span class="line">c    <span class="number">2</span></span><br><span class="line">d    <span class="number">3</span></span><br><span class="line">e    <span class="number">4</span></span><br><span class="line">f    <span class="number">5</span></span><br><span class="line">g    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>默认情况下，concat是在axis=0上工作的，最终产生一个新的Series。如果传入axis=1，则结果就会变成一个DataFrame（axis=1是列）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">86</span>]: pd.concat([s1, s2, s3], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span></span><br><span class="line">a  <span class="number">0.0</span>  NaN  NaN</span><br><span class="line">b  <span class="number">1.0</span>  NaN  NaN</span><br><span class="line">c  NaN  <span class="number">2.0</span>  NaN</span><br><span class="line">d  NaN  <span class="number">3.0</span>  NaN</span><br><span class="line">e  NaN  <span class="number">4.0</span>  NaN</span><br><span class="line">f  NaN  NaN  <span class="number">5.0</span></span><br><span class="line">g  NaN  NaN  <span class="number">6.0</span></span><br></pre></td></tr></table></figure></p>
<p>这种情况下，另外的轴上没有重叠，从索引的有序并集（外连接）上就可以看出来。传入join=’inner’即可得到它们的交集：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: s4 = pd.concat([s1, s3])</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: s4</span><br><span class="line">Out[<span class="number">88</span>]: </span><br><span class="line">a    <span class="number">0</span></span><br><span class="line">b    <span class="number">1</span></span><br><span class="line">f    <span class="number">5</span></span><br><span class="line">g    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: pd.concat([s1, s4], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">89</span>]: </span><br><span class="line">     <span class="number">0</span>  <span class="number">1</span></span><br><span class="line">a  <span class="number">0.0</span>  <span class="number">0</span></span><br><span class="line">b  <span class="number">1.0</span>  <span class="number">1</span></span><br><span class="line">f  NaN  <span class="number">5</span></span><br><span class="line">g  NaN  <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: pd.concat([s1, s4], axis=<span class="number">1</span>, join=<span class="string">&#x27;inner&#x27;</span>)</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">   <span class="number">0</span>  <span class="number">1</span></span><br><span class="line">a  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line">b  <span class="number">1</span>  <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>在这个例子中，f和g标签消失了，是因为使用的是join=’inner’选项。</p>
<p>你可以通过join_axes指定要在其它轴上使用的索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: pd.concat([s1, s4], axis=<span class="number">1</span>, join_axes=[[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;e&#x27;</span>]])</span><br><span class="line">Out[<span class="number">91</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span></span><br><span class="line">a  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line">c  NaN  NaN</span><br><span class="line">b  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line">e  NaN  NaN</span><br></pre></td></tr></table></figure></p>
<p>不过有个问题，参与连接的片段在结果中区分不开。假设你想要在连接轴上创建一个层次化索引。使用keys参数即可达到这个目的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">92</span>]: result = pd.concat([s1, s1, s3], keys=[<span class="string">&#x27;one&#x27;</span>,<span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: result</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line">one    a    <span class="number">0</span></span><br><span class="line">       b    <span class="number">1</span></span><br><span class="line">two    a    <span class="number">0</span></span><br><span class="line">       b    <span class="number">1</span></span><br><span class="line">three  f    <span class="number">5</span></span><br><span class="line">       g    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">94</span>]: result.unstack()</span><br><span class="line">Out[<span class="number">94</span>]: </span><br><span class="line">         a    b    f    g</span><br><span class="line">one    <span class="number">0.0</span>  <span class="number">1.0</span>  NaN  NaN</span><br><span class="line">two    <span class="number">0.0</span>  <span class="number">1.0</span>  NaN  NaN</span><br><span class="line">three  NaN  NaN  <span class="number">5.0</span>  <span class="number">6.0</span></span><br></pre></td></tr></table></figure></p>
<p>如果沿着axis=1对Series进行合并，则keys就会成为DataFrame的列头：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: pd.concat([s1, s2, s3], axis=<span class="number">1</span>, keys=[<span class="string">&#x27;one&#x27;</span>,<span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>])</span><br><span class="line">Out[<span class="number">95</span>]: </span><br><span class="line">   one  two  three</span><br><span class="line">a  <span class="number">0.0</span>  NaN    NaN</span><br><span class="line">b  <span class="number">1.0</span>  NaN    NaN</span><br><span class="line">c  NaN  <span class="number">2.0</span>    NaN</span><br><span class="line">d  NaN  <span class="number">3.0</span>    NaN</span><br><span class="line">e  NaN  <span class="number">4.0</span>    NaN</span><br><span class="line">f  NaN  NaN    <span class="number">5.0</span></span><br><span class="line">g  NaN  NaN    <span class="number">6.0</span></span><br></pre></td></tr></table></figure></p>
<p>同样的逻辑也适用于DataFrame对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: df1 = pd.DataFrame(np.arange(<span class="number">6</span>).reshape(<span class="number">3</span>, <span class="number">2</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">   ....:                    columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: df2 = pd.DataFrame(<span class="number">5</span> + np.arange(<span class="number">4</span>).reshape(<span class="number">2</span>, <span class="number">2</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">   ....:                    columns=[<span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: df1</span><br><span class="line">Out[<span class="number">98</span>]: </span><br><span class="line">   one  two</span><br><span class="line">a    <span class="number">0</span>    <span class="number">1</span></span><br><span class="line">b    <span class="number">2</span>    <span class="number">3</span></span><br><span class="line">c    <span class="number">4</span>    <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: df2</span><br><span class="line">Out[<span class="number">99</span>]: </span><br><span class="line">   three  four</span><br><span class="line">a      <span class="number">5</span>     <span class="number">6</span></span><br><span class="line">c      <span class="number">7</span>     <span class="number">8</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: pd.concat([df1, df2], axis=<span class="number">1</span>, keys=[<span class="string">&#x27;level1&#x27;</span>, <span class="string">&#x27;level2&#x27;</span>])</span><br><span class="line">Out[<span class="number">100</span>]: </span><br><span class="line">  level1     level2     </span><br><span class="line">     one two  three four</span><br><span class="line">a      <span class="number">0</span>   <span class="number">1</span>    <span class="number">5.0</span>  <span class="number">6.0</span></span><br><span class="line">b      <span class="number">2</span>   <span class="number">3</span>    NaN  NaN</span><br><span class="line">c      <span class="number">4</span>   <span class="number">5</span>    <span class="number">7.0</span>  <span class="number">8.0</span></span><br></pre></td></tr></table></figure></p>
<p>如果传入的不是列表而是一个字典，则字典的键就会被当做keys选项的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">101</span>]: pd.concat(&#123;<span class="string">&#x27;level1&#x27;</span>: df1, <span class="string">&#x27;level2&#x27;</span>: df2&#125;, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">Out[<span class="number">101</span>]: </span><br><span class="line">  level1     level2     </span><br><span class="line">     one two  three four</span><br><span class="line">a      <span class="number">0</span>   <span class="number">1</span>    <span class="number">5.0</span>  <span class="number">6.0</span></span><br><span class="line">b      <span class="number">2</span>   <span class="number">3</span>    NaN  NaN</span><br><span class="line">c      <span class="number">4</span>   <span class="number">5</span>    <span class="number">7.0</span>  <span class="number">8.0</span></span><br></pre></td></tr></table></figure></p>
<p>此外还有两个用于管理层次化索引创建方式的参数（参见表8-3）。举个例子，我们可以用names参数命名创建的轴级别：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: pd.concat([df1, df2], axis=<span class="number">1</span>, keys=[<span class="string">&#x27;level1&#x27;</span>, <span class="string">&#x27;level2&#x27;</span>],</span><br><span class="line">   .....:           names=[<span class="string">&#x27;upper&#x27;</span>, <span class="string">&#x27;lower&#x27;</span>])</span><br><span class="line">Out[<span class="number">102</span>]: </span><br><span class="line">upper level1     level2     </span><br><span class="line">lower    one two  three four</span><br><span class="line">a          <span class="number">0</span>   <span class="number">1</span>    <span class="number">5.0</span>  <span class="number">6.0</span></span><br><span class="line">b          <span class="number">2</span>   <span class="number">3</span>    NaN  NaN</span><br><span class="line">c          <span class="number">4</span>   <span class="number">5</span>    <span class="number">7.0</span>  <span class="number">8.0</span></span><br></pre></td></tr></table></figure></p>
<p>最后一个关于DataFrame的问题是，DataFrame的行索引不包含任何相关数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">103</span>]: df1 = pd.DataFrame(np.random.randn(<span class="number">3</span>, <span class="number">4</span>), columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">104</span>]: df2 = pd.DataFrame(np.random.randn(<span class="number">2</span>, <span class="number">3</span>), columns=[<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: df1</span><br><span class="line">Out[<span class="number">105</span>]: </span><br><span class="line">          a         b         c         d</span><br><span class="line"><span class="number">0</span>  <span class="number">1.246435</span>  <span class="number">1.007189</span> -<span class="number">1.296221</span>  <span class="number">0.274992</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span></span><br><span class="line"><span class="number">2</span> -<span class="number">0.371843</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: df2</span><br><span class="line">Out[<span class="number">106</span>]: </span><br><span class="line">          b         d         a</span><br><span class="line"><span class="number">0</span>  <span class="number">0.476985</span>  <span class="number">3.248944</span> -<span class="number">1.021228</span></span><br><span class="line"><span class="number">1</span> -<span class="number">0.577087</span>  <span class="number">0.124121</span>  <span class="number">0.302614</span></span><br></pre></td></tr></table></figure></p>
<p>在这种情况下，传入ignore_index=True即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">107</span>]: pd.concat([df1, df2], ignore_index=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">107</span>]: </span><br><span class="line">          a         b         c         d</span><br><span class="line"><span class="number">0</span>  <span class="number">1.246435</span>  <span class="number">1.007189</span> -<span class="number">1.296221</span>  <span class="number">0.274992</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span></span><br><span class="line"><span class="number">2</span> -<span class="number">0.371843</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br><span class="line"><span class="number">3</span> -<span class="number">1.021228</span>  <span class="number">0.476985</span>       NaN  <span class="number">3.248944</span></span><br><span class="line"><span class="number">4</span>  <span class="number">0.302614</span> -<span class="number">0.577087</span>       NaN  <span class="number">0.124121</span></span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-339436563b519415.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表8-3 concat函数的参数"></p>
<h2><span id="合并重叠数据">合并重叠数据</span></h2><p>还有一种数据组合问题不能用简单的合并（merge）或连接（concatenation）运算来处理。比如说，你可能有索引全部或部分重叠的两个数据集。举个有启发性的例子，我们使用NumPy的where函数，它表示一种等价于面向数组的if-else：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: a = pd.Series([np.nan, <span class="number">2.5</span>, np.nan, <span class="number">3.5</span>, <span class="number">4.5</span>, np.nan],</span><br><span class="line">   .....:               index=[<span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: b = pd.Series(np.arange(<span class="built_in">len</span>(a), dtype=np.float64),</span><br><span class="line">   .....:               index=[<span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: b[-<span class="number">1</span>] = np.nan</span><br><span class="line"></span><br><span class="line">In [<span class="number">111</span>]: a</span><br><span class="line">Out[<span class="number">111</span>]: </span><br><span class="line">f    NaN</span><br><span class="line">e    <span class="number">2.5</span></span><br><span class="line">d    NaN</span><br><span class="line">c    <span class="number">3.5</span></span><br><span class="line">b    <span class="number">4.5</span></span><br><span class="line">a    NaN</span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: b</span><br><span class="line">Out[<span class="number">112</span>]: </span><br><span class="line">f    <span class="number">0.0</span></span><br><span class="line">e    <span class="number">1.0</span></span><br><span class="line">d    <span class="number">2.0</span></span><br><span class="line">c    <span class="number">3.0</span></span><br><span class="line">b    <span class="number">4.0</span></span><br><span class="line">a    NaN</span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: np.where(pd.isnull(a), b, a)</span><br><span class="line">Out[<span class="number">113</span>]: array([ <span class="number">0.</span> ,  <span class="number">2.5</span>,  <span class="number">2.</span> ,  <span class="number">3.5</span>,  <span class="number">4.5</span>,  nan])</span><br></pre></td></tr></table></figure></p>
<p>Series有一个combine_first方法，实现的也是一样的功能，还带有pandas的数据对齐：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">114</span>]: b[:-<span class="number">2</span>].combine_first(a[<span class="number">2</span>:])</span><br><span class="line">Out[<span class="number">114</span>]: </span><br><span class="line">a    NaN</span><br><span class="line">b    <span class="number">4.5</span></span><br><span class="line">c    <span class="number">3.0</span></span><br><span class="line">d    <span class="number">2.0</span></span><br><span class="line">e    <span class="number">1.0</span></span><br><span class="line">f    <span class="number">0.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>对于DataFrame，combine_first自然也会在列上做同样的事情，因此你可以将其看做：用传递对象中的数据为调用对象的缺失数据“打补丁”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">115</span>]: df1 = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>: [<span class="number">1.</span>, np.nan, <span class="number">5.</span>, np.nan],</span><br><span class="line">   .....:                     <span class="string">&#x27;b&#x27;</span>: [np.nan, <span class="number">2.</span>, np.nan, <span class="number">6.</span>],</span><br><span class="line">   .....:                     <span class="string">&#x27;c&#x27;</span>: <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">18</span>, <span class="number">4</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: df2 = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>: [<span class="number">5.</span>, <span class="number">4.</span>, np.nan, <span class="number">3.</span>, <span class="number">7.</span>],</span><br><span class="line">   .....:                     <span class="string">&#x27;b&#x27;</span>: [np.nan, <span class="number">3.</span>, <span class="number">4.</span>, <span class="number">6.</span>, <span class="number">8.</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">117</span>]: df1</span><br><span class="line">Out[<span class="number">117</span>]: </span><br><span class="line">     a    b   c</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  NaN   <span class="number">2</span></span><br><span class="line"><span class="number">1</span>  NaN  <span class="number">2.0</span>   <span class="number">6</span></span><br><span class="line"><span class="number">2</span>  <span class="number">5.0</span>  NaN  <span class="number">10</span></span><br><span class="line"><span class="number">3</span>  NaN  <span class="number">6.0</span>  <span class="number">14</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: df2</span><br><span class="line">Out[<span class="number">118</span>]: </span><br><span class="line">     a    b</span><br><span class="line"><span class="number">0</span>  <span class="number">5.0</span>  NaN</span><br><span class="line"><span class="number">1</span>  <span class="number">4.0</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">2</span>  NaN  <span class="number">4.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3.0</span>  <span class="number">6.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">7.0</span>  <span class="number">8.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: df1.combine_first(df2)</span><br><span class="line">Out[<span class="number">119</span>]: </span><br><span class="line">     a    b     c</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  NaN   <span class="number">2.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">4.0</span>  <span class="number">2.0</span>   <span class="number">6.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">5.0</span>  <span class="number">4.0</span>  <span class="number">10.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3.0</span>  <span class="number">6.0</span>  <span class="number">14.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">7.0</span>  <span class="number">8.0</span>   NaN</span><br></pre></td></tr></table></figure></p>
<h1><span id="83-重塑和轴向旋转">8.3 重塑和轴向旋转</span></h1><p>有许多用于重新排列表格型数据的基础运算。这些函数也称作重塑（reshape）或轴向旋转（pivot）运算。</p>
<h2><span id="重塑层次化索引">重塑层次化索引</span></h2><p>层次化索引为DataFrame数据的重排任务提供了一种具有良好一致性的方式。主要功能有二：</p>
<ul>
<li>stack：将数据的列“旋转”为行。</li>
<li>unstack：将数据的行“旋转”为列。</li>
</ul>
<p>我将通过一系列的范例来讲解这些操作。接下来看一个简单的DataFrame，其中的行列索引均为字符串数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">120</span>]: data = pd.DataFrame(np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>)),</span><br><span class="line">   .....:                     index=pd.Index([<span class="string">&#x27;Ohio&#x27;</span>,<span class="string">&#x27;Colorado&#x27;</span>], name=<span class="string">&#x27;state&#x27;</span>),</span><br><span class="line">   .....:                     columns=pd.Index([<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>],</span><br><span class="line">   .....:                     name=<span class="string">&#x27;number&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: data</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line">number    one  two  three</span><br><span class="line">state                    </span><br><span class="line">Ohio        <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span></span><br><span class="line">Colorado    <span class="number">3</span>    <span class="number">4</span>      <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p>对该数据使用stack方法即可将列转换为行，得到一个Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">122</span>]: result = data.stack()</span><br><span class="line"></span><br><span class="line">In [<span class="number">123</span>]: result</span><br><span class="line">Out[<span class="number">123</span>]: </span><br><span class="line">state     number</span><br><span class="line">Ohio      one       <span class="number">0</span></span><br><span class="line">          two       <span class="number">1</span></span><br><span class="line">          three     <span class="number">2</span></span><br><span class="line">Colorado  one       <span class="number">3</span></span><br><span class="line">          two       <span class="number">4</span></span><br><span class="line">          three     <span class="number">5</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>对于一个层次化索引的Series，你可以用unstack将其重排为一个DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">124</span>]: result.unstack()</span><br><span class="line">Out[<span class="number">124</span>]: </span><br><span class="line">number    one  two  three</span><br><span class="line">state                    </span><br><span class="line">Ohio        <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span></span><br><span class="line">Colorado    <span class="number">3</span>    <span class="number">4</span>      <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p>默认情况下，unstack操作的是最内层（stack也是如此）。传入分层级别的编号或名称即可对其它级别进行unstack操作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">125</span>]: result.unstack(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">125</span>]: </span><br><span class="line">state   Ohio  Colorado</span><br><span class="line">number                </span><br><span class="line">one        <span class="number">0</span>         <span class="number">3</span></span><br><span class="line">two        <span class="number">1</span>         <span class="number">4</span></span><br><span class="line">three      <span class="number">2</span>         <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">126</span>]: result.unstack(<span class="string">&#x27;state&#x27;</span>)</span><br><span class="line">Out[<span class="number">126</span>]: </span><br><span class="line">state   Ohio  Colorado</span><br><span class="line">number                </span><br><span class="line">one        <span class="number">0</span>         <span class="number">3</span></span><br><span class="line">two        <span class="number">1</span>         <span class="number">4</span></span><br><span class="line">three      <span class="number">2</span>         <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p>如果不是所有的级别值都能在各分组中找到的话，则unstack操作可能会引入缺失数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">127</span>]: s1 = pd.Series([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">128</span>]: s2 = pd.Series([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], index=[<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: data2 = pd.concat([s1, s2], keys=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">130</span>]: data2</span><br><span class="line">Out[<span class="number">130</span>]: </span><br><span class="line">one  a    <span class="number">0</span></span><br><span class="line">     b    <span class="number">1</span></span><br><span class="line">     c    <span class="number">2</span></span><br><span class="line">     d    <span class="number">3</span></span><br><span class="line">two  c    <span class="number">4</span></span><br><span class="line">     d    <span class="number">5</span></span><br><span class="line">     e    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">131</span>]: data2.unstack()</span><br><span class="line">Out[<span class="number">131</span>]: </span><br><span class="line">       a    b    c    d    e</span><br><span class="line">one  <span class="number">0.0</span>  <span class="number">1.0</span>  <span class="number">2.0</span>  <span class="number">3.0</span>  NaN</span><br><span class="line">two  NaN  NaN  <span class="number">4.0</span>  <span class="number">5.0</span>  <span class="number">6.0</span></span><br></pre></td></tr></table></figure></p>
<p>stack默认会滤除缺失数据，因此该运算是可逆的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">132</span>]: data2.unstack()</span><br><span class="line">Out[<span class="number">132</span>]: </span><br><span class="line">       a    b    c    d    e</span><br><span class="line">one  <span class="number">0.0</span>  <span class="number">1.0</span>  <span class="number">2.0</span>  <span class="number">3.0</span>  NaN</span><br><span class="line">two  NaN  NaN  <span class="number">4.0</span>  <span class="number">5.0</span>  <span class="number">6.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">133</span>]: data2.unstack().stack()</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">one  a    <span class="number">0.0</span></span><br><span class="line">     b    <span class="number">1.0</span></span><br><span class="line">     c    <span class="number">2.0</span></span><br><span class="line">     d    <span class="number">3.0</span></span><br><span class="line">two  c    <span class="number">4.0</span></span><br><span class="line">     d    <span class="number">5.0</span></span><br><span class="line">     e    <span class="number">6.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: data2.unstack().stack(dropna=<span class="literal">False</span>)</span><br><span class="line">Out[<span class="number">134</span>]: </span><br><span class="line">one  a    <span class="number">0.0</span></span><br><span class="line">     b    <span class="number">1.0</span></span><br><span class="line">     c    <span class="number">2.0</span></span><br><span class="line">     d    <span class="number">3.0</span></span><br><span class="line">     e    NaN</span><br><span class="line">two  a    NaN</span><br><span class="line">     b    NaN</span><br><span class="line">     c    <span class="number">4.0</span></span><br><span class="line">     d    <span class="number">5.0</span></span><br><span class="line">     e    <span class="number">6.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>在对DataFrame进行unstack操作时，作为旋转轴的级别将会成为结果中的最低级别：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">135</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;left&#x27;</span>: result, <span class="string">&#x27;right&#x27;</span>: result + <span class="number">5</span>&#125;,</span><br><span class="line">   .....:                   columns=pd.Index([<span class="string">&#x27;left&#x27;</span>, <span class="string">&#x27;right&#x27;</span>], name=<span class="string">&#x27;side&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: df</span><br><span class="line">Out[<span class="number">136</span>]: </span><br><span class="line">side             left  right</span><br><span class="line">state    number             </span><br><span class="line">Ohio     one        <span class="number">0</span>      <span class="number">5</span></span><br><span class="line">         two        <span class="number">1</span>      <span class="number">6</span></span><br><span class="line">         three      <span class="number">2</span>      <span class="number">7</span></span><br><span class="line">Colorado one        <span class="number">3</span>      <span class="number">8</span></span><br><span class="line">         two        <span class="number">4</span>      <span class="number">9</span></span><br><span class="line">         three      <span class="number">5</span>     <span class="number">10</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">137</span>]: df.unstack(<span class="string">&#x27;state&#x27;</span>)</span><br><span class="line">Out[<span class="number">137</span>]: </span><br><span class="line">side   left          right</span><br><span class="line">state  Ohio Colorado  Ohio Colorado</span><br><span class="line">number                             </span><br><span class="line">one       <span class="number">0</span>        <span class="number">3</span>     <span class="number">5</span>        <span class="number">8</span></span><br><span class="line">two       <span class="number">1</span>        <span class="number">4</span>     <span class="number">6</span>        <span class="number">9</span></span><br><span class="line">three     <span class="number">2</span>        <span class="number">5</span>     <span class="number">7</span>       <span class="number">10</span></span><br></pre></td></tr></table></figure></p>
<p>当调用stack，我们可以指明轴的名字：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">138</span>]: df.unstack(<span class="string">&#x27;state&#x27;</span>).stack(<span class="string">&#x27;side&#x27;</span>)</span><br><span class="line">Out[<span class="number">138</span>]: </span><br><span class="line">state         Colorado  Ohio</span><br><span class="line">number side                 </span><br><span class="line">one    left          <span class="number">3</span>     <span class="number">0</span></span><br><span class="line">       right         <span class="number">8</span>     <span class="number">5</span></span><br><span class="line">two    left          <span class="number">4</span>     <span class="number">1</span></span><br><span class="line">       right         <span class="number">9</span>     <span class="number">6</span></span><br><span class="line">three  left          <span class="number">5</span>     <span class="number">2</span></span><br><span class="line">       right        <span class="number">10</span>     <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="将长格式旋转为宽格式">将“长格式”旋转为“宽格式”</span></h2><p>多个时间序列数据通常是以所谓的“长格式”（long）或“堆叠格式”（stacked）存储在数据库和CSV中的。我们先加载一些示例数据，做一些时间序列规整和数据清洗：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">139</span>]: data = pd.read_csv(<span class="string">&#x27;examples/macrodata.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: data.head()</span><br><span class="line">Out[<span class="number">140</span>]: </span><br><span class="line">     year  quarter   realgdp  realcons  realinv  realgovt  realdpi    cpi  \</span><br><span class="line"><span class="number">0</span>  <span class="number">1959.0</span>      <span class="number">1.0</span>  <span class="number">2710.349</span>    <span class="number">1707.4</span>  <span class="number">286.898</span>   <span class="number">470.045</span>   <span class="number">1886.9</span>  <span class="number">28.98</span>   </span><br><span class="line"><span class="number">1</span>  <span class="number">1959.0</span>      <span class="number">2.0</span>  <span class="number">2778.801</span>    <span class="number">1733.7</span>  <span class="number">310.859</span>   <span class="number">481.301</span>   <span class="number">1919.7</span>  <span class="number">29.15</span>   </span><br><span class="line"><span class="number">2</span>  <span class="number">1959.0</span>      <span class="number">3.0</span>  <span class="number">2775.488</span>    <span class="number">1751.8</span>  <span class="number">289.226</span>   <span class="number">491.260</span>   <span class="number">1916.4</span>  <span class="number">29.35</span>   </span><br><span class="line"><span class="number">3</span>  <span class="number">1959.0</span>      <span class="number">4.0</span>  <span class="number">2785.204</span>    <span class="number">1753.7</span>  <span class="number">299.356</span>   <span class="number">484.052</span>   <span class="number">1931.3</span>  <span class="number">29.37</span>   </span><br><span class="line"><span class="number">4</span>  <span class="number">1960.0</span>      <span class="number">1.0</span>  <span class="number">2847.699</span>    <span class="number">1770.5</span>  <span class="number">331.722</span>   <span class="number">462.199</span>   <span class="number">1955.5</span>  <span class="number">29.54</span>   </span><br><span class="line">      m1  tbilrate  unemp      pop  infl  realint  </span><br><span class="line"><span class="number">0</span>  <span class="number">139.7</span>      <span class="number">2.82</span>    <span class="number">5.8</span>  <span class="number">177.146</span>  <span class="number">0.00</span>     <span class="number">0.00</span></span><br><span class="line"><span class="number">1</span>  <span class="number">141.7</span>      <span class="number">3.08</span>    <span class="number">5.1</span>  <span class="number">177.830</span>  <span class="number">2.34</span>     <span class="number">0.74</span>  </span><br><span class="line"><span class="number">2</span>  <span class="number">140.5</span>      <span class="number">3.82</span>    <span class="number">5.3</span>  <span class="number">178.657</span>  <span class="number">2.74</span>     <span class="number">1.09</span>  </span><br><span class="line"><span class="number">3</span>  <span class="number">140.0</span>      <span class="number">4.33</span>    <span class="number">5.6</span>  <span class="number">179.386</span>  <span class="number">0.27</span>     <span class="number">4.06</span>  </span><br><span class="line"><span class="number">4</span>  <span class="number">139.6</span>      <span class="number">3.50</span>    <span class="number">5.2</span>  <span class="number">180.007</span>  <span class="number">2.31</span>     <span class="number">1.19</span>  </span><br><span class="line"></span><br><span class="line">In [<span class="number">141</span>]: periods = pd.PeriodIndex(year=data.year, quarter=data.quarter,</span><br><span class="line">   .....:                          name=<span class="string">&#x27;date&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">142</span>]: columns = pd.Index([<span class="string">&#x27;realgdp&#x27;</span>, <span class="string">&#x27;infl&#x27;</span>, <span class="string">&#x27;unemp&#x27;</span>], name=<span class="string">&#x27;item&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">143</span>]: data = data.reindex(columns=columns)</span><br><span class="line"></span><br><span class="line">In [<span class="number">144</span>]: data.index = periods.to_timestamp(<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;end&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">145</span>]: ldata = data.stack().reset_index().rename(columns=&#123;<span class="number">0</span>: <span class="string">&#x27;value&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure></p>
<p>这就是多个时间序列（或者其它带有两个或多个键的可观察数据，这里，我们的键是date和item）的长格式。表中的每行代表一次观察。</p>
<p>关系型数据库（如MySQL）中的数据经常都是这样存储的，因为固定架构（即列名和数据类型）有一个好处：随着表中数据的添加，item列中的值的种类能够增加。在前面的例子中，date和item通常就是主键（用关系型数据库的说法），不仅提供了关系完整性，而且提供了更为简单的查询支持。有的情况下，使用这样的数据会很麻烦，你可能会更喜欢DataFrame，不同的item值分别形成一列，date列中的时间戳则用作索引。DataFrame的pivot方法完全可以实现这个转换：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">147</span>]: pivoted = ldata.pivot(<span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;item&#x27;</span>, <span class="string">&#x27;value&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: pivoted</span><br><span class="line">Out[<span class="number">148</span>]: </span><br><span class="line">item        infl    realgdp  unemp</span><br><span class="line">date                              </span><br><span class="line"><span class="number">1959</span>-03-<span class="number">31</span>  <span class="number">0.00</span>   <span class="number">2710.349</span>    <span class="number">5.8</span></span><br><span class="line"><span class="number">1959</span>-06-<span class="number">30</span>  <span class="number">2.34</span>   <span class="number">2778.801</span>    <span class="number">5.1</span></span><br><span class="line"><span class="number">1959</span>-09-<span class="number">30</span>  <span class="number">2.74</span>   <span class="number">2775.488</span>    <span class="number">5.3</span></span><br><span class="line"><span class="number">1959</span>-<span class="number">12</span>-<span class="number">31</span>  <span class="number">0.27</span>   <span class="number">2785.204</span>    <span class="number">5.6</span></span><br><span class="line"><span class="number">1960</span>-03-<span class="number">31</span>  <span class="number">2.31</span>   <span class="number">2847.699</span>    <span class="number">5.2</span></span><br><span class="line"><span class="number">1960</span>-06-<span class="number">30</span>  <span class="number">0.14</span>   <span class="number">2834.390</span>    <span class="number">5.2</span></span><br><span class="line"><span class="number">1960</span>-09-<span class="number">30</span>  <span class="number">2.70</span>   <span class="number">2839.022</span>    <span class="number">5.6</span></span><br><span class="line"><span class="number">1960</span>-<span class="number">12</span>-<span class="number">31</span>  <span class="number">1.21</span>   <span class="number">2802.616</span>    <span class="number">6.3</span></span><br><span class="line"><span class="number">1961</span>-03-<span class="number">31</span> -<span class="number">0.40</span>   <span class="number">2819.264</span>    <span class="number">6.8</span></span><br><span class="line"><span class="number">1961</span>-06-<span class="number">30</span>  <span class="number">1.47</span>   <span class="number">2872.005</span>    <span class="number">7.0</span></span><br><span class="line"><span class="meta">... </span>         ...        ...    ...</span><br><span class="line"><span class="number">2007</span>-06-<span class="number">30</span>  <span class="number">2.75</span>  <span class="number">13203.977</span>    <span class="number">4.5</span></span><br><span class="line"><span class="number">2007</span>-09-<span class="number">30</span>  <span class="number">3.45</span>  <span class="number">13321.109</span>    <span class="number">4.7</span></span><br><span class="line"><span class="number">2007</span>-<span class="number">12</span>-<span class="number">31</span>  <span class="number">6.38</span>  <span class="number">13391.249</span>    <span class="number">4.8</span></span><br><span class="line"><span class="number">2008</span>-03-<span class="number">31</span>  <span class="number">2.82</span>  <span class="number">13366.865</span>    <span class="number">4.9</span></span><br><span class="line"><span class="number">2008</span>-06-<span class="number">30</span>  <span class="number">8.53</span>  <span class="number">13415.266</span>    <span class="number">5.4</span></span><br><span class="line"><span class="number">2008</span>-09-<span class="number">30</span> -<span class="number">3.16</span>  <span class="number">13324.600</span>    <span class="number">6.0</span></span><br><span class="line"><span class="number">2008</span>-<span class="number">12</span>-<span class="number">31</span> -<span class="number">8.79</span>  <span class="number">13141.920</span>    <span class="number">6.9</span></span><br><span class="line"><span class="number">2009</span>-03-<span class="number">31</span>  <span class="number">0.94</span>  <span class="number">12925.410</span>    <span class="number">8.1</span></span><br><span class="line"><span class="number">2009</span>-06-<span class="number">30</span>  <span class="number">3.37</span>  <span class="number">12901.504</span>    <span class="number">9.2</span></span><br><span class="line"><span class="number">2009</span>-09-<span class="number">30</span>  <span class="number">3.56</span>  <span class="number">12990.341</span>    <span class="number">9.6</span></span><br><span class="line">[<span class="number">203</span> rows x <span class="number">3</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>前两个传递的值分别用作行和列索引，最后一个可选值则是用于填充DataFrame的数据列。假设有两个需要同时重塑的数据列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">149</span>]: ldata[<span class="string">&#x27;value2&#x27;</span>] = np.random.randn(<span class="built_in">len</span>(ldata))</span><br><span class="line"></span><br><span class="line">In [<span class="number">150</span>]: ldata[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">150</span>]: </span><br><span class="line">        date     item     value    value2</span><br><span class="line"><span class="number">0</span> <span class="number">1959</span>-03-<span class="number">31</span>  realgdp  <span class="number">2710.349</span>  <span class="number">0.523772</span></span><br><span class="line"><span class="number">1</span> <span class="number">1959</span>-03-<span class="number">31</span>     infl     <span class="number">0.000</span>  <span class="number">0.000940</span></span><br><span class="line"><span class="number">2</span> <span class="number">1959</span>-03-<span class="number">31</span>    unemp     <span class="number">5.800</span>  <span class="number">1.343810</span></span><br><span class="line"><span class="number">3</span> <span class="number">1959</span>-06-<span class="number">30</span>  realgdp  <span class="number">2778.801</span> -<span class="number">0.713544</span></span><br><span class="line"><span class="number">4</span> <span class="number">1959</span>-06-<span class="number">30</span>     infl     <span class="number">2.340</span> -<span class="number">0.831154</span></span><br><span class="line"><span class="number">5</span> <span class="number">1959</span>-06-<span class="number">30</span>    unemp     <span class="number">5.100</span> -<span class="number">2.370232</span></span><br><span class="line"><span class="number">6</span> <span class="number">1959</span>-09-<span class="number">30</span>  realgdp  <span class="number">2775.488</span> -<span class="number">1.860761</span></span><br><span class="line"><span class="number">7</span> <span class="number">1959</span>-09-<span class="number">30</span>     infl     <span class="number">2.740</span> -<span class="number">0.860757</span></span><br><span class="line"><span class="number">8</span> <span class="number">1959</span>-09-<span class="number">30</span>    unemp     <span class="number">5.300</span>  <span class="number">0.560145</span></span><br><span class="line"><span class="number">9</span> <span class="number">1959</span>-<span class="number">12</span>-<span class="number">31</span>  realgdp  <span class="number">2785.204</span> -<span class="number">1.265934</span></span><br></pre></td></tr></table></figure></p>
<p>如果忽略最后一个参数，得到的DataFrame就会带有层次化的列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">151</span>]: pivoted = ldata.pivot(<span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;item&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">152</span>]: pivoted[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">152</span>]: </span><br><span class="line">           value                    value2                    </span><br><span class="line">item        infl   realgdp unemp      infl   realgdp     unemp</span><br><span class="line">date                                                          </span><br><span class="line"><span class="number">1959</span>-03-<span class="number">31</span>  <span class="number">0.00</span>  <span class="number">2710.349</span>   <span class="number">5.8</span>  <span class="number">0.000940</span>  <span class="number">0.523772</span>  <span class="number">1.343810</span></span><br><span class="line"><span class="number">1959</span>-06-<span class="number">30</span>  <span class="number">2.34</span>  <span class="number">2778.801</span>   <span class="number">5.1</span> -<span class="number">0.831154</span> -<span class="number">0.713544</span> -<span class="number">2.370232</span></span><br><span class="line"><span class="number">1959</span>-09-<span class="number">30</span>  <span class="number">2.74</span>  <span class="number">2775.488</span>   <span class="number">5.3</span> -<span class="number">0.860757</span> -<span class="number">1.860761</span>  <span class="number">0.560145</span></span><br><span class="line"><span class="number">1959</span>-<span class="number">12</span>-<span class="number">31</span>  <span class="number">0.27</span>  <span class="number">2785.204</span>   <span class="number">5.6</span>  <span class="number">0.119827</span> -<span class="number">1.265934</span> -<span class="number">1.063512</span></span><br><span class="line"><span class="number">1960</span>-03-<span class="number">31</span>  <span class="number">2.31</span>  <span class="number">2847.699</span>   <span class="number">5.2</span> -<span class="number">2.359419</span>  <span class="number">0.332883</span> -<span class="number">0.199543</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">153</span>]: pivoted[<span class="string">&#x27;value&#x27;</span>][:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">153</span>]: </span><br><span class="line">item        infl   realgdp  unemp</span><br><span class="line">date                             </span><br><span class="line"><span class="number">1959</span>-03-<span class="number">31</span>  <span class="number">0.00</span>  <span class="number">2710.349</span>    <span class="number">5.8</span></span><br><span class="line"><span class="number">1959</span>-06-<span class="number">30</span>  <span class="number">2.34</span>  <span class="number">2778.801</span>    <span class="number">5.1</span></span><br><span class="line"><span class="number">1959</span>-09-<span class="number">30</span>  <span class="number">2.74</span>  <span class="number">2775.488</span>    <span class="number">5.3</span></span><br><span class="line"><span class="number">1959</span>-<span class="number">12</span>-<span class="number">31</span>  <span class="number">0.27</span>  <span class="number">2785.204</span>    <span class="number">5.6</span></span><br><span class="line"><span class="number">1960</span>-03-<span class="number">31</span>  <span class="number">2.31</span>  <span class="number">2847.699</span>    <span class="number">5.2</span></span><br></pre></td></tr></table></figure></p>
<p>注意，pivot其实就是用set_index创建层次化索引，再用unstack重塑：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">154</span>]: unstacked = ldata.set_index([<span class="string">&#x27;date&#x27;</span>, <span class="string">&#x27;item&#x27;</span>]).unstack(<span class="string">&#x27;item&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">155</span>]: unstacked[:<span class="number">7</span>]</span><br><span class="line">Out[<span class="number">155</span>]: </span><br><span class="line">           value                    value2                    </span><br><span class="line">item        infl   realgdp unemp      infl   realgdp     unemp</span><br><span class="line">date                                                          </span><br><span class="line"><span class="number">1959</span>-03-<span class="number">31</span>  <span class="number">0.00</span>  <span class="number">2710.349</span>   <span class="number">5.8</span>  <span class="number">0.000940</span>  <span class="number">0.523772</span>  <span class="number">1.343810</span></span><br><span class="line"><span class="number">1959</span>-06-<span class="number">30</span>  <span class="number">2.34</span>  <span class="number">2778.801</span>   <span class="number">5.1</span> -<span class="number">0.831154</span> -<span class="number">0.713544</span> -<span class="number">2.370232</span></span><br><span class="line"><span class="number">1959</span>-09-<span class="number">30</span>  <span class="number">2.74</span>  <span class="number">2775.488</span>   <span class="number">5.3</span> -<span class="number">0.860757</span> -<span class="number">1.860761</span>  <span class="number">0.560145</span></span><br><span class="line"><span class="number">1959</span>-<span class="number">12</span>-<span class="number">31</span>  <span class="number">0.27</span>  <span class="number">2785.204</span>   <span class="number">5.6</span>  <span class="number">0.119827</span> -<span class="number">1.265934</span> -<span class="number">1.063512</span></span><br><span class="line"><span class="number">1960</span>-03-<span class="number">31</span>  <span class="number">2.31</span>  <span class="number">2847.699</span>   <span class="number">5.2</span> -<span class="number">2.359419</span>  <span class="number">0.332883</span> -<span class="number">0.199543</span></span><br><span class="line"><span class="number">1960</span>-06-<span class="number">30</span>  <span class="number">0.14</span>  <span class="number">2834.390</span>   <span class="number">5.2</span> -<span class="number">0.970736</span> -<span class="number">1.541996</span> -<span class="number">1.307030</span></span><br><span class="line"><span class="number">1960</span>-09-<span class="number">30</span>  <span class="number">2.70</span>  <span class="number">2839.022</span>   <span class="number">5.6</span>  <span class="number">0.377984</span>  <span class="number">0.286350</span> -<span class="number">0.753887</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="将宽格式旋转为长格式">将“宽格式”旋转为“长格式”</span></h2><p>旋转DataFrame的逆运算是pandas.melt。它不是将一列转换到多个新的DataFrame，而是合并多个列成为一个，产生一个比输入长的DataFrame。看一个例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">157</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>],</span><br><span class="line">   .....:                    <span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   .....:                    <span class="string">&#x27;B&#x27;</span>: [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">   .....:                    <span class="string">&#x27;C&#x27;</span>: [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">158</span>]: df</span><br><span class="line">Out[<span class="number">158</span>]: </span><br><span class="line">   A  B  C  key</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span>  foo</span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span>  bar</span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span>  baz</span><br></pre></td></tr></table></figure></p>
<p>key列可能是分组指标，其它的列是数据值。当使用pandas.melt，我们必须指明哪些列是分组指标。下面使用key作为唯一的分组指标：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">159</span>]: melted = pd.melt(df, [<span class="string">&#x27;key&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">160</span>]: melted</span><br><span class="line">Out[<span class="number">160</span>]: </span><br><span class="line">   key variable  value</span><br><span class="line"><span class="number">0</span>  foo        A      <span class="number">1</span></span><br><span class="line"><span class="number">1</span>  bar        A      <span class="number">2</span></span><br><span class="line"><span class="number">2</span>  baz        A      <span class="number">3</span></span><br><span class="line"><span class="number">3</span>  foo        B      <span class="number">4</span></span><br><span class="line"><span class="number">4</span>  bar        B      <span class="number">5</span></span><br><span class="line"><span class="number">5</span>  baz        B      <span class="number">6</span></span><br><span class="line"><span class="number">6</span>  foo        C      <span class="number">7</span></span><br><span class="line"><span class="number">7</span>  bar        C      <span class="number">8</span></span><br><span class="line"><span class="number">8</span>  baz        C      <span class="number">9</span></span><br></pre></td></tr></table></figure></p>
<p>使用pivot，可以重塑回原来的样子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">161</span>]: reshaped = melted.pivot(<span class="string">&#x27;key&#x27;</span>, <span class="string">&#x27;variable&#x27;</span>, <span class="string">&#x27;value&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: reshaped</span><br><span class="line">Out[<span class="number">162</span>]: </span><br><span class="line">variable  A  B  C</span><br><span class="line">key              </span><br><span class="line">bar       <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line">baz       <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line">foo       <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<p>因为pivot的结果从列创建了一个索引，用作行标签，我们可以使用reset_index将数据移回列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">163</span>]: reshaped.reset_index()</span><br><span class="line">Out[<span class="number">163</span>]: </span><br><span class="line">variable  key  A  B  C</span><br><span class="line"><span class="number">0</span>         bar  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line"><span class="number">1</span>         baz  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line"><span class="number">2</span>         foo  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<p>你还可以指定列的子集，作为值的列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">164</span>]: pd.melt(df, id_vars=[<span class="string">&#x27;key&#x27;</span>], value_vars=[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>])</span><br><span class="line">Out[<span class="number">164</span>]: </span><br><span class="line">   key variable  value</span><br><span class="line"><span class="number">0</span>  foo        A      <span class="number">1</span></span><br><span class="line"><span class="number">1</span>  bar        A      <span class="number">2</span></span><br><span class="line"><span class="number">2</span>  baz        A      <span class="number">3</span></span><br><span class="line"><span class="number">3</span>  foo        B      <span class="number">4</span></span><br><span class="line"><span class="number">4</span>  bar        B      <span class="number">5</span></span><br><span class="line"><span class="number">5</span>  baz        B      <span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<p>pandas.melt也可以不用分组指标：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">165</span>]: pd.melt(df, value_vars=[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>])</span><br><span class="line">Out[<span class="number">165</span>]: </span><br><span class="line">  variable  value</span><br><span class="line"><span class="number">0</span>        A      <span class="number">1</span></span><br><span class="line"><span class="number">1</span>        A      <span class="number">2</span></span><br><span class="line"><span class="number">2</span>        A      <span class="number">3</span></span><br><span class="line"><span class="number">3</span>        B      <span class="number">4</span></span><br><span class="line"><span class="number">4</span>        B      <span class="number">5</span></span><br><span class="line"><span class="number">5</span>        B      <span class="number">6</span></span><br><span class="line"><span class="number">6</span>        C      <span class="number">7</span></span><br><span class="line"><span class="number">7</span>        C      <span class="number">8</span></span><br><span class="line"><span class="number">8</span>        C      <span class="number">9</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">166</span>]: pd.melt(df, value_vars=[<span class="string">&#x27;key&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>])</span><br><span class="line">Out[<span class="number">166</span>]: </span><br><span class="line">  variable value</span><br><span class="line"><span class="number">0</span>      key   foo</span><br><span class="line"><span class="number">1</span>      key   bar</span><br><span class="line"><span class="number">2</span>      key   baz</span><br><span class="line"><span class="number">3</span>        A     <span class="number">1</span></span><br><span class="line"><span class="number">4</span>        A     <span class="number">2</span></span><br><span class="line"><span class="number">5</span>        A     <span class="number">3</span></span><br><span class="line"><span class="number">6</span>        B     <span class="number">4</span></span><br><span class="line"><span class="number">7</span>        B     <span class="number">5</span></span><br><span class="line"><span class="number">8</span>        B     <span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="84-总结">8.4 总结</span></h1><p>现在你已经掌握了pandas数据导入、清洗、重塑，我们可以进一步学习matplotlib数据可视化。我们在稍后会回到pandas，学习更高级的分析。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-7.数据清洗</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-7-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在数据分析和建模的过程中，相当多的时间要用在数据准备上：加载、清理、转换以及重塑。这些工作会占到分析师时间的80%或更多。有时，存储在文件和数据库中的数据的格式不适合某个特定的任务。许多研究者都选择使用通用编程语言（如Python、Perl、R或Java）或UNIX文本处理工具（如sed或awk）对数据格式进行专门处理。幸运的是，pandas和内置的Python标准库提供了一组高级的、灵活的、快速的工具，可以让你轻松地将数据规整为想要的格式。</p>
<span id="more"></span>
<p>如果你发现了一种本书或pandas库中没有的数据操作方式，请在邮件列表或GitHub网站上提出。实际上，pandas的许多设计和实现都是由真实应用的需求所驱动的。</p>
<p>在本章中，我会讨论处理缺失数据、重复数据、字符串操作和其它分析数据转换的工具。下一章，我会关注于用多种方法合并、重塑数据集。</p>
<h1><span id="71-处理缺失数据">7.1 处理缺失数据</span></h1><p>在许多数据分析工作中，缺失数据是经常发生的。pandas的目标之一就是尽量轻松地处理缺失数据。例如，pandas对象的所有描述性统计默认都不包括缺失数据。</p>
<p>缺失数据在pandas中呈现的方式有些不完美，但对于大多数用户可以保证功能正常。对于数值数据，pandas使用浮点值NaN（Not a Number）表示缺失数据。我们称其为哨兵值，可以方便的检测出来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: string_data = pd.Series([<span class="string">&#x27;aardvark&#x27;</span>, <span class="string">&#x27;artichoke&#x27;</span>, np.nan, <span class="string">&#x27;avocado&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: string_data</span><br><span class="line">Out[<span class="number">11</span>]:</span><br><span class="line"><span class="number">0</span>     aardvark</span><br><span class="line"><span class="number">1</span>    artichoke</span><br><span class="line"><span class="number">2</span>          NaN</span><br><span class="line"><span class="number">3</span>      avocado</span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: string_data.isnull()</span><br><span class="line">Out[<span class="number">12</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">1</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">3</span>    <span class="literal">False</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure></p>
<p>在pandas中，我们采用了R语言中的惯用法，即将缺失值表示为NA，它表示不可用not available。在统计应用中，NA数据可能是不存在的数据或者虽然存在，但是没有观察到（例如，数据采集中发生了问题）。当进行数据清洗以进行分析时，最好直接对缺失数据进行分析，以判断数据采集的问题或缺失数据可能导致的偏差。</p>
<p>Python内置的None值在对象数组中也可以作为NA：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: string_data[<span class="number">0</span>] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: string_data.isnull()</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line"><span class="number">0</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">1</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">3</span>    <span class="literal">False</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure></p>
<p>pandas项目中还在不断优化内部细节以更好处理缺失数据，像用户API功能，例如pandas.isnull，去除了许多恼人的细节。表7-1列出了一些关于缺失数据处理的函数。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-1a0f73e5bb26ea21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表7-1 NA处理方法"></p>
<h2><span id="滤除缺失数据">滤除缺失数据</span></h2><p>过滤掉缺失数据的办法有很多种。你可以通过pandas.isnull或布尔索引的手工方法，但dropna可能会更实用一些。对于一个Series，dropna返回一个仅含非空数据和索引值的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: <span class="keyword">from</span> numpy <span class="keyword">import</span> nan <span class="keyword">as</span> NA</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: data = pd.Series([<span class="number">1</span>, NA, <span class="number">3.5</span>, NA, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: data.dropna()</span><br><span class="line">Out[<span class="number">17</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">3.5</span></span><br><span class="line"><span class="number">4</span>    <span class="number">7.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这等价于：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: data[data.notnull()]</span><br><span class="line">Out[<span class="number">18</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">3.5</span></span><br><span class="line"><span class="number">4</span>    <span class="number">7.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>而对于DataFrame对象，事情就有点复杂了。你可能希望丢弃全NA或含有NA的行或列。dropna默认丢弃任何含有缺失值的行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">19</span>]: data = pd.DataFrame([[<span class="number">1.</span>, <span class="number">6.5</span>, <span class="number">3.</span>], [<span class="number">1.</span>, NA, NA],</span><br><span class="line">   ....:                      [NA, NA, NA], [NA, <span class="number">6.5</span>, <span class="number">3.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: cleaned = data.dropna()</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: data</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">6.5</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  NaN  NaN</span><br><span class="line"><span class="number">2</span>  NaN  NaN  NaN</span><br><span class="line"><span class="number">3</span>  NaN  <span class="number">6.5</span>  <span class="number">3.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: cleaned</span><br><span class="line">Out[<span class="number">22</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">6.5</span>  <span class="number">3.0</span></span><br></pre></td></tr></table></figure></p>
<p>传入how=’all’将只丢弃全为NA的那些行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">23</span>]: data.dropna(how=<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">6.5</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  NaN  NaN</span><br><span class="line"><span class="number">3</span>  NaN  <span class="number">6.5</span>  <span class="number">3.0</span></span><br></pre></td></tr></table></figure></p>
<p>用这种方式丢弃列，只需传入axis=1即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: data[<span class="number">4</span>] = NA</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: data</span><br><span class="line">Out[<span class="number">25</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span>   <span class="number">4</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">6.5</span>  <span class="number">3.0</span> NaN</span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  NaN  NaN NaN</span><br><span class="line"><span class="number">2</span>  NaN  NaN  NaN NaN</span><br><span class="line"><span class="number">3</span>  NaN  <span class="number">6.5</span>  <span class="number">3.0</span> NaN</span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: data.dropna(axis=<span class="number">1</span>, how=<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line">Out[<span class="number">26</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">6.5</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  NaN  NaN</span><br><span class="line"><span class="number">2</span>  NaN  NaN  NaN</span><br><span class="line"><span class="number">3</span>  NaN  <span class="number">6.5</span>  <span class="number">3.0</span></span><br></pre></td></tr></table></figure></p>
<p>另一个滤除DataFrame行的问题涉及时间序列数据。假设你只想留下一部分观测数据，可以用thresh参数实现此目的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: df = pd.DataFrame(np.random.randn(<span class="number">7</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: df.iloc[:<span class="number">4</span>, <span class="number">1</span>] = NA</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: df.iloc[:<span class="number">2</span>, <span class="number">2</span>] = NA</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: df</span><br><span class="line">Out[<span class="number">30</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>       NaN       NaN</span><br><span class="line"><span class="number">1</span> -<span class="number">0.555730</span>       NaN       NaN</span><br><span class="line"><span class="number">2</span>  <span class="number">0.092908</span>       NaN  <span class="number">0.769023</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.246435</span>       NaN -<span class="number">1.296221</span></span><br><span class="line"><span class="number">4</span>  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span></span><br><span class="line"><span class="number">6</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: df.dropna()</span><br><span class="line">Out[<span class="number">31</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">4</span>  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span></span><br><span class="line"><span class="number">6</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: df.dropna(thresh=<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">32</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.092908</span>       NaN  <span class="number">0.769023</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.246435</span>       NaN -<span class="number">1.296221</span></span><br><span class="line"><span class="number">4</span>  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span></span><br><span class="line"><span class="number">6</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="填充缺失数据">填充缺失数据</span></h2><p>你可能不想滤除缺失数据（有可能会丢弃跟它有关的其他数据），而是希望通过其他方式填补那些“空洞”。对于大多数情况而言，fillna方法是最主要的函数。通过一个常数调用fillna就会将缺失值替换为那个常数值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: df.fillna(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">33</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span></span><br><span class="line"><span class="number">1</span> -<span class="number">0.555730</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.092908</span>  <span class="number">0.000000</span>  <span class="number">0.769023</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.246435</span>  <span class="number">0.000000</span> -<span class="number">1.296221</span></span><br><span class="line"><span class="number">4</span>  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span></span><br><span class="line"><span class="number">6</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br></pre></td></tr></table></figure></p>
<p>若是通过一个字典调用fillna，就可以实现对不同的列填充不同的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: df.fillna(&#123;<span class="number">1</span>: <span class="number">0.5</span>, <span class="number">2</span>: <span class="number">0</span>&#125;)</span><br><span class="line">Out[<span class="number">34</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">0.500000</span>  <span class="number">0.000000</span></span><br><span class="line"><span class="number">1</span> -<span class="number">0.555730</span>  <span class="number">0.500000</span>  <span class="number">0.000000</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.092908</span>  <span class="number">0.500000</span>  <span class="number">0.769023</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.246435</span>  <span class="number">0.500000</span> -<span class="number">1.296221</span></span><br><span class="line"><span class="number">4</span>  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span></span><br><span class="line"><span class="number">6</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br></pre></td></tr></table></figure></p>
<p>fillna默认会返回新对象，但也可以对现有对象进行就地修改：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: _ = df.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: df</span><br><span class="line">Out[<span class="number">36</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span></span><br><span class="line"><span class="number">1</span> -<span class="number">0.555730</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.092908</span>  <span class="number">0.000000</span>  <span class="number">0.769023</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.246435</span>  <span class="number">0.000000</span> -<span class="number">1.296221</span></span><br><span class="line"><span class="number">4</span>  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span></span><br><span class="line"><span class="number">6</span>  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br></pre></td></tr></table></figure></p>
<p>对reindexing有效的那些插值方法也可用于fillna：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">37</span>]: df = pd.DataFrame(np.random.randn(<span class="number">6</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: df.iloc[<span class="number">2</span>:, <span class="number">1</span>] = NA</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: df.iloc[<span class="number">4</span>:, <span class="number">2</span>] = NA</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: df</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">0.476985</span>  <span class="number">3.248944</span> -<span class="number">1.021228</span></span><br><span class="line"><span class="number">1</span> -<span class="number">0.577087</span>  <span class="number">0.124121</span>  <span class="number">0.302614</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.523772</span>       NaN  <span class="number">1.343810</span></span><br><span class="line"><span class="number">3</span> -<span class="number">0.713544</span>       NaN -<span class="number">2.370232</span></span><br><span class="line"><span class="number">4</span> -<span class="number">1.860761</span>       NaN       NaN</span><br><span class="line"><span class="number">5</span> -<span class="number">1.265934</span>       NaN       NaN</span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: df.fillna(method=<span class="string">&#x27;ffill&#x27;</span>)</span><br><span class="line">Out[<span class="number">41</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">0.476985</span>  <span class="number">3.248944</span> -<span class="number">1.021228</span></span><br><span class="line"><span class="number">1</span> -<span class="number">0.577087</span>  <span class="number">0.124121</span>  <span class="number">0.302614</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.523772</span>  <span class="number">0.124121</span>  <span class="number">1.343810</span></span><br><span class="line"><span class="number">3</span> -<span class="number">0.713544</span>  <span class="number">0.124121</span> -<span class="number">2.370232</span></span><br><span class="line"><span class="number">4</span> -<span class="number">1.860761</span>  <span class="number">0.124121</span> -<span class="number">2.370232</span></span><br><span class="line"><span class="number">5</span> -<span class="number">1.265934</span>  <span class="number">0.124121</span> -<span class="number">2.370232</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: df.fillna(method=<span class="string">&#x27;ffill&#x27;</span>, limit=<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">42</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">0.476985</span>  <span class="number">3.248944</span> -<span class="number">1.021228</span></span><br><span class="line"><span class="number">1</span> -<span class="number">0.577087</span>  <span class="number">0.124121</span>  <span class="number">0.302614</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.523772</span>  <span class="number">0.124121</span>  <span class="number">1.343810</span></span><br><span class="line"><span class="number">3</span> -<span class="number">0.713544</span>  <span class="number">0.124121</span> -<span class="number">2.370232</span></span><br><span class="line"><span class="number">4</span> -<span class="number">1.860761</span>       NaN -<span class="number">2.370232</span></span><br><span class="line"><span class="number">5</span> -<span class="number">1.265934</span>       NaN -<span class="number">2.370232</span></span><br></pre></td></tr></table></figure></p>
<p>只要有些创新，你就可以利用fillna实现许多别的功能。比如说，你可以传入Series的平均值或中位数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">43</span>]: data = pd.Series([<span class="number">1.</span>, NA, <span class="number">3.5</span>, NA, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: data.fillna(data.mean())</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.000000</span></span><br><span class="line"><span class="number">1</span>    <span class="number">3.833333</span></span><br><span class="line"><span class="number">2</span>    <span class="number">3.500000</span></span><br><span class="line"><span class="number">3</span>    <span class="number">3.833333</span></span><br><span class="line"><span class="number">4</span>    <span class="number">7.000000</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><br>表7-2列出了fillna的参考。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-0bf235386a64c3b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-4edd39e68f4dc530.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="fillna函数参数"></p>
<h1><span id="72-数据转换">7.2 数据转换</span></h1><p>本章到目前为止介绍的都是数据的重排。另一类重要操作则是过滤、清理以及其他的转换工作。</p>
<h2><span id="移除重复数据">移除重复数据</span></h2><p>DataFrame中出现重复行有多种原因。下面就是一个例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: data = pd.DataFrame(&#123;<span class="string">&#x27;k1&#x27;</span>: [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>] * <span class="number">3</span> + [<span class="string">&#x27;two&#x27;</span>],</span><br><span class="line">   ....:                      <span class="string">&#x27;k2&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: data</span><br><span class="line">Out[<span class="number">46</span>]: </span><br><span class="line">    k1  k2</span><br><span class="line"><span class="number">0</span>  one   <span class="number">1</span></span><br><span class="line"><span class="number">1</span>  two   <span class="number">1</span></span><br><span class="line"><span class="number">2</span>  one   <span class="number">2</span></span><br><span class="line"><span class="number">3</span>  two   <span class="number">3</span></span><br><span class="line"><span class="number">4</span>  one   <span class="number">3</span></span><br><span class="line"><span class="number">5</span>  two   <span class="number">4</span></span><br><span class="line"><span class="number">6</span>  two   <span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p>DataFrame的duplicated方法返回一个布尔型Series，表示各行是否是重复行（前面出现过的行）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: data.duplicated()</span><br><span class="line">Out[<span class="number">47</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">1</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">3</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">4</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">5</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">6</span>     <span class="literal">True</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure></p>
<p>还有一个与此相关的drop_duplicates方法，它会返回一个DataFrame，重复的数组会标为False：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: data.drop_duplicates()</span><br><span class="line">Out[<span class="number">48</span>]: </span><br><span class="line">    k1  k2</span><br><span class="line"><span class="number">0</span>  one   <span class="number">1</span></span><br><span class="line"><span class="number">1</span>  two   <span class="number">1</span></span><br><span class="line"><span class="number">2</span>  one   <span class="number">2</span></span><br><span class="line"><span class="number">3</span>  two   <span class="number">3</span></span><br><span class="line"><span class="number">4</span>  one   <span class="number">3</span></span><br><span class="line"><span class="number">5</span>  two   <span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p>这两个方法默认会判断全部列，你也可以指定部分列进行重复项判断。假设我们还有一列值，且只希望根据k1列过滤重复项：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: data[<span class="string">&#x27;v1&#x27;</span>] = <span class="built_in">range</span>(<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: data.drop_duplicates([<span class="string">&#x27;k1&#x27;</span>])</span><br><span class="line">Out[<span class="number">50</span>]: </span><br><span class="line">    k1  k2  v1</span><br><span class="line"><span class="number">0</span>  one   <span class="number">1</span>   <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  two   <span class="number">1</span>   <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>duplicated和drop_duplicates默认保留的是第一个出现的值组合。传入keep=’last’则保留最后一个：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: data.drop_duplicates([<span class="string">&#x27;k1&#x27;</span>, <span class="string">&#x27;k2&#x27;</span>], keep=<span class="string">&#x27;last&#x27;</span>)</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">    k1  k2  v1</span><br><span class="line"><span class="number">0</span>  one   <span class="number">1</span>   <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  two   <span class="number">1</span>   <span class="number">1</span></span><br><span class="line"><span class="number">2</span>  one   <span class="number">2</span>   <span class="number">2</span></span><br><span class="line"><span class="number">3</span>  two   <span class="number">3</span>   <span class="number">3</span></span><br><span class="line"><span class="number">4</span>  one   <span class="number">3</span>   <span class="number">4</span></span><br><span class="line"><span class="number">6</span>  two   <span class="number">4</span>   <span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="利用函数或映射进行数据转换">利用函数或映射进行数据转换</span></h2><p>对于许多数据集，你可能希望根据数组、Series或DataFrame列中的值来实现转换工作。我们来看看下面这组有关肉类的数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">52</span>]: data = pd.DataFrame(&#123;<span class="string">&#x27;food&#x27;</span>: [<span class="string">&#x27;bacon&#x27;</span>, <span class="string">&#x27;pulled pork&#x27;</span>, <span class="string">&#x27;bacon&#x27;</span>,</span><br><span class="line">   ....:                               <span class="string">&#x27;Pastrami&#x27;</span>, <span class="string">&#x27;corned beef&#x27;</span>, <span class="string">&#x27;Bacon&#x27;</span>,</span><br><span class="line">   ....:                               <span class="string">&#x27;pastrami&#x27;</span>, <span class="string">&#x27;honey ham&#x27;</span>, <span class="string">&#x27;nova lox&#x27;</span>],</span><br><span class="line">   ....:                      <span class="string">&#x27;ounces&#x27;</span>: [<span class="number">4</span>, <span class="number">3</span>, <span class="number">12</span>, <span class="number">6</span>, <span class="number">7.5</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: data</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">          food  ounces</span><br><span class="line"><span class="number">0</span>        bacon     <span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>  pulled pork     <span class="number">3.0</span></span><br><span class="line"><span class="number">2</span>        bacon    <span class="number">12.0</span></span><br><span class="line"><span class="number">3</span>     Pastrami     <span class="number">6.0</span></span><br><span class="line"><span class="number">4</span>  corned beef     <span class="number">7.5</span></span><br><span class="line"><span class="number">5</span>        Bacon     <span class="number">8.0</span></span><br><span class="line"><span class="number">6</span>     pastrami     <span class="number">3.0</span></span><br><span class="line"><span class="number">7</span>    honey ham     <span class="number">5.0</span></span><br><span class="line"><span class="number">8</span>     nova lox     <span class="number">6.0</span></span><br></pre></td></tr></table></figure></p>
<p>假设你想要添加一列表示该肉类食物来源的动物类型。我们先编写一个不同肉类到动物的映射：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">meat_to_animal = &#123;</span><br><span class="line">  <span class="string">&#x27;bacon&#x27;</span>: <span class="string">&#x27;pig&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;pulled pork&#x27;</span>: <span class="string">&#x27;pig&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;pastrami&#x27;</span>: <span class="string">&#x27;cow&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;corned beef&#x27;</span>: <span class="string">&#x27;cow&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;honey ham&#x27;</span>: <span class="string">&#x27;pig&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;nova lox&#x27;</span>: <span class="string">&#x27;salmon&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Series的map方法可以接受一个函数或含有映射关系的字典型对象，但是这里有一个小问题，即有些肉类的首字母大写了，而另一些则没有。因此，我们还需要使用Series的str.lower方法，将各个值转换为小写：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">55</span>]: lowercased = data[<span class="string">&#x27;food&#x27;</span>].<span class="built_in">str</span>.lower()</span><br><span class="line"></span><br><span class="line">In [<span class="number">56</span>]: lowercased</span><br><span class="line">Out[<span class="number">56</span>]: </span><br><span class="line"><span class="number">0</span>          bacon</span><br><span class="line"><span class="number">1</span>    pulled pork</span><br><span class="line"><span class="number">2</span>          bacon</span><br><span class="line"><span class="number">3</span>       pastrami</span><br><span class="line"><span class="number">4</span>    corned beef</span><br><span class="line"><span class="number">5</span>          bacon</span><br><span class="line"><span class="number">6</span>       pastrami</span><br><span class="line"><span class="number">7</span>      honey ham</span><br><span class="line"><span class="number">8</span>       nova lox</span><br><span class="line">Name: food, dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: data[<span class="string">&#x27;animal&#x27;</span>] = lowercased.<span class="built_in">map</span>(meat_to_animal)</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: data</span><br><span class="line">Out[<span class="number">58</span>]: </span><br><span class="line">          food  ounces  animal</span><br><span class="line"><span class="number">0</span>        bacon     <span class="number">4.0</span>     pig</span><br><span class="line"><span class="number">1</span>  pulled pork     <span class="number">3.0</span>     pig</span><br><span class="line"><span class="number">2</span>        bacon    <span class="number">12.0</span>     pig</span><br><span class="line"><span class="number">3</span>     Pastrami     <span class="number">6.0</span>     cow</span><br><span class="line"><span class="number">4</span>  corned beef     <span class="number">7.5</span>     cow</span><br><span class="line"><span class="number">5</span>        Bacon     <span class="number">8.0</span>     pig</span><br><span class="line"><span class="number">6</span>     pastrami     <span class="number">3.0</span>     cow</span><br><span class="line"><span class="number">7</span>    honey ham     <span class="number">5.0</span>     pig</span><br><span class="line"><span class="number">8</span>     nova lox     <span class="number">6.0</span>  salmon</span><br></pre></td></tr></table></figure></p>
<p>我们也可以传入一个能够完成全部这些工作的函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">59</span>]: data[<span class="string">&#x27;food&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: meat_to_animal[x.lower()])</span><br><span class="line">Out[<span class="number">59</span>]: </span><br><span class="line"><span class="number">0</span>       pig</span><br><span class="line"><span class="number">1</span>       pig</span><br><span class="line"><span class="number">2</span>       pig</span><br><span class="line"><span class="number">3</span>       cow</span><br><span class="line"><span class="number">4</span>       cow</span><br><span class="line"><span class="number">5</span>       pig</span><br><span class="line"><span class="number">6</span>       cow</span><br><span class="line"><span class="number">7</span>       pig</span><br><span class="line"><span class="number">8</span>    salmon</span><br><span class="line">Name: food, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>使用map是一种实现元素级转换以及其他数据清理工作的便捷方式。</p>
<h2><span id="替换值">替换值</span></h2><p>利用fillna方法填充缺失数据可以看做值替换的一种特殊情况。前面已经看到，map可用于修改对象的数据子集，而replace则提供了一种实现该功能的更简单、更灵活的方式。我们来看看下面这个Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: data = pd.Series([<span class="number">1.</span>, -<span class="number">999.</span>, <span class="number">2.</span>, -<span class="number">999.</span>, -<span class="number">1000.</span>, <span class="number">3.</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: data</span><br><span class="line">Out[<span class="number">61</span>]: </span><br><span class="line"><span class="number">0</span>       <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    -<span class="number">999.0</span></span><br><span class="line"><span class="number">2</span>       <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>    -<span class="number">999.0</span></span><br><span class="line"><span class="number">4</span>   -<span class="number">1000.0</span></span><br><span class="line"><span class="number">5</span>       <span class="number">3.0</span></span><br></pre></td></tr></table></figure></p>
<p>-999这个值可能是一个表示缺失数据的标记值。要将其替换为pandas能够理解的NA值，我们可以利用replace来产生一个新的Series（除非传入inplace=True）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">62</span>]: data.replace(-<span class="number">999</span>, np.nan)</span><br><span class="line">Out[<span class="number">62</span>]: </span><br><span class="line"><span class="number">0</span>       <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>       NaN</span><br><span class="line"><span class="number">2</span>       <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>       NaN</span><br><span class="line"><span class="number">4</span>   -<span class="number">1000.0</span></span><br><span class="line"><span class="number">5</span>       <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>如果你希望一次性替换多个值，可以传入一个由待替换值组成的列表以及一个替换值：：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">63</span>]: data.replace([-<span class="number">999</span>, -<span class="number">1000</span>], np.nan)</span><br><span class="line">Out[<span class="number">63</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    NaN</span><br><span class="line"><span class="number">2</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>    NaN</span><br><span class="line"><span class="number">4</span>    NaN</span><br><span class="line"><span class="number">5</span>    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>要让每个值有不同的替换值，可以传递一个替换列表：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: data.replace([-<span class="number">999</span>, -<span class="number">1000</span>], [np.nan, <span class="number">0</span>])</span><br><span class="line">Out[<span class="number">64</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    NaN</span><br><span class="line"><span class="number">2</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>    NaN</span><br><span class="line"><span class="number">4</span>    <span class="number">0.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>传入的参数也可以是字典：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">65</span>]: data.replace(&#123;-<span class="number">999</span>: np.nan, -<span class="number">1000</span>: <span class="number">0</span>&#125;)</span><br><span class="line">Out[<span class="number">65</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    NaN</span><br><span class="line"><span class="number">2</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>    NaN</span><br><span class="line"><span class="number">4</span>    <span class="number">0.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：data.replace方法与data.str.replace不同，后者做的是字符串的元素级替换。我们会在后面学习Series的字符串方法。</p>
</blockquote>
<h2><span id="重命名轴索引">重命名轴索引</span></h2><p>跟Series中的值一样，轴标签也可以通过函数或映射进行转换，从而得到一个新的不同标签的对象。轴还可以被就地修改，而无需新建一个数据结构。接下来看看下面这个简单的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: data = pd.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>)),</span><br><span class="line">   ....:                     index=[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Colorado&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>],</span><br><span class="line">   ....:                     columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>])</span><br></pre></td></tr></table></figure></p>
<p>跟Series一样，轴索引也有一个map方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">67</span>]: transform = <span class="keyword">lambda</span> x: x[:<span class="number">4</span>].upper()</span><br><span class="line"></span><br><span class="line">In [<span class="number">68</span>]: data.index.<span class="built_in">map</span>(transform)</span><br><span class="line">Out[<span class="number">68</span>]: Index([<span class="string">&#x27;OHIO&#x27;</span>, <span class="string">&#x27;COLO&#x27;</span>, <span class="string">&#x27;NEW &#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>你可以将其赋值给index，这样就可以对DataFrame进行就地修改：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: data.index = data.index.<span class="built_in">map</span>(transform)</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: data</span><br><span class="line">Out[<span class="number">70</span>]:</span><br><span class="line">one  two  three  four</span><br><span class="line">OHIO    <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">COLO    <span class="number">4</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">NEW     <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<p>如果想要创建数据集的转换版（而不是修改原始数据），比较实用的方法是rename：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">71</span>]: data.rename(index=<span class="built_in">str</span>.title, columns=<span class="built_in">str</span>.upper)</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line">      ONE  TWO  THREE  FOUR</span><br><span class="line">Ohio    <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">Colo    <span class="number">4</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">New     <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<p>特别说明一下，rename可以结合字典型对象实现对部分轴标签的更新：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">72</span>]: data.rename(index=&#123;<span class="string">&#x27;OHIO&#x27;</span>: <span class="string">&#x27;INDIANA&#x27;</span>&#125;,</span><br><span class="line">   ....:             columns=&#123;<span class="string">&#x27;three&#x27;</span>: <span class="string">&#x27;peekaboo&#x27;</span>&#125;)</span><br><span class="line">Out[<span class="number">72</span>]:</span><br><span class="line">one  two  peekaboo  four</span><br><span class="line">INDIANA    <span class="number">0</span>    <span class="number">1</span>         <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">COLO       <span class="number">4</span>    <span class="number">5</span>         <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">NEW        <span class="number">8</span>    <span class="number">9</span>        <span class="number">10</span>    <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<p>rename可以实现复制DataFrame并对其索引和列标签进行赋值。如果希望就地修改某个数据集，传入inplace=True即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: data.rename(index=&#123;<span class="string">&#x27;OHIO&#x27;</span>: <span class="string">&#x27;INDIANA&#x27;</span>&#125;, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: data</span><br><span class="line">Out[<span class="number">74</span>]: </span><br><span class="line">         one  two  three  four</span><br><span class="line">INDIANA    <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">COLO       <span class="number">4</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">NEW        <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="离散化和面元划分">离散化和面元划分</span></h2><p>为了便于分析，连续数据常常被离散化或拆分为“面元”（bin）。假设有一组人员数据，而你希望将它们划分为不同的年龄组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: ages = [<span class="number">20</span>, <span class="number">22</span>, <span class="number">25</span>, <span class="number">27</span>, <span class="number">21</span>, <span class="number">23</span>, <span class="number">37</span>, <span class="number">31</span>, <span class="number">61</span>, <span class="number">45</span>, <span class="number">41</span>, <span class="number">32</span>]</span><br></pre></td></tr></table></figure></p>
<p>接下来将这些数据划分为“18到25”、“26到35”、“35到60”以及“60以上”几个面元。要实现该功能，你需要使用pandas的cut函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: bins = [<span class="number">18</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">60</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: cats = pd.cut(ages, bins)</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: cats</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line">[(<span class="number">18</span>, <span class="number">25</span>], (<span class="number">18</span>, <span class="number">25</span>], (<span class="number">18</span>, <span class="number">25</span>], (<span class="number">25</span>, <span class="number">35</span>], (<span class="number">18</span>, <span class="number">25</span>], ..., (<span class="number">25</span>, <span class="number">35</span>], (<span class="number">60</span>, <span class="number">100</span>], (<span class="number">35</span>,<span class="number">60</span>], (<span class="number">35</span>, <span class="number">60</span>], (<span class="number">25</span>, <span class="number">35</span>]]</span><br><span class="line">Length: <span class="number">12</span></span><br><span class="line">Categories (<span class="number">4</span>, interval[int64]): [(<span class="number">18</span>, <span class="number">25</span>] &lt; (<span class="number">25</span>, <span class="number">35</span>] &lt; (<span class="number">35</span>, <span class="number">60</span>] &lt; (<span class="number">60</span>, <span class="number">100</span>]]</span><br></pre></td></tr></table></figure></p>
<p>pandas返回的是一个特殊的Categorical对象。结果展示了pandas.cut划分的面元。你可以将其看做一组表示面元名称的字符串。它的底层含有一个表示不同分类名称的类型数组，以及一个codes属性中的年龄数据的标签：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">79</span>]: cats.codes</span><br><span class="line">Out[<span class="number">79</span>]: array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], dtype=int8)</span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: cats.categories</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line">IntervalIndex([(<span class="number">18</span>, <span class="number">25</span>], (<span class="number">25</span>, <span class="number">35</span>], (<span class="number">35</span>, <span class="number">60</span>], (<span class="number">60</span>, <span class="number">100</span>]]</span><br><span class="line">              closed=<span class="string">&#x27;right&#x27;</span>,</span><br><span class="line">              dtype=<span class="string">&#x27;interval[int64]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: pd.value_counts(cats)</span><br><span class="line">Out[<span class="number">81</span>]: </span><br><span class="line">(<span class="number">18</span>, <span class="number">25</span>]     <span class="number">5</span></span><br><span class="line">(<span class="number">35</span>, <span class="number">60</span>]     <span class="number">3</span></span><br><span class="line">(<span class="number">25</span>, <span class="number">35</span>]     <span class="number">3</span></span><br><span class="line">(<span class="number">60</span>, <span class="number">100</span>]    <span class="number">1</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>pd.value_counts(cats)是pandas.cut结果的面元计数。</p>
<p>跟“区间”的数学符号一样，圆括号表示开端，而方括号则表示闭端（包括）。哪边是闭端可以通过right=False进行修改：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: pd.cut(ages, [<span class="number">18</span>, <span class="number">26</span>, <span class="number">36</span>, <span class="number">61</span>, <span class="number">100</span>], right=<span class="literal">False</span>)</span><br><span class="line">Out[<span class="number">82</span>]: </span><br><span class="line">[[<span class="number">18</span>, <span class="number">26</span>), [<span class="number">18</span>, <span class="number">26</span>), [<span class="number">18</span>, <span class="number">26</span>), [<span class="number">26</span>, <span class="number">36</span>), [<span class="number">18</span>, <span class="number">26</span>), ..., [<span class="number">26</span>, <span class="number">36</span>), [<span class="number">61</span>, <span class="number">100</span>), [<span class="number">36</span>,</span><br><span class="line"> <span class="number">61</span>), [<span class="number">36</span>, <span class="number">61</span>), [<span class="number">26</span>, <span class="number">36</span>)]</span><br><span class="line">Length: <span class="number">12</span></span><br><span class="line">Categories (<span class="number">4</span>, interval[int64]): [[<span class="number">18</span>, <span class="number">26</span>) &lt; [<span class="number">26</span>, <span class="number">36</span>) &lt; [<span class="number">36</span>, <span class="number">61</span>) &lt; [<span class="number">61</span>, <span class="number">100</span>)]</span><br></pre></td></tr></table></figure></p>
<p>你可 以通过传递一个列表或数组到labels，设置自己的面元名称：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">83</span>]: group_names = [<span class="string">&#x27;Youth&#x27;</span>, <span class="string">&#x27;YoungAdult&#x27;</span>, <span class="string">&#x27;MiddleAged&#x27;</span>, <span class="string">&#x27;Senior&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: pd.cut(ages, bins, labels=group_names)</span><br><span class="line">Out[<span class="number">84</span>]: </span><br><span class="line">[Youth, Youth, Youth, YoungAdult, Youth, ..., YoungAdult, Senior, MiddleAged, Mid</span><br><span class="line">dleAged, YoungAdult]</span><br><span class="line">Length: <span class="number">12</span></span><br><span class="line">Categories (<span class="number">4</span>, <span class="built_in">object</span>): [Youth &lt; YoungAdult &lt; MiddleAged &lt; Senior]</span><br></pre></td></tr></table></figure></p>
<p>如果向cut传入的是面元的数量而不是确切的面元边界，则它会根据数据的最小值和最大值计算等长面元。下面这个例子中，我们将一些均匀分布的数据分成四组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: data = np.random.rand(<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: pd.cut(data, <span class="number">4</span>, precision=<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line">[(<span class="number">0.34</span>, <span class="number">0.55</span>], (<span class="number">0.34</span>, <span class="number">0.55</span>], (<span class="number">0.76</span>, <span class="number">0.97</span>], (<span class="number">0.76</span>, <span class="number">0.97</span>], (<span class="number">0.34</span>, <span class="number">0.55</span>], ..., (<span class="number">0.34</span></span><br><span class="line">, <span class="number">0.55</span>], (<span class="number">0.34</span>, <span class="number">0.55</span>], (<span class="number">0.55</span>, <span class="number">0.76</span>], (<span class="number">0.34</span>, <span class="number">0.55</span>], (<span class="number">0.12</span>, <span class="number">0.34</span>]]</span><br><span class="line">Length: <span class="number">20</span></span><br><span class="line">Categories (<span class="number">4</span>, interval[float64]): [(<span class="number">0.12</span>, <span class="number">0.34</span>] &lt; (<span class="number">0.34</span>, <span class="number">0.55</span>] &lt; (<span class="number">0.55</span>, <span class="number">0.76</span>] &lt; </span><br><span class="line">(<span class="number">0.76</span>, <span class="number">0.97</span>]]</span><br></pre></td></tr></table></figure></p>
<p>选项precision=2，限定小数只有两位。</p>
<p>qcut是一个非常类似于cut的函数，它可以根据样本分位数对数据进行面元划分。根据数据的分布情况，cut可能无法使各个面元中含有相同数量的数据点。而qcut由于使用的是样本分位数，因此可以得到大小基本相等的面元：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: data = np.random.randn(<span class="number">1000</span>)  <span class="comment"># Normally distributed</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: cats = pd.qcut(data, <span class="number">4</span>)  <span class="comment"># Cut into quartiles</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: cats</span><br><span class="line">Out[<span class="number">89</span>]: </span><br><span class="line">[(-<span class="number">0.0265</span>, <span class="number">0.62</span>], (<span class="number">0.62</span>, <span class="number">3.928</span>], (-<span class="number">0.68</span>, -<span class="number">0.0265</span>], (<span class="number">0.62</span>, <span class="number">3.928</span>], (-<span class="number">0.0265</span>, <span class="number">0.62</span>]</span><br><span class="line">, ..., (-<span class="number">0.68</span>, -<span class="number">0.0265</span>], (-<span class="number">0.68</span>, -<span class="number">0.0265</span>], (-<span class="number">2.95</span>, -<span class="number">0.68</span>], (<span class="number">0.62</span>, <span class="number">3.928</span>], (-<span class="number">0.68</span>,</span><br><span class="line"> -<span class="number">0.0265</span>]]</span><br><span class="line">Length: <span class="number">1000</span></span><br><span class="line">Categories (<span class="number">4</span>, interval[float64]): [(-<span class="number">2.95</span>, -<span class="number">0.68</span>] &lt; (-<span class="number">0.68</span>, -<span class="number">0.0265</span>] &lt; (-<span class="number">0.0265</span>,</span><br><span class="line"> <span class="number">0.62</span>] &lt;</span><br><span class="line">                                    (<span class="number">0.62</span>, <span class="number">3.928</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: pd.value_counts(cats)</span><br><span class="line">Out[<span class="number">90</span>]:</span><br><span class="line">(<span class="number">0.62</span>, <span class="number">3.928</span>]       <span class="number">250</span></span><br><span class="line">(-<span class="number">0.0265</span>, <span class="number">0.62</span>]     <span class="number">250</span></span><br><span class="line">(-<span class="number">0.68</span>, -<span class="number">0.0265</span>]    <span class="number">250</span></span><br><span class="line">(-<span class="number">2.95</span>, -<span class="number">0.68</span>]      <span class="number">250</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>与cut类似，你也可以传递自定义的分位数（0到1之间的数值，包含端点）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: pd.qcut(data, [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.9</span>, <span class="number">1.</span>])</span><br><span class="line">Out[<span class="number">91</span>]: </span><br><span class="line">[(-<span class="number">0.0265</span>, <span class="number">1.286</span>], (-<span class="number">0.0265</span>, <span class="number">1.286</span>], (-<span class="number">1.187</span>, -<span class="number">0.0265</span>], (-<span class="number">0.0265</span>, <span class="number">1.286</span>], (-<span class="number">0.026</span></span><br><span class="line"><span class="number">5</span>, <span class="number">1.286</span>], ..., (-<span class="number">1.187</span>, -<span class="number">0.0265</span>], (-<span class="number">1.187</span>, -<span class="number">0.0265</span>], (-<span class="number">2.95</span>, -<span class="number">1.187</span>], (-<span class="number">0.0265</span>, </span><br><span class="line"><span class="number">1.286</span>], (-<span class="number">1.187</span>, -<span class="number">0.0265</span>]]</span><br><span class="line">Length: <span class="number">1000</span></span><br><span class="line">Categories (<span class="number">4</span>, interval[float64]): [(-<span class="number">2.95</span>, -<span class="number">1.187</span>] &lt; (-<span class="number">1.187</span>, -<span class="number">0.0265</span>] &lt; (-<span class="number">0.026</span></span><br><span class="line"><span class="number">5</span>, <span class="number">1.286</span>] &lt;</span><br><span class="line">                                    (<span class="number">1.286</span>, <span class="number">3.928</span>]]</span><br></pre></td></tr></table></figure></p>
<p>本章稍后在讲解聚合和分组运算时会再次用到cut和qcut，因为这两个离散化函数对分位和分组分析非常重要。</p>
<h2><span id="检测和过滤异常值">检测和过滤异常值</span></h2><p>过滤或变换异常值（outlier）在很大程度上就是运用数组运算。来看一个含有正态分布数据的DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">92</span>]: data = pd.DataFrame(np.random.randn(<span class="number">1000</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: data.describe()</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line">                 <span class="number">0</span>            <span class="number">1</span>            <span class="number">2</span>            <span class="number">3</span></span><br><span class="line">count  <span class="number">1000.000000</span>  <span class="number">1000.000000</span>  <span class="number">1000.000000</span>  <span class="number">1000.000000</span></span><br><span class="line">mean      <span class="number">0.049091</span>     <span class="number">0.026112</span>    -<span class="number">0.002544</span>    -<span class="number">0.051827</span></span><br><span class="line">std       <span class="number">0.996947</span>     <span class="number">1.007458</span>     <span class="number">0.995232</span>     <span class="number">0.998311</span></span><br><span class="line"><span class="built_in">min</span>      -<span class="number">3.645860</span>    -<span class="number">3.184377</span>    -<span class="number">3.745356</span>    -<span class="number">3.428254</span></span><br><span class="line"><span class="number">25</span>%      -<span class="number">0.599807</span>    -<span class="number">0.612162</span>    -<span class="number">0.687373</span>    -<span class="number">0.747478</span></span><br><span class="line"><span class="number">50</span>%       <span class="number">0.047101</span>    -<span class="number">0.013609</span>    -<span class="number">0.022158</span>    -<span class="number">0.088274</span></span><br><span class="line"><span class="number">75</span>%       <span class="number">0.756646</span>     <span class="number">0.695298</span>     <span class="number">0.699046</span>     <span class="number">0.623331</span></span><br><span class="line"><span class="built_in">max</span>       <span class="number">2.653656</span>     <span class="number">3.525865</span>     <span class="number">2.735527</span>     <span class="number">3.366626</span></span><br></pre></td></tr></table></figure></p>
<p>假设你想要找出某列中绝对值大小超过3的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: col = data[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">95</span>]: col[np.<span class="built_in">abs</span>(col) &gt; <span class="number">3</span>]</span><br><span class="line">Out[<span class="number">95</span>]: </span><br><span class="line"><span class="number">41</span>    -<span class="number">3.399312</span></span><br><span class="line"><span class="number">136</span>   -<span class="number">3.745356</span></span><br><span class="line">Name: <span class="number">2</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>要选出全部含有“超过3或－3的值”的行，你可以在布尔型DataFrame中使用any方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: data[(np.<span class="built_in">abs</span>(data) &gt; <span class="number">3</span>).<span class="built_in">any</span>(<span class="number">1</span>)]</span><br><span class="line">Out[<span class="number">96</span>]: </span><br><span class="line">            <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span>         <span class="number">3</span></span><br><span class="line"><span class="number">41</span>   <span class="number">0.457246</span> -<span class="number">0.025907</span> -<span class="number">3.399312</span> -<span class="number">0.974657</span></span><br><span class="line"><span class="number">60</span>   <span class="number">1.951312</span>  <span class="number">3.260383</span>  <span class="number">0.963301</span>  <span class="number">1.201206</span></span><br><span class="line"><span class="number">136</span>  <span class="number">0.508391</span> -<span class="number">0.196713</span> -<span class="number">3.745356</span> -<span class="number">1.520113</span></span><br><span class="line"><span class="number">235</span> -<span class="number">0.242459</span> -<span class="number">3.056990</span>  <span class="number">1.918403</span> -<span class="number">0.578828</span></span><br><span class="line"><span class="number">258</span>  <span class="number">0.682841</span>  <span class="number">0.326045</span>  <span class="number">0.425384</span> -<span class="number">3.428254</span></span><br><span class="line"><span class="number">322</span>  <span class="number">1.179227</span> -<span class="number">3.184377</span>  <span class="number">1.369891</span> -<span class="number">1.074833</span></span><br><span class="line"><span class="number">544</span> -<span class="number">3.548824</span>  <span class="number">1.553205</span> -<span class="number">2.186301</span>  <span class="number">1.277104</span></span><br><span class="line"><span class="number">635</span> -<span class="number">0.578093</span>  <span class="number">0.193299</span>  <span class="number">1.397822</span>  <span class="number">3.366626</span></span><br><span class="line"><span class="number">782</span> -<span class="number">0.207434</span>  <span class="number">3.525865</span>  <span class="number">0.283070</span>  <span class="number">0.544635</span></span><br><span class="line"><span class="number">803</span> -<span class="number">3.645860</span>  <span class="number">0.255475</span> -<span class="number">0.549574</span> -<span class="number">1.907459</span></span><br></pre></td></tr></table></figure></p>
<p>根据这些条件，就可以对值进行设置。下面的代码可以将值限制在区间－3到3以内：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">97</span>]: data[np.<span class="built_in">abs</span>(data) &gt; <span class="number">3</span>] = np.sign(data) * <span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: data.describe()</span><br><span class="line">Out[<span class="number">98</span>]: </span><br><span class="line">                 <span class="number">0</span>            <span class="number">1</span>            <span class="number">2</span>            <span class="number">3</span></span><br><span class="line">count  <span class="number">1000.000000</span>  <span class="number">1000.000000</span>  <span class="number">1000.000000</span>  <span class="number">1000.000000</span></span><br><span class="line">mean      <span class="number">0.050286</span>     <span class="number">0.025567</span>    -<span class="number">0.001399</span>    -<span class="number">0.051765</span></span><br><span class="line">std       <span class="number">0.992920</span>     <span class="number">1.004214</span>     <span class="number">0.991414</span>     <span class="number">0.995761</span></span><br><span class="line"><span class="built_in">min</span>      -<span class="number">3.000000</span>    -<span class="number">3.000000</span>    -<span class="number">3.000000</span>    -<span class="number">3.000000</span></span><br><span class="line"><span class="number">25</span>%      -<span class="number">0.599807</span>    -<span class="number">0.612162</span>    -<span class="number">0.687373</span>    -<span class="number">0.747478</span></span><br><span class="line"><span class="number">50</span>%       <span class="number">0.047101</span>    -<span class="number">0.013609</span>    -<span class="number">0.022158</span>    -<span class="number">0.088274</span></span><br><span class="line"><span class="number">75</span>%       <span class="number">0.756646</span>     <span class="number">0.695298</span>     <span class="number">0.699046</span>     <span class="number">0.623331</span></span><br><span class="line"><span class="built_in">max</span>       <span class="number">2.653656</span>     <span class="number">3.000000</span>     <span class="number">2.735527</span>     <span class="number">3.000000</span></span><br></pre></td></tr></table></figure></p>
<p>根据数据的值是正还是负，np.sign(data)可以生成1和-1：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">99</span>]: np.sign(data).head()</span><br><span class="line">Out[<span class="number">99</span>]: </span><br><span class="line">     <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span>    <span class="number">3</span></span><br><span class="line"><span class="number">0</span> -<span class="number">1.0</span>  <span class="number">1.0</span> -<span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span> -<span class="number">1.0</span>  <span class="number">1.0</span> -<span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span> -<span class="number">1.0</span></span><br><span class="line"><span class="number">3</span> -<span class="number">1.0</span> -<span class="number">1.0</span>  <span class="number">1.0</span> -<span class="number">1.0</span></span><br><span class="line"><span class="number">4</span> -<span class="number">1.0</span>  <span class="number">1.0</span> -<span class="number">1.0</span> -<span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="排列和随机采样">排列和随机采样</span></h2><p>利用numpy.random.permutation函数可以轻松实现对Series或DataFrame的列的排列工作（permuting，随机重排序）。通过需要排列的轴的长度调用permutation，可产生一个表示新顺序的整数数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">100</span>]: df = pd.DataFrame(np.arange(<span class="number">5</span> * <span class="number">4</span>).reshape((<span class="number">5</span>, <span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line">In [<span class="number">101</span>]: sampler = np.random.permutation(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: sampler</span><br><span class="line">Out[<span class="number">102</span>]: array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<p>然后就可以在基于iloc的索引操作或take函数中使用该数组了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">103</span>]: df</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">    <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"><span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"><span class="number">1</span>   <span class="number">4</span>   <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span></span><br><span class="line"><span class="number">2</span>   <span class="number">8</span>   <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span></span><br><span class="line"><span class="number">3</span>  <span class="number">12</span>  <span class="number">13</span>  <span class="number">14</span>  <span class="number">15</span></span><br><span class="line"><span class="number">4</span>  <span class="number">16</span>  <span class="number">17</span>  <span class="number">18</span>  <span class="number">19</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">104</span>]: df.take(sampler)</span><br><span class="line">Out[<span class="number">104</span>]: </span><br><span class="line">    <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"><span class="number">3</span>  <span class="number">12</span>  <span class="number">13</span>  <span class="number">14</span>  <span class="number">15</span></span><br><span class="line"><span class="number">1</span>   <span class="number">4</span>   <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span></span><br><span class="line"><span class="number">4</span>  <span class="number">16</span>  <span class="number">17</span>  <span class="number">18</span>  <span class="number">19</span></span><br><span class="line"><span class="number">2</span>   <span class="number">8</span>   <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span></span><br><span class="line"><span class="number">0</span>   <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<p>如果不想用替换的方式选取随机子集，可以在Series和DataFrame上使用sample方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">105</span>]: df.sample(n=<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">105</span>]: </span><br><span class="line">    <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span></span><br><span class="line"><span class="number">3</span>  <span class="number">12</span>  <span class="number">13</span>  <span class="number">14</span>  <span class="number">15</span></span><br><span class="line"><span class="number">4</span>  <span class="number">16</span>  <span class="number">17</span>  <span class="number">18</span>  <span class="number">19</span></span><br><span class="line"><span class="number">2</span>   <span class="number">8</span>   <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span></span><br></pre></td></tr></table></figure></p>
<p>要通过替换的方式产生样本（允许重复选择），可以传递replace=True到sample：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">106</span>]: choices = pd.Series([<span class="number">5</span>, <span class="number">7</span>, -<span class="number">1</span>, <span class="number">6</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">107</span>]: draws = choices.sample(n=<span class="number">10</span>, replace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">108</span>]: draws</span><br><span class="line">Out[<span class="number">108</span>]: </span><br><span class="line"><span class="number">4</span>    <span class="number">4</span></span><br><span class="line"><span class="number">1</span>    <span class="number">7</span></span><br><span class="line"><span class="number">4</span>    <span class="number">4</span></span><br><span class="line"><span class="number">2</span>   -<span class="number">1</span></span><br><span class="line"><span class="number">0</span>    <span class="number">5</span></span><br><span class="line"><span class="number">3</span>    <span class="number">6</span></span><br><span class="line"><span class="number">1</span>    <span class="number">7</span></span><br><span class="line"><span class="number">4</span>    <span class="number">4</span></span><br><span class="line"><span class="number">0</span>    <span class="number">5</span></span><br><span class="line"><span class="number">4</span>    <span class="number">4</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<h2><span id="计算指标哑变量">计算指标/哑变量</span></h2><p>另一种常用于统计建模或机器学习的转换方式是：将分类变量（categorical variable）转换为“哑变量”或“指标矩阵”。</p>
<p>如果DataFrame的某一列中含有k个不同的值，则可以派生出一个k列矩阵或DataFrame（其值全为1和0）。pandas有一个get_dummies函数可以实现该功能（其实自己动手做一个也不难）。使用之前的一个DataFrame例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">109</span>]: df = pd.DataFrame(&#123;<span class="string">&#x27;key&#x27;</span>: [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>],</span><br><span class="line">   .....:                    <span class="string">&#x27;data1&#x27;</span>: <span class="built_in">range</span>(<span class="number">6</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: pd.get_dummies(df[<span class="string">&#x27;key&#x27;</span>])</span><br><span class="line">Out[<span class="number">110</span>]: </span><br><span class="line">   a  b  c</span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">1</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1</span>  <span class="number">0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0</span>  <span class="number">1</span>  <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>有时候，你可能想给指标DataFrame的列加上一个前缀，以便能够跟其他数据进行合并。get_dummies的prefix参数可以实现该功能：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">111</span>]: dummies = pd.get_dummies(df[<span class="string">&#x27;key&#x27;</span>], prefix=<span class="string">&#x27;key&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: df_with_dummy = df[[<span class="string">&#x27;data1&#x27;</span>]].join(dummies)</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: df_with_dummy</span><br><span class="line">Out[<span class="number">113</span>]: </span><br><span class="line">   data1  key_a  key_b  key_c</span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>      <span class="number">0</span>      <span class="number">1</span>      <span class="number">0</span></span><br><span class="line"><span class="number">1</span>      <span class="number">1</span>      <span class="number">0</span>      <span class="number">1</span>      <span class="number">0</span></span><br><span class="line"><span class="number">2</span>      <span class="number">2</span>      <span class="number">1</span>      <span class="number">0</span>      <span class="number">0</span></span><br><span class="line"><span class="number">3</span>      <span class="number">3</span>      <span class="number">0</span>      <span class="number">0</span>      <span class="number">1</span></span><br><span class="line"><span class="number">4</span>      <span class="number">4</span>      <span class="number">1</span>      <span class="number">0</span>      <span class="number">0</span></span><br><span class="line"><span class="number">5</span>      <span class="number">5</span>      <span class="number">0</span>      <span class="number">1</span>      <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>如果DataFrame中的某行同属于多个分类，则事情就会有点复杂。看一下MovieLens 1M数据集，14章会更深入地研究它：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">114</span>]: mnames = [<span class="string">&#x27;movie_id&#x27;</span>, <span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;genres&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">115</span>]: movies = pd.read_table(<span class="string">&#x27;datasets/movielens/movies.dat&#x27;</span>, sep=<span class="string">&#x27;::&#x27;</span>,</span><br><span class="line">   .....:                        header=<span class="literal">None</span>, names=mnames)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: movies[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">116</span>]: </span><br><span class="line">   movie_id                               title                        genres</span><br><span class="line"><span class="number">0</span>         <span class="number">1</span>                    Toy Story (<span class="number">1995</span>)   Animation|Children<span class="string">&#x27;s|Comedy</span></span><br><span class="line"><span class="string">1         2                      Jumanji (1995)  Adventure|Children&#x27;</span>s|Fantasy</span><br><span class="line"><span class="number">2</span>         <span class="number">3</span>             Grumpier Old Men (<span class="number">1995</span>)                Comedy|Romance</span><br><span class="line"><span class="number">3</span>         <span class="number">4</span>            Waiting to Exhale (<span class="number">1995</span>)                  Comedy|Drama</span><br><span class="line"><span class="number">4</span>         <span class="number">5</span>  Father of the Bride Part II (<span class="number">1995</span>)                        Comedy</span><br><span class="line"><span class="number">5</span>         <span class="number">6</span>                         Heat (<span class="number">1995</span>)         Action|Crime|Thriller</span><br><span class="line"><span class="number">6</span>         <span class="number">7</span>                      Sabrina (<span class="number">1995</span>)                Comedy|Romance</span><br><span class="line"><span class="number">7</span>         <span class="number">8</span>                 Tom <span class="keyword">and</span> Huck (<span class="number">1995</span>)          Adventure|Children<span class="string">&#x27;s</span></span><br><span class="line"><span class="string">8         9                 Sudden Death (1995)</span></span><br><span class="line"><span class="string">Action</span></span><br><span class="line"><span class="string">9        10                    GoldenEye (1995)     Action|Adventure|Thriller</span></span><br></pre></td></tr></table></figure></p>
<p>要为每个genre添加指标变量就需要做一些数据规整操作。首先，我们从数据集中抽取出不同的genre值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: all_genres = []</span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: <span class="keyword">for</span> x <span class="keyword">in</span> movies.genres:</span><br><span class="line">   .....:     all_genres.extend(x.split(<span class="string">&#x27;|&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: genres = pd.unique(all_genres)</span><br></pre></td></tr></table></figure></p>
<p>现在有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">120</span>]: genres</span><br><span class="line">Out[<span class="number">120</span>]: </span><br><span class="line">array([<span class="string">&#x27;Animation&#x27;</span>, <span class="string">&quot;Children&#x27;s&quot;</span>, <span class="string">&#x27;Comedy&#x27;</span>, <span class="string">&#x27;Adventure&#x27;</span>, <span class="string">&#x27;Fantasy&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Romance&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>, <span class="string">&#x27;Action&#x27;</span>, <span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Thriller&#x27;</span>,<span class="string">&#x27;Horror&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Sci-Fi&#x27;</span>, <span class="string">&#x27;Documentary&#x27;</span>, <span class="string">&#x27;War&#x27;</span>, <span class="string">&#x27;Musical&#x27;</span>, <span class="string">&#x27;Mystery&#x27;</span>, <span class="string">&#x27;Film-Noir&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;Western&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure></p>
<p>构建指标DataFrame的方法之一是从一个全零DataFrame开始：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">121</span>]: zero_matrix = np.zeros((<span class="built_in">len</span>(movies), <span class="built_in">len</span>(genres)))</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: dummies = pd.DataFrame(zero_matrix, columns=genres)</span><br></pre></td></tr></table></figure></p>
<p>现在，迭代每一部电影，并将dummies各行的条目设为1。要这么做，我们使用dummies.columns来计算每个类型的列索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">123</span>]: gen = movies.genres[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: gen.split(<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line">Out[<span class="number">124</span>]: [<span class="string">&#x27;Animation&#x27;</span>, <span class="string">&quot;Children&#x27;s&quot;</span>, <span class="string">&#x27;Comedy&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: dummies.columns.get_indexer(gen.split(<span class="string">&#x27;|&#x27;</span>))</span><br><span class="line">Out[<span class="number">125</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure></p>
<p>然后，根据索引，使用.iloc设定值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">126</span>]: <span class="keyword">for</span> i, gen <span class="keyword">in</span> <span class="built_in">enumerate</span>(movies.genres):</span><br><span class="line">   .....:     indices = dummies.columns.get_indexer(gen.split(<span class="string">&#x27;|&#x27;</span>))</span><br><span class="line">   .....:     dummies.iloc[i, indices] = <span class="number">1</span></span><br><span class="line">   .....:</span><br></pre></td></tr></table></figure></p>
<p>然后，和以前一样，再将其与movies合并起来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">127</span>]: movies_windic = movies.join(dummies.add_prefix(<span class="string">&#x27;Genre_&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">128</span>]: movies_windic.iloc[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">128</span>]: </span><br><span class="line">movie_id                                       <span class="number">1</span></span><br><span class="line">title                           Toy Story (<span class="number">1995</span>)</span><br><span class="line">genres               Animation|Children<span class="string">&#x27;s|Comedy</span></span><br><span class="line"><span class="string">Genre_Animation                                1</span></span><br><span class="line"><span class="string">Genre_Children&#x27;</span>s                               <span class="number">1</span></span><br><span class="line">Genre_Comedy                                   <span class="number">1</span></span><br><span class="line">Genre_Adventure                                <span class="number">0</span></span><br><span class="line">Genre_Fantasy                                  <span class="number">0</span></span><br><span class="line">Genre_Romance                                  <span class="number">0</span></span><br><span class="line">Genre_Drama                                    <span class="number">0</span></span><br><span class="line">                                ...             </span><br><span class="line">Genre_Crime                                    <span class="number">0</span></span><br><span class="line">Genre_Thriller                                 <span class="number">0</span></span><br><span class="line">Genre_Horror                                   <span class="number">0</span></span><br><span class="line">Genre_Sci-Fi                                   <span class="number">0</span></span><br><span class="line">Genre_Documentary                              <span class="number">0</span></span><br><span class="line">Genre_War                                      <span class="number">0</span></span><br><span class="line">Genre_Musical                                  <span class="number">0</span></span><br><span class="line">Genre_Mystery                                  <span class="number">0</span></span><br><span class="line">Genre_Film-Noir                                <span class="number">0</span></span><br><span class="line">Genre_Western                                  <span class="number">0</span></span><br><span class="line">Name: <span class="number">0</span>, Length: <span class="number">21</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：对于很大的数据，用这种方式构建多成员指标变量就会变得非常慢。最好使用更低级的函数，将其写入NumPy数组，然后结果包装在DataFrame中。</p>
</blockquote>
<p>一个对统计应用有用的秘诀是：结合get_dummies和诸如cut之类的离散化函数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">129</span>]: np.random.seed(<span class="number">12345</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">130</span>]: values = np.random.rand(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">131</span>]: values</span><br><span class="line">Out[<span class="number">131</span>]: </span><br><span class="line">array([ <span class="number">0.9296</span>,  <span class="number">0.3164</span>,  <span class="number">0.1839</span>,  <span class="number">0.2046</span>,  <span class="number">0.5677</span>,  <span class="number">0.5955</span>,  <span class="number">0.9645</span>,</span><br><span class="line">        <span class="number">0.6532</span>,  <span class="number">0.7489</span>,  <span class="number">0.6536</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: bins = [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">133</span>]: pd.get_dummies(pd.cut(values, bins))</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">   (<span class="number">0.0</span>, <span class="number">0.2</span>]  (<span class="number">0.2</span>, <span class="number">0.4</span>]  (<span class="number">0.4</span>, <span class="number">0.6</span>]  (<span class="number">0.6</span>, <span class="number">0.8</span>]  (<span class="number">0.8</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">1</span></span><br><span class="line"><span class="number">1</span>           <span class="number">0</span>           <span class="number">1</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">2</span>           <span class="number">1</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">3</span>           <span class="number">0</span>           <span class="number">1</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">4</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">1</span>           <span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">5</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">1</span>           <span class="number">0</span>           <span class="number">0</span></span><br><span class="line"><span class="number">6</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">1</span></span><br><span class="line"><span class="number">7</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">1</span>           <span class="number">0</span></span><br><span class="line"><span class="number">8</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">1</span>           <span class="number">0</span></span><br><span class="line"><span class="number">9</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">0</span>           <span class="number">1</span>           <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>我们用numpy.random.seed，使这个例子具有确定性。本书后面会介绍pandas.get_dummies。</p>
<h1><span id="73-字符串操作">7.3 字符串操作</span></h1><p>Python能够成为流行的数据处理语言，部分原因是其简单易用的字符串和文本处理功能。大部分文本运算都直接做成了字符串对象的内置方法。对于更为复杂的模式匹配和文本操作，则可能需要用到正则表达式。pandas对此进行了加强，它使你能够对整组数据应用字符串表达式和正则表达式，而且能处理烦人的缺失数据。</p>
<h2><span id="字符串对象方法">字符串对象方法</span></h2><p>对于许多字符串处理和脚本应用，内置的字符串方法已经能够满足要求了。例如，以逗号分隔的字符串可以用split拆分成数段：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">134</span>]: val = <span class="string">&#x27;a,b,  guido&#x27;</span></span><br><span class="line">In [<span class="number">135</span>]: val.split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">Out[<span class="number">135</span>]: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;  guido&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>split常常与strip一起使用，以去除空白符（包括换行符）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">136</span>]: pieces = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> val.split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">137</span>]: pieces</span><br><span class="line">Out[<span class="number">137</span>]: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;guido&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>利用加法，可以将这些子字符串以双冒号分隔符的形式连接起来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">138</span>]: first, second, third = pieces</span><br><span class="line"></span><br><span class="line">In [<span class="number">139</span>]: first + <span class="string">&#x27;::&#x27;</span> + second + <span class="string">&#x27;::&#x27;</span> + third</span><br><span class="line">Out[<span class="number">139</span>]: <span class="string">&#x27;a:<span class="github-emoji" alias="b" style fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f171.png?v8">&#x1f171;</span>:guido&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>但这种方式并不是很实用。一种更快更符合Python风格的方式是，向字符串”::”的join方法传入一个列表或元组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">140</span>]: <span class="string">&#x27;::&#x27;</span>.join(pieces)</span><br><span class="line">Out[<span class="number">140</span>]: <span class="string">&#x27;a:<span class="github-emoji" alias="b" style fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f171.png?v8">&#x1f171;</span>:guido&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>其它方法关注的是子串定位。检测子串的最佳方式是利用Python的in关键字，还可以使用index和find：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">141</span>]: <span class="string">&#x27;guido&#x27;</span> <span class="keyword">in</span> val</span><br><span class="line">Out[<span class="number">141</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">142</span>]: val.index(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">Out[<span class="number">142</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">143</span>]: val.find(<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">Out[<span class="number">143</span>]: -<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>注意find和index的区别：如果找不到字符串，index将会引发一个异常（而不是返回－1）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">144</span>]: val.index(<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">ValueError                                Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">144</span>-280f8b2856ce&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> val.index(<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">ValueError: substring <span class="keyword">not</span> found</span><br></pre></td></tr></table></figure></p>
<p>与此相关，count可以返回指定子串的出现次数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">145</span>]: val.count(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">Out[<span class="number">145</span>]: <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p>replace用于将指定模式替换为另一个模式。通过传入空字符串，它也常常用于删除模式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">146</span>]: val.replace(<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;::&#x27;</span>)</span><br><span class="line">Out[<span class="number">146</span>]: <span class="string">&#x27;a:<span class="github-emoji" alias="b" style fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f171.png?v8">&#x1f171;</span>:  guido&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">147</span>]: val.replace(<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">Out[<span class="number">147</span>]: <span class="string">&#x27;ab  guido&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>表7-3列出了Python内置的字符串方法。</p>
<p>这些运算大部分都能使用正则表达式实现（马上就会看到）。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-087fe67bf6db0701.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-d1f0d4ed3e895016.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>casefold      将字符转换为小写，并将任何特定区域的变量字符组合转换成一个通用的可比较形式。</p>
<h2><span id="正则表达式">正则表达式</span></h2><p>正则表达式提供了一种灵活的在文本中搜索或匹配（通常比前者复杂）字符串模式的方式。正则表达式，常称作regex，是根据正则表达式语言编写的字符串。Python内置的re模块负责对字符串应用正则表达式。我将通过一些例子说明其使用方法。</p>
<blockquote>
<p>笔记：正则表达式的编写技巧可以自成一章，超出了本书的范围。从网上和其它书可以找到许多非常不错的教程和参考资料。</p>
</blockquote>
<p>re模块的函数可以分为三个大类：模式匹配、替换以及拆分。当然，它们之间是相辅相成的。一个regex描述了需要在文本中定位的一个模式，它可以用于许多目的。我们先来看一个简单的例子：假设我想要拆分一个字符串，分隔符为数量不定的一组空白符（制表符、空格、换行符等）。描述一个或多个空白符的regex是\s+：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">148</span>]: <span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">In [<span class="number">149</span>]: text = <span class="string">&quot;foo    bar\t baz  \tqux&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">150</span>]: re.split(<span class="string">&#x27;\s+&#x27;</span>, text)</span><br><span class="line">Out[<span class="number">150</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;qux&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>调用re.split(‘\s+’,text)时，正则表达式会先被编译，然后再在text上调用其split方法。你可以用re.compile自己编译regex以得到一个可重用的regex对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">151</span>]: regex = re.<span class="built_in">compile</span>(<span class="string">&#x27;\s+&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">152</span>]: regex.split(text)</span><br><span class="line">Out[<span class="number">152</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;qux&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>如果只希望得到匹配regex的所有模式，则可以使用findall方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">153</span>]: regex.findall(text)</span><br><span class="line">Out[<span class="number">153</span>]: [<span class="string">&#x27;    &#x27;</span>, <span class="string">&#x27;\t &#x27;</span>, <span class="string">&#x27;  \t&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：如果想避免正则表达式中不需要的转义（\），则可以使用原始字符串字面量如r’C:\x’（也可以编写其等价式’C:\x’）。</p>
</blockquote>
<p>如果打算对许多字符串应用同一条正则表达式，强烈建议通过re.compile创建regex对象。这样将可以节省大量的CPU时间。</p>
<p>match和search跟findall功能类似。findall返回的是字符串中所有的匹配项，而search则只返回第一个匹配项。match更加严格，它只匹配字符串的首部。来看一个小例子，假设我们有一段文本以及一条能够识别大部分电子邮件地址的正则表达式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text = <span class="string">&quot;&quot;&quot;Dave dave@google.com</span></span><br><span class="line"><span class="string">Steve steve@gmail.com</span></span><br><span class="line"><span class="string">Rob rob@gmail.com</span></span><br><span class="line"><span class="string">Ryan ryan@yahoo.com</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">pattern = <span class="string">r&#x27;[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]&#123;2,4&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># re.IGNORECASE makes the regex case-insensitive</span></span><br><span class="line">regex = re.<span class="built_in">compile</span>(pattern, flags=re.IGNORECASE)</span><br></pre></td></tr></table></figure></p>
<p>对text使用findall将得到一组电子邮件地址：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">155</span>]: regex.findall(text)</span><br><span class="line">Out[<span class="number">155</span>]: </span><br><span class="line">[<span class="string">&#x27;dave@google.com&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;steve@gmail.com&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;rob@gmail.com&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ryan@yahoo.com&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>search返回的是文本中第一个电子邮件地址（以特殊的匹配项对象形式返回）。对于上面那个regex，匹配项对象只能告诉我们模式在原字符串中的起始和结束位置：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">156</span>]: m = regex.search(text)</span><br><span class="line"></span><br><span class="line">In [<span class="number">157</span>]: m</span><br><span class="line">Out[<span class="number">157</span>]: &lt;_sre.SRE_Match <span class="built_in">object</span>; span=(<span class="number">5</span>, <span class="number">20</span>), match=<span class="string">&#x27;dave@google.com&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">158</span>]: text[m.start():m.end()]</span><br><span class="line">Out[<span class="number">158</span>]: <span class="string">&#x27;dave@google.com&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>regex.match则将返回None，因为它只匹配出现在字符串开头的模式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">159</span>]: <span class="built_in">print</span>(regex.match(text))</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></table></figure></p>
<p>相关的，sub方法可以将匹配到的模式替换为指定字符串，并返回所得到的新字符串：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">160</span>]: <span class="built_in">print</span>(regex.sub(<span class="string">&#x27;REDACTED&#x27;</span>, text))</span><br><span class="line">Dave REDACTED</span><br><span class="line">Steve REDACTED</span><br><span class="line">Rob REDACTED</span><br><span class="line">Ryan REDACTED</span><br></pre></td></tr></table></figure></p>
<p>假设你不仅想要找出电子邮件地址，还想将各个地址分成3个部分：用户名、域名以及域后缀。要实现此功能，只需将待分段的模式的各部分用圆括号包起来即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">161</span>]: pattern = <span class="string">r&#x27;([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]&#123;2,4&#125;)&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: regex = re.<span class="built_in">compile</span>(pattern, flags=re.IGNORECASE)</span><br></pre></td></tr></table></figure></p>
<p>由这种修改过的正则表达式所产生的匹配项对象，可以通过其groups方法返回一个由模式各段组成的元组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">163</span>]: m = regex.match(<span class="string">&#x27;wesm@bright.net&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">164</span>]: m.groups()</span><br><span class="line">Out[<span class="number">164</span>]: (<span class="string">&#x27;wesm&#x27;</span>, <span class="string">&#x27;bright&#x27;</span>, <span class="string">&#x27;net&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>对于带有分组功能的模式，findall会返回一个元组列表：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">165</span>]: regex.findall(text)</span><br><span class="line">Out[<span class="number">165</span>]:</span><br><span class="line">[(<span class="string">&#x27;dave&#x27;</span>, <span class="string">&#x27;google&#x27;</span>, <span class="string">&#x27;com&#x27;</span>),</span><br><span class="line"> (<span class="string">&#x27;steve&#x27;</span>, <span class="string">&#x27;gmail&#x27;</span>, <span class="string">&#x27;com&#x27;</span>),</span><br><span class="line"> (<span class="string">&#x27;rob&#x27;</span>, <span class="string">&#x27;gmail&#x27;</span>, <span class="string">&#x27;com&#x27;</span>),</span><br><span class="line"> (<span class="string">&#x27;ryan&#x27;</span>, <span class="string">&#x27;yahoo&#x27;</span>, <span class="string">&#x27;com&#x27;</span>)]</span><br></pre></td></tr></table></figure></p>
<p>sub还能通过诸如\1、\2之类的特殊符号访问各匹配项中的分组。符号\1对应第一个匹配的组，\2对应第二个匹配的组，以此类推：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">166</span>]: <span class="built_in">print</span>(regex.sub(<span class="string">r&#x27;Username: \1, Domain: \2, Suffix: \3&#x27;</span>, text))</span><br><span class="line">Dave Username: dave, Domain: google, Suffix: com</span><br><span class="line">Steve Username: steve, Domain: gmail, Suffix: com</span><br><span class="line">Rob Username: rob, Domain: gmail, Suffix: com</span><br><span class="line">Ryan Username: ryan, Domain: yahoo, Suffix: com</span><br></pre></td></tr></table></figure></p>
<p>Python中还有许多的正则表达式，但大部分都超出了本书的范围。表7-4是一个简要概括。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-efbb80a793759fc0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h2><span id="pandas的矢量化字符串函数">pandas的矢量化字符串函数</span></h2><p>清理待分析的散乱数据时，常常需要做一些字符串规整化工作。更为复杂的情况是，含有字符串的列有时还含有缺失数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">167</span>]: data = &#123;<span class="string">&#x27;Dave&#x27;</span>: <span class="string">&#x27;dave@google.com&#x27;</span>, <span class="string">&#x27;Steve&#x27;</span>: <span class="string">&#x27;steve@gmail.com&#x27;</span>,</span><br><span class="line">   .....:         <span class="string">&#x27;Rob&#x27;</span>: <span class="string">&#x27;rob@gmail.com&#x27;</span>, <span class="string">&#x27;Wes&#x27;</span>: np.nan&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">168</span>]: data = pd.Series(data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: data</span><br><span class="line">Out[<span class="number">169</span>]: </span><br><span class="line">Dave     dave@google.com</span><br><span class="line">Rob        rob@gmail.com</span><br><span class="line">Steve    steve@gmail.com</span><br><span class="line">Wes                  NaN</span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">170</span>]: data.isnull()</span><br><span class="line">Out[<span class="number">170</span>]: </span><br><span class="line">Dave     <span class="literal">False</span></span><br><span class="line">Rob      <span class="literal">False</span></span><br><span class="line">Steve    <span class="literal">False</span></span><br><span class="line">Wes       <span class="literal">True</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure></p>
<p>通过data.map，所有字符串和正则表达式方法都能被应用于（传入lambda表达式或其他函数）各个值，但是如果存在NA（null）就会报错。为了解决这个问题，Series有一些能够跳过NA值的面向数组方法，进行字符串操作。通过Series的str属性即可访问这些方法。例如，我们可以通过str.contains检查各个电子邮件地址是否含有”gmail”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">171</span>]: data.<span class="built_in">str</span>.contains(<span class="string">&#x27;gmail&#x27;</span>)</span><br><span class="line">Out[<span class="number">171</span>]: </span><br><span class="line">Dave     <span class="literal">False</span></span><br><span class="line">Rob       <span class="literal">True</span></span><br><span class="line">Steve     <span class="literal">True</span></span><br><span class="line">Wes        NaN</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>也可以使用正则表达式，还可以加上任意re选项（如IGNORECASE）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">172</span>]: pattern</span><br><span class="line">Out[<span class="number">172</span>]: <span class="string">&#x27;([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]&#123;2,4&#125;)&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">173</span>]: data.<span class="built_in">str</span>.findall(pattern, flags=re.IGNORECASE)</span><br><span class="line">Out[<span class="number">173</span>]: </span><br><span class="line">Dave     [(dave, google, com)]</span><br><span class="line">Rob        [(rob, gmail, com)]</span><br><span class="line">Steve    [(steve, gmail, com)]</span><br><span class="line">Wes                        NaN</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>有两个办法可以实现矢量化的元素获取操作：要么使用str.get，要么在str属性上使用索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">174</span>]: matches = data.<span class="built_in">str</span>.match(pattern, flags=re.IGNORECASE)</span><br><span class="line"></span><br><span class="line">In [<span class="number">175</span>]: matches</span><br><span class="line">Out[<span class="number">175</span>]: </span><br><span class="line">Dave     <span class="literal">True</span></span><br><span class="line">Rob      <span class="literal">True</span></span><br><span class="line">Steve    <span class="literal">True</span></span><br><span class="line">Wes       NaN</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>要访问嵌入列表中的元素，我们可以传递索引到这两个函数中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">176</span>]: matches.<span class="built_in">str</span>.get(<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">176</span>]: </span><br><span class="line">Dave    NaN</span><br><span class="line">Rob     NaN</span><br><span class="line">Steve   NaN</span><br><span class="line">Wes     NaN</span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">177</span>]: matches.<span class="built_in">str</span>[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">177</span>]: </span><br><span class="line">Dave    NaN</span><br><span class="line">Rob     NaN</span><br><span class="line">Steve   NaN</span><br><span class="line">Wes     NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>你可以利用这种方法对字符串进行截取：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">178</span>]: data.<span class="built_in">str</span>[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">178</span>]: </span><br><span class="line">Dave     dave@</span><br><span class="line">Rob      rob@g</span><br><span class="line">Steve    steve</span><br><span class="line">Wes        NaN</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>表7-5介绍了更多的pandas字符串方法。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-a634364ed6d5d5c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表7-5 部分矢量化字符串方法"></p>
<h1><span id="74-总结">7.4 总结</span></h1><p>高效的数据准备可以让你将更多的时间用于数据分析，花较少的时间用于准备工作，这样就可以极大地提高生产力。我们在本章中学习了许多工具，但覆盖并不全面。下一章，我们会学习pandas的聚合与分组。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-6.数据加载</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-6-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>访问数据是使用本书所介绍的这些工具的第一步。我会着重介绍pandas的数据输入与输出，虽然别的库中也有不少以此为目的的工具。</p>
<p>输入输出通常可以划分为几个大类：读取文本文件和其他更高效的磁盘存储格式，加载数据库中的数据，利用Web API操作网络资源。</p>
<span id="more"></span>
<h1><span id="61-读写文本格式的数据">6.1 读写文本格式的数据</span></h1><p>pandas提供了一些用于将表格型数据读取为DataFrame对象的函数。表6-1对它们进行了总结，其中read_csv和read_table可能会是你今后用得最多的。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-958f849e6067b19b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表6-1 pandas中的解析函数"></p>
<p>我将大致介绍一下这些函数在将文本数据转换为DataFrame时所用到的一些技术。这些函数的选项可以划分为以下几个大类：</p>
<ul>
<li>索引：将一个或多个列当做返回的DataFrame处理，以及是否从文件、用户获取列名。</li>
<li>类型推断和数据转换：包括用户定义值的转换、和自定义的缺失值标记列表等。</li>
<li>日期解析：包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列。</li>
<li>迭代：支持对大文件进行逐块迭代。</li>
<li>不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西（比如由成千上万个逗号隔开的数值数据）。</li>
</ul>
<p>因为工作中实际碰到的数据可能十分混乱，一些数据加载函数（尤其是read_csv）的选项逐渐变得复杂起来。面对不同的参数，感到头痛很正常（read_csv有超过50个参数）。pandas文档有这些参数的例子，如果你感到阅读某个文件很难，可以通过相似的足够多的例子找到正确的参数。</p>
<p>其中一些函数，比如pandas.read_csv，有类型推断功能，因为列数据的类型不属于数据类型。也就是说，你不需要指定列的类型到底是数值、整数、布尔值，还是字符串。其它的数据格式，如HDF5、Feather和msgpack，会在格式中存储数据类型。</p>
<p>日期和其他自定义类型的处理需要多花点工夫才行。首先我们来看一个以逗号分隔的（CSV）文本文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: !cat examples/ex1.csv</span><br><span class="line">a,b,c,d,message</span><br><span class="line"><span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,hello</span><br><span class="line"><span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,world</span><br><span class="line"><span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,foo</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：这里，我用的是Unix的cat shell命令将文件的原始内容打印到屏幕上。如果你用的是Windows，你可以使用type达到同样的效果。</p>
</blockquote>
<p>由于该文件以逗号分隔，所以我们可以使用read_csv将其读入一个DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">9</span>]: df = pd.read_csv(<span class="string">&#x27;examples/ex1.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: df</span><br><span class="line">Out[<span class="number">10</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>我们还可以使用read_table，并指定分隔符：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">11</span>]: pd.read_table(<span class="string">&#x27;examples/ex1.csv&#x27;</span>, sep=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">Out[<span class="number">11</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>并不是所有文件都有标题行。看看下面这个文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: !cat examples/ex2.csv</span><br><span class="line"><span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,hello</span><br><span class="line"><span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,world</span><br><span class="line"><span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,foo</span><br></pre></td></tr></table></figure></p>
<p>读入该文件的办法有两个。你可以让pandas为其分配默认的列名，也可以自己定义列名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: pd.read_csv(<span class="string">&#x27;examples/ex2.csv&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">Out[<span class="number">13</span>]: </span><br><span class="line">   <span class="number">0</span>   <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>      <span class="number">4</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>  hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>  world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>    foo</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: pd.read_csv(<span class="string">&#x27;examples/ex2.csv&#x27;</span>, names=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;message&#x27;</span>])</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>假设你希望将message列做成DataFrame的索引。你可以明确表示要将该列放到索引4的位置上，也可以通过index_col参数指定”message”：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: names = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;message&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: pd.read_csv(<span class="string">&#x27;examples/ex2.csv&#x27;</span>, names=names, index_col=<span class="string">&#x27;message&#x27;</span>)</span><br><span class="line">Out[<span class="number">16</span>]: </span><br><span class="line">         a   b   c   d</span><br><span class="line">message               </span><br><span class="line">hello    <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span></span><br><span class="line">world    <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span></span><br><span class="line">foo      <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span></span><br></pre></td></tr></table></figure></p>
<p>如果希望将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: !cat examples/csv_mindex.csv</span><br><span class="line">key1,key2,value1,value2</span><br><span class="line">one,a,<span class="number">1</span>,<span class="number">2</span></span><br><span class="line">one,b,<span class="number">3</span>,<span class="number">4</span></span><br><span class="line">one,c,<span class="number">5</span>,<span class="number">6</span></span><br><span class="line">one,d,<span class="number">7</span>,<span class="number">8</span></span><br><span class="line">two,a,<span class="number">9</span>,<span class="number">10</span></span><br><span class="line">two,b,<span class="number">11</span>,<span class="number">12</span></span><br><span class="line">two,c,<span class="number">13</span>,<span class="number">14</span></span><br><span class="line">two,d,<span class="number">15</span>,<span class="number">16</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: parsed = pd.read_csv(<span class="string">&#x27;examples/csv_mindex.csv&#x27;</span>,</span><br><span class="line">   ....:                      index_col=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: parsed</span><br><span class="line">Out[<span class="number">19</span>]: </span><br><span class="line">           value1  value2</span><br><span class="line">key1 key2                </span><br><span class="line">one  a          <span class="number">1</span>       <span class="number">2</span></span><br><span class="line">     b          <span class="number">3</span>       <span class="number">4</span></span><br><span class="line">     c          <span class="number">5</span>       <span class="number">6</span></span><br><span class="line">     d          <span class="number">7</span>       <span class="number">8</span></span><br><span class="line">two  a          <span class="number">9</span>      <span class="number">10</span></span><br><span class="line">     b         <span class="number">11</span>      <span class="number">12</span></span><br><span class="line">     c         <span class="number">13</span>      <span class="number">14</span></span><br><span class="line">     d         <span class="number">15</span>      <span class="number">16</span></span><br></pre></td></tr></table></figure></p>
<p>有些情况下，有些表格可能不是用固定的分隔符去分隔字段的（比如空白符或其它模式）。看看下面这个文本文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">20</span>]: <span class="built_in">list</span>(<span class="built_in">open</span>(<span class="string">&#x27;examples/ex3.txt&#x27;</span>))</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">[<span class="string">&#x27;            A         B         C\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;aaa -0.264438 -1.026059 -0.619500\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;bbb  0.927272  0.302904 -0.032399\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ccc -0.264273 -0.386314 -0.217601\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ddd -0.871858 -0.348382  1.100491\n&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>虽然可以手动对数据进行规整，这里的字段是被数量不同的空白字符间隔开的。这种情况下，你可以传递一个正则表达式作为read_table的分隔符。可以用正则表达式表达为\s+，于是有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: result = pd.read_table(<span class="string">&#x27;examples/ex3.txt&#x27;</span>, sep=<span class="string">&#x27;\s+&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: result</span><br><span class="line">Out[<span class="number">22</span>]: </span><br><span class="line">            A         B         C</span><br><span class="line">aaa -<span class="number">0.264438</span> -<span class="number">1.026059</span> -<span class="number">0.619500</span></span><br><span class="line">bbb  <span class="number">0.927272</span>  <span class="number">0.302904</span> -<span class="number">0.032399</span></span><br><span class="line">ccc -<span class="number">0.264273</span> -<span class="number">0.386314</span> -<span class="number">0.217601</span></span><br><span class="line">ddd -<span class="number">0.871858</span> -<span class="number">0.348382</span>  <span class="number">1.100491</span></span><br></pre></td></tr></table></figure></p>
<p>这里，由于列名比数据行的数量少，所以read_table推断第一列应该是DataFrame的索引。</p>
<p>这些解析器函数还有许多参数可以帮助你处理各种各样的异形文件格式（表6-2列出了一些）。比如说，你可以用skiprows跳过文件的第一行、第三行和第四行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">23</span>]: !cat examples/ex4.csv</span><br><span class="line"><span class="comment"># hey!</span></span><br><span class="line">a,b,c,d,message</span><br><span class="line"><span class="comment"># just wanted to make things more difficult for you</span></span><br><span class="line"><span class="comment"># who reads CSV files with computers, anyway?</span></span><br><span class="line"><span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,hello</span><br><span class="line"><span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,world</span><br><span class="line"><span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,foo</span><br><span class="line">In [<span class="number">24</span>]: pd.read_csv(<span class="string">&#x27;examples/ex4.csv&#x27;</span>, skiprows=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>缺失值处理是文件解析任务中的一个重要组成部分。缺失数据经常是要么没有（空字符串），要么用某个标记值表示。默认情况下，pandas会用一组经常出现的标记值进行识别，比如NA及NULL：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">25</span>]: !cat examples/ex5.csv</span><br><span class="line">something,a,b,c,d,message</span><br><span class="line">one,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,NA</span><br><span class="line">two,<span class="number">5</span>,<span class="number">6</span>,,<span class="number">8</span>,world</span><br><span class="line">three,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,foo</span><br><span class="line">In [<span class="number">26</span>]: result = pd.read_csv(<span class="string">&#x27;examples/ex5.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: result</span><br><span class="line">Out[<span class="number">27</span>]: </span><br><span class="line">  something  a   b     c   d message</span><br><span class="line"><span class="number">0</span>       one  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3.0</span>   <span class="number">4</span>     NaN</span><br><span class="line"><span class="number">1</span>       two  <span class="number">5</span>   <span class="number">6</span>   NaN   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>     three  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11.0</span>  <span class="number">12</span>     foo</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: pd.isnull(result)</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">   something      a      b      c      d  message</span><br><span class="line"><span class="number">0</span>      <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">1</span>      <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>   <span class="literal">True</span>  <span class="literal">False</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>      <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>    <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>na_values可以用一个列表或集合的字符串表示缺失值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: result = pd.read_csv(<span class="string">&#x27;examples/ex5.csv&#x27;</span>, na_values=[<span class="string">&#x27;NULL&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: result</span><br><span class="line">Out[<span class="number">30</span>]: </span><br><span class="line">  something  a   b     c   d message</span><br><span class="line"><span class="number">0</span>       one  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3.0</span>   <span class="number">4</span>     NaN</span><br><span class="line"><span class="number">1</span>       two  <span class="number">5</span>   <span class="number">6</span>   NaN   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>     three  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11.0</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>字典的各列可以使用不同的NA标记值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">31</span>]: sentinels = &#123;<span class="string">&#x27;message&#x27;</span>: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;NA&#x27;</span>], <span class="string">&#x27;something&#x27;</span>: [<span class="string">&#x27;two&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: pd.read_csv(<span class="string">&#x27;examples/ex5.csv&#x27;</span>, na_values=sentinels)</span><br><span class="line">Out[<span class="number">32</span>]:</span><br><span class="line">something  a   b     c   d message</span><br><span class="line"><span class="number">0</span>       one  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3.0</span>   <span class="number">4</span>     NaN</span><br><span class="line"><span class="number">1</span>       NaN  <span class="number">5</span>   <span class="number">6</span>   NaN   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>     three  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11.0</span>  <span class="number">12</span>     NaN</span><br></pre></td></tr></table></figure></p>
<p>表6-2列出了pandas.read_csv和pandas.read_table常用的选项。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-082daf4a00ed9494.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-f2bcc0a703c7236f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-597327ade3e94c7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h2><span id="逐块读取文本文件">逐块读取文本文件</span></h2><p>在处理很大的文件时，或找出大文件中的参数集以便于后续处理时，你可能只想读取文件的一小部分或逐块对文件进行迭代。</p>
<p>在看大文件之前，我们先设置pandas显示地更紧些：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: pd.options.display.max_rows = <span class="number">10</span></span><br></pre></td></tr></table></figure></p>
<p>然后有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: result = pd.read_csv(<span class="string">&#x27;examples/ex6.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: result</span><br><span class="line">Out[<span class="number">35</span>]: </span><br><span class="line">           one       two     three      four key</span><br><span class="line"><span class="number">0</span>     <span class="number">0.467976</span> -<span class="number">0.038649</span> -<span class="number">0.295344</span> -<span class="number">1.824726</span>   L</span><br><span class="line"><span class="number">1</span>    -<span class="number">0.358893</span>  <span class="number">1.404453</span>  <span class="number">0.704965</span> -<span class="number">0.200638</span>   B</span><br><span class="line"><span class="number">2</span>    -<span class="number">0.501840</span>  <span class="number">0.659254</span> -<span class="number">0.421691</span> -<span class="number">0.057688</span>   G</span><br><span class="line"><span class="number">3</span>     <span class="number">0.204886</span>  <span class="number">1.074134</span>  <span class="number">1.388361</span> -<span class="number">0.982404</span>   R</span><br><span class="line"><span class="number">4</span>     <span class="number">0.354628</span> -<span class="number">0.133116</span>  <span class="number">0.283763</span> -<span class="number">0.837063</span>   Q</span><br><span class="line"><span class="meta">... </span>       ...       ...       ...       ...  ..</span><br><span class="line"><span class="number">9995</span>  <span class="number">2.311896</span> -<span class="number">0.417070</span> -<span class="number">1.409599</span> -<span class="number">0.515821</span>   L</span><br><span class="line"><span class="number">9996</span> -<span class="number">0.479893</span> -<span class="number">0.650419</span>  <span class="number">0.745152</span> -<span class="number">0.646038</span>   E</span><br><span class="line"><span class="number">9997</span>  <span class="number">0.523331</span>  <span class="number">0.787112</span>  <span class="number">0.486066</span>  <span class="number">1.093156</span>   K</span><br><span class="line"><span class="number">9998</span> -<span class="number">0.362559</span>  <span class="number">0.598894</span> -<span class="number">1.843201</span>  <span class="number">0.887292</span>   G</span><br><span class="line"><span class="number">9999</span> -<span class="number">0.096376</span> -<span class="number">1.012999</span> -<span class="number">0.657431</span> -<span class="number">0.573315</span>   <span class="number">0</span></span><br><span class="line">[<span class="number">10000</span> rows x <span class="number">5</span> columns]</span><br><span class="line">If you want to only read a small</span><br></pre></td></tr></table></figure></p>
<p>如果只想读取几行（避免读取整个文件），通过nrows进行指定即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">36</span>]: pd.read_csv(<span class="string">&#x27;examples/ex6.csv&#x27;</span>, nrows=<span class="number">5</span>)</span><br><span class="line">Out[<span class="number">36</span>]: </span><br><span class="line">        one       two     three      four key</span><br><span class="line"><span class="number">0</span>  <span class="number">0.467976</span> -<span class="number">0.038649</span> -<span class="number">0.295344</span> -<span class="number">1.824726</span>   L</span><br><span class="line"><span class="number">1</span> -<span class="number">0.358893</span>  <span class="number">1.404453</span>  <span class="number">0.704965</span> -<span class="number">0.200638</span>   B</span><br><span class="line"><span class="number">2</span> -<span class="number">0.501840</span>  <span class="number">0.659254</span> -<span class="number">0.421691</span> -<span class="number">0.057688</span>   G</span><br><span class="line"><span class="number">3</span>  <span class="number">0.204886</span>  <span class="number">1.074134</span>  <span class="number">1.388361</span> -<span class="number">0.982404</span>   R</span><br><span class="line"><span class="number">4</span>  <span class="number">0.354628</span> -<span class="number">0.133116</span>  <span class="number">0.283763</span> -<span class="number">0.837063</span>   Q</span><br></pre></td></tr></table></figure></p>
<p>要逐块读取文件，可以指定chunksize（行数）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">874</span>]: chunker = pd.read_csv(<span class="string">&#x27;ch06/ex6.csv&#x27;</span>, chunksize=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">875</span>]: chunker</span><br><span class="line">Out[<span class="number">875</span>]: &lt;pandas.io.parsers.TextParser at <span class="number">0x8398150</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p>read_csv所返回的这个TextParser对象使你可以根据chunksize对文件进行逐块迭代。比如说，我们可以迭代处理ex6.csv，将值计数聚合到”key”列中，如下所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chunker = pd.read_csv(<span class="string">&#x27;examples/ex6.csv&#x27;</span>, chunksize=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">tot = pd.Series([])</span><br><span class="line"><span class="keyword">for</span> piece <span class="keyword">in</span> chunker:</span><br><span class="line">    tot = tot.add(piece[<span class="string">&#x27;key&#x27;</span>].value_counts(), fill_value=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">tot = tot.sort_values(ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>
<p>然后有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">40</span>]: tot[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">E    <span class="number">368.0</span></span><br><span class="line">X    <span class="number">364.0</span></span><br><span class="line">L    <span class="number">346.0</span></span><br><span class="line">O    <span class="number">343.0</span></span><br><span class="line">Q    <span class="number">340.0</span></span><br><span class="line">M    <span class="number">338.0</span></span><br><span class="line">J    <span class="number">337.0</span></span><br><span class="line">F    <span class="number">335.0</span></span><br><span class="line">K    <span class="number">334.0</span></span><br><span class="line">H    <span class="number">330.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>TextParser还有一个get_chunk方法，它使你可以读取任意大小的块。</p>
<h2><span id="将数据写出到文本格式">将数据写出到文本格式</span></h2><p>数据也可以被输出为分隔符格式的文本。我们再来看看之前读过的一个CSV文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: data = pd.read_csv(<span class="string">&#x27;examples/ex5.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: data</span><br><span class="line">Out[<span class="number">42</span>]: </span><br><span class="line">  something  a   b     c   d message</span><br><span class="line"><span class="number">0</span>       one  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3.0</span>   <span class="number">4</span>     NaN</span><br><span class="line"><span class="number">1</span>       two  <span class="number">5</span>   <span class="number">6</span>   NaN   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>     three  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11.0</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>利用DataFrame的to_csv方法，我们可以将数据写到一个以逗号分隔的文件中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">43</span>]: data.to_csv(<span class="string">&#x27;examples/out.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: !cat examples/out.csv</span><br><span class="line">,something,a,b,c,d,message</span><br><span class="line"><span class="number">0</span>,one,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.0</span>,<span class="number">4</span>,</span><br><span class="line"><span class="number">1</span>,two,<span class="number">5</span>,<span class="number">6</span>,,<span class="number">8</span>,world</span><br><span class="line"><span class="number">2</span>,three,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11.0</span>,<span class="number">12</span>,foo</span><br></pre></td></tr></table></figure></p>
<p>当然，还可以使用其他分隔符（由于这里直接写出到sys.stdout，所以仅仅是打印出文本结果而已）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: <span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: data.to_csv(sys.stdout, sep=<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line">|something|a|b|c|d|message</span><br><span class="line"><span class="number">0</span>|one|<span class="number">1</span>|<span class="number">2</span>|<span class="number">3.0</span>|<span class="number">4</span>|</span><br><span class="line"><span class="number">1</span>|two|<span class="number">5</span>|<span class="number">6</span>||<span class="number">8</span>|world</span><br><span class="line"><span class="number">2</span>|three|<span class="number">9</span>|<span class="number">10</span>|<span class="number">11.0</span>|<span class="number">12</span>|foo</span><br></pre></td></tr></table></figure></p>
<p>缺失值在输出结果中会被表示为空字符串。你可能希望将其表示为别的标记值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: data.to_csv(sys.stdout, na_rep=<span class="string">&#x27;NULL&#x27;</span>)</span><br><span class="line">,something,a,b,c,d,message</span><br><span class="line"><span class="number">0</span>,one,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.0</span>,<span class="number">4</span>,NULL</span><br><span class="line"><span class="number">1</span>,two,<span class="number">5</span>,<span class="number">6</span>,NULL,<span class="number">8</span>,world</span><br><span class="line"><span class="number">2</span>,three,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11.0</span>,<span class="number">12</span>,foo</span><br></pre></td></tr></table></figure></p>
<p>如果没有设置其他选项，则会写出行和列的标签。当然，它们也都可以被禁用：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: data.to_csv(sys.stdout, index=<span class="literal">False</span>, header=<span class="literal">False</span>)</span><br><span class="line">one,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.0</span>,<span class="number">4</span>,</span><br><span class="line">two,<span class="number">5</span>,<span class="number">6</span>,,<span class="number">8</span>,world</span><br><span class="line">three,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11.0</span>,<span class="number">12</span>,foo</span><br></pre></td></tr></table></figure></p>
<p>此外，你还可以只写出一部分的列，并以你指定的顺序排列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: data.to_csv(sys.stdout, index=<span class="literal">False</span>, columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">a,b,c</span><br><span class="line"><span class="number">1</span>,<span class="number">2</span>,<span class="number">3.0</span></span><br><span class="line"><span class="number">5</span>,<span class="number">6</span>,</span><br><span class="line"><span class="number">9</span>,<span class="number">10</span>,<span class="number">11.0</span></span><br></pre></td></tr></table></figure></p>
<p>Series也有一个to_csv方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: dates = pd.date_range(<span class="string">&#x27;1/1/2000&#x27;</span>, periods=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: ts = pd.Series(np.arange(<span class="number">7</span>), index=dates)</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: ts.to_csv(<span class="string">&#x27;examples/tseries.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: !cat examples/tseries.csv</span><br><span class="line"><span class="number">2000</span>-01-01,<span class="number">0</span></span><br><span class="line"><span class="number">2000</span>-01-02,<span class="number">1</span></span><br><span class="line"><span class="number">2000</span>-01-03,<span class="number">2</span></span><br><span class="line"><span class="number">2000</span>-01-04,<span class="number">3</span></span><br><span class="line"><span class="number">2000</span>-01-05,<span class="number">4</span></span><br><span class="line"><span class="number">2000</span>-01-06,<span class="number">5</span></span><br><span class="line"><span class="number">2000</span>-01-07,<span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="处理分隔符格式">处理分隔符格式</span></h2><p>大部分存储在磁盘上的表格型数据都能用pandas.read_table进行加载。然而，有时还是需要做一些手工处理。由于接收到含有畸形行的文件而使read_table出毛病的情况并不少见。为了说明这些基本工具，看看下面这个简单的CSV文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">54</span>]: !cat examples/ex7.csv</span><br><span class="line"><span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span></span><br><span class="line"><span class="string">&quot;1&quot;</span>,<span class="string">&quot;2&quot;</span>,<span class="string">&quot;3&quot;</span></span><br><span class="line"><span class="string">&quot;1&quot;</span>,<span class="string">&quot;2&quot;</span>,<span class="string">&quot;3&quot;</span></span><br></pre></td></tr></table></figure></p>
<p>对于任何单字符分隔符文件，可以直接使用Python内置的csv模块。将任意已打开的文件或文件型的对象传给csv.reader：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;examples/ex7.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">reader = csv.reader(f)</span><br></pre></td></tr></table></figure></p>
<p>对这个reader进行迭代将会为每行产生一个元组（并移除了所有的引号）：对这个reader进行迭代将会为每行产生一个元组（并移除了所有的引号）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: <span class="keyword">for</span> line <span class="keyword">in</span> reader:</span><br><span class="line">   ....:     <span class="built_in">print</span>(line)</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>现在，为了使数据格式合乎要求，你需要对其做一些整理工作。我们一步一步来做。首先，读取文件到一个多行的列表中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;examples/ex7.csv&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">   ....:     lines = <span class="built_in">list</span>(csv.reader(f))</span><br></pre></td></tr></table></figure></p>
<p>然后，我们将这些行分为标题行和数据行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">58</span>]: header, values = lines[<span class="number">0</span>], lines[<span class="number">1</span>:]</span><br></pre></td></tr></table></figure></p>
<p>然后，我们可以用字典构造式和zip(*values)，后者将行转置为列，创建数据列的字典：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">59</span>]: data_dict = &#123;h: v <span class="keyword">for</span> h, v <span class="keyword">in</span> <span class="built_in">zip</span>(header, <span class="built_in">zip</span>(*values))&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: data_dict</span><br><span class="line">Out[<span class="number">60</span>]: &#123;<span class="string">&#x27;a&#x27;</span>: (<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>), <span class="string">&#x27;b&#x27;</span>: (<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;2&#x27;</span>), <span class="string">&#x27;c&#x27;</span>: (<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;3&#x27;</span>)&#125;</span><br></pre></td></tr></table></figure></p>
<p>CSV文件的形式有很多。只需定义csv.Dialect的一个子类即可定义出新格式（如专门的分隔符、字符串引用约定、行结束符等）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">my_dialect</span>(<span class="params">csv.Dialect</span>):</span></span><br><span class="line">    lineterminator = <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    delimiter = <span class="string">&#x27;;&#x27;</span></span><br><span class="line">    quotechar = <span class="string">&#x27;&quot;&#x27;</span></span><br><span class="line">    quoting = csv.QUOTE_MINIMAL</span><br><span class="line">reader = csv.reader(f, dialect=my_dialect)</span><br></pre></td></tr></table></figure></p>
<p>各个CSV语支的参数也可以用关键字的形式提供给csv.reader，而无需定义子类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">reader = csv.reader(f, delimiter=<span class="string">&#x27;|&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>可用的选项（csv.Dialect的属性）及其功能如表6-3所示。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-7a1cee622459072b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<blockquote>
<p>笔记：对于那些使用复杂分隔符或多字符分隔符的文件，csv模块就无能为力了。这种情况下，你就只能使用字符串的split方法或正则表达式方法re.split进行行拆分和其他整理工作了。</p>
</blockquote>
<p>要手工输出分隔符文件，你可以使用csv.writer。它接受一个已打开且可写的文件对象以及跟csv.reader相同的那些语支和格式化选项：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;mydata.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    writer = csv.writer(f, dialect=my_dialect)</span><br><span class="line">    writer.writerow((<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>))</span><br><span class="line">    writer.writerow((<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>))</span><br><span class="line">    writer.writerow((<span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;6&#x27;</span>))</span><br><span class="line">    writer.writerow((<span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;9&#x27;</span>))</span><br></pre></td></tr></table></figure></p>
<h2><span id="json数据">JSON数据</span></h2><p>JSON（JavaScript Object Notation的简称）已经成为通过HTTP请求在Web浏览器和其他应用程序之间发送数据的标准格式之一。它是一种比表格型文本格式（如CSV）灵活得多的数据格式。下面是一个例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#123;&quot;name&quot;: &quot;Wes&quot;,</span></span><br><span class="line"><span class="string"> &quot;places_lived&quot;: [&quot;United States&quot;, &quot;Spain&quot;, &quot;Germany&quot;],</span></span><br><span class="line"><span class="string"> &quot;pet&quot;: null,</span></span><br><span class="line"><span class="string"> &quot;siblings&quot;: [&#123;&quot;name&quot;: &quot;Scott&quot;, &quot;age&quot;: 30, &quot;pets&quot;: [&quot;Zeus&quot;, &quot;Zuko&quot;]&#125;,</span></span><br><span class="line"><span class="string">              &#123;&quot;name&quot;: &quot;Katie&quot;, &quot;age&quot;: 38,</span></span><br><span class="line"><span class="string">               &quot;pets&quot;: [&quot;Sixes&quot;, &quot;Stache&quot;, &quot;Cisco&quot;]&#125;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><br>除其空值null和一些其他的细微差别（如列表末尾不允许存在多余的逗号）之外，JSON非常接近于有效的Python代码。基本类型有对象（字典）、数组（列表）、字符串、数值、布尔值以及null。对象中所有的键都必须是字符串。许多Python库都可以读写JSON数据。我将使用json，因为它是构建于Python标准库中的。通过json.loads即可将JSON字符串转换成Python形式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">62</span>]: <span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: result = json.loads(obj)</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: result</span><br><span class="line">Out[<span class="number">64</span>]: </span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Wes&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;pet&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">&#x27;places_lived&#x27;</span>: [<span class="string">&#x27;United States&#x27;</span>, <span class="string">&#x27;Spain&#x27;</span>, <span class="string">&#x27;Germany&#x27;</span>],</span><br><span class="line"> <span class="string">&#x27;siblings&#x27;</span>: [&#123;<span class="string">&#x27;age&#x27;</span>: <span class="number">30</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Scott&#x27;</span>, <span class="string">&#x27;pets&#x27;</span>: [<span class="string">&#x27;Zeus&#x27;</span>, <span class="string">&#x27;Zuko&#x27;</span>]&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;age&#x27;</span>: <span class="number">38</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Katie&#x27;</span>, <span class="string">&#x27;pets&#x27;</span>: [<span class="string">&#x27;Sixes&#x27;</span>, <span class="string">&#x27;Stache&#x27;</span>, <span class="string">&#x27;Cisco&#x27;</span>]&#125;]&#125;</span><br></pre></td></tr></table></figure></p>
<p>json.dumps则将Python对象转换成JSON格式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">65</span>]: asjson = json.dumps(result)</span><br></pre></td></tr></table></figure></p>
<p>如何将（一个或一组）JSON对象转换为DataFrame或其他便于分析的数据结构就由你决定了。最简单方便的方式是：向DataFrame构造器传入一个字典的列表（就是原先的JSON对象），并选取数据字段的子集：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: siblings = pd.DataFrame(result[<span class="string">&#x27;siblings&#x27;</span>], columns=[<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: siblings</span><br><span class="line">Out[<span class="number">67</span>]: </span><br><span class="line">    name  age</span><br><span class="line"><span class="number">0</span>  Scott   <span class="number">30</span></span><br><span class="line"><span class="number">1</span>  Katie   <span class="number">38</span></span><br></pre></td></tr></table></figure></p>
<p>pandas.read_json可以自动将特别格式的JSON数据集转换为Series或DataFrame。例如：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: !cat examples/example.json</span><br><span class="line">[&#123;<span class="string">&quot;a&quot;</span>: <span class="number">1</span>, <span class="string">&quot;b&quot;</span>: <span class="number">2</span>, <span class="string">&quot;c&quot;</span>: <span class="number">3</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&quot;a&quot;</span>: <span class="number">4</span>, <span class="string">&quot;b&quot;</span>: <span class="number">5</span>, <span class="string">&quot;c&quot;</span>: <span class="number">6</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&quot;a&quot;</span>: <span class="number">7</span>, <span class="string">&quot;b&quot;</span>: <span class="number">8</span>, <span class="string">&quot;c&quot;</span>: <span class="number">9</span>&#125;]</span><br></pre></td></tr></table></figure></p>
<p>pandas.read_json的默认选项假设JSON数组中的每个对象是表格中的一行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: data = pd.read_json(<span class="string">&#x27;examples/example.json&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: data</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line">   a  b  c</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span></span><br><span class="line"><span class="number">1</span>  <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span></span><br><span class="line"><span class="number">2</span>  <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span></span><br></pre></td></tr></table></figure></p>
<p>第7章中关于USDA Food Database的那个例子进一步讲解了JSON数据的读取和处理（包括嵌套记录）。</p>
<p>如果你需要将数据从pandas输出到JSON，可以使用to_json方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">71</span>]: <span class="built_in">print</span>(data.to_json())</span><br><span class="line">&#123;<span class="string">&quot;a&quot;</span>:&#123;<span class="string">&quot;0&quot;</span>:<span class="number">1</span>,<span class="string">&quot;1&quot;</span>:<span class="number">4</span>,<span class="string">&quot;2&quot;</span>:<span class="number">7</span>&#125;,<span class="string">&quot;b&quot;</span>:&#123;<span class="string">&quot;0&quot;</span>:<span class="number">2</span>,<span class="string">&quot;1&quot;</span>:<span class="number">5</span>,<span class="string">&quot;2&quot;</span>:<span class="number">8</span>&#125;,<span class="string">&quot;c&quot;</span>:&#123;<span class="string">&quot;0&quot;</span>:<span class="number">3</span>,<span class="string">&quot;1&quot;</span>:<span class="number">6</span>,<span class="string">&quot;2&quot;</span>:<span class="number">9</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: <span class="built_in">print</span>(data.to_json(orient=<span class="string">&#x27;records&#x27;</span>))</span><br><span class="line">[&#123;<span class="string">&quot;a&quot;</span>:<span class="number">1</span>,<span class="string">&quot;b&quot;</span>:<span class="number">2</span>,<span class="string">&quot;c&quot;</span>:<span class="number">3</span>&#125;,&#123;<span class="string">&quot;a&quot;</span>:<span class="number">4</span>,<span class="string">&quot;b&quot;</span>:<span class="number">5</span>,<span class="string">&quot;c&quot;</span>:<span class="number">6</span>&#125;,&#123;<span class="string">&quot;a&quot;</span>:<span class="number">7</span>,<span class="string">&quot;b&quot;</span>:<span class="number">8</span>,<span class="string">&quot;c&quot;</span>:<span class="number">9</span>&#125;]</span><br></pre></td></tr></table></figure></p>
<h2><span id="xml和htmlweb信息收集">XML和HTML：Web信息收集</span></h2><p>Python有许多可以读写常见的HTML和XML格式数据的库，包括lxml、Beautiful Soup和html5lib。lxml的速度比较快，但其它的库处理有误的HTML或XML文件更好。</p>
<p>pandas有一个内置的功能，read_html，它可以使用lxml和Beautiful Soup自动将HTML文件中的表格解析为DataFrame对象。为了进行展示，我从美国联邦存款保险公司下载了一个HTML文件（pandas文档中也使用过），它记录了银行倒闭的情况。首先，你需要安装read_html用到的库：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install lxml</span><br><span class="line">pip install beautifulsoup4 html5lib</span><br></pre></td></tr></table></figure></p>
<p>如果你用的不是conda，可以使用<code>pip install lxml</code>。</p>
<p>pandas.read_html有一些选项，默认条件下，它会搜索、尝试解析<table>标签内的的表格数据。结果是一个列表的DataFrame对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: tables = pd.read_html(<span class="string">&#x27;examples/fdic_failed_bank_list.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: <span class="built_in">len</span>(tables)</span><br><span class="line">Out[<span class="number">74</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">75</span>]: failures = tables[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: failures.head()</span><br><span class="line">Out[<span class="number">76</span>]: </span><br><span class="line">                      Bank Name             City  ST   CERT  \</span><br><span class="line"><span class="number">0</span>                   Allied Bank         Mulberry  AR     <span class="number">91</span>   </span><br><span class="line"><span class="number">1</span>  The Woodbury Banking Company         Woodbury  GA  <span class="number">11297</span>   </span><br><span class="line"><span class="number">2</span>        First CornerStone Bank  King of Prussia  PA  <span class="number">35312</span>   </span><br><span class="line"><span class="number">3</span>            Trust Company Bank          Memphis  TN   <span class="number">9956</span>   </span><br><span class="line"><span class="number">4</span>    North Milwaukee State Bank        Milwaukee  WI  <span class="number">20364</span>   </span><br><span class="line">                 Acquiring Institution        Closing Date       Updated Date  </span><br><span class="line"><span class="number">0</span>                         Today<span class="string">&#x27;s Bank  September 23, 2016  November 17, 2016  </span></span><br><span class="line"><span class="string">1                          United Bank     August 19, 2016  November 17, 2016  </span></span><br><span class="line"><span class="string">2  First-Citizens Bank &amp; Trust Company         May 6, 2016  September 6, 2016  </span></span><br><span class="line"><span class="string">3           The Bank of Fayette County      April 29, 2016  September 6, 2016  </span></span><br><span class="line"><span class="string">4  First-Citizens Bank &amp; Trust Company      March 11, 2016      June 16, 2016</span></span><br></pre></td></tr></table></figure></table></p>
<p>因为failures有许多列，pandas插入了一个换行符\。</p>
<p>这里，我们可以做一些数据清洗和分析（后面章节会进一步讲解），比如计算按年份计算倒闭的银行数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">77</span>]: close_timestamps = pd.to_datetime(failures[<span class="string">&#x27;Closing Date&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: close_timestamps.dt.year.value_counts()</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line"><span class="number">2010</span>    <span class="number">157</span></span><br><span class="line"><span class="number">2009</span>    <span class="number">140</span></span><br><span class="line"><span class="number">2011</span>     <span class="number">92</span></span><br><span class="line"><span class="number">2012</span>     <span class="number">51</span></span><br><span class="line"><span class="number">2008</span>     <span class="number">25</span></span><br><span class="line">       ... </span><br><span class="line"><span class="number">2004</span>      <span class="number">4</span></span><br><span class="line"><span class="number">2001</span>      <span class="number">4</span></span><br><span class="line"><span class="number">2007</span>      <span class="number">3</span></span><br><span class="line"><span class="number">2003</span>      <span class="number">3</span></span><br><span class="line"><span class="number">2000</span>      <span class="number">2</span></span><br><span class="line">Name: Closing Date, Length: <span class="number">15</span>, dtype: int64</span><br></pre></td></tr></table></figure></p>
<h2><span id="利用lxmlobjectify解析xml">利用lxml.objectify解析XML</span></h2><p>XML（Extensible Markup Language）是另一种常见的支持分层、嵌套数据以及元数据的结构化数据格式。本书所使用的这些文件实际上来自于一个很大的XML文档。</p>
<p>前面，我介绍了pandas.read_html函数，它可以使用lxml或Beautiful Soup从HTML解析数据。XML和HTML的结构很相似，但XML更为通用。这里，我会用一个例子演示如何利用lxml从XML格式解析数据。</p>
<p>纽约大都会运输署发布了一些有关其公交和列车服务的数据资料（<a href="http://www.mta.info/developers/download.html）。这里，我们将看看包含在一组XML文件中的运行情况数据。每项列车或公交服务都有各自的文件（如Metro-North">http://www.mta.info/developers/download.html）。这里，我们将看看包含在一组XML文件中的运行情况数据。每项列车或公交服务都有各自的文件（如Metro-North</a> Railroad的文件是Performance_MNR.xml），其中每条XML记录就是一条月度数据，如下所示：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">INDICATOR</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">INDICATOR_SEQ</span>&gt;</span>373889<span class="tag">&lt;/<span class="name">INDICATOR_SEQ</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">PARENT_SEQ</span>&gt;</span><span class="tag">&lt;/<span class="name">PARENT_SEQ</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">AGENCY_NAME</span>&gt;</span>Metro-North Railroad<span class="tag">&lt;/<span class="name">AGENCY_NAME</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">INDICATOR_NAME</span>&gt;</span>Escalator Availability<span class="tag">&lt;/<span class="name">INDICATOR_NAME</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DESCRIPTION</span>&gt;</span>Percent of the time that escalators are operational</span><br><span class="line">  systemwide. The availability rate is based on physical observations performed</span><br><span class="line">  the morning of regular business days only. This is a new indicator the agency</span><br><span class="line">  began reporting in 2009.<span class="tag">&lt;/<span class="name">DESCRIPTION</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">PERIOD_YEAR</span>&gt;</span>2011<span class="tag">&lt;/<span class="name">PERIOD_YEAR</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">PERIOD_MONTH</span>&gt;</span>12<span class="tag">&lt;/<span class="name">PERIOD_MONTH</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">CATEGORY</span>&gt;</span>Service Indicators<span class="tag">&lt;/<span class="name">CATEGORY</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">FREQUENCY</span>&gt;</span>M<span class="tag">&lt;/<span class="name">FREQUENCY</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DESIRED_CHANGE</span>&gt;</span>U<span class="tag">&lt;/<span class="name">DESIRED_CHANGE</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">INDICATOR_UNIT</span>&gt;</span>%<span class="tag">&lt;/<span class="name">INDICATOR_UNIT</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">DECIMAL_PLACES</span>&gt;</span>1<span class="tag">&lt;/<span class="name">DECIMAL_PLACES</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">YTD_TARGET</span>&gt;</span>97.00<span class="tag">&lt;/<span class="name">YTD_TARGET</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">YTD_ACTUAL</span>&gt;</span><span class="tag">&lt;/<span class="name">YTD_ACTUAL</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">MONTHLY_TARGET</span>&gt;</span>97.00<span class="tag">&lt;/<span class="name">MONTHLY_TARGET</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">MONTHLY_ACTUAL</span>&gt;</span><span class="tag">&lt;/<span class="name">MONTHLY_ACTUAL</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">INDICATOR</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>我们先用lxml.objectify解析该文件，然后通过getroot得到该XML文件的根节点的引用：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> objectify</span><br><span class="line"></span><br><span class="line">path = <span class="string">&#x27;datasets/mta_perf/Performance_MNR.xml&#x27;</span></span><br><span class="line">parsed = objectify.parse(<span class="built_in">open</span>(path))</span><br><span class="line">root = parsed.getroot()</span><br></pre></td></tr></table></figure></p>
<p>root.INDICATOR返回一个用于产生各个<indicator>XML元素的生成器。对于每条记录，我们可以用标记名（如YTD_ACTUAL）和数据值填充一个字典（排除几个标记）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = []</span><br><span class="line"></span><br><span class="line">skip_fields = [<span class="string">&#x27;PARENT_SEQ&#x27;</span>, <span class="string">&#x27;INDICATOR_SEQ&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;DESIRED_CHANGE&#x27;</span>, <span class="string">&#x27;DECIMAL_PLACES&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> elt <span class="keyword">in</span> root.INDICATOR:</span><br><span class="line">    el_data = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> child <span class="keyword">in</span> elt.getchildren():</span><br><span class="line">        <span class="keyword">if</span> child.tag <span class="keyword">in</span> skip_fields:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        el_data[child.tag] = child.pyval</span><br><span class="line">    data.append(el_data)</span><br></pre></td></tr></table></figure></indicator></p>
<p>最后，将这组字典转换为一个DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">81</span>]: perf = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line">In [<span class="number">82</span>]: perf.head()</span><br><span class="line">Out[<span class="number">82</span>]:</span><br><span class="line">Empty DataFrame</span><br><span class="line">Columns: []</span><br><span class="line">Index: []</span><br></pre></td></tr></table></figure></p>
<p>XML数据可以比本例复杂得多。每个标记都可以有元数据。看看下面这个HTML的链接标签（它也算是一段有效的XML）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line">tag = <span class="string">&#x27;&lt;a href=&quot;http://www.google.com&quot;&gt;Google&lt;/a&gt;&#x27;</span></span><br><span class="line">root = objectify.parse(StringIO(tag)).getroot()</span><br></pre></td></tr></table></figure></p>
<p>现在就可以访问标签或链接文本中的任何字段了（如href）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">84</span>]: root</span><br><span class="line">Out[<span class="number">84</span>]: &lt;Element a at <span class="number">0x7f6b15817748</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: root.get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">Out[<span class="number">85</span>]: <span class="string">&#x27;http://www.google.com&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: root.text</span><br><span class="line">Out[<span class="number">86</span>]: <span class="string">&#x27;Google&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="62-二进制数据格式">6.2 二进制数据格式</span></h1><p>实现数据的高效二进制格式存储最简单的办法之一是使用Python内置的pickle序列化。pandas对象都有一个用于将数据以pickle格式保存到磁盘上的to_pickle方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: frame = pd.read_csv(<span class="string">&#x27;examples/ex1.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: frame</span><br><span class="line">Out[<span class="number">88</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: frame.to_pickle(<span class="string">&#x27;examples/frame_pickle&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>你可以通过pickle直接读取被pickle化的数据，或是使用更为方便的pandas.read_pickle：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">90</span>]: pd.read_pickle(<span class="string">&#x27;examples/frame_pickle&#x27;</span>)</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：pickle仅建议用于短期存储格式。其原因是很难保证该格式永远是稳定的；今天pickle的对象可能无法被后续版本的库unpickle出来。虽然我尽力保证这种事情不会发生在pandas中，但是今后的某个时候说不定还是得“打破”该pickle格式。</p>
</blockquote>
<p>pandas内置支持两个二进制数据格式：HDF5和MessagePack。下一节，我会给出几个HDF5的例子，但我建议你尝试下不同的文件格式，看看它们的速度以及是否适合你的分析工作。pandas或NumPy数据的其它存储格式有：</p>
<ul>
<li>bcolz：一种可压缩的列存储二进制格式，基于Blosc压缩库。</li>
<li>Feather：我与R语言社区的Hadley Wickham设计的一种跨语言的列存储文件格式。Feather使用了Apache Arrow的列式内存格式。</li>
</ul>
<h2><span id="使用hdf5格式">使用HDF5格式</span></h2><p>HDF5是一种存储大规模科学数组数据的非常好的文件格式。它可以被作为C标准库，带有许多语言的接口，如Java、Python和MATLAB等。HDF5中的HDF指的是层次型数据格式（hierarchical data format）。每个HDF5文件都含有一个文件系统式的节点结构，它使你能够存储多个数据集并支持元数据。与其他简单格式相比，HDF5支持多种压缩器的即时压缩，还能更高效地存储重复模式数据。对于那些非常大的无法直接放入内存的数据集，HDF5就是不错的选择，因为它可以高效地分块读写。</p>
<p>虽然可以用PyTables或h5py库直接访问HDF5文件，pandas提供了更为高级的接口，可以简化存储Series和DataFrame对象。HDFStore类可以像字典一样，处理低级的细节：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">92</span>]: frame = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>: np.random.randn(<span class="number">100</span>)&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: store = pd.HDFStore(<span class="string">&#x27;mydata.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">94</span>]: store[<span class="string">&#x27;obj1&#x27;</span>] = frame</span><br><span class="line"></span><br><span class="line">In [<span class="number">95</span>]: store[<span class="string">&#x27;obj1_col&#x27;</span>] = frame[<span class="string">&#x27;a&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: store</span><br><span class="line">Out[<span class="number">96</span>]: </span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">pandas</span>.<span class="title">io</span>.<span class="title">pytables</span>.<span class="title">HDFStore</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">File</span> <span class="title">path</span>:</span> mydata.h5</span><br><span class="line">/obj1                frame        (shape-&gt;[<span class="number">100</span>,<span class="number">1</span>])                               </span><br><span class="line">        </span><br><span class="line">/obj1_col            series       (shape-&gt;[<span class="number">100</span>])                                 </span><br><span class="line">        </span><br><span class="line">/obj2                frame_table  (typ-&gt;appendable,nrows-&gt;<span class="number">100</span>,ncols-&gt;<span class="number">1</span>,indexers-&gt;</span><br><span class="line">[index])</span><br><span class="line">/obj3                frame_table  (typ-&gt;appendable,nrows-&gt;<span class="number">100</span>,ncols-&gt;<span class="number">1</span>,indexers-&gt;</span><br><span class="line">[index])</span><br></pre></td></tr></table></figure></p>
<p>HDF5文件中的对象可以通过与字典一样的API进行获取：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">97</span>]: store[<span class="string">&#x27;obj1&#x27;</span>]</span><br><span class="line">Out[<span class="number">97</span>]: </span><br><span class="line">           a</span><br><span class="line"><span class="number">0</span>  -<span class="number">0.204708</span></span><br><span class="line"><span class="number">1</span>   <span class="number">0.478943</span></span><br><span class="line"><span class="number">2</span>  -<span class="number">0.519439</span></span><br><span class="line"><span class="number">3</span>  -<span class="number">0.555730</span></span><br><span class="line"><span class="number">4</span>   <span class="number">1.965781</span></span><br><span class="line">..       ...</span><br><span class="line"><span class="number">95</span>  <span class="number">0.795253</span></span><br><span class="line"><span class="number">96</span>  <span class="number">0.118110</span></span><br><span class="line"><span class="number">97</span> -<span class="number">0.748532</span></span><br><span class="line"><span class="number">98</span>  <span class="number">0.584970</span></span><br><span class="line"><span class="number">99</span>  <span class="number">0.152677</span></span><br><span class="line">[<span class="number">100</span> rows x <span class="number">1</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>HDFStore支持两种存储模式，’fixed’和’table’。后者通常会更慢，但是支持使用特殊语法进行查询操作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">98</span>]: store.put(<span class="string">&#x27;obj2&#x27;</span>, frame, <span class="built_in">format</span>=<span class="string">&#x27;table&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: store.select(<span class="string">&#x27;obj2&#x27;</span>, where=[<span class="string">&#x27;index &gt;= 10 and index &lt;= 15&#x27;</span>])</span><br><span class="line">Out[<span class="number">99</span>]: </span><br><span class="line">           a</span><br><span class="line"><span class="number">10</span>  <span class="number">1.007189</span></span><br><span class="line"><span class="number">11</span> -<span class="number">1.296221</span></span><br><span class="line"><span class="number">12</span>  <span class="number">0.274992</span></span><br><span class="line"><span class="number">13</span>  <span class="number">0.228913</span></span><br><span class="line"><span class="number">14</span>  <span class="number">1.352917</span></span><br><span class="line"><span class="number">15</span>  <span class="number">0.886429</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: store.close()</span><br></pre></td></tr></table></figure></p>
<p>put是store[‘obj2’] = frame方法的显示版本，允许我们设置其它的选项，比如格式。</p>
<p>pandas.read_hdf函数可以快捷使用这些工具：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">101</span>]: frame.to_hdf(<span class="string">&#x27;mydata.h5&#x27;</span>, <span class="string">&#x27;obj3&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;table&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: pd.read_hdf(<span class="string">&#x27;mydata.h5&#x27;</span>, <span class="string">&#x27;obj3&#x27;</span>, where=[<span class="string">&#x27;index &lt; 5&#x27;</span>])</span><br><span class="line">Out[<span class="number">102</span>]: </span><br><span class="line">          a</span><br><span class="line"><span class="number">0</span> -<span class="number">0.204708</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.478943</span></span><br><span class="line"><span class="number">2</span> -<span class="number">0.519439</span></span><br><span class="line"><span class="number">3</span> -<span class="number">0.555730</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.965781</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：如果你要处理的数据位于远程服务器，比如Amazon S3或HDFS，使用专门为分布式存储（比如Apache Parquet）的二进制格式也许更加合适。Python的Parquet和其它存储格式还在不断的发展之中，所以这本书中没有涉及。</p>
</blockquote>
<p>如果需要本地处理海量数据，我建议你好好研究一下PyTables和h5py，看看它们能满足你的哪些需求。。由于许多数据分析问题都是IO密集型（而不是CPU密集型），利用HDF5这样的工具能显著提升应用程序的效率。</p>
<blockquote>
<p>注意：HDF5不是数据库。它最适合用作“一次写多次读”的数据集。虽然数据可以在任何时候被添加到文件中，但如果同时发生多个写操作，文件就可能会被破坏。</p>
</blockquote>
<h2><span id="读取microsoft-excel文件">读取Microsoft Excel文件</span></h2><p>pandas的ExcelFile类或pandas.read_excel函数支持读取存储在Excel 2003（或更高版本）中的表格型数据。这两个工具分别使用扩展包xlrd和openpyxl读取XLS和XLSX文件。你可以用pip或conda安装它们。</p>
<p>要使用ExcelFile，通过传递xls或xlsx路径创建一个实例：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">104</span>]: xlsx = pd.ExcelFile(<span class="string">&#x27;examples/ex1.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>存储在表单中的数据可以read_excel读取到DataFrame（原书这里写的是用parse解析，但代码中用的是read_excel，是个笔误：只换了代码，没有改文字）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">105</span>]: pd.read_excel(xlsx, <span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line">Out[<span class="number">105</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>如果要读取一个文件中的多个表单，创建ExcelFile会更快，但你也可以将文件名传递到pandas.read_excel：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">106</span>]: frame = pd.read_excel(<span class="string">&#x27;examples/ex1.xlsx&#x27;</span>, <span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">107</span>]: frame</span><br><span class="line">Out[<span class="number">107</span>]: </span><br><span class="line">   a   b   c   d message</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>   <span class="number">2</span>   <span class="number">3</span>   <span class="number">4</span>   hello</span><br><span class="line"><span class="number">1</span>  <span class="number">5</span>   <span class="number">6</span>   <span class="number">7</span>   <span class="number">8</span>   world</span><br><span class="line"><span class="number">2</span>  <span class="number">9</span>  <span class="number">10</span>  <span class="number">11</span>  <span class="number">12</span>     foo</span><br></pre></td></tr></table></figure></p>
<p>如果要将pandas数据写入为Excel格式，你必须首先创建一个ExcelWriter，然后使用pandas对象的to_excel方法将数据写入到其中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: writer = pd.ExcelWriter(<span class="string">&#x27;examples/ex2.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: frame.to_excel(writer, <span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: writer.save()</span><br></pre></td></tr></table></figure></p>
<p>你还可以不使用ExcelWriter，而是传递文件的路径到to_excel：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">111</span>]: frame.to_excel(<span class="string">&#x27;examples/ex2.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h1><span id="63-web-apis交互">6.3 Web APIs交互</span></h1><p>许多网站都有一些通过JSON或其他格式提供数据的公共API。通过Python访问这些API的办法有不少。一个简单易用的办法（推荐）是requests包（<a href="http://docs.python-requests.org）。">http://docs.python-requests.org）。</a></p>
<p>为了搜索最新的30个GitHub上的pandas主题，我们可以发一个HTTP GET请求，使用requests扩展库：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">113</span>]: <span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: url = <span class="string">&#x27;https://api.github.com/repos/pandas-dev/pandas/issues&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">115</span>]: resp = requests.get(url)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: resp</span><br><span class="line">Out[<span class="number">116</span>]: &lt;Response [<span class="number">200</span>]&gt;</span><br></pre></td></tr></table></figure></p>
<p>响应对象的json方法会返回一个包含被解析过的JSON字典，加载到一个Python对象中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: data = resp.json()</span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: data[<span class="number">0</span>][<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">Out[<span class="number">118</span>]: <span class="string">&#x27;Period does not round down for frequencies less that 1 hour&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>data中的每个元素都是一个包含所有GitHub主题页数据（不包含评论）的字典。我们可以直接传递数据到DataFrame，并提取感兴趣的字段：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">119</span>]: issues = pd.DataFrame(data, columns=[<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;title&#x27;</span>,</span><br><span class="line">   .....:                                      <span class="string">&#x27;labels&#x27;</span>, <span class="string">&#x27;state&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">120</span>]: issues</span><br><span class="line">Out[<span class="number">120</span>]:</span><br><span class="line">    number                                              title  \</span><br><span class="line"><span class="number">0</span>    <span class="number">17666</span>  Period does <span class="keyword">not</span> <span class="built_in">round</span> down <span class="keyword">for</span> frequencies les...   </span><br><span class="line"><span class="number">1</span>    <span class="number">17665</span>           DOC: improve docstring of function where   </span><br><span class="line"><span class="number">2</span>    <span class="number">17664</span>               COMPAT: skip <span class="number">32</span>-bit test on <span class="built_in">int</span> <span class="built_in">repr</span>   </span><br><span class="line"><span class="number">3</span>    <span class="number">17662</span>                          implement Delegator <span class="class"><span class="keyword">class</span></span></span><br><span class="line"><span class="class">4    17654  <span class="title">BUG</span>:</span> Fix series rename called <span class="keyword">with</span> <span class="built_in">str</span> alterin...   </span><br><span class="line">..     ...                                                ...   </span><br><span class="line"><span class="number">25</span>   <span class="number">17603</span>  BUG: Correctly localize naive datetime strings...   </span><br><span class="line"><span class="number">26</span>   <span class="number">17599</span>                     core.dtypes.generic --&gt; cython   </span><br><span class="line"><span class="number">27</span>   <span class="number">17596</span>   Merge cdate_range functionality into bdate_range   </span><br><span class="line"><span class="number">28</span>   <span class="number">17587</span>  Time Grouper bug fix when applied <span class="keyword">for</span> <span class="built_in">list</span> gro...   </span><br><span class="line"><span class="number">29</span>   <span class="number">17583</span>  BUG: fix tz-aware DatetimeIndex + TimedeltaInd...   </span><br><span class="line">                                               labels state  </span><br><span class="line"><span class="number">0</span>                                                  []  <span class="built_in">open</span>  </span><br><span class="line"><span class="number">1</span>   [&#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">134699</span>, <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://api.github.com...  open  </span></span><br><span class="line"><span class="string">2   [&#123;&#x27;</span><span class="built_in">id</span><span class="string">&#x27;: 563047854, &#x27;</span>url<span class="string">&#x27;: &#x27;</span>https://api.github....  <span class="built_in">open</span>  </span><br><span class="line"><span class="number">3</span>                                                  []  <span class="built_in">open</span>  </span><br><span class="line"><span class="number">4</span>   [&#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">76811</span>, <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://api.github.com/...  open  </span></span><br><span class="line"><span class="string">..                                                ...   ...  </span></span><br><span class="line"><span class="string">25  [&#123;&#x27;</span><span class="built_in">id</span><span class="string">&#x27;: 76811, &#x27;</span>url<span class="string">&#x27;: &#x27;</span>https://api.github.com/...  <span class="built_in">open</span>  </span><br><span class="line"><span class="number">26</span>  [&#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">49094459</span>, <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://api.github.c...  open  </span></span><br><span class="line"><span class="string">27  [&#123;&#x27;</span><span class="built_in">id</span><span class="string">&#x27;: 35818298, &#x27;</span>url<span class="string">&#x27;: &#x27;</span>https://api.github.c...  <span class="built_in">open</span>  </span><br><span class="line"><span class="number">28</span>  [&#123;<span class="string">&#x27;id&#x27;</span>: <span class="number">233160</span>, <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://api.github.com...  open  </span></span><br><span class="line"><span class="string">29  [&#123;&#x27;</span><span class="built_in">id</span><span class="string">&#x27;: 76811, &#x27;</span>url<span class="string">&#x27;: &#x27;</span>https://api.github.com/...  <span class="built_in">open</span>  </span><br><span class="line">[<span class="number">30</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>花费一些精力，你就可以创建一些更高级的常见的Web API的接口，返回DataFrame对象，方便进行分析。</p>
<h1><span id="64-数据库交互">6.4 数据库交互</span></h1><p>在商业场景下，大多数数据可能不是存储在文本或Excel文件中。基于SQL的关系型数据库（如SQL Server、PostgreSQL和MySQL等）使用非常广泛，其它一些数据库也很流行。数据库的选择通常取决于性能、数据完整性以及应用程序的伸缩性需求。</p>
<p>将数据从SQL加载到DataFrame的过程很简单，此外pandas还有一些能够简化该过程的函数。例如，我将使用SQLite数据库（通过Python内置的sqlite3驱动器）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">121</span>]: <span class="keyword">import</span> sqlite3</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   .....: CREATE TABLE test</span></span><br><span class="line"><span class="string">   .....: (a VARCHAR(20), b VARCHAR(20),</span></span><br><span class="line"><span class="string">   .....:  c REAL,        d INTEGER</span></span><br><span class="line"><span class="string">   .....: );&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">123</span>]: con = sqlite3.connect(<span class="string">&#x27;mydata.sqlite&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: con.execute(query)</span><br><span class="line">Out[<span class="number">124</span>]: &lt;sqlite3.Cursor at <span class="number">0x7f6b12a50f10</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: con.commit()</span><br></pre></td></tr></table></figure></p>
<p>然后插入几行数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">126</span>]: data = [(<span class="string">&#x27;Atlanta&#x27;</span>, <span class="string">&#x27;Georgia&#x27;</span>, <span class="number">1.25</span>, <span class="number">6</span>),</span><br><span class="line">   .....:         (<span class="string">&#x27;Tallahassee&#x27;</span>, <span class="string">&#x27;Florida&#x27;</span>, <span class="number">2.6</span>, <span class="number">3</span>),</span><br><span class="line">   .....:         (<span class="string">&#x27;Sacramento&#x27;</span>, <span class="string">&#x27;California&#x27;</span>, <span class="number">1.7</span>, <span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">127</span>]: stmt = <span class="string">&quot;INSERT INTO test VALUES(?, ?, ?, ?)&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">128</span>]: con.executemany(stmt, data)</span><br><span class="line">Out[<span class="number">128</span>]: &lt;sqlite3.Cursor at <span class="number">0x7f6b15c66ce0</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p>从表中选取数据时，大部分Python SQL驱动器（PyODBC、psycopg2、MySQLdb、pymssql等）都会返回一个元组列表：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">130</span>]: cursor = con.execute(<span class="string">&#x27;select * from test&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">131</span>]: rows = cursor.fetchall()</span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: rows</span><br><span class="line">Out[<span class="number">132</span>]: </span><br><span class="line">[(<span class="string">&#x27;Atlanta&#x27;</span>, <span class="string">&#x27;Georgia&#x27;</span>, <span class="number">1.25</span>, <span class="number">6</span>),</span><br><span class="line"> (<span class="string">&#x27;Tallahassee&#x27;</span>, <span class="string">&#x27;Florida&#x27;</span>, <span class="number">2.6</span>, <span class="number">3</span>),</span><br><span class="line"> (<span class="string">&#x27;Sacramento&#x27;</span>, <span class="string">&#x27;California&#x27;</span>, <span class="number">1.7</span>, <span class="number">5</span>)]</span><br></pre></td></tr></table></figure></p>
<p>你可以将这个元组列表传给DataFrame构造器，但还需要列名（位于光标的description属性中）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">133</span>]: cursor.description</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">((<span class="string">&#x27;a&#x27;</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>),</span><br><span class="line"> (<span class="string">&#x27;b&#x27;</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>),</span><br><span class="line"> (<span class="string">&#x27;c&#x27;</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>),</span><br><span class="line"> (<span class="string">&#x27;d&#x27;</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: pd.DataFrame(rows, columns=[x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> cursor.description])</span><br><span class="line">Out[<span class="number">134</span>]: </span><br><span class="line">             a           b     c  d</span><br><span class="line"><span class="number">0</span>      Atlanta     Georgia  <span class="number">1.25</span>  <span class="number">6</span></span><br><span class="line"><span class="number">1</span>  Tallahassee     Florida  <span class="number">2.60</span>  <span class="number">3</span></span><br><span class="line"><span class="number">2</span>   Sacramento  California  <span class="number">1.70</span>  <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p>这种数据规整操作相当多，你肯定不想每查一次数据库就重写一次。<a href="http://www.sqlalchemy.org/">SQLAlchemy项目</a>是一个流行的Python SQL工具，它抽象出了SQL数据库中的许多常见差异。pandas有一个read_sql函数，可以让你轻松的从SQLAlchemy连接读取数据。这里，我们用SQLAlchemy连接SQLite数据库，并从之前创建的表读取数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">135</span>]: <span class="keyword">import</span> sqlalchemy <span class="keyword">as</span> sqla</span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: db = sqla.create_engine(<span class="string">&#x27;sqlite:///mydata.sqlite&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">137</span>]: pd.read_sql(<span class="string">&#x27;select * from test&#x27;</span>, db)</span><br><span class="line">Out[<span class="number">137</span>]: </span><br><span class="line">             a           b     c  d</span><br><span class="line"><span class="number">0</span>      Atlanta     Georgia  <span class="number">1.25</span>  <span class="number">6</span></span><br><span class="line"><span class="number">1</span>  Tallahassee     Florida  <span class="number">2.60</span>  <span class="number">3</span></span><br><span class="line"><span class="number">2</span>   Sacramento  California  <span class="number">1.70</span>  <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="65-总结">6.5 总结</span></h1><p>访问数据通常是数据分析的第一步。在本章中，我们已经学了一些有用的工具。在接下来的章节中，我们将深入研究数据规整、数据可视化、时间序列分析和其它主题。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-5.pandas</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-5-pandas/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>pandas是本书后续内容的首选库。它含有使数据清洗和分析工作变得更快更简单的数据结构和操作工具。pandas经常和其它工具一同使用，如数值计算工具NumPy和SciPy，分析库statsmodels和scikit-learn，和数据可视化库matplotlib。pandas是基于NumPy数组构建的，特别是基于数组的函数和不使用for循环的数据处理。</p>
<span id="more"></span>
<p>虽然pandas采用了大量的NumPy编码风格，但二者最大的不同是pandas是专门为处理表格和混杂数据设计的。而NumPy更适合处理统一的数值数组数据。</p>
<p>自从2010年pandas开源以来，pandas逐渐成长为一个非常大的库，应用于许多真实案例。开发者社区已经有了800个独立的贡献者，他们在解决日常数据问题的同时为这个项目提供贡献。</p>
<p>在本书后续部分中，我将使用下面这样的pandas引入约定：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure></p>
<p>因此，只要你在代码中看到pd.，就得想到这是pandas。因为Series和DataFrame用的次数非常多，所以将其引入本地命名空间中会更方便：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">2</span>]: <span class="keyword">from</span> pandas <span class="keyword">import</span> Series, DataFrame</span><br></pre></td></tr></table></figure></p>
<h1><span id="51-pandas的数据结构介绍">5.1 pandas的数据结构介绍</span></h1><p>要使用pandas，你首先就得熟悉它的两个主要数据结构：Series和DataFrame。虽然它们并不能解决所有问题，但它们为大多数应用提供了一种可靠的、易于使用的基础。</p>
<h2><span id="series">Series</span></h2><p>Series是一种类似于一维数组的对象，它由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。仅由一组数据即可产生最简单的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">11</span>]: obj = pd.Series([<span class="number">4</span>, <span class="number">7</span>, -<span class="number">5</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: obj</span><br><span class="line">Out[<span class="number">12</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">4</span></span><br><span class="line"><span class="number">1</span>    <span class="number">7</span></span><br><span class="line"><span class="number">2</span>   -<span class="number">5</span></span><br><span class="line"><span class="number">3</span>    <span class="number">3</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>Series的字符串表现形式为：索引在左边，值在右边。由于我们没有为数据指定索引，于是会自动创建一个0到N-1（N为数据的长度）的整数型索引。你可以通过Series 的values和index属性获取其数组表示形式和索引对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: obj.values</span><br><span class="line">Out[<span class="number">13</span>]: array([ <span class="number">4</span>,  <span class="number">7</span>, -<span class="number">5</span>,  <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: obj.index  <span class="comment"># like range(4)</span></span><br><span class="line">Out[<span class="number">14</span>]: RangeIndex(start=<span class="number">0</span>, stop=<span class="number">4</span>, step=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>通常，我们希望所创建的Series带有一个可以对各个数据点进行标记的索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: obj2 = pd.Series([<span class="number">4</span>, <span class="number">7</span>, -<span class="number">5</span>, <span class="number">3</span>], index=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: obj2</span><br><span class="line">Out[<span class="number">16</span>]: </span><br><span class="line">d    <span class="number">4</span></span><br><span class="line">b    <span class="number">7</span></span><br><span class="line">a   -<span class="number">5</span></span><br><span class="line">c    <span class="number">3</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: obj2.index</span><br><span class="line">Out[<span class="number">17</span>]: Index([<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>与普通NumPy数组相比，你可以通过索引的方式选取Series中的单个或一组值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: obj2[<span class="string">&#x27;a&#x27;</span>]</span><br><span class="line">Out[<span class="number">18</span>]: -<span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: obj2[<span class="string">&#x27;d&#x27;</span>] = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: obj2[[<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>]]</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">c    <span class="number">3</span></span><br><span class="line">a   -<span class="number">5</span></span><br><span class="line">d    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>[‘c’, ‘a’, ‘d’]是索引列表，即使它包含的是字符串而不是整数。</p>
<p>使用NumPy函数或类似NumPy的运算（如根据布尔型数组进行过滤、标量乘法、应用数学函数等）都会保留索引值的链接：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: obj2[obj2 &gt; <span class="number">0</span>]</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">d    <span class="number">6</span></span><br><span class="line">b    <span class="number">7</span></span><br><span class="line">c    <span class="number">3</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: obj2 * <span class="number">2</span></span><br><span class="line">Out[<span class="number">22</span>]:</span><br><span class="line">d    <span class="number">12</span></span><br><span class="line">b    <span class="number">14</span></span><br><span class="line">a   -<span class="number">10</span></span><br><span class="line">c     <span class="number">6</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: np.exp(obj2)</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line">d     <span class="number">403.428793</span></span><br><span class="line">b    <span class="number">1096.633158</span></span><br><span class="line">a       <span class="number">0.006738</span></span><br><span class="line">c      <span class="number">20.085537</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>还可以将Series看成是一个定长的有序字典，因为它是索引值到数据值的一个映射。它可以用在许多原本需要字典参数的函数中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> obj2</span><br><span class="line">Out[<span class="number">24</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: <span class="string">&#x27;e&#x27;</span> <span class="keyword">in</span> obj2</span><br><span class="line">Out[<span class="number">25</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>如果数据被存放在一个Python字典中，也可以直接通过这个字典来创建Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">26</span>]: sdata = &#123;<span class="string">&#x27;Ohio&#x27;</span>: <span class="number">35000</span>, <span class="string">&#x27;Texas&#x27;</span>: <span class="number">71000</span>, <span class="string">&#x27;Oregon&#x27;</span>: <span class="number">16000</span>, <span class="string">&#x27;Utah&#x27;</span>: <span class="number">5000</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: obj3 = pd.Series(sdata)</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: obj3</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">Ohio      <span class="number">35000</span></span><br><span class="line">Oregon    <span class="number">16000</span></span><br><span class="line">Texas     <span class="number">71000</span></span><br><span class="line">Utah       <span class="number">5000</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>如果只传入一个字典，则结果Series中的索引就是原字典的键（有序排列）。你可以传入排好序的字典的键以改变顺序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: states = [<span class="string">&#x27;California&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Oregon&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: obj4 = pd.Series(sdata, index=states)</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: obj4</span><br><span class="line">Out[<span class="number">31</span>]: </span><br><span class="line">California        NaN</span><br><span class="line">Ohio          <span class="number">35000.0</span></span><br><span class="line">Oregon        <span class="number">16000.0</span></span><br><span class="line">Texas         <span class="number">71000.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>在这个例子中，sdata中跟states索引相匹配的那3个值会被找出来并放到相应的位置上，但由于”California”所对应的sdata值找不到，所以其结果就为NaN（即“非数字”（not a number），在pandas中，它用于表示缺失或NA值）。因为‘Utah’不在states中，它被从结果中除去。</p>
<p>我将使用缺失（missing）或NA表示缺失数据。pandas的isnull和notnull函数可用于检测缺失数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: pd.isnull(obj4)</span><br><span class="line">Out[<span class="number">32</span>]: </span><br><span class="line">California     <span class="literal">True</span></span><br><span class="line">Ohio          <span class="literal">False</span></span><br><span class="line">Oregon        <span class="literal">False</span></span><br><span class="line">Texas         <span class="literal">False</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: pd.notnull(obj4)</span><br><span class="line">Out[<span class="number">33</span>]: </span><br><span class="line">California    <span class="literal">False</span></span><br><span class="line">Ohio           <span class="literal">True</span></span><br><span class="line">Oregon         <span class="literal">True</span></span><br><span class="line">Texas          <span class="literal">True</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure></p>
<p>Series也有类似的实例方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: obj4.isnull()</span><br><span class="line">Out[<span class="number">34</span>]: </span><br><span class="line">California     <span class="literal">True</span></span><br><span class="line">Ohio          <span class="literal">False</span></span><br><span class="line">Oregon        <span class="literal">False</span></span><br><span class="line">Texas         <span class="literal">False</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br></pre></td></tr></table></figure></p>
<p>我将在第7章详细讲解如何处理缺失数据。</p>
<p>对于许多应用而言，Series最重要的一个功能是，它会根据运算的索引标签自动对齐数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: obj3</span><br><span class="line">Out[<span class="number">35</span>]: </span><br><span class="line">Ohio      <span class="number">35000</span></span><br><span class="line">Oregon    <span class="number">16000</span></span><br><span class="line">Texas     <span class="number">71000</span></span><br><span class="line">Utah       <span class="number">5000</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: obj4</span><br><span class="line">Out[<span class="number">36</span>]: </span><br><span class="line">California        NaN</span><br><span class="line">Ohio          <span class="number">35000.0</span></span><br><span class="line">Oregon        <span class="number">16000.0</span></span><br><span class="line">Texas         <span class="number">71000.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: obj3 + obj4</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">California         NaN</span><br><span class="line">Ohio           <span class="number">70000.0</span></span><br><span class="line">Oregon         <span class="number">32000.0</span></span><br><span class="line">Texas         <span class="number">142000.0</span></span><br><span class="line">Utah               NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>数据对齐功能将在后面详细讲解。如果你使用过数据库，你可以认为是类似join的操作。</p>
<p>Series对象本身及其索引都有一个name属性，该属性跟pandas其他的关键功能关系非常密切：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">38</span>]: obj4.name = <span class="string">&#x27;population&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: obj4.index.name = <span class="string">&#x27;state&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: obj4</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">state</span><br><span class="line">California        NaN</span><br><span class="line">Ohio          <span class="number">35000.0</span></span><br><span class="line">Oregon        <span class="number">16000.0</span></span><br><span class="line">Texas         <span class="number">71000.0</span></span><br><span class="line">Name: population, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>Series的索引可以通过赋值的方式就地修改：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: obj</span><br><span class="line">Out[<span class="number">41</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">4</span></span><br><span class="line"><span class="number">1</span>    <span class="number">7</span></span><br><span class="line"><span class="number">2</span>   -<span class="number">5</span></span><br><span class="line"><span class="number">3</span>    <span class="number">3</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: obj.index = [<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Steve&#x27;</span>, <span class="string">&#x27;Jeff&#x27;</span>, <span class="string">&#x27;Ryan&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: obj</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line">Bob      <span class="number">4</span></span><br><span class="line">Steve    <span class="number">7</span></span><br><span class="line">Jeff    -<span class="number">5</span></span><br><span class="line">Ryan     <span class="number">3</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<h2><span id="dataframe">DataFrame</span></h2><p>DataFrame是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame既有行索引也有列索引，它可以被看做由Series组成的字典（共用同一个索引）。DataFrame中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。有关DataFrame内部的技术细节远远超出了本书所讨论的范围。</p>
<blockquote>
<p>笔记：虽然DataFrame是以二维结构保存数据的，但你仍然可以轻松地将其表示为更高维度的数据（层次化索引的表格型结构，这是pandas中许多高级数据处理功能的关键要素，我们会在第8章讨论这个问题）。</p>
</blockquote>
<p>建DataFrame的办法有很多，最常用的一种是直接传入一个由等长列表或NumPy数组组成的字典：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = &#123;<span class="string">&#x27;state&#x27;</span>: [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2003</span>],</span><br><span class="line">        <span class="string">&#x27;pop&#x27;</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>, <span class="number">3.2</span>]&#125;</span><br><span class="line">frame = pd.DataFrame(data)</span><br></pre></td></tr></table></figure></p>
<p>结果DataFrame会自动加上索引（跟Series一样），且全部列会被有序排列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: frame</span><br><span class="line">Out[<span class="number">45</span>]: </span><br><span class="line">   pop   state  year</span><br><span class="line"><span class="number">0</span>  <span class="number">1.5</span>    Ohio  <span class="number">2000</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.7</span>    Ohio  <span class="number">2001</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3.6</span>    Ohio  <span class="number">2002</span></span><br><span class="line"><span class="number">3</span>  <span class="number">2.4</span>  Nevada  <span class="number">2001</span></span><br><span class="line"><span class="number">4</span>  <span class="number">2.9</span>  Nevada  <span class="number">2002</span></span><br><span class="line"><span class="number">5</span>  <span class="number">3.2</span>  Nevada  <span class="number">2003</span></span><br></pre></td></tr></table></figure></p>
<p>如果你使用的是Jupyter notebook，pandas DataFrame对象会以对浏览器友好的HTML表格的方式呈现。</p>
<p>对于特别大的DataFrame，head方法会选取前五行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">46</span>]: frame.head()</span><br><span class="line">Out[<span class="number">46</span>]: </span><br><span class="line">   pop   state  year</span><br><span class="line"><span class="number">0</span>  <span class="number">1.5</span>    Ohio  <span class="number">2000</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.7</span>    Ohio  <span class="number">2001</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3.6</span>    Ohio  <span class="number">2002</span></span><br><span class="line"><span class="number">3</span>  <span class="number">2.4</span>  Nevada  <span class="number">2001</span></span><br><span class="line"><span class="number">4</span>  <span class="number">2.9</span>  Nevada  <span class="number">2002</span></span><br></pre></td></tr></table></figure></p>
<p>如果指定了列序列，则DataFrame的列就会按照指定顺序进行排列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: pd.DataFrame(data, columns=[<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;state&#x27;</span>, <span class="string">&#x27;pop&#x27;</span>])</span><br><span class="line">Out[<span class="number">47</span>]: </span><br><span class="line">   year   state  pop</span><br><span class="line"><span class="number">0</span>  <span class="number">2000</span>    Ohio  <span class="number">1.5</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2001</span>    Ohio  <span class="number">1.7</span></span><br><span class="line"><span class="number">2</span>  <span class="number">2002</span>    Ohio  <span class="number">3.6</span></span><br><span class="line"><span class="number">3</span>  <span class="number">2001</span>  Nevada  <span class="number">2.4</span></span><br><span class="line"><span class="number">4</span>  <span class="number">2002</span>  Nevada  <span class="number">2.9</span></span><br><span class="line"><span class="number">5</span>  <span class="number">2003</span>  Nevada  <span class="number">3.2</span></span><br></pre></td></tr></table></figure></p>
<p>如果传入的列在数据中找不到，就会在结果中产生缺失值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: frame2 = pd.DataFrame(data, columns=[<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;state&#x27;</span>, <span class="string">&#x27;pop&#x27;</span>, <span class="string">&#x27;debt&#x27;</span>],</span><br><span class="line">   ....:                       index=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>,</span><br><span class="line">   ....:                              <span class="string">&#x27;five&#x27;</span>, <span class="string">&#x27;six&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: frame2</span><br><span class="line">Out[<span class="number">49</span>]: </span><br><span class="line">       year   state  pop debt</span><br><span class="line">one    <span class="number">2000</span>    Ohio  <span class="number">1.5</span>  NaN</span><br><span class="line">two    <span class="number">2001</span>    Ohio  <span class="number">1.7</span>  NaN</span><br><span class="line">three  <span class="number">2002</span>    Ohio  <span class="number">3.6</span>  NaN</span><br><span class="line">four   <span class="number">2001</span>  Nevada  <span class="number">2.4</span>  NaN</span><br><span class="line">five   <span class="number">2002</span>  Nevada  <span class="number">2.9</span>  NaN</span><br><span class="line">six    <span class="number">2003</span>  Nevada  <span class="number">3.2</span>  NaN</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: frame2.columns</span><br><span class="line">Out[<span class="number">50</span>]: Index([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;state&#x27;</span>, <span class="string">&#x27;pop&#x27;</span>, <span class="string">&#x27;debt&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>通过类似字典标记的方式或属性的方式，可以将DataFrame的列获取为一个Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: frame2[<span class="string">&#x27;state&#x27;</span>]</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">one        Ohio</span><br><span class="line">two        Ohio</span><br><span class="line">three      Ohio</span><br><span class="line">four     Nevada</span><br><span class="line">five     Nevada</span><br><span class="line">six      Nevada</span><br><span class="line">Name: state, dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: frame2.year</span><br><span class="line">Out[<span class="number">52</span>]: </span><br><span class="line">one      <span class="number">2000</span></span><br><span class="line">two      <span class="number">2001</span></span><br><span class="line">three    <span class="number">2002</span></span><br><span class="line">four     <span class="number">2001</span></span><br><span class="line">five     <span class="number">2002</span></span><br><span class="line">six      <span class="number">2003</span></span><br><span class="line">Name: year, dtype: int64</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：IPython提供了类似属性的访问（即frame2.year）和tab补全。<br>frame2[column]适用于任何列的名，但是frame2.column只有在列名是一个合理的Python变量名时才适用。</p>
</blockquote>
<p>注意，返回的Series拥有原DataFrame相同的索引，且其name属性也已经被相应地设置好了。</p>
<p>行也可以通过位置或名称的方式进行获取，比如用loc属性（稍后将对此进行详细讲解）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">53</span>]: frame2.loc[<span class="string">&#x27;three&#x27;</span>]</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">year     <span class="number">2002</span></span><br><span class="line">state    Ohio</span><br><span class="line">pop       <span class="number">3.6</span></span><br><span class="line">debt      NaN</span><br><span class="line">Name: three, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>列可以通过赋值的方式进行修改。例如，我们可以给那个空的”debt”列赋上一个标量值或一组值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">54</span>]: frame2[<span class="string">&#x27;debt&#x27;</span>] = <span class="number">16.5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: frame2</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line">       year   state  pop  debt</span><br><span class="line">one    <span class="number">2000</span>    Ohio  <span class="number">1.5</span>  <span class="number">16.5</span></span><br><span class="line">two    <span class="number">2001</span>    Ohio  <span class="number">1.7</span>  <span class="number">16.5</span></span><br><span class="line">three  <span class="number">2002</span>    Ohio  <span class="number">3.6</span>  <span class="number">16.5</span></span><br><span class="line">four   <span class="number">2001</span>  Nevada  <span class="number">2.4</span>  <span class="number">16.5</span></span><br><span class="line">five   <span class="number">2002</span>  Nevada  <span class="number">2.9</span>  <span class="number">16.5</span></span><br><span class="line">six    <span class="number">2003</span>  Nevada  <span class="number">3.2</span>  <span class="number">16.5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">56</span>]: frame2[<span class="string">&#x27;debt&#x27;</span>] = np.arange(<span class="number">6.</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: frame2</span><br><span class="line">Out[<span class="number">57</span>]: </span><br><span class="line">       year   state  pop  debt</span><br><span class="line">one    <span class="number">2000</span>    Ohio  <span class="number">1.5</span>   <span class="number">0.0</span></span><br><span class="line">two    <span class="number">2001</span>    Ohio  <span class="number">1.7</span>   <span class="number">1.0</span></span><br><span class="line">three  <span class="number">2002</span>    Ohio  <span class="number">3.6</span>   <span class="number">2.0</span></span><br><span class="line">four   <span class="number">2001</span>  Nevada  <span class="number">2.4</span>   <span class="number">3.0</span></span><br><span class="line">five   <span class="number">2002</span>  Nevada  <span class="number">2.9</span>   <span class="number">4.0</span></span><br><span class="line">six    <span class="number">2003</span>  Nevada  <span class="number">3.2</span>   <span class="number">5.0</span></span><br></pre></td></tr></table></figure></p>
<p>将列表或数组赋值给某个列时，其长度必须跟DataFrame的长度相匹配。如果赋值的是一个Series，就会精确匹配DataFrame的索引，所有的空位都将被填上缺失值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">58</span>]: val = pd.Series([-<span class="number">1.2</span>, -<span class="number">1.5</span>, -<span class="number">1.7</span>], index=[<span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;four&#x27;</span>, <span class="string">&#x27;five&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: frame2[<span class="string">&#x27;debt&#x27;</span>] = val</span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: frame2</span><br><span class="line">Out[<span class="number">60</span>]: </span><br><span class="line">       year   state  pop  debt</span><br><span class="line">one    <span class="number">2000</span>    Ohio  <span class="number">1.5</span>   NaN</span><br><span class="line">two    <span class="number">2001</span>    Ohio  <span class="number">1.7</span>  -<span class="number">1.2</span></span><br><span class="line">three  <span class="number">2002</span>    Ohio  <span class="number">3.6</span>   NaN</span><br><span class="line">four   <span class="number">2001</span>  Nevada  <span class="number">2.4</span>  -<span class="number">1.5</span></span><br><span class="line">five   <span class="number">2002</span>  Nevada  <span class="number">2.9</span>  -<span class="number">1.7</span></span><br><span class="line">six    <span class="number">2003</span>  Nevada  <span class="number">3.2</span>   NaN</span><br></pre></td></tr></table></figure></p>
<p>为不存在的列赋值会创建出一个新列。关键字del用于删除列。</p>
<p>作为del的例子，我先添加一个新的布尔值的列，state是否为’Ohio’：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">61</span>]: frame2[<span class="string">&#x27;eastern&#x27;</span>] = frame2.state == <span class="string">&#x27;Ohio&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: frame2</span><br><span class="line">Out[<span class="number">62</span>]: </span><br><span class="line">       year   state  pop  debt  eastern</span><br><span class="line">one    <span class="number">2000</span>    Ohio  <span class="number">1.5</span>   NaN     <span class="literal">True</span></span><br><span class="line">two    <span class="number">2001</span>    Ohio  <span class="number">1.7</span>  -<span class="number">1.2</span>     <span class="literal">True</span></span><br><span class="line">three  <span class="number">2002</span>    Ohio  <span class="number">3.6</span>   NaN     <span class="literal">True</span></span><br><span class="line">four   <span class="number">2001</span>  Nevada  <span class="number">2.4</span>  -<span class="number">1.5</span>    <span class="literal">False</span></span><br><span class="line">five   <span class="number">2002</span>  Nevada  <span class="number">2.9</span>  -<span class="number">1.7</span>    <span class="literal">False</span></span><br><span class="line">six    <span class="number">2003</span>  Nevada  <span class="number">3.2</span>   NaN    <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：不能用frame2.eastern创建新的列。</p>
</blockquote>
<p>del方法可以用来删除这列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">63</span>]: <span class="keyword">del</span> frame2[<span class="string">&#x27;eastern&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: frame2.columns</span><br><span class="line">Out[<span class="number">64</span>]: Index([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;state&#x27;</span>, <span class="string">&#x27;pop&#x27;</span>, <span class="string">&#x27;debt&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：通过索引方式返回的列只是相应数据的视图而已，并不是副本。因此，对返回的Series所做的任何就地修改全都会反映到源DataFrame上。通过Series的copy方法即可指定复制列。</p>
</blockquote>
<p>另一种常见的数据形式是嵌套字典：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">65</span>]: pop = &#123;<span class="string">&#x27;Nevada&#x27;</span>: &#123;<span class="number">2001</span>: <span class="number">2.4</span>, <span class="number">2002</span>: <span class="number">2.9</span>&#125;,</span><br><span class="line">....:        <span class="string">&#x27;Ohio&#x27;</span>: &#123;<span class="number">2000</span>: <span class="number">1.5</span>, <span class="number">2001</span>: <span class="number">1.7</span>, <span class="number">2002</span>: <span class="number">3.6</span>&#125;&#125;</span><br></pre></td></tr></table></figure></p>
<p>如果嵌套字典传给DataFrame，pandas就会被解释为：外层字典的键作为列，内层键则作为行索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: frame3 = pd.DataFrame(pop)</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: frame3</span><br><span class="line">Out[<span class="number">67</span>]: </span><br><span class="line">      Nevada  Ohio</span><br><span class="line"><span class="number">2000</span>     NaN   <span class="number">1.5</span></span><br><span class="line"><span class="number">2001</span>     <span class="number">2.4</span>   <span class="number">1.7</span></span><br><span class="line"><span class="number">2002</span>     <span class="number">2.9</span>   <span class="number">3.6</span></span><br></pre></td></tr></table></figure></p>
<p>你也可以使用类似NumPy数组的方法，对DataFrame进行转置（交换行和列）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: frame3.T</span><br><span class="line">Out[<span class="number">68</span>]: </span><br><span class="line">        <span class="number">2000</span>  <span class="number">2001</span>  <span class="number">2002</span></span><br><span class="line">Nevada   NaN   <span class="number">2.4</span>   <span class="number">2.9</span></span><br><span class="line">Ohio     <span class="number">1.5</span>   <span class="number">1.7</span>   <span class="number">3.6</span></span><br></pre></td></tr></table></figure></p>
<p>内层字典的键会被合并、排序以形成最终的索引。如果明确指定了索引，则不会这样：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: pd.DataFrame(pop, index=[<span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2003</span>])</span><br><span class="line">Out[<span class="number">69</span>]: </span><br><span class="line">      Nevada  Ohio</span><br><span class="line"><span class="number">2001</span>     <span class="number">2.4</span>   <span class="number">1.7</span></span><br><span class="line"><span class="number">2002</span>     <span class="number">2.9</span>   <span class="number">3.6</span></span><br><span class="line"><span class="number">2003</span>     NaN   NaN</span><br></pre></td></tr></table></figure></p>
<p>由Series组成的字典差不多也是一样的用法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">70</span>]: pdata = &#123;<span class="string">&#x27;Ohio&#x27;</span>: frame3[<span class="string">&#x27;Ohio&#x27;</span>][:-<span class="number">1</span>],</span><br><span class="line">....:          <span class="string">&#x27;Nevada&#x27;</span>: frame3[<span class="string">&#x27;Nevada&#x27;</span>][:<span class="number">2</span>]&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: pd.DataFrame(pdata)</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line">      Nevada  Ohio</span><br><span class="line"><span class="number">2000</span>     NaN   <span class="number">1.5</span></span><br><span class="line"><span class="number">2001</span>     <span class="number">2.4</span>   <span class="number">1.7</span></span><br></pre></td></tr></table></figure></p>
<p>表5-1列出了DataFrame构造函数所能接受的各种数据。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-106835b28c0cea5a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>如果设置了DataFrame的index和columns的name属性，则这些信息也会被显示出来：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">72</span>]: frame3.index.name = <span class="string">&#x27;year&#x27;</span>; frame3.columns.name = <span class="string">&#x27;state&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">73</span>]: frame3</span><br><span class="line">Out[<span class="number">73</span>]: </span><br><span class="line">state  Nevada  Ohio</span><br><span class="line">year</span><br><span class="line"><span class="number">2000</span>      NaN   <span class="number">1.5</span></span><br><span class="line"><span class="number">2001</span>      <span class="number">2.4</span>   <span class="number">1.7</span></span><br><span class="line"><span class="number">2002</span>      <span class="number">2.9</span>   <span class="number">3.6</span></span><br></pre></td></tr></table></figure></p>
<p>跟Series一样，values属性也会以二维ndarray的形式返回DataFrame中的数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: frame3.values</span><br><span class="line">Out[<span class="number">74</span>]: </span><br><span class="line">array([[ nan,  <span class="number">1.5</span>],</span><br><span class="line">       [ <span class="number">2.4</span>,  <span class="number">1.7</span>],</span><br><span class="line">       [ <span class="number">2.9</span>,  <span class="number">3.6</span>]])</span><br></pre></td></tr></table></figure></p>
<p>如果DataFrame各列的数据类型不同，则值数组的dtype就会选用能兼容所有列的数据类型：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: frame2.values</span><br><span class="line">Out[<span class="number">75</span>]:</span><br><span class="line">array([[<span class="number">2000</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="number">1.5</span>, nan],</span><br><span class="line">       [<span class="number">2001</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="number">1.7</span>, -<span class="number">1.2</span>],</span><br><span class="line">       [<span class="number">2002</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="number">3.6</span>, nan],</span><br><span class="line">       [<span class="number">2001</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="number">2.4</span>, -<span class="number">1.5</span>],</span><br><span class="line">       [<span class="number">2002</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="number">2.9</span>, -<span class="number">1.7</span>],</span><br><span class="line">       [<span class="number">2003</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="number">3.2</span>, nan]], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure></p>
<h2><span id="索引对象">索引对象</span></h2><p>pandas的索引对象负责管理轴标签和其他元数据（比如轴名称等）。构建Series或DataFrame时，所用到的任何数组或其他序列的标签都会被转换成一个Index：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: obj = pd.Series(<span class="built_in">range</span>(<span class="number">3</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: index = obj.index</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: index</span><br><span class="line">Out[<span class="number">78</span>]: Index([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: index[<span class="number">1</span>:]</span><br><span class="line">Out[<span class="number">79</span>]: Index([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>Index对象是不可变的，因此用户不能对其进行修改：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">index[<span class="number">1</span>] = <span class="string">&#x27;d&#x27;</span>  <span class="comment"># TypeError</span></span><br></pre></td></tr></table></figure></p>
<p>不可变可以使Index对象在多个数据结构之间安全共享：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">80</span>]: labels = pd.Index(np.arange(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: labels</span><br><span class="line">Out[<span class="number">81</span>]: Int64Index([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">82</span>]: obj2 = pd.Series([<span class="number">1.5</span>, -<span class="number">2.5</span>, <span class="number">0</span>], index=labels)</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: obj2</span><br><span class="line">Out[<span class="number">83</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.5</span></span><br><span class="line"><span class="number">1</span>   -<span class="number">2.5</span></span><br><span class="line"><span class="number">2</span>    <span class="number">0.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: obj2.index <span class="keyword">is</span> labels</span><br><span class="line">Out[<span class="number">84</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：虽然用户不需要经常使用Index的功能，但是因为一些操作会生成包含被索引化的数据，理解它们的工作原理是很重要的。</p>
</blockquote>
<p>除了类似于数组，Index的功能也类似一个固定大小的集合：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: frame3</span><br><span class="line">Out[<span class="number">85</span>]: </span><br><span class="line">state  Nevada  Ohio</span><br><span class="line">year               </span><br><span class="line"><span class="number">2000</span>      NaN   <span class="number">1.5</span></span><br><span class="line"><span class="number">2001</span>      <span class="number">2.4</span>   <span class="number">1.7</span></span><br><span class="line"><span class="number">2002</span>      <span class="number">2.9</span>   <span class="number">3.6</span></span><br><span class="line">In [<span class="number">86</span>]: frame3.columns</span><br><span class="line">Out[<span class="number">86</span>]: Index([<span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>, name=<span class="string">&#x27;state&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: <span class="string">&#x27;Ohio&#x27;</span> <span class="keyword">in</span> frame3.columns</span><br><span class="line">Out[<span class="number">87</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: <span class="number">2003</span> <span class="keyword">in</span> frame3.index</span><br><span class="line">Out[<span class="number">88</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>与python的集合不同，pandas的Index可以包含重复的标签：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">89</span>]: dup_labels = pd.Index([<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: dup_labels</span><br><span class="line">Out[<span class="number">90</span>]: Index([<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>选择重复的标签，会显示所有的结果。</p>
<p>每个索引都有一些方法和属性，它们可用于设置逻辑并回答有关该索引所包含的数据的常见问题。表5-2列出了这些函数。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-5499d14f0e2cd639.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h1><span id="52-基本功能">5.2 基本功能</span></h1><p>本节中，我将介绍操作Series和DataFrame中的数据的基本手段。后续章节将更加深入地挖掘pandas在数据分析和处理方面的功能。本书不是pandas库的详尽文档，主要关注的是最重要的功能，那些不大常用的内容（也就是那些更深奥的内容）就交给你自己去摸索吧。</p>
<h2><span id="重新索引">重新索引</span></h2><p>pandas对象的一个重要方法是reindex，其作用是创建一个新对象，它的数据符合新的索引。看下面的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: obj = pd.Series([<span class="number">4.5</span>, <span class="number">7.2</span>, -<span class="number">5.3</span>, <span class="number">3.6</span>], index=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: obj</span><br><span class="line">Out[<span class="number">92</span>]: </span><br><span class="line">d    <span class="number">4.5</span></span><br><span class="line">b    <span class="number">7.2</span></span><br><span class="line">a   -<span class="number">5.3</span></span><br><span class="line">c    <span class="number">3.6</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>用该Series的reindex将会根据新索引进行重排。如果某个索引值当前不存在，就引入缺失值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">93</span>]: obj2 = obj.reindex([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">94</span>]: obj2</span><br><span class="line">Out[<span class="number">94</span>]: </span><br><span class="line">a   -<span class="number">5.3</span></span><br><span class="line">b    <span class="number">7.2</span></span><br><span class="line">c    <span class="number">3.6</span></span><br><span class="line">d    <span class="number">4.5</span></span><br><span class="line">e    NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>对于时间序列这样的有序数据，重新索引时可能需要做一些插值处理。method选项即可达到此目的，例如，使用ffill可以实现前向值填充：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: obj3 = pd.Series([<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;purple&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>], index=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: obj3</span><br><span class="line">Out[<span class="number">96</span>]: </span><br><span class="line"><span class="number">0</span>      blue</span><br><span class="line"><span class="number">2</span>    purple</span><br><span class="line"><span class="number">4</span>    yellow</span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: obj3.reindex(<span class="built_in">range</span>(<span class="number">6</span>), method=<span class="string">&#x27;ffill&#x27;</span>)</span><br><span class="line">Out[<span class="number">97</span>]: </span><br><span class="line"><span class="number">0</span>      blue</span><br><span class="line"><span class="number">1</span>      blue</span><br><span class="line"><span class="number">2</span>    purple</span><br><span class="line"><span class="number">3</span>    purple</span><br><span class="line"><span class="number">4</span>    yellow</span><br><span class="line"><span class="number">5</span>    yellow</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>借助DataFrame，reindex可以修改（行）索引和列。只传递一个序列时，会重新索引结果的行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">98</span>]: frame = pd.DataFrame(np.arange(<span class="number">9</span>).reshape((<span class="number">3</span>, <span class="number">3</span>)),</span><br><span class="line">   ....:                      index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>],</span><br><span class="line">   ....:                      columns=[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;California&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: frame</span><br><span class="line">Out[<span class="number">99</span>]: </span><br><span class="line">   Ohio  Texas  California</span><br><span class="line">a     <span class="number">0</span>      <span class="number">1</span>           <span class="number">2</span></span><br><span class="line">c     <span class="number">3</span>      <span class="number">4</span>           <span class="number">5</span></span><br><span class="line">d     <span class="number">6</span>      <span class="number">7</span>           <span class="number">8</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: frame2 = frame.reindex([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">101</span>]: frame2</span><br><span class="line">Out[<span class="number">101</span>]: </span><br><span class="line">   Ohio  Texas  California</span><br><span class="line">a   <span class="number">0.0</span>    <span class="number">1.0</span>         <span class="number">2.0</span></span><br><span class="line">b   NaN    NaN         NaN</span><br><span class="line">c   <span class="number">3.0</span>    <span class="number">4.0</span>         <span class="number">5.0</span></span><br><span class="line">d   <span class="number">6.0</span>    <span class="number">7.0</span>         <span class="number">8.0</span></span><br></pre></td></tr></table></figure></p>
<p>列可以用columns关键字重新索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: states = [<span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;Utah&#x27;</span>, <span class="string">&#x27;California&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: frame.reindex(columns=states)</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">   Texas  Utah  California</span><br><span class="line">a      <span class="number">1</span>   NaN           <span class="number">2</span></span><br><span class="line">c      <span class="number">4</span>   NaN           <span class="number">5</span></span><br><span class="line">d      <span class="number">7</span>   NaN           <span class="number">8</span></span><br></pre></td></tr></table></figure></p>
<p>表5-3列出了reindex函数的各参数及说明。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-efa3dbd4b83c61ec.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h2><span id="丢弃指定轴上的项">丢弃指定轴上的项</span></h2><p>丢弃某条轴上的一个或多个项很简单，只要有一个索引数组或列表即可。由于需要执行一些数据整理和集合逻辑，所以drop方法返回的是一个在指定轴上删除了指定值的新对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">105</span>]: obj = pd.Series(np.arange(<span class="number">5.</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: obj</span><br><span class="line">Out[<span class="number">106</span>]: </span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">c    <span class="number">2.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">e    <span class="number">4.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">107</span>]: new_obj = obj.drop(<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">108</span>]: new_obj</span><br><span class="line">Out[<span class="number">108</span>]: </span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">e    <span class="number">4.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: obj.drop([<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">Out[<span class="number">109</span>]: </span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">e    <span class="number">4.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>对于DataFrame，可以删除任意轴上的索引值。为了演示，先新建一个DataFrame例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">110</span>]: data = pd.DataFrame(np.arange(<span class="number">16</span>).reshape((<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">   .....:                     index=[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Colorado&#x27;</span>, <span class="string">&#x27;Utah&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>],</span><br><span class="line">   .....:                     columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">111</span>]: data</span><br><span class="line">Out[<span class="number">111</span>]: </span><br><span class="line">          one  two  three  four</span><br><span class="line">Ohio        <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">Colorado    <span class="number">4</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">Utah        <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br><span class="line">New York   <span class="number">12</span>   <span class="number">13</span>     <span class="number">14</span>    <span class="number">15</span></span><br></pre></td></tr></table></figure></p>
<p>用标签序列调用drop会从行标签（axis 0）删除值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">112</span>]: data.drop([<span class="string">&#x27;Colorado&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>])</span><br><span class="line">Out[<span class="number">112</span>]: </span><br><span class="line">          one  two  three  four</span><br><span class="line">Utah        <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br><span class="line">New York   <span class="number">12</span>   <span class="number">13</span>     <span class="number">14</span>    <span class="number">15</span></span><br></pre></td></tr></table></figure></p>
<p>通过传递axis=1或axis=’columns’可以删除列的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">113</span>]: data.drop(<span class="string">&#x27;two&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">113</span>]: </span><br><span class="line">          one  three  four</span><br><span class="line">Ohio        <span class="number">0</span>      <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">Colorado    <span class="number">4</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">Utah        <span class="number">8</span>     <span class="number">10</span>    <span class="number">11</span></span><br><span class="line">New York   <span class="number">12</span>     <span class="number">14</span>    <span class="number">15</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: data.drop([<span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;four&#x27;</span>], axis=<span class="string">&#x27;columns&#x27;</span>)</span><br><span class="line">Out[<span class="number">114</span>]: </span><br><span class="line">          one  three</span><br><span class="line">Ohio        <span class="number">0</span>      <span class="number">2</span></span><br><span class="line">Colorado    <span class="number">4</span>      <span class="number">6</span></span><br><span class="line">Utah        <span class="number">8</span>     <span class="number">10</span></span><br><span class="line">New York   <span class="number">12</span>     <span class="number">14</span></span><br></pre></td></tr></table></figure></p>
<p>许多函数，如drop，会修改Series或DataFrame的大小或形状，可以就地修改对象，不会返回新的对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">115</span>]: obj.drop(<span class="string">&#x27;c&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: obj</span><br><span class="line">Out[<span class="number">116</span>]: </span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">e    <span class="number">4.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>小心使用inplace，它会销毁所有被删除的数据。</p>
<h2><span id="索引-选取和过滤">索引、选取和过滤</span></h2><p>Series索引（obj[…]）的工作方式类似于NumPy数组的索引，只不过Series的索引值不只是整数。下面是几个例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: obj = pd.Series(np.arange(<span class="number">4.</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: obj</span><br><span class="line">Out[<span class="number">118</span>]: </span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">c    <span class="number">2.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: obj[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">Out[<span class="number">119</span>]: <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">120</span>]: obj[<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">120</span>]: <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: obj[<span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line">c    <span class="number">2.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: obj[[<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>]]</span><br><span class="line">Out[<span class="number">122</span>]:</span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">123</span>]: obj[[<span class="number">1</span>, <span class="number">3</span>]]</span><br><span class="line">Out[<span class="number">123</span>]: </span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: obj[obj &lt; <span class="number">2</span>]</span><br><span class="line">Out[<span class="number">124</span>]: </span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>利用标签的切片运算与普通的Python切片运算不同，其末端是包含的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">125</span>]: obj[<span class="string">&#x27;b&#x27;</span>:<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">Out[<span class="number">125</span>]:</span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">c    <span class="number">2.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>用切片可以对Series的相应部分进行设置：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">126</span>]: obj[<span class="string">&#x27;b&#x27;</span>:<span class="string">&#x27;c&#x27;</span>] = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">127</span>]: obj</span><br><span class="line">Out[<span class="number">127</span>]: </span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">5.0</span></span><br><span class="line">c    <span class="number">5.0</span></span><br><span class="line">d    <span class="number">3.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>用一个值或序列对DataFrame进行索引其实就是获取一个或多个列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">128</span>]: data = pd.DataFrame(np.arange(<span class="number">16</span>).reshape((<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">   .....:                     index=[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Colorado&#x27;</span>, <span class="string">&#x27;Utah&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>],</span><br><span class="line">   .....:                     columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;four&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: data</span><br><span class="line">Out[<span class="number">129</span>]: </span><br><span class="line">          one  two  three  four</span><br><span class="line">Ohio        <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">Colorado    <span class="number">4</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">Utah        <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br><span class="line">New York   <span class="number">12</span>   <span class="number">13</span>     <span class="number">14</span>    <span class="number">15</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">130</span>]: data[<span class="string">&#x27;two&#x27;</span>]</span><br><span class="line">Out[<span class="number">130</span>]: </span><br><span class="line">Ohio         <span class="number">1</span></span><br><span class="line">Colorado     <span class="number">5</span></span><br><span class="line">Utah         <span class="number">9</span></span><br><span class="line">New York    <span class="number">13</span></span><br><span class="line">Name: two, dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">131</span>]: data[[<span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;one&#x27;</span>]]</span><br><span class="line">Out[<span class="number">131</span>]: </span><br><span class="line">          three  one</span><br><span class="line">Ohio          <span class="number">2</span>    <span class="number">0</span></span><br><span class="line">Colorado      <span class="number">6</span>    <span class="number">4</span></span><br><span class="line">Utah         <span class="number">10</span>    <span class="number">8</span></span><br><span class="line">New York     <span class="number">14</span>   <span class="number">12</span></span><br></pre></td></tr></table></figure></p>
<p>这种索引方式有几个特殊的情况。首先通过切片或布尔型数组选取数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">132</span>]: data[:<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">132</span>]: </span><br><span class="line">          one  two  three  four</span><br><span class="line">Ohio        <span class="number">0</span>    <span class="number">1</span>      <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">Colorado    <span class="number">4</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">133</span>]: data[data[<span class="string">&#x27;three&#x27;</span>] &gt; <span class="number">5</span>]</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">          one  two  three  four</span><br><span class="line">Colorado    <span class="number">4</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">Utah        <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br><span class="line">New York   <span class="number">12</span>   <span class="number">13</span>     <span class="number">14</span>    <span class="number">15</span></span><br></pre></td></tr></table></figure></p>
<p>选取行的语法data[:2]十分方便。向[ ]传递单一的元素或列表，就可选择列。</p>
<p>另一种用法是通过布尔型DataFrame（比如下面这个由标量比较运算得出的）进行索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">134</span>]: data &lt; <span class="number">5</span></span><br><span class="line">Out[<span class="number">134</span>]: </span><br><span class="line">            one    two  three   four</span><br><span class="line">Ohio       <span class="literal">True</span>   <span class="literal">True</span>   <span class="literal">True</span>   <span class="literal">True</span></span><br><span class="line">Colorado   <span class="literal">True</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span></span><br><span class="line">Utah      <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span></span><br><span class="line">New York  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">135</span>]: data[data &lt; <span class="number">5</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: data</span><br><span class="line">Out[<span class="number">136</span>]: </span><br><span class="line">          one  two  three  four</span><br><span class="line">Ohio        <span class="number">0</span>    <span class="number">0</span>      <span class="number">0</span>     <span class="number">0</span></span><br><span class="line">Colorado    <span class="number">0</span>    <span class="number">5</span>      <span class="number">6</span>     <span class="number">7</span></span><br><span class="line">Utah        <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span>    <span class="number">11</span></span><br><span class="line">New York   <span class="number">12</span>   <span class="number">13</span>     <span class="number">14</span>    <span class="number">15</span></span><br></pre></td></tr></table></figure></p>
<p>这使得DataFrame的语法与NumPy二维数组的语法很像。</p>
<h2><span id="用loc和iloc进行选取">用loc和iloc进行选取</span></h2><p>对于DataFrame的行的标签索引，我引入了特殊的标签运算符loc和iloc。它们可以让你用类似NumPy的标记，使用轴标签（loc）或整数索引（iloc），从DataFrame选择行和列的子集。</p>
<p>作为一个初步示例，让我们通过标签选择一行和多列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">137</span>]: data.loc[<span class="string">&#x27;Colorado&#x27;</span>, [<span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]]</span><br><span class="line">Out[<span class="number">137</span>]: </span><br><span class="line">two      <span class="number">5</span></span><br><span class="line">three    <span class="number">6</span></span><br><span class="line">Name: Colorado, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>然后用iloc和整数进行选取：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">138</span>]: data.iloc[<span class="number">2</span>, [<span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">Out[<span class="number">138</span>]: </span><br><span class="line">four    <span class="number">11</span></span><br><span class="line">one      <span class="number">8</span></span><br><span class="line">two      <span class="number">9</span></span><br><span class="line">Name: Utah, dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">139</span>]: data.iloc[<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">139</span>]: </span><br><span class="line">one       <span class="number">8</span></span><br><span class="line">two       <span class="number">9</span></span><br><span class="line">three    <span class="number">10</span></span><br><span class="line">four     <span class="number">11</span></span><br><span class="line">Name: Utah, dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: data.iloc[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">Out[<span class="number">140</span>]: </span><br><span class="line">          four  one  two</span><br><span class="line">Colorado     <span class="number">7</span>    <span class="number">0</span>    <span class="number">5</span></span><br><span class="line">Utah        <span class="number">11</span>    <span class="number">8</span>    <span class="number">9</span></span><br></pre></td></tr></table></figure></p>
<p>这两个索引函数也适用于一个标签或多个标签的切片：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">141</span>]: data.loc[:<span class="string">&#x27;Utah&#x27;</span>, <span class="string">&#x27;two&#x27;</span>]</span><br><span class="line">Out[<span class="number">141</span>]: </span><br><span class="line">Ohio        <span class="number">0</span></span><br><span class="line">Colorado    <span class="number">5</span></span><br><span class="line">Utah        <span class="number">9</span></span><br><span class="line">Name: two, dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">142</span>]: data.iloc[:, :<span class="number">3</span>][data.three &gt; <span class="number">5</span>]</span><br><span class="line">Out[<span class="number">142</span>]: </span><br><span class="line">          one  two  three</span><br><span class="line">Colorado    <span class="number">0</span>    <span class="number">5</span>      <span class="number">6</span></span><br><span class="line">Utah        <span class="number">8</span>    <span class="number">9</span>     <span class="number">10</span></span><br><span class="line">New York   <span class="number">12</span>   <span class="number">13</span>     <span class="number">14</span></span><br></pre></td></tr></table></figure></p>
<p>所以，在pandas中，有多个方法可以选取和重新组合数据。对于DataFrame，表5-4进行了总结。后面会看到，还有更多的方法进行层级化索引。</p>
<blockquote>
<p>笔记：在一开始设计pandas时，我觉得用frame[:, col]选取列过于繁琐（也容易出错），因为列的选择是非常常见的操作。我做了些取舍，将花式索引的功能（标签和整数）放到了ix运算符中。在实践中，这会导致许多边缘情况，数据的轴标签是整数，所以pandas团队决定创造loc和iloc运算符分别处理严格基于标签和整数的索引。<br>ix运算符仍然可用，但并不推荐。</p>
</blockquote>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-64354f2ab777bd8c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表5-4 DataFrame的索引选项"></p>
<h2><span id="整数索引">整数索引</span></h2><p>处理整数索引的pandas对象常常难住新手，因为它与Python内置的列表和元组的索引语法不同。例如，你可能不认为下面的代码会出错：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ser = pd.Series(np.arange(<span class="number">3.</span>))</span><br><span class="line">ser</span><br><span class="line">ser[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<p>这里，pandas可以勉强进行整数索引，但是会导致小bug。我们有包含0,1,2的索引，但是引入用户想要的东西（基于标签或位置的索引）很难：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">144</span>]: ser</span><br><span class="line">Out[<span class="number">144</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">2.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>另外，对于非整数索引，不会产生歧义：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">145</span>]: ser2 = pd.Series(np.arange(<span class="number">3.</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">146</span>]: ser2[-<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">146</span>]: <span class="number">2.0</span></span><br></pre></td></tr></table></figure></p>
<p>为了进行统一，如果轴索引含有整数，数据选取总会使用标签。为了更准确，请使用loc（标签）或iloc（整数）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">147</span>]: ser[:<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">147</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">0.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: ser.loc[:<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">148</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">149</span>]: ser.iloc[:<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">149</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">0.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2><span id="算术运算和数据对齐">算术运算和数据对齐</span></h2><p>pandas最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。对于有数据库经验的用户，这就像在索引标签上进行自动外连接。看一个简单的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">150</span>]: s1 = pd.Series([<span class="number">7.3</span>, -<span class="number">2.5</span>, <span class="number">3.4</span>, <span class="number">1.5</span>], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">151</span>]: s2 = pd.Series([-<span class="number">2.1</span>, <span class="number">3.6</span>, -<span class="number">1.5</span>, <span class="number">4</span>, <span class="number">3.1</span>],</span><br><span class="line">   .....:                index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;g&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">152</span>]: s1</span><br><span class="line">Out[<span class="number">152</span>]: </span><br><span class="line">a    <span class="number">7.3</span></span><br><span class="line">c   -<span class="number">2.5</span></span><br><span class="line">d    <span class="number">3.4</span></span><br><span class="line">e    <span class="number">1.5</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">153</span>]: s2</span><br><span class="line">Out[<span class="number">153</span>]: </span><br><span class="line">a   -<span class="number">2.1</span></span><br><span class="line">c    <span class="number">3.6</span></span><br><span class="line">e   -<span class="number">1.5</span></span><br><span class="line">f    <span class="number">4.0</span></span><br><span class="line">g    <span class="number">3.1</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>将它们相加就会产生：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">154</span>]: s1 + s2</span><br><span class="line">Out[<span class="number">154</span>]: </span><br><span class="line">a    <span class="number">5.2</span></span><br><span class="line">c    <span class="number">1.1</span></span><br><span class="line">d    NaN</span><br><span class="line">e    <span class="number">0.0</span></span><br><span class="line">f    NaN</span><br><span class="line">g    NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>自动的数据对齐操作在不重叠的索引处引入了NA值。缺失值会在算术运算过程中传播。</p>
<p>对于DataFrame，对齐操作会同时发生在行和列上：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">155</span>]: df1 = pd.DataFrame(np.arange(<span class="number">9.</span>).reshape((<span class="number">3</span>, <span class="number">3</span>)), columns=<span class="built_in">list</span>(<span class="string">&#x27;bcd&#x27;</span>),</span><br><span class="line">   .....:                    index=[<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;Colorado&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">156</span>]: df2 = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape((<span class="number">4</span>, <span class="number">3</span>)), columns=<span class="built_in">list</span>(<span class="string">&#x27;bde&#x27;</span>),</span><br><span class="line">   .....:                    index=[<span class="string">&#x27;Utah&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;Oregon&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">157</span>]: df1</span><br><span class="line">Out[<span class="number">157</span>]: </span><br><span class="line">            b    c    d</span><br><span class="line">Ohio      <span class="number">0.0</span>  <span class="number">1.0</span>  <span class="number">2.0</span></span><br><span class="line">Texas     <span class="number">3.0</span>  <span class="number">4.0</span>  <span class="number">5.0</span></span><br><span class="line">Colorado  <span class="number">6.0</span>  <span class="number">7.0</span>  <span class="number">8.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">158</span>]: df2</span><br><span class="line">Out[<span class="number">158</span>]: </span><br><span class="line">          b     d     e</span><br><span class="line">Utah    <span class="number">0.0</span>   <span class="number">1.0</span>   <span class="number">2.0</span></span><br><span class="line">Ohio    <span class="number">3.0</span>   <span class="number">4.0</span>   <span class="number">5.0</span></span><br><span class="line">Texas   <span class="number">6.0</span>   <span class="number">7.0</span>   <span class="number">8.0</span></span><br><span class="line">Oregon  <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11.0</span></span><br></pre></td></tr></table></figure></p>
<p>把它们相加后将会返回一个新的DataFrame，其索引和列为原来那两个DataFrame的并集：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">159</span>]: df1 + df2</span><br><span class="line">Out[<span class="number">159</span>]: </span><br><span class="line">            b   c     d   e</span><br><span class="line">Colorado  NaN NaN   NaN NaN</span><br><span class="line">Ohio      <span class="number">3.0</span> NaN   <span class="number">6.0</span> NaN</span><br><span class="line">Oregon    NaN NaN   NaN NaN</span><br><span class="line">Texas     <span class="number">9.0</span> NaN  <span class="number">12.0</span> NaN</span><br><span class="line">Utah      NaN NaN   NaN NaN</span><br></pre></td></tr></table></figure></p>
<p>因为’c’和’e’列均不在两个DataFrame对象中，在结果中以缺省值呈现。行也是同样。</p>
<p>如果DataFrame对象相加，没有共用的列或行标签，结果都会是空：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">160</span>]: df1 = pd.DataFrame(&#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">161</span>]: df2 = pd.DataFrame(&#123;<span class="string">&#x27;B&#x27;</span>: [<span class="number">3</span>, <span class="number">4</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: df1</span><br><span class="line">Out[<span class="number">162</span>]: </span><br><span class="line">   A</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">163</span>]: df2</span><br><span class="line">Out[<span class="number">163</span>]: </span><br><span class="line">   B</span><br><span class="line"><span class="number">0</span>  <span class="number">3</span></span><br><span class="line"><span class="number">1</span>  <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">164</span>]: df1 - df2</span><br><span class="line">Out[<span class="number">164</span>]: </span><br><span class="line">    A   B</span><br><span class="line"><span class="number">0</span> NaN NaN</span><br><span class="line"><span class="number">1</span> NaN NaN</span><br></pre></td></tr></table></figure></p>
<h2><span id="在算术方法中填充值">在算术方法中填充值</span></h2><p>在对不同索引的对象进行算术运算时，你可能希望当一个对象中某个轴标签在另一个对象中找不到时填充一个特殊值（比如0）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">165</span>]: df1 = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape((<span class="number">3</span>, <span class="number">4</span>)),</span><br><span class="line">   .....:                    columns=<span class="built_in">list</span>(<span class="string">&#x27;abcd&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">166</span>]: df2 = pd.DataFrame(np.arange(<span class="number">20.</span>).reshape((<span class="number">4</span>, <span class="number">5</span>)),</span><br><span class="line">   .....:                    columns=<span class="built_in">list</span>(<span class="string">&#x27;abcde&#x27;</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">167</span>]: df2.loc[<span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>] = np.nan</span><br><span class="line"></span><br><span class="line">In [<span class="number">168</span>]: df1</span><br><span class="line">Out[<span class="number">168</span>]: </span><br><span class="line">     a    b     c     d</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">1.0</span>   <span class="number">2.0</span>   <span class="number">3.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">4.0</span>  <span class="number">5.0</span>   <span class="number">6.0</span>   <span class="number">7.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">8.0</span>  <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: df2</span><br><span class="line">Out[<span class="number">169</span>]: </span><br><span class="line">      a     b     c     d     e</span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>   <span class="number">1.0</span>   <span class="number">2.0</span>   <span class="number">3.0</span>   <span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>   <span class="number">5.0</span>   NaN   <span class="number">7.0</span>   <span class="number">8.0</span>   <span class="number">9.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">10.0</span>  <span class="number">11.0</span>  <span class="number">12.0</span>  <span class="number">13.0</span>  <span class="number">14.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">15.0</span>  <span class="number">16.0</span>  <span class="number">17.0</span>  <span class="number">18.0</span>  <span class="number">19.0</span></span><br></pre></td></tr></table></figure></p>
<p>将它们相加时，没有重叠的位置就会产生NA值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">170</span>]: df1 + df2</span><br><span class="line">Out[<span class="number">170</span>]: </span><br><span class="line">      a     b     c     d   e</span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>   <span class="number">2.0</span>   <span class="number">4.0</span>   <span class="number">6.0</span> NaN</span><br><span class="line"><span class="number">1</span>   <span class="number">9.0</span>   NaN  <span class="number">13.0</span>  <span class="number">15.0</span> NaN</span><br><span class="line"><span class="number">2</span>  <span class="number">18.0</span>  <span class="number">20.0</span>  <span class="number">22.0</span>  <span class="number">24.0</span> NaN</span><br><span class="line"><span class="number">3</span>   NaN   NaN   NaN   NaN NaN</span><br></pre></td></tr></table></figure></p>
<p>使用df1的add方法，传入df2以及一个fill_value参数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">171</span>]: df1.add(df2, fill_value=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">171</span>]: </span><br><span class="line">      a     b     c     d     e</span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span>   <span class="number">2.0</span>   <span class="number">4.0</span>   <span class="number">6.0</span>   <span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>   <span class="number">9.0</span>   <span class="number">5.0</span>  <span class="number">13.0</span>  <span class="number">15.0</span>   <span class="number">9.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">18.0</span>  <span class="number">20.0</span>  <span class="number">22.0</span>  <span class="number">24.0</span>  <span class="number">14.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">15.0</span>  <span class="number">16.0</span>  <span class="number">17.0</span>  <span class="number">18.0</span>  <span class="number">19.0</span></span><br></pre></td></tr></table></figure></p>
<p>表5-5列出了Series和DataFrame的算术方法。它们每个都有一个副本，以字母r开头，它会翻转参数。因此这两个语句是等价的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">172</span>]: <span class="number">1</span> / df1</span><br><span class="line">Out[<span class="number">172</span>]: </span><br><span class="line">          a         b         c         d</span><br><span class="line"><span class="number">0</span>       inf  <span class="number">1.000000</span>  <span class="number">0.500000</span>  <span class="number">0.333333</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.250000</span>  <span class="number">0.200000</span>  <span class="number">0.166667</span>  <span class="number">0.142857</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.125000</span>  <span class="number">0.111111</span>  <span class="number">0.100000</span>  <span class="number">0.090909</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">173</span>]: df1.rdiv(<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">173</span>]: </span><br><span class="line">          a         b         c         d</span><br><span class="line"><span class="number">0</span>       inf  <span class="number">1.000000</span>  <span class="number">0.500000</span>  <span class="number">0.333333</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.250000</span>  <span class="number">0.200000</span>  <span class="number">0.166667</span>  <span class="number">0.142857</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.125000</span>  <span class="number">0.111111</span>  <span class="number">0.100000</span>  <span class="number">0.090909</span></span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-16857a1021f98d1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表5-5 灵活的算术方法"></p>
<p>与此类似，在对Series或DataFrame重新索引时，也可以指定一个填充值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">174</span>]: df1.reindex(columns=df2.columns, fill_value=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">174</span>]: </span><br><span class="line">     a    b     c     d  e</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">1.0</span>   <span class="number">2.0</span>   <span class="number">3.0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">4.0</span>  <span class="number">5.0</span>   <span class="number">6.0</span>   <span class="number">7.0</span>  <span class="number">0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">8.0</span>  <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11.0</span>  <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="dataframe和series之间的运算">DataFrame和Series之间的运算</span></h2><p>跟不同维度的NumPy数组一样，DataFrame和Series之间算术运算也是有明确规定的。先来看一个具有启发性的例子，计算一个二维数组与其某行之间的差：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">175</span>]: arr = np.arange(<span class="number">12.</span>).reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">176</span>]: arr</span><br><span class="line">Out[<span class="number">176</span>]: </span><br><span class="line">array([[  <span class="number">0.</span>,   <span class="number">1.</span>,   <span class="number">2.</span>,   <span class="number">3.</span>],</span><br><span class="line">       [  <span class="number">4.</span>,   <span class="number">5.</span>,   <span class="number">6.</span>,   <span class="number">7.</span>],</span><br><span class="line">       [  <span class="number">8.</span>,   <span class="number">9.</span>,  <span class="number">10.</span>,  <span class="number">11.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">177</span>]: arr[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">177</span>]: array([ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">178</span>]: arr - arr[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">178</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">4.</span>,  <span class="number">4.</span>,  <span class="number">4.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [ <span class="number">8.</span>,  <span class="number">8.</span>,  <span class="number">8.</span>,  <span class="number">8.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>当我们从arr减去arr[0]，每一行都会执行这个操作。这就叫做广播（broadcasting），附录A将对此进行详细讲解。DataFrame和Series之间的运算差不多也是如此：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">179</span>]: frame = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape((<span class="number">4</span>, <span class="number">3</span>)),</span><br><span class="line">   .....:                      columns=<span class="built_in">list</span>(<span class="string">&#x27;bde&#x27;</span>),</span><br><span class="line">   .....:                      index=[<span class="string">&#x27;Utah&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;Oregon&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">180</span>]: series = frame.iloc[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">181</span>]: frame</span><br><span class="line">Out[<span class="number">181</span>]: </span><br><span class="line">          b     d     e</span><br><span class="line">Utah    <span class="number">0.0</span>   <span class="number">1.0</span>   <span class="number">2.0</span></span><br><span class="line">Ohio    <span class="number">3.0</span>   <span class="number">4.0</span>   <span class="number">5.0</span></span><br><span class="line">Texas   <span class="number">6.0</span>   <span class="number">7.0</span>   <span class="number">8.0</span></span><br><span class="line">Oregon  <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">182</span>]: series</span><br><span class="line">Out[<span class="number">182</span>]: </span><br><span class="line">b    <span class="number">0.0</span></span><br><span class="line">d    <span class="number">1.0</span></span><br><span class="line">e    <span class="number">2.0</span></span><br><span class="line">Name: Utah, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>默认情况下，DataFrame和Series之间的算术运算会将Series的索引匹配到DataFrame的列，然后沿着行一直向下广播：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">183</span>]: frame - series</span><br><span class="line">Out[<span class="number">183</span>]: </span><br><span class="line">          b    d    e</span><br><span class="line">Utah    <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line">Ohio    <span class="number">3.0</span>  <span class="number">3.0</span>  <span class="number">3.0</span></span><br><span class="line">Texas   <span class="number">6.0</span>  <span class="number">6.0</span>  <span class="number">6.0</span></span><br><span class="line">Oregon  <span class="number">9.0</span>  <span class="number">9.0</span>  <span class="number">9.0</span></span><br></pre></td></tr></table></figure></p>
<p>如果某个索引值在DataFrame的列或Series的索引中找不到，则参与运算的两个对象就会被重新索引以形成并集：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">184</span>]: series2 = pd.Series(<span class="built_in">range</span>(<span class="number">3</span>), index=[<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">185</span>]: frame + series2</span><br><span class="line">Out[<span class="number">185</span>]: </span><br><span class="line">          b   d     e   f</span><br><span class="line">Utah    <span class="number">0.0</span> NaN   <span class="number">3.0</span> NaN</span><br><span class="line">Ohio    <span class="number">3.0</span> NaN   <span class="number">6.0</span> NaN</span><br><span class="line">Texas   <span class="number">6.0</span> NaN   <span class="number">9.0</span> NaN</span><br><span class="line">Oregon  <span class="number">9.0</span> NaN  <span class="number">12.0</span> NaN</span><br></pre></td></tr></table></figure></p>
<p>如果你希望匹配行且在列上广播，则必须使用算术运算方法。例如：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">186</span>]: series3 = frame[<span class="string">&#x27;d&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">187</span>]: frame</span><br><span class="line">Out[<span class="number">187</span>]: </span><br><span class="line">          b     d     e</span><br><span class="line">Utah    <span class="number">0.0</span>   <span class="number">1.0</span>   <span class="number">2.0</span></span><br><span class="line">Ohio    <span class="number">3.0</span>   <span class="number">4.0</span>   <span class="number">5.0</span></span><br><span class="line">Texas   <span class="number">6.0</span>   <span class="number">7.0</span>   <span class="number">8.0</span></span><br><span class="line">Oregon  <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">188</span>]: series3</span><br><span class="line">Out[<span class="number">188</span>]: </span><br><span class="line">Utah       <span class="number">1.0</span></span><br><span class="line">Ohio       <span class="number">4.0</span></span><br><span class="line">Texas      <span class="number">7.0</span></span><br><span class="line">Oregon    <span class="number">10.0</span></span><br><span class="line">Name: d, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">189</span>]: frame.sub(series3, axis=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">Out[<span class="number">189</span>]: </span><br><span class="line">          b    d    e</span><br><span class="line">Utah   -<span class="number">1.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span></span><br><span class="line">Ohio   -<span class="number">1.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span></span><br><span class="line">Texas  -<span class="number">1.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span></span><br><span class="line">Oregon -<span class="number">1.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<p>传入的轴号就是希望匹配的轴。在本例中，我们的目的是匹配DataFrame的行索引（axis=’index’ or axis=0）并进行广播。</p>
<h2><span id="函数应用和映射">函数应用和映射</span></h2><p>NumPy的ufuncs（元素级数组方法）也可用于操作pandas对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">190</span>]: frame = pd.DataFrame(np.random.randn(<span class="number">4</span>, <span class="number">3</span>), columns=<span class="built_in">list</span>(<span class="string">&#x27;bde&#x27;</span>),</span><br><span class="line">   .....:                      index=[<span class="string">&#x27;Utah&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Texas&#x27;</span>, <span class="string">&#x27;Oregon&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">191</span>]: frame</span><br><span class="line">Out[<span class="number">191</span>]: </span><br><span class="line">               b         d         e</span><br><span class="line">Utah   -<span class="number">0.204708</span>  <span class="number">0.478943</span> -<span class="number">0.519439</span></span><br><span class="line">Ohio   -<span class="number">0.555730</span>  <span class="number">1.965781</span>  <span class="number">1.393406</span></span><br><span class="line">Texas   <span class="number">0.092908</span>  <span class="number">0.281746</span>  <span class="number">0.769023</span></span><br><span class="line">Oregon  <span class="number">1.246435</span>  <span class="number">1.007189</span> -<span class="number">1.296221</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">192</span>]: np.<span class="built_in">abs</span>(frame)</span><br><span class="line">Out[<span class="number">192</span>]: </span><br><span class="line">               b         d         e</span><br><span class="line">Utah    <span class="number">0.204708</span>  <span class="number">0.478943</span>  <span class="number">0.519439</span></span><br><span class="line">Ohio    <span class="number">0.555730</span>  <span class="number">1.965781</span>  <span class="number">1.393406</span></span><br><span class="line">Texas   <span class="number">0.092908</span>  <span class="number">0.281746</span>  <span class="number">0.769023</span></span><br><span class="line">Oregon  <span class="number">1.246435</span>  <span class="number">1.007189</span>  <span class="number">1.296221</span></span><br></pre></td></tr></table></figure></p>
<p>另一个常见的操作是，将函数应用到由各列或行所形成的一维数组上。DataFrame的apply方法即可实现此功能：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">193</span>]: f = <span class="keyword">lambda</span> x: x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>()</span><br><span class="line"></span><br><span class="line">In [<span class="number">194</span>]: frame.apply(f)</span><br><span class="line">Out[<span class="number">194</span>]: </span><br><span class="line">b    <span class="number">1.802165</span></span><br><span class="line">d    <span class="number">1.684034</span></span><br><span class="line">e    <span class="number">2.689627</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这里的函数f，计算了一个Series的最大值和最小值的差，在frame的每列都执行了一次。结果是一个Series，使用frame的列作为索引。</p>
<p>如果传递axis=’columns’到apply，这个函数会在每行执行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">195</span>]: frame.apply(f, axis=<span class="string">&#x27;columns&#x27;</span>)</span><br><span class="line">Out[<span class="number">195</span>]:</span><br><span class="line">Utah      <span class="number">0.998382</span></span><br><span class="line">Ohio      <span class="number">2.521511</span></span><br><span class="line">Texas     <span class="number">0.676115</span></span><br><span class="line">Oregon    <span class="number">2.542656</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>许多最为常见的数组统计功能都被实现成DataFrame的方法（如sum和mean），因此无需使用apply方法。</p>
<p>传递到apply的函数不是必须返回一个标量，还可以返回由多个值组成的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">196</span>]: <span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">   .....:     <span class="keyword">return</span> pd.Series([x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>()], index=[<span class="string">&#x27;min&#x27;</span>, <span class="string">&#x27;max&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">197</span>]: frame.apply(f)</span><br><span class="line">Out[<span class="number">197</span>]: </span><br><span class="line">            b         d         e</span><br><span class="line"><span class="built_in">min</span> -<span class="number">0.555730</span>  <span class="number">0.281746</span> -<span class="number">1.296221</span></span><br><span class="line"><span class="built_in">max</span>  <span class="number">1.246435</span>  <span class="number">1.965781</span>  <span class="number">1.393406</span></span><br></pre></td></tr></table></figure></p>
<p>元素级的Python函数也是可以用的。假如你想得到frame中各个浮点值的格式化字符串，使用applymap即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">198</span>]: <span class="built_in">format</span> = <span class="keyword">lambda</span> x: <span class="string">&#x27;%.2f&#x27;</span> % x</span><br><span class="line"></span><br><span class="line">In [<span class="number">199</span>]: frame.applymap(<span class="built_in">format</span>)</span><br><span class="line">Out[<span class="number">199</span>]: </span><br><span class="line">            b     d      e</span><br><span class="line">Utah    -<span class="number">0.20</span>  <span class="number">0.48</span>  -<span class="number">0.52</span></span><br><span class="line">Ohio    -<span class="number">0.56</span>  <span class="number">1.97</span>   <span class="number">1.39</span></span><br><span class="line">Texas    <span class="number">0.09</span>  <span class="number">0.28</span>   <span class="number">0.77</span></span><br><span class="line">Oregon   <span class="number">1.25</span>  <span class="number">1.01</span>  -<span class="number">1.30</span></span><br></pre></td></tr></table></figure></p>
<p>之所以叫做applymap，是因为Series有一个用于应用元素级函数的map方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">200</span>]: frame[<span class="string">&#x27;e&#x27;</span>].<span class="built_in">map</span>(<span class="built_in">format</span>)</span><br><span class="line">Out[<span class="number">200</span>]: </span><br><span class="line">Utah      -<span class="number">0.52</span></span><br><span class="line">Ohio       <span class="number">1.39</span></span><br><span class="line">Texas      <span class="number">0.77</span></span><br><span class="line">Oregon    -<span class="number">1.30</span></span><br><span class="line">Name: e, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="排序和排名">排序和排名</span></h2><p>根据条件对数据集排序（sorting）也是一种重要的内置运算。要对行或列索引进行排序（按字典顺序），可使用sort_index方法，它将返回一个已排序的新对象：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">201</span>]: obj = pd.Series(<span class="built_in">range</span>(<span class="number">4</span>), index=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">202</span>]: obj.sort_index()</span><br><span class="line">Out[<span class="number">202</span>]:</span><br><span class="line">a    <span class="number">1</span></span><br><span class="line">b    <span class="number">2</span></span><br><span class="line">c    <span class="number">3</span></span><br><span class="line">d    <span class="number">0</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>对于DataFrame，则可以根据任意一个轴上的索引进行排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">203</span>]: frame = pd.DataFrame(np.arange(<span class="number">8</span>).reshape((<span class="number">2</span>, <span class="number">4</span>)),</span><br><span class="line">   .....:                      index=[<span class="string">&#x27;three&#x27;</span>, <span class="string">&#x27;one&#x27;</span>],</span><br><span class="line">   .....:                      columns=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">204</span>]: frame.sort_index()</span><br><span class="line">Out[<span class="number">204</span>]: </span><br><span class="line">       d  a  b  c</span><br><span class="line">one    <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>  <span class="number">7</span></span><br><span class="line">three  <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">205</span>]: frame.sort_index(axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">205</span>]:</span><br><span class="line">       a  b  c  d</span><br><span class="line">three  <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">0</span></span><br><span class="line">one    <span class="number">5</span>  <span class="number">6</span>  <span class="number">7</span>  <span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p>数据默认是按升序排序的，但也可以降序排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">206</span>]: frame.sort_index(axis=<span class="number">1</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">Out[<span class="number">206</span>]: </span><br><span class="line">       d  c  b  a</span><br><span class="line">three  <span class="number">0</span>  <span class="number">3</span>  <span class="number">2</span>  <span class="number">1</span></span><br><span class="line">one    <span class="number">4</span>  <span class="number">7</span>  <span class="number">6</span>  <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p>若要按值对Series进行排序，可使用其sort_values方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">207</span>]: obj = pd.Series([<span class="number">4</span>, <span class="number">7</span>, -<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">208</span>]: obj.sort_values()</span><br><span class="line">Out[<span class="number">208</span>]: </span><br><span class="line"><span class="number">2</span>   -<span class="number">3</span></span><br><span class="line"><span class="number">3</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0</span>    <span class="number">4</span></span><br><span class="line"><span class="number">1</span>    <span class="number">7</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>在排序时，任何缺失值默认都会被放到Series的末尾：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">209</span>]: obj = pd.Series([<span class="number">4</span>, np.nan, <span class="number">7</span>, np.nan, -<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">210</span>]: obj.sort_values()</span><br><span class="line">Out[<span class="number">210</span>]: </span><br><span class="line"><span class="number">4</span>   -<span class="number">3.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">0</span>    <span class="number">4.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">7.0</span></span><br><span class="line"><span class="number">1</span>    NaN</span><br><span class="line"><span class="number">3</span>    NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>当排序一个DataFrame时，你可能希望根据一个或多个列中的值进行排序。将一个或多个列的名字传递给sort_values的by选项即可达到该目的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">211</span>]: frame = pd.DataFrame(&#123;<span class="string">&#x27;b&#x27;</span>: [<span class="number">4</span>, <span class="number">7</span>, -<span class="number">3</span>, <span class="number">2</span>], <span class="string">&#x27;a&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">212</span>]: frame</span><br><span class="line">Out[<span class="number">212</span>]: </span><br><span class="line">   a  b</span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1</span>  <span class="number">7</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0</span> -<span class="number">3</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">213</span>]: frame.sort_values(by=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">Out[<span class="number">213</span>]: </span><br><span class="line">   a  b</span><br><span class="line"><span class="number">2</span>  <span class="number">0</span> -<span class="number">3</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1</span>  <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<p>要根据多个列进行排序，传入名称的列表即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">214</span>]: frame.sort_values(by=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line">Out[<span class="number">214</span>]: </span><br><span class="line">   a  b</span><br><span class="line"><span class="number">2</span>  <span class="number">0</span> -<span class="number">3</span></span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">4</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1</span>  <span class="number">7</span></span><br></pre></td></tr></table></figure></p>
<p>排名会从1开始一直到数组中有效数据的数量。接下来介绍Series和DataFrame的rank方法。默认情况下，rank是通过“为各组分配一个平均排名”的方式破坏平级关系的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">215</span>]: obj = pd.Series([<span class="number">7</span>, -<span class="number">5</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">4</span>])</span><br><span class="line">In [<span class="number">216</span>]: obj.rank()</span><br><span class="line">Out[<span class="number">216</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">6.5</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">6.5</span></span><br><span class="line"><span class="number">3</span>    <span class="number">4.5</span></span><br><span class="line"><span class="number">4</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">6</span>    <span class="number">4.5</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>也可以根据值在原数据中出现的顺序给出排名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">217</span>]: obj.rank(method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">Out[<span class="number">217</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">6.0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">7.0</span></span><br><span class="line"><span class="number">3</span>    <span class="number">4.0</span></span><br><span class="line"><span class="number">4</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">6</span>    <span class="number">5.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>这里，条目0和2没有使用平均排名6.5，它们被设成了6和7，因为数据中标签0位于标签2的前面。</p>
<p>你也可以按降序进行排名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Assign tie values the maximum rank in the group</span></span><br><span class="line">In [<span class="number">218</span>]: obj.rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">Out[<span class="number">218</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">7.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">2.0</span></span><br><span class="line"><span class="number">3</span>    <span class="number">4.0</span></span><br><span class="line"><span class="number">4</span>    <span class="number">5.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">6.0</span></span><br><span class="line"><span class="number">6</span>    <span class="number">4.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>表5-6列出了所有用于破坏平级关系的method选项。DataFrame可以在行或列上计算排名：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">219</span>]: frame = pd.DataFrame(&#123;<span class="string">&#x27;b&#x27;</span>: [<span class="number">4.3</span>, <span class="number">7</span>, -<span class="number">3</span>, <span class="number">2</span>], <span class="string">&#x27;a&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">   .....:                       <span class="string">&#x27;c&#x27;</span>: [-<span class="number">2</span>, <span class="number">5</span>, <span class="number">8</span>, -<span class="number">2.5</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">220</span>]: frame</span><br><span class="line">Out[<span class="number">220</span>]: </span><br><span class="line">   a    b    c</span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">4.3</span> -<span class="number">2.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1</span>  <span class="number">7.0</span>  <span class="number">5.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0</span> -<span class="number">3.0</span>  <span class="number">8.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1</span>  <span class="number">2.0</span> -<span class="number">2.5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">221</span>]: frame.rank(axis=<span class="string">&#x27;columns&#x27;</span>)</span><br><span class="line">Out[<span class="number">221</span>]: </span><br><span class="line">     a    b    c</span><br><span class="line"><span class="number">0</span>  <span class="number">2.0</span>  <span class="number">3.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  <span class="number">3.0</span>  <span class="number">2.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">2.0</span>  <span class="number">1.0</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">2.0</span>  <span class="number">3.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-7edfab5b4a147581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表5-6 排名时用于破坏平级关系的方法"></p>
<h2><span id="带有重复标签的轴索引">带有重复标签的轴索引</span></h2><p>直到目前为止，我所介绍的所有范例都有着唯一的轴标签（索引值）。虽然许多pandas函数（如reindex）都要求标签唯一，但这并不是强制性的。我们来看看下面这个简单的带有重复索引值的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">222</span>]: obj = pd.Series(<span class="built_in">range</span>(<span class="number">5</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">223</span>]: obj</span><br><span class="line">Out[<span class="number">223</span>]: </span><br><span class="line">a    <span class="number">0</span></span><br><span class="line">a    <span class="number">1</span></span><br><span class="line">b    <span class="number">2</span></span><br><span class="line">b    <span class="number">3</span></span><br><span class="line">c    <span class="number">4</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>索引的is_unique属性可以告诉你它的值是否是唯一的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">224</span>]: obj.index.is_unique</span><br><span class="line">Out[<span class="number">224</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>对于带有重复值的索引，数据选取的行为将会有些不同。如果某个索引对应多个值，则返回一个Series；而对应单个值的，则返回一个标量值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">225</span>]: obj[<span class="string">&#x27;a&#x27;</span>]</span><br><span class="line">Out[<span class="number">225</span>]: </span><br><span class="line">a    <span class="number">0</span></span><br><span class="line">a    <span class="number">1</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">226</span>]: obj[<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">Out[<span class="number">226</span>]: <span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p>这样会使代码变复杂，因为索引的输出类型会根据标签是否有重复发生变化。</p>
<p>对DataFrame的行进行索引时也是如此：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">227</span>]: df = pd.DataFrame(np.random.randn(<span class="number">4</span>, <span class="number">3</span>), index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">228</span>]: df</span><br><span class="line">Out[<span class="number">228</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line">a  <span class="number">0.274992</span>  <span class="number">0.228913</span>  <span class="number">1.352917</span></span><br><span class="line">a  <span class="number">0.886429</span> -<span class="number">2.001637</span> -<span class="number">0.371843</span></span><br><span class="line">b  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br><span class="line">b  <span class="number">0.476985</span>  <span class="number">3.248944</span> -<span class="number">1.021228</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">229</span>]: df.loc[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">Out[<span class="number">229</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span></span><br><span class="line">b  <span class="number">1.669025</span> -<span class="number">0.438570</span> -<span class="number">0.539741</span></span><br><span class="line">b  <span class="number">0.476985</span>  <span class="number">3.248944</span> -<span class="number">1.021228</span></span><br></pre></td></tr></table></figure></p>
<h1><span id="53-汇总和计算描述统计">5.3 汇总和计算描述统计</span></h1><p>pandas对象拥有一组常用的数学和统计方法。它们大部分都属于约简和汇总统计，用于从Series中提取单个值（如sum或mean）或从DataFrame的行或列中提取一个Series。跟对应的NumPy数组方法相比，它们都是基于没有缺失数据的假设而构建的。看一个简单的DataFrame：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">230</span>]: df = pd.DataFrame([[<span class="number">1.4</span>, np.nan], [<span class="number">7.1</span>, -<span class="number">4.5</span>],</span><br><span class="line">   .....:                    [np.nan, np.nan], [<span class="number">0.75</span>, -<span class="number">1.3</span>]],</span><br><span class="line">   .....:                   index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>],</span><br><span class="line">   .....:                   columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">231</span>]: df</span><br><span class="line">Out[<span class="number">231</span>]: </span><br><span class="line">    one  two</span><br><span class="line">a  <span class="number">1.40</span>  NaN</span><br><span class="line">b  <span class="number">7.10</span> -<span class="number">4.5</span></span><br><span class="line">c   NaN  NaN</span><br><span class="line">d  <span class="number">0.75</span> -<span class="number">1.3</span></span><br></pre></td></tr></table></figure></p>
<p>调用DataFrame的sum方法将会返回一个含有列的和的Series：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">232</span>]: df.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">232</span>]: </span><br><span class="line">one    <span class="number">9.25</span></span><br><span class="line">two   -<span class="number">5.80</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>传入axis=’columns’或axis=1将会按行进行求和运算：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">233</span>]: df.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">233</span>]:</span><br><span class="line">a    <span class="number">1.40</span></span><br><span class="line">b    <span class="number">2.60</span></span><br><span class="line">c     NaN</span><br><span class="line">d   -<span class="number">0.55</span></span><br></pre></td></tr></table></figure></p>
<p>NA值会自动被排除，除非整个切片（这里指的是行或列）都是NA。通过skipna选项可以禁用该功能：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">234</span>]: df.mean(axis=<span class="string">&#x27;columns&#x27;</span>, skipna=<span class="literal">False</span>)</span><br><span class="line">Out[<span class="number">234</span>]: </span><br><span class="line">a      NaN</span><br><span class="line">b    <span class="number">1.300</span></span><br><span class="line">c      NaN</span><br><span class="line">d   -<span class="number">0.275</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>表5-7列出了这些约简方法的常用选项。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-af35e3809278410e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>有些方法（如idxmin和idxmax）返回的是间接统计（比如达到最小值或最大值的索引）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">235</span>]: df.idxmax()</span><br><span class="line">Out[<span class="number">235</span>]: </span><br><span class="line">one    b</span><br><span class="line">two    d</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>另一些方法则是累计型的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">236</span>]: df.cumsum()</span><br><span class="line">Out[<span class="number">236</span>]: </span><br><span class="line">    one  two</span><br><span class="line">a  <span class="number">1.40</span>  NaN</span><br><span class="line">b  <span class="number">8.50</span> -<span class="number">4.5</span></span><br><span class="line">c   NaN  NaN</span><br><span class="line">d  <span class="number">9.25</span> -<span class="number">5.8</span></span><br></pre></td></tr></table></figure></p>
<p>还有一种方法，它既不是约简型也不是累计型。describe就是一个例子，它用于一次性产生多个汇总统计：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">237</span>]: df.describe()</span><br><span class="line">Out[<span class="number">237</span>]: </span><br><span class="line">            one       two</span><br><span class="line">count  <span class="number">3.000000</span>  <span class="number">2.000000</span></span><br><span class="line">mean   <span class="number">3.083333</span> -<span class="number">2.900000</span></span><br><span class="line">std    <span class="number">3.493685</span>  <span class="number">2.262742</span></span><br><span class="line"><span class="built_in">min</span>    <span class="number">0.750000</span> -<span class="number">4.500000</span></span><br><span class="line"><span class="number">25</span>%    <span class="number">1.075000</span> -<span class="number">3.700000</span></span><br><span class="line"><span class="number">50</span>%    <span class="number">1.400000</span> -<span class="number">2.900000</span></span><br><span class="line"><span class="number">75</span>%    <span class="number">4.250000</span> -<span class="number">2.100000</span></span><br><span class="line"><span class="built_in">max</span>    <span class="number">7.100000</span> -<span class="number">1.300000</span></span><br></pre></td></tr></table></figure></p>
<p>对于非数值型数据，describe会产生另外一种汇总统计：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">238</span>]: obj = pd.Series([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>] * <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">239</span>]: obj.describe()</span><br><span class="line">Out[<span class="number">239</span>]: </span><br><span class="line">count     <span class="number">16</span></span><br><span class="line">unique     <span class="number">3</span></span><br><span class="line">top        a</span><br><span class="line">freq       <span class="number">8</span></span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>表5-8列出了所有与描述统计相关的方法。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-11fa967f658ac314.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h2><span id="相关系数与协方差">相关系数与协方差</span></h2><p>有些汇总统计（如相关系数和协方差）是通过参数对计算出来的。我们来看几个DataFrame，它们的数据来自Yahoo!Finance的股票价格和成交量，使用的是pandas-datareader包（可以用conda或pip安装）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda install pandas-datareader</span><br></pre></td></tr></table></figure></p>
<p>我使用pandas_datareader模块下载了一些股票数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas_datareader.data <span class="keyword">as</span> web</span><br><span class="line">all_data = &#123;ticker: web.get_data_yahoo(ticker)</span><br><span class="line">            <span class="keyword">for</span> ticker <span class="keyword">in</span> [<span class="string">&#x27;AAPL&#x27;</span>, <span class="string">&#x27;IBM&#x27;</span>, <span class="string">&#x27;MSFT&#x27;</span>, <span class="string">&#x27;GOOG&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">price = pd.DataFrame(&#123;ticker: data[<span class="string">&#x27;Adj Close&#x27;</span>]</span><br><span class="line">                     <span class="keyword">for</span> ticker, data <span class="keyword">in</span> all_data.items()&#125;)</span><br><span class="line">volume = pd.DataFrame(&#123;ticker: data[<span class="string">&#x27;Volume&#x27;</span>]</span><br><span class="line">                      <span class="keyword">for</span> ticker, data <span class="keyword">in</span> all_data.items()&#125;)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：此时Yahoo! Finance已经不存在了，因为2017年Yahoo!被Verizon收购了。参阅pandas-datareader文档，可以学习最新的功能。</p>
</blockquote>
<p>现在计算价格的百分数变化，时间序列的操作会在第11章介绍：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">242</span>]: returns = price.pct_change()</span><br><span class="line"></span><br><span class="line">In [<span class="number">243</span>]: returns.tail()</span><br><span class="line">Out[<span class="number">243</span>]: </span><br><span class="line">                AAPL      GOOG       IBM      MSFT</span><br><span class="line">Date                                              </span><br><span class="line"><span class="number">2016</span>-<span class="number">10</span>-<span class="number">17</span> -<span class="number">0.000680</span>  <span class="number">0.001837</span>  <span class="number">0.002072</span> -<span class="number">0.003483</span></span><br><span class="line"><span class="number">2016</span>-<span class="number">10</span>-<span class="number">18</span> -<span class="number">0.000681</span>  <span class="number">0.019616</span> -<span class="number">0.026168</span>  <span class="number">0.007690</span></span><br><span class="line"><span class="number">2016</span>-<span class="number">10</span>-<span class="number">19</span> -<span class="number">0.002979</span>  <span class="number">0.007846</span>  <span class="number">0.003583</span> -<span class="number">0.002255</span></span><br><span class="line"><span class="number">2016</span>-<span class="number">10</span>-<span class="number">20</span> -<span class="number">0.000512</span> -<span class="number">0.005652</span>  <span class="number">0.001719</span> -<span class="number">0.004867</span></span><br><span class="line"><span class="number">2016</span>-<span class="number">10</span>-<span class="number">21</span> -<span class="number">0.003930</span>  <span class="number">0.003011</span> -<span class="number">0.012474</span>  <span class="number">0.042096</span></span><br></pre></td></tr></table></figure></p>
<p>Series的corr方法用于计算两个Series中重叠的、非NA的、按索引对齐的值的相关系数。与此类似，cov用于计算协方差：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">244</span>]: returns[<span class="string">&#x27;MSFT&#x27;</span>].corr(returns[<span class="string">&#x27;IBM&#x27;</span>])</span><br><span class="line">Out[<span class="number">244</span>]: <span class="number">0.49976361144151144</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">245</span>]: returns[<span class="string">&#x27;MSFT&#x27;</span>].cov(returns[<span class="string">&#x27;IBM&#x27;</span>])</span><br><span class="line">Out[<span class="number">245</span>]: <span class="number">8.8706554797035462e-05</span></span><br></pre></td></tr></table></figure></p>
<p>因为MSTF是一个合理的Python属性，我们还可以用更简洁的语法选择列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">246</span>]: returns.MSFT.corr(returns.IBM)</span><br><span class="line">Out[<span class="number">246</span>]: <span class="number">0.49976361144151144</span></span><br></pre></td></tr></table></figure></p>
<p>另一方面，DataFrame的corr和cov方法将以DataFrame的形式分别返回完整的相关系数或协方差矩阵：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">247</span>]: returns.corr()</span><br><span class="line">Out[<span class="number">247</span>]: </span><br><span class="line">          AAPL      GOOG       IBM      MSFT</span><br><span class="line">AAPL  <span class="number">1.000000</span>  <span class="number">0.407919</span>  <span class="number">0.386817</span>  <span class="number">0.389695</span></span><br><span class="line">GOOG  <span class="number">0.407919</span>  <span class="number">1.000000</span>  <span class="number">0.405099</span>  <span class="number">0.465919</span></span><br><span class="line">IBM   <span class="number">0.386817</span>  <span class="number">0.405099</span>  <span class="number">1.000000</span>  <span class="number">0.499764</span></span><br><span class="line">MSFT  <span class="number">0.389695</span>  <span class="number">0.465919</span>  <span class="number">0.499764</span>  <span class="number">1.000000</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">248</span>]: returns.cov()</span><br><span class="line">Out[<span class="number">248</span>]: </span><br><span class="line">          AAPL      GOOG       IBM      MSFT</span><br><span class="line">AAPL  <span class="number">0.000277</span>  <span class="number">0.000107</span>  <span class="number">0.000078</span>  <span class="number">0.000095</span></span><br><span class="line">GOOG  <span class="number">0.000107</span>  <span class="number">0.000251</span>  <span class="number">0.000078</span>  <span class="number">0.000108</span></span><br><span class="line">IBM   <span class="number">0.000078</span>  <span class="number">0.000078</span>  <span class="number">0.000146</span>  <span class="number">0.000089</span></span><br><span class="line">MSFT  <span class="number">0.000095</span>  <span class="number">0.000108</span>  <span class="number">0.000089</span>  <span class="number">0.000215</span></span><br></pre></td></tr></table></figure></p>
<p>利用DataFrame的corrwith方法，你可以计算其列或行跟另一个Series或DataFrame之间的相关系数。传入一个Series将会返回一个相关系数值Series（针对各列进行计算）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">249</span>]: returns.corrwith(returns.IBM)</span><br><span class="line">Out[<span class="number">249</span>]: </span><br><span class="line">AAPL    <span class="number">0.386817</span></span><br><span class="line">GOOG    <span class="number">0.405099</span></span><br><span class="line">IBM     <span class="number">1.000000</span></span><br><span class="line">MSFT    <span class="number">0.499764</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>传入一个DataFrame则会计算按列名配对的相关系数。这里，我计算百分比变化与成交量的相关系数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">250</span>]: returns.corrwith(volume)</span><br><span class="line">Out[<span class="number">250</span>]: </span><br><span class="line">AAPL   -<span class="number">0.075565</span></span><br><span class="line">GOOG   -<span class="number">0.007067</span></span><br><span class="line">IBM    -<span class="number">0.204849</span></span><br><span class="line">MSFT   -<span class="number">0.092950</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>传入axis=’columns’即可按行进行计算。无论如何，在计算相关系数之前，所有的数据项都会按标签对齐。</p>
<h2><span id="唯一值-值计数以及成员资格">唯一值、值计数以及成员资格</span></h2><p>还有一类方法可以从一维Series的值中抽取信息。看下面的例子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">251</span>]: obj = pd.Series([<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br></pre></td></tr></table></figure></p>
<p>第一个函数是unique，它可以得到Series中的唯一值数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">252</span>]: uniques = obj.unique()</span><br><span class="line"></span><br><span class="line">In [<span class="number">253</span>]: uniques</span><br><span class="line">Out[<span class="number">253</span>]: array([<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure></p>
<p>返回的唯一值是未排序的，如果需要的话，可以对结果再次进行排序（uniques.sort()）。相似的，value_counts用于计算一个Series中各值出现的频率：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">254</span>]: obj.value_counts()</span><br><span class="line">Out[<span class="number">254</span>]: </span><br><span class="line">c    <span class="number">3</span></span><br><span class="line">a    <span class="number">3</span></span><br><span class="line">b    <span class="number">2</span></span><br><span class="line">d    <span class="number">1</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>为了便于查看，结果Series是按值频率降序排列的。value_counts还是一个顶级pandas方法，可用于任何数组或序列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">255</span>]: pd.value_counts(obj.values, sort=<span class="literal">False</span>)</span><br><span class="line">Out[<span class="number">255</span>]: </span><br><span class="line">a    <span class="number">3</span></span><br><span class="line">b    <span class="number">2</span></span><br><span class="line">c    <span class="number">3</span></span><br><span class="line">d    <span class="number">1</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>isin用于判断矢量化集合的成员资格，可用于过滤Series中或DataFrame列中数据的子集：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">256</span>]: obj</span><br><span class="line">Out[<span class="number">256</span>]: </span><br><span class="line"><span class="number">0</span>    c</span><br><span class="line"><span class="number">1</span>    a</span><br><span class="line"><span class="number">2</span>    d</span><br><span class="line"><span class="number">3</span>    a</span><br><span class="line"><span class="number">4</span>    a</span><br><span class="line"><span class="number">5</span>    b</span><br><span class="line"><span class="number">6</span>    b</span><br><span class="line"><span class="number">7</span>    c</span><br><span class="line"><span class="number">8</span>    c</span><br><span class="line">dtype: <span class="built_in">object</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">257</span>]: mask = obj.isin([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">258</span>]: mask</span><br><span class="line">Out[<span class="number">258</span>]: </span><br><span class="line"><span class="number">0</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">1</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">3</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">4</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">5</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">6</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">7</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">8</span>     <span class="literal">True</span></span><br><span class="line">dtype: <span class="built_in">bool</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">259</span>]: obj[mask]</span><br><span class="line">Out[<span class="number">259</span>]: </span><br><span class="line"><span class="number">0</span>    c</span><br><span class="line"><span class="number">5</span>    b</span><br><span class="line"><span class="number">6</span>    b</span><br><span class="line"><span class="number">7</span>    c</span><br><span class="line"><span class="number">8</span>    c</span><br><span class="line">dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure></p>
<p>与isin类似的是Index.get_indexer方法，它可以给你一个索引数组，从可能包含重复值的数组到另一个不同值的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">260</span>]: to_match = pd.Series([<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">261</span>]: unique_vals = pd.Series([<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">262</span>]: pd.Index(unique_vals).get_indexer(to_match)</span><br><span class="line">Out[<span class="number">262</span>]: array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure></p>
<p>表5-9给出了这几个方法的一些参考信息。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-b53c4a9d65a2db32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表5-9 唯一值、值计数、成员资格方法"></p>
<p>有时，你可能希望得到DataFrame中多个相关列的一张柱状图。例如：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">263</span>]: data = pd.DataFrame(&#123;<span class="string">&#x27;Qu1&#x27;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">   .....:                      <span class="string">&#x27;Qu2&#x27;</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   .....:                      <span class="string">&#x27;Qu3&#x27;</span>: [<span class="number">1</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">264</span>]: data</span><br><span class="line">Out[<span class="number">264</span>]: </span><br><span class="line">   Qu1  Qu2  Qu3</span><br><span class="line"><span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span>    <span class="number">1</span></span><br><span class="line"><span class="number">1</span>    <span class="number">3</span>    <span class="number">3</span>    <span class="number">5</span></span><br><span class="line"><span class="number">2</span>    <span class="number">4</span>    <span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">3</span>    <span class="number">3</span>    <span class="number">2</span>    <span class="number">4</span></span><br><span class="line"><span class="number">4</span>    <span class="number">4</span>    <span class="number">3</span>    <span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p>将pandas.value_counts传给该DataFrame的apply函数，就会出现：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">265</span>]: result = data.apply(pd.value_counts).fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">266</span>]: result</span><br><span class="line">Out[<span class="number">266</span>]: </span><br><span class="line">   Qu1  Qu2  Qu3</span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">2.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">2.0</span>  <span class="number">0.0</span>  <span class="number">2.0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<p>这里，结果中的行标签是所有列的唯一值。后面的频率值是每个列中这些值的相应计数。</p>
<h1><span id="54-总结">5.4 总结</span></h1><p>在下一章，我们将讨论用pandas读取（或加载）和写入数据集的工具。</p>
<p>之后，我们将更深入地研究使用pandas进行数据清洗、规整、分析和可视化工具。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-4.numpy</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-4-numpy/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>NumPy（Numerical Python的简称）是Python数值计算最重要的基础包。大多数提供科学计算的包都是用NumPy的数组作为构建基础。</p>
<p>NumPy的部分功能如下：</p>
<ul>
<li>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。</li>
<li>用于对整组数据进行快速运算的标准数学函数（无需编写循环）。</li>
<li>用于读写磁盘数据的工具以及用于操作内存映射文件的工具。</li>
<li>线性代数、随机数生成以及傅里叶变换功能。</li>
<li>用于集成由C、C++、Fortran等语言编写的代码的A C API。</li>
</ul>
<span id="more"></span>
<p>由于NumPy提供了一个简单易用的C API，因此很容易将数据传递给由低级语言编写的外部库，外部库也能以NumPy数组的形式将数据返回给Python。这个功能使Python成为一种包装C/C++/Fortran历史代码库的选择，并使被包装库拥有一个动态的、易用的接口。</p>
<p>NumPy本身并没有提供多么高级的数据分析功能，理解NumPy数组以及面向数组的计算将有助于你更加高效地使用诸如pandas之类的工具。因为NumPy是一个很大的题目，我会在附录A中介绍更多NumPy高级功能，比如广播。</p>
<p>对于大部分数据分析应用而言，我最关注的功能主要集中在：</p>
<ul>
<li>用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。</li>
<li>常用的数组算法，如排序、唯一化、集合运算等。</li>
<li>高效的描述统计和数据聚合/摘要运算。</li>
<li>用于异构数据集的合并/连接运算的数据对齐和关系型数据运算。</li>
<li>将条件逻辑表述为数组表达式（而不是带有if-elif-else分支的循环）。</li>
<li>数据的分组运算（聚合、转换、函数应用等）。。</li>
</ul>
<p>虽然NumPy提供了通用的数值数据处理的计算基础，但大多数读者可能还是想将pandas作为统计和分析工作的基础，尤其是处理表格数据时。pandas还提供了一些NumPy所没有的领域特定的功能，如时间序列处理等。</p>
<blockquote>
<p>笔记：Python的面向数组计算可以追溯到1995年，Jim Hugunin创建了Numeric库。接下来的10年，许多科学编程社区纷纷开始使用Python的数组编程，但是进入21世纪，库的生态系统变得碎片化了。2005年，Travis Oliphant从Numeric和Numarray项目整合出了NumPy项目，进而所有社区都集合到了这个框架下。</p>
</blockquote>
<p>NumPy之于数值计算特别重要的原因之一，是因为它可以高效处理大数组的数据。这是因为：</p>
<ul>
<li>NumPy是在一个连续的内存块中存储数据，独立于其他Python内置对象。NumPy的C语言编写的算法库可以操作内存，而不必进行类型检查或其它前期工作。比起Python的内置序列，NumPy数组使用的内存更少。</li>
<li>NumPy可以在整个数组上执行复杂的计算，而不需要Python的for循环。</li>
</ul>
<p>要搞明白具体的性能差距，考察一个包含一百万整数的数组，和一个等价的Python列表：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">7</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: my_arr = np.arange(<span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: my_list = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1000000</span>))</span><br></pre></td></tr></table></figure></p>
<p>各个序列分别乘以2：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: %time <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): my_arr2 = my_arr * <span class="number">2</span></span><br><span class="line">CPU times: user <span class="number">20</span> ms, sys: <span class="number">50</span> ms, total: <span class="number">70</span> ms</span><br><span class="line">Wall time: <span class="number">72.4</span> ms</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: %time <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): my_list2 = [x * <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> my_list]</span><br><span class="line">CPU times: user <span class="number">760</span> ms, sys: <span class="number">290</span> ms, total: <span class="number">1.05</span> s</span><br><span class="line">Wall time: <span class="number">1.05</span> s</span><br></pre></td></tr></table></figure></p>
<p>基于NumPy的算法要比纯Python快10到100倍（甚至更快），并且使用的内存更少。</p>
<h1><span id="41-numpy的ndarray一种多维数组对象">4.1 NumPy的ndarray：一种多维数组对象</span></h1><p>NumPy最重要的一个特点就是其N维数组对象（即ndarray），该对象是一个快速而灵活的大数据集容器。你可以利用这种数组对整块数据执行一些数学运算，其语法跟标量元素之间的运算一样。</p>
<p>要明白Python是如何利用与标量值类似的语法进行批次计算，我先引入NumPy，然后生成一个包含随机数据的小数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate some random data</span></span><br><span class="line">In [<span class="number">13</span>]: data = np.random.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: data</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">array([[-<span class="number">0.2047</span>,  <span class="number">0.4789</span>, -<span class="number">0.5194</span>],</span><br><span class="line">       [-<span class="number">0.5557</span>,  <span class="number">1.9658</span>,  <span class="number">1.3934</span>]])</span><br></pre></td></tr></table></figure></p>
<p>然后进行数学运算：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: data * <span class="number">10</span></span><br><span class="line">Out[<span class="number">15</span>]: </span><br><span class="line">array([[ -<span class="number">2.0471</span>,   <span class="number">4.7894</span>,  -<span class="number">5.1944</span>],</span><br><span class="line">       [ -<span class="number">5.5573</span>,  <span class="number">19.6578</span>,  <span class="number">13.9341</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: data + data</span><br><span class="line">Out[<span class="number">16</span>]: </span><br><span class="line">array([[-<span class="number">0.4094</span>,  <span class="number">0.9579</span>, -<span class="number">1.0389</span>],</span><br><span class="line">       [-<span class="number">1.1115</span>,  <span class="number">3.9316</span>,  <span class="number">2.7868</span>]])</span><br></pre></td></tr></table></figure></p>
<p>第一个例子中，所有的元素都乘以10。第二个例子中，每个元素都与自身相加。</p>
<blockquote>
<p>笔记：在本章及全书中，我会使用标准的NumPy惯用法<code>import numpy as np</code>。你当然也可以在代码中使用<code>from numpy import *</code>，但不建议这么做。<code>numpy</code>的命名空间很大，包含许多函数，其中一些的名字与Python的内置函数重名（比如min和max）。</p>
</blockquote>
<p>ndarray是一个通用的同构数据多维容器，也就是说，其中的所有元素必须是相同类型的。每个数组都有一个shape（一个表示各维度大小的元组）和一个dtype（一个用于说明数组数据类型的对象）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: data.shape</span><br><span class="line">Out[<span class="number">17</span>]: (<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: data.dtype</span><br><span class="line">Out[<span class="number">18</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>本章将会介绍NumPy数组的基本用法，这对于本书后面各章的理解基本够用。虽然大多数数据分析工作不需要深入理解NumPy，但是精通面向数组的编程和思维方式是成为Python科学计算牛人的一大关键步骤。</p>
<blockquote>
<p>笔记：当你在本书中看到“数组”、“NumPy数组”、”ndarray”时，基本上都指的是同一样东西，即ndarray对象。</p>
</blockquote>
<h2><span id="创建ndarray">创建ndarray</span></h2><p>创建数组最简单的办法就是使用array函数。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的NumPy数组。以一个列表的转换为例：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">19</span>]: data1 = [<span class="number">6</span>, <span class="number">7.5</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: arr1 = np.array(data1)</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: arr1</span><br><span class="line">Out[<span class="number">21</span>]: array([ <span class="number">6.</span> ,  <span class="number">7.5</span>,  <span class="number">8.</span> ,  <span class="number">0.</span> ,  <span class="number">1.</span> ])</span><br></pre></td></tr></table></figure></p>
<p>嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">22</span>]: data2 = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: arr2 = np.array(data2)</span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: arr2</span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br></pre></td></tr></table></figure></p>
<p>因为data2是列表的列表，NumPy数组arr2的两个维度的shape是从data2引入的。可以用属性ndim和shape验证：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">25</span>]: arr2.ndim</span><br><span class="line">Out[<span class="number">25</span>]: <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: arr2.shape</span><br><span class="line">Out[<span class="number">26</span>]: (<span class="number">2</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure></p>
<p>除非特别说明（稍后将会详细介绍），np.array会尝试为新建的这个数组推断出一个较为合适的数据类型。数据类型保存在一个特殊的dtype对象中。比如说，在上面的两个例子中，我们有：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: arr1.dtype</span><br><span class="line">Out[<span class="number">27</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: arr2.dtype</span><br><span class="line">Out[<span class="number">28</span>]: dtype(<span class="string">&#x27;int64&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>除np.array之外，还有一些函数也可以新建数组。比如，zeros和ones分别可以创建指定长度或形状的全0或全1数组。empty可以创建一个没有任何具体值的数组。要用这些方法创建多维数组，只需传入一个表示形状的元组即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: np.zeros(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">29</span>]: array([ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: np.zeros((<span class="number">3</span>, <span class="number">6</span>))</span><br><span class="line">Out[<span class="number">30</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: np.empty((<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">Out[<span class="number">31</span>]: </span><br><span class="line">array([[[ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>]],</span><br><span class="line">       [[ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>]]])</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：认为np.empty会返回全0数组的想法是不安全的。很多情况下（如前所示），它返回的都是一些未初始化的垃圾值。</p>
</blockquote>
<p>arange是Python内置函数range的数组版：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: np.arange(<span class="number">15</span>)</span><br><span class="line">Out[<span class="number">32</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>])</span><br></pre></td></tr></table></figure></p>
<p>表4-1列出了一些数组创建函数。由于NumPy关注的是数值计算，因此，如果没有特别指定，数据类型基本都是float64（浮点数）。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-78ab11f67e7077a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表4-1 数组创建函数"></p>
<h2><span id="ndarray的数据类型">ndarray的数据类型</span></h2><p>dtype（数据类型）是一个特殊的对象，它含有ndarray将一块内存解释为特定数据类型所需的信息：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: arr1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=np.float64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: arr2 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=np.int32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: arr1.dtype</span><br><span class="line">Out[<span class="number">35</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: arr2.dtype</span><br><span class="line">Out[<span class="number">36</span>]: dtype(<span class="string">&#x27;int32&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>dtype是NumPy灵活交互其它系统的源泉之一。多数情况下，它们直接映射到相应的机器表示，这使得“读写磁盘上的二进制数据流”以及“集成低级语言代码（如C、Fortran）”等工作变得更加简单。数值型dtype的命名方式相同：一个类型名（如float或int），后面跟一个用于表示各元素位长的数字。标准的双精度浮点值（即Python中的float对象）需要占用8字节（即64位）。因此，该类型在NumPy中就记作float64。表4-2列出了NumPy所支持的全部数据类型。</p>
<blockquote>
<p>笔记：记不住这些NumPy的dtype也没关系，新手更是如此。通常只需要知道你所处理的数据的大致类型是浮点数、复数、整数、布尔值、字符串，还是普通的Python对象即可。当你需要控制数据在内存和磁盘中的存储方式时（尤其是对大数据集），那就得了解如何控制存储类型。</p>
</blockquote>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-2f2d7406a8bc076c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-5cc31115615737b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>你可以通过ndarray的astype方法明确地将一个数组从一个dtype转换成另一个dtype：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">37</span>]: arr = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: arr.dtype</span><br><span class="line">Out[<span class="number">38</span>]: dtype(<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: float_arr = arr.astype(np.float64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: float_arr.dtype</span><br><span class="line">Out[<span class="number">40</span>]: dtype(<span class="string">&#x27;float64&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<p>在本例中，整数被转换成了浮点数。如果将浮点数转换成整数，则小数部分将会被截取删除：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: arr = np.array([<span class="number">3.7</span>, -<span class="number">1.2</span>, -<span class="number">2.6</span>, <span class="number">0.5</span>, <span class="number">12.9</span>, <span class="number">10.1</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: arr</span><br><span class="line">Out[<span class="number">42</span>]: array([  <span class="number">3.7</span>,  -<span class="number">1.2</span>,  -<span class="number">2.6</span>,   <span class="number">0.5</span>,  <span class="number">12.9</span>,  <span class="number">10.1</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: arr.astype(np.int32)</span><br><span class="line">Out[<span class="number">43</span>]: array([ <span class="number">3</span>, -<span class="number">1</span>, -<span class="number">2</span>,  <span class="number">0</span>, <span class="number">12</span>, <span class="number">10</span>], dtype=int32)</span><br></pre></td></tr></table></figure></p>
<p>如果某字符串数组表示的全是数字，也可以用astype将其转换为数值形式：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: numeric_strings = np.array([<span class="string">&#x27;1.25&#x27;</span>, <span class="string">&#x27;-9.6&#x27;</span>, <span class="string">&#x27;42&#x27;</span>], dtype=np.string_)</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: numeric_strings.astype(<span class="built_in">float</span>)</span><br><span class="line">Out[<span class="number">45</span>]: array([  <span class="number">1.25</span>,  -<span class="number">9.6</span> ,  <span class="number">42.</span>  ])</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：使用numpy.string_类型时，一定要小心，因为NumPy的字符串数据是大小固定的，发生截取时，不会发出警告。pandas提供了更多非数值数据的便利的处理方法。</p>
</blockquote>
<p>如果转换过程因为某种原因而失败了（比如某个不能被转换为float64的字符串），就会引发一个ValueError。这里，我比较懒，写的是float而不是np.float64；NumPy很聪明，它会将Python类型映射到等价的dtype上。</p>
<p>数组的dtype还有另一个属性：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">46</span>]: int_array = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: calibers = np.array([<span class="number">.22</span>, <span class="number">.270</span>, <span class="number">.357</span>, <span class="number">.380</span>, <span class="number">.44</span>, <span class="number">.50</span>], dtype=np.float64)</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: int_array.astype(calibers.dtype)</span><br><span class="line">Out[<span class="number">48</span>]: array([ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>,  <span class="number">8.</span>,  <span class="number">9.</span>])</span><br></pre></td></tr></table></figure></p>
<p>你还可以用简洁的类型代码来表示dtype：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: empty_uint32 = np.empty(<span class="number">8</span>, dtype=<span class="string">&#x27;u4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: empty_uint32</span><br><span class="line">Out[<span class="number">50</span>]: </span><br><span class="line">array([         <span class="number">0</span>, <span class="number">1075314688</span>,          <span class="number">0</span>, <span class="number">1075707904</span>,          <span class="number">0</span>,</span><br><span class="line">       <span class="number">1075838976</span>,          <span class="number">0</span>, <span class="number">1072693248</span>], dtype=uint32)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>笔记：调用astype总会创建一个新的数组（一个数据的备份），即使新的dtype与旧的dtype相同。</p>
</blockquote>
<h2><span id="numpy数组的运算">NumPy数组的运算</span></h2><p>数组很重要，因为它使你不用编写循环即可对数据执行批量运算。NumPy用户称其为矢量化（vectorization）。大小相等的数组之间的任何算术运算都会将运算应用到元素级：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: arr = np.array([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: arr</span><br><span class="line">Out[<span class="number">52</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">       [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: arr * arr</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">array([[  <span class="number">1.</span>,   <span class="number">4.</span>,   <span class="number">9.</span>],</span><br><span class="line">       [ <span class="number">16.</span>,  <span class="number">25.</span>,  <span class="number">36.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: arr - arr</span><br><span class="line">Out[<span class="number">54</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>数组与标量的算术运算会将标量值传播到各个元素：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">55</span>]: <span class="number">1</span> / arr</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>    ,  <span class="number">0.5</span>   ,  <span class="number">0.3333</span>],</span><br><span class="line">       [ <span class="number">0.25</span>  ,  <span class="number">0.2</span>   ,  <span class="number">0.1667</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">56</span>]: arr ** <span class="number">0.5</span></span><br><span class="line">Out[<span class="number">56</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>    ,  <span class="number">1.4142</span>,  <span class="number">1.7321</span>],</span><br><span class="line">       [ <span class="number">2.</span>    ,  <span class="number">2.2361</span>,  <span class="number">2.4495</span>]])</span><br></pre></td></tr></table></figure></p>
<p>大小相同的数组之间的比较会生成布尔值数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: arr2 = np.array([[<span class="number">0.</span>, <span class="number">4.</span>, <span class="number">1.</span>], [<span class="number">7.</span>, <span class="number">2.</span>, <span class="number">12.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: arr2</span><br><span class="line">Out[<span class="number">58</span>]: </span><br><span class="line">array([[  <span class="number">0.</span>,   <span class="number">4.</span>,   <span class="number">1.</span>],</span><br><span class="line">       [  <span class="number">7.</span>,   <span class="number">2.</span>,  <span class="number">12.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: arr2 &gt; arr</span><br><span class="line">Out[<span class="number">59</span>]:</span><br><span class="line">array([[<span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">       [ <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>]], dtype=<span class="built_in">bool</span>)</span><br></pre></td></tr></table></figure></p>
<p>不同大小的数组之间的运算叫做广播（broadcasting），将在附录A中对其进行详细讨论。本书的内容不需要对广播机制有多深的理解。</p>
<h2><span id="基本的索引和切片">基本的索引和切片</span></h2><p>NumPy数组的索引是一个内容丰富的主题，因为选取数据子集或单个元素的方式有很多。一维数组很简单。从表面上看，它们跟Python列表的功能差不多：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: arr = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: arr</span><br><span class="line">Out[<span class="number">61</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: arr[<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">62</span>]: <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: arr[<span class="number">5</span>:<span class="number">8</span>]</span><br><span class="line">Out[<span class="number">63</span>]: array([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: arr[<span class="number">5</span>:<span class="number">8</span>] = <span class="number">12</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: arr</span><br><span class="line">Out[<span class="number">65</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">12</span>, <span class="number">12</span>, <span class="number">12</span>,  <span class="number">8</span>,  <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>如上所示，当你将一个标量值赋值给一个切片时（如arr[5:8]=12），该值会自动传播（也就说后面将会讲到的“广播”）到整个选区。跟列表最重要的区别在于，数组切片是原始数组的视图。这意味着数据不会被复制，视图上的任何修改都会直接反映到源数组上。</p>
<p>作为例子，先创建一个arr的切片：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: arr_slice = arr[<span class="number">5</span>:<span class="number">8</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: arr_slice</span><br><span class="line">Out[<span class="number">67</span>]: array([<span class="number">12</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br></pre></td></tr></table></figure></p>
<p>现在，当我修稿arr_slice中的值，变动也会体现在原始数组arr中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: arr_slice[<span class="number">1</span>] = <span class="number">12345</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: arr</span><br><span class="line">Out[<span class="number">69</span>]: array([    <span class="number">0</span>,     <span class="number">1</span>,     <span class="number">2</span>,     <span class="number">3</span>,     <span class="number">4</span>,    <span class="number">12</span>, <span class="number">12345</span>,    <span class="number">12</span>,     <span class="number">8</span>,   </span><br><span class="line">  <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>切片[ : ]会给数组中的所有值赋值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">70</span>]: arr_slice[:] = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: arr</span><br><span class="line">Out[<span class="number">71</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">64</span>,  <span class="number">8</span>,  <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>如果你刚开始接触NumPy，可能会对此感到惊讶（尤其是当你曾经用过其他热衷于复制数组数据的编程语言）。由于NumPy的设计目的是处理大数据，所以你可以想象一下，假如NumPy坚持要将数据复制来复制去的话会产生何等的性能和内存问题。</p>
<blockquote>
<p>注意：如果你想要得到的是ndarray切片的一份副本而非视图，就需要明确地进行复制操作，例如<code>arr[5:8].copy()</code>。</p>
</blockquote>
<p>对于高维度数组，能做的事情更多。在一个二维数组中，各索引位置上的元素不再是标量而是一维数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">72</span>]: arr2d = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">73</span>]: arr2d[<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">73</span>]: array([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>因此，可以对各个元素进行递归访问，但这样需要做的事情有点多。你可以传入一个以逗号隔开的索引列表来选取单个元素。也就是说，下面两种方式是等价的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: arr2d[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">74</span>]: <span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">75</span>]: arr2d[<span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line">Out[<span class="number">75</span>]: <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<p>图4-1说明了二维数组的索引方式。轴0作为行，轴1作为列。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-0a641536f73f560e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-1 NumPy数组中的元素索引"></p>
<p>在多维数组中，如果省略了后面的索引，则返回对象会是一个维度低一点的ndarray（它含有高一级维度上的所有数据）。因此，在2×2×3数组arr3d中：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: arr3d = np.array([[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], [[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: arr3d</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">array([[[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>]],</span><br><span class="line">       [[ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]])</span><br></pre></td></tr></table></figure></p>
<p>arr3d[0]是一个2×3数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">78</span>]: arr3d[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">78</span>]: </span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure></p>
<p>标量值和数组都可以被赋值给arr3d[0]：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">79</span>]: old_values = arr3d[<span class="number">0</span>].copy()</span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: arr3d[<span class="number">0</span>] = <span class="number">42</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: arr3d</span><br><span class="line">Out[<span class="number">81</span>]: </span><br><span class="line">array([[[<span class="number">42</span>, <span class="number">42</span>, <span class="number">42</span>],</span><br><span class="line">        [<span class="number">42</span>, <span class="number">42</span>, <span class="number">42</span>]],</span><br><span class="line">       [[ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">82</span>]: arr3d[<span class="number">0</span>] = old_values</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: arr3d</span><br><span class="line">Out[<span class="number">83</span>]: </span><br><span class="line">array([[[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>]],</span><br><span class="line">       [[ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]])</span><br></pre></td></tr></table></figure></p>
<p>相似的，arr3d[1,0]可以访问索引以(1,0)开头的那些值（以一维数组的形式返回）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">84</span>]: arr3d[<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">Out[<span class="number">84</span>]: array([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>虽然是用两步进行索引的，表达式是相同的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: x = arr3d[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: x</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line">array([[ <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">       [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: x[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">87</span>]: array([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>注意，在上面所有这些选取数组子集的例子中，返回的数组都是视图。</p>
<h2><span id="切片索引">切片索引</span></h2><p>ndarray的切片语法跟Python列表这样的一维对象差不多：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">88</span>]: arr</span><br><span class="line">Out[<span class="number">88</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">64</span>,  <span class="number">8</span>,  <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: arr[<span class="number">1</span>:<span class="number">6</span>]</span><br><span class="line">Out[<span class="number">89</span>]: array([ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">64</span>])</span><br></pre></td></tr></table></figure></p>
<p>对于之前的二维数组arr2d，其切片方式稍显不同：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">90</span>]: arr2d</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">91</span>]: arr2d[:<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">91</span>]: </span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure></p>
<p>可以看出，它是沿着第0轴（即第一个轴）切片的。也就是说，切片是沿着一个轴向选取元素的。表达式arr2d[:2]可以被认为是“选取arr2d的前两行”。</p>
<p>你可以一次传入多个切片，就像传入多个索引那样：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">92</span>]: arr2d[:<span class="number">2</span>, <span class="number">1</span>:]</span><br><span class="line">Out[<span class="number">92</span>]: </span><br><span class="line">array([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure></p>
<p>像这样进行切片时，只能得到相同维数的数组视图。通过将整数索引和切片混合，可以得到低维度的切片。</p>
<p>例如，我可以选取第二行的前两列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">93</span>]: arr2d[<span class="number">1</span>, :<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">93</span>]: array([<span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure></p>
<p>相似的，还可以选择第三列的前两行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: arr2d[:<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">Out[<span class="number">94</span>]: array([<span class="number">3</span>, <span class="number">6</span>])</span><br></pre></td></tr></table></figure></p>
<p>图4-2对此进行了说明。注意，“只有冒号”表示选取整个轴，因此你可以像下面这样只对高维轴进行切片：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: arr2d[:, :<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">95</span>]: </span><br><span class="line">array([[<span class="number">1</span>],</span><br><span class="line">       [<span class="number">4</span>],</span><br><span class="line">       [<span class="number">7</span>]])</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-9da32d2f4629c304.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-2 二维数组切片"></p>
<p>自然，对切片表达式的赋值操作也会被扩散到整个选区：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: arr2d[:<span class="number">2</span>, <span class="number">1</span>:] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: arr2d</span><br><span class="line">Out[<span class="number">97</span>]: </span><br><span class="line">array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br></pre></td></tr></table></figure></p>
<h2><span id="布尔型索引">布尔型索引</span></h2><p>来看这样一个例子，假设我们有一个用于存储数据的数组以及一个存储姓名的数组（含有重复项）。在这里，我将使用numpy.random中的randn函数生成一些正态分布的随机数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">98</span>]: names = np.array([<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: data = np.random.randn(<span class="number">7</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: names</span><br><span class="line">Out[<span class="number">100</span>]: </span><br><span class="line">array([<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>],</span><br><span class="line">      dtype=<span class="string">&#x27;&lt;U4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">101</span>]: data</span><br><span class="line">Out[<span class="number">101</span>]: </span><br><span class="line">array([[ <span class="number">0.0929</span>,  <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">1.2464</span>],</span><br><span class="line">       [ <span class="number">1.0072</span>, -<span class="number">1.2962</span>,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>],</span><br><span class="line">       [ <span class="number">1.3529</span>,  <span class="number">0.8864</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>, -<span class="number">0.5397</span>,  <span class="number">0.477</span> ],</span><br><span class="line">       [ <span class="number">3.2489</span>, -<span class="number">1.0212</span>, -<span class="number">0.5771</span>,  <span class="number">0.1241</span>],</span><br><span class="line">       [ <span class="number">0.3026</span>,  <span class="number">0.5238</span>,  <span class="number">0.0009</span>,  <span class="number">1.3438</span>],</span><br><span class="line">       [-<span class="number">0.7135</span>, -<span class="number">0.8312</span>, -<span class="number">2.3702</span>, -<span class="number">1.8608</span>]])</span><br></pre></td></tr></table></figure></p>
<p>假设每个名字都对应data数组中的一行，而我们想要选出对应于名字”Bob”的所有行。跟算术运算一样，数组的比较运算（如==）也是矢量化的。因此，对names和字符串”Bob”的比较运算将会产生一个布尔型数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: names == <span class="string">&#x27;Bob&#x27;</span></span><br><span class="line">Out[<span class="number">102</span>]: array([ <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>], dtype=<span class="built_in">bool</span>)</span><br></pre></td></tr></table></figure></p>
<p>这个布尔型数组可用于数组索引：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">103</span>]: data[names == <span class="string">&#x27;Bob&#x27;</span>]</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">array([[ <span class="number">0.0929</span>,  <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">1.2464</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>, -<span class="number">0.5397</span>,  <span class="number">0.477</span> ]])</span><br></pre></td></tr></table></figure></p>
<p>布尔型数组的长度必须跟被索引的轴长度一致。此外，还可以将布尔型数组跟切片、整数（或整数序列，稍后将对此进行详细讲解）混合使用：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">103</span>]: data[names == <span class="string">&#x27;Bob&#x27;</span>]</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">array([[ <span class="number">0.0929</span>,  <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">1.2464</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>, -<span class="number">0.5397</span>,  <span class="number">0.477</span> ]])</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意：如果布尔型数组的长度不对，布尔型选择就会出错，因此一定要小心。</p>
</blockquote>
<p>下面的例子，我选取了<code>names == &#39;Bob&#39;</code>的行，并索引了列：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">104</span>]: data[names == <span class="string">&#x27;Bob&#x27;</span>, <span class="number">2</span>:]</span><br><span class="line">Out[<span class="number">104</span>]: </span><br><span class="line">array([[ <span class="number">0.769</span> ,  <span class="number">1.2464</span>],</span><br><span class="line">       [-<span class="number">0.5397</span>,  <span class="number">0.477</span> ]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: data[names == <span class="string">&#x27;Bob&#x27;</span>, <span class="number">3</span>]</span><br><span class="line">Out[<span class="number">105</span>]: array([ <span class="number">1.2464</span>,  <span class="number">0.477</span> ])</span><br></pre></td></tr></table></figure></p>
<p>要选择除”Bob”以外的其他值，既可以使用不等于符号（!=），也可以通过~对条件进行否定：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">106</span>]: names != <span class="string">&#x27;Bob&#x27;</span></span><br><span class="line">Out[<span class="number">106</span>]: array([<span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>], dtype=<span class="built_in">bool</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">107</span>]: data[~(names == <span class="string">&#x27;Bob&#x27;</span>)]</span><br><span class="line">Out[<span class="number">107</span>]:</span><br><span class="line">array([[ <span class="number">1.0072</span>, -<span class="number">1.2962</span>,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>],</span><br><span class="line">       [ <span class="number">1.3529</span>,  <span class="number">0.8864</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">3.2489</span>, -<span class="number">1.0212</span>, -<span class="number">0.5771</span>,  <span class="number">0.1241</span>],</span><br><span class="line">       [ <span class="number">0.3026</span>,  <span class="number">0.5238</span>,  <span class="number">0.0009</span>,  <span class="number">1.3438</span>],</span><br><span class="line">       [-<span class="number">0.7135</span>, -<span class="number">0.8312</span>, -<span class="number">2.3702</span>, -<span class="number">1.8608</span>]])</span><br></pre></td></tr></table></figure></p>
<p>~操作符用来反转条件很好用：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: cond = names == <span class="string">&#x27;Bob&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: data[~cond]</span><br><span class="line">Out[<span class="number">109</span>]: </span><br><span class="line">array([[ <span class="number">1.0072</span>, -<span class="number">1.2962</span>,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>],</span><br><span class="line">       [ <span class="number">1.3529</span>,  <span class="number">0.8864</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">3.2489</span>, -<span class="number">1.0212</span>, -<span class="number">0.5771</span>,  <span class="number">0.1241</span>],</span><br><span class="line">       [ <span class="number">0.3026</span>,  <span class="number">0.5238</span>,  <span class="number">0.0009</span>,  <span class="number">1.3438</span>],</span><br><span class="line">       [-<span class="number">0.7135</span>, -<span class="number">0.8312</span>, -<span class="number">2.3702</span>, -<span class="number">1.8608</span>]])</span><br></pre></td></tr></table></figure></p>
<p>选取这三个名字中的两个需要组合应用多个布尔条件，使用&amp;（和）、|（或）之类的布尔算术运算符即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">110</span>]: mask = (names == <span class="string">&#x27;Bob&#x27;</span>) | (names == <span class="string">&#x27;Will&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">111</span>]: mask</span><br><span class="line">Out[<span class="number">111</span>]: array([ <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>], dtype=<span class="built_in">bool</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: data[mask]</span><br><span class="line">Out[<span class="number">112</span>]: </span><br><span class="line">array([[ <span class="number">0.0929</span>,  <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">1.2464</span>],</span><br><span class="line">       [ <span class="number">1.3529</span>,  <span class="number">0.8864</span>, -<span class="number">2.0016</span>, -<span class="number">0.3718</span>],</span><br><span class="line">       [ <span class="number">1.669</span> , -<span class="number">0.4386</span>, -<span class="number">0.5397</span>,  <span class="number">0.477</span> ],</span><br><span class="line">       [ <span class="number">3.2489</span>, -<span class="number">1.0212</span>, -<span class="number">0.5771</span>,  <span class="number">0.1241</span>]])</span><br></pre></td></tr></table></figure></p>
<p>通过布尔型索引选取数组中的数据，将总是创建数据的副本，即使返回一模一样的数组也是如此。</p>
<blockquote>
<p>注意：Python关键字and和or在布尔型数组中无效。要使用&amp;与|。</p>
</blockquote>
<p>通过布尔型数组设置值是一种经常用到的手段。为了将data中的所有负值都设置为0，我们只需：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">113</span>]: data[data &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: data</span><br><span class="line">Out[<span class="number">114</span>]: </span><br><span class="line">array([[ <span class="number">0.0929</span>,  <span class="number">0.2817</span>,  <span class="number">0.769</span> ,  <span class="number">1.2464</span>],</span><br><span class="line">       [ <span class="number">1.0072</span>,  <span class="number">0.</span>    ,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>],</span><br><span class="line">       [ <span class="number">1.3529</span>,  <span class="number">0.8864</span>,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ],</span><br><span class="line">       [ <span class="number">1.669</span> ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.477</span> ],</span><br><span class="line">       [ <span class="number">3.2489</span>,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.1241</span>],</span><br><span class="line">       [ <span class="number">0.3026</span>,  <span class="number">0.5238</span>,  <span class="number">0.0009</span>,  <span class="number">1.3438</span>],</span><br><span class="line">       [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ]])</span><br></pre></td></tr></table></figure></p>
<p>通过一维布尔数组设置整行或列的值也很简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">115</span>]: data[names != <span class="string">&#x27;Joe&#x27;</span>] = <span class="number">7</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: data</span><br><span class="line">Out[<span class="number">116</span>]: </span><br><span class="line">array([[ <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ],</span><br><span class="line">       [ <span class="number">1.0072</span>,  <span class="number">0.</span>    ,  <span class="number">0.275</span> ,  <span class="number">0.2289</span>],</span><br><span class="line">       [ <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ],</span><br><span class="line">       [ <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ],</span><br><span class="line">       [ <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ,  <span class="number">7.</span>    ],</span><br><span class="line">       [ <span class="number">0.3026</span>,  <span class="number">0.5238</span>,  <span class="number">0.0009</span>,  <span class="number">1.3438</span>],</span><br><span class="line">       [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ]])</span><br></pre></td></tr></table></figure></p>
<p>后面会看到，这类二维数据的操作也可以用pandas方便的来做。</p>
<h2><span id="花式索引">花式索引</span></h2><p>花式索引（Fancy indexing）是一个NumPy术语，它指的是利用整数数组进行索引。假设我们有一个8×4数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: arr = np.empty((<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">   .....:     arr[i] = i</span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: arr</span><br><span class="line">Out[<span class="number">119</span>]: </span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">3.</span>,  <span class="number">3.</span>,  <span class="number">3.</span>],</span><br><span class="line">       [ <span class="number">4.</span>,  <span class="number">4.</span>,  <span class="number">4.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [ <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>],</span><br><span class="line">       [ <span class="number">6.</span>,  <span class="number">6.</span>,  <span class="number">6.</span>,  <span class="number">6.</span>],</span><br><span class="line">       [ <span class="number">7.</span>,  <span class="number">7.</span>,  <span class="number">7.</span>,  <span class="number">7.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>为了以特定顺序选取行子集，只需传入一个用于指定顺序的整数列表或ndarray即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">120</span>]: arr[[<span class="number">4</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">6</span>]]</span><br><span class="line">Out[<span class="number">120</span>]: </span><br><span class="line">array([[ <span class="number">4.</span>,  <span class="number">4.</span>,  <span class="number">4.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">3.</span>,  <span class="number">3.</span>,  <span class="number">3.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">6.</span>,  <span class="number">6.</span>,  <span class="number">6.</span>,  <span class="number">6.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>这段代码确实达到我们的要求了！使用负数索引将会从末尾开始选取行：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">121</span>]: arr[[-<span class="number">3</span>, -<span class="number">5</span>, -<span class="number">7</span>]]</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line">array([[ <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>,  <span class="number">5.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">3.</span>,  <span class="number">3.</span>,  <span class="number">3.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>一次传入多个索引数组会有一点特别。它返回的是一个一维数组，其中的元素对应各个索引元组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">122</span>]: arr = np.arange(<span class="number">32</span>).reshape((<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">123</span>]: arr</span><br><span class="line">Out[<span class="number">123</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">       [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">       [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">       [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">       [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>],</span><br><span class="line">       [<span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: arr[[<span class="number">1</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">Out[<span class="number">124</span>]: array([ <span class="number">4</span>, <span class="number">23</span>, <span class="number">29</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure></p>
<p>附录A中会详细介绍reshape方法。</p>
<p>最终选出的是元素(1,0)、(5,3)、(7,1)和(2,2)。无论数组是多少维的，花式索引总是一维的。</p>
<p>这个花式索引的行为可能会跟某些用户的预期不一样（包括我在内），选取矩阵的行列子集应该是矩形区域的形式才对。下面是得到该结果的一个办法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">125</span>]: arr[[<span class="number">1</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">2</span>]][:, [<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">Out[<span class="number">125</span>]: </span><br><span class="line">array([[ <span class="number">4</span>,  <span class="number">7</span>,  <span class="number">5</span>,  <span class="number">6</span>],</span><br><span class="line">       [<span class="number">20</span>, <span class="number">23</span>, <span class="number">21</span>, <span class="number">22</span>],</span><br><span class="line">       [<span class="number">28</span>, <span class="number">31</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">       [ <span class="number">8</span>, <span class="number">11</span>,  <span class="number">9</span>, <span class="number">10</span>]])</span><br></pre></td></tr></table></figure></p>
<p>记住，花式索引跟切片不一样，它总是将数据复制到新数组中。</p>
<h2><span id="数组转置和轴对换">数组转置和轴对换</span></h2><p>转置是重塑的一种特殊形式，它返回的是源数据的视图（不会进行任何复制操作）。数组不仅有transpose方法，还有一个特殊的T属性：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">126</span>]: arr = np.arange(<span class="number">15</span>).reshape((<span class="number">3</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">127</span>]: arr</span><br><span class="line">Out[<span class="number">127</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>],</span><br><span class="line">       [ <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">       [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">128</span>]: arr.T</span><br><span class="line">Out[<span class="number">128</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">5</span>, <span class="number">10</span>],</span><br><span class="line">       [ <span class="number">1</span>,  <span class="number">6</span>, <span class="number">11</span>],</span><br><span class="line">       [ <span class="number">2</span>,  <span class="number">7</span>, <span class="number">12</span>],</span><br><span class="line">       [ <span class="number">3</span>,  <span class="number">8</span>, <span class="number">13</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">9</span>, <span class="number">14</span>]])</span><br></pre></td></tr></table></figure></p>
<p>在进行矩阵计算时，经常需要用到该操作，比如利用np.dot计算矩阵内积：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">129</span>]: arr = np.random.randn(<span class="number">6</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">130</span>]: arr</span><br><span class="line">Out[<span class="number">130</span>]: </span><br><span class="line">array([[-<span class="number">0.8608</span>,  <span class="number">0.5601</span>, -<span class="number">1.2659</span>],</span><br><span class="line">       [ <span class="number">0.1198</span>, -<span class="number">1.0635</span>,  <span class="number">0.3329</span>],</span><br><span class="line">       [-<span class="number">2.3594</span>, -<span class="number">0.1995</span>, -<span class="number">1.542</span> ],</span><br><span class="line">       [-<span class="number">0.9707</span>, -<span class="number">1.307</span> ,  <span class="number">0.2863</span>],</span><br><span class="line">       [ <span class="number">0.378</span> , -<span class="number">0.7539</span>,  <span class="number">0.3313</span>],</span><br><span class="line">       [ <span class="number">1.3497</span>,  <span class="number">0.0699</span>,  <span class="number">0.2467</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">131</span>]: np.dot(arr.T, arr)</span><br><span class="line">Out[<span class="number">131</span>]:</span><br><span class="line">array([[ <span class="number">9.2291</span>,  <span class="number">0.9394</span>,  <span class="number">4.948</span> ],</span><br><span class="line">       [ <span class="number">0.9394</span>,  <span class="number">3.7662</span>, -<span class="number">1.3622</span>],</span><br><span class="line">       [ <span class="number">4.948</span> , -<span class="number">1.3622</span>,  <span class="number">4.3437</span>]])</span><br></pre></td></tr></table></figure></p>
<p>对于高维数组，transpose需要得到一个由轴编号组成的元组才能对这些轴进行转置（比较费脑子）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">132</span>]: arr = np.arange(<span class="number">16</span>).reshape((<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">133</span>]: arr</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">array([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>]],</span><br><span class="line">       [[ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: arr.transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">Out[<span class="number">134</span>]: </span><br><span class="line">array([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line">       [[ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]]])</span><br></pre></td></tr></table></figure></p>
<p>这里，第一个轴被换成了第二个，第二个轴被换成了第一个，最后一个轴不变。</p>
<p>简单的转置可以使用.T，它其实就是进行轴对换而已。ndarray还有一个swapaxes方法，它需要接受一对轴编号：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">135</span>]: arr</span><br><span class="line">Out[<span class="number">135</span>]: </span><br><span class="line">array([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>]],</span><br><span class="line">       [[ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: arr.swapaxes(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">Out[<span class="number">136</span>]: </span><br><span class="line">array([[[ <span class="number">0</span>,  <span class="number">4</span>],</span><br><span class="line">        [ <span class="number">1</span>,  <span class="number">5</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">6</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">7</span>]],</span><br><span class="line">       [[ <span class="number">8</span>, <span class="number">12</span>],</span><br><span class="line">        [ <span class="number">9</span>, <span class="number">13</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">14</span>],</span><br><span class="line">        [<span class="number">11</span>, <span class="number">15</span>]]])</span><br></pre></td></tr></table></figure></p>
<p>swapaxes也是返回源数据的视图（不会进行任何复制操作）。</p>
<h1><span id="42-通用函数快速的元素级数组函数">4.2 通用函数：快速的元素级数组函数</span></h1><p>通用函数（即ufunc）是一种对ndarray中的数据执行元素级运算的函数。你可以将其看做简单函数（接受一个或多个标量值，并产生一个或多个标量值）的矢量化包装器。</p>
<p>许多ufunc都是简单的元素级变体，如sqrt和exp：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">137</span>]: arr = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">138</span>]: arr</span><br><span class="line">Out[<span class="number">138</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">139</span>]: np.sqrt(arr)</span><br><span class="line">Out[<span class="number">139</span>]: </span><br><span class="line">array([ <span class="number">0.</span>    ,  <span class="number">1.</span>    ,  <span class="number">1.4142</span>,  <span class="number">1.7321</span>,  <span class="number">2.</span>    ,  <span class="number">2.2361</span>,  <span class="number">2.4495</span>,</span><br><span class="line">        <span class="number">2.6458</span>,  <span class="number">2.8284</span>,  <span class="number">3.</span>    ])</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: np.exp(arr)</span><br><span class="line">Out[<span class="number">140</span>]: </span><br><span class="line">array([    <span class="number">1.</span>    ,     <span class="number">2.7183</span>,     <span class="number">7.3891</span>,    <span class="number">20.0855</span>,    <span class="number">54.5982</span>,</span><br><span class="line">         <span class="number">148.4132</span>,   <span class="number">403.4288</span>,  <span class="number">1096.6332</span>,  <span class="number">2980.958</span> ,  <span class="number">8103.0839</span>])</span><br></pre></td></tr></table></figure></p>
<p>这些都是一元（unary）ufunc。另外一些（如add或maximum）接受2个数组（因此也叫二元（binary）ufunc），并返回一个结果数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">141</span>]: x = np.random.randn(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">142</span>]: y = np.random.randn(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">143</span>]: x</span><br><span class="line">Out[<span class="number">143</span>]: </span><br><span class="line">array([-<span class="number">0.0119</span>,  <span class="number">1.0048</span>,  <span class="number">1.3272</span>, -<span class="number">0.9193</span>, -<span class="number">1.5491</span>,  <span class="number">0.0222</span>,  <span class="number">0.7584</span>,</span><br><span class="line">       -<span class="number">0.6605</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">144</span>]: y</span><br><span class="line">Out[<span class="number">144</span>]: </span><br><span class="line">array([ <span class="number">0.8626</span>, -<span class="number">0.01</span>  ,  <span class="number">0.05</span>  ,  <span class="number">0.6702</span>,  <span class="number">0.853</span> , -<span class="number">0.9559</span>, -<span class="number">0.0235</span>,</span><br><span class="line">       -<span class="number">2.3042</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">145</span>]: np.maximum(x, y)</span><br><span class="line">Out[<span class="number">145</span>]: </span><br><span class="line">array([ <span class="number">0.8626</span>,  <span class="number">1.0048</span>,  <span class="number">1.3272</span>,  <span class="number">0.6702</span>,  <span class="number">0.853</span> ,  <span class="number">0.0222</span>,  <span class="number">0.7584</span>,   </span><br><span class="line">       -<span class="number">0.6605</span>])</span><br></pre></td></tr></table></figure></p>
<p>这里，numpy.maximum计算了x和y中元素级别最大的元素。</p>
<p>虽然并不常见，但有些ufunc的确可以返回多个数组。modf就是一个例子，它是Python内置函数divmod的矢量化版本，它会返回浮点数数组的小数和整数部分：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">146</span>]: arr = np.random.randn(<span class="number">7</span>) * <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">147</span>]: arr</span><br><span class="line">Out[<span class="number">147</span>]: array([-<span class="number">3.2623</span>, -<span class="number">6.0915</span>, -<span class="number">6.663</span> ,  <span class="number">5.3731</span>,  <span class="number">3.6182</span>,  <span class="number">3.45</span>  ,  <span class="number">5.0077</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: remainder, whole_part = np.modf(arr)</span><br><span class="line"></span><br><span class="line">In [<span class="number">149</span>]: remainder</span><br><span class="line">Out[<span class="number">149</span>]: array([-<span class="number">0.2623</span>, -<span class="number">0.0915</span>, -<span class="number">0.663</span> ,  <span class="number">0.3731</span>,</span><br><span class="line"><span class="number">0.6182</span>,  <span class="number">0.45</span>  ,  <span class="number">0.0077</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">150</span>]: whole_part</span><br><span class="line">Out[<span class="number">150</span>]: array([-<span class="number">3.</span>, -<span class="number">6.</span>, -<span class="number">6.</span>,  <span class="number">5.</span>,  <span class="number">3.</span>,  <span class="number">3.</span>,  <span class="number">5.</span>])</span><br></pre></td></tr></table></figure></p>
<p>Ufuncs可以接受一个out可选参数，这样就能在数组原地进行操作：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">151</span>]: arr</span><br><span class="line">Out[<span class="number">151</span>]: array([-<span class="number">3.2623</span>, -<span class="number">6.0915</span>, -<span class="number">6.663</span> ,  <span class="number">5.3731</span>,  <span class="number">3.6182</span>,  <span class="number">3.45</span>  ,  <span class="number">5.0077</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">152</span>]: np.sqrt(arr)</span><br><span class="line">Out[<span class="number">152</span>]: array([    nan,     nan,     nan,  <span class="number">2.318</span> ,  <span class="number">1.9022</span>,  <span class="number">1.8574</span>,  <span class="number">2.2378</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">153</span>]: np.sqrt(arr, arr)</span><br><span class="line">Out[<span class="number">153</span>]: array([    nan,     nan,     nan,  <span class="number">2.318</span> ,  <span class="number">1.9022</span>,  <span class="number">1.8574</span>,  <span class="number">2.2378</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">154</span>]: arr</span><br><span class="line">Out[<span class="number">154</span>]: array([    nan,     nan,     nan,  <span class="number">2.318</span> ,  <span class="number">1.9022</span>,  <span class="number">1.8574</span>,  <span class="number">2.2378</span>])</span><br></pre></td></tr></table></figure></p>
<p>表4-3和表4-4分别列出了一些一元和二元ufunc。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-1d494e73b61c7ced.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-2be79faf68ab6ff8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-4e38d02a66481530.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-eff1e61e5464159f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-236dba83b6a420cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h1><span id="43-利用数组进行数据处理">4.3 利用数组进行数据处理</span></h1><p>NumPy数组使你可以将许多种数据处理任务表述为简洁的数组表达式（否则需要编写循环）。用数组表达式代替循环的做法，通常被称为矢量化。一般来说，矢量化数组运算要比等价的纯Python方式快上一两个数量级（甚至更多），尤其是各种数值计算。在后面内容中（见附录A）我将介绍广播，这是一种针对矢量化计算的强大手段。</p>
<p>作为简单的例子，假设我们想要在一组值（网格型）上计算函数<code>sqrt(x^2+y^2)</code>。np.meshgrid函数接受两个一维数组，并产生两个二维矩阵（对应于两个数组中所有的(x,y)对）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">155</span>]: points = np.arange(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">0.01</span>) <span class="comment"># 1000 equally spaced points</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">156</span>]: xs, ys = np.meshgrid(points, points)</span><br><span class="line">In [<span class="number">157</span>]: ys</span><br><span class="line">Out[<span class="number">157</span>]: </span><br><span class="line">array([[-<span class="number">5.</span>  , -<span class="number">5.</span>  , -<span class="number">5.</span>  , ..., -<span class="number">5.</span>  , -<span class="number">5.</span>  , -<span class="number">5.</span>  ],</span><br><span class="line">       [-<span class="number">4.99</span>, -<span class="number">4.99</span>, -<span class="number">4.99</span>, ..., -<span class="number">4.99</span>, -<span class="number">4.99</span>, -<span class="number">4.99</span>],</span><br><span class="line">       [-<span class="number">4.98</span>, -<span class="number">4.98</span>, -<span class="number">4.98</span>, ..., -<span class="number">4.98</span>, -<span class="number">4.98</span>, -<span class="number">4.98</span>],</span><br><span class="line">       ..., </span><br><span class="line">       [ <span class="number">4.97</span>,  <span class="number">4.97</span>,  <span class="number">4.97</span>, ...,  <span class="number">4.97</span>,  <span class="number">4.97</span>,  <span class="number">4.97</span>],</span><br><span class="line">       [ <span class="number">4.98</span>,  <span class="number">4.98</span>,  <span class="number">4.98</span>, ...,  <span class="number">4.98</span>,  <span class="number">4.98</span>,  <span class="number">4.98</span>],</span><br><span class="line">       [ <span class="number">4.99</span>,  <span class="number">4.99</span>,  <span class="number">4.99</span>, ...,  <span class="number">4.99</span>,  <span class="number">4.99</span>,  <span class="number">4.99</span>]])</span><br></pre></td></tr></table></figure></p>
<p>现在，对该函数的求值运算就好办了，把这两个数组当做两个浮点数那样编写表达式即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">158</span>]: z = np.sqrt(xs ** <span class="number">2</span> + ys ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">159</span>]: z</span><br><span class="line">Out[<span class="number">159</span>]: </span><br><span class="line">array([[ <span class="number">7.0711</span>,  <span class="number">7.064</span> ,  <span class="number">7.0569</span>, ...,  <span class="number">7.0499</span>,  <span class="number">7.0569</span>,  <span class="number">7.064</span> ],</span><br><span class="line">       [ <span class="number">7.064</span> ,  <span class="number">7.0569</span>,  <span class="number">7.0499</span>, ...,  <span class="number">7.0428</span>,  <span class="number">7.0499</span>,  <span class="number">7.0569</span>],</span><br><span class="line">       [ <span class="number">7.0569</span>,  <span class="number">7.0499</span>,  <span class="number">7.0428</span>, ...,  <span class="number">7.0357</span>,  <span class="number">7.0428</span>, <span class="number">7.0499</span>],</span><br><span class="line">       ..., </span><br><span class="line">       [ <span class="number">7.0499</span>,  <span class="number">7.0428</span>,  <span class="number">7.0357</span>, ...,  <span class="number">7.0286</span>,  <span class="number">7.0357</span>,  <span class="number">7.0428</span>],</span><br><span class="line">       [ <span class="number">7.0569</span>,  <span class="number">7.0499</span>,  <span class="number">7.0428</span>, ...,  <span class="number">7.0357</span>,  <span class="number">7.0428</span>,  <span class="number">7.0499</span>],</span><br><span class="line">       [ <span class="number">7.064</span> ,  <span class="number">7.0569</span>,  <span class="number">7.0499</span>, ...,  <span class="number">7.0428</span>,  <span class="number">7.0499</span>,  <span class="number">7.0569</span>]])</span><br></pre></td></tr></table></figure></p>
<p>作为第9章的先导，我用matplotlib创建了这个二维数组的可视化：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">160</span>]: <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">In [<span class="number">161</span>]: plt.imshow(z, cmap=plt.cm.gray); plt.colorbar()</span><br><span class="line">Out[<span class="number">161</span>]: &lt;matplotlib.colorbar.Colorbar at <span class="number">0x7f715e3fa630</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: plt.title(<span class="string">&quot;Image plot of $\sqrt&#123;x^2 + y^2&#125;$ for a grid of values&quot;</span>)</span><br><span class="line">Out[<span class="number">162</span>]: &lt;matplotlib.text.Text at <span class="number">0x7f715d2de748</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p>见图4-3。这张图是用matplotlib的imshow函数创建的。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-3b22000d4cd38650.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-3 根据网格对函数求值的结果"></p>
<h2><span id="将条件逻辑表述为数组运算">将条件逻辑表述为数组运算</span></h2><p>numpy.where函数是三元表达式x if condition else y的矢量化版本。假设我们有一个布尔数组和两个值数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">165</span>]: xarr = np.array([<span class="number">1.1</span>, <span class="number">1.2</span>, <span class="number">1.3</span>, <span class="number">1.4</span>, <span class="number">1.5</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">166</span>]: yarr = np.array([<span class="number">2.1</span>, <span class="number">2.2</span>, <span class="number">2.3</span>, <span class="number">2.4</span>, <span class="number">2.5</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">167</span>]: cond = np.array([<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">False</span>])</span><br></pre></td></tr></table></figure></p>
<p>假设我们想要根据cond中的值选取xarr和yarr的值：当cond中的值为True时，选取xarr的值，否则从yarr中选取。列表推导式的写法应该如下所示：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">168</span>]: result = [(x <span class="keyword">if</span> c <span class="keyword">else</span> y)</span><br><span class="line">   .....:           <span class="keyword">for</span> x, y, c <span class="keyword">in</span> <span class="built_in">zip</span>(xarr, yarr, cond)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: result</span><br><span class="line">Out[<span class="number">169</span>]: [<span class="number">1.1000000000000001</span>, <span class="number">2.2000000000000002</span>, <span class="number">1.3</span>, <span class="number">1.3999999999999999</span>, <span class="number">2.5</span>]</span><br></pre></td></tr></table></figure></p>
<p>这有几个问题。第一，它对大数组的处理速度不是很快（因为所有工作都是由纯Python完成的）。第二，无法用于多维数组。若使用np.where，则可以将该功能写得非常简洁：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">170</span>]: result = np.where(cond, xarr, yarr)</span><br><span class="line"></span><br><span class="line">In [<span class="number">171</span>]: result</span><br><span class="line">Out[<span class="number">171</span>]: array([ <span class="number">1.1</span>,  <span class="number">2.2</span>,  <span class="number">1.3</span>,  <span class="number">1.4</span>,  <span class="number">2.5</span>])</span><br></pre></td></tr></table></figure></p>
<p>np.where的第二个和第三个参数不必是数组，它们都可以是标量值。在数据分析工作中，where通常用于根据另一个数组而产生一个新的数组。假设有一个由随机数据组成的矩阵，你希望将所有正值替换为2，将所有负值替换为－2。若利用np.where，则会非常简单：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">172</span>]: arr = np.random.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">173</span>]: arr</span><br><span class="line">Out[<span class="number">173</span>]: </span><br><span class="line">array([[-<span class="number">0.5031</span>, -<span class="number">0.6223</span>, -<span class="number">0.9212</span>, -<span class="number">0.7262</span>],</span><br><span class="line">       [ <span class="number">0.2229</span>,  <span class="number">0.0513</span>, -<span class="number">1.1577</span>,  <span class="number">0.8167</span>],</span><br><span class="line">       [ <span class="number">0.4336</span>,  <span class="number">1.0107</span>,  <span class="number">1.8249</span>, -<span class="number">0.9975</span>],</span><br><span class="line">       [ <span class="number">0.8506</span>, -<span class="number">0.1316</span>,  <span class="number">0.9124</span>,  <span class="number">0.1882</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">174</span>]: arr &gt; <span class="number">0</span></span><br><span class="line">Out[<span class="number">174</span>]: </span><br><span class="line">array([[<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">       [ <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>],</span><br><span class="line">       [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">       [ <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>]], dtype=<span class="built_in">bool</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">175</span>]: np.where(arr &gt; <span class="number">0</span>, <span class="number">2</span>, -<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">175</span>]: </span><br><span class="line">array([[-<span class="number">2</span>, -<span class="number">2</span>, -<span class="number">2</span>, -<span class="number">2</span>],</span><br><span class="line">       [ <span class="number">2</span>,  <span class="number">2</span>, -<span class="number">2</span>,  <span class="number">2</span>],</span><br><span class="line">       [ <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>, -<span class="number">2</span>],</span><br><span class="line">       [ <span class="number">2</span>, -<span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>]])</span><br></pre></td></tr></table></figure></p>
<p>使用np.where，可以将标量和数组结合起来。例如，我可用常数2替换arr中所有正的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">176</span>]: np.where(arr &gt; <span class="number">0</span>, <span class="number">2</span>, arr) <span class="comment"># set only positive values to 2</span></span><br><span class="line">Out[<span class="number">176</span>]: </span><br><span class="line">array([[-<span class="number">0.5031</span>, -<span class="number">0.6223</span>, -<span class="number">0.9212</span>, -<span class="number">0.7262</span>],</span><br><span class="line">       [ <span class="number">2.</span>    ,  <span class="number">2.</span>    , -<span class="number">1.1577</span>,  <span class="number">2.</span>    ],</span><br><span class="line">       [ <span class="number">2.</span>    ,  <span class="number">2.</span>    ,  <span class="number">2.</span>    , -<span class="number">0.9975</span>],</span><br><span class="line">       [ <span class="number">2.</span>    , -<span class="number">0.1316</span>,  <span class="number">2.</span>    ,  <span class="number">2.</span>    ]])</span><br></pre></td></tr></table></figure></p>
<p>传递给where的数组大小可以不相等，甚至可以是标量值。</p>
<h2><span id="数学和统计方法">数学和统计方法</span></h2><p>可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算。sum、mean以及标准差std等聚合计算（aggregation，通常叫做约简（reduction））既可以当做数组的实例方法调用，也可以当做顶级NumPy函数使用。</p>
<p>这里，我生成了一些正态分布随机数据，然后做了聚类统计：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">177</span>]: arr = np.random.randn(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">178</span>]: arr</span><br><span class="line">Out[<span class="number">178</span>]: </span><br><span class="line">array([[ <span class="number">2.1695</span>, -<span class="number">0.1149</span>,  <span class="number">2.0037</span>,  <span class="number">0.0296</span>],</span><br><span class="line">       [ <span class="number">0.7953</span>,  <span class="number">0.1181</span>, -<span class="number">0.7485</span>,  <span class="number">0.585</span> ],</span><br><span class="line">       [ <span class="number">0.1527</span>, -<span class="number">1.5657</span>, -<span class="number">0.5625</span>, -<span class="number">0.0327</span>],</span><br><span class="line">       [-<span class="number">0.929</span> , -<span class="number">0.4826</span>, -<span class="number">0.0363</span>,  <span class="number">1.0954</span>],</span><br><span class="line">       [ <span class="number">0.9809</span>, -<span class="number">0.5895</span>,  <span class="number">1.5817</span>, -<span class="number">0.5287</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">179</span>]: arr.mean()</span><br><span class="line">Out[<span class="number">179</span>]: <span class="number">0.19607051119998253</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">180</span>]: np.mean(arr)</span><br><span class="line">Out[<span class="number">180</span>]: <span class="number">0.19607051119998253</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">181</span>]: arr.<span class="built_in">sum</span>()</span><br><span class="line">Out[<span class="number">181</span>]: <span class="number">3.9214102239996507</span></span><br></pre></td></tr></table></figure></p>
<p>mean和sum这类的函数可以接受一个axis选项参数，用于计算该轴向上的统计值，最终结果是一个少一维的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">182</span>]: arr.mean(axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">182</span>]: array([ <span class="number">1.022</span> ,  <span class="number">0.1875</span>, -<span class="number">0.502</span> , -<span class="number">0.0881</span>,  <span class="number">0.3611</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">183</span>]: arr.<span class="built_in">sum</span>(axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">183</span>]: array([ <span class="number">3.1693</span>, -<span class="number">2.6345</span>,  <span class="number">2.2381</span>,  <span class="number">1.1486</span>])</span><br></pre></td></tr></table></figure></p>
<p>这里，arr.mean(1)是“计算行的平均值”，arr.sum(0)是“计算每列的和”。</p>
<p>其他如cumsum和cumprod之类的方法则不聚合，而是产生一个由中间结果组成的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">184</span>]: arr = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">185</span>]: arr.cumsum()</span><br><span class="line">Out[<span class="number">185</span>]: array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">3</span>,  <span class="number">6</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">21</span>, <span class="number">28</span>])</span><br></pre></td></tr></table></figure></p>
<p>在多维数组中，累加函数（如cumsum）返回的是同样大小的数组，但是会根据每个低维的切片沿着标记轴计算部分聚类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">186</span>]: arr = np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">187</span>]: arr</span><br><span class="line">Out[<span class="number">187</span>]: </span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">188</span>]: arr.cumsum(axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">188</span>]: </span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">       [ <span class="number">3</span>,  <span class="number">5</span>,  <span class="number">7</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">12</span>, <span class="number">15</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">189</span>]: arr.cumprod(axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">189</span>]: </span><br><span class="line">array([[  <span class="number">0</span>,   <span class="number">0</span>,   <span class="number">0</span>],</span><br><span class="line">       [  <span class="number">3</span>,  <span class="number">12</span>,  <span class="number">60</span>],</span><br><span class="line">       [  <span class="number">6</span>,  <span class="number">42</span>, <span class="number">336</span>]])</span><br></pre></td></tr></table></figure></p>
<p>表4-5列出了全部的基本数组统计方法。后续章节中有很多例子都会用到这些方法。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-a6c6df3ca8e0b98e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-866fcde885b1d357.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h2><span id="用于布尔型数组的方法">用于布尔型数组的方法</span></h2><p>在上面这些方法中，布尔值会被强制转换为1（True）和0（False）。因此，sum经常被用来对布尔型数组中的True值计数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">190</span>]: arr = np.random.randn(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">191</span>]: (arr &gt; <span class="number">0</span>).<span class="built_in">sum</span>() <span class="comment"># Number of positive values</span></span><br><span class="line">Out[<span class="number">191</span>]: <span class="number">42</span></span><br></pre></td></tr></table></figure></p>
<p>另外还有两个方法any和all，它们对布尔型数组非常有用。any用于测试数组中是否存在一个或多个True，而all则检查数组中所有值是否都是True：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">192</span>]: bools = np.array([<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">193</span>]: bools.<span class="built_in">any</span>()</span><br><span class="line">Out[<span class="number">193</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">194</span>]: bools.<span class="built_in">all</span>()</span><br><span class="line">Out[<span class="number">194</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>这两个方法也能用于非布尔型数组，所有非0元素将会被当做True。</p>
<h2><span id="排序">排序</span></h2><p>跟Python内置的列表类型一样，NumPy数组也可以通过sort方法就地排序：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">195</span>]: arr = np.random.randn(<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">196</span>]: arr</span><br><span class="line">Out[<span class="number">196</span>]: array([ <span class="number">0.6095</span>, -<span class="number">0.4938</span>,  <span class="number">1.24</span>  , -<span class="number">0.1357</span>,  <span class="number">1.43</span>  , -<span class="number">0.8469</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">197</span>]: arr.sort()</span><br><span class="line"></span><br><span class="line">In [<span class="number">198</span>]: arr</span><br><span class="line">Out[<span class="number">198</span>]: array([-<span class="number">0.8469</span>, -<span class="number">0.4938</span>, -<span class="number">0.1357</span>,  <span class="number">0.6095</span>,  <span class="number">1.24</span>  ,  <span class="number">1.43</span>  ])</span><br></pre></td></tr></table></figure></p>
<p>多维数组可以在任何一个轴向上进行排序，只需将轴编号传给sort即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">199</span>]: arr = np.random.randn(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">200</span>]: arr</span><br><span class="line">Out[<span class="number">200</span>]: </span><br><span class="line">array([[ <span class="number">0.6033</span>,  <span class="number">1.2636</span>, -<span class="number">0.2555</span>],</span><br><span class="line">       [-<span class="number">0.4457</span>,  <span class="number">0.4684</span>, -<span class="number">0.9616</span>],</span><br><span class="line">       [-<span class="number">1.8245</span>,  <span class="number">0.6254</span>,  <span class="number">1.0229</span>],</span><br><span class="line">       [ <span class="number">1.1074</span>,  <span class="number">0.0909</span>, -<span class="number">0.3501</span>],</span><br><span class="line">       [ <span class="number">0.218</span> , -<span class="number">0.8948</span>, -<span class="number">1.7415</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">201</span>]: arr.sort(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">202</span>]: arr</span><br><span class="line">Out[<span class="number">202</span>]: </span><br><span class="line">array([[-<span class="number">0.2555</span>,  <span class="number">0.6033</span>,  <span class="number">1.2636</span>],</span><br><span class="line">       [-<span class="number">0.9616</span>, -<span class="number">0.4457</span>,  <span class="number">0.4684</span>],</span><br><span class="line">       [-<span class="number">1.8245</span>,  <span class="number">0.6254</span>,  <span class="number">1.0229</span>],</span><br><span class="line">       [-<span class="number">0.3501</span>,  <span class="number">0.0909</span>,  <span class="number">1.1074</span>],</span><br><span class="line">       [-<span class="number">1.7415</span>, -<span class="number">0.8948</span>,  <span class="number">0.218</span> ]])</span><br></pre></td></tr></table></figure></p>
<p>顶级方法np.sort返回的是数组的已排序副本，而就地排序则会修改数组本身。计算数组分位数最简单的办法是对其进行排序，然后选取特定位置的值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">203</span>]: large_arr = np.random.randn(<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">204</span>]: large_arr.sort()</span><br><span class="line"></span><br><span class="line">In [<span class="number">205</span>]: large_arr[<span class="built_in">int</span>(<span class="number">0.05</span> * <span class="built_in">len</span>(large_arr))] <span class="comment"># 5% quantile</span></span><br><span class="line">Out[<span class="number">205</span>]: -<span class="number">1.5311513550102103</span></span><br></pre></td></tr></table></figure></p>
<p>更多关于NumPy排序方法以及诸如间接排序之类的高级技术，请参阅附录A。在pandas中还可以找到一些其他跟排序有关的数据操作（比如根据一列或多列对表格型数据进行排序）。</p>
<h2><span id="唯一化以及其它的集合逻辑">唯一化以及其它的集合逻辑</span></h2><p>NumPy提供了一些针对一维ndarray的基本集合运算。最常用的可能要数np.unique了，它用于找出数组中的唯一值并返回已排序的结果：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">206</span>]: names = np.array([<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">207</span>]: np.unique(names)</span><br><span class="line">Out[<span class="number">207</span>]: </span><br><span class="line">array([<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>],</span><br><span class="line">      dtype=<span class="string">&#x27;&lt;U4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">208</span>]: ints = np.array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">209</span>]: np.unique(ints)</span><br><span class="line">Out[<span class="number">209</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<p>拿跟np.unique等价的纯Python代码来对比一下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">210</span>]: <span class="built_in">sorted</span>(<span class="built_in">set</span>(names))</span><br><span class="line">Out[<span class="number">210</span>]: [<span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Joe&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>另一个函数np.in1d用于测试一个数组中的值在另一个数组中的成员资格，返回一个布尔型数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">211</span>]: values = np.array([<span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">212</span>]: np.in1d(values, [<span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>])</span><br><span class="line">Out[<span class="number">212</span>]: array([ <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>], dtype=<span class="built_in">bool</span>)</span><br></pre></td></tr></table></figure></p>
<p>NumPy中的集合函数请参见表4-6。<br><img data-src="http://upload-images.jianshu.io/upload_images/7178691-80e85ae6b9c89ada.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h1><span id="44-用于数组的文件输入输出">4.4 用于数组的文件输入输出</span></h1><p>NumPy能够读写磁盘上的文本数据或二进制数据。这一小节只讨论NumPy的内置二进制格式，因为更多的用户会使用pandas或其它工具加载文本或表格数据（见第6章）。</p>
<p>np.save和np.load是读写磁盘数组数据的两个主要函数。默认情况下，数组是以未压缩的原始二进制格式保存在扩展名为.npy的文件中的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">213</span>]: arr = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">214</span>]: np.save(<span class="string">&#x27;some_array&#x27;</span>, arr)</span><br></pre></td></tr></table></figure></p>
<p>如果文件路径末尾没有扩展名.npy，则该扩展名会被自动加上。然后就可以通过np.load读取磁盘上的数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">215</span>]: np.load(<span class="string">&#x27;some_array.npy&#x27;</span>)</span><br><span class="line">Out[<span class="number">215</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>通过np.savez可以将多个数组保存到一个未压缩文件中，将数组以关键字参数的形式传入即可：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">216</span>]: np.savez(<span class="string">&#x27;array_archive.npz&#x27;</span>, a=arr, b=arr)</span><br></pre></td></tr></table></figure></p>
<p>加载.npz文件时，你会得到一个类似字典的对象，该对象会对各个数组进行延迟加载：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">217</span>]: arch = np.load(<span class="string">&#x27;array_archive.npz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">218</span>]: arch[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">Out[<span class="number">218</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<p>如果要将数据压缩，可以使用numpy.savez_compressed：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">219</span>]: np.savez_compressed(<span class="string">&#x27;arrays_compressed.npz&#x27;</span>, a=arr, b=arr)</span><br></pre></td></tr></table></figure></p>
<h1><span id="45-线性代数">4.5 线性代数</span></h1><p>线性代数（如矩阵乘法、矩阵分解、行列式以及其他方阵数学等）是任何数组库的重要组成部分。不像某些语言（如MATLAB），通过*对两个二维数组相乘得到的是一个元素级的积，而不是一个矩阵点积。因此，NumPy提供了一个用于矩阵乘法的dot函数（既是一个数组方法也是numpy命名空间中的一个函数）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">223</span>]: x = np.array([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">224</span>]: y = np.array([[<span class="number">6.</span>, <span class="number">23.</span>], [-<span class="number">1</span>, <span class="number">7</span>], [<span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">225</span>]: x</span><br><span class="line">Out[<span class="number">225</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">       [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">226</span>]: y</span><br><span class="line">Out[<span class="number">226</span>]: </span><br><span class="line">array([[  <span class="number">6.</span>,  <span class="number">23.</span>],</span><br><span class="line">       [ -<span class="number">1.</span>,   <span class="number">7.</span>],</span><br><span class="line">       [  <span class="number">8.</span>,   <span class="number">9.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">227</span>]: x.dot(y)</span><br><span class="line">Out[<span class="number">227</span>]: </span><br><span class="line">array([[  <span class="number">28.</span>,   <span class="number">64.</span>],</span><br><span class="line">       [  <span class="number">67.</span>,  <span class="number">181.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>x.dot(y)等价于np.dot(x, y)：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">228</span>]: np.dot(x, y)</span><br><span class="line">Out[<span class="number">228</span>]: </span><br><span class="line">array([[  <span class="number">28.</span>,   <span class="number">64.</span>],</span><br><span class="line">       [  <span class="number">67.</span>,  <span class="number">181.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>一个二维数组跟一个大小合适的一维数组的矩阵点积运算之后将会得到一个一维数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">229</span>]: np.dot(x, np.ones(<span class="number">3</span>))</span><br><span class="line">Out[<span class="number">229</span>]: array([  <span class="number">6.</span>,  <span class="number">15.</span>])</span><br></pre></td></tr></table></figure></p>
<p>@符（类似Python 3.5）也可以用作中缀运算符，进行矩阵乘法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">230</span>]: x @ np.ones(<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">230</span>]: array([  <span class="number">6.</span>,  <span class="number">15.</span>])</span><br></pre></td></tr></table></figure></p>
<p>numpy.linalg中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的东西。它们跟MATLAB和R等语言所使用的是相同的行业标准线性代数库，如BLAS、LAPACK、Intel MKL（Math Kernel Library，可能有，取决于你的NumPy版本）等：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">231</span>]: <span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> inv, qr</span><br><span class="line"></span><br><span class="line">In [<span class="number">232</span>]: X = np.random.randn(<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">233</span>]: mat = X.T.dot(X)</span><br><span class="line"></span><br><span class="line">In [<span class="number">234</span>]: inv(mat)</span><br><span class="line">Out[<span class="number">234</span>]: </span><br><span class="line">array([[  <span class="number">933.1189</span>,   <span class="number">871.8258</span>, -<span class="number">1417.6902</span>, -<span class="number">1460.4005</span>,  <span class="number">1782.1391</span>],</span><br><span class="line">       [  <span class="number">871.8258</span>,   <span class="number">815.3929</span>, -<span class="number">1325.9965</span>, -<span class="number">1365.9242</span>,  <span class="number">1666.9347</span>],</span><br><span class="line">       [-<span class="number">1417.6902</span>, -<span class="number">1325.9965</span>,  <span class="number">2158.4424</span>,  <span class="number">2222.0191</span>, -<span class="number">2711.6822</span>],</span><br><span class="line">       [-<span class="number">1460.4005</span>, -<span class="number">1365.9242</span>,  <span class="number">2222.0191</span>,  <span class="number">2289.0575</span>, -<span class="number">2793.422</span> ],</span><br><span class="line">       [ <span class="number">1782.1391</span>,  <span class="number">1666.9347</span>, -<span class="number">2711.6822</span>, -<span class="number">2793.422</span> ,  <span class="number">3409.5128</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">235</span>]: mat.dot(inv(mat))</span><br><span class="line">Out[<span class="number">235</span>]: </span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">0.</span>, -<span class="number">0.</span>, -<span class="number">0.</span>, -<span class="number">0.</span>],</span><br><span class="line">       [-<span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [-<span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>, -<span class="number">0.</span>],</span><br><span class="line">       [-<span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">236</span>]: q, r = qr(mat)</span><br><span class="line"></span><br><span class="line">In [<span class="number">237</span>]: r</span><br><span class="line">Out[<span class="number">237</span>]: </span><br><span class="line">array([[-<span class="number">1.6914</span>,  <span class="number">4.38</span>  ,  <span class="number">0.1757</span>,  <span class="number">0.4075</span>, -<span class="number">0.7838</span>],</span><br><span class="line">       [ <span class="number">0.</span>    , -<span class="number">2.6436</span>,  <span class="number">0.1939</span>, -<span class="number">3.072</span> , -<span class="number">1.0702</span>],</span><br><span class="line">       [ <span class="number">0.</span>    ,  <span class="number">0.</span>    , -<span class="number">0.8138</span>,  <span class="number">1.5414</span>,  <span class="number">0.6155</span>],</span><br><span class="line">       [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    , -<span class="number">2.6445</span>, -<span class="number">2.1669</span>],</span><br><span class="line">       [ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.0002</span>]])</span><br></pre></td></tr></table></figure></p>
<p>表达式X.T.dot(X)计算X和它的转置X.T的点积。</p>
<p>表4-7中列出了一些最常用的线性代数函数。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-dcdb66e49e5f70ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h1><span id="46-伪随机数生成">4.6 伪随机数生成</span></h1><p>numpy.random模块对Python内置的random进行了补充，增加了一些用于高效生成多种概率分布的样本值的函数。例如，你可以用normal来得到一个标准正态分布的4×4样本数组：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">238</span>]: samples = np.random.normal(size=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">239</span>]: samples</span><br><span class="line">Out[<span class="number">239</span>]: </span><br><span class="line">array([[ <span class="number">0.5732</span>,  <span class="number">0.1933</span>,  <span class="number">0.4429</span>,  <span class="number">1.2796</span>],</span><br><span class="line">       [ <span class="number">0.575</span> ,  <span class="number">0.4339</span>, -<span class="number">0.7658</span>, -<span class="number">1.237</span> ],</span><br><span class="line">       [-<span class="number">0.5367</span>,  <span class="number">1.8545</span>, -<span class="number">0.92</span>  , -<span class="number">0.1082</span>],</span><br><span class="line">       [ <span class="number">0.1525</span>,  <span class="number">0.9435</span>, -<span class="number">1.0953</span>, -<span class="number">0.144</span> ]])</span><br></pre></td></tr></table></figure></p>
<p>而Python内置的random模块则只能一次生成一个样本值。从下面的测试结果中可以看出，如果需要产生大量样本值，numpy.random快了不止一个数量级：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">240</span>]: <span class="keyword">from</span> random <span class="keyword">import</span> normalvariate</span><br><span class="line"></span><br><span class="line">In [<span class="number">241</span>]: N = <span class="number">1000000</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">242</span>]: %timeit samples = [normalvariate(<span class="number">0</span>, <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(N)]</span><br><span class="line"><span class="number">1.77</span> s +- <span class="number">126</span> ms per loop (mean +- std. dev. of <span class="number">7</span> runs, <span class="number">1</span> loop each)</span><br><span class="line"></span><br><span class="line">In [<span class="number">243</span>]: %timeit np.random.normal(size=N)</span><br><span class="line"><span class="number">61.7</span> ms +- <span class="number">1.32</span> ms per loop (mean +- std. dev. of <span class="number">7</span> runs, <span class="number">10</span> loops each)</span><br></pre></td></tr></table></figure></p>
<p>我们说这些都是伪随机数，是因为它们都是通过算法基于随机数生成器种子，在确定性的条件下生成的。你可以用NumPy的np.random.seed更改随机数生成种子：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">244</span>]: np.random.seed(<span class="number">1234</span>)</span><br></pre></td></tr></table></figure></p>
<p>numpy.random的数据生成函数使用了全局的随机种子。要避免全局状态，你可以使用numpy.random.RandomState，创建一个与其它隔离的随机数生成器：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">245</span>]: rng = np.random.RandomState(<span class="number">1234</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">246</span>]: rng.randn(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">246</span>]: </span><br><span class="line">array([ <span class="number">0.4714</span>, -<span class="number">1.191</span> ,  <span class="number">1.4327</span>, -<span class="number">0.3127</span>, -<span class="number">0.7206</span>,  <span class="number">0.8872</span>,  <span class="number">0.8596</span>,</span><br><span class="line">       -<span class="number">0.6365</span>,  <span class="number">0.0157</span>, -<span class="number">2.2427</span>])</span><br></pre></td></tr></table></figure></p>
<p>表4-8列出了numpy.random中的部分函数。在下一节中，我将给出一些利用这些函数一次性生成大量样本值的范例。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-97ba09c96dab93a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-6ed04fae3d1178e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<h1><span id="47-示例随机漫步">4.7 示例：随机漫步</span></h1><p>我们通过模拟随机漫步来说明如何运用数组运算。先来看一个简单的随机漫步的例子：从0开始，步长1和－1出现的概率相等。</p>
<p>下面是一个通过内置的random模块以纯Python的方式实现1000步的随机漫步：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">247</span>]: <span class="keyword">import</span> random</span><br><span class="line">   .....: position = <span class="number">0</span></span><br><span class="line">   .....: walk = [position]</span><br><span class="line">   .....: steps = <span class="number">1000</span></span><br><span class="line">   .....: <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(steps):</span><br><span class="line">   .....:     step = <span class="number">1</span> <span class="keyword">if</span> random.randint(<span class="number">0</span>, <span class="number">1</span>) <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">   .....:     position += step</span><br><span class="line">   .....:     walk.append(position)</span><br><span class="line">   .....:</span><br></pre></td></tr></table></figure></p>
<p>图4-4是根据前100个随机漫步值生成的折线图：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">249</span>]: plt.plot(walk[:<span class="number">100</span>])</span><br></pre></td></tr></table></figure></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-0833621694f6dda0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-4 简单的随机漫步"></p>
<p>不难看出，这其实就是随机漫步中各步的累计和，可以用一个数组运算来实现。因此，我用np.random模块一次性随机产生1000个“掷硬币”结果（即两个数中任选一个），将其分别设置为1或－1，然后计算累计和：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">251</span>]: nsteps = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">252</span>]: draws = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=nsteps)</span><br><span class="line"></span><br><span class="line">In [<span class="number">253</span>]: steps = np.where(draws &gt; <span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">254</span>]: walk = steps.cumsum()</span><br></pre></td></tr></table></figure></p>
<p>有了这些数据之后，我们就可以沿着漫步路径做一些统计工作了，比如求取最大值和最小值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">255</span>]: walk.<span class="built_in">min</span>()</span><br><span class="line">Out[<span class="number">255</span>]: -<span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">256</span>]: walk.<span class="built_in">max</span>()</span><br><span class="line">Out[<span class="number">256</span>]: <span class="number">31</span></span><br></pre></td></tr></table></figure></p>
<p>现在来看一个复杂点的统计任务——首次穿越时间，即随机漫步过程中第一次到达某个特定值的时间。假设我们想要知道本次随机漫步需要多久才能距离初始0点至少10步远（任一方向均可）。np.abs(walk)&gt;=10可以得到一个布尔型数组，它表示的是距离是否达到或超过10，而我们想要知道的是第一个10或－10的索引。可以用argmax来解决这个问题，它返回的是该布尔型数组第一个最大值的索引（True就是最大值）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">257</span>]: (np.<span class="built_in">abs</span>(walk) &gt;= <span class="number">10</span>).argmax()</span><br><span class="line">Out[<span class="number">257</span>]: <span class="number">37</span></span><br></pre></td></tr></table></figure></p>
<p>注意，这里使用argmax并不是很高效，因为它无论如何都会对数组进行完全扫描。在本例中，只要发现了一个True，那我们就知道它是个最大值了。</p>
<h2><span id="一次模拟多个随机漫步">一次模拟多个随机漫步</span></h2><p>如果你希望模拟多个随机漫步过程（比如5000个），只需对上面的代码做一点点修改即可生成所有的随机漫步过程。只要给numpy.random的函数传入一个二元元组就可以产生一个二维数组，然后我们就可以一次性计算5000个随机漫步过程（一行一个）的累计和了：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">258</span>]: nwalks = <span class="number">5000</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">259</span>]: nsteps = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">260</span>]: draws = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(nwalks, nsteps)) <span class="comment"># 0 or 1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">261</span>]: steps = np.where(draws &gt; <span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">262</span>]: walks = steps.cumsum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">263</span>]: walks</span><br><span class="line">Out[<span class="number">263</span>]: </span><br><span class="line">array([[  <span class="number">1</span>,   <span class="number">0</span>,   <span class="number">1</span>, ...,   <span class="number">8</span>,   <span class="number">7</span>,   <span class="number">8</span>],</span><br><span class="line">       [  <span class="number">1</span>,   <span class="number">0</span>,  -<span class="number">1</span>, ...,  <span class="number">34</span>,  <span class="number">33</span>,  <span class="number">32</span>],</span><br><span class="line">       [  <span class="number">1</span>,   <span class="number">0</span>,  -<span class="number">1</span>, ...,   <span class="number">4</span>,   <span class="number">5</span>,   <span class="number">4</span>],</span><br><span class="line">       ..., </span><br><span class="line">       [  <span class="number">1</span>,   <span class="number">2</span>,   <span class="number">1</span>, ...,  <span class="number">24</span>,  <span class="number">25</span>,  <span class="number">26</span>],</span><br><span class="line">       [  <span class="number">1</span>,   <span class="number">2</span>,   <span class="number">3</span>, ...,  <span class="number">14</span>,  <span class="number">13</span>,  <span class="number">14</span>],</span><br><span class="line">       [ -<span class="number">1</span>,  -<span class="number">2</span>,  -<span class="number">3</span>, ..., -<span class="number">24</span>, -<span class="number">23</span>, -<span class="number">22</span>]])</span><br></pre></td></tr></table></figure></p>
<p>现在，我们来计算所有随机漫步过程的最大值和最小值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">264</span>]: walks.<span class="built_in">max</span>()</span><br><span class="line">Out[<span class="number">264</span>]: <span class="number">138</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">265</span>]: walks.<span class="built_in">min</span>()</span><br><span class="line">Out[<span class="number">265</span>]: -<span class="number">133</span></span><br></pre></td></tr></table></figure></p>
<p>得到这些数据之后，我们来计算30或－30的最小穿越时间。这里稍微复杂些，因为不是5000个过程都到达了30。我们可以用any方法来对此进行检查：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">266</span>]: hits30 = (np.<span class="built_in">abs</span>(walks) &gt;= <span class="number">30</span>).<span class="built_in">any</span>(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">267</span>]: hits30</span><br><span class="line">Out[<span class="number">267</span>]: array([<span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>, ..., <span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>], dtype=<span class="built_in">bool</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">268</span>]: hits30.<span class="built_in">sum</span>() <span class="comment"># Number that hit 30 or -30</span></span><br><span class="line">Out[<span class="number">268</span>]: <span class="number">3410</span></span><br></pre></td></tr></table></figure></p>
<p>然后我们利用这个布尔型数组选出那些穿越了30（绝对值）的随机漫步（行），并调用argmax在轴1上获取穿越时间：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">269</span>]: crossing_times = (np.<span class="built_in">abs</span>(walks[hits30]) &gt;= <span class="number">30</span>).argmax(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">270</span>]: crossing_times.mean()</span><br><span class="line">Out[<span class="number">270</span>]: <span class="number">498.88973607038122</span></span><br></pre></td></tr></table></figure></p>
<p>请尝试用其他分布方式得到漫步数据。只需使用不同的随机数生成函数即可，如normal用于生成指定均值和标准差的正态分布数据：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">271</span>]: steps = np.random.normal(loc=<span class="number">0</span>, scale=<span class="number">0.25</span>,</span><br><span class="line">   .....:                          size=(nwalks, nsteps))</span><br></pre></td></tr></table></figure></p>
<h1><span id="48-结论">4.8 结论</span></h1><p>虽然本书剩下的章节大部分是用pandas规整数据，我们还是会用到相似的基于数组的计算。在附录A中，我们会深入挖掘NumPy的特点，进一步学习数组的技巧。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-3.Python高级语法</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-3-Python%E9%AB%98%E7%BA%A7%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>本章讨论Python的内置功能，这些功能本书会用到很多。虽然扩展库，比如pandas和Numpy，使处理大数据集很方便，但它们是和Python的内置数据处理工具一同使用的。</p>
<p>我们会从Python最基础的数据结构开始：元组、列表、字典和集合。然后会讨论创建你自己的、可重复使用的Python函数。最后，会学习Python的文件对象，以及如何与本地硬盘交互。<br><span id="more"></span></p>
<h1><span id="31-数据结构和序列">3.1 数据结构和序列</span></h1><p>Python的数据结构简单而强大。通晓它们才能成为熟练的Python程序员。</p>
<h2><span id="元组">元组</span></h2><p>元组是一个固定长度，不可改变的Python序列对象。创建元组的最简单方式，是用逗号分隔一列值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: tup = <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: tup</span><br><span class="line">Out[<span class="number">2</span>]: (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure>
<p>当用复杂的表达式定义元组，最好将值放到圆括号内，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">3</span>]: nested_tup = (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: nested_tup</span><br><span class="line">Out[<span class="number">4</span>]: ((<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>))</span><br></pre></td></tr></table></figure>
<p>用<code>tuple</code>可以将任意序列或迭代器转换成元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: <span class="built_in">tuple</span>([<span class="number">4</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">Out[<span class="number">5</span>]: (<span class="number">4</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: tup = <span class="built_in">tuple</span>(<span class="string">&#x27;string&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: tup</span><br><span class="line">Out[<span class="number">7</span>]: (<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;g&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>可以用方括号访问元组中的元素。和C、C++、JAVA等语言一样，序列是从0开始的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: tup[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">8</span>]: <span class="string">&#x27;s&#x27;</span></span><br></pre></td></tr></table></figure>
<p>元组中存储的对象可能是可变对象。一旦创建了元组，元组中的对象就不能修改了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">9</span>]: tup = <span class="built_in">tuple</span>([<span class="string">&#x27;foo&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>], <span class="literal">True</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: tup[<span class="number">2</span>] = <span class="literal">False</span></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">10</span>-c7308343b841&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> tup[<span class="number">2</span>] = <span class="literal">False</span></span><br><span class="line">TypeError: <span class="string">&#x27;tuple&#x27;</span> <span class="built_in">object</span> does <span class="keyword">not</span> support item assignment</span><br></pre></td></tr></table></figure>
<p>如果元组中的某个对象是可变的，比如列表，可以在原位进行修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">11</span>]: tup[<span class="number">1</span>].append(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: tup</span><br><span class="line">Out[<span class="number">12</span>]: (<span class="string">&#x27;foo&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>可以用加号运算符将元组串联起来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: (<span class="number">4</span>, <span class="literal">None</span>, <span class="string">&#x27;foo&#x27;</span>) + (<span class="number">6</span>, <span class="number">0</span>) + (<span class="string">&#x27;bar&#x27;</span>,)</span><br><span class="line">Out[<span class="number">13</span>]: (<span class="number">4</span>, <span class="literal">None</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="string">&#x27;bar&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>元组乘以一个整数，像列表一样，会将几个元组的复制串联起来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">14</span>]: (<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>) * <span class="number">4</span></span><br><span class="line">Out[<span class="number">14</span>]: (<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>对象本身并没有被复制，只是引用了它。</p>
<h2><span id="拆分元组">拆分元组</span></h2><p>如果你想将元组赋值给类似元组的变量，Python会试图拆分等号右边的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: tup = (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: a, b, c = tup</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: b</span><br><span class="line">Out[<span class="number">17</span>]: <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>即使含有元组的元组也会被拆分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: tup = <span class="number">4</span>, <span class="number">5</span>, (<span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: a, b, (c, d) = tup</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: d</span><br><span class="line">Out[<span class="number">20</span>]: <span class="number">7</span></span><br></pre></td></tr></table></figure>
<p>使用这个功能，你可以很容易地替换变量的名字，其它语言可能是这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tmp = a</span><br><span class="line">a = b</span><br><span class="line">b = tmp</span><br></pre></td></tr></table></figure>
<p>但是在Python中，替换可以这样做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: a, b = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: a</span><br><span class="line">Out[<span class="number">22</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: b</span><br><span class="line">Out[<span class="number">23</span>]: <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: b, a = a, b</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: a</span><br><span class="line">Out[<span class="number">25</span>]: <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: b</span><br><span class="line">Out[<span class="number">26</span>]: <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>变量拆分常用来迭代元组或列表序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: seq = [(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: <span class="keyword">for</span> a, b, c <span class="keyword">in</span> seq:</span><br><span class="line">   ....:     <span class="built_in">print</span>(<span class="string">&#x27;a=&#123;0&#125;, b=&#123;1&#125;, c=&#123;2&#125;&#x27;</span>.<span class="built_in">format</span>(a, b, c))</span><br><span class="line">a=<span class="number">1</span>, b=<span class="number">2</span>, c=<span class="number">3</span></span><br><span class="line">a=<span class="number">4</span>, b=<span class="number">5</span>, c=<span class="number">6</span></span><br><span class="line">a=<span class="number">7</span>, b=<span class="number">8</span>, c=<span class="number">9</span></span><br></pre></td></tr></table></figure>
<p>另一个常见用法是从函数返回多个值。后面会详解。</p>
<p>Python最近新增了更多高级的元组拆分功能，允许从元组的开头“摘取”几个元素。它使用了特殊的语法<code>*rest</code>，这也用在函数签名中以抓取任意长度列表的位置参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: values = <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: a, b, *rest = values</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: a, b</span><br><span class="line">Out[<span class="number">31</span>]: (<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: rest</span><br><span class="line">Out[<span class="number">32</span>]: [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p><code>rest</code>的部分是想要舍弃的部分，rest的名字不重要。作为惯用写法，许多Python程序员会将不需要的变量使用下划线：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: a, b, *_ = values</span><br></pre></td></tr></table></figure>
<h2><span id="tuple方法">tuple方法</span></h2><p>因为元组的大小和内容不能修改，它的实例方法都很轻量。其中一个很有用的就是<code>count</code>（也适用于列表），它可以统计某个值得出现频率：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: a = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: a.count(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">35</span>]: <span class="number">4</span></span><br></pre></td></tr></table></figure>
<h2><span id="列表">列表</span></h2><p>与元组对比，列表的长度可变、内容可以被修改。你可以用方括号定义，或用<code>list</code>函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">36</span>]: a_list = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="literal">None</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: tup = (<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: b_list = <span class="built_in">list</span>(tup)</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: b_list</span><br><span class="line">Out[<span class="number">39</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: b_list[<span class="number">1</span>] = <span class="string">&#x27;peekaboo&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: b_list</span><br><span class="line">Out[<span class="number">41</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;peekaboo&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>列表和元组的语义接近，在许多函数中可以交叉使用。</p>
<p><code>list</code>函数常用来在数据处理中实体化迭代器或生成器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">42</span>]: gen = <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: gen</span><br><span class="line">Out[<span class="number">43</span>]: <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: <span class="built_in">list</span>(gen)</span><br><span class="line">Out[<span class="number">44</span>]: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br></pre></td></tr></table></figure>
<h2><span id="添加和删除元素">添加和删除元素</span></h2><p>可以用<code>append</code>在列表末尾添加元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: b_list.append(<span class="string">&#x27;dwarf&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: b_list</span><br><span class="line">Out[<span class="number">46</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;peekaboo&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;dwarf&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><code>insert</code>可以在特定的位置插入元素：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: b_list.insert(<span class="number">1</span>, <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: b_list</span><br><span class="line">Out[<span class="number">48</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;peekaboo&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;dwarf&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>插入的序号必须在0和列表长度之间。</p>
<blockquote>
<p>警告：与<code>append</code>相比，<code>insert</code>耗费的计算量大，因为对后续元素的引用必须在内部迁移，以便为新元素提供空间。如果要在序列的头部和尾部插入元素，你可能需要使用<code>collections.deque</code>，一个双尾部队列。</p>
</blockquote>
<p>insert的逆运算是pop，它移除并返回指定位置的元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: b_list.pop(<span class="number">2</span>)</span><br><span class="line">Out[<span class="number">49</span>]: <span class="string">&#x27;peekaboo&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: b_list</span><br><span class="line">Out[<span class="number">50</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;dwarf&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>可以用<code>remove</code>去除某个值，<code>remove</code>会先寻找第一个值并除去：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: b_list.append(<span class="string">&#x27;foo&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: b_list</span><br><span class="line">Out[<span class="number">52</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;dwarf&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: b_list.remove(<span class="string">&#x27;foo&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: b_list</span><br><span class="line">Out[<span class="number">54</span>]: [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;dwarf&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>如果不考虑性能，使用<code>append</code>和<code>remove</code>，可以把Python的列表当做完美的“多重集”数据结构。</p>
<p>用<code>in</code>可以检查列表是否包含某个值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">55</span>]: <span class="string">&#x27;dwarf&#x27;</span> <span class="keyword">in</span> b_list</span><br><span class="line">Out[<span class="number">55</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>否定<code>in</code>可以再加一个not：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: <span class="string">&#x27;dwarf&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> b_list</span><br><span class="line">Out[<span class="number">56</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>在列表中检查是否存在某个值远比字典和集合速度慢，因为Python是线性搜索列表中的值，但在字典和集合中，在同样的时间内还可以检查其它项（基于哈希表）。</p>
<h2><span id="串联和组合列表">串联和组合列表</span></h2><p>与元组类似，可以用加号将两个列表串联起来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: [<span class="number">4</span>, <span class="literal">None</span>, <span class="string">&#x27;foo&#x27;</span>] + [<span class="number">7</span>, <span class="number">8</span>, (<span class="number">2</span>, <span class="number">3</span>)]</span><br><span class="line">Out[<span class="number">57</span>]: [<span class="number">4</span>, <span class="literal">None</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="number">7</span>, <span class="number">8</span>, (<span class="number">2</span>, <span class="number">3</span>)]</span><br></pre></td></tr></table></figure>
<p>如果已经定义了一个列表，用<code>extend</code>方法可以追加多个元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">58</span>]: x = [<span class="number">4</span>, <span class="literal">None</span>, <span class="string">&#x27;foo&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: x.extend([<span class="number">7</span>, <span class="number">8</span>, (<span class="number">2</span>, <span class="number">3</span>)])</span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: x</span><br><span class="line">Out[<span class="number">60</span>]: [<span class="number">4</span>, <span class="literal">None</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="number">7</span>, <span class="number">8</span>, (<span class="number">2</span>, <span class="number">3</span>)]</span><br></pre></td></tr></table></figure>
<p>通过加法将列表串联的计算量较大，因为要新建一个列表，并且要复制对象。用<code>extend</code>追加元素，尤其是到一个大列表中，更为可取。因此：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">everything = []</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> list_of_lists:</span><br><span class="line">    everything.extend(chunk)</span><br></pre></td></tr></table></figure>
<p>要比串联方法快：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">everything = []</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> list_of_lists:</span><br><span class="line">    everything = everything + chunk</span><br></pre></td></tr></table></figure>
<h2><span id="排序">排序</span></h2><p>你可以用<code>sort</code>函数将一个列表原地排序（不创建新的对象）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">61</span>]: a = [<span class="number">7</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: a.sort()</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: a</span><br><span class="line">Out[<span class="number">63</span>]: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>]</span><br></pre></td></tr></table></figure>
<p><code>sort</code>有一些选项，有时会很好用。其中之一是二级排序key，可以用这个key进行排序。例如，我们可以按长度对字符串进行排序：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: b = [<span class="string">&#x27;saw&#x27;</span>, <span class="string">&#x27;small&#x27;</span>, <span class="string">&#x27;He&#x27;</span>, <span class="string">&#x27;foxes&#x27;</span>, <span class="string">&#x27;six&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: b.sort(key=<span class="built_in">len</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: b</span><br><span class="line">Out[<span class="number">66</span>]: [<span class="string">&#x27;He&#x27;</span>, <span class="string">&#x27;saw&#x27;</span>, <span class="string">&#x27;six&#x27;</span>, <span class="string">&#x27;small&#x27;</span>, <span class="string">&#x27;foxes&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>稍后，我们会学习<code>sorted</code>函数，它可以产生一个排好序的序列副本。</p>
<h2><span id="二分搜索和维护已排序的列表">二分搜索和维护已排序的列表</span></h2><p><code>bisect</code>模块支持二分查找，和向已排序的列表插入值。<code>bisect.bisect</code>可以找到插入值后仍保证排序的位置，<code>bisect.insort</code>是向这个位置插入值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">67</span>]: <span class="keyword">import</span> bisect</span><br><span class="line"></span><br><span class="line">In [<span class="number">68</span>]: c = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: bisect.bisect(c, <span class="number">2</span>)</span><br><span class="line">Out[<span class="number">69</span>]: <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: bisect.bisect(c, <span class="number">5</span>)</span><br><span class="line">Out[<span class="number">70</span>]: <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: bisect.insort(c, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: c</span><br><span class="line">Out[<span class="number">72</span>]: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：<code>bisect</code>模块不会检查列表是否已排好序，进行检查的话会耗费大量计算。因此，对未排序的列表使用<code>bisect</code>不会产生错误，但结果不一定正确。</p>
</blockquote>
<h2><span id="切片">切片</span></h2><p>用切边可以选取大多数序列类型的一部分，切片的基本形式是在方括号中使用<code>start:stop</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: seq = [<span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: seq[<span class="number">1</span>:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">74</span>]: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p>切片也可以被序列赋值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: seq[<span class="number">3</span>:<span class="number">4</span>] = [<span class="number">6</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: seq</span><br><span class="line">Out[<span class="number">76</span>]: [<span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<p>切片的起始元素是包括的，不包含结束元素。因此，结果中包含的元素个数是<code>stop - start</code>。</p>
<p><code>start</code>或<code>stop</code>都可以被省略，省略之后，分别默认序列的开头和结尾：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">77</span>]: seq[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">77</span>]: [<span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: seq[<span class="number">3</span>:]</span><br><span class="line">Out[<span class="number">78</span>]: [<span class="number">6</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>负数表明从后向前切片：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">79</span>]: seq[-<span class="number">4</span>:]</span><br><span class="line">Out[<span class="number">79</span>]: [<span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: seq[-<span class="number">6</span>:-<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">80</span>]: [<span class="number">6</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br></pre></td></tr></table></figure>
<p>需要一段时间来熟悉使用切片，尤其是当你之前学的是R或MATLAB。图3-1展示了正整数和负整数的切片。在图中，指数标示在边缘以表明切片是在哪里开始哪里结束的。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-522e2b688b755ff3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图3-1 Python切片演示"></p>
<p>在第二个冒号后面使用<code>step</code>，可以隔一个取一个元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">81</span>]: seq[::<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">81</span>]: [<span class="number">7</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>一个聪明的方法是使用<code>-1</code>，它可以将列表或元组颠倒过来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: seq[::-<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">82</span>]: [<span class="number">1</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">7</span>]</span><br></pre></td></tr></table></figure>
<h2><span id="序列函数">序列函数</span></h2><p>Python有一些有用的序列函数。</p>
<h2><span id="enumerate函数">enumerate函数</span></h2><p>迭代一个序列时，你可能想跟踪当前项的序号。手动的方法可能是下面这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> collection:</span><br><span class="line">   <span class="comment"># do something with value</span></span><br><span class="line">   i += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>因为这么做很常见，Python内建了一个<code>enumerate</code>函数，可以返回<code>(i, value)</code>元组序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(collection):</span><br><span class="line">   <span class="comment"># do something with value</span></span><br></pre></td></tr></table></figure>
<p>当你索引数据时，使用<code>enumerate</code>的一个好方法是计算序列（唯一的）<code>dict</code>映射到位置的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">83</span>]: some_list = [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: mapping = &#123;&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(some_list):</span><br><span class="line">   ....:     mapping[v] = i</span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: mapping</span><br><span class="line">Out[<span class="number">86</span>]: &#123;<span class="string">&#x27;bar&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;baz&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;foo&#x27;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure>
<h2><span id="sorted函数">sorted函数</span></h2><p><code>sorted</code>函数可以从任意序列的元素返回一个新的排好序的列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: <span class="built_in">sorted</span>([<span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">Out[<span class="number">87</span>]: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: <span class="built_in">sorted</span>(<span class="string">&#x27;horse race&#x27;</span>)</span><br><span class="line">Out[<span class="number">88</span>]: [<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;s&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><code>sorted</code>函数可以接受和<code>sort</code>相同的参数。</p>
<h2><span id="zip函数">zip函数</span></h2><p><code>zip</code>可以将多个列表、元组或其它序列成对组合成一个元组列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">89</span>]: seq1 = [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;baz&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: seq2 = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">91</span>]: zipped = <span class="built_in">zip</span>(seq1, seq2)</span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: <span class="built_in">list</span>(zipped)</span><br><span class="line">Out[<span class="number">92</span>]: [(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;one&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;two&#x27;</span>), (<span class="string">&#x27;baz&#x27;</span>, <span class="string">&#x27;three&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<p><code>zip</code>可以处理任意多的序列，元素的个数取决于最短的序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">93</span>]: seq3 = [<span class="literal">False</span>, <span class="literal">True</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">94</span>]: <span class="built_in">list</span>(<span class="built_in">zip</span>(seq1, seq2, seq3))</span><br><span class="line">Out[<span class="number">94</span>]: [(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="literal">False</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="literal">True</span>)]</span><br></pre></td></tr></table></figure>
<p><code>zip</code>的常见用法之一是同时迭代多个序列，可能结合<code>enumerate</code>使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: <span class="keyword">for</span> i, (a, b) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(seq1, seq2)):</span><br><span class="line">   ....:     <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;: &#123;1&#125;, &#123;2&#125;&#x27;</span>.<span class="built_in">format</span>(i, a, b))</span><br><span class="line">   ....:</span><br><span class="line"><span class="number">0</span>: foo, one</span><br><span class="line"><span class="number">1</span>: bar, two</span><br><span class="line"><span class="number">2</span>: baz, three</span><br></pre></td></tr></table></figure>
<p>给出一个“被压缩的”序列，<code>zip</code>可以被用来解压序列。也可以当作把行的列表转换为列的列表。这个方法看起来有点神奇：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">96</span>]: pitchers = [(<span class="string">&#x27;Nolan&#x27;</span>, <span class="string">&#x27;Ryan&#x27;</span>), (<span class="string">&#x27;Roger&#x27;</span>, <span class="string">&#x27;Clemens&#x27;</span>),</span><br><span class="line">   ....:             (<span class="string">&#x27;Schilling&#x27;</span>, <span class="string">&#x27;Curt&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: first_names, last_names = <span class="built_in">zip</span>(*pitchers)</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: first_names</span><br><span class="line">Out[<span class="number">98</span>]: (<span class="string">&#x27;Nolan&#x27;</span>, <span class="string">&#x27;Roger&#x27;</span>, <span class="string">&#x27;Schilling&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: last_names</span><br><span class="line">Out[<span class="number">99</span>]: (<span class="string">&#x27;Ryan&#x27;</span>, <span class="string">&#x27;Clemens&#x27;</span>, <span class="string">&#x27;Curt&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2><span id="reversed函数">reversed函数</span></h2><p><code>reversed</code>可以从后向前迭代一个序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">100</span>]: <span class="built_in">list</span>(<span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="number">10</span>)))</span><br><span class="line">Out[<span class="number">100</span>]: [<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>要记住<code>reversed</code>是一个生成器（后面详细介绍），只有实体化（即列表或for循环）之后才能创建翻转的序列。</p>
<h2><span id="字典">字典</span></h2><p>字典可能是Python最为重要的数据结构。它更为常见的名字是哈希映射或关联数组。它是键值对的大小可变集合，键和值都是Python对象。创建字典的方法之一是使用尖括号，用冒号分隔键和值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">101</span>]: empty_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: d1 = &#123;<span class="string">&#x27;a&#x27;</span> : <span class="string">&#x27;some value&#x27;</span>, <span class="string">&#x27;b&#x27;</span> : [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: d1</span><br><span class="line">Out[<span class="number">103</span>]: &#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;some value&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;</span><br></pre></td></tr></table></figure>
<p>你可以像访问列表或元组中的元素一样，访问、插入或设定字典中的元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">104</span>]: d1[<span class="number">7</span>] = <span class="string">&#x27;an integer&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: d1</span><br><span class="line">Out[<span class="number">105</span>]: &#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;some value&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], <span class="number">7</span>: <span class="string">&#x27;an integer&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: d1[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">Out[<span class="number">106</span>]: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>你可以用检查列表和元组是否包含某个值的方法，检查字典中是否包含某个键：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">107</span>]: <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> d1</span><br><span class="line">Out[<span class="number">107</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>可以用<code>del</code>关键字或<code>pop</code>方法（返回值的同时删除键）删除值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: d1[<span class="number">5</span>] = <span class="string">&#x27;some value&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: d1</span><br><span class="line">Out[<span class="number">109</span>]: </span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;some value&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;b&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line"> <span class="number">7</span>: <span class="string">&#x27;an integer&#x27;</span>,</span><br><span class="line"> <span class="number">5</span>: <span class="string">&#x27;some value&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: d1[<span class="string">&#x27;dummy&#x27;</span>] = <span class="string">&#x27;another value&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">111</span>]: d1</span><br><span class="line">Out[<span class="number">111</span>]: </span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;some value&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;b&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line"> <span class="number">7</span>: <span class="string">&#x27;an integer&#x27;</span>,</span><br><span class="line"> <span class="number">5</span>: <span class="string">&#x27;some value&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;dummy&#x27;</span>: <span class="string">&#x27;another value&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: <span class="keyword">del</span> d1[<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: d1</span><br><span class="line">Out[<span class="number">113</span>]: </span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;some value&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;b&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line"> <span class="number">7</span>: <span class="string">&#x27;an integer&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;dummy&#x27;</span>: <span class="string">&#x27;another value&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: ret = d1.pop(<span class="string">&#x27;dummy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">115</span>]: ret</span><br><span class="line">Out[<span class="number">115</span>]: <span class="string">&#x27;another value&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: d1</span><br><span class="line">Out[<span class="number">116</span>]: &#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;some value&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], <span class="number">7</span>: <span class="string">&#x27;an integer&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p><code>keys</code>和<code>values</code>是字典的键和值的迭代器方法。虽然键值对没有顺序，这两个方法可以用相同的顺序输出键和值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: <span class="built_in">list</span>(d1.keys())</span><br><span class="line">Out[<span class="number">117</span>]: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: <span class="built_in">list</span>(d1.values())</span><br><span class="line">Out[<span class="number">118</span>]: [<span class="string">&#x27;some value&#x27;</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], <span class="string">&#x27;an integer&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>用<code>update</code>方法可以将一个字典与另一个融合：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">119</span>]: d1.update(&#123;<span class="string">&#x27;b&#x27;</span> : <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;c&#x27;</span> : <span class="number">12</span>&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">120</span>]: d1</span><br><span class="line">Out[<span class="number">120</span>]: &#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;some value&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: <span class="string">&#x27;foo&#x27;</span>, <span class="number">7</span>: <span class="string">&#x27;an integer&#x27;</span>, <span class="string">&#x27;c&#x27;</span>: <span class="number">12</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>update</code>方法是原地改变字典，因此任何传递给<code>update</code>的键的旧的值都会被舍弃。</p>
<h2><span id="用序列创建字典">用序列创建字典</span></h2><p>常常，你可能想将两个序列配对组合成字典。下面是一种写法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mapping = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> <span class="built_in">zip</span>(key_list, value_list):</span><br><span class="line">    mapping[key] = value</span><br></pre></td></tr></table></figure>
<p>因为字典本质上是2元元组的集合，dict可以接受2元元组的列表：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">121</span>]: mapping = <span class="built_in">dict</span>(<span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">5</span>), <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="number">5</span>))))</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: mapping</span><br><span class="line">Out[<span class="number">122</span>]: &#123;<span class="number">0</span>: <span class="number">4</span>, <span class="number">1</span>: <span class="number">3</span>, <span class="number">2</span>: <span class="number">2</span>, <span class="number">3</span>: <span class="number">1</span>, <span class="number">4</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>后面会谈到<code>dict comprehensions</code>，另一种构建字典的优雅方式。</p>
<h2><span id="默认值">默认值</span></h2><p>下面的逻辑很常见：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> key <span class="keyword">in</span> some_dict:</span><br><span class="line">    value = some_dict[key]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    value = default_value</span><br></pre></td></tr></table></figure>
<p>因此，dict的方法get和pop可以取默认值进行返回，上面的if-else语句可以简写成下面：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">value = some_dict.get(key, default_value)</span><br></pre></td></tr></table></figure></p>
<p>get默认会返回None，如果不存在键，pop会抛出一个例外。关于设定值，常见的情况是在字典的值是属于其它集合，如列表。例如，你可以通过首字母，将一个列表中的单词分类：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">123</span>]: words = [<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;bat&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;atom&#x27;</span>, <span class="string">&#x27;book&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: by_letter = &#123;&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">   .....:     letter = word[<span class="number">0</span>]</span><br><span class="line">   .....:     <span class="keyword">if</span> letter <span class="keyword">not</span> <span class="keyword">in</span> by_letter:</span><br><span class="line">   .....:         by_letter[letter] = [word]</span><br><span class="line">   .....:     <span class="keyword">else</span>:</span><br><span class="line">   .....:         by_letter[letter].append(word)</span><br><span class="line">   .....:</span><br><span class="line"></span><br><span class="line">In [<span class="number">126</span>]: by_letter</span><br><span class="line">Out[<span class="number">126</span>]: &#123;<span class="string">&#x27;a&#x27;</span>: [<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;atom&#x27;</span>], <span class="string">&#x27;b&#x27;</span>: [<span class="string">&#x27;bat&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;book&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>setdefault</code>方法就正是干这个的。前面的for循环可以改写为：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    letter = word[<span class="number">0</span>]</span><br><span class="line">    by_letter.setdefault(letter, []).append(word)</span><br></pre></td></tr></table></figure></p>
<p><code>collections</code>模块有一个很有用的类，<code>defaultdict</code>，它可以进一步简化上面。传递类型或函数以生成每个位置的默认值：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line">by_letter = defaultdict(<span class="built_in">list</span>)</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    by_letter[word[<span class="number">0</span>]].append(word)</span><br></pre></td></tr></table></figure></p>
<h2><span id="有效的键类型">有效的键类型</span></h2><p>字典的值可以是任意Python对象，而键通常是不可变的标量类型（整数、浮点型、字符串）或元组（元组中的对象必须是不可变的）。这被称为“可哈希性”。可以用<code>hash</code>函数检测一个对象是否是可哈希的（可被用作字典的键）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">127</span>]: <span class="built_in">hash</span>(<span class="string">&#x27;string&#x27;</span>)</span><br><span class="line">Out[<span class="number">127</span>]: <span class="number">5023931463650008331</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">128</span>]: <span class="built_in">hash</span>((<span class="number">1</span>, <span class="number">2</span>, (<span class="number">2</span>, <span class="number">3</span>)))</span><br><span class="line">Out[<span class="number">128</span>]: <span class="number">1097636502276347782</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: <span class="built_in">hash</span>((<span class="number">1</span>, <span class="number">2</span>, [<span class="number">2</span>, <span class="number">3</span>])) <span class="comment"># fails because lists are mutable</span></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">129</span>-800cd14ba8be&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> <span class="built_in">hash</span>((<span class="number">1</span>, <span class="number">2</span>, [<span class="number">2</span>, <span class="number">3</span>])) <span class="comment"># fails because lists are mutable</span></span><br><span class="line">TypeError: unhashable <span class="built_in">type</span>: <span class="string">&#x27;list&#x27;</span></span><br></pre></td></tr></table></figure>
<p>要用列表当做键，一种方法是将列表转化为元组，只要内部元素可以被哈希，它也就可以被哈希：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">130</span>]: d = &#123;&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">131</span>]: d[<span class="built_in">tuple</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])] = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: d</span><br><span class="line">Out[<span class="number">132</span>]: &#123;(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>): <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h2><span id="集合">集合</span></h2><p>集合是无序的不可重复的元素的集合。你可以把它当做字典，但是只有键没有值。可以用两种方式创建集合：通过set函数或使用尖括号set语句：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">133</span>]: <span class="built_in">set</span>([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">Out[<span class="number">133</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: &#123;<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>&#125;</span><br><span class="line">Out[<span class="number">134</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>
<p>集合支持合并、交集、差分和对称差等数学集合运算。考虑两个示例集合：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">135</span>]: a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: b = &#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;</span><br></pre></td></tr></table></figure>
<p>合并是取两个集合中不重复的元素。可以用<code>union</code>方法，或者<code>|</code>运算符：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">137</span>]: a.union(b)</span><br><span class="line">Out[<span class="number">137</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">138</span>]: a | b</span><br><span class="line">Out[<span class="number">138</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;</span><br></pre></td></tr></table></figure>
<p>交集的元素包含在两个集合中。可以用<code>intersection</code>或<code>&amp;</code>运算符：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">139</span>]: a.intersection(b)</span><br><span class="line">Out[<span class="number">139</span>]: &#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: a &amp; b</span><br><span class="line">Out[<span class="number">140</span>]: &#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>
<p>表3-1列出了常用的集合方法。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-980efe5d98ecc4d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表3-1 Python的集合操作"></p>
<p>所有逻辑集合操作都有另外的原地实现方法，可以直接用结果替代集合的内容。对于大的集合，这么做效率更高：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">141</span>]: c = a.copy()</span><br><span class="line"></span><br><span class="line">In [<span class="number">142</span>]: c |= b</span><br><span class="line"></span><br><span class="line">In [<span class="number">143</span>]: c</span><br><span class="line">Out[<span class="number">143</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">144</span>]: d = a.copy()</span><br><span class="line"></span><br><span class="line">In [<span class="number">145</span>]: d &amp;= b</span><br><span class="line"></span><br><span class="line">In [<span class="number">146</span>]: d</span><br><span class="line">Out[<span class="number">146</span>]: &#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>
<p>与字典类似，集合元素通常都是不可变的。要获得类似列表的元素，必须转换成元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">147</span>]: my_data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: my_set = &#123;<span class="built_in">tuple</span>(my_data)&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">149</span>]: my_set</span><br><span class="line">Out[<span class="number">149</span>]: &#123;(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)&#125;</span><br></pre></td></tr></table></figure>
<p>你还可以检测一个集合是否是另一个集合的子集或父集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">150</span>]: a_set = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">151</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;.issubset(a_set)</span><br><span class="line">Out[<span class="number">151</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">152</span>]: a_set.issuperset(&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;)</span><br><span class="line">Out[<span class="number">152</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>集合的内容相同时，集合才对等：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">153</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125; == &#123;<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>&#125;</span><br><span class="line">Out[<span class="number">153</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h2><span id="列表-集合和字典推导式">列表、集合和字典推导式</span></h2><p>列表推导式是Python最受喜爱的特性之一。它允许用户方便的从一个集合过滤元素，形成列表，在传递参数的过程中还可以修改元素。形式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[expr <span class="keyword">for</span> val <span class="keyword">in</span> collection <span class="keyword">if</span> condition]</span><br></pre></td></tr></table></figure>
<p>它等同于下面的for循环;</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> val <span class="keyword">in</span> collection:</span><br><span class="line">    <span class="keyword">if</span> condition:</span><br><span class="line">        result.append(expr)</span><br></pre></td></tr></table></figure>
<p>filter条件可以被忽略，只留下表达式就行。例如，给定一个字符串列表，我们可以过滤出长度在2及以下的字符串，并将其转换成大写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">154</span>]: strings = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;as&#x27;</span>, <span class="string">&#x27;bat&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;dove&#x27;</span>, <span class="string">&#x27;python&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">155</span>]: [x.upper() <span class="keyword">for</span> x <span class="keyword">in</span> strings <span class="keyword">if</span> <span class="built_in">len</span>(x) &gt; <span class="number">2</span>]</span><br><span class="line">Out[<span class="number">155</span>]: [<span class="string">&#x27;BAT&#x27;</span>, <span class="string">&#x27;CAR&#x27;</span>, <span class="string">&#x27;DOVE&#x27;</span>, <span class="string">&#x27;PYTHON&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>用相似的方法，还可以推导集合和字典。字典的推导式如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dict_comp = &#123;key-expr : value-expr <span class="keyword">for</span> value <span class="keyword">in</span> collection <span class="keyword">if</span> condition&#125;</span><br></pre></td></tr></table></figure>
<p>集合的推导式与列表很像，只不过用的是尖括号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">set_comp = &#123;expr <span class="keyword">for</span> value <span class="keyword">in</span> collection <span class="keyword">if</span> condition&#125;</span><br></pre></td></tr></table></figure>
<p>与列表推导式类似，集合与字典的推导也很方便，而且使代码的读写都很容易。来看前面的字符串列表。假如我们只想要字符串的长度，用集合推导式的方法非常方便：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">156</span>]: unique_lengths = &#123;<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> strings&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">157</span>]: unique_lengths</span><br><span class="line">Out[<span class="number">157</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>&#125;</span><br></pre></td></tr></table></figure>
<p><code>map</code>函数可以进一步简化：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">158</span>]: <span class="built_in">set</span>(<span class="built_in">map</span>(<span class="built_in">len</span>, strings))</span><br><span class="line">Out[<span class="number">158</span>]: &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>作为一个字典推导式的例子，我们可以创建一个字符串的查找映射表以确定它在列表中的位置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">159</span>]: loc_mapping = &#123;val : index <span class="keyword">for</span> index, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(strings)&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">160</span>]: loc_mapping</span><br><span class="line">Out[<span class="number">160</span>]: &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;as&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;bat&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;car&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;dove&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;python&#x27;</span>: <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>
<h2><span id="嵌套列表推导式">嵌套列表推导式</span></h2><p>假设我们有一个包含列表的列表，包含了一些英文名和西班牙名：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">161</span>]: all_data = [[<span class="string">&#x27;John&#x27;</span>, <span class="string">&#x27;Emily&#x27;</span>, <span class="string">&#x27;Michael&#x27;</span>, <span class="string">&#x27;Mary&#x27;</span>, <span class="string">&#x27;Steven&#x27;</span>],</span><br><span class="line">   .....:             [<span class="string">&#x27;Maria&#x27;</span>, <span class="string">&#x27;Juan&#x27;</span>, <span class="string">&#x27;Javier&#x27;</span>, <span class="string">&#x27;Natalia&#x27;</span>, <span class="string">&#x27;Pilar&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<p>你可能是从一些文件得到的这些名字，然后想按照语言进行分类。现在假设我们想用一个列表包含所有的名字，这些名字中包含两个或更多的e。可以用for循环来做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">names_of_interest = []</span><br><span class="line"><span class="keyword">for</span> names <span class="keyword">in</span> all_data:</span><br><span class="line">    enough_es = [name <span class="keyword">for</span> name <span class="keyword">in</span> names <span class="keyword">if</span> name.count(<span class="string">&#x27;e&#x27;</span>) &gt;= <span class="number">2</span>]</span><br><span class="line">    names_of_interest.extend(enough_es)</span><br></pre></td></tr></table></figure>
<p>可以用嵌套列表推导式的方法，将这些写在一起，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">162</span>]: result = [name <span class="keyword">for</span> names <span class="keyword">in</span> all_data <span class="keyword">for</span> name <span class="keyword">in</span> names</span><br><span class="line">   .....:           <span class="keyword">if</span> name.count(<span class="string">&#x27;e&#x27;</span>) &gt;= <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">163</span>]: result</span><br><span class="line">Out[<span class="number">163</span>]: [<span class="string">&#x27;Steven&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>嵌套列表推导式看起来有些复杂。列表推导式的for部分是根据嵌套的顺序，过滤条件还是放在最后。下面是另一个例子，我们将一个整数元组的列表扁平化成了一个整数列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">164</span>]: some_tuples = [(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">165</span>]: flattened = [x <span class="keyword">for</span> tup <span class="keyword">in</span> some_tuples <span class="keyword">for</span> x <span class="keyword">in</span> tup]</span><br><span class="line"></span><br><span class="line">In [<span class="number">166</span>]: flattened</span><br><span class="line">Out[<span class="number">166</span>]: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br></pre></td></tr></table></figure>
<p>记住，for表达式的顺序是与嵌套for循环的顺序一样（而不是列表推导式的顺序）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">flattened = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tup <span class="keyword">in</span> some_tuples:</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> tup:</span><br><span class="line">        flattened.append(x)</span><br></pre></td></tr></table></figure>
<p>你可以有任意多级别的嵌套，但是如果你有两三个以上的嵌套，你就应该考虑下代码可读性的问题了。分辨列表推导式的列表推导式中的语法也是很重要的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">167</span>]: [[x <span class="keyword">for</span> x <span class="keyword">in</span> tup] <span class="keyword">for</span> tup <span class="keyword">in</span> some_tuples]</span><br><span class="line">Out[<span class="number">167</span>]: [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]</span><br></pre></td></tr></table></figure>
<p>这段代码产生了一个列表的列表，而不是扁平化的只包含元素的列表。</p>
<h1><span id="32-函数">3.2 函数</span></h1><p>函数是Python中最主要也是最重要的代码组织和复用手段。作为最重要的原则，如果你要重复使用相同或非常类似的代码，就需要写一个函数。通过给函数起一个名字，还可以提高代码的可读性。</p>
<p>函数使用<code>def</code>关键字声明，用<code>return</code>关键字返回值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_function</span>(<span class="params">x, y, z=<span class="number">1.5</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> z &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> z * (x + y)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> z / (x + y)</span><br></pre></td></tr></table></figure>
<p>同时拥有多条return语句也是可以的。如果到达函数末尾时没有遇到任何一条return语句，则返回None。</p>
<p>函数可以有一些位置参数（positional）和一些关键字参数（keyword）。关键字参数通常用于指定默认值或可选参数。在上面的函数中，x和y是位置参数，而z则是关键字参数。也就是说，该函数可以下面这两种方式进行调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">my_function(<span class="number">5</span>, <span class="number">6</span>, z=<span class="number">0.7</span>)</span><br><span class="line">my_function(<span class="number">3.14</span>, <span class="number">7</span>, <span class="number">3.5</span>)</span><br><span class="line">my_function(<span class="number">10</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<p>函数参数的主要限制在于：关键字参数必须位于位置参数（如果有的话）之后。你可以任何顺序指定关键字参数。也就是说，你不用死记硬背函数参数的顺序，只要记得它们的名字就可以了。</p>
<blockquote>
<p>笔记：也可以用关键字传递位置参数。前面的例子，也可以写为：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;my_function(x=<span class="number">5</span>, y=<span class="number">6</span>, z=<span class="number">7</span>)</span><br><span class="line">&gt;my_function(y=<span class="number">6</span>, x=<span class="number">5</span>, z=<span class="number">7</span>)</span><br></pre></td></tr></table></figure><br>这种写法可以提高可读性。</p>
</blockquote>
<h2><span id="命名空间-作用域和局部函数">命名空间、作用域，和局部函数</span></h2><p>函数可以访问两种不同作用域中的变量：全局（global）和局部（local）。Python有一种更科学的用于描述变量作用域的名称，即命名空间（namespace）。任何在函数中赋值的变量默认都是被分配到局部命名空间（local namespace）中的。局部命名空间是在函数被调用时创建的，函数参数会立即填入该命名空间。在函数执行完毕之后，局部命名空间就会被销毁（会有一些例外的情况，具体请参见后面介绍闭包的那一节）。看看下面这个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>():</span></span><br><span class="line">    a = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        a.append(i)</span><br></pre></td></tr></table></figure>
<p>调用func()之后，首先会创建出空列表a，然后添加5个元素，最后a会在该函数退出的时候被销毁。假如我们像下面这样定义a：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        a.append(i)</span><br></pre></td></tr></table></figure>
<p>虽然可以在函数中对全局变量进行赋值操作，但是那些变量必须用global关键字声明成全局的才行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">168</span>]: a = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: <span class="function"><span class="keyword">def</span> <span class="title">bind_a_variable</span>():</span></span><br><span class="line">   .....:     <span class="keyword">global</span> a</span><br><span class="line">   .....:     a = []</span><br><span class="line">   .....: bind_a_variable()</span><br><span class="line">   .....:</span><br><span class="line"></span><br><span class="line">In [<span class="number">170</span>]: <span class="built_in">print</span>(a)</span><br><span class="line">[]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：我常常建议人们不要频繁使用global关键字。因为全局变量一般是用于存放系统的某些状态的。如果你发现自己用了很多，那可能就说明得要来点儿面向对象编程了（即使用类）。</p>
</blockquote>
<h2><span id="返回多个值">返回多个值</span></h2><p>在我第一次用Python编程时（之前已经习惯了Java和C++），最喜欢的一个功能是：函数可以返回多个值。下面是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>():</span></span><br><span class="line">    a = <span class="number">5</span></span><br><span class="line">    b = <span class="number">6</span></span><br><span class="line">    c = <span class="number">7</span></span><br><span class="line">    <span class="keyword">return</span> a, b, c</span><br><span class="line"></span><br><span class="line">a, b, c = f()</span><br></pre></td></tr></table></figure>
<p>在数据分析和其他科学计算应用中，你会发现自己常常这么干。该函数其实只返回了一个对象，也就是一个元组，最后该元组会被拆包到各个结果变量中。在上面的例子中，我们还可以这样写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">return_value = f()</span><br></pre></td></tr></table></figure>
<p>这里的return_value将会是一个含有3个返回值的三元元组。此外，还有一种非常具有吸引力的多值返回方式——返回字典：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>():</span></span><br><span class="line">    a = <span class="number">5</span></span><br><span class="line">    b = <span class="number">6</span></span><br><span class="line">    c = <span class="number">7</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;a&#x27;</span> : a, <span class="string">&#x27;b&#x27;</span> : b, <span class="string">&#x27;c&#x27;</span> : c&#125;</span><br></pre></td></tr></table></figure>
<p>取决于工作内容，第二种方法可能很有用。</p>
<h2><span id="函数也是对象">函数也是对象</span></h2><p>由于Python函数都是对象，因此，在其他语言中较难表达的一些设计思想在Python中就要简单很多了。假设我们有下面这样一个字符串数组，希望对其进行一些数据清理工作并执行一堆转换：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">171</span>]: states = [<span class="string">&#x27;   Alabama &#x27;</span>, <span class="string">&#x27;Georgia!&#x27;</span>, <span class="string">&#x27;Georgia&#x27;</span>, <span class="string">&#x27;georgia&#x27;</span>, <span class="string">&#x27;FlOrIda&#x27;</span>,</span><br><span class="line">   .....:           <span class="string">&#x27;south   carolina##&#x27;</span>, <span class="string">&#x27;West virginia?&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>不管是谁，只要处理过由用户提交的调查数据，就能明白这种乱七八糟的数据是怎么一回事。为了得到一组能用于分析工作的格式统一的字符串，需要做很多事情：去除空白符、删除各种标点符号、正确的大写格式等。做法之一是使用内建的字符串方法和正则表达式<code>re</code>模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_strings</span>(<span class="params">strings</span>):</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> strings:</span><br><span class="line">        value = value.strip()</span><br><span class="line">        value = re.sub(<span class="string">&#x27;[!#?]&#x27;</span>, <span class="string">&#x27;&#x27;</span>, value)</span><br><span class="line">        value = value.title()</span><br><span class="line">        result.append(value)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>结果如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">173</span>]: clean_strings(states)</span><br><span class="line">Out[<span class="number">173</span>]: </span><br><span class="line">[<span class="string">&#x27;Alabama&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Georgia&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Georgia&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Georgia&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Florida&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;South   Carolina&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;West Virginia&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>其实还有另外一种不错的办法：将需要在一组给定字符串上执行的所有运算做成一个列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_punctuation</span>(<span class="params">value</span>):</span></span><br><span class="line">    <span class="keyword">return</span> re.sub(<span class="string">&#x27;[!#?]&#x27;</span>, <span class="string">&#x27;&#x27;</span>, value)</span><br><span class="line"></span><br><span class="line">clean_ops = [<span class="built_in">str</span>.strip, remove_punctuation, <span class="built_in">str</span>.title]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_strings</span>(<span class="params">strings, ops</span>):</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> strings:</span><br><span class="line">        <span class="keyword">for</span> function <span class="keyword">in</span> ops:</span><br><span class="line">            value = function(value)</span><br><span class="line">        result.append(value)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>然后我们就有了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">175</span>]: clean_strings(states, clean_ops)</span><br><span class="line">Out[<span class="number">175</span>]: </span><br><span class="line">[<span class="string">&#x27;Alabama&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Georgia&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Georgia&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Georgia&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Florida&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;South   Carolina&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;West Virginia&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>这种多函数模式使你能在很高的层次上轻松修改字符串的转换方式。此时的clean_strings也更具可复用性！</p>
<p>还可以将函数用作其他函数的参数，比如内置的map函数，它用于在一组数据上应用一个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">176</span>]: <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">map</span>(remove_punctuation, states):</span><br><span class="line">   .....:     <span class="built_in">print</span>(x)</span><br><span class="line">Alabama </span><br><span class="line">Georgia</span><br><span class="line">Georgia</span><br><span class="line">georgia</span><br><span class="line">FlOrIda</span><br><span class="line">south   carolina</span><br><span class="line">West virginia</span><br></pre></td></tr></table></figure>
<h2><span id="匿名lambda函数">匿名（lambda）函数</span></h2><p>Python支持一种被称为匿名的、或lambda函数。它仅由单条语句组成，该语句的结果就是返回值。它是通过lambda关键字定义的，这个关键字没有别的含义，仅仅是说“我们正在声明的是一个匿名函数”。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">short_function</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">equiv_anon = <span class="keyword">lambda</span> x: x * <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>本书其余部分一般将其称为lambda函数。它们在数据分析工作中非常方便，因为你会发现很多数据转换函数都以函数作为参数的。直接传入lambda函数比编写完整函数声明要少输入很多字（也更清晰），甚至比将lambda函数赋值给一个变量还要少输入很多字。看看下面这个简单得有些傻的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply_to_list</span>(<span class="params">some_list, f</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [f(x) <span class="keyword">for</span> x <span class="keyword">in</span> some_list]</span><br><span class="line"></span><br><span class="line">ints = [<span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">apply_to_list(ints, <span class="keyword">lambda</span> x: x * <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>虽然你可以直接编写[x *2for x in ints]，但是这里我们可以非常轻松地传入一个自定义运算给apply_to_list函数。</p>
<p>再来看另外一个例子。假设有一组字符串，你想要根据各字符串不同字母的数量对其进行排序：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">177</span>]: strings = [<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;card&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;aaaa&#x27;</span>, <span class="string">&#x27;abab&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>这里，我们可以传入一个lambda函数到列表的sort方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">178</span>]: strings.sort(key=<span class="keyword">lambda</span> x: <span class="built_in">len</span>(<span class="built_in">set</span>(<span class="built_in">list</span>(x))))</span><br><span class="line"></span><br><span class="line">In [<span class="number">179</span>]: strings</span><br><span class="line">Out[<span class="number">179</span>]: [<span class="string">&#x27;aaaa&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;abab&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;card&#x27;</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>笔记：lambda函数之所以会被称为匿名函数，与def声明的函数不同，原因之一就是这种函数对象本身是没有提供名称<strong>name</strong>属性。</p>
</blockquote>
<h2><span id="柯里化部分参数应用">柯里化：部分参数应用</span></h2><p>柯里化（currying）是一个有趣的计算机科学术语，它指的是通过“部分参数应用”（partial argument application）从现有函数派生出新函数的技术。例如，假设我们有一个执行两数相加的简单函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_numbers</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x + y</span><br></pre></td></tr></table></figure>
<p>通过这个函数，我们可以派生出一个新的只有一个参数的函数——add_five，它用于对其参数加5：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">add_five = <span class="keyword">lambda</span> y: add_numbers(<span class="number">5</span>, y)</span><br></pre></td></tr></table></figure>
<p>add_numbers的第二个参数称为“柯里化的”（curried）。这里没什么特别花哨的东西，因为我们其实就只是定义了一个可以调用现有函数的新函数而已。内置的functools模块可以用partial函数将此过程简化：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line">add_five = partial(add_numbers, <span class="number">5</span>)</span><br></pre></td></tr></table></figure></p>
<h2><span id="生成器">生成器</span></h2><p>能以一种一致的方式对序列进行迭代（比如列表中的对象或文件中的行）是Python的一个重要特点。这是通过一种叫做迭代器协议（iterator protocol，它是一种使对象可迭代的通用方式）的方式实现的，一个原生的使对象可迭代的方法。比如说，对字典进行迭代可以得到其所有的键：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">180</span>]: some_dict = &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;c&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">181</span>]: <span class="keyword">for</span> key <span class="keyword">in</span> some_dict:</span><br><span class="line">   .....:     <span class="built_in">print</span>(key)</span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line">c</span><br></pre></td></tr></table></figure>
<p>当你编写for key in some_dict时，Python解释器首先会尝试从some_dict创建一个迭代器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">182</span>]: dict_iterator = <span class="built_in">iter</span>(some_dict)</span><br><span class="line"></span><br><span class="line">In [<span class="number">183</span>]: dict_iterator</span><br><span class="line">Out[<span class="number">183</span>]: &lt;dict_keyiterator at <span class="number">0x7fbbd5a9f908</span>&gt;</span><br></pre></td></tr></table></figure>
<p>迭代器是一种特殊对象，它可以在诸如for循环之类的上下文中向Python解释器输送对象。大部分能接受列表之类的对象的方法也都可以接受任何可迭代对象。比如min、max、sum等内置方法以及list、tuple等类型构造器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">184</span>]: <span class="built_in">list</span>(dict_iterator)</span><br><span class="line">Out[<span class="number">184</span>]: [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>生成器（generator）是构造新的可迭代对象的一种简单方式。一般的函数执行之后只会返回单个值，而生成器则是以延迟的方式返回一个值序列，即每返回一个值之后暂停，直到下一个值被请求时再继续。要创建一个生成器，只需将函数中的return替换为yeild即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squares</span>(<span class="params">n=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Generating squares from 1 to &#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(n ** <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">yield</span> i ** <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>调用该生成器时，没有任何代码会被立即执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">186</span>]: gen = squares()</span><br><span class="line"></span><br><span class="line">In [<span class="number">187</span>]: gen</span><br><span class="line">Out[<span class="number">187</span>]: &lt;generator <span class="built_in">object</span> squares at <span class="number">0x7fbbd5ab4570</span>&gt;</span><br></pre></td></tr></table></figure>
<p>直到你从该生成器中请求元素时，它才会开始执行其代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">188</span>]: <span class="keyword">for</span> x <span class="keyword">in</span> gen:</span><br><span class="line">   .....:     <span class="built_in">print</span>(x, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">Generating squares <span class="keyword">from</span> <span class="number">1</span> to <span class="number">100</span></span><br><span class="line"><span class="number">1</span> <span class="number">4</span> <span class="number">9</span> <span class="number">16</span> <span class="number">25</span> <span class="number">36</span> <span class="number">49</span> <span class="number">64</span> <span class="number">81</span> <span class="number">100</span></span><br></pre></td></tr></table></figure></p>
<h2><span id="生成器表达式">生成器表达式</span></h2><p>另一种更简洁的构造生成器的方法是使用生成器表达式（generator expression）。这是一种类似于列表、字典、集合推导式的生成器。其创建方式为，把列表推导式两端的方括号改成圆括号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">189</span>]: gen = (x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">190</span>]: gen</span><br><span class="line">Out[<span class="number">190</span>]: &lt;generator <span class="built_in">object</span> &lt;genexpr&gt; at <span class="number">0x7fbbd5ab29e8</span>&gt;</span><br></pre></td></tr></table></figure>
<p>它跟下面这个冗长得多的生成器是完全等价的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_gen</span>():</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">yield</span> x ** <span class="number">2</span></span><br><span class="line">gen = _make_gen()</span><br></pre></td></tr></table></figure>
<p>生成器表达式也可以取代列表推导式，作为函数参数：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">191</span>]: <span class="built_in">sum</span>(x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>))</span><br><span class="line">Out[<span class="number">191</span>]: <span class="number">328350</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">192</span>]: <span class="built_in">dict</span>((i, i **<span class="number">2</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>))</span><br><span class="line">Out[<span class="number">192</span>]: &#123;<span class="number">0</span>: <span class="number">0</span>, <span class="number">1</span>: <span class="number">1</span>, <span class="number">2</span>: <span class="number">4</span>, <span class="number">3</span>: <span class="number">9</span>, <span class="number">4</span>: <span class="number">16</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h2><span id="itertools模块">itertools模块</span></h2><p>标准库itertools模块中有一组用于许多常见数据算法的生成器。例如，groupby可以接受任何序列和一个函数。它根据函数的返回值对序列中的连续元素进行分组。下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">193</span>]: <span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line">In [<span class="number">194</span>]: first_letter = <span class="keyword">lambda</span> x: x[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">195</span>]: names = [<span class="string">&#x27;Alan&#x27;</span>, <span class="string">&#x27;Adam&#x27;</span>, <span class="string">&#x27;Wes&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>, <span class="string">&#x27;Albert&#x27;</span>, <span class="string">&#x27;Steven&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">196</span>]: <span class="keyword">for</span> letter, names <span class="keyword">in</span> itertools.groupby(names, first_letter):</span><br><span class="line">   .....:     <span class="built_in">print</span>(letter, <span class="built_in">list</span>(names)) <span class="comment"># names is a generator</span></span><br><span class="line">A [<span class="string">&#x27;Alan&#x27;</span>, <span class="string">&#x27;Adam&#x27;</span>]</span><br><span class="line">W [<span class="string">&#x27;Wes&#x27;</span>, <span class="string">&#x27;Will&#x27;</span>]</span><br><span class="line">A [<span class="string">&#x27;Albert&#x27;</span>]</span><br><span class="line">S [<span class="string">&#x27;Steven&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>表3-2中列出了一些我经常用到的itertools函数。建议参阅Python官方文档，进一步学习。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-111823d8767a104d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表3-2 一些有用的itertools函数"></p>
<h2><span id="错误和异常处理">错误和异常处理</span></h2><p>优雅地处理Python的错误和异常是构建健壮程序的重要部分。在数据分析中，许多函数函数只用于部分输入。例如，Python的float函数可以将字符串转换成浮点数，但输入有误时，有<code>ValueError</code>错误：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">197</span>]: <span class="built_in">float</span>(<span class="string">&#x27;1.2345&#x27;</span>)</span><br><span class="line">Out[<span class="number">197</span>]: <span class="number">1.2345</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">198</span>]: <span class="built_in">float</span>(<span class="string">&#x27;something&#x27;</span>)</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">ValueError                                Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">198</span>-<span class="number">439904410854</span>&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> <span class="built_in">float</span>(<span class="string">&#x27;something&#x27;</span>)</span><br><span class="line">ValueError: could <span class="keyword">not</span> convert string to <span class="built_in">float</span>: <span class="string">&#x27;something&#x27;</span></span><br></pre></td></tr></table></figure>
<p>假如想优雅地处理float的错误，让它返回输入值。我们可以写一个函数，在try/except中调用float：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attempt_float</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">float</span>(x)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>当float(x)抛出异常时，才会执行except的部分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">200</span>]: attempt_float(<span class="string">&#x27;1.2345&#x27;</span>)</span><br><span class="line">Out[<span class="number">200</span>]: <span class="number">1.2345</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">201</span>]: attempt_float(<span class="string">&#x27;something&#x27;</span>)</span><br><span class="line">Out[<span class="number">201</span>]: <span class="string">&#x27;something&#x27;</span></span><br></pre></td></tr></table></figure>
<p>你可能注意到float抛出的异常不仅是ValueError：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">202</span>]: <span class="built_in">float</span>((<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">202</span>-842079ebb635&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> <span class="built_in">float</span>((<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">TypeError: <span class="built_in">float</span>() argument must be a string <span class="keyword">or</span> a number, <span class="keyword">not</span> <span class="string">&#x27;tuple&#x27;</span></span><br></pre></td></tr></table></figure>
<p>你可能只想处理ValueError，TypeError错误（输入不是字符串或数值）可能是合理的bug。可以写一个异常类型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attempt_float</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">float</span>(x)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>然后有：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">204</span>]: attempt_float((<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">204</span>-9bdfd730cead&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> attempt_float((<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">203</span>-3e06b8379b6b&gt; <span class="keyword">in</span> attempt_float(x)</span><br><span class="line">      <span class="number">1</span> <span class="function"><span class="keyword">def</span> <span class="title">attempt_float</span>(<span class="params">x</span>):</span></span><br><span class="line">      <span class="number">2</span>     <span class="keyword">try</span>:</span><br><span class="line">----&gt; <span class="number">3</span>         <span class="keyword">return</span> <span class="built_in">float</span>(x)</span><br><span class="line">      <span class="number">4</span>     <span class="keyword">except</span> ValueError:</span><br><span class="line">      <span class="number">5</span>         <span class="keyword">return</span> x</span><br><span class="line">TypeError: <span class="built_in">float</span>() argument must be a string <span class="keyword">or</span> a number, <span class="keyword">not</span> <span class="string">&#x27;tuple&#x27;</span></span><br></pre></td></tr></table></figure>
<p>可以用元组包含多个异常：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attempt_float</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">float</span>(x)</span><br><span class="line">    <span class="keyword">except</span> (TypeError, ValueError):</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>某些情况下，你可能不想抑制异常，你想无论try部分的代码是否成功，都执行一段代码。可以使用finally：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f = <span class="built_in">open</span>(path, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    write_to_file(f)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>
<p>这里，文件处理f总会被关闭。相似的，你可以用else让只在try部分成功的情况下，才执行代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f = <span class="built_in">open</span>(path, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    write_to_file(f)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Failed&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Succeeded&#x27;</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>
<h2><span id="ipython的异常">IPython的异常</span></h2><p>如果是在%run一个脚本或一条语句时抛出异常，IPython默认会打印完整的调用栈（traceback），在栈的每个点都会有几行上下文：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: %run examples/ipython_bug.py</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AssertionError                            Traceback (most recent call last)</span><br><span class="line">/home/wesm/code/pydata-book/examples/ipython_bug.py <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">     <span class="number">13</span>     throws_an_exception()</span><br><span class="line">     <span class="number">14</span></span><br><span class="line">---&gt; <span class="number">15</span> calling_things()</span><br><span class="line"></span><br><span class="line">/home/wesm/code/pydata-book/examples/ipython_bug.py <span class="keyword">in</span> calling_things()</span><br><span class="line">     <span class="number">11</span> <span class="function"><span class="keyword">def</span> <span class="title">calling_things</span>():</span></span><br><span class="line">     <span class="number">12</span>     works_fine()</span><br><span class="line">---&gt; <span class="number">13</span>     throws_an_exception()</span><br><span class="line">     <span class="number">14</span></span><br><span class="line">     <span class="number">15</span> calling_things()</span><br><span class="line"></span><br><span class="line">/home/wesm/code/pydata-book/examples/ipython_bug.py <span class="keyword">in</span> throws_an_exception()</span><br><span class="line">      <span class="number">7</span>     a = <span class="number">5</span></span><br><span class="line">      <span class="number">8</span>     b = <span class="number">6</span></span><br><span class="line">----&gt; <span class="number">9</span>     <span class="keyword">assert</span>(a + b == <span class="number">10</span>)</span><br><span class="line">     <span class="number">10</span></span><br><span class="line">     <span class="number">11</span> <span class="function"><span class="keyword">def</span> <span class="title">calling_things</span>():</span></span><br><span class="line"></span><br><span class="line">AssertionError:</span><br></pre></td></tr></table></figure>
<p>自身就带有文本是相对于Python标准解释器的极大优点。你可以用魔术命令<code>%xmode</code>，从Plain（与Python标准解释器相同）到Verbose（带有函数的参数值）控制文本显示的数量。后面可以看到，发生错误之后，（用%debug或%pdb magics）可以进入stack进行事后调试。</p>
<h1><span id="33-文件和操作系统">3.3 文件和操作系统</span></h1><p>本书的代码示例大多使用诸如pandas.read_csv之类的高级工具将磁盘上的数据文件读入Python数据结构。但我们还是需要了解一些有关Python文件处理方面的基础知识。好在它本来就很简单，这也是Python在文本和文件处理方面的如此流行的原因之一。</p>
<p>为了打开一个文件以便读写，可以使用内置的open函数以及一个相对或绝对的文件路径：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">207</span>]: path = <span class="string">&#x27;examples/segismundo.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">208</span>]: f = <span class="built_in">open</span>(path)</span><br></pre></td></tr></table></figure>
<p>默认情况下，文件是以只读模式（’r’）打开的。然后，我们就可以像处理列表那样来处理这个文件句柄f了，比如对行进行迭代：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>从文件中取出的行都带有完整的行结束符（EOL），因此你常常会看到下面这样的代码（得到一组没有EOL的行）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">209</span>]: lines = [x.rstrip() <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">open</span>(path)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">210</span>]: lines</span><br><span class="line">Out[<span class="number">210</span>]: </span><br><span class="line">[<span class="string">&#x27;Sueña el rico en su riqueza,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;que más cuidados le ofrece;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el pobre que padece&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;su miseria y su pobreza;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el que a medrar empieza,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el que afana y pretende,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el que agravia y ofende,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;y en el mundo, en conclusión,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;todos sueñan lo que son,&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;aunque ninguno lo entiende.&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>如果使用open创建文件对象，一定要用close关闭它。关闭文件可以返回操作系统资源：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">211</span>]: f.close()</span><br></pre></td></tr></table></figure>
<p>用with语句可以可以更容易地清理打开的文件：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">212</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(path) <span class="keyword">as</span> f:</span><br><span class="line">   .....:     lines = [x.rstrip() <span class="keyword">for</span> x <span class="keyword">in</span> f]</span><br></pre></td></tr></table></figure></p>
<p>这样可以在退出代码块时，自动关闭文件。</p>
<p>如果输入f =open(path,’w’)，就会有一个新文件被创建在examples/segismundo.txt，并覆盖掉该位置原来的任何数据。另外有一个x文件模式，它可以创建可写的文件，但是如果文件路径存在，就无法创建。表3-3列出了所有的读/写模式。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-28274484129f0ea7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表3-3 Python的文件模式"></p>
<p>对于可读文件，一些常用的方法是read、seek和tell。read会从文件返回字符。字符的内容是由文件的编码决定的（如UTF-8），如果是二进制模式打开的就是原始字节：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">213</span>]: f = <span class="built_in">open</span>(path)</span><br><span class="line"></span><br><span class="line">In [<span class="number">214</span>]: f.read(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">214</span>]: <span class="string">&#x27;Sueña el r&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">215</span>]: f2 = <span class="built_in">open</span>(path, <span class="string">&#x27;rb&#x27;</span>)  <span class="comment"># Binary mode</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">216</span>]: f2.read(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">216</span>]: <span class="string">b&#x27;Sue\xc3\xb1a el &#x27;</span></span><br></pre></td></tr></table></figure>
<p>read模式会将文件句柄的位置提前，提前的数量是读取的字节数。tell可以给出当前的位置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">217</span>]: f.tell()</span><br><span class="line">Out[<span class="number">217</span>]: <span class="number">11</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">218</span>]: f2.tell()</span><br><span class="line">Out[<span class="number">218</span>]: <span class="number">10</span></span><br></pre></td></tr></table></figure>
<p>尽管我们从文件读取了10个字符，位置却是11，这是因为用默认的编码用了这么多字节才解码了这10个字符。你可以用sys模块检查默认的编码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">219</span>]: <span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">In [<span class="number">220</span>]: sys.getdefaultencoding()</span><br><span class="line">Out[<span class="number">220</span>]: <span class="string">&#x27;utf-8&#x27;</span></span><br></pre></td></tr></table></figure>
<p>seek将文件位置更改为文件中的指定字节：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">221</span>]: f.seek(<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">221</span>]: <span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">222</span>]: f.read(<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">222</span>]: <span class="string">&#x27;ñ&#x27;</span></span><br></pre></td></tr></table></figure>
<p>最后，关闭文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">223</span>]: f.close()</span><br><span class="line"></span><br><span class="line">In [<span class="number">224</span>]: f2.close()</span><br></pre></td></tr></table></figure>
<p>向文件写入，可以使用文件的write或writelines方法。例如，我们可以创建一个无空行版的prof_mod.py：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">225</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;tmp.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> handle:</span><br><span class="line">   .....:     handle.writelines(x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">open</span>(path) <span class="keyword">if</span> <span class="built_in">len</span>(x) &gt; <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">226</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;tmp.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">   .....:     lines = f.readlines()</span><br><span class="line"></span><br><span class="line">In [<span class="number">227</span>]: lines</span><br><span class="line">Out[<span class="number">227</span>]: </span><br><span class="line">[<span class="string">&#x27;Sueña el rico en su riqueza,\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;que más cuidados le ofrece;\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el pobre que padece\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;su miseria y su pobreza;\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el que a medrar empieza,\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el que afana y pretende,\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;sueña el que agravia y ofende,\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;y en el mundo, en conclusión,\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;todos sueñan lo que son,\n&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;aunque ninguno lo entiende.\n&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>表3-4列出了一些最常用的文件方法。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-d25bd6e730afeb39.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表3-4 Python重要的文件方法或属性"></p>
<h2><span id="文件的字节和unicode">文件的字节和Unicode</span></h2><p>Python文件的默认操作是“文本模式”，也就是说，你需要处理Python的字符串（即Unicode）。它与“二进制模式”相对，文件模式加一个b。我们来看上一节的文件（UTF-8编码、包含非ASCII字符）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">230</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(path) <span class="keyword">as</span> f:</span><br><span class="line">   .....:     chars = f.read(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">231</span>]: chars</span><br><span class="line">Out[<span class="number">231</span>]: <span class="string">&#x27;Sueña el r&#x27;</span></span><br></pre></td></tr></table></figure>
<p>UTF-8是长度可变的Unicode编码，所以当我从文件请求一定数量的字符时，Python会从文件读取足够多（可能少至10或多至40字节）的字节进行解码。如果以“rb”模式打开文件，则读取确切的请求字节数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">232</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">   .....:     data = f.read(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">233</span>]: data</span><br><span class="line">Out[<span class="number">233</span>]: <span class="string">b&#x27;Sue\xc3\xb1a el &#x27;</span></span><br></pre></td></tr></table></figure>
<p>取决于文本的编码，你可以将字节解码为str对象，但只有当每个编码的Unicode字符都完全成形时才能这么做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">234</span>]: data.decode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">Out[<span class="number">234</span>]: <span class="string">&#x27;Sueña el &#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">235</span>]: data[:<span class="number">4</span>].decode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">UnicodeDecodeError                        Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">235</span>-300e0af10bb7&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> data[:<span class="number">4</span>].decode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">UnicodeDecodeError: <span class="string">&#x27;utf-8&#x27;</span> codec can<span class="string">&#x27;t decode byte 0xc3 in position 3: unexpecte</span></span><br><span class="line"><span class="string">d end of data</span></span><br></pre></td></tr></table></figure>
<p>文本模式结合了open的编码选项，提供了一种更方便的方法将Unicode转换为另一种编码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">236</span>]: sink_path = <span class="string">&#x27;sink.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">237</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(path) <span class="keyword">as</span> source:</span><br><span class="line">   .....:     <span class="keyword">with</span> <span class="built_in">open</span>(sink_path, <span class="string">&#x27;xt&#x27;</span>, encoding=<span class="string">&#x27;iso-8859-1&#x27;</span>) <span class="keyword">as</span> sink:</span><br><span class="line">   .....:         sink.write(source.read())</span><br><span class="line"></span><br><span class="line">In [<span class="number">238</span>]: <span class="keyword">with</span> <span class="built_in">open</span>(sink_path, encoding=<span class="string">&#x27;iso-8859-1&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">   .....:     <span class="built_in">print</span>(f.read(<span class="number">10</span>))</span><br><span class="line">Sueña el r</span><br></pre></td></tr></table></figure>
<p>注意，不要在二进制模式中使用seek。如果文件位置位于定义Unicode字符的字节的中间位置，读取后面会产生错误：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">240</span>]: f = <span class="built_in">open</span>(path)</span><br><span class="line"></span><br><span class="line">In [<span class="number">241</span>]: f.read(<span class="number">5</span>)</span><br><span class="line">Out[<span class="number">241</span>]: <span class="string">&#x27;Sueña&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">242</span>]: f.seek(<span class="number">4</span>)</span><br><span class="line">Out[<span class="number">242</span>]: <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">243</span>]: f.read(<span class="number">1</span>)</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">UnicodeDecodeError                        Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">243</span>-7841103e33f5&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> f.read(<span class="number">1</span>)</span><br><span class="line">/miniconda/envs/book-env/lib/python3<span class="number">.6</span>/codecs.py <span class="keyword">in</span> decode(self, <span class="built_in">input</span>, final)</span><br><span class="line">    <span class="number">319</span>         <span class="comment"># decode input (taking the buffer into account)</span></span><br><span class="line">    <span class="number">320</span>         data = self.buffer + <span class="built_in">input</span></span><br><span class="line">--&gt; <span class="number">321</span>         (result, consumed) = self._buffer_decode(data, self.errors, final</span><br><span class="line">)</span><br><span class="line">    <span class="number">322</span>         <span class="comment"># keep undecoded input until the next call</span></span><br><span class="line">    <span class="number">323</span>         self.buffer = data[consumed:]</span><br><span class="line">UnicodeDecodeError: <span class="string">&#x27;utf-8&#x27;</span> codec can<span class="string">&#x27;t decode byte 0xb1 in position 0: invalid s</span></span><br><span class="line"><span class="string">tart byte</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [244]: f.close()</span></span><br></pre></td></tr></table></figure>
<p>如果你经常要对非ASCII字符文本进行数据分析，通晓Python的Unicode功能是非常重要的。更多内容，参阅Python官方文档。</p>
<h1><span id="34-结论">3.4 结论</span></h1><p>我们已经学过了Python的基础、环境和语法，接下来学习NumPy和Python的面向数组计算。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>利用python进行数据分析-2.Python语法基础，IPython和Jupyter</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-2-IPython%E5%92%8CJupyter/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="第2章-python语法基础ipython和jupyter-notebooks">第2章 Python语法基础，IPython和Jupyter Notebooks</span></h1><p>当我在2011年和2012年写作本书的第一版时，可用的学习Python数据分析的资源很少。这部分上是一个鸡和蛋的问题：我们现在使用的库，比如pandas、scikit-learn和statsmodels，那时相对来说并不成熟。2017年，数据科学、数据分析和机器学习的资源已经很多，原来通用的科学计算拓展到了计算机科学家、物理学家和其它研究领域的工作人员。学习Python和成为软件工程师的优秀书籍也有了。</p>
<span id="more"></span>
<p>因为这本书是专注于Python数据处理的，对于一些Python的数据结构和库的特性难免不足。因此，本章和第3章的内容只够你能学习本书后面的内容。</p>
<p>在我来看，没有必要为了数据分析而去精通Python。我鼓励你使用IPython shell和Jupyter试验示例代码，并学习不同类型、函数和方法的文档。虽然我已尽力让本书内容循序渐进，但读者偶尔仍会碰到没有之前介绍过的内容。</p>
<p>本书大部分内容关注的是基于表格的分析和处理大规模数据集的数据准备工具。为了使用这些工具，必须首先将混乱的数据规整为整洁的表格（或结构化）形式。幸好，Python是一个理想的语言，可以快速整理数据。Python使用得越熟练，越容易准备新数据集以进行分析。</p>
<p>最好在IPython和Jupyter中亲自尝试本书中使用的工具。当你学会了如何启动Ipython和Jupyter，我建议你跟随示例代码进行练习。与任何键盘驱动的操作环境一样，记住常见的命令也是学习曲线的一部分。</p>
<blockquote>
<p>笔记：本章没有介绍Python的某些概念，如类和面向对象编程，你可能会发现它们在Python数据分析中很有用。 为了加强Python知识，我建议你学习官方Python教程，<a href="https://docs.python.org/3/，或是通用的Python教程书籍，比如：">https://docs.python.org/3/，或是通用的Python教程书籍，比如：</a></p>
<ul>
<li>Python Cookbook，第3版，David Beazley和Brian K. Jones著（O’Reilly）</li>
<li>流畅的Python，Luciano Ramalho著 (O’Reilly)</li>
<li>高效的Python，Brett Slatkin著 (Pearson)</li>
</ul>
</blockquote>
<h2><span id="21-python解释器">2.1 Python解释器</span></h2><p>Python是解释性语言。Python解释器同一时间只能运行一个程序的一条语句。标准的交互Python解释器可以在命令行中通过键入<code>python</code>命令打开：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ python</span><br><span class="line">Python 3.6.0 | packaged by conda-forge | (default, Jan 13 2017, 23:17:12)</span><br><span class="line">[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt; a = 5</span><br><span class="line">&gt;&gt;&gt; print(a)</span><br><span class="line">5</span><br></pre></td></tr></table></figure>
<p><code>&gt;&gt;&gt;</code>提示输入代码。要退出Python解释器返回终端，可以输入<code>exit()</code>或按Ctrl-D。</p>
<p>运行Python程序只需调用Python的同时，使用一个<code>.py</code>文件作为它的第一个参数。假设创建了一个<code>hello_world.py</code>文件，它的内容是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hello world&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>你可以用下面的命令运行它（<code>hello_world.py</code>文件必须位于终端的工作目录）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python hello_world.py</span><br><span class="line">Hello world</span><br></pre></td></tr></table></figure>
<p>一些Python程序员总是这样执行Python代码的，从事数据分析和科学计算的人却会使用IPython，一个强化的Python解释器，或Jupyter notebooks，一个网页代码笔记本，它原先是IPython的一个子项目。在本章中，我介绍了如何使用IPython和Jupyter，在附录A中有更深入的介绍。当你使用<code>%run</code>命令，IPython会同样执行指定文件中的代码，结束之后，还可以与结果交互：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ipython</span><br><span class="line">Python 3.6.0 | packaged by conda-forge | (default, Jan 13 2017, 23:17:12)</span><br><span class="line">Type &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line"></span><br><span class="line">IPython 5.1.0 -- An enhanced Interactive Python.</span><br><span class="line">?         -&gt; Introduction and overview of IPython&#x27;s features.</span><br><span class="line">%quickref -&gt; Quick reference.</span><br><span class="line">help      -&gt; Python&#x27;s own help system.</span><br><span class="line">object?   -&gt; Details about &#x27;object&#x27;, use &#x27;object??&#x27; for extra details.</span><br><span class="line"></span><br><span class="line">In [1]: %run hello_world.py</span><br><span class="line">Hello world</span><br><span class="line"></span><br><span class="line">In [2]:</span><br></pre></td></tr></table></figure>
<p>IPython默认采用序号的格式<code>In [2]:</code>，与标准的<code>&gt;&gt;&gt;</code>提示符不同。</p>
<h2><span id="22-ipython基础">2.2 IPython基础</span></h2><p>在本节中，我们会教你打开运行IPython shell和jupyter notebook，并介绍一些基本概念。</p>
<h3><span id="运行ipython-shell">运行IPython Shell</span></h3><p>你可以用<code>ipython</code>在命令行打开IPython Shell，就像打开普通的Python解释器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ipython</span><br><span class="line">Python 3.6.0 | packaged by conda-forge | (default, Jan 13 2017, 23:17:12)</span><br><span class="line">Type &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line"></span><br><span class="line">IPython 5.1.0 -- An enhanced Interactive Python.</span><br><span class="line">?         -&gt; Introduction and overview of IPython&#x27;s features.</span><br><span class="line">%quickref -&gt; Quick reference.</span><br><span class="line">help      -&gt; Python&#x27;s own help system.</span><br><span class="line">object?   -&gt; Details about &#x27;object&#x27;, use &#x27;object??&#x27; for extra details.</span><br><span class="line"></span><br><span class="line">In [1]: a = 5</span><br><span class="line">In [2]: a</span><br><span class="line">Out[2]: 5</span><br></pre></td></tr></table></figure>
<p>你可以通过输入代码并按Return（或Enter），运行任意Python语句。当你只输入一个变量，它会显示代表的对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: data = &#123;i : np.random.randn() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>)&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: data</span><br><span class="line">Out[<span class="number">7</span>]: </span><br><span class="line">&#123;<span class="number">0</span>: -<span class="number">0.20470765948471295</span>,</span><br><span class="line"> <span class="number">1</span>: <span class="number">0.47894333805754824</span>,</span><br><span class="line"> <span class="number">2</span>: -<span class="number">0.5194387150567381</span>,</span><br><span class="line"> <span class="number">3</span>: -<span class="number">0.55573030434749</span>,</span><br><span class="line"> <span class="number">4</span>: <span class="number">1.9657805725027142</span>,</span><br><span class="line"> <span class="number">5</span>: <span class="number">1.3934058329729904</span>,</span><br><span class="line"><span class="number">6</span>: <span class="number">0.09290787674371767</span>&#125;</span><br></pre></td></tr></table></figure>
<p>前两行是Python代码语句；第二条语句创建一个名为<code>data</code>的变量，它引用一个新创建的Python字典。最后一行打印<code>data</code>的值。</p>
<p>许多Python对象被格式化为更易读的形式，或称作<code>pretty-printed</code>，它与普通的<code>print</code>不同。如果在标准Python解释器中打印上述<code>data</code>变量，则可读性要降低：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; from numpy.random import randn</span><br><span class="line">&gt;&gt;&gt; data = &#123;i : randn() for i in range(7)&#125;</span><br><span class="line">&gt;&gt;&gt; print(data)</span><br><span class="line">&#123;0: -1.5948255432744511, 1: 0.10569006472787983, 2: 1.972367135977295,</span><br><span class="line">3: 0.15455217573074576, 4: -0.24058577449429575, 5: -1.2904897053651216,</span><br><span class="line">6: 0.3308507317325902&#125;</span><br></pre></td></tr></table></figure>
<p>IPython还支持执行任意代码块（通过一个华丽的复制-粘贴方法）和整段Python脚本的功能。你也可以使用Jupyter notebook运行大代码块，接下来就会看到。</p>
<h3><span id="运行jupyter-notebook">运行Jupyter Notebook</span></h3><p>notebook是Jupyter项目的重要组件之一，它是一个代码、文本（有标记或无标记）、数据可视化或其它输出的交互式文档。Jupyter Notebook需要与内核互动，内核是Jupyter与其它编程语言的交互编程协议。Python的Jupyter内核是使用IPython。要启动Jupyter，在命令行中输入<code>jupyter notebook</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ jupyter notebook</span><br><span class="line">[I 15:20:52.739 NotebookApp] Serving notebooks from local directory:</span><br><span class="line">/home/wesm/code/pydata-book</span><br><span class="line">[I 15:20:52.739 NotebookApp] 0 active kernels</span><br><span class="line">[I 15:20:52.739 NotebookApp] The Jupyter Notebook is running at:</span><br><span class="line">http://localhost:8888/</span><br><span class="line">[I 15:20:52.740 NotebookApp] Use Control-C to stop this server and shut down</span><br><span class="line">all kernels (twice to skip confirmation).</span><br><span class="line">Created new window in existing browser session.</span><br></pre></td></tr></table></figure>
<p>在多数平台上，Jupyter会自动打开默认的浏览器（除非指定了<code>--no-browser</code>）。或者，可以在启动notebook之后，手动打开网页<code>http://localhost:8888/</code>。图2-1展示了Google Chrome中的notebook。</p>
<blockquote>
<p>笔记：许多人使用Jupyter作为本地的计算环境，但它也可以部署到服务器上远程访问。这里不做介绍，如果需要的话，鼓励读者自行到网上学习。</p>
</blockquote>
<p>要新建一个notebook，点击按钮New，选择“Python3”或“conda[默认项]”。如果是第一次，点击空格，输入一行Python代码。然后按Shift-Enter执行。</p>
<p>当保存notebook时（File目录下的Save and Checkpoint），会创建一个后缀名为<code>.ipynb</code>的文件。这是一个自包含文件格式，包含当前笔记本中的所有内容（包括所有已评估的代码输出）。可以被其它Jupyter用户加载和编辑。要加载存在的notebook，把它放到启动notebook进程的相同目录内。你可以用本书的示例代码练习，见图2-3。</p>
<p>虽然Jupyter notebook和IPython shell使用起来不同，本章中几乎所有的命令和工具都可以通用。</p>
<h3><span id="tab补全">Tab补全</span></h3><p>从外观上，IPython shell和标准的Python解释器只是看起来不同。IPython shell的进步之一是具备其它IDE和交互计算分析环境都有的tab补全功能。在shell中输入表达式，按下Tab，会搜索已输入变量（对象、函数等等）的命名空间：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [1]: an_apple = 27</span><br><span class="line"></span><br><span class="line">In [2]: an_example = 42</span><br><span class="line"></span><br><span class="line">In [3]: an&lt;Tab&gt;</span><br><span class="line">an_apple    and         an_example  any</span><br></pre></td></tr></table></figure>
<p>在这个例子中，IPython呈现出了之前两个定义的变量和Python的关键字和内建的函数<code>any</code>。当然，你也可以补全任何对象的方法和属性：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [3]: b = [1, 2, 3]</span><br><span class="line"></span><br><span class="line">In [4]: b.&lt;Tab&gt;</span><br><span class="line">b.append  b.count   b.insert  b.reverse</span><br><span class="line">b.clear   b.extend  b.pop     b.sort</span><br><span class="line">b.copy    b.index   b.remove</span><br></pre></td></tr></table></figure>
<p>同样也适用于模块：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [1]: import datetime</span><br><span class="line"></span><br><span class="line">In [2]: datetime.&lt;Tab&gt;</span><br><span class="line">datetime.date          datetime.MAXYEAR       datetime.timedelta</span><br><span class="line">datetime.datetime      datetime.MINYEAR       datetime.timezone</span><br><span class="line">datetime.datetime_CAPI datetime.time          datetime.tzinfo</span><br></pre></td></tr></table></figure>
<p>在Jupyter notebook和新版的IPython（5.0及以上），自动补全功能是下拉框的形式。</p>
<blockquote>
<p>笔记：注意，默认情况下，IPython会隐藏下划线开头的方法和属性，比如魔术方法和内部的“私有”方法和属性，以避免混乱的显示（和让新手迷惑！）这些也可以tab补全，但是你必须首先键入一个下划线才能看到它们。如果你喜欢总是在tab补全中看到这样的方法，你可以IPython配置中进行设置。可以在IPython文档中查找方法。</p>
</blockquote>
<p>除了补全命名、对象和模块属性，Tab还可以补全其它的。当输入看似文件路径时（即使是Python字符串），按下Tab也可以补全电脑上对应的文件信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [7]: datasets/movielens/&lt;Tab&gt;</span><br><span class="line">datasets/movielens/movies.dat    datasets/movielens/README</span><br><span class="line">datasets/movielens/ratings.dat   datasets/movielens/users.dat</span><br><span class="line"></span><br><span class="line">In [7]: path = &#x27;datasets/movielens/&lt;Tab&gt;</span><br><span class="line">datasets/movielens/movies.dat    datasets/movielens/README</span><br><span class="line">datasets/movielens/ratings.dat   datasets/movielens/users.dat</span><br></pre></td></tr></table></figure>
<p>结合<code>%run</code>，tab补全可以节省许多键盘操作。</p>
<p>另外，tab补全可以补全函数的关键词参数（包括等于号=）。见图2-4。</p>
<p>后面会仔细地学习函数。</p>
<h3><span id="自省">自省</span></h3><p>在变量前后使用问号？，可以显示对象的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: b = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: b?</span><br><span class="line"><span class="type">Type</span>:       <span class="built_in">list</span></span><br><span class="line">String Form:[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">Length:     <span class="number">3</span></span><br><span class="line">Docstring:</span><br><span class="line"><span class="built_in">list</span>() -&gt; new empty <span class="built_in">list</span></span><br><span class="line"><span class="built_in">list</span>(iterable) -&gt; new <span class="built_in">list</span> initialized <span class="keyword">from</span> iterable<span class="string">&#x27;s items</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [10]: print?</span></span><br><span class="line"><span class="string">Docstring:</span></span><br><span class="line"><span class="string">print(value, ..., sep=&#x27;</span> <span class="string">&#x27;, end=&#x27;</span>\n<span class="string">&#x27;, file=sys.stdout, flush=False)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Prints the values to a stream, or to sys.stdout by default.</span></span><br><span class="line"><span class="string">Optional keyword arguments:</span></span><br><span class="line"><span class="string">file:  a file-like object (stream); defaults to the current sys.stdout.</span></span><br><span class="line"><span class="string">sep:   string inserted between values, default a space.</span></span><br><span class="line"><span class="string">end:   string appended after the last value, default a newline.</span></span><br><span class="line"><span class="string">flush: whether to forcibly flush the stream.</span></span><br><span class="line"><span class="string">Type:      builtin_function_or_method</span></span><br></pre></td></tr></table></figure>
<p>这可以作为对象的自省。如果对象是一个函数或实例方法，定义过的文档字符串，也会显示出信息。假设我们写了一个如下的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_numbers</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Add two numbers together</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    the_sum : type of arguments</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br></pre></td></tr></table></figure>
<p>然后使用?符号，就可以显示如下的文档字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">11</span>]: add_numbers?</span><br><span class="line">Signature: add_numbers(a, b)</span><br><span class="line">Docstring:</span><br><span class="line">Add two numbers together</span><br><span class="line"></span><br><span class="line">Returns</span><br><span class="line">-------</span><br><span class="line">the_sum : <span class="built_in">type</span> of arguments</span><br><span class="line">File:      &lt;ipython-<span class="built_in">input</span>-<span class="number">9</span>-6a548a216e27&gt;</span><br><span class="line"><span class="type">Type</span>:      function</span><br></pre></td></tr></table></figure>
<p>使用??会显示函数的源码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: add_numbers??</span><br><span class="line">Signature: add_numbers(a, b)</span><br><span class="line">Source:</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_numbers</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Add two numbers together</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    the_sum : type of arguments</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line">File:      &lt;ipython-<span class="built_in">input</span>-<span class="number">9</span>-6a548a216e27&gt;</span><br><span class="line"><span class="type">Type</span>:      function</span><br></pre></td></tr></table></figure>
<p>?还有一个用途，就是像Unix或Windows命令行一样搜索IPython的命名空间。字符与通配符结合可以匹配所有的名字。例如，我们可以获得所有包含load的顶级NumPy命名空间：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: np.*load*?</span><br><span class="line">np.__loader__</span><br><span class="line">np.load</span><br><span class="line">np.loads</span><br><span class="line">np.loadtxt</span><br><span class="line">np.pkgload</span><br></pre></td></tr></table></figure>
<h3><span id="run命令">%run命令</span></h3><p>你可以用<code>%run</code>命令运行所有的Python程序。假设有一个文件<code>ipython_script_test.py</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x, y, z</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (x + y) / z</span><br><span class="line"></span><br><span class="line">a = <span class="number">5</span></span><br><span class="line">b = <span class="number">6</span></span><br><span class="line">c = <span class="number">7.5</span></span><br><span class="line"></span><br><span class="line">result = f(a, b, c)</span><br></pre></td></tr></table></figure>
<p>可以如下运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">14</span>]: %run ipython_script_test.py</span><br></pre></td></tr></table></figure>
<p>这段脚本运行在空的命名空间（没有import和其它定义的变量），因此结果和普通的运行方式<code>python script.py</code>相同。文件中所有定义的变量（import、函数和全局变量，除非抛出异常），都可以在IPython shell中随后访问：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: c</span><br><span class="line">Out [<span class="number">15</span>]: <span class="number">7.5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: result</span><br><span class="line">Out[<span class="number">16</span>]: <span class="number">1.4666666666666666</span></span><br></pre></td></tr></table></figure>
<p>如果一个Python脚本需要命令行参数（在<code>sys.argv</code>中查找），可以在文件路径之后传递，就像在命令行上运行一样。</p>
<blockquote>
<p>笔记：如果想让一个脚本访问IPython已经定义过的变量，可以使用<code>%run -i</code>。</p>
</blockquote>
<p>在Jupyter notebook中，你也可以使用<code>%load</code>，它将脚本导入到一个代码格中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; %load ipython_script_test.py</span><br><span class="line"></span><br><span class="line">    def f(x, y, z):</span><br><span class="line">        return (x + y) / z</span><br><span class="line">    a = 5</span><br><span class="line">    b = 6</span><br><span class="line">    c = 7.5</span><br><span class="line"></span><br><span class="line">    result = f(a, b, c)</span><br></pre></td></tr></table></figure>
<h3><span id="中断运行的代码">中断运行的代码</span></h3><p>代码运行时按Ctrl-C，无论是%run或长时间运行命令，都会导致<code>KeyboardInterrupt</code>。这会导致几乎所有Python程序立即停止，除非一些特殊情况。</p>
<blockquote>
<p>警告：当Python代码调用了一些编译的扩展模块，按Ctrl-C不一定将执行的程序立即停止。在这种情况下，你必须等待，直到控制返回Python解释器，或者在更糟糕的情况下强制终止Python进程。</p>
</blockquote>
<h3><span id="从剪贴板执行程序">从剪贴板执行程序</span></h3><p>如果使用Jupyter notebook，你可以将代码复制粘贴到任意代码格执行。在IPython shell中也可以从剪贴板执行。假设在其它应用中复制了如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="number">5</span></span><br><span class="line">y = <span class="number">7</span></span><br><span class="line"><span class="keyword">if</span> x &gt; <span class="number">5</span>:</span><br><span class="line">    x += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    y = <span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>最简单的方法是使用<code>%paste</code>和<code>%cpaste</code>函数。<code>%paste</code>可以直接运行剪贴板中的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: %paste</span><br><span class="line">x = <span class="number">5</span></span><br><span class="line">y = <span class="number">7</span></span><br><span class="line"><span class="keyword">if</span> x &gt; <span class="number">5</span>:</span><br><span class="line">    x += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    y = <span class="number">8</span></span><br><span class="line"><span class="comment">## -- End pasted text --</span></span><br></pre></td></tr></table></figure>
<p><code>%cpaste</code>功能类似，但会给出一条提示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: %cpaste</span><br><span class="line">Pasting code; enter <span class="string">&#x27;--&#x27;</span> alone on the line to stop <span class="keyword">or</span> use Ctrl-D.</span><br><span class="line">:x = <span class="number">5</span></span><br><span class="line">:y = <span class="number">7</span></span><br><span class="line">:<span class="keyword">if</span> x &gt; <span class="number">5</span>:</span><br><span class="line">:    x += <span class="number">1</span></span><br><span class="line">:</span><br><span class="line">:    y = <span class="number">8</span></span><br><span class="line">:--</span><br></pre></td></tr></table></figure>
<p>使用<code>%cpaste</code>，你可以粘贴任意多的代码再运行。你可能想在运行前，先看看代码。如果粘贴了错误的代码，可以用Ctrl-C中断。</p>
<h3><span id="键盘快捷键">键盘快捷键</span></h3><p>IPython有许多键盘快捷键进行导航提示（类似Emacs文本编辑器或UNIX bash Shell）和交互shell的历史命令。表2-1总结了常见的快捷键。图2-5展示了一部分，如移动光标。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-9ed3866ea25c11f8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x56FE;2-5 IPython shell&#x4E2D;&#x4E00;&#x4E9B;&#x5FEB;&#x6377;&#x952E;&#x7684;&#x8BF4;&#x660E;"></p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-e179f5ea00e50691.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x8868;2-1 IPython&#x7684;&#x6807;&#x51C6;&#x5FEB;&#x6377;&#x952E;"></p>
<p>Jupyter notebooks有另外一套庞大的快捷键。因为它的快捷键比IPython的变化快，建议你参阅Jupyter notebook的帮助文档。</p>
<h3><span id="魔术命令">魔术命令</span></h3><p>IPython中特殊的命令（Python中没有）被称作“魔术”命令。这些命令可以使普通任务更便捷，更容易控制IPython系统。魔术命令是在指令前添加百分号%前缀。例如，可以用<code>%timeit</code>（这个命令后面会详谈）测量任何Python语句，例如矩阵乘法，的执行时间：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">20</span>]: a = np.random.randn(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: %timeit np.dot(a, a)</span><br><span class="line"><span class="number">10000</span> loops, best of <span class="number">3</span>: <span class="number">20.9</span> µs per loop</span><br></pre></td></tr></table></figure>
<p>魔术命令可以被看做IPython中运行的命令行。许多魔术命令有“命令行”选项，可以通过？查看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [21]: %debug?</span><br><span class="line">Docstring:</span><br><span class="line">::</span><br><span class="line"></span><br><span class="line">  %debug [--breakpoint FILE:LINE] [statement [statement ...]]</span><br><span class="line"></span><br><span class="line">Activate the interactive debugger.</span><br><span class="line"></span><br><span class="line">This magic command support two ways of activating debugger.</span><br><span class="line">One is to activate debugger before executing code.  This way, you</span><br><span class="line">can set a break point, to step through the code from the point.</span><br><span class="line">You can use this mode by giving statements to execute and optionally</span><br><span class="line">a breakpoint.</span><br><span class="line"></span><br><span class="line">The other one is to activate debugger in post-mortem mode.  You can</span><br><span class="line">activate this mode simply running %debug without any argument.</span><br><span class="line">If an exception has just occurred, this lets you inspect its stack</span><br><span class="line">frames interactively.  Note that this will always work only on the last</span><br><span class="line">traceback that occurred, so you must call this quickly after an</span><br><span class="line">exception that you wish to inspect has fired, because if another one</span><br><span class="line">occurs, it clobbers the previous one.</span><br><span class="line"></span><br><span class="line">If you want IPython to automatically do this on every exception, see</span><br><span class="line">the %pdb magic for more details.</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  statement             Code to run in debugger. You can omit this in cell</span><br><span class="line">                        magic mode.</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  --breakpoint &lt;FILE:LINE&gt;, -b &lt;FILE:LINE&gt;</span><br><span class="line">                        Set break point at LINE in FILE.</span><br></pre></td></tr></table></figure>
<p>魔术函数默认可以不用百分号，只要没有变量和函数名相同。这个特点被称为“自动魔术”，可以用<code>%automagic</code>打开或关闭。</p>
<p>一些魔术函数与Python函数很像，它的结果可以赋值给一个变量：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [22]: %pwd</span><br><span class="line">Out[22]: &#x27;/home/wesm/code/pydata-book</span><br><span class="line"></span><br><span class="line">In [23]: foo = %pwd</span><br><span class="line"></span><br><span class="line">In [24]: foo</span><br><span class="line">Out[24]: &#x27;/home/wesm/code/pydata-book&#x27;</span><br></pre></td></tr></table></figure>
<p>IPython的文档可以在shell中打开，我建议你用<code>%quickref</code>或<code>%magic</code>学习下所有特殊命令。表2-2列出了一些可以提高生产率的交互计算和Python开发的IPython指令。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-c72b11add9b8ccf8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x8868;2-2 &#x4E00;&#x4E9B;&#x5E38;&#x7528;&#x7684;IPython&#x9B54;&#x672F;&#x547D;&#x4EE4;"></p>
<h3><span id="集成matplotlib">集成Matplotlib</span></h3><p>IPython在分析计算领域能够流行的原因之一是它非常好的集成了数据可视化和其它用户界面库，比如matplotlib。不用担心以前没用过matplotlib，本书后面会详细介绍。<code>%matplotlib</code>魔术函数配置了IPython shell和Jupyter notebook中的matplotlib。这点很重要，其它创建的图不会出现（notebook）或获取session的控制，直到结束（shell）。</p>
<p>在IPython shell中，运行<code>%matplotlib</code>可以进行设置，可以创建多个绘图窗口，而不会干扰控制台session：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [26]: %matplotlib</span><br><span class="line">Using matplotlib backend: Qt4Agg</span><br></pre></td></tr></table></figure>
<p>在JUpyter中，命令有所不同（图2-6）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [26]: %matplotlib inline</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-3ab3738a92a15486.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x56FE;2-6 Jupyter&#x884C;&#x5185;matplotlib&#x4F5C;&#x56FE;"></p>
<h2><span id="23-python语法基础">2.3 Python语法基础</span></h2><p>在本节中，我将概述基本的Python概念和语言机制。在下一章，我将详细介绍Python的数据结构、函数和其它内建工具。</p>
<h3><span id="语言的语义">语言的语义</span></h3><p>Python的语言设计强调的是可读性、简洁和清晰。有些人称Python为“可执行的伪代码”。</p>
<h3><span id="使用缩进而不是括号">使用缩进，而不是括号</span></h3><p>Python使用空白字符（tab和空格）来组织代码，而不是像其它语言，比如R、C++、JAVA和Perl那样使用括号。看一个排序算法的<code>for</code>循环：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> array:</span><br><span class="line">    <span class="keyword">if</span> x &lt; pivot:</span><br><span class="line">        less.append(x)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        greater.append(x)</span><br></pre></td></tr></table></figure>
<p>冒号标志着缩进代码块的开始，冒号之后的所有代码的缩进量必须相同，直到代码块结束。不管是否喜欢这种形式，使用空白符是Python程序员开发的一部分，在我看来，这可以让python的代码可读性大大优于其它语言。虽然期初看起来很奇怪，经过一段时间，你就能适应了。</p>
<blockquote>
<p>笔记：我强烈建议你使用四个空格作为默认的缩进，可以使用tab代替四个空格。许多文本编辑器的设置是使用制表位替代空格。某些人使用tabs或不同数目的空格数，常见的是使用两个空格。大多数情况下，四个空格是大多数人采用的方法，因此建议你也这样做。</p>
</blockquote>
<p>你应该已经看到，Python的语句不需要用分号结尾。但是，分号却可以用来给同在一行的语句切分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">5</span>; b = <span class="number">6</span>; c = <span class="number">7</span></span><br></pre></td></tr></table></figure>
<p>Python不建议将多条语句放到一行，这会降低代码的可读性。</p>
<h3><span id="万物皆对象">万物皆对象</span></h3><p>Python语言的一个重要特性就是它的对象模型的一致性。每个数字、字符串、数据结构、函数、类、模块等等，都是在Python解释器的自有“盒子”内，它被认为是Python对象。每个对象都有类型（例如，字符串或函数）和内部数据。在实际中，这可以让语言非常灵活，因为函数也可以被当做对象使用。</p>
<h3><span id="注释">注释</span></h3><p>任何前面带有井号#的文本都会被Python解释器忽略。这通常被用来添加注释。有时，你会想排除一段代码，但并不删除。简便的方法就是将其注释掉：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> file_handle:</span><br><span class="line">    <span class="comment"># keep the empty lines for now</span></span><br><span class="line">    <span class="comment"># if len(line) == 0:</span></span><br><span class="line">    <span class="comment">#   continue</span></span><br><span class="line">    results.append(line.replace(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;bar&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>也可以在执行过的代码后面添加注释。一些人习惯在代码之前添加注释，前者这种方法有时也是有用的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Reached this line&quot;</span>)  <span class="comment"># Simple status report</span></span><br></pre></td></tr></table></figure>
<h3><span id="函数和对象方法调用">函数和对象方法调用</span></h3><p>你可以用圆括号调用函数，传递零个或几个参数，或者将返回值给一个变量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = f(x, y, z)</span><br><span class="line">g()</span><br></pre></td></tr></table></figure>
<p>几乎Python中的每个对象都有附加的函数，称作方法，可以用来访问对象的内容。可以用下面的语句调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj.some_method(x, y, z)</span><br></pre></td></tr></table></figure>
<p>函数可以使用位置和关键词参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = f(a, b, c, d=<span class="number">5</span>, e=<span class="string">&#x27;foo&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>后面会有更多介绍。</p>
<h3><span id="变量和参数传递">变量和参数传递</span></h3><p>当在Python中创建变量（或名字），你就在等号右边创建了一个对这个变量的引用。考虑一个整数列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p>假设将a赋值给一个新变量b：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">9</span>]: b = a</span><br></pre></td></tr></table></figure>
<p>在有些方法中，这个赋值会将数据[1, 2, 3]也复制。在Python中，a和b实际上是同一个对象，即原有列表[1, 2, 3]（见图2-7）。你可以在a中添加一个元素，然后检查b：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: a.append(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: b</span><br><span class="line">Out[<span class="number">11</span>]: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-3e3a8c6b9c5040fc.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x56FE;2-7 &#x5BF9;&#x540C;&#x4E00;&#x5BF9;&#x8C61;&#x7684;&#x53CC;&#x91CD;&#x5F15;&#x7528;"></p>
<p>理解Python的引用的含义，数据是何时、如何、为何复制的，是非常重要的。尤其是当你用Python处理大的数据集时。</p>
<blockquote>
<p>笔记：赋值也被称作绑定，我们是把一个名字绑定给一个对象。变量名有时可能被称为绑定变量。</p>
</blockquote>
<p>当你将对象作为参数传递给函数时，新的局域变量创建了对原始对象的引用，而不是复制。如果在函数里绑定一个新对象到一个变量，这个变动不会反映到上一层。因此可以改变可变参数的内容。假设有以下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_element</span>(<span class="params">some_list, element</span>):</span></span><br><span class="line">    some_list.append(element)</span><br></pre></td></tr></table></figure>
<p>然后有：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: append_element(data, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: data</span><br><span class="line">Out[<span class="number">29</span>]: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<h3><span id="动态引用强类型">动态引用，强类型</span></h3><p>与许多编译语言（如JAVA和C++）对比，Python中的对象引用不包含附属的类型。下面的代码是没有问题的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: a = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: <span class="built_in">type</span>(a)</span><br><span class="line">Out[<span class="number">13</span>]: <span class="built_in">int</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: a = <span class="string">&#x27;foo&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: <span class="built_in">type</span>(a)</span><br><span class="line">Out[<span class="number">15</span>]: <span class="built_in">str</span></span><br></pre></td></tr></table></figure>
<p>变量是在特殊命名空间中的对象的名字，类型信息保存在对象自身中。一些人可能会说Python不是“类型化语言”。这是不正确的，看下面的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [16]: &#x27;5&#x27; + 5</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-16-f9dbf5f0b234&gt; in &lt;module&gt;()</span><br><span class="line">----&gt; 1 &#x27;5&#x27; + 5</span><br><span class="line">TypeError: must be str, not int</span><br></pre></td></tr></table></figure>
<p>在某些语言中，例如Visual Basic，字符串‘5’可能被默许转换（或投射）为整数，因此会产生10。但在其它语言中，例如JavaScript，整数5会被投射成字符串，结果是联结字符串‘55’。在这个方面，Python被认为是强类型化语言，意味着每个对象都有明确的类型（或类），默许转换只会发生在特定的情况下，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [17]: a = 4.5</span><br><span class="line"></span><br><span class="line">In [18]: b = 2</span><br><span class="line"></span><br><span class="line"># String formatting, to be visited later</span><br><span class="line">In [19]: print(&#x27;a is &#123;0&#125;, b is &#123;1&#125;&#x27;.format(type(a), type(b)))</span><br><span class="line">a is &lt;class &#x27;float&#x27;&gt;, b is &lt;class &#x27;int&#x27;&gt;</span><br><span class="line"></span><br><span class="line">In [20]: a / b</span><br><span class="line">Out[20]: 2.25</span><br></pre></td></tr></table></figure>
<p>知道对象的类型很重要，最好能让函数可以处理多种类型的输入。你可以用<code>isinstance</code>函数检查对象是某个类型的实例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [21]: a = 5</span><br><span class="line"></span><br><span class="line">In [22]: isinstance(a, int)</span><br><span class="line">Out[22]: True</span><br></pre></td></tr></table></figure>
<p><code>isinstance</code>可以用类型元组，检查对象的类型是否在元组中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [23]: a = 5; b = 4.5</span><br><span class="line"></span><br><span class="line">In [24]: isinstance(a, (int, float))</span><br><span class="line">Out[24]: True</span><br><span class="line"></span><br><span class="line">In [25]: isinstance(b, (int, float))</span><br><span class="line">Out[25]: True</span><br></pre></td></tr></table></figure>
<h3><span id="属性和方法">属性和方法</span></h3><p>Python的对象通常都有属性（其它存储在对象内部的Python对象）和方法（对象的附属函数可以访问对象的内部数据）。可以用<code>obj.attribute_name</code>访问属性和方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [1]: a = &#x27;foo&#x27;</span><br><span class="line"></span><br><span class="line">In [2]: a.&lt;Press Tab&gt;</span><br><span class="line">a.capitalize  a.format      a.isupper     a.rindex      a.strip</span><br><span class="line">a.center      a.index       a.join        a.rjust       a.swapcase</span><br><span class="line">a.count       a.isalnum     a.ljust       a.rpartition  a.title</span><br><span class="line">a.decode      a.isalpha     a.lower       a.rsplit      a.translate</span><br><span class="line">a.encode      a.isdigit     a.lstrip      a.rstrip      a.upper</span><br><span class="line">a.endswith    a.islower     a.partition   a.split       a.zfill</span><br><span class="line">a.expandtabs  a.isspace     a.replace     a.splitlines</span><br><span class="line">a.find        a.istitle     a.rfind       a.startswith</span><br></pre></td></tr></table></figure>
<p>也可以用<code>getattr</code>函数，通过名字访问属性和方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [27]: getattr(a, &#x27;split&#x27;)</span><br><span class="line">Out[27]: &lt;function str.split&gt;</span><br></pre></td></tr></table></figure>
<p>在其它语言中，访问对象的名字通常称作“反射”。本书不会大量使用<code>getattr</code>函数和相关的<code>hasattr</code>和<code>setattr</code>函数，使用这些函数可以高效编写原生的、可重复使用的代码。</p>
<h3><span id="鸭子类型">鸭子类型</span></h3><p>经常地，你可能不关心对象的类型，只关心对象是否有某些方法或用途。这通常被称为“鸭子类型”，来自“走起来像鸭子、叫起来像鸭子，那么它就是鸭子”的说法。例如，你可以通过验证一个对象是否遵循迭代协议，判断它是可迭代的。对于许多对象，这意味着它有一个<code>__iter__</code>魔术方法，其它更好的判断方法是使用<code>iter</code>函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isiterable</span>(<span class="params">obj</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">iter</span>(obj)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> TypeError: <span class="comment"># not iterable</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>这个函数会返回字符串以及大多数Python集合类型为<code>True</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [29]: isiterable(&#x27;a string&#x27;)</span><br><span class="line">Out[29]: True</span><br><span class="line"></span><br><span class="line">In [30]: isiterable([1, 2, 3])</span><br><span class="line">Out[30]: True</span><br><span class="line"></span><br><span class="line">In [31]: isiterable(5)</span><br><span class="line">Out[31]: False</span><br></pre></td></tr></table></figure>
<p>我总是用这个功能编写可以接受多种输入类型的函数。常见的例子是编写一个函数可以接受任意类型的序列（list、tuple、ndarray）或是迭代器。你可先检验对象是否是列表（或是NUmPy数组），如果不是的话，将其转变成列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, <span class="built_in">list</span>) <span class="keyword">and</span> isiterable(x):</span><br><span class="line">    x = <span class="built_in">list</span>(x)</span><br></pre></td></tr></table></figure>
<h3><span id="引入">引入</span></h3><p>在Python中，模块就是一个有<code>.py</code>扩展名、包含Python代码的文件。假设有以下模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># some_module.py</span></span><br><span class="line">PI = <span class="number">3.14159</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x + <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br></pre></td></tr></table></figure>
<p>如果想从同目录下的另一个文件访问<code>some_module.py</code>中定义的变量和函数，可以：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> some_module</span><br><span class="line">result = some_module.f(<span class="number">5</span>)</span><br><span class="line">pi = some_module.PI</span><br></pre></td></tr></table></figure>
<p>或者：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> some_module <span class="keyword">import</span> f, g, PI</span><br><span class="line">result = g(<span class="number">5</span>, PI)</span><br></pre></td></tr></table></figure>
<p>使用<code>as</code>关键词，你可以给引入起不同的变量名：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> some_module <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">from</span> some_module <span class="keyword">import</span> PI <span class="keyword">as</span> pi, g <span class="keyword">as</span> gf</span><br><span class="line"></span><br><span class="line">r1 = sm.f(pi)</span><br><span class="line">r2 = gf(<span class="number">6</span>, pi)</span><br></pre></td></tr></table></figure>
<h3><span id="二元运算符和比较运算符">二元运算符和比较运算符</span></h3><p>大多数二元数学运算和比较都不难想到：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: <span class="number">5</span> - <span class="number">7</span></span><br><span class="line">Out[<span class="number">32</span>]: -<span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: <span class="number">12</span> + <span class="number">21.5</span></span><br><span class="line">Out[<span class="number">33</span>]: <span class="number">33.5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: <span class="number">5</span> &lt;= <span class="number">2</span></span><br><span class="line">Out[<span class="number">34</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>表2-3列出了所有的二元运算符。</p>
<p>要判断两个引用是否指向同一个对象，可以使用<code>is</code>方法。<code>is not</code>可以判断两个对象是不同的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: b = a</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: c = <span class="built_in">list</span>(a)</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: a <span class="keyword">is</span> b</span><br><span class="line">Out[<span class="number">38</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: a <span class="keyword">is</span> <span class="keyword">not</span> c</span><br><span class="line">Out[<span class="number">39</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>因为<code>list</code>总是创建一个新的Python列表（即复制），我们可以断定c是不同于a的。使用<code>is</code>比较与<code>==</code>运算符不同，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">40</span>]: a == c</span><br><span class="line">Out[<span class="number">40</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p><code>is</code>和<code>is not</code>常用来判断一个变量是否为<code>None</code>，因为只有一个<code>None</code>的实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: a = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: a <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">Out[<span class="number">42</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-9fb5f25b33166acf.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x8868;2-3 &#x4E8C;&#x5143;&#x8FD0;&#x7B97;&#x7B26;"></p>
<h3><span id="可变与不可变对象">可变与不可变对象</span></h3><p>Python中的大多数对象，比如列表、字典、NumPy数组，和用户定义的类型（类），都是可变的。意味着这些对象或包含的值可以被修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">43</span>]: a_list = [<span class="string">&#x27;foo&#x27;</span>, <span class="number">2</span>, [<span class="number">4</span>, <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: a_list[<span class="number">2</span>] = (<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: a_list</span><br><span class="line">Out[<span class="number">45</span>]: [<span class="string">&#x27;foo&#x27;</span>, <span class="number">2</span>, (<span class="number">3</span>, <span class="number">4</span>)]</span><br></pre></td></tr></table></figure>
<p>其它的，例如字符串和元组，是不可变的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">46</span>]: a_tuple = (<span class="number">3</span>, <span class="number">5</span>, (<span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: a_tuple[<span class="number">1</span>] = <span class="string">&#x27;four&#x27;</span></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">47</span>-b7966a9ae0f1&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> a_tuple[<span class="number">1</span>] = <span class="string">&#x27;four&#x27;</span></span><br><span class="line">TypeError: <span class="string">&#x27;tuple&#x27;</span> <span class="built_in">object</span> does <span class="keyword">not</span> support item assignment</span><br></pre></td></tr></table></figure>
<p>记住，可以修改一个对象并不意味就要修改它。这被称为副作用。例如，当写一个函数，任何副作用都要在文档或注释中写明。如果可能的话，我推荐避免副作用，采用不可变的方式，即使要用到可变对象。</p>
<h3><span id="标量类型">标量类型</span></h3><p>Python的标准库中有一些内建的类型，用于处理数值数据、字符串、布尔值，和日期时间。这些单值类型被称为标量类型，本书中称其为标量。表2-4列出了主要的标量。日期和时间处理会另外讨论，因为它们是标准库的<code>datetime</code>模块提供的。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-27a30ac3e7d262a1.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x8868;2-4 Python&#x7684;&#x6807;&#x91CF;"></p>
<h3><span id="数值类型">数值类型</span></h3><p>Python的主要数值类型是<code>int</code>和<code>float</code>。<code>int</code>可以存储任意大的数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: ival = <span class="number">17239871</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: ival ** <span class="number">6</span></span><br><span class="line">Out[<span class="number">49</span>]: <span class="number">26254519291092456596965462913230729701102721</span></span><br></pre></td></tr></table></figure>
<p>浮点数使用Python的<code>float</code>类型。每个数都是双精度（64位）的值。也可以用科学计数法表示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: fval = <span class="number">7.243</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: fval2 = <span class="number">6.78e-5</span></span><br></pre></td></tr></table></figure>
<p>不能得到整数的除法会得到浮点数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">52</span>]: <span class="number">3</span> / <span class="number">2</span></span><br><span class="line">Out[<span class="number">52</span>]: <span class="number">1.5</span></span><br></pre></td></tr></table></figure>
<p>要获得C-风格的整除（去掉小数部分），可以使用底除运算符//：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">53</span>]: <span class="number">3</span> // <span class="number">2</span></span><br><span class="line">Out[<span class="number">53</span>]: <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3><span id="字符串">字符串</span></h3><p>许多人是因为Python强大而灵活的字符串处理而使用Python的。你可以用单引号或双引号来写字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="string">&#x27;one way of writing a string&#x27;</span></span><br><span class="line">b = <span class="string">&quot;another way&quot;</span></span><br></pre></td></tr></table></figure>
<p>对于有换行符的字符串，可以使用三引号，’’’或”””都行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">c = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">This is a longer string that</span></span><br><span class="line"><span class="string">spans multiple lines</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>字符串<code>c</code>实际包含四行文本，”””后面和lines后面的换行符。可以用<code>count</code>方法计算<code>c</code>中的新的行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">55</span>]: c.count(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">Out[<span class="number">55</span>]: <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>Python的字符串是不可变的，不能修改字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: a = <span class="string">&#x27;this is a string&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: a[<span class="number">10</span>] = <span class="string">&#x27;f&#x27;</span></span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">TypeError                                 Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">57</span>-5ca625d1e504&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> a[<span class="number">10</span>] = <span class="string">&#x27;f&#x27;</span></span><br><span class="line">TypeError: <span class="string">&#x27;str&#x27;</span> <span class="built_in">object</span> does <span class="keyword">not</span> support item assignment</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: b = a.replace(<span class="string">&#x27;string&#x27;</span>, <span class="string">&#x27;longer string&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: b</span><br><span class="line">Out[<span class="number">59</span>]: <span class="string">&#x27;this is a longer string&#x27;</span></span><br></pre></td></tr></table></figure>
<p>经过以上的操作，变量<code>a</code>并没有被修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">60</span>]: a</span><br><span class="line">Out[<span class="number">60</span>]: <span class="string">&#x27;this is a string&#x27;</span></span><br></pre></td></tr></table></figure>
<p>许多Python对象使用<code>str</code>函数可以被转化为字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">61</span>]: a = <span class="number">5.6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: s = <span class="built_in">str</span>(a)</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: <span class="built_in">print</span>(s)</span><br><span class="line"><span class="number">5.6</span></span><br></pre></td></tr></table></figure>
<p>字符串是一个序列的Unicode字符，因此可以像其它序列，比如列表和元组（下一章会详细介绍两者）一样处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: s = <span class="string">&#x27;python&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: <span class="built_in">list</span>(s)</span><br><span class="line">Out[<span class="number">65</span>]: [<span class="string">&#x27;p&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;n&#x27;</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: s[:<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">66</span>]: <span class="string">&#x27;pyt&#x27;</span></span><br></pre></td></tr></table></figure>
<p>语法<code>s[:3]</code>被称作切片，适用于许多Python序列。后面会更详细的介绍，本书中用到很多切片。</p>
<p>反斜杠是转义字符，意思是它备用来表示特殊字符，比如换行符\n或Unicode字符。要写一个包含反斜杠的字符串，需要进行转义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">67</span>]: s = <span class="string">&#x27;12\\34&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">68</span>]: <span class="built_in">print</span>(s)</span><br><span class="line"><span class="number">12</span>\<span class="number">34</span></span><br></pre></td></tr></table></figure>
<p>如果字符串中包含许多反斜杠，但没有特殊字符，这样做就很麻烦。幸好，可以在字符串前面加一个r，表明字符就是它自身：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">69</span>]: s = <span class="string">r&#x27;this\has\no\special\characters&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: s</span><br><span class="line">Out[<span class="number">70</span>]: <span class="string">&#x27;this\\has\\no\\special\\characters&#x27;</span></span><br></pre></td></tr></table></figure>
<p>r表示raw。</p>
<p>将两个字符串合并，会产生一个新的字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">71</span>]: a = <span class="string">&#x27;this is the first half &#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: b = <span class="string">&#x27;and this is the second half&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">73</span>]: a + b</span><br><span class="line">Out[<span class="number">73</span>]: <span class="string">&#x27;this is the first half and this is the second half&#x27;</span></span><br></pre></td></tr></table></figure>
<p>字符串的模板化或格式化，是另一个重要的主题。Python 3拓展了此类的方法，这里只介绍一些。字符串对象有<code>format</code>方法，可以替换格式化的参数为字符串，产生一个新的字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: template = <span class="string">&#x27;&#123;0:.2f&#125; &#123;1:s&#125; are worth US$&#123;2:d&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>在这个字符串中，</p>
<ul>
<li><code>&#123;0:.2f&#125;</code>表示格式化第一个参数为带有两位小数的浮点数。</li>
<li><code>&#123;1:s&#125;</code>表示格式化第二个参数为字符串。</li>
<li><code>&#123;2:d&#125;</code>表示格式化第三个参数为一个整数。</li>
</ul>
<p>要替换参数为这些格式化的参数，我们传递<code>format</code>方法一个序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">75</span>]: template.<span class="built_in">format</span>(<span class="number">4.5560</span>, <span class="string">&#x27;Argentine Pesos&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">Out[<span class="number">75</span>]: <span class="string">&#x27;4.56 Argentine Pesos are worth US$1&#x27;</span></span><br></pre></td></tr></table></figure>
<p>字符串格式化是一个很深的主题，有多种方法和大量的选项，可以控制字符串中的值是如何格式化的。推荐参阅Python官方文档。</p>
<p>这里概括介绍字符串处理，第8章的数据分析会详细介绍。</p>
<h3><span id="字节和unicode">字节和Unicode</span></h3><p>在Python 3及以上版本中，Unicode是一级的字符串类型，这样可以更一致的处理ASCII和Non-ASCII文本。在老的Python版本中，字符串都是字节，不使用Unicode编码。假如知道字符编码，可以将其转化为Unicode。看一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: val = <span class="string">&quot;español&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: val</span><br><span class="line">Out[<span class="number">77</span>]: <span class="string">&#x27;español&#x27;</span></span><br></pre></td></tr></table></figure>
<p>可以用<code>encode</code>将这个Unicode字符串编码为UTF-8：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">78</span>]: val_utf8 = val.encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: val_utf8</span><br><span class="line">Out[<span class="number">79</span>]: <span class="string">b&#x27;espa\xc3\xb1ol&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: <span class="built_in">type</span>(val_utf8)</span><br><span class="line">Out[<span class="number">80</span>]: <span class="built_in">bytes</span></span><br></pre></td></tr></table></figure>
<p>如果你知道一个字节对象的Unicode编码，用<code>decode</code>方法可以解码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">81</span>]: val_utf8.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">Out[<span class="number">81</span>]: <span class="string">&#x27;español&#x27;</span></span><br></pre></td></tr></table></figure>
<p>虽然UTF-8编码已经变成主流，但因为历史的原因，你仍然可能碰到其它编码的数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: val.encode(<span class="string">&#x27;latin1&#x27;</span>)</span><br><span class="line">Out[<span class="number">82</span>]: <span class="string">b&#x27;espa\xf1ol&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: val.encode(<span class="string">&#x27;utf-16&#x27;</span>)</span><br><span class="line">Out[<span class="number">83</span>]: <span class="string">b&#x27;\xff\xfee\x00s\x00p\x00a\x00\xf1\x00o\x00l\x00&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: val.encode(<span class="string">&#x27;utf-16le&#x27;</span>)</span><br><span class="line">Out[<span class="number">84</span>]: <span class="string">b&#x27;e\x00s\x00p\x00a\x00\xf1\x00o\x00l\x00&#x27;</span></span><br></pre></td></tr></table></figure>
<p>工作中碰到的文件很多都是字节对象，盲目地将所有数据编码为Unicode是不可取的。</p>
<p>虽然用的不多，你可以在字节文本的前面加上一个b：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: bytes_val = <span class="string">b&#x27;this is bytes&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: bytes_val</span><br><span class="line">Out[<span class="number">86</span>]: <span class="string">b&#x27;this is bytes&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: decoded = bytes_val.decode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: decoded  <span class="comment"># this is str (Unicode) now</span></span><br><span class="line">Out[<span class="number">88</span>]: <span class="string">&#x27;this is bytes&#x27;</span></span><br></pre></td></tr></table></figure>
<h3><span id="布尔值">布尔值</span></h3><p>Python中的布尔值有两个，True和False。比较和其它条件表达式可以用True和False判断。布尔值可以与and和or结合使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">89</span>]: <span class="literal">True</span> <span class="keyword">and</span> <span class="literal">True</span></span><br><span class="line">Out[<span class="number">89</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: <span class="literal">False</span> <span class="keyword">or</span> <span class="literal">True</span></span><br><span class="line">Out[<span class="number">90</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h3><span id="类型转换">类型转换</span></h3><p>str、bool、int和float也是函数，可以用来转换类型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: s = <span class="string">&#x27;3.14159&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: fval = <span class="built_in">float</span>(s)</span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: <span class="built_in">type</span>(fval)</span><br><span class="line">Out[<span class="number">93</span>]: <span class="built_in">float</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">94</span>]: <span class="built_in">int</span>(fval)</span><br><span class="line">Out[<span class="number">94</span>]: <span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">95</span>]: <span class="built_in">bool</span>(fval)</span><br><span class="line">Out[<span class="number">95</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: <span class="built_in">bool</span>(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">96</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h3><span id="none">None</span></h3><p>None是Python的空值类型。如果一个函数没有明确的返回值，就会默认返回None：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">97</span>]: a = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: a <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">Out[<span class="number">98</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: b = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">100</span>]: b <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">Out[<span class="number">100</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>None也常常作为函数的默认参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_and_maybe_multiply</span>(<span class="params">a, b, c=<span class="literal">None</span></span>):</span></span><br><span class="line">    result = a + b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> c <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        result = result * c</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>另外，None不仅是一个保留字，还是唯一的NoneType的实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">101</span>]: <span class="built_in">type</span>(<span class="literal">None</span>)</span><br><span class="line">Out[<span class="number">101</span>]: NoneType</span><br></pre></td></tr></table></figure>
<h3><span id="日期和时间">日期和时间</span></h3><p>Python内建的<code>datetime</code>模块提供了<code>datetime</code>、<code>date</code>和<code>time</code>类型。<code>datetime</code>类型结合了<code>date</code>和<code>time</code>，是最常使用的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: <span class="keyword">from</span> datetime <span class="keyword">import</span> datetime, date, time</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: dt = datetime(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">21</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">104</span>]: dt.day</span><br><span class="line">Out[<span class="number">104</span>]: <span class="number">29</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: dt.minute</span><br><span class="line">Out[<span class="number">105</span>]: <span class="number">30</span></span><br></pre></td></tr></table></figure>
<p>根据<code>datetime</code>实例，你可以用<code>date</code>和<code>time</code>提取出各自的对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">106</span>]: dt.date()</span><br><span class="line">Out[<span class="number">106</span>]: datetime.date(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">107</span>]: dt.time()</span><br><span class="line">Out[<span class="number">107</span>]: datetime.time(<span class="number">20</span>, <span class="number">30</span>, <span class="number">21</span>)</span><br></pre></td></tr></table></figure>
<p><code>strftime</code>方法可以将datetime格式化为字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: dt.strftime(<span class="string">&#x27;%m/%d/%Y %H:%M&#x27;</span>)</span><br><span class="line">Out[<span class="number">108</span>]: <span class="string">&#x27;10/29/2011 20:30&#x27;</span></span><br></pre></td></tr></table></figure>
<p><code>strptime</code>可以将字符串转换成<code>datetime</code>对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">109</span>]: datetime.strptime(<span class="string">&#x27;20091031&#x27;</span>, <span class="string">&#x27;%Y%m%d&#x27;</span>)</span><br><span class="line">Out[<span class="number">109</span>]: datetime.datetime(<span class="number">2009</span>, <span class="number">10</span>, <span class="number">31</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>表2-5列出了所有的格式化命令。</p>
<p><img data-src="http://upload-images.jianshu.io/upload_images/7178691-100f9a20c1536553.png?imageMogr2/auto-orient/strip|imageView2/2/w/1240" alt="&#x8868;2-5 Datetime&#x683C;&#x5F0F;&#x5316;&#x6307;&#x4EE4;&#xFF08;&#x4E0E;ISO C89&#x517C;&#x5BB9;&#xFF09;"></p>
<p>当你聚类或对时间序列进行分组，替换datetimes的time字段有时会很有用。例如，用0替换分和秒：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">110</span>]: dt.replace(minute=<span class="number">0</span>, second=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">110</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>, <span class="number">20</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>因为<code>datetime.datetime</code>是不可变类型，上面的方法会产生新的对象。</p>
<p>两个datetime对象的差会产生一个<code>datetime.timedelta</code>类型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">111</span>]: dt2 = datetime(<span class="number">2011</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">22</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: delta = dt2 - dt</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: delta</span><br><span class="line">Out[<span class="number">113</span>]: datetime.timedelta(<span class="number">17</span>, <span class="number">7179</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: <span class="built_in">type</span>(delta)</span><br><span class="line">Out[<span class="number">114</span>]: datetime.timedelta</span><br></pre></td></tr></table></figure>
<p>结果<code>timedelta(17, 7179)</code>指明了<code>timedelta</code>将17天、7179秒的编码方式。</p>
<p>将<code>timedelta</code>添加到<code>datetime</code>，会产生一个新的偏移<code>datetime</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">115</span>]: dt</span><br><span class="line">Out[<span class="number">115</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">21</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: dt + delta</span><br><span class="line">Out[<span class="number">116</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">22</span>, <span class="number">30</span>)</span><br></pre></td></tr></table></figure>
<h3><span id="控制流">控制流</span></h3><p>Python有若干内建的关键字进行条件逻辑、循环和其它控制流操作。</p>
<h3><span id="if-elif和else">if、elif和else</span></h3><p>if是最广为人知的控制流语句。它检查一个条件，如果为True，就执行后面的语句：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x &lt; <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;It&#x27;</span>s negative<span class="string">&#x27;)</span></span><br></pre></td></tr></table></figure>
<p><code>if</code>后面可以跟一个或多个<code>elif</code>，所有条件都是False时，还可以添加一个<code>else</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x &lt; <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;It&#x27;</span>s negative<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">elif x == 0:</span></span><br><span class="line"><span class="string">    print(&#x27;</span>Equal to zero<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">elif 0 &lt; x &lt; 5:</span></span><br><span class="line"><span class="string">    print(&#x27;</span>Positive but smaller than <span class="number">5</span><span class="string">&#x27;)</span></span><br><span class="line"><span class="string">else:</span></span><br><span class="line"><span class="string">    print(&#x27;</span>Positive <span class="keyword">and</span> larger than <span class="keyword">or</span> equal to <span class="number">5</span><span class="string">&#x27;)</span></span><br></pre></td></tr></table></figure>
<p>如果某个条件为True，后面的<code>elif</code>就不会被执行。当使用and和or时，复合条件语句是从左到右执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: a = <span class="number">5</span>; b = <span class="number">7</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: c = <span class="number">8</span>; d = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: <span class="keyword">if</span> a &lt; b <span class="keyword">or</span> c &gt; d:</span><br><span class="line">   .....:     <span class="built_in">print</span>(<span class="string">&#x27;Made it&#x27;</span>)</span><br><span class="line">Made it</span><br></pre></td></tr></table></figure>
<p>在这个例子中，<code>c &gt; d</code>不会被执行，因为第一个比较是True：</p>
<p>也可以把比较式串在一起：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">120</span>]: <span class="number">4</span> &gt; <span class="number">3</span> &gt; <span class="number">2</span> &gt; <span class="number">1</span></span><br><span class="line">Out[<span class="number">120</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h3><span id="for循环">for循环</span></h3><p>for循环是在一个集合（列表或元组）中进行迭代，或者就是一个迭代器。for循环的标准语法是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> collection:</span><br><span class="line">    <span class="comment"># do something with value</span></span><br></pre></td></tr></table></figure>
<p>你可以用continue使for循环提前，跳过剩下的部分。看下面这个例子，将一个列表中的整数相加，跳过None：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sequence = [<span class="number">1</span>, <span class="number">2</span>, <span class="literal">None</span>, <span class="number">4</span>, <span class="literal">None</span>, <span class="number">5</span>]</span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> sequence:</span><br><span class="line">    <span class="keyword">if</span> value <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    total += value</span><br></pre></td></tr></table></figure>
<p>可以用<code>break</code>跳出for循环。下面的代码将各元素相加，直到遇到5：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sequence = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">total_until_5 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> sequence:</span><br><span class="line">    <span class="keyword">if</span> value == <span class="number">5</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    total_until_5 += value</span><br></pre></td></tr></table></figure>
<p>break只中断for循环的最内层，其余的for循环仍会运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">121</span>]: <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">   .....:     <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">   .....:         <span class="keyword">if</span> j &gt; i:</span><br><span class="line">   .....:             <span class="keyword">break</span></span><br><span class="line">   .....:         <span class="built_in">print</span>((i, j))</span><br><span class="line">   .....:</span><br><span class="line">(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="number">0</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>如果集合或迭代器中的元素序列（元组或列表），可以用for循环将其方便地拆分成变量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> a, b, c <span class="keyword">in</span> iterator:</span><br><span class="line">    <span class="comment"># do something</span></span><br></pre></td></tr></table></figure>
<h3><span id="while循环">While循环</span></h3><p>while循环指定了条件和代码，当条件为False或用break退出循环，代码才会退出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="number">256</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> x &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">if</span> total &gt; <span class="number">500</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    total += x</span><br><span class="line">    x = x // <span class="number">2</span></span><br></pre></td></tr></table></figure>
<h3><span id="pass">pass</span></h3><p>pass是Python中的非操作语句。代码块不需要任何动作时可以使用（作为未执行代码的占位符）；因为Python需要使用空白字符划定代码块，所以需要pass：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x &lt; <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;negative!&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> x == <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> put something smart here</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;positive!&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3><span id="range">range</span></h3><p>range函数返回一个迭代器，它产生一个均匀分布的整数序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">122</span>]: <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">122</span>]: <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">123</span>]: <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line">Out[<span class="number">123</span>]: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br></pre></td></tr></table></figure>
<p>range的三个参数是（起点，终点，步进）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">124</span>]: <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">20</span>, <span class="number">2</span>))</span><br><span class="line">Out[<span class="number">124</span>]: [<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">18</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>, <span class="number">0</span>, -<span class="number">1</span>))</span><br><span class="line">Out[<span class="number">125</span>]: [<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>可以看到，range产生的整数不包括终点。range的常见用法是用序号迭代序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seq = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(seq)):</span><br><span class="line">    val = seq[i]</span><br></pre></td></tr></table></figure>
<p>可以使用list来存储range在其他数据结构中生成的所有整数，默认的迭代器形式通常是你想要的。下面的代码对0到99999中3或5的倍数求和：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>):</span><br><span class="line">    <span class="comment"># % is the modulo operator</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">3</span> == <span class="number">0</span> <span class="keyword">or</span> i % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">sum</span> += i</span><br></pre></td></tr></table></figure>
<p>虽然range可以产生任意大的数，但任意时刻耗用的内存却很小。</p>
<h3><span id="三元表达式">三元表达式</span></h3><p>Python中的三元表达式可以将if-else语句放到一行里。语法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">value = true-expr <span class="keyword">if</span> condition <span class="keyword">else</span> false-expr</span><br></pre></td></tr></table></figure>
<p><code>true-expr</code>或<code>false-expr</code>可以是任何Python代码。它和下面的代码效果相同：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> condition:</span><br><span class="line">    value = true-expr</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    value = false-expr</span><br></pre></td></tr></table></figure>
<p>下面是一个更具体的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">126</span>]: x = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">127</span>]: <span class="string">&#x27;Non-negative&#x27;</span> <span class="keyword">if</span> x &gt;= <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;Negative&#x27;</span></span><br><span class="line">Out[<span class="number">127</span>]: <span class="string">&#x27;Non-negative&#x27;</span></span><br></pre></td></tr></table></figure>
<p>和if-else一样，只有一个表达式会被执行。因此，三元表达式中的if和else可以包含大量的计算，但只有True的分支会被执行。因此，三元表达式中的if和else可以包含大量的计算，但只有True的分支会被执行。</p>
<p>虽然使用三元表达式可以压缩代码，但会降低代码可读性。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Scikit-Learn与TensorFlow机器学习实用指南-1</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Scikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>一、简介</p>
<p>很多机器学习的问题都会涉及到有着几千甚至数百万维的特征的训练实例。这不仅让训练过程变得非常缓慢，同时还很难找到一个很好的解，我们接下来就会遇到这种情况。这种问题通常被称为维数灾难（curse of dimentionality）。</p>
<p>幸运的是，在现实生活中我们经常可以极大的降低特征维度，将一个十分棘手的问题转变成一个可以较为容易解决的问题。例如，对于 MNIST 图片集（第 3 章中提到）：图片四周边缘部分的像素几乎总是白的，因此你完全可以将这些像素从你的训练集中扔掉而不会丢失太多信息。图 7-6 向我们证实了这些像素的确对我们的分类任务是完全不重要的。同时，两个相邻的像素往往是高度相关的：如果你想要将他们合并成一个像素（比如取这两个像素点的平均值）你并不会丢失很多信息。</p>
<span id="more"></span>
<p>警告：降维肯定会丢失一些信息（这就好比将一个图片压缩成 JPEG 的格式会降低图像的质量），因此即使这种方法可以加快训练的速度，同时也会让你的系统表现的稍微差一点。降维会让你的工作流水线更复杂因而更难维护。所有你应该先尝试使用原始的数据来训练，如果训练速度太慢的话再考虑使用降维。在某些情况下，降低训练集数据的维度可能会筛选掉一些噪音和不必要的细节，这可能会让你的结果比降维之前更好（这种情况通常不会发生；它只会加快你训练的速度）。</p>
<p>降维除了可以加快训练速度外，在数据可视化方面（或者 DataViz）也十分有用。降低特征维度到 2（或者 3）维从而可以在图中画出一个高维度的训练集，让我们可以通过视觉直观的发现一些非常重要的信息，比如聚类。</p>
<p>在这一章里，我们将会讨论维数灾难问题并且了解在高维空间的数据。然后，我们将会展示两种主要的降维方法：投影（projection）和流形学习（Manifold Learning），同时我们还会介绍三种流行的降维技术：主成分分析（PCA），核主成分分析（Kernel PCA）和局部线性嵌入（LLE）。</p>
<p>二、维数灾难<br>我们已经习惯生活在一个三维的世界里，以至于当我们尝试想象更高维的空间时，我们的直觉不管用了。即使是一个基本的 4D 超正方体也很难在我们的脑中想象出来（见图 8-1），更不用说一个 200 维的椭球弯曲在一个 1000 维的空间里了。</p>
<p>图 8-1 点，线，方形，立方体和超正方体（0D 到 4D 超正方体）<br>这表明很多物体在高维空间表现的十分不同。比如，如果你在一个正方形单元中随机取一个点（一个1×1的正方形），那么随机选的点离所有边界大于 0.001（靠近中间位置）的概率为 0.4%（1 - 0.998^2）（换句话说，一个随机产生的点不大可能严格落在某一个维度上。但是在一个 1,0000 维的单位超正方体（一个1×1×…×1的立方体，有 10,000 个 1），这种可能性超过了 99.999999%。在高维超正方体中，大多数点都分布在边界处。</p>
<p>还有一个更麻烦的区别：如果你在一个平方单位中随机选取两个点，那么这两个点之间的距离平均约为 0.52。如果您在单位 3D 立方体中选取两个随机点，平均距离将大致为 0.66。但是，在一个 1,000,000 维超立方体中随机抽取两点呢？那么，平均距离，信不信由你，大概为 408.25！这非常违反直觉：当它们都位于同一单元超立方体内时，两点是怎么距离这么远的？这一事实意味着高维数据集有很大风险分布的非常稀疏：大多数训练实例可能彼此远离。当然，这也意味着一个新实例可能远离任何训练实例，这使得预测的可靠性远低于我们处理较低维度数据的预测，因为它们将基于更大的推测（extrapolations）。简而言之，训练集的维度越高，过拟合的风险就越大。</p>
<p>理论上来说，维数爆炸的一个解决方案是增加训练集的大小从而达到拥有足够密度的训练集。不幸的是，在实践中，达到给定密度所需的训练实例的数量随着维度的数量呈指数增长。如果只有 100 个特征（比 MNIST 问题要少得多）并且假设它们均匀分布在所有维度上，那么如果想要各个临近的训练实例之间的距离在 0.1 以内，您需要比宇宙中的原子还要多的训练实例。</p>
<p>三、降维的主要方法<br>在我们深入研究具体的降维算法之前，我们来看看降低维度的两种主要方法：投影和流形学习。</p>
<p>3.1 投影（Projection）<br>在大多数现实生活的问题中，训练实例并不是在所有维度上均匀分布的。许多特征几乎是常数，而其他特征则高度相关（如前面讨论的 MNIST）。结果，所有训练实例实际上位于（或接近）高维空间的低维子空间内。这听起来有些抽象，所以我们不妨来看一个例子。在图 8-2 中，您可以看到由圆圈表示的 3D 数据集。</p>
<p>图 8-2 一个分布接近于2D子空间的3D数据集<br>注意到所有训练实例的分布都贴近一个平面：这是高维（3D）空间的较低维（2D）子空间。现在，如果我们将每个训练实例垂直投影到这个子空间上（就像将短线连接到平面的点所表示的那样），我们就可以得到如图8-3所示的新2D数据集。铛铛铛！我们刚刚将数据集的维度从 3D 降低到了 2D。请注意，坐标轴对应于新的特征z1和z2（平面上投影的坐标）。</p>
<p>图 8-3 一个经过投影后的新的 2D 数据集<br>但是，投影并不总是降维的最佳方法。在很多情况下，子空间可能会扭曲和转动，比如图 8-4 所示的着名瑞士滚动玩具数据集。</p>
<p>图 8-4 瑞士滚动数玩具数据集<br>简单地将数据集投射到一个平面上（例如，直接丢弃x3）会将瑞士卷的不同层叠在一起，如图 8-5 左侧所示。但是，你真正想要的是展开瑞士卷所获取到的类似图 8-5 右侧的 2D 数据集。</p>
<p>图 8-5 投射到平面的压缩（左）vs 展开瑞士卷（右）<br>3.2 流形学习</p>
<p>瑞士卷一个是二维流形的例子。简而言之，二维流形是一种二维形状，它可以在更高维空间中弯曲或扭曲。更一般地，一个d维流形是类似于d维超平面的n维空间（其中d &lt; n）的一部分。在我们瑞士卷这个例子中，d = 2，n = 3：它有些像 2D 平面，但是它实际上是在第三维中卷曲。</p>
<p>许多降维算法通过对训练实例所在的流形进行建模从而达到降维目的；这叫做流形学习。它依赖于流形猜想（manifold assumption），也被称为流形假设（manifold hypothesis），它认为大多数现实世界的高维数据集大都靠近一个更低维的流形。这种假设经常在实践中被证实。</p>
<p>让我们再回到 MNIST 数据集：所有手写数字图像都有一些相似之处。它们由连线组成，边界是白色的，大多是在图片中中间的，等等。如果你随机生成图像，只有一小部分看起来像手写数字。换句话说，如果您尝试创建数字图像，那么您的自由度远低于您生成任何随便一个图像时的自由度。这些约束往往会将数据集压缩到较低维流形中。</p>
<p>流形假设通常包含着另一个隐含的假设：你现在的手上的工作（例如分类或回归）如果在流形的较低维空间中表示，那么它们会变得更简单。例如，在图 8-6 的第一行中，瑞士卷被分为两类：在三维空间中（图左上），分类边界会相当复杂，但在二维展开的流形空间中（图右上），分类边界是一条简单的直线。</p>
<p>但是，这个假设并不总是成立。例如，在图 8-6 的最下面一行，决策边界位于x1 = 5（图左下）。这个决策边界在原始三维空间（一个垂直平面）看起来非常简单，但在展开的流形中却变得更复杂了（四个独立线段的集合）（图右下）。</p>
<p>简而言之，如果在训练模型之前降低训练集的维数，那训练速度肯定会加快，但并不总是会得出更好的训练效果；这一切都取决于数据集。</p>
<p>希望你现在对于维数爆炸以及降维算法如何解决这个问题有了一定的理解，特别是对流形假设提出的内容。本章的其余部分将介绍一些最流行的降维算法。</p>
<p>图 8-6 决策边界并不总是会在低维空间中变的简单</p>
<p><a href="https://zhuanlan.zhihu.com/p/83284762">参考</a><br><a href="https://www.zhihu.com/topic/20134952/hot">参考二</a></p>
]]></content>
  </entry>
  <entry>
    <title>利用python进行数据分析-1.简介</title>
    <url>/posts/%E5%88%A9%E7%94%A8python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-1-%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="第1章-准备工作">第1章 准备工作</span></h1><h2><span id="11-本书的内容">1.1 本书的内容</span></h2><p>本书讲的是利用Python进行数据控制、处理、整理、分析等方面的具体细节和基本要点。我的目标是介绍Python编程和用于数据处理的库和工具环境，掌握这些，可以让你成为一个数据分析专家。虽然本书的标题是“数据分析”，重点却是Python编程、库，以及用于数据分析的工具。这就是数据分析要用到的Python编程。</p>
<span id="more"></span>
<h3><span id="什么样的数据">什么样的数据？</span></h3><p>当书中出现“数据”时，究竟指的是什么呢？主要指的是结构化数据（structured data），这个故意含糊其辞的术语代指了所有通用格式的数据，例如：</p>
<ul>
<li>表格型数据，其中各列可能是不同的类型（字符串、数值、日期等）。比如保存在关系型数据库中或以制表符/逗号为分隔符的文本文件中的那些数据。</li>
<li>多维数组（矩阵）。</li>
<li>通过关键列（对于SQL用户而言，就是主键和外键）相互联系的多个表。</li>
<li>间隔平均或不平均的时间序列。</li>
</ul>
<p>这绝不是一个完整的列表。大部分数据集都能被转化为更加适合分析和建模的结构化形式，虽然有时这并不是很明显。如果不行的话，也可以将数据集的特征提取为某种结构化形式。例如，一组新闻文章可以被处理为一张词频表，而这张词频表就可以用于情感分析。</p>
<p>大部分电子表格软件（比如Microsoft Excel，它可能是世界上使用最广泛的数据分析工具了）的用户不会对此类数据感到陌生。</p>
<h2><span id="12-为什么要使用python进行数据分析">1.2 为什么要使用Python进行数据分析</span></h2><p>许许多多的人（包括我自己）都很容易爱上Python这门语言。自从1991年诞生以来，Python现在已经成为最受欢迎的动态编程语言之一，其他还有Perl、Ruby等。由于拥有大量的Web框架（比如Rails（Ruby）和Django（Python）），自从2005年，使用Python和Ruby进行网站建设工作非常流行。这些语言常被称作脚本（scripting）语言，因为它们可以用于编写简短而粗糙的小程序（也就是脚本）。我个人并不喜欢“脚本语言”这个术语，因为它好像在说这些语言无法用于构建严谨的软件。在众多解释型语言中，由于各种历史和文化的原因，Python发展出了一个巨大而活跃的科学计算（scientific computing）社区。在过去的10年，Python从一个边缘或“自担风险”的科学计算语言，成为了数据科学、机器学习、学界和工业界软件开发最重要的语言之一。</p>
<p>在数据分析、交互式计算以及数据可视化方面，Python将不可避免地与其他开源和商业的领域特定编程语言/工具进行对比，如R、MATLAB、SAS、Stata等。近年来，由于Python的库（例如pandas和scikit-learn）不断改良，使其成为数据分析任务的一个优选方案。结合其在通用编程方面的强大实力，我们完全可以只使用Python这一种语言构建以数据为中心的应用。</p>
<h3><span id="python作为胶水语言">Python作为胶水语言</span></h3><p>Python成为成功的科学计算工具的部分原因是，它能够轻松地集成C、C++以及Fortran代码。大部分现代计算环境都利用了一些Fortran和C库来实现线性代数、优选、积分、快速傅里叶变换以及其他诸如此类的算法。许多企业和国家实验室也利用Python来“粘合”那些已经用了多年的遗留软件系统。</p>
<p>大多数软件都是由两部分代码组成的：少量需要占用大部分执行时间的代码，以及大量不经常执行的“胶水代码”。大部分情况下，胶水代码的执行时间是微不足道的。开发人员的精力几乎都是花在优化计算瓶颈上面，有时更是直接转用更低级的语言（比如C）。</p>
<h3><span id="解决两种语言问题">解决“两种语言”问题</span></h3><p>很多组织通常都会用一种类似于领域特定的计算语言（如SAS和R）对新想法做研究、原型构建和测试，然后再将这些想法移植到某个更大的生产系统中去（可能是用Java、C#或C++编写的）。人们逐渐意识到，Python不仅适用于研究和原型构建，同时也适用于构建生产系统。为什么一种语言就够了，却要使用两个语言的开发环境呢？我相信越来越多的企业也会这样看，因为研究人员和工程技术人员使用同一种编程工具将会给企业带来非常显著的组织效益。</p>
<h3><span id="为什么不选python">为什么不选Python</span></h3><p>虽然Python非常适合构建分析应用以及通用系统，但它对不少应用场景适用性较差。</p>
<p>由于Python是一种解释型编程语言，因此大部分Python代码都要比用编译型语言（比如Java和C++）编写的代码运行慢得多。由于程序员的时间通常都比CPU时间值钱，因此许多人也愿意对此做一些取舍。但是，在那些延迟要求非常小或高资源利用率的应用中（例如高频交易系统），耗费时间使用诸如C++这样更低级、更低生产率的语言进行编程也是值得的。</p>
<p>对于高并发、多线程的应用程序而言（尤其是拥有许多计算密集型线程的应用程序），Python并不是一种理想的编程语言。这是因为Python有一个叫做全局解释器锁（Global Interpreter Lock，GIL）的组件，这是一种防止解释器同时执行多条Python字节码指令的机制。有关“为什么会存在GIL”的技术性原因超出了本书的范围。虽然很多大数据处理应用程序为了能在较短的时间内完成数据集的处理工作都需要运行在计算机集群上，但是仍然有一些情况需要用单进程多线程系统来解决。</p>
<p>这并不是说Python不能执行真正的多线程并行代码。例如，Python的C插件使用原生的C或C++的多线程，可以并行运行而不被GIL影响，只要它们不频繁地与Python对象交互。</p>
<h2><span id="13-重要的python库">1.3 重要的Python库</span></h2><p>考虑到那些还不太了解Python科学计算生态系统和库的读者，下面我先对各个库做一个简单的介绍。</p>
<h3><span id="numpy">NumPy</span></h3><p>NumPy（Numerical Python的简称）是Python科学计算的基础包。本书大部分内容都基于NumPy以及构建于其上的库。它提供了以下功能（不限于此）：</p>
<ul>
<li>快速高效的多维数组对象ndarray。</li>
<li>用于对数组执行元素级计算以及直接对数组执行数学运算的函数。</li>
<li>用于读写硬盘上基于数组的数据集的工具。</li>
<li><p>线性代数运算、傅里叶变换，以及随机数生成。 </p>
<p>-成熟的C API， 用于Python插件和原生C、C++、Fortran代码访问NumPy的数据结构和计算工具。</p>
</li>
</ul>
<p>除了为Python提供快速的数组处理能力，NumPy在数据分析方面还有另外一个主要作用，即作为在算法和库之间传递数据的容器。对于数值型数据，NumPy数组在存储和处理数据时要比内置的Python数据结构高效得多。此外，由低级语言（比如C和Fortran）编写的库可以直接操作NumPy数组中的数据，无需进行任何数据复制工作。因此，许多Python的数值计算工具要么使用NumPy数组作为主要的数据结构，要么可以与NumPy进行无缝交互操作。</p>
<h3><span id="pandas">pandas</span></h3><p>pandas提供了快速便捷处理结构化数据的大量数据结构和函数。自从2010年出现以来，它助使Python成为强大而高效的数据分析环境。本书用得最多的pandas对象是DataFrame，它是一个面向列（column-oriented）的二维表结构，另一个是Series，一个一维的标签化数组对象。</p>
<p>pandas兼具NumPy高性能的数组计算功能以及电子表格和关系型数据库（如SQL）灵活的数据处理功能。它提供了复杂精细的索引功能，能更加便捷地完成重塑、切片和切块、聚合以及选取数据子集等操作。因为数据操作、准备、清洗是数据分析最重要的技能，pandas是本书的重点。</p>
<p>作为背景，我是在2008年初开始开发pandas的，那时我任职于AQR Capital Management，一家量化投资管理公司，我有许多工作需求都不能用任何单一的工具解决：</p>
<ul>
<li>有标签轴的数据结构，支持自动或清晰的数据对齐。这可以防止由于数据不对齐，或处理来源不同的索引不同的数据，所造成的错误。</li>
<li>集成时间序列功能。</li>
<li>相同的数据结构用于处理时间序列数据和非时间序列数据。</li>
<li>保存元数据的算术运算和压缩。</li>
<li>灵活处理缺失数据。</li>
<li>合并和其它流行数据库（例如基于SQL的数据库）的关系操作。</li>
</ul>
<p>我想只用一种工具就实现所有功能，并使用通用软件开发语言。Python是一个不错的候选语言，但是此时没有集成的数据结构和工具来实现。我一开始就是想把pandas设计为一款适用于金融和商业分析的工具，pandas专注于深度时间序列功能和工具，适用于时间索引化的数据。</p>
<p>对于使用R语言进行统计计算的用户，肯定不会对DataFrame这个名字感到陌生，因为它源自于R的data.frame对象。但与Python不同，data frames是构建于R和它的标准库。因此，pandas的许多功能不属于R或它的扩展包。</p>
<p>pandas这个名字源于panel data（面板数据，这是多维结构化数据集在计量经济学中的术语）以及Python data analysis（Python数据分析）。</p>
<h3><span id="matplotlib">matplotlib</span></h3><p>matplotlib是最流行的用于绘制图表和其它二维数据可视化的Python库。它最初由John D.Hunter（JDH）创建，目前由一个庞大的开发团队维护。它非常适合创建出版物上用的图表。虽然还有其它的Python可视化库，matplotlib却是使用最广泛的，并且它和其它生态工具配合也非常完美。我认为，可以使用它作为默认的可视化工具。</p>
<h3><span id="ipython和jupyter">IPython和Jupyter</span></h3><p>IPython项目起初是Fernando Pérez在2001年的一个用以加强和Python交互的子项目。在随后的16年中，它成为了Python数据栈最重要的工具之一。虽然IPython本身没有提供计算和数据分析的工具，它却可以大大提高交互式计算和软件开发的生产率。IPython鼓励“执行-探索”的工作流，区别于其它编程软件的“编辑-编译-运行”的工作流。它还可以方便地访问系统的shell和文件系统。因为大部分的数据分析代码包括探索、试错和重复，IPython可以使工作更快。</p>
<p>2014年，Fernando和IPython团队宣布了Jupyter项目，一个更宽泛的多语言交互计算工具的计划。IPython web notebook变成了Jupyter notebook，现在支持40种编程语言。IPython现在可以作为Jupyter使用Python的内核（一种编程语言模式）。</p>
<p>IPython变成了Jupyter庞大开源项目（一个交互和探索式计算的高效环境）中的一个组件。它最老也是最简单的模式，现在是一个用于编写、测试、调试Python代码的强化shell。你还可以使用通过Jupyter Notebook，一个支持多种语言的交互式网络代码“笔记本”，来使用IPython。IPython shell 和Jupyter notebooks特别适合进行数据探索和可视化。</p>
<p>Jupyter notebooks还可以编写Markdown和HTML内容，它提供了一种创建代码和文本的富文本方法。其它编程语言也在Jupyter中植入了内核，好让在Jupyter中可以使用Python以外的语言。</p>
<p>对我个人而言，我的大部分Python工作都要用到IPython，包括运行、调试和测试代码。</p>
<p>在本书的GitHub页面，你可以找到包含各章节所有代码实例的Jupyter notebooks。</p>
<h3><span id="scipy">SciPy</span></h3><p>SciPy是一组专门解决科学计算中各种标准问题域的包的集合，主要包括下面这些包：</p>
<ul>
<li>scipy.integrate：数值积分例程和微分方程求解器。</li>
<li>scipy.linalg：扩展了由numpy.linalg提供的线性代数例程和矩阵分解功能。</li>
<li>scipy.optimize：函数优化器（最小化器）以及根查找算法。</li>
<li>scipy.signal：信号处理工具。</li>
<li>scipy.sparse：稀疏矩阵和稀疏线性系统求解器。</li>
<li>scipy.special：SPECFUN（这是一个实现了许多常用数学函数（如伽玛函数）的Fortran库）的包装器。</li>
<li>scipy.stats：标准连续和离散概率分布（如密度函数、采样器、连续分布函数等）、各种统计检验方法，以及更好的描述统计法。</li>
</ul>
<p>NumPy和SciPy结合使用，便形成了一个相当完备和成熟的计算平台，可以处理多种传统的科学计算问题。</p>
<h3><span id="scikit-learn">scikit-learn</span></h3><p>2010年诞生以来，scikit-learn成为了Python的通用机器学习工具包。仅仅七年，就汇聚了全世界超过1500名贡献者。它的子模块包括：</p>
<ul>
<li>分类：SVM、近邻、随机森林、逻辑回归等等。</li>
<li>回归：Lasso、岭回归等等。</li>
<li>聚类：k-均值、谱聚类等等。</li>
<li>降维：PCA、特征选择、矩阵分解等等。</li>
<li>选型：网格搜索、交叉验证、度量。</li>
<li>预处理：特征提取、标准化。</li>
</ul>
<p>与pandas、statsmodels和IPython一起，scikit-learn对于Python成为高效数据科学编程语言起到了关键作用。虽然本书不会详细讲解scikit-learn，我会简要介绍它的一些模型，以及用其它工具如何使用这些模型。</p>
<h3><span id="statsmodels">statsmodels</span></h3><p>statsmodels是一个统计分析包，起源于斯坦福大学统计学教授Jonathan Taylor，他设计了多种流行于R语言的回归分析模型。Skipper Seabold和Josef Perktold在2010年正式创建了statsmodels项目，随后汇聚了大量的使用者和贡献者。受到R的公式系统的启发，Nathaniel Smith发展出了Patsy项目，它提供了statsmodels的公式或模型的规范框架。</p>
<p>与scikit-learn比较，statsmodels包含经典统计学和经济计量学的算法。包括如下子模块：</p>
<ul>
<li>回归模型：线性回归，广义线性模型，健壮线性模型，线性混合效应模型等等。</li>
<li>方差分析（ANOVA）。</li>
<li>时间序列分析：AR，ARMA，ARIMA，VAR和其它模型。</li>
<li>非参数方法： 核密度估计，核回归。</li>
<li>统计模型结果可视化。</li>
</ul>
<p>statsmodels更关注与统计推断，提供不确定估计和参数p-值。相反的，scikit-learn注重预测。</p>
<p>同scikit-learn一样，我也只是简要介绍statsmodels，以及如何用NumPy和pandas使用它。</p>
<h2><span id="14-安装和设置">1.4 安装和设置</span></h2><p>由于人们用Python所做的事情不同，所以没有一个普适的Python及其插件包的安装方案。由于许多读者的Python科学计算环境都不能完全满足本书的需要，所以接下来我将详细介绍各个操作系统上的安装方法。我推荐免费的Anaconda安装包。写作本书时，Anaconda提供Python 2.7和3.6两个版本，以后可能发生变化。本书使用的是Python 3.6，因此推荐选择Python 3.6或更高版本。</p>
<h3><span id="windows">Windows</span></h3><p>要在Windows上运行，先下载<a href="https://www.anaconda.com/download/">Anaconda安装包</a>。推荐跟随Anaconda下载页面的Windows安装指导，安装指导在写作本书和读者看到此文的的这段时间内可能发生变化。</p>
<p>现在，来确认设置是否正确。打开命令行窗口（<code>cmd.exe</code>），输入<code>python</code>以打开Python解释器。可以看到类似下面的Anaconda版本的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\Users\wesm&gt;python</span><br><span class="line">Python 3.5.2 |Anaconda 4.1.1 (64-bit)| (default, Jul  5 2016, 11:41:13)</span><br><span class="line">[MSC v.1900 64 bit (AMD64)] on win32</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>要退出shell，按Ctrl-D（Linux或macOS上），Ctrl-Z（Windows上），或输入命令<code>exit()</code>，再按Enter。</p>
<h3><span id="apple-os-x-macos">Apple (OS X, macOS)</span></h3><p>下载OS X Anaconda安装包，它的名字类似Anaconda3-4.1.0-MacOSX-x86_64.pkg。双击.pkg文件，运行安装包。安装包运行时，会自动将Anaconda执行路径添加到<code>.bash_profile</code>文件，它位于<code>/Users/$USER/.bash_profile</code>。</p>
<p>为了确认成功，在系统shell打开IPython：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ipython</span><br></pre></td></tr></table></figure>
<p>要退出shell，按Ctrl-D，或输入命令<code>exit()</code>，再按Enter。</p>
<h3><span id="gnulinux">GNU/Linux</span></h3><p>Linux版本很多，这里给出Debian、Ubantu、CentOS和Fedora的安装方法。安装包是一个脚本文件，必须在shell中运行。取决于系统是32位还是64位，要么选择x86 (32位)或x86_64 (64位)安装包。随后你会得到一个文件，名字类似于<code>Anaconda3-4.1.0-Linux-x86_64.sh</code>。用bash进行安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ bash Anaconda3-4.1.0-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>笔记：某些Linux版本在包管理器中有满足需求的Python包，只需用类似apt的工具安装就行。这里讲的用Anaconda安装，适用于不同的Linux安装包，也很容易将包升级到最新版本。</p>
</blockquote>
<p>接受许可之后，会向你询问在哪里放置Anaconda的文件。我推荐将文件安装到默认的home目录，例如<code>/home/$USER/anaconda</code>。</p>
<p>Anaconda安装包可能会询问你是否将<code>bin/</code>目录添加到<code>$PATH</code>变量。如果在安装之后有任何问题，你可以修改文件<code>.bashrc</code>（或<code>.zshrc</code>，如果使用的是zsh shell）为类似以下的内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=/home/$USER/anaconda/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>做完之后，你可以开启一个新窗口，或再次用<code>~/.bashrc</code>执行<code>.bashrc</code>。</p>
<h3><span id="安装或升级python包">安装或升级Python包</span></h3><p>在你阅读本书的时候，你可能想安装另外的不在Anaconda中的Python包。通常，可以用以下命令安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install package_name</span><br></pre></td></tr></table></figure>
<p>如果这个命令不行，也可以用pip包管理工具：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install package_name</span><br></pre></td></tr></table></figure>
<p>你可以用<code>conda update</code>命令升级包：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda update package_name</span><br></pre></td></tr></table></figure>
<p>pip可以用<code>--upgrade</code>升级：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install --upgrade package_name</span><br></pre></td></tr></table></figure>
<p>本书中，你有许多机会尝试这些命令。</p>
<blockquote>
<p>注意：当你使用conda和pip二者安装包时，千万不要用pip升级conda的包，这样会导致环境发生问题。当使用Anaconda或Miniconda时，最好首先使用conda进行升级。</p>
</blockquote>
<p>Python 2 和 Python 3</p>
<p>第一版的Python 3.x出现于2008年。它有一系列的变化，与之前的Python 2.x代码有不兼容的地方。因为从1991年Python出现算起，已经过了17年，Python 3 的出现被视为吸取一些列教训的更优结果。</p>
<p>2012年，因为许多包还没有完全支持Python 3，许多科学和数据分析社区还是在使用Python 2.x。因此，本书第一版使用的是Python 2.7。现在，用户可以在Python 2.x和Python 3.x间自由选择，二者都有良好的支持。</p>
<p>但是，Python 2.x在2020年就会到期（包括重要的安全补丁），因此再用Python 2.7就不是好的选择了。因此，本书使用了Python 3.6，这一广泛使用、支持良好的稳定版本。我们已经称Python 2.x为“遗留版本”，简称Python 3.x为“Python”。我建议你也是如此。</p>
<p>本书基于Python 3.6。你的Python版本也许高于3.6，但是示例代码应该是向前兼容的。一些示例代码可能在Python 2.7上有所不同，或完全不兼容。</p>
<h3><span id="集成开发环境ides和文本编辑器">集成开发环境（IDEs）和文本编辑器</span></h3><p>当被问到我的标准开发环境，我几乎总是回答“IPython加文本编辑器”。我通常在编程时，反复在IPython或Jupyter notebooks中测试和调试每条代码。也可以交互式操作数据，和可视化验证数据操作中某一特殊集合。在shell中使用pandas和NumPy也很容易。</p>
<p>但是，当创建软件时，一些用户可能更想使用特点更为丰富的IDE，而不仅仅是原始的Emacs或Vim的文本编辑器。以下是一些IDE：</p>
<ul>
<li>PyDev（免费），基于Eclipse平台的IDE；</li>
<li>JetBrains的PyCharm（商业用户需要订阅，开源开发者免费）；</li>
<li>Visual Studio（Windows用户）的Python Tools；</li>
<li>Spyder（免费），Anaconda附带的IDE；</li>
<li>Komodo IDE（商业）。</li>
</ul>
<p>因为Python的流行，大多数文本编辑器，比如Atom和Sublime Text 3，对Python的支持也非常好。</p>
<h2><span id="15-社区和会议">1.5 社区和会议</span></h2><p>除了在网上搜索，各式各样的科学和数据相关的Python邮件列表是非常有帮助的，很容易获得回答。包括：</p>
<ul>
<li>pydata：一个Google群组列表，用以回答Python数据分析和pandas的问题；</li>
<li>pystatsmodels： statsmodels或pandas相关的问题；</li>
<li>scikit-learn和Python机器学习邮件列表，scikit-learn@python.org；</li>
<li>numpy-discussion：和NumPy相关的问题；</li>
<li>scipy-user：SciPy和科学计算的问题；</li>
</ul>
<p>因为这些邮件列表的URLs可以很容易搜索到，但因为可能发生变化，所以没有给出。</p>
<p>每年，世界各地会举办许多Python开发者大会。如果你想结识其他有相同兴趣的人，如果可能的话，我建议你去参加一个。许多会议会对无力支付入场费和差旅费的人提供财力帮助。下面是一些会议：</p>
<ul>
<li>PyCon和EuroPython：北美和欧洲的两大Python会议；</li>
<li>SciPy和EuroSciPy：北美和欧洲两大面向科学计算的会议；</li>
<li>PyData：世界范围内，一些列的地区性会议，专注数据科学和数据分析；</li>
<li>国际和地区的PyCon会议（<a href="http://pycon.org有完整列表）">http://pycon.org有完整列表）</a> 。</li>
</ul>
<h2><span id="16-本书导航">1.6 本书导航</span></h2><p>如果之前从未使用过Python，那你可能需要先看看本书的第2章和第3章，我简要介绍了Python的特点，IPython和Jupyter notebooks。这些知识是为本书后面的内容做铺垫。如果你已经掌握Python，可以选择跳过。</p>
<p>接下来，简单地介绍了NumPy的关键特性，附录A中是更高级的NumPy功能。然后，我介绍了pandas，本书剩余的内容全部是使用pandas、NumPy和matplotlib处理数据分析的问题。我已经尽量让全书的结构循序渐进，但偶尔会有章节之间的交叉，有时用到的概念还没有介绍过。</p>
<p>尽管读者各自的工作任务不同，大体可以分为几类：</p>
<ul>
<li><p>与外部世界交互</p>
<p>阅读编写多种文件格式和数据存储；</p>
</li>
<li><p>数据准备</p>
<p>清洗、修改、结合、标准化、重塑、切片、切割、转换数据，以进行分析；</p>
</li>
<li><p>转换数据</p>
<p>对旧的数据集进行数学和统计操作，生成新的数据集（例如，通过各组变量聚类成大的表）；</p>
</li>
<li><p>建模和计算</p>
<p>将数据绑定统计模型、机器学习算法、或其他计算工具；</p>
</li>
<li><p>展示</p>
<p>创建交互式和静态的图表可视化和文本总结。</p>
</li>
</ul>
<h3><span id="代码示例">代码示例</span></h3><p>本书大部分代码示例的输入形式和输出结果都会按照其在IPython shell或Jupyter notebooks中执行时的样子进行排版：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [5]: CODE EXAMPLE</span><br><span class="line">Out[5]: OUTPUT</span><br></pre></td></tr></table></figure>
<p>但你看到类似的示例代码，就是让你在<code>in</code>的部分输入代码，按Enter键执行（Jupyter中是按Shift-Enter）。然后就可以在<code>out</code>看到输出。</p>
<h3><span id="示例数据">示例数据</span></h3><p>各章的示例数据都存放在GitHub上：<a href="http://github.com/pydata/pydata-book。">http://github.com/pydata/pydata-book。</a> 下载这些数据的方法有二：使用git版本控制命令行程序；直接从网站上下载该GitHub库的zip文件。如果遇到了问题，可以到我的个人主页，<a href="http://wesmckinney.com/，">http://wesmckinney.com/，</a> 获取最新的指导。</p>
<p>为了让所有示例都能重现，我已经尽我所能使其包含所有必需的东西，但仍然可能会有一些错误或遗漏。如果出现这种情况的话，请给我发邮件：wesmckinn@gmail.com。报告本书错误的最好方法是O’Reilly的errata页面，<a href="http://www.bit.ly/pyDataAnalysis_errata。">http://www.bit.ly/pyDataAnalysis_errata。</a></p>
<h3><span id="引入惯例">引入惯例</span></h3><p>Python社区已经广泛采取了一些常用模块的命名惯例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> statsmodels <span class="keyword">as</span> sm</span><br></pre></td></tr></table></figure>
<p>也就是说，当你看到np.arange时，就应该想到它引用的是NumPy中的arange函数。这样做的原因是：在Python软件开发过程中，不建议直接引入类似NumPy这种大型库的全部内容（from numpy import *）。</p>
<h3><span id="行话">行话</span></h3><p>由于你可能不太熟悉书中使用的一些有关编程和数据科学方面的常用术语，所以我在这里先给出其简单定义：</p>
<p>数据规整（Munge/Munging/Wrangling） 指的是将非结构化和（或）散乱数据处理为结构化或整洁形式的整个过程。这几个词已经悄悄成为当今数据黑客们的行话了。Munge这个词跟Lunge押韵。</p>
<p>伪码（Pseudocode） 算法或过程的“代码式”描述，而这些代码本身并不是实际有效的源代码。</p>
<p>语法糖（Syntactic sugar） 这是一种编程语法，它并不会带来新的特性，但却能使代码更易读、更易写。</p>
<p><a href="https://github.com/iamseancheney/python_for_data_analysis_2nd_chinese_version">参考</a></p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>利用python进行数据分析</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习路线</title>
    <url>/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="机器学习路线图">机器学习路线图</span></h1><h2><span id="入门课程">入门课程</span></h2><ol>
<li><a href="https://www.coursera.org/learn/machine-learning">Machine Learning | Coursera</a><br>入门首选，推荐只认识“机器学习”四个字但还不知道它是什么的学习这些年机器学习的大多数年轻人靠这个入门。具体提纲我就不列了，免得增加篇幅。建议是直接按顺序一课课学，不要着急。在学完这个课程前，不要学后面的。<br>关于这门课的官方介绍是：本课程将广泛介绍机器学习、数据挖掘和统计模式识别。相关主题包括：(i) 监督式学习（参数和非参数算法、支持向量机、核函数和神经网络）。(ii) 无监督学习（集群、降维、推荐系统和深度学习）。(iii) 机器学习实例（偏见/方差理论；机器学习和AI领域的创新）。课程将引用很多案例和应用，您还需要学习如何在不同领域应用学习算法，例如智能机器人（感知和控制）、文本理解（网络搜索和垃圾邮件过滤）、计算机视觉、医学信息学、音频、数据库挖掘等领域。这门课基本涵盖了机器学习的主要知识点，例如：线性回归、逻辑回归、支持向量机、神经网络、K-Means、异常检测等等。而且课程中没有复杂的公式推导和理论分析。Ng 的目的是让机器学习初学者能够快速对整个机器学习知识点有比较整体的认识，便于快速入门。</li>
</ol>
<p><img data-src="https://pic1.zhimg.com/v2-2b979310ac6c053b9a96a1e594824934_b.jpg" alt="img"></p>
<ol>
<li><p><a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual RecognitionStanford</a><br>最受欢迎的课之一.</p>
</li>
<li><p>机器学习体系图</p>
<p><img data-src="https://img-blog.csdnimg.cn/20190425205801254.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE2MDYzMDc=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</li>
</ol>
<h1><span id="引用链接">引用链接</span></h1><p><a href="https://www.nowcoder.com/tutorial/95/3cefbe4d0e914256b1271fe3417dded8">面试技巧</a><br><a href="https://www.nowcoder.com/discuss/experience?tagId=645">面经</a><br><a href="https://www.nowcoder.com/ta/review-ml">面试题</a><br><a href="https://www.bilibili.com/read/cv15624770">优质课程与资料汇总</a><br><a href="https://www.bilibili.com/read/cv15625299">优质电子书籍资料汇总</a></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>自己写一个数据库</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%87%AA%E5%B7%B1%E5%86%99%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="godb">godb</span></h1><blockquote>
<p>本项目中，数据库就是本地一个文件夹，表也是数据库下的目录，里面的数据就是表文件夹下的文件，<br>表目录下的scheme.json保存着表结构<br>表目录下data0.json data1.json分别存储着数据，每个文件里的数据不超过1000行。</p>
</blockquote>
<h2><span id="设计逻辑">设计逻辑</span></h2><ul>
<li>代码分为client端和server端</li>
<li>server端开启端口，接收指令，并执行指令</li>
<li>client端连接端口，发送指令</li>
<li>server端分层执行<ul>
<li>解析语句，判断类型，建库、建表、插入数据等等</li>
<li>不同类型语句进入不同service执行，互不干扰</li>
<li>验证语句，返回数据</li>
</ul>
</li>
</ul>
<h2><span id="建库">建库</span></h2><blockquote>
<p>暂时建表只支持这种格式，实际实现是在项目tmp目录下新建一个db1的文件夹</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database db1</span><br></pre></td></tr></table></figure>
<h2><span id="建表">建表</span></h2><blockquote>
<p>暂时只支持  ‘id’ 列名， varchar（255） 类型长度，以及默认值<br>以及主键<br>实际实现是在数据库目录下新建一个表名的文件夹，并有一个scheme.json文件记录各列属性</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span>  table1 (`id` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">  );</span><br></pre></td></tr></table></figure>
<h2><span id="插入数据">插入数据</span></h2><blockquote>
<p>支持语句格式,value 只支持一个括号，values支持多个括号多行数据插入<br>实际实现是在表文件夹下，新建data(i).json文件，里面存储具体数据，i是预留数据量大的情况下的分文件存储，每个文件暂时最多支持存储1000行。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> feature_conf <span class="keyword">values</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>// TODO</p>
<ul>
<li>[ ] 增加索引文件，指向data(i).json并指明多少列</li>
<li>[ ] 索引文件分层，类似B+树存储</li>
</ul>
]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>String.intern方法理解</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/String-intern%E6%96%B9%E6%B3%95%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="intern作用">intern作用</span></h2><blockquote>
<p>如果常量池中存在当前字符串, 就会直接返回当前字符串. 如果常量池中没有此字符串, 会将此字符串放入常量池中后, 再返回</p>
</blockquote>
<p>先明白含义是什么，再看一道题，copy美团的文章，详见参考一<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    String s = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    s.intern();</span><br><span class="line">    String s2 = <span class="string">&quot;1&quot;</span>;</span><br><span class="line">    System.out.println(s == s2);</span><br><span class="line"></span><br><span class="line">    String s3 = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>) + <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    s3.intern();</span><br><span class="line">    String s4 = <span class="string">&quot;11&quot;</span>;</span><br><span class="line">    System.out.println(s3 == s4);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>jdk7,8下false true<br>jdk6以下false false</p>
</blockquote>
<p>接下来把intern下移一行<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    String s = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    String s2 = <span class="string">&quot;1&quot;</span>;</span><br><span class="line">    s.intern();</span><br><span class="line">    System.out.println(s == s2);</span><br><span class="line"></span><br><span class="line">    String s3 = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>) + <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    String s4 = <span class="string">&quot;11&quot;</span>;</span><br><span class="line">    s3.intern();</span><br><span class="line">    System.out.println(s3 == s4);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>jdk7,8下false false<br>jdk6以下false false</p>
</blockquote>
<p>看完答案后，我是很懵逼的，我有看了美团文章的解释，瞬间，更懵逼了。美团文章解释的其实挺好的，但是没有抓住重点。<br>详细论证两篇文章都有，基本都能看明白（看不明白可以找我交流），重点在两点：</p>
<ul>
<li>jdk7、8和6有什么不同： 7以上将常量池从perm区移到了heap中</li>
<li>jdk7、8第一个程序中为什么一个是false，一个是true，<strong>jdk7以后常量去不仅仅可以保存对象，也可以保存对象的引用</strong>，所以s3的引用被保存到常量区中，s4直接在常量区找到了对象的引用，所以为true。</li>
</ul>
<p>有兴趣研究的同学，可以联系我，微信 ryry89，邮箱earyantLee@gmail.com</p>
<p><a href="https://tech.meituan.com/in_depth_understanding_string_intern.html">参考一</a><br><a href="https://www.cnblogs.com/Kidezyq/p/8040338.html">参考二</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>谷歌jib工具试用</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/%E8%B0%B7%E6%AD%8Cjib%E5%B7%A5%E5%85%B7%E8%AF%95%E7%94%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="jib">Jib</span></h1><p>好久没写blog了，最近看到google新开源的工具心痒痒，试着玩下~<br>首先什么是Jib，：</p>
<blockquote>
<p>Jib 是 Google 开发的可以直接构建 Java 应用的 Docker 和 OCI 镜像的类库，以 Maven 和 Gradle 插件形式提供。<br>通过 Jib，Java 开发者可以使用他们熟悉的 Java 工具来构建容器。Jib 是一个快速而简单的容器镜像构建工具，它负责处理将应用程序打包到容器镜像中所需的所有步骤。它不需要你编写 Dockerfile 或安装 Docker，而且可以直接集成到 Maven 和 Gradle中 —— 只需要将插件添加到构建中，就可以立即将 Java 应用程序容器化。</p>
</blockquote>
<h2><span id="构建流程">构建流程</span></h2><ul>
<li><p>Docker构建的复杂流程<br><img data-src="https://static.oschina.net/uploads/space/2018/0710/155927_vHQt_2720166.png" alt></p>
</li>
<li><p>Jib构建流程<br><img data-src="https://static.oschina.net/uploads/space/2018/0710/155918_xYRX_2720166.png" alt></p>
</li>
</ul>
<p>从此可以告别繁琐的Dockerfile啦~~</p>
<h2><span id="上手">上手</span></h2><ol>
<li><p>首先配置jib插件<br> maven:</p>
 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.cloud.tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jib-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">from</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">image</span>&gt;</span></span><br><span class="line">                        registry.hub.docker.com/adoptopenjdk/openjdk8</span><br><span class="line">          <span class="tag">&lt;/<span class="name">image</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">from</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">to</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">image</span>&gt;</span>registry.hub.docker.com/earyant/earyant<span class="tag">&lt;/<span class="name">image</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">to</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p> gradle</p>
 <figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">plugins &#123;</span><br><span class="line">  id <span class="string">&#x27;com.google.cloud.tools.jib&#x27;</span> version <span class="string">&#x27;0.9.6&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">jib.to.image = <span class="string">&#x27;registry.hub.docker.com/earyant/earyant&#x27;</span></span><br><span class="line">jib.<span class="keyword">from</span>.image = <span class="string">&#x27;registry.hub.docker.com/adoptopenjdk/openjdk8&#x27;</span></span><br></pre></td></tr></table></figure>
<hr>
<p>需要注意的是image不加域名的话，默认是gcr.io,google Cloud下的镜像，<strong>需要梯子</strong>，所以没有梯子的话，请使用 registry.hub.docker.com,阿里云加速同理</p>
</li>
</ol>
<p>如果不加from标签，也是默认访问grc.io去下载jdk镜像，emmmm，同样需要梯子，报错如下：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Build to Docker daemon failed: Connect to gcr.io/108.177.97.82:443 timed out</span><br></pre></td></tr></table></figure><br>所以记得加上from镜像标签哦~~</p>
<p>如果报错信息如下，请先登录docker login -name=earyant registry.hub.docker.com  ，如果没有注册过，请到docker官网注册~<br>Retrieving registry credentials for registry.hub.docker.com</p>
<ol>
<li>Build</li>
</ol>
<ul>
<li><p>build到远程仓库</p>
<ul>
<li>gradle jib</li>
<li>mvn compile jib:build</li>
</ul>
</li>
<li><p>本地运行（确保本地docker已运行 ）</p>
<ul>
<li>mvn compile jib:dockerBuild</li>
<li>gradle jibDockerBuild</li>
</ul>
</li>
</ul>
<ol>
<li>运行<br>本地镜像查看如下：<br>docker images<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">earyant/earyant       latest              e34b4cad637b        48 years ago        367MB</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>docker run -p 8880:8880  -it —rm —name earyant registry.hub.docker.com/earyant/earyant</p>
<p>访问 <a href="http://localhost:8880">http://localhost:8880</a> 即可纵享丝滑，开心~~~</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>持续实战</title>
    <url>/posts/java/%E6%8C%81%E7%BB%AD%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><ul>
<li>[ ] mysql主从配置</li>
<li>[ ] mybatis自动生成代码</li>
<li>[ ] 读写分离，与主从配置相关联</li>
<li>[ ] 分布式redis缓存</li>
<li>[ ] tomcat session共享、session绑定</li>
<li>[ ] 分布式锁：redis、mysql</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>持续实战</tag>
      </tags>
  </entry>
  <entry>
    <title>jvm系列</title>
    <url>/posts/java/jvm/jvm%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="jvm系列一java类的加载机制"></span></h2><ul>
<li><p>什么是类的加载</p>
<blockquote>
<p>类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。</p>
</blockquote>
</li>
<li><p>类的生命周期</p>
<ul>
<li>加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象</li>
<li>连接，连接又包含三块内容：验证、准备、初始化。1）验证，文件格式、元数据、字节码、符号引用验证；2）准备，为类的静态变量分配内存，并将其初始化为默认值；3）解析，把类中的符号引用转换为直接引用</li>
<li>初始化，为类的静态变量赋予正确的初始值</li>
<li>使用，new出对象程序中使用</li>
<li>卸载，执行垃圾回收</li>
</ul>
</li>
<li><p>类加载器</p>
<ul>
<li><p>启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库</p>
</li>
<li><p>扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载DK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。</p>
</li>
<li><p>应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器</p>
</li>
</ul>
</li>
<li><p>双亲委派模型</p>
<pre><code>\-  全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入

- 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类

- 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效
</code></pre><h2><span id="jvm系列二jvm内存结构"></span></h2><p><img data-src="http://mmbiz.qpic.cn/mmbiz_png/PgqYrEEtEnprm5p8TE8Ogn2WfVM3YUA5R55vvKcRJC1UXBVrjuEJuLOxD6woyWpicufMicSZbZTpLrGrNrr0cmAQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt></p>
</li>
</ul>
<blockquote>
<p>方法区和堆是所有线程共享的内存区域；而java栈、本地方法栈和程序计数器是运行是线程私有的内存区域。</p>
</blockquote>
<ul>
<li><p>Java堆（Heap）,是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。</p>
</li>
<li><p>方法区（Method Area）,方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。</p>
</li>
<li><p>程序计数器（Program Counter Register）,程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。</p>
</li>
<li><p>JVM栈（JVM Stacks）,与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p>
</li>
<li><p>本地方法栈（Native Method Stacks）,本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。</p>
</li>
</ul>
<h3><span id="对象分配规则">对象分配规则</span></h3><ul>
<li><p>对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。</p>
</li>
<li><p>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。</p>
</li>
<li><p>长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，知道达到阀值对象进入老年区。</p>
</li>
<li><p>动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。</p>
</li>
<li><p>空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。</p>
</li>
</ul>
<h2><span id="jvm系列三gc算法-垃圾收集器"></span></h2><h3><span id="对象存活判断">对象存活判断</span></h3><blockquote>
<p>判断对象是否存活一般有两种方式：</p>
</blockquote>
<ul>
<li><p>引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。</p>
</li>
<li><p>可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，不可达对象。</p>
</li>
</ul>
<h3><span id="gc算法">GC算法</span></h3><ul>
<li><p>GC最基础的算法有三种：标记 -清除算法、复制算法、标记-压缩算法，我们常用的垃圾回收器一般都采用分代收集算法。</p>
</li>
<li><p>标记 -清除算法，“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。</p>
</li>
<li><p>复制算法，“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</p>
</li>
<li><p>标记-压缩算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</p>
</li>
<li><p>分代收集算法，“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。</p>
</li>
</ul>
<h3><span id="垃圾回收器">垃圾回收器</span></h3><ul>
<li><p>Serial收集器，串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。</p>
</li>
<li><p>ParNew收集器，ParNew收集器其实就是Serial收集器的多线程版本。</p>
</li>
<li><p>Parallel收集器，Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。</p>
</li>
<li><p>Parallel Old 收集器，Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法</p>
</li>
<li><p>CMS收集器，CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。</p>
</li>
<li><p>G1收集器，G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征</p>
</li>
</ul>
<p>在Java语言中，GC Roots包括：</p>
<ul>
<li>虚拟机栈中引用的对象。</li>
<li>方法区中类静态属性实体引用的对象。</li>
<li>方法区中常量引用的对象。</li>
<li>本地方法栈中JNI引用的对象。</li>
</ul>
<h2><span id="jvm系列四jvm调优-命令篇"></span></h2><h3><span id="调优命令">调优命令</span></h3><blockquote>
<p>  Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo</p>
</blockquote>
<ul>
<li>jps，JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。</li>
<li>jstat，JVM statistics Monitoring是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。</li>
<li>jmap，JVM Memory Map命令用于生成heap dump文件</li>
<li>jhat，JVM Heap Analysis Tool命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看</li>
<li>jstack，用于生成java虚拟机当前时刻的线程快照。</li>
<li>jinfo，JVM Configuration info 这个命令作用是实时查看和调整虚拟机运行参数。</li>
</ul>
<h2><span id="jvm系列五java-gc-分析"></span></h2><h3><span id="主要关注点">主要关注点：</span></h3><ul>
<li><p>GC日志分析</p>
</li>
<li><p>调优命令</p>
</li>
<li>调优工具</li>
</ul>
<p><a href="https://earyant.github.io/2018/05/04/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E8%84%9A%E6%9C%AC/">参考</a><br><a href="https://earyant.github.io/2018/05/04/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">参考</a></p>
<h2><span id="jvm系列六java服务gc参数调优案例"></span></h2><p>##<a href="https://mp.weixin.qq.com/s?__biz=MzI4NDY5Mjc1Mg==&amp;mid=2247484023&amp;idx=1&amp;sn=39be119fdf3132240adc84a85bf8a054&amp;chksm=ebf6da08dc81531e3719389555150f2d0237554b6b6c07a123efdea7c78c0ae2f064cc577bd4&amp;scene=21#wechat_redirect">jvm系列(七):jvm调优-工具篇</a></p>
<blockquote>
<p>调优工具</p>
</blockquote>
<ul>
<li>常用调优工具分为两类,jdk自带监控工具：jconsole和jvisualvm，第三方有：MAT(Memory Analyzer Tool)、GChisto。</li>
<li>jconsole，Java Monitoring and Management Console是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控</li>
<li>jvisualvm，jdk自带全能工具，可以分析内存快照、线程快照；监控内存变化、GC变化等。</li>
<li>MAT，Memory Analyzer Tool，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗</li>
<li>GChisto，一款专业分析gc日志的工具</li>
</ul>
<h2><span id="jvm系列八jvm知识点总览"></span></h2><h2><span id="jvm系列九如何优化java-gc译"></span></h2><h2><span id="jvm系列十教你如何成为java的oom-killer"></span></h2><h2><span id="jvm系列十一java-8-从持久代到metaspace"></span></h2>]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>日志分析脚本</title>
    <url>/posts/%E5%B7%A5%E5%85%B7%E7%B1%BB/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="sed编辑器">sed编辑器</span></h2><p>不修改原内容的行级别流编辑器</p>
<ul>
<li><p>sed ‘s/baidu /earyant/‘ access.log | head -10</p>
<blockquote>
<p>将日志文件中的baidu替换成earyant输出<br>s表示执行的事文本替换命令</p>
</blockquote>
</li>
<li><p>sed -n ‘2,6p’ access.log</p>
<blockquote>
<p>-n表示只输出指定的行，’2,6p’表示选择的事第二行到第六行</p>
</blockquote>
</li>
<li><p>sed ‘/earyant/d’ access.log</p>
<blockquote>
<p>d表示执行文本删除命令，将包含earyant的行删除</p>
</blockquote>
</li>
<li><p>sed ‘=’ access.log</p>
<blockquote>
<p>显示文本行号</p>
</blockquote>
</li>
<li><p>sed -e ‘i\head’ access.log | head -10</p>
<blockquote>
<p>在行首插入文本</p>
</blockquote>
</li>
<li><p>sed -e ‘a\end’ access.log | head -10</p>
<blockquote>
<p> 在文末追加文本</p>
</blockquote>
</li>
<li><p>sed -e ‘/baidu/c\hello’ access.log | head -10</p>
<blockquote>
<p>c命令对文本进行替换，查找/baidu/匹配的行，用hello对匹配的行进行替换，与s不同的是，这个替换行，s是替换单词</p>
</blockquote>
</li>
<li>sed -n ‘1,5p;1,5=’ access.log<blockquote>
<p>多条命令，分号隔开</p>
</blockquote>
</li>
</ul>
<h2><span id="awk">awk</span></h2><ul>
<li>awk ‘{print $1}’ access.log | head -10<blockquote>
<p>打印指定的列</p>
</blockquote>
</li>
<li>awk ‘/baidu/{print $5,%6}’ access.log | head -10<blockquote>
<p>筛选指定的行，并且打印出其中一部分列</p>
</blockquote>
</li>
<li><p>awk ‘length{$0} &gt; 40 {print $3}’ access.log | head  -10</p>
<blockquote>
<p>$0 表示当前的行，length($0)获取当前行的长度，print $3 打印出第三列</p>
</blockquote>
</li>
<li><p>awk ‘{line = sprintf (“method:%s,response:%s”,$3,$7); print line}’ access.log | head -10</p>
<blockquote>
<p>定义line接收sprintf输出，sprintf用户格式化输出第三行的请求式和第七行的响应时间</p>
</blockquote>
</li>
</ul>
<h2><span id="shell">shell</span></h2><ul>
<li>系统load超过2或者磁盘利用率超过85%报警：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#earyantlee@gmail.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#top取系统load值， -n 1 表示只刷新一次</span></span><br><span class="line"><span class="comment"># sed 过滤第一行</span></span><br><span class="line"><span class="comment"># top命令会输出1分钟、5分钟、15分钟load的平均值，awk筛选出1分钟内的平均load，赋值给load</span></span><br><span class="line">load = `top -n 1| sed -n <span class="string">&#x27;1p&#x27;</span> | awk <span class="string">&#x27;&#123;print $11&#125;&#x27;</span>`</span><br><span class="line"><span class="comment"># 从右边开始，过滤掉不需要的逗号</span></span><br><span class="line">load = <span class="variable">$&#123;load%\,*&#125;</span></span><br><span class="line"><span class="comment"># df取得磁盘利用率信息，用sed筛选磁盘总利用率第二行</span></span><br><span class="line">disk_usage = `df -h | sed -n <span class="string">&#x27;2p&#x27;</span> |awk <span class="string">&#x27;&#123;print $(NF - 1)&#125;&#x27;</span> `</span><br><span class="line"><span class="comment"># 过滤掉百分号</span></span><br><span class="line">disk_usage = <span class="variable">$&#123;disk_usage%\%*&#125;</span></span><br><span class="line">overhead = `expr <span class="variable">$load</span> \&gt; 2.00`</span><br><span class="line"><span class="keyword">if</span> [<span class="variable">$overhead</span> -eq 1];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&quot;System load is overhead&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [<span class="variable">$disk_usage</span> -gt 85 ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&quot;disk is nearly full ,need more disk space&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>
<ul>
<li>读取日志文件，对字段切割，插入到sql。<br>db:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table access_log(</span><br><span class="line">  ip varchar(20),# ip地址</span><br><span class="line">  rt bigint,# 响应时间</span><br><span class="line">  method varchar(10), #请求方式</span><br><span class="line">  url varchar (400), # 请求地址</span><br><span class="line">  refer varchar(400),# 请求来源</span><br><span class="line">  return_code int,# 返回码</span><br><span class="line">  response_size bigint # 响应大小</span><br><span class="line">  );</span><br></pre></td></tr></table></figure>
<p>shell:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#earyantlee@gmail.com</span></span><br><span class="line"><span class="comment"># 日志路径</span></span><br><span class="line">ACCESS_FILE=<span class="string">&quot;D:\\0\\nginx-1.11.13\\logs\\access2.log&quot;</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">read</span> LINE</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="comment"># 系统数组分隔符</span></span><br><span class="line">  OLD_IFS=<span class="string">&quot;<span class="variable">$IFS</span>&quot;</span></span><br><span class="line">  IFS=<span class="string">&quot; &quot;</span></span><br><span class="line">  <span class="comment"># 每行分割成数组</span></span><br><span class="line">  field_arr=(<span class="variable">$LINE</span>)</span><br><span class="line">  IFS=<span class="string">&quot;<span class="variable">$OLD_IFS</span>&quot;</span></span><br><span class="line">  <span class="comment"># 生成插入语句，各列的值对应什么，懒得改了。</span></span><br><span class="line">  STATEMENT=<span class="string">&quot;insert into access_log values(&#x27;<span class="variable">$&#123;field_arr[0]&#125;</span>&#x27; , &#x27;<span class="variable">$&#123;field_arr[1]&#125;</span>&#x27;, &#x27;<span class="variable">$&#123;field_arr[2]&#125;</span>&#x27;, &#x27;<span class="variable">$&#123;field_arr[3]&#125;</span>&#x27;, &#x27;<span class="variable">$&#123;field_arr[4]&#125;</span>&#x27;, &#x27;<span class="variable">$&#123;field_arr[5]&#125;</span>&#x27;, &#x27;<span class="variable">$&#123;field_arr[6]&#125;</span>&#x27;);&quot;</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$STATEMENT</span></span><br><span class="line">  mysql earyant -u root -p123456 -e <span class="string">&quot;<span class="variable">$&#123;STATEMENT&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">done</span> &lt; <span class="variable">$ACCESS_FILE</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>日志分析常用命令</title>
    <url>/posts/%E5%B7%A5%E5%85%B7%E7%B1%BB/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="查看文件的内容">查看文件的内容</span></h2><ul>
<li><p>cat：正序查看</p>
<blockquote>
<p>cat access.log</p>
</blockquote>
</li>
<li><p>tac：倒序查看</p>
<blockquote>
<p>tac access.log</p>
</blockquote>
</li>
</ul>
<h2><span id="分页显示文件">分页显示文件</span></h2><ul>
<li><p>more</p>
<blockquote>
<p>more access.log</p>
</blockquote>
<p> Enter显示文件下一行<br> 空格显示下一页<br> F显示下一屏内容<br> B显示上一屏内容</p>
</li>
<li><p>less</p>
<blockquote>
<p>/GET 查找GET字符串</p>
</blockquote>
</li>
</ul>
<h2><span id="显示文件尾">显示文件尾</span></h2><ul>
<li><p>tail</p>
<blockquote>
<p>tail  -f -n 500 access.log</p>
</blockquote>
<p> -f  持续查看<br> -n 显示最后n行</p>
</li>
</ul>
<h2><span id="显示文件头">显示文件头</span></h2><ul>
<li>head<blockquote>
<p>head -n2 access.log</p>
</blockquote>
</li>
</ul>
<h2><span id="内容排序">内容排序</span></h2><ul>
<li><p>sort</p>
<blockquote>
<p>sort -n -r access.log</p>
</blockquote>
<p> -n 按照数字排序<br> -r 逆序排序</p>
<blockquote>
<p>sort -k 2 -t “ “ -n access.log</p>
</blockquote>
<p> -k 指定排序的列<br> -t 指定列分隔符<br> -n 按照数字排序</p>
</li>
</ul>
<h2><span id="字符统计">字符统计</span></h2><ul>
<li><p>wc</p>
<blockquote>
<p>  wc -l access.log</p>
</blockquote>
<p>  -l 统计文件中的行数</p>
<blockquote>
<p>  wc -c access.log</p>
</blockquote>
<p>  -c 显示文件的字节数</p>
<blockquote>
<p>  wc -L access.log</p>
</blockquote>
<p>  -L得出最长的行长度</p>
<blockquote>
<p>  wc -w access.log</p>
</blockquote>
<p>  -w 查看文件包含多少单词</p>
</li>
</ul>
<h2><span id="重复行">重复行</span></h2><ul>
<li><p>uniq</p>
<blockquote>
<p> sort uniqfile| uniq -c</p>
</blockquote>
<p>  -c 用来在每一行前面加上该行出现的次数</p>
<blockquote>
<p>  sort uniqfile | uniq -c -u</p>
</blockquote>
<p>  -u 只会显示出现一次的行</p>
<blockquote>
<p>  sort uniqfile | uniq -c -d</p>
</blockquote>
<p>  -d 只会显示重复出现的行</p>
</li>
</ul>
<h2><span id="字符串查找">字符串查找</span></h2><ul>
<li><p>grep</p>
<pre><code>&gt;   grep earyant access.log

  earyant 为指定的查找串

&gt; grep -c earyant access.log

  -c 可以显示查找到的行数

&gt;   grep &#39;G.\*T&#39; access.log

  支持正则表达式
</code></pre><h2><span id="文件查找">文件查找</span></h2></li>
<li><p>find</p>
<blockquote>
<p>find /home/earyant -name access.log</p>
</blockquote>
<p>   在/home/earyant 目录下查找文件名为access.log的文件</p>
<blockquote>
<p>find /home/earyant -name “*.txt”</p>
<p>find . -print</p>
</blockquote>
<p>   打印当前目录所有文件</p>
</li>
<li><p>whereis</p>
<blockquote>
<p>whereis java</p>
</blockquote>
</li>
<li>which<blockquote>
<p>which java</p>
</blockquote>
</li>
</ul>
<h2><span id="表达式求值">表达式求值</span></h2><ul>
<li>expr<blockquote>
<p>expr 10 * 3<br>expr 10 % 3<br>expr index “earyant.github.io” earyant</p>
</blockquote>
</li>
</ul>
<h2><span id="压缩">压缩</span></h2><ul>
<li><p>tar</p>
<blockquote>
<p>tar -cf aaa.tar tmp1 tmp2</p>
</blockquote>
<pre><code>将当前目录下的tmp1和tmp2目录打包成aaa.tar
-c 表示生成新包
-f 指定包名称
</code></pre><blockquote>
<p>tar -tf aaa.tar</p>
</blockquote>
<pre><code>-t 能够列出包中文件的名称
</code></pre><blockquote>
<p>tar -xf aaa.tar</p>
</blockquote>
<pre><code>-x 将打包文件解压
</code></pre></li>
</ul>
<h2><span id="url-访问工具">url 访问工具</span></h2><ul>
<li><p>curl</p>
<blockquote>
<p>curl www.baidu.com</p>
<p>curl -i www.baidu.com</p>
</blockquote>
<p>-i 返回带header的文档</p>
<blockquote>
<p>curl -I www.baidu.com</p>
</blockquote>
<p>-I 只返回页面的header信息</p>
<h2><span id="查看请求访问量">查看请求访问量</span></h2></li>
</ul>
<blockquote>
<p>cat access.log | cut -f1 -d “ “ | sort | uniq -c | sort -k 1 -n -r | head -10</p>
</blockquote>
<p>访问量排名前10的ip地址</p>
<blockquote>
<p>cat  access.log | cut  -f4 -d “ “ | sort | uniq -c | sort -k 1 -n -r | head -10</p>
</blockquote>
<p>页面访问量排名前10的url</p>
<h2><span id="查看最耗时的页面">查看最耗时的页面</span></h2><blockquote>
<p>cat access.log | sort -k 2 -n -r |head -10</p>
</blockquote>
<h2><span id="统计404请求的占比">统计404请求的占比</span></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export total_line = `wc -l access.log | cut -f1 -d &quot; &quot;` &amp;&amp; export not_found_line = `awk &#x27;$6==&#x27;404&#x27;&#123;print $6&#125;&#x27; access.log | wc -l`  &amp;&amp; expr $ not_found_line \*100 / $total_line</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>Guava 1.1基本工具</title>
    <url>/posts/java/Guava-1-1%E5%9F%BA%E6%9C%AC%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="11-使用和避免null">1.1-使用和避免null</span></h1><p>map允许null作为键，但只能有一个。<br>concurrentHashMap不允许null作为键。</p>
<h2><span id="optional">Optional</span></h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Optional&lt;Integer&gt; possible = Optional.of(<span class="number">5</span>);</span><br><span class="line">possible.isPresent(); <span class="comment">// returns true</span></span><br><span class="line">possible.get(); <span class="comment">// returns 5</span></span><br></pre></td></tr></table></figure>
<h3><span id="静态创建方法">静态创建方法</span></h3><ul>
<li>of</li>
<li>ofNullable</li>
<li>empty<h3><span id="实例方法">实例方法</span></h3></li>
<li>isPresent</li>
<li>get</li>
<li>or (jdk中是orElse)</li>
<li>orNull</li>
<li>asSet</li>
</ul>
<blockquote>
<p>意义：<br>    使用Optional除了赋予null语义，增加了可读性，最大的优点在于它是一种傻瓜式的防护。Optional迫使你积极思考引用缺失的情况，因为你必须显式地从Optional获取引用。直接使用null很容易让人忘掉某些情形，尽管FindBugs可以帮助查找null相关的问题，但是我们还是认为它并不能准确地定位问题根源。<br>    如同输入参数，方法的返回值也可能是null。和其他人一样，你绝对很可能会忘记别人写的方法method(a,b)会返回一个null，就好像当你实现method(a,b)时，也很可能忘记输入参数a可以为null。将方法的返回类型指定为Optional，也可以迫使调用者思考返回的引用缺失的情形。</p>
</blockquote>
<h3><span id="使用方式">使用方式：</span></h3><ul>
<li>错误的使用方式：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Optional&lt;User&gt; user = Optional.ofNullable(user);</span><br><span class="line"><span class="keyword">if</span> (user.isPresent()) &#123;</span><br><span class="line">  <span class="keyword">int</span> sex = user.getSex();</span><br><span class="line">  <span class="comment">// 链式调用，最容易出现空指针</span></span><br><span class="line">  <span class="keyword">int</span> age = user.getParent().getParent().getParent().getAge();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>正确的使用方式<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Optional&lt;User&gt; user = Optional.ofNullable(user);</span><br><span class="line"><span class="keyword">int</span> sex = user.map(User::getSex).orElse(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">int</span> age = user.map(User::getParent).map(User::getParent).map(User::getParent).map(User::getAge).orElse(<span class="number">0</span>);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2><span id="其他处理null的便利方法">其他处理null的便利方法</span></h2><ul>
<li>Objects.firstNonNull(T, T)</li>
<li>Objects还有其它一些方法专门处理null或空字符串：emptyToNull(String)，nullToEmpty(String)，isNullOrEmpty(String)。</li>
</ul>
<h1><span id="12-前置条件-preconditions">1.2-前置条件 Preconditions</span></h1><div class="table-container">
<table>
<thead>
<tr>
<th>—</th>
<th>—</th>
<th>—</th>
</tr>
</thead>
<tbody>
<tr>
<td>方法声明（不包括额外参数）</td>
<td>描述</td>
<td>检查失败时抛出的异常</td>
</tr>
<tr>
<td>checkArgument(boolean)</td>
<td>检查boolean是否为true，用来检查传递给方法的参数。</td>
<td>IllegalArgumentException</td>
</tr>
<tr>
<td>checkNotNull(T)</td>
<td>检查value是否为null，该方法直接返回value，因此可以内嵌使用checkNotNull。</td>
<td>NullPointerException</td>
</tr>
<tr>
<td>checkState(boolean)</td>
<td>用来检查对象的某些状态。</td>
<td>IllegalStateException</td>
</tr>
<tr>
<td>checkElementIndex(int index, int size)</td>
<td>检查index作为索引值对某个列表、字符串或数组是否有效</td>
<td>IndexOutOfBoundsException</td>
</tr>
<tr>
<td>checkPositionIndex(int index, int size)</td>
<td>检查index作为位置值对某个列表、字符串或数组是否有效。</td>
<td>IndexOutOfBoundsException</td>
</tr>
<tr>
<td>checkPositionIndexes(int start, int end, int size)</td>
<td>检查[start, end]表示的位置范围对某个列表、字符串或数组是否有效*</td>
<td>IndexOutOfBoundsException</td>
</tr>
</tbody>
</table>
</div>
<p><a href="http://ifeve.com/google-guava-using-and-avoiding-null/">参考</a></p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>Guava</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK1.5-JDK1.8各个新特性</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/JDK1-5-JDK1-8%E5%90%84%E4%B8%AA%E6%96%B0%E7%89%B9%E6%80%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://juejin.im/entry/5ab860ce5188255587238a36?utm_source=gold_browser_extension">转载来源</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java内存模型</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://ifeve.com/jmm-faq/">参考</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>情深不寿</title>
    <url>/posts/%E6%95%A3%E6%96%87%E8%AF%97/%E6%83%85%E6%B7%B1%E4%B8%8D%E5%AF%BF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>如果我孑身一人是个赛车手<br>无牵无挂，无畏无惧<br>即使受伤、死亡<br>也会为我爱的事倾尽所有</p>
<p>如果我生在乱世是个将军<br>交出我爱的人换取一时和平<br>不要和我讲大义<br>提枪上马，马革裹尸不休</p>
]]></content>
      <categories>
        <category>散文诗</category>
      </categories>
      <tags>
        <tag>散文诗</tag>
      </tags>
  </entry>
  <entry>
    <title>爱吃西瓜</title>
    <url>/posts/%E6%95%A3%E6%96%87%E8%AF%97/%E7%88%B1%E5%90%83%E8%A5%BF%E7%93%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>最甜的是西瓜中间的那口</p>
<p>可我连籽都吃掉</p>
<p>我爱的东西本来就不多</p>
<p>爱就爱它的所有</p>
]]></content>
      <categories>
        <category>散文诗</category>
      </categories>
      <tags>
        <tag>散文诗</tag>
      </tags>
  </entry>
  <entry>
    <title>docker简单结合elk、logstash</title>
    <url>/posts/java/docker%E7%AE%80%E5%8D%95%E7%BB%93%E5%90%88elk%E3%80%81logstash/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="本文记录docker搭建elk并简单结合logstash日志输出">本文记录docker搭建elk，并简单结合logstash日志输出</span></h2><h3><span id="filebeat">filebeat</span></h3><blockquote>
<p>docker pull docker.elastic.co/beats/filebeat:6.2.1</p>
</blockquote>
<ul>
<li>filebeat.yml<br><strong>enabled要改为true，filebeat默认为false</strong><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">    - D:\workspace\baidu\baiyi\baidu\dsp\dsp-main-server\log\*.log</span><br><span class="line">output:</span><br><span class="line">    logstash:</span><br><span class="line">          hosts: [&quot;192.168.99.100:5044&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>docker run -it —name filebeat -v /data/filebeat.yml::/usr/share/filebeat/filebeat.yml</p>
</blockquote>
</li>
</ul>
<h3><span id="logstash">logstash</span></h3><p>改写/opt/logstash/logstash/config/logstash.yml文件</p>
<ul>
<li>logstash.yml</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input&#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; 5044</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output&#123;</span><br><span class="line">    stdout&#123; codec =&gt; rubydebug &#125;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; &quot;192.168.99.100:9200&quot;</span><br><span class="line">        index =&gt;  &quot;t-server-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        document_type =&gt; &quot;log4j_type&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>logstash</tag>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title>docker简单部署elk服务</title>
    <url>/posts/java/docker%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2elk%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="本文章记录自己通过docker搭建elk的过程">本文章记录自己通过docker搭建elk的过程</span></h1><h2><span id="docker下载镜像">docker下载镜像</span></h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker pull sebp/elk :latest</span><br></pre></td></tr></table></figure>
<h2><span id="docker-至少分配3g内存">docker 至少分配3g内存</span></h2><p>elasticsearch 至少需要2g，logstash至少需要1g</p>
<h2><span id="设置最大运行线程数">设置最大运行线程数</span></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">最大线程数要超过262144</span><br></pre></td></tr></table></figure>
<ul>
<li><p>使用docker toolbox方式 先进入虚拟机</p>
<blockquote>
<p>docker-machine ssh default</p>
</blockquote>
</li>
<li><p>永久生效配置</p>
<blockquote>
<p>sudo vi /etc/sysctl.conf</p>
<p>vm.max_map_count=262144</p>
<p>sudo sysctl -p //生效</p>
</blockquote>
</li>
<li><p>临时生效配置</p>
<blockquote>
<p>sysctl -w vm.max_map_count=262144</p>
</blockquote>
</li>
</ul>
<h2><span id="启动">启动</span></h2><p>启动，并配置端口映射</p>
<blockquote>
<p>docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -it —name elk sebp/elk</p>
</blockquote>
<h2><span id="查看kibana">查看kibana</span></h2><p>打开网址 http:\192.168.99.100:5601 若打开成功说明部署成功</p>
<h2><span id="配置使用">配置使用</span></h2><ol>
<li><p>进入容器</p>
<blockquote>
<p>docker exec -it elk /bin/bash</p>
</blockquote>
</li>
<li><p>配置logstash</p>
<blockquote>
<p>/opt/logstash/bin/logstash -e ‘input { stdin { } } output { elasticsearch { hosts =&gt; [“localhost”] } }’</p>
<p><strong>注意</strong>：如果看到这样的报错信息 Logstash could not be started because there is already another instance using the configured data directory. If you wish to run multiple instances, you must change the “path.data” setting. 请执行命令：service logstash stop 然后在执行就可以了。</p>
<p>当命令成功被执行后，看到：Successfully started Logstash API endpoint {:port=&gt;9600} 信息后，输入：test 然后回车，模拟一条日志进行测试。</p>
<ol>
<li>打开浏览器，输入：<a href="http://192.168.99.100:9200/_search?pretty">http://192.168.99.100:9200/_search?pretty</a> ，就会看到我们刚刚输入的日志内容</li>
<li>创建kibana与logstash关联</li>
<li>index name or pattern 输入 logstash-*</li>
<li>time-field name 输入 @timestamp</li>
<li>create</li>
<li>打开kibana首页即可看到刚刚输入的内容</li>
</ol>
</blockquote>
</li>
</ol>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title>java8新特性</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java8%E6%96%B0%E7%89%B9%E6%80%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="java8新特性">java8新特性</span></h1><h2><span id="lambda表达式">lambda表达式</span></h2><blockquote>
<p>java8接受一个函数作为另一个函数的参数传入进去</p>
</blockquote>
<p>Arrays.asList( “a”, “b”, “d” ).forEach( e -&gt; System.out.println( e ) ); 参数的类型是编译器推断出来的</p>
<blockquote>
<p>Lambda可以引用类的成员变量与局部变量（如果这些变量不是final的话，它们会被隐含的转为final，这样效率更高）。</p>
</blockquote>
<h2><span id="默认方法和静态方法">默认方法和静态方法</span></h2><blockquote>
<p>在JVM中，默认方法的实现是非常高效的，并且通过字节码指令为方法调用提供了支持。默认方法允许继续使用现有的Java接口，而同时能够保障正常的编译过程。这方面好的例子是大量的方法被添加到java.util.Collection接口中去：stream()，parallelStream()，forEach()，removeIf()，……</p>
</blockquote>
<h2><span id="重复注解">重复注解</span></h2><h2><span id="java编译器的新特性">Java编译器的新特性</span></h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ParameterNames</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Method method = ParameterNames.class.getMethod( <span class="string">&quot;main&quot;</span>, String[].class );</span><br><span class="line">        <span class="keyword">for</span>( <span class="keyword">final</span> Parameter parameter: method.getParameters() ) &#123;</span><br><span class="line">            System.out.println( <span class="string">&quot;Parameter: &quot;</span> + parameter.getName() );</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Parameter: args</p>
</blockquote>
<p>对于有经验的Maven用户，通过maven-compiler-plugin的配置可以将-parameters参数添加到编译器中去。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">compilerArgument</span>&gt;</span>-parameters<span class="tag">&lt;/<span class="name">compilerArgument</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2><span id="java-类库的新特性">Java 类库的新特性</span></h2><h3><span id="optional">Optional</span></h3><p>平时用的判空：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">get</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (name == <span class="keyword">null</span>)&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">  &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> name;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>改成Optional：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">get</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">  Optional&lt;String &gt; names = Opntional.of(name);</span><br><span class="line">  <span class="keyword">if</span> (names.isPresent())&#123;</span><br><span class="line">      <span class="keyword">return</span> names.get();</span><br><span class="line">  &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果单纯改成这样，还不如直接写成 ==null，看起来更加繁琐。 应该改成这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">get</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> Opntional.of(name).get().orElse(<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3><span id="stream">Stream</span></h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="keyword">long</span> totalPointsOfOpenTasks = tasks</span><br><span class="line">    .stream()</span><br><span class="line">    .filter( task -&gt; task.getStatus() == Status.OPEN )</span><br><span class="line">    .mapToInt( Task::getPoints )</span><br><span class="line">    .sum();</span><br></pre></td></tr></table></figure>
<h4><span id="filter">filter</span></h4><blockquote>
<p>对于Stream中包含的元素使用给定的过滤函数进行过滤操作，新生成的Stream只包含符合条件的元素；</p>
</blockquote>
<h4><span id="map">map</span></h4><blockquote>
<p>映射转换</p>
</blockquote>
<h4><span id="mapto">mapTo*</span></h4><blockquote>
<p>映射转换成 <em>的类型，</em> 包括Integer、Double、Long</p>
</blockquote>
<h4><span id="flatmap">flatMap</span></h4><blockquote>
<p>合并集合,和map类似，不同的是其每个元素转换得到的是Stream对象，会把子Stream中的元素压缩到父集合中；</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#123;1,2&#125;，&#123;3,4&#125;，&#123;5,6&#125;&#125; - &gt; flatMap - &gt; &#123;1,2,3,4,5,6&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#x27;a&#x27;，&#x27;b&#x27;&#125;，&#123;&#x27;c&#x27;，&#x27;d&#x27;&#125;，&#123;&#x27;e&#x27;，&#x27;f&#x27;&#125;&#125; - &gt; flatMap - &gt; &#123;&#x27;a&#x27;，&#x27;b&#x27;，&#x27;c&#x27; D&quot;， &#x27;E&#x27;， &#x27;F&#x27;&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="flatmapto">flatMapTo*</span></h4><h4><span id="distinct">distinct</span></h4><blockquote>
<p>对于Stream中包含的元素进行去重操作（去重逻辑依赖元素的equals方法），新生成的Stream中没有重复的元素；</p>
<h4><span id="sorted">sorted</span></h4></blockquote>
<h4><span id="peek">peek</span></h4><blockquote>
<p>监控器</p>
</blockquote>
<p>提供一个Consumer消费函数，返回一个新的Stream，如果只写 Stream.of(“1”,”2”,”3”).peek(e-&gt; System.out.Println(e)) 是不会打印结果的 新Stream每个元素被<strong>消费</strong>的时候都会执行给定的消费函数； Stream.of(“1”,”2”,”3”).peek(e-&gt; System.out.Println(e)).collect(Collectors.toList());</p>
<h4><span id="limit">limit</span></h4><p>对一个Stream进行截断操作，获取其前N个元素，如果原Stream中包含的元素个数小于N，那就获取其所有的元素；</p>
<h4><span id="skip">skip</span></h4><p>返回一个丢弃原Stream的前N个元素后剩下元素组成的新Stream，如果原Stream中包含的元素个数小于N，那么返回空Stream；</p>
<h4><span id="foreach">forEach</span></h4><blockquote>
<p>遍历</p>
</blockquote>
<h4><span id="foreachordered">forEachOrdered</span></h4><blockquote>
<p>与forEach一样，只不过每次遍历结果都是相同的，forEach不是固定的序列</p>
</blockquote>
<h4><span id="generate">generate</span></h4><p>给定一个生成函数，生成一个无限的队列 Stream.generate(Math::random);</p>
<h4><span id="iterate">iterate</span></h4><p>也是生成无限长度的Stream，和generator不同的是，其元素的生成是重复对给定的种子值(seed)调用用户指定函数来生成的。其中包含的元素可以认为是：seed，f(seed),f(f(seed))无限循环</p>
<p>Stream.iterate(1, item -&gt; item + 1).limit(10).forEach(System.out::println);</p>
<h4><span id="collect">collect</span></h4><blockquote>
<p>汇聚函数</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法参数</th>
<th>返回类型</th>
<th>作用</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>toList</td>
<td>List<code>&lt;T &gt;</code></td>
<td>把流中的参数汇聚成List集合</td>
<td>示例:List<code>&lt;Menu&gt;</code> menus=Menu.getMenus.stream().collect(Collectors.toList())</td>
</tr>
<tr>
<td>toSet</td>
<td>Set<code>&lt;T&gt;</code></td>
<td>把流中所有元素收集到Set中,删除重复项</td>
<td>Set<code>&lt;Menu&gt;</code> menus=Menu.getMenus.stream().collect(Collectors.toSet())</td>
</tr>
<tr>
<td>toCollection</td>
<td>Collection<code>&lt;T&gt;</code></td>
<td>把流中所有元素收集到给定的供应源创建的集合中</td>
<td><code>ArrayList&lt;Menu&gt; menus=Menu.getMenus.stream().collect(Collectors.toCollection(ArrayList::new))</code></td>
</tr>
<tr>
<td>Counting</td>
<td>Long</td>
<td>计算流中元素个数</td>
<td>Long count=Menu.getMenus.stream().collect(Collectors.counting());</td>
</tr>
<tr>
<td>SummingInt</td>
<td>Integer</td>
<td>对流中元素的一个整数属性求和</td>
<td>Integer count=Menu.getMenus.stream().collect(Collectors.summingInt(Menu::getCalories))</td>
</tr>
<tr>
<td>averagingInt</td>
<td>Double</td>
<td>计算流中元素integer属性的平均值</td>
<td>Double averaging=Menu.getMenus.stream().collect((Collectors.averagingInt(Menu::getCalories))</td>
</tr>
<tr>
<td>Joining</td>
<td>String</td>
<td>连接流中每个元素的toString方法生成的字符串</td>
<td>String name=Menu.getMenus.stream().map(Menu::getName).collect(Collectors.joining(“, “))</td>
</tr>
<tr>
<td>maxBy</td>
<td>Optional<code>&lt;T&gt;</code></td>
<td>一个包裹了流中按照给定比较器选出的最大元素的optional 如果为空返回的是Optional.empty()</td>
<td>Optional<code>&lt;Menu&gt;</code> fattest=Menu.getMenus.stream().collectCollectors.maxBy(Menu::getCalories))</td>
</tr>
<tr>
<td>minBy</td>
<td>Optional<code>&lt;T&gt;</code></td>
<td>一个包裹了流中按照给定比较器选出的最大元素的optional如果为空返回的是Optional.empty()</td>
<td>Optional<code>&lt;Menu&gt;</code> lessest=Menu.getMenus.stream().collect(minBy(Menu::getCalories))</td>
</tr>
<tr>
<td>Reducing</td>
<td>归约操作产生的类型</td>
<td>从一个作为累加器的初始值开始,利用binaryOperator与流中的元素逐个结合,从而将流归约为单个值</td>
<td>int count=Menu.getMenus.stream().collect(reducing(0,Menu::getCalories,Integer::sum));</td>
</tr>
<tr>
<td>collectingAndThen</td>
<td>转换函数返回的类型</td>
<td>包裹另一个转换器,对其结果应用转换函数</td>
<td>Int count=Menu.getMenus.stream().collect(collectingAndThen(toList(),List::size))</td>
</tr>
<tr>
<td>groupingBy</td>
<td>Map<code>&lt;K,List&lt;T&gt;&gt;</code></td>
<td>根据流中元素的某个值对流中的元素进行分组,并将属性值做为结果map的键</td>
<td>Map<code>&lt;Type,List&lt;Menu&gt;&gt;</code> menuType=Menu.getMenus.stream().collect(groupingby(Menu::getType))</td>
</tr>
<tr>
<td>partitioningBy</td>
<td>Map<code>&lt;Boolean,List&lt;T&gt;&gt;</code></td>
<td>根据流中每个元素应用谓语的结果来对项目进行分区</td>
<td>Map<code>&lt;Boolean,List&lt;Menu&gt;&gt;</code> menuType=Menu.getMenus.stream().collect(partitioningBy(Menu::isType));</td>
</tr>
</tbody>
</table>
</div>
<h4><span id="reduce">reduce</span></h4><ul>
<li><code>Optional&lt;t&gt; reduce(BinaryOperator&lt;t&gt; accumulator);</code></li>
</ul>
<p>List <code>&lt;integer&gt;</code> ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10); System.out.println(“ints sum is:” + ints.stream().reduce((sum, item) -&gt; sum + item).get());</p>
<p>可以看到reduce方法接受一个函数，这个函数有两个参数，第一个参数是上次函数执行的返回值（也称为中间结果），第二个参数是stream中的元素，这个函数把这两个值相加，得到的和会被赋值给下次执行这个函数的第一个参数。要注意的是：<strong>第一次执行的时候第一个参数的值是Stream的第一个元素，第二个参数是Stream的第二个元素</strong>。这个方法返回值类型是Optional，这是Java8防止出现NPE的一种可行方法，后面的文章会详细介绍，这里就简单的认为是一个容器，其中可能会包含0个或者1个对象。</p>
<ul>
<li>T reduce(T identity, BinaryOperator<code>&lt;t&gt;</code> accumulator);<br>这个定义上上面已经介绍过的基本一致，不同的是：它允许用户提供一个循环计算的初始值，如果Stream为空，就直接返回该值。而且这个方法不会返回Optional，因为其不会出现null值。</li>
</ul>
<h4><span id="count">count</span></h4><blockquote>
<p>个数</p>
</blockquote>
<h4><span id="allmatch">allMatch</span></h4><p>是不是所有都满足给定的条件</p>
<h4><span id="anymatch">anyMatch</span></h4><p>是不是存在某一个元素满足给定的条件</p>
<h4><span id="findfirst">findFirst</span></h4><p>返回第一个，返回的是Optional值</p>
<h4><span id="nonematch">noneMatch</span></h4><p>是否没有一个元素满足给定的条件</p>
<h4><span id="max和min">max和min</span></h4><p>给定的比较条件，返回最大最小值</p>
<p><a href="http://ifeve.com/stream/">参考</a><br><a href="https://blog.csdn.net/dm_vincent/article/category/2268127">好文收藏</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>springcloud配置问题</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/springcloud%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><ul>
<li>注册中心不自动上线下线</li>
<li>异步返回值</li>
<li>bean参数传值<br>*</li>
</ul>
<h3><span id="eureka-不自动下线">eureka 不自动下线</span></h3><p>Eureka Server在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%，如果出现低于的情况（在单机调试的时候很容易满足，实际在生产环境上通常是由于网络不稳定导致），Eureka Server会将当前的实例注册信息保护起来，同时提示这个警告。保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。</p>
<p>详见：<a href="https://github.com/Netflix/eureka/wiki/Understanding-Eureka-Peer-to-Peer-Communication">https://github.com/Netflix/eureka/wiki/Understanding-Eureka-Peer-to-Peer-Communication</a></p>
<p>解决方法：设置enableSelfPreservation:false</p>
<p>配置心跳检测时长，下线leaseRenewalIntervalInSeconds: 2</p>
<h3><span id="负载均衡在服务下掉后的重试策略"></span></h3><p>默认没有开启：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">spring.cloud.loadbalancer.retry.enabled=<span class="keyword">true</span></span><br><span class="line"></span><br><span class="line">hystrix.command.<span class="keyword">default</span>.execution.isolation.thread.timeoutInMilliseconds=<span class="number">10000</span></span><br><span class="line"></span><br><span class="line">hello-service.ribbon.ConnectTimeout=<span class="number">250</span></span><br><span class="line">hello-service.ribbon.ReadTimeout=<span class="number">1000</span></span><br><span class="line">hello-service.ribbon.OkToRetryOnAllOperations=<span class="keyword">true</span></span><br><span class="line">hello-service.ribbon.MaxAutoRetriesNextServer=<span class="number">2</span></span><br><span class="line">hello-service.ribbon.MaxAutoRetries=<span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3><span id="断路器配置重试"></span></h3><p>如何处理服务挂掉后或者手动关闭服务后，Ribbon负载均衡还是一直调用这个服务，然后调用@HystrixCommand断路器注解的方法：利用Hystrix，在error callback方法中可以shutdown指定的server<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ZoneAwareLoadBalancer&lt;Server&gt; lb = (ZoneAwareLoadBalancer&lt;Server&gt;) springClientFactory.getLoadBalancer(<span class="string">&quot;CLOUD-SERVICE&quot;</span>);</span><br><span class="line">Server server = lb.chooseServer();</span><br><span class="line">System.out.println(<span class="string">&quot;error-&gt;&quot;</span> + server.getHostPort());</span><br><span class="line">lb.markServerDown(server);</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud集群同步、自我保护模式以及实例注册、心跳、下线配置</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/SpringCloud%E9%9B%86%E7%BE%A4%E5%90%8C%E6%AD%A5%E3%80%81%E8%87%AA%E6%88%91%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E4%BB%A5%E5%8F%8A%E5%AE%9E%E4%BE%8B%E6%B3%A8%E5%86%8C%E3%80%81%E5%BF%83%E8%B7%B3%E3%80%81%E4%B8%8B%E7%BA%BF%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="1-概述">1. 概述</span></h1><p>本文在上文 Spring cloud系列四 Eureka 之概述和服务注册中心集群的基础上，继续介绍Eureka新的内容:</p>
<pre><code>集群重要类：PeerAwareInstanceRegistryImpl
新的Eureka Server节点加入集群后的影响
新服务注册(Register)注册时的影响
服务心跳(renew)
服务下线和剔除
自我保护模式
</code></pre><h1><span id="2-eureka-server的集群同步操作">2. Eureka Server的集群同步操作</span></h1><h2><span id="21-eureka官网的架构图">2.1. Eureka官网的架构图</span></h2><p>下方的操作需要结合下图理解：<br>这里写图片描述</p>
<h2><span id="22-peerawareinstanceregistryimpl">2.2. PeerAwareInstanceRegistryImpl</span></h2><p>集群相关重要的类com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl: 为了保证集群里所有Eureka Server节点的状态同步，所有以下操作都会同步到集群的所有服务上：服务注册（Registers）、服务更新（Renewals）、服务取消（Cancels）,服务超时（Expirations）和服务状态变更（Status Changes）。以下是一些部分方法：</p>
<pre><code>syncUp：在Eureka Server重启或新的Eureka Server节点加进来的，会执行初始化，从集群其他节点中获取所有的实例注册信息，从而能够正常提供服务。当Eureka Server启动时，它会从其它节点获取所有的注册信息，如果获取同步失败，它在一定时间（此值由决定）内拒绝服务。
replicateToPeers： 同步以下操作到所有的集群节点：服务注册（Registers）、服务更新（Renewals）、服务取消（Cancels）,服务超时（Expirations）和服务状态变更（Status Changes）
register: 注册实例，并且复印此实例的信息到所有的eureka server的节点。如果其它Eureka Server调用此节点，只在本节点更新实例信息，避免通知其他节点执行更新
renew：心跳，同步集群
cancel
其他
</code></pre><p>Eureka Server集群之间的状态是采用异步方式同步的，所以不保证节点间的状态一定是一致的，不过基本能保证最终状态是一致的。</p>
<h2><span id="23-新的eureka-server节点加入集群后的影响">2.3. 新的Eureka Server节点加入集群后的影响</span></h2><p>当有新的节点加入到集群中，会对现在Eureka Server和Eureka Client有什么影响以及他们如何发现新增的Eureka Server节点：</p>
<pre><code>新增的Eureka Server：在Eureka Server重启或新的Eureka Server节点加进来的，它会从集群里其它节点获取所有的实例注册信息。如果获取同步失败，它会在一定时间（此值由决定eureka.server.peer-eureka-nodes-update-interval-ms决定）内拒绝服务。

已有Eureka Server和Service Consumer如何发现新的Eureka Server
    已有的Eureka Server：在运行过程中，Eureka Server之间会定时同步实例的注册信息。这样即使新的Application Service只向集群中一台注册服务，则经过一段时间会集群中所有的Eureka Server都会有这个实例的信息。那么Eureka Server节点之间如何相互发现，各个节点之间定时（时间由eureka.server.peer-eureka-nodes-update-interval-ms决定）更新节点信息，进行相互发现。
    Service Consumer：Service Consumer刚启动时，它会从配置文件读取Eureka Server的地址信息。当集群中新增一个Eureka Server中时，那么Service Provider如何发现这个Eureka Server？Service Consumer会定时（此值由eureka.client.eureka-service-url-poll-interval-seconds决定）调用Eureka Server集群接口，获取所有的Eureka Server信息的并更新本地配置。
</code></pre><h2><span id="24-新服务注册register注册时的影响">2.4. 新服务注册(Register)注册时的影响</span></h2><p>Service Provider要对外提供服务，把自己注册到Eureka Server上。如果配置参数eureka.client.registerWithEureka=true（默认值true）时，会向Eureka Server注册进行注册，Eureka Server会保存注册信息到内存中。</p>
<p>Service Consumer为了避免每次调用服务请求都需要向Eureka Server获取服务实例的注册信息，此时需要设置eureka.client.fetchRegistry=true，它会在本地缓存所有实例注册信息。为了保证缓存数据的有效性，它会定时（值由eureka.client.registry-fetch-interval-seconds定义，默认值为30s）向注册中心更新实例。</p>
<h2><span id="25-服务心跳renew">2.5. 服务心跳(renew)</span></h2><p>服务实例会通过心跳(eureka.instance.lease-renewal-interval-in-seconds定义心跳的频率，默认值为30s)续约的方式向Eureka Server定时更新自己的状态。Eureka Server收到心跳后，会通知集群里的其它Eureka Server更新此实例的状态。Service Provider/Service Consumer也会定时更新缓存的实例信息。</p>
<h2><span id="26-服务下线和剔除">2.6. 服务下线和剔除</span></h2><p>服务的下线有两种情况：</p>
<pre><code>在Service Provider服务shutdown的时候，主动通知Eureka Server把自己剔除，从而避免客户端调用已经下线的服务。
Eureka Server会定时（间隔值是eureka.server.eviction-interval-timer-in-ms，默认值为0，默认情况不删除实例）进行检查，如果发现实例在在一定时间（此值由eureka.instance.lease-expiration-duration-in-seconds定义，默认值为90s）内没有收到心跳，则会注销此实例。
</code></pre><p>这种情况下，Eureka Client的最多需要[eureka.instance.lease-renewal-interval-in-seconds + eureka.client.registry-fetch-interval-seconds]时间才发现服务已经下线。同理，一个新的服务上线后，Eureka Client的服务消费方最多需要相同的时间才发现服务已经上线</p>
<p>服务下线，同时会更新到Eureka Server其他节点和Eureka client的缓存，流程类似同以上的register过程</p>
<h2><span id="27-自我保护模式">2.7. 自我保护模式</span></h2><p>如果Eureka Server最近1分钟收到renew的次数小于阈值（即预期的最小值），则会触发自我保护模式，此时Eureka Server此时会认为这是网络问题，它不会注销任何过期的实例。等到最近收到renew的次数大于阈值后，则Eureka Server退出自我保护模式。</p>
<p>自我保护模式阈值计算：</p>
<pre><code>每个instance的预期心跳数目 = 60/每个instance的心跳间隔秒数
阈值 = 所有注册到服务的instance的数量的预期心跳之和 *自我保护系数
</code></pre><p>以上的参数都可配置的：</p>
<pre><code>instance的心跳间隔秒数：eureka.instance.lease-renewal-interval-in-seconds
自我保护系数：eureka.server.renewal-percent-threshold
</code></pre><p>如果我们的实例比较少且是内部网络时，推荐关掉此选项。我们也可以通过eureka.server.enable-self-preservation = false来禁用自我保护系数</p>
<h2><span id="28-配置demo">2.8 配置demo</span></h2><p>以下配置的demo如下：<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">10761</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">application:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">cloud-registration-center</span></span><br><span class="line"><span class="comment">## eureka ： 主要配置属性在EurekaInstanceConfigBean和EurekaClientConfigBean中</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line">  <span class="attr">instance:</span></span><br><span class="line">    <span class="comment"># hostname: 127.0.0.1</span></span><br><span class="line">    <span class="comment"># 使用IP注册</span></span><br><span class="line">    <span class="attr">preferIpAddress:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># 心跳间隔</span></span><br><span class="line">    <span class="attr">lease-renewal-interval-in-seconds:</span> <span class="number">3</span></span><br><span class="line">    <span class="comment"># 服务失效时间： 如果多久没有收到请求，则可以删除服务</span></span><br><span class="line">    <span class="attr">lease-expiration-duration-in-seconds:</span> <span class="number">7</span></span><br><span class="line">  <span class="attr">client:</span></span><br><span class="line">    <span class="comment"># 关闭eureka client</span></span><br><span class="line">    <span class="comment"># enabled: false</span></span><br><span class="line">    <span class="comment"># 注册自身到eureka服务器</span></span><br><span class="line">    <span class="attr">registerWithEureka:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># 表示是否从eureka服务器获取注册信息</span></span><br><span class="line">    <span class="attr">fetchRegistry:</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># 客户端从Eureka Server集群里更新Eureka Server信息的频率</span></span><br><span class="line">    <span class="attr">eureka-service-url-poll-interval-seconds:</span> <span class="number">60</span></span><br><span class="line">    <span class="comment"># 定义从注册中心获取注册服务的信息</span></span><br><span class="line">    <span class="attr">registry-fetch-interval-seconds:</span> <span class="number">5</span></span><br><span class="line">    <span class="comment"># 设置eureka服务器所在的地址，查询服务和注册服务都需要依赖这个地址</span></span><br><span class="line">    <span class="attr">serviceUrl:</span></span><br><span class="line">      <span class="attr">defaultZone:</span> <span class="string">http://127.0.0.1:10761/eureka/</span></span><br><span class="line">       <span class="comment"># 设置eureka服务器所在的地址，可以同时向多个服务注册服务</span></span><br><span class="line">       <span class="comment"># defaultZone: http://192.168.21.3:10761/eureka/,http://192.168.21.4:10761/eureka/</span></span><br><span class="line">  <span class="attr">server:</span></span><br><span class="line">     <span class="comment"># renewal-percent-threshold: 0.1</span></span><br><span class="line">     <span class="comment"># 关闭自我保护模式</span></span><br><span class="line">     <span class="attr">enable-self-preservation:</span> <span class="literal">false</span></span><br><span class="line">     <span class="comment"># Eureka Server 自我保护系数，当enable-self-preservation=true时，启作用</span></span><br><span class="line">     <span class="comment"># renewal-percent-threshold:</span></span><br><span class="line">     <span class="comment"># 设置清理间隔,单位为毫秒,默认为0</span></span><br><span class="line">     <span class="attr">eviction-interval-timer-in-ms:</span> <span class="number">3000</span></span><br><span class="line">     <span class="comment"># 设置如果Eureka Server启动时无法从临近Eureka Server节点获取注册信息，它多久不对外提供注册服务</span></span><br><span class="line">     <span class="attr">wait-time-in-ms-when-sync-empty:</span> <span class="number">6000000</span></span><br><span class="line">     <span class="comment"># 集群之间相互更新节点信息的时间频率</span></span><br><span class="line">     <span class="attr">peer-eureka-nodes-update-interval-ms:</span> <span class="number">60000</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>索引</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="索引介绍">索引介绍</span></h2><blockquote>
<p>索引对查询的速度有至关重要的影响。考虑如下情况，假设数据库中一个表有10^6^条记录，DBMS的页面大小为4K，并存储100条记录。如果没有索引，查询将对整个表进行扫描，最坏的情况下，如果所有数据页都不在内存，需要读取10^4^个页面，如果这10^4^个页面在磁盘上随机分布，需要进行10^4^次I/O，假设磁盘每次I/O时间为10ms(忽略数据传输时间)，则总共需要100s(但实际上要好很多很多)。如果对之建立B-Tree索引，则只需要进行log100(10^6^)=3次页面读取，最坏情况下耗时30ms。这就是索引带来的效果，很多时候，当你的应用程序进行SQL查询速度很慢时，应该想想是否可以建索引</p>
</blockquote>
<h2><span id="索引与优化">索引与优化</span></h2><h3><span id="索引的数据类型">索引的数据类型</span></h3><pre><code>选择索引类型原则：
</code></pre><ol>
<li>数据整形： 越小的整形在磁盘、内存、和CPU之间都需要更少的空间，处理起来更快。<ol>
<li>简单的数据类型更好： 整形数据比起字符型，处理开销更小，因为字符串的比较更复杂，在Mysql中，应该用内置的日期和时间数据类型，而不是字符串来存储时间，以及用整形数据类型存储ip地址。</li>
<li>尽量避免NULL： 应该指定列为NOT NULL ，除非想存储NULL。在mysql中，含有空值的列很难进行查询优化，以为他使得索引、索引的统计信息以及比较运算符更加复杂。应该用0、一个特殊值、或者一个空串代替空值。</li>
</ol>
</li>
</ol>
<h4><span id="选择标识符">选择标识符</span></h4><p>  选择合适的标识符是非常重要的，选择是不仅应该考虑存储类型，而且应该考虑mysql是怎么进行运算和比较的，一旦选定数据类型，应该保证所有的表都使用相同的数据类型。</p>
<pre><code>1. 整形： 通常是作为标识符最好的选择，因为更苦阿爹处理，因为可以更快的处理，而且可以设置为AUTO_INCREMENT。
2. 字符串：尽量避免使用字符串作为标识符，它们消耗更好的空间，处理起来也较慢。而且，通常来说，字符串都是随机的，所以它们在索引中的位置也是随机的，这会导致页面分裂、随机访问磁盘，聚簇索引分裂（对于使用聚簇索引的存储引擎）。
</code></pre><h3><span id="索引入门">索引入门</span></h3><pre><code>对于任何DBMS，索引都是进行优化的最主要的因素。对于少量的数据，没有合适的索引影响不是很大，但是，当随着数据量的增加，性能会急剧下降。
如果对多列进行索引(组合索引)，**列的顺序**非常重要，MySQL仅能对索引最左边的前缀进行有效的查找。例如：
</code></pre><p>假设存在组合索引 表t1 建立 c1c2(c1,c2)联合索引，查询语句select <em> from t1 where c1=1 and c2=2能够使用该索引。查询语句select </em> from t1 where c1=1也能够使用该索引。但是，查询语句select * from t1 where c2=2不能够使用该索引，因为没有组合索引的引导列，即，要想使用c2列进行查找，必需出现c1等于某值。</p>
<h4><span id="索引的类型">索引的类型</span></h4><p>索引是在存储引擎中实现的，而不是在服务器层中实现的。所以，每种存储引擎的索引都不一定完全相同，并不是所有的存储引擎都支持所有的索引类型。</p>
<h5><span id="b-tree索引">B-Tree索引</span></h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE People (</span><br><span class="line"></span><br><span class="line"> last_name varchar(50)    not null,</span><br><span class="line"></span><br><span class="line"> first_name varchar(50)    not null,</span><br><span class="line"></span><br><span class="line"> dob        date           not null,</span><br><span class="line"></span><br><span class="line"> gender     enum(&#x27;m&#x27;, &#x27;f&#x27;) not null,</span><br><span class="line"></span><br><span class="line"> key(last_name, first_name, dob)</span><br><span class="line"></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>其索引包含表中每一行的last_name、first_name和dob列。其结构大致如下：<br><img data-src="img/mysql索引关系.jpg" alt><br>索引存储的值按索引列中的顺序排列。可以利用B-Tree索引进行全关键字、关键字范围和关键字前缀查询，当然，如果想使用索引，你必须保证按索引的最左边前缀(leftmost prefix of the index)来进行查询。</p>
<ol>
<li>匹配全值(Match the full value)：对索引中的所有列都指定具体的值。例如，上图中索引可以帮助你查找出生于1960-01-01的Cuba Allen。</li>
<li>匹配最左前缀(Match a leftmost prefix)：你可以利用索引查找last name为Allen的人，仅仅使用索引中的第1列。</li>
<li>匹配列前缀(Match a column prefix)：例如，你可以利用索引查找last name以J开始的人，这仅仅使用索引中的第1列。</li>
<li>匹配值的范围查询(Match a range of values)：可以利用索引查找last name在Allen和Barrymore之间的人，仅仅使用索引中第1列。</li>
<li>匹配部分精确而其它部分进行范围匹配(Match one part exactly and match a range on another part)：可以利用索引查找last name为Allen，而first name以字母K开始的人。</li>
<li>仅对索引进行查询(Index-only queries)：如果查询的列都位于索引中，则不需要读取元组的值。</li>
</ol>
<p>由于B-树中的节点都是<strong>顺序存储</strong>的，所以可以利用索引进行查找(找某些值)，也可以对查询结果进行ORDER BY。当然，使用B-tree索引有以下一些限制：</p>
<ol>
<li>查询必须从索引的最左边的列开始。关于这点已经提了很多遍了。例如你不能利用索引查找在某一天出生的人。</li>
<li>不能跳过某一索引列。例如，你不能利用索引查找last name为Smith且出生于某一天的人。</li>
<li><p>存储引擎不能使用索引中范围条件右边的列。例如，如果你的查询语句为WHERE last_name=”Smith” AND first_name LIKE ‘J%’ AND dob=’1976-12-23’，则该查询只会使用索引中的前两列，因为LIKE是范围查询。</p>
<h5><span id="hash索引">Hash索引</span></h5><blockquote>
<p>MySQL中，只有Memory存储引擎显示支持hash索引，是Memory表的默认索引类型，尽管Memory表也可以使用B-Tree索引。Memory存储引擎支持非唯一hash索引，这在数据库领域是罕见的，如果多个值有相同的hash code，索引把它们的行指针用链表保存到同一个hash表项中。</p>
</blockquote>
<p>假设创建如下一个表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE testhash (</span><br><span class="line">   fname VARCHAR(50) NOT NULL,</span><br><span class="line">   lname VARCHAR(50) NOT NULL,</span><br><span class="line">   KEY USING HASH(fname)</span><br><span class="line">) ENGINE=MEMORY;</span><br></pre></td></tr></table></figure>
<p>假设索引使用hash函数f( )，如下：</p>
<blockquote>
<p>  f(‘Arjen’) = 2323<br>f(‘Baron’) = 7437<br>f(‘Peter’) = 8784<br>f(‘Vadim’) = 2458<br>此时，索引的结构大概如下：<br><img data-src="img/mysqlHash索引图.jpg" alt></p>
</blockquote>
</li>
</ol>
<p>Slots是有序的，但是记录不是有序的。当你执行<br>mysql&gt; SELECT lname FROM testhash WHERE fname=’Peter’;<br>MySQL会计算’Peter’的hash值，然后通过它来查询索引的行指针。因为f(‘Peter’) = 8784，MySQL会在索引中查找8784，得到指向记录3的指针。<br>因为索引自己仅仅存储很短的值，所以，索引非常紧凑。Hash值不取决于列的数据类型，一个TINYINT列的索引与一个长字符串列的索引一样大。<br>Hash索引有以下一些<strong>限制</strong>：</p>
<ol>
<li>由于索引仅包含hash code和记录指针，所以，MySQL不能通过使用索引避免读取记录。但是访问内存中的记录是非常迅速的，不会对性造成太大的影响。</li>
<li>不能使用hash索引排序。</li>
<li>Hash索引不支持键的部分匹配，因为是通过整个索引值来计算hash值的。</li>
<li>Hash索引只支持等值比较，例如使用=，IN( )和&lt;=&gt;。对于WHERE price&gt;100并不能加速查询。</li>
</ol>
<h5><span id="空间r-tree索引">空间(R-Tree)索引</span></h5><pre><code>MyISAM支持空间索引，主要用于地理空间数据类型，例如GEOMETRY。
</code></pre><h5><span id="全文full-text索引">全文(Full-text)索引</span></h5><pre><code>全文索引是MyISAM的一个特殊索引类型，主要用于全文检索。
</code></pre><h2><span id="高性能的索引策略">高性能的索引策略</span></h2><h3><span id="聚簇索引clustered-indexes">聚簇索引(Clustered Indexes)</span></h3><blockquote>
<p>mysql聚簇索引保证关键字的值相近的元组存储的物理位置也相同（所以字符串类型不宜建立聚簇索引，特别是随机字符串，会使得系统进行大量的移动操作），且一个表只能有一个聚簇索引。因为由存储引擎实现索引，所以，并不是所有的引擎都支持聚簇索引。目前，只有solidDB和InnoDB支持。<br> 结构如下：<br> <img data-src="img/mysql聚簇索引.jpg" alt><br>注：叶子页面包含完整的元组，而内节点页面仅包含索引的列(索引的列为整型)。一些DBMS允许用户指定聚簇索引，但是MySQL的存储引擎到目前为止都不支持。InnoDB对主键建立聚簇索引。如果你不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后对其建立聚簇索引。一般来说，DBMS都会以聚簇索引的形式来存储实际的数据，它是其它二级索引的基础。</p>
</blockquote>
<h4><span id="innodb和myisam的数据布局的比较">InnoDB和MyISAM的数据布局的比较</span></h4><blockquote>
<p>为了更加理解聚簇索引和非聚簇索引，或者primary索引和second索引(MyISAM不支持聚簇索引)，来比较一下InnoDB和MyISAM的数据布局，对于如下表：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE layout_test (</span><br><span class="line"></span><br><span class="line">col1 int NOT NULL,</span><br><span class="line"></span><br><span class="line">col2 int NOT NULL,</span><br><span class="line"></span><br><span class="line">PRIMARY KEY(col1),</span><br><span class="line"></span><br><span class="line">KEY(col2)</span><br><span class="line"></span><br><span class="line">);</span><br></pre></td></tr></table></figure><br>假设主键的值位于1—-10,000之间，且按随机顺序插入，然后用OPTIMIZE TABLE进行优化。col2随机赋予1—-100之间的值，所以会存在许多重复的值。</p>
<ol>
<li>MyISAM的数据布局<br>其布局十分简单，MyISAM按照插入的顺序在磁盘上存储数据，如下：<br><img data-src="img/mysqlMyisam索引.jpg" alt></li>
</ol>
</blockquote>
<p><a href="http://www.cnblogs.com/hustcat/archive/2009/10/28/1591648.html">参考</a></p>
]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title>线程间通信</title>
    <url>/posts/java/%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://mp.weixin.qq.com/s/Nij2KMBmDn5E5nFhpwn24w">参考如下</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>EffectiveJava读书笔记</title>
    <url>/posts/java/EffectiveJava%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="effectivejava-读书笔记">EffectiveJava 读书笔记</span></h1><p>本文于2017年10月26日再读一遍，对书中的内容进行整理提取，方便以后查阅</p>
<p>[TOC]</p>
<h2><span id="第一章创建和销毁对象">第一章：创建和销毁对象</span></h2><h3><span id="创建对象的方法">创建对象的方法</span></h3><ul>
<li>构造器方法new一个；</li>
<li>公共静态方法返回实例；</li>
<li>Build工程模式。<blockquote>
<p>一般来说创建对象最简单的方法就是使用的时候new一个，如Person  person = new Person();既通过构造器创建对象。这种使用方法不适用于所有情况，例如一个单例工具类，不需要每次使用都new，而是通过一个公共静态方法返回类的实例。</p>
</blockquote>
</li>
</ul>
<h4><span id="构造器方式">构造器方式</span></h4><p>  <em>缺点</em></p>
<blockquote>
<p>每一个构造器都与类名相同，无法知其寓意。</p>
</blockquote>
<p>  构造器方法时最常用的方法；</p>
<h4><span id="公共静态方法">公共静态方法</span></h4><p>  <em>优点1</em></p>
<blockquote>
<p>每一个公共静态方法都有名字，顾名思义。</p>
</blockquote>
<p>  <em>优点2</em></p>
<blockquote>
<p>不必为每次调用都产生一个新的实例，可以重复利用。</p>
</blockquote>
<p>  <em>优点3</em></p>
<blockquote>
<p>可以返回原返回类型的任何子类型对象。</p>
</blockquote>
<p>  <em>优点3</em></p>
<blockquote>
<p>创建参数化类型实例，使代码变得更简洁。</p>
</blockquote>
<p>  <em>缺点1</em></p>
<blockquote>
<p>类如果不含有共有的或者受保护的构造器，就不能被子类化。</p>
</blockquote>
<p>  <em>缺点2</em></p>
<blockquote>
<p>与其他静态方法没有任何区别。</p>
</blockquote>
<h4><span id="使用情景1-通过方法名知其方法作用">使用情景1 通过方法名知其方法作用</span></h4><p>  如BigInteger(int,int,Random)返回的BitInteger可能为素数，但如果用BigInteger.probablePrime静态方法来表示，更加清楚方法寓意。</p>
<p>  如果两个构造器方法中只是参数类型顺序上不同，很容易造成寓意混乱，需要进一步查询文档才能确定用哪一个，容错率很低。</p>
<h4><span id="使用场景2-使用预先定义好的实例">使用场景2 使用预先定义好的实例。</span></h4><p>  公共静态方法返回的实例可以控制是否是单例,或者控制是否可以实例化。</p>
<ul>
<li>getInstance和newInstance区别：<blockquote>
<p>getInstance方法重点是返回已经创建好的实例。<br>newInstance方法重点是返回一个新的实例。</p>
</blockquote>
</li>
</ul>
<h4><span id="使用场景3-collections的32个便利实现-通过适配器提供更丰富的服务接口">使用场景3 Collections的32个便利实现、通过适配器提供更丰富的服务接口</span></h4><p>  分别提供了不可修改的集合、同步集合等。<br>  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Service interface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Service</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Service provider interface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Provider</span></span>&#123;</span><br><span class="line">  <span class="function">Service <span class="title">newService</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Services</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Services</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Map&lt;String,Provider&gt; providers = <span class="keyword">new</span> ConcurrentHashMap&lt;String,Provider&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_PROVIDER_NAME = <span class="string">&quot;&lt;def&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">registerDefaultProvider</span><span class="params">(Provider p)</span></span>&#123;</span><br><span class="line">    registerProvider(DEFAULT_PROVIDER_NAME,p););</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">registerProvider</span><span class="params">(String name,Provider p)</span></span>&#123;</span><br><span class="line">    providers.put(name,p);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Service <span class="title">newInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> newInstance(DEFAULT_PROVIDER_NAME);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Service <span class="title">newInstance</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">    Provider p = provider.get(name);</span><br><span class="line">    <span class="keyword">if</span>(p == <span class="keyword">null</span>)&#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;No provider registered with name:&quot;</span>+ name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> p.newService();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4><span id="使用场景4-代替繁琐的参数声明">使用场景4  代替繁琐的参数声明。</span></h4><h4><span id="使用场景6">使用场景6</span></h4><p>  valueOf — 返回的实例与参数具有相同的值，实际上是类型转换方法。<br>  of  — valueOf的简洁替代。<br>  getInstance  — 返回的实例是通过方法的参数来描述的，但是不能说与参数有相同的值。对于Singleton来说，该方法没有参数。<br>  newInstance  — 跟getInstance一样，但是该方法确保返回的实例与其他实例不同。<br>  getType  — 跟getInstance一样，但是在工厂方法中处于不同的类中的时候使用，Type表示工厂方法锁返回的对象类型。<br>  newType  — 像newInstance一样，但是在工厂方法中处于不同的类中的时候使用。</p>
<h3><span id="构建器">构建器</span></h3><p>  静态工厂和构造器都有个局限性，都不能很好的扩展到大量的可选参数。<br>  参数量大的情况下通常有两种方法：</p>
<ul>
<li><p>重叠构造器</p>
<blockquote>
<p>可行，但很难编写，难以阅读。</p>
</blockquote>
</li>
<li><p><em>工厂模式</em></p>
<blockquote>
<p>build构造参数很简单明了，链式调用很少出错。<br>  但是在构造Bean的时候，可能出现不一致的状态，类无法仅仅通过构造器参数的有效性来保证一致性。</p>
</blockquote>
</li>
</ul>
<h3><span id="用私有构造器或者枚举类型强化singleton属性">用私有构造器或者枚举类型强化Singleton属性</span></h3><p>  构造器私有，公开一个公共静态方法返回实例。</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java类解析</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E7%B1%BB%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="java对象头">Java对象头</span></h2><p>  一般占用两个机器码，在32位虚拟机中，一个机器码占用4个字节，就是32位，但是如果是数组，需要占用3个机器码，需要1位确认数组大小。</p>
<ul>
<li>标记字段<ul>
<li>哈希码</li>
<li>GC分代年龄</li>
<li>锁状态标志</li>
<li>线程持有的锁</li>
<li>偏向线程ID</li>
<li>偏向时间戳</li>
</ul>
</li>
<li><p>类型指针</p>
<p>| 25bit | 4bit | 1bit | 2bit |<br>| —- | —- | —- | —- |<br>| 对象的hashCode | 分代年龄  | 是否是偏向锁 | 锁标记位 |</p>
<p><img data-src="img/java对象头.jpg" alt></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>求m的n次方</title>
    <url>/posts/%E7%AE%97%E6%B3%95/%E6%B1%82m%E7%9A%84n%E6%AC%A1%E6%96%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="初步设想">初步设想</span></h2><p>  最简单的方法，就是for循环一下。<br>  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> result = <span class="number">1L</span>;</span><br><span class="line"> <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">     result *= m;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><br>  这种方法结果肯定正确，但是时间复杂度上，需要O(n)。很是不理想。于是我想着改进一下。</p>
<h2><span id="探求乘法原理">探求乘法原理</span></h2><p>  乘法原理就是n个m相乘，例如m=10，n=5， 那么表达式为 10<em>10</em>10<em>10</em>10,有人说这不是废话嘛，当然不是，之所以展开，是因为可以改写法，如：(10<em>10)</em> (10<em>10)</em> 10,又有人说了，这不是还是废话嘛，别急往下看，你会发现(10*10)重复了。</p>
<p>  什么意思？</p>
<p>  如果单纯用for循环10的4次幂，需要 <em>循环4次运算</em>，现在我先用10<em>10,</em>第1次运算<em>，再用得出的结果乘以得出的结果，也就是(10</em>10)<em> (10</em>10),<em>第2次运算</em>。就这么简单，此次运算节省了2次，节省了百分之50啊，重大发现啊。</p>
<p>  如果是10的8次幂呢？单纯for循环需要8次，新的方法需要几次？<em>3次</em>。怎么算的？(10<em>10)</em> (10<em>10)</em> (10<em>10)</em> (10<em>10)。发现就是算10</em>10的4次方，算出10<em>10需要 </em>第一次*，4次方刚刚算了是2次，一共是3次，这么神奇啊，节省了5次运算啊。这是节省了百分之。。。ummmm，管他百分之多少呢，反正很多。</p>
<p>  照这么下去，16次方需要 <em>4</em> 次运算，32次方需要 <em>5</em> 次运算，64次方需要 <em>6</em> 次运算，重大发现，也就是说，<em>如果n是2的i次幂，那么就需要i次运算就可以算出m的n次方了。</em></p>
<p>  天晴了， 世界和平了，我又拯救了世界了，可以回家睡懒觉了。</p>
<p>  咦，等等，如果n不是2的多少次幂怎么办？比如10的5次幂？</p>
<p>  ummmm，我想了想，把5拆成4+1呢？也就是10的4次幂再乘以10，这个方法可以。</p>
<p>  那10的6次幂就可以拆成4+2.</p>
<p>  7次方就可以拆成4+2+1.嗯，不错。</p>
<p>  于是，我写了个代码，如下</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pow</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> m = <span class="number">5</span>;</span><br><span class="line">      <span class="keyword">int</span> n = <span class="number">134</span>;</span><br><span class="line">      <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">      System.out.println(<span class="string">&quot;for循环版，结果为 ： &quot;</span> + Double.toString(pow(m, n)));</span><br><span class="line">      <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">      System.out.println(<span class="string">&quot;for循环版，总耗时： &quot;</span> + (end - start));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      start = System.currentTimeMillis();</span><br><span class="line">      System.out.println(<span class="string">&quot;叠乘法，结果为 ： &quot;</span> + Double.toString(pow2(m, n)));</span><br><span class="line">      end = System.currentTimeMillis();</span><br><span class="line">      System.out.println(<span class="string">&quot;叠乘法，总耗时： &quot;</span> + (end - start));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * m的n次方,for循环版</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> m 底数</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> n 幂数</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">double</span> <span class="title">pow</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">boolean</span> negative = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (m == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">          n = -n;</span><br><span class="line">          negative = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 循环乘法</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">double</span> result = <span class="number">1L</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">          result *= m;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (negative) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">1</span> / result;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * m的n次方,折中叠乘法</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> m 底数</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> n 幂数</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">double</span> <span class="title">pow2</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">boolean</span> negative = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (m == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">          n = -n;</span><br><span class="line">          negative = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line"><span class="comment">//        当m是2的时候，直接位移就可以。</span></span><br><span class="line">      <span class="keyword">if</span> (m == <span class="number">2</span>) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">2</span> &lt;&lt; n;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 叠乘法</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line"><span class="comment">//        最后结果。</span></span><br><span class="line">      <span class="keyword">double</span> result = <span class="number">1L</span>;</span><br><span class="line"><span class="comment">//        定义一个指针，从右向左按位与。</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i &lt;&lt;= <span class="number">1</span>) &#123;</span><br><span class="line"><span class="comment">//            按位与，如果大于0，说明此位为1,需要m的i次方。</span></span><br><span class="line">          <span class="keyword">if</span> ((i &amp; n) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">              <span class="keyword">double</span> resultTemp = <span class="number">1L</span>;</span><br><span class="line"><span class="comment">//                m的i次方不能写成循环i次的m相乘，而是m叠乘，次数为ln(i)。    例如m的8次方，就是((m*m)*(m*m))*((m*m)*(m*m)),也就是 ((m*m)2)2</span></span><br><span class="line">              <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= i; j &lt;&lt;= <span class="number">1</span>) &#123;</span><br><span class="line">                  <span class="keyword">if</span> (j == <span class="number">1</span>) &#123;</span><br><span class="line">                      resultTemp = m;</span><br><span class="line">                  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                      <span class="keyword">if</span> (greatThanMax(resultTemp, resultTemp)) &#123;</span><br><span class="line">                          <span class="keyword">return</span> Double.MAX_VALUE;</span><br><span class="line">                      &#125;</span><br><span class="line">                          resultTemp *= resultTemp;</span><br><span class="line">                  &#125;</span><br><span class="line">              &#125;</span><br><span class="line">              <span class="keyword">if</span> (greatThanMax(resultTemp, result)) &#123;</span><br><span class="line">                  <span class="keyword">return</span> Double.MAX_VALUE;</span><br><span class="line">              &#125;</span><br><span class="line">              result *= resultTemp;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (negative) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">1</span> / result;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 检查两个数相乘是否大于double的最大值。</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> m</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> n</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">greatThanMax</span><span class="params">(<span class="keyword">double</span> m, <span class="keyword">double</span> n)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> (m &gt; (Double.MAX_VALUE / n));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试结果为</p>
<blockquote>
<p>for循环版，结果为 ： 4.591774807899563E93<br>    for循环版，总耗时： 1<br>    叠乘法，结果为 ： 4.591774807899562E93<br>    叠乘法，总耗时： 0</p>
</blockquote>
<h2><span id="彩蛋">彩蛋</span></h2><p>  如果m是2的话，只需要返回2&lt;&lt;n就行了。自行判断是否越界。</p>
]]></content>
  </entry>
  <entry>
    <title>java学习路线</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="本文作为收藏用">本文作为收藏用</span></h1><h1><span id>#</span></h1><p>作者：匿名用户<br>链接：<a href="https://www.zhihu.com/question/39890405/answer/83676977">https://www.zhihu.com/question/39890405/answer/83676977</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<ul>
<li><p>第一个是基础。</p>
<blockquote>
<p>比如对集合类，并发包，IO/NIO，JVM，内存模型，泛型，异常，反射，等有深入了解，最好是看过源码了解底层的设计。比如一般面试都会问ConcurrentHashMap，CopyOnWrite，线程池，CAS，AQS，虚拟机优化等知识点，因为这些对互联网的企业是绝对重要的。而且一般人这关都过不了，还发闹骚说这些没什么用，为什么要面试。举一例子，在使用线程池时，因为使用了无界队列，在远程服务异常情况下导致内层飙升，怎么去解决？你要是连线程池都不清楚，你怎么去玩？再举一例，由于对ThreadLocal理解出错，使用它做线程安全的控制，导致没能实现真的线程安全。所以作为一个拿两万的JAVA程序员这点基础是要有的。</p>
</blockquote>
</li>
<li><p>第二你需要有全面的互联网技术相关知识。</p>
<blockquote>
<p>从底层说起，你起码得深入了解mysql，redis，mongodb，nginx，tomcat，rpc，jms等方面的知识。你要问需要了解到什么程度，我可以给你说个大慨。首先对于MySQL，你要知道常见的参数设置，存储引擎怎么去选择，还需要了解常见的索引引擎，知道怎么去选择。知道怎么去设计表，怎么优化sql，怎么根据执行计划去调优。高级的你需要去做分库分表的设计和优化，一般互联网企业的数据库都是读写分离，还会垂直与水平拆分，所以这个也有经验的成分在里面。然后redis，mongodb都是需要了解原理，需要会调整参数的，而nginx和tomcat几乎都是JAVA互联网方面必配，其实很阿里的技术栈选择有点关系。至于rpc相关的就多的去，必须各种网络协议，序列化技术，SOA等等，你要有一个深入的理解。现在应用比较广的rpc框架，在国内就是dubbo了，可以自行搜索。至于jms相关的起码得了解原理吧，一般情况下不是专门开发中间件系统和支撑系统的不需要了解太多细节，国内企业常用的主要是activeMQ和kafka。你能对我说的都研究的比较深入，阿里p7都不是太大问题的，当然这个还需要看你的架构能力方面的面试表现了。</p>
</blockquote>
</li>
<li><p>第三就是编程能力</p>
<blockquote>
<p>编程思想，算法能力，架构能力。首先2W程序员对算法的要求我觉得还是比较低，再高级也最多红黑树吧，但是排序和查询的基本算法得会。编程思想是必须的，问你个AOP和IOC你起码的清清楚楚，设计模式不说每种都用过，但也能了解个几种吧。编程能力这个我觉得不好去评价，但是拿一个2000W用户根据姓名年龄排序这种题目也能信手拈来。最后就是架构能力，这种不是说要你设计个多牛逼多高并发的系统，起码让你做一个秒杀系统，防重请求的设计能快速搞定而没有坑吧。</p>
</blockquote>
</li>
</ul>
<h3><span id="感谢">感谢</span></h3><p><a href="https://www.zhihu.com/question/39890405/answer/83676977">在北京做Java开发如何月薪达到两万，需要技术水平达到什么程度？</a><br><a href="https://www.zhihu.com/question/40801731/answer/91814769">零基础应该选择学习 java、php、前端 还是 python？</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库架构设计（转发）</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%EF%BC%88%E8%BD%AC%E5%8F%91%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://gitbook.cn/books/59be67b577cac00b9c2362fa/index.html">链接地址</a></p>
]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库跨库分页实践（转发）</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B7%A8%E5%BA%93%E5%88%86%E9%A1%B5%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%BD%AC%E5%8F%91%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://gitbook.cn/books/58a98f512bd83c246b6b8866/index.html">转载链接</a></p>
]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>基本类型和包装类型差别</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%8C%85%E8%A3%85%E7%B1%BB%E5%9E%8B%E5%B7%AE%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="基本类型以及包装类型">基本类型以及包装类型</span></h2><p>   java中定义了基本类型： </p>
<pre><code>    * 整形： byte、short、int、long
    * 浮点型：float、double
    * 逻辑型： boolean
    * 字符型： char
</code></pre><p>   以及对应的包装类型：</p>
<pre><code>    * 整形： Byte、Short、Integer、Long
    * 浮点型： Float、Double
    * 逻辑型： Boolean
    * 字符型： Char 
</code></pre><h2><span id="自动装箱-拆箱">自动装箱、拆箱</span></h2><p>   java为满足程序员基本类型和包装类型混合使用，按需自动装箱拆箱。<br>   自动装箱拆箱使基本类型和包装类型之间的区别逐渐模糊，但是语义上有些许差别，性能上也有明显差别。</p>
<h2><span id="基本类型和包装类型差别">基本类型和包装类型差别</span></h2><ul>
<li>基本类型有默认值，例如int值默认为0 ，而Integer没有默认引用，默认为null。<br> 所以在写数据库实体类或者网络请求接收字段的时候要使用包装类型，防止接受参数为null的情况。</li>
<li><p>包装类的频繁更改并不是在原来的基础上更改，而是产生新的对象，所以包装类的频繁更改性能很差.</p>
<blockquote>
<p>使用Long情况</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> now = System.currentTimeMillis();</span><br><span class="line">        Long sum = <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; Integer.MAX_VALUE; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">        <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">&quot;using Long total time = &quot;</span> + (end - now));</span><br></pre></td></tr></table></figure>
<p>耗费时间为</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2305843005992468481</span></span><br><span class="line">all time = <span class="number">8832</span></span><br></pre></td></tr></table></figure>
<p>使用long情况</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testlongAutoBoxing</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> now = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">long</span> sum = <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; Integer.MAX_VALUE; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;using long ,sum =&quot;</span> + sum);</span><br><span class="line">        <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">&quot;using long total time = &quot;</span> + (end - now));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>总耗费时间为</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2305843005992468481</span></span><br><span class="line">all time = <span class="number">787</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>在使用Long的时间比long增加10倍，原因是Long的操作过程中会构造大概2^31个实例。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java单例的七种写法</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E5%8D%95%E4%BE%8B%E7%9A%84%E4%B8%83%E7%A7%8D%E5%86%99%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="懒汉">懒汉</span></h1><h2><span id="线程不安全">线程不安全</span></h2>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;  </span><br><span class="line">     <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;   </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">       <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;  </span><br><span class="line">           instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">       &#125;  </span><br><span class="line">     <span class="keyword">return</span> instance;  </span><br><span class="line">     &#125;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h2><span id="线程安全">线程安全</span></h2>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;  </span><br><span class="line">      instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="keyword">return</span> instance;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<h1><span id="饿汉">饿汉</span></h1>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line"> <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line"> <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line"> <span class="keyword">return</span> instance;  </span><br><span class="line"> &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2><span id="饿汉变种">饿汉变种</span></h2>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance = <span class="keyword">null</span>;  </span><br><span class="line">  <span class="keyword">static</span> &#123;  </span><br><span class="line">  instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">this</span>.instance;  </span><br><span class="line">  &#125;  </span><br><span class="line"> &#125;  </span><br></pre></td></tr></table></figure>
<h2><span id="静态内部类">静态内部类</span></h2>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">      <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span> </span>&#123;  </span><br><span class="line">      <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();  </span><br><span class="line">      &#125;  </span><br><span class="line">      <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">          <span class="keyword">return</span> SingletonHolder.INSTANCE;  </span><br><span class="line">      &#125;  </span><br><span class="line">  &#125;  </span><br></pre></td></tr></table></figure>
<h2><span id="枚举">枚举</span></h2>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">     INSTANCE;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">whateverMethod</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">     &#125;  </span><br><span class="line"> &#125; </span><br></pre></td></tr></table></figure>
<h2><span id="双重校验锁">双重校验锁</span></h2>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">      <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton singleton;  </span><br><span class="line">      <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;   </span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getSingleton</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">      <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;  </span><br><span class="line">          <span class="keyword">synchronized</span> (Singleton.class) &#123;  </span><br><span class="line">          <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;  </span><br><span class="line">              singleton = <span class="keyword">new</span> Singleton();  </span><br><span class="line">          &#125;  </span><br><span class="line">         &#125;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="keyword">return</span> singleton;  </span><br><span class="line">     &#125;  </span><br><span class="line"> &#125; </span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java线程详解</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E7%BA%BF%E7%A8%8B%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="线程状态">线程状态</span></h2><ul>
<li>新建状态(New) : <blockquote>
<p>线程对象被创建后，就进入了新建状态。例如，Thread thread = new Thread()。</p>
</blockquote>
</li>
<li>就绪状态(Runnable): <blockquote>
<p>也被称为“可执行状态”。线程对象被创建后，其它线程调用了该对象的start()方法，从而来启动该线程。例如，thread.start()。处于就绪状态的线程，随时可能被CPU调度执行。</p>
</blockquote>
</li>
<li>运行状态(Running) : <blockquote>
<p>线程获取CPU权限进行执行。需要注意的是，线程只能从就绪状态进入到运行状态。</p>
</blockquote>
</li>
<li><p>阻塞状态(Blocked) : </p>
<blockquote>
<p>阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：</p>
<ul>
<li>等待阻塞 — 通过调用线程的wait()方法，让线程等待某工作的完成。</li>
<li>同步阻塞 — 线程在获取synchronized同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态。</li>
<li>其他阻塞 — 通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。</li>
<li>死亡状态(Dead) : 线程执行完了或者因异常退出了run()方法，该线程结束生命周期。<br>这5种状态涉及到的内容包括Object类, Thread和synchronized关键字。</li>
</ul>
</blockquote>
</li>
<li><p>Object类，定义了wait(), notify(), notifyAll()等休眠/唤醒函数。</p>
</li>
<li>Thread类，定义了一些列的线程操作函数。例如，sleep()休眠函数, interrupt()中断函数, getName()获取线程名称等。</li>
<li>synchronized，是关键字；它区分为synchronized代码块和synchronized方法。synchronized的作用是让线程获取对象的同步锁。</li>
</ul>
<h2><span id="实现多线程的两种方式thread和runnable">实现多线程的两种方式：Thread和Runnable</span></h2><ul>
<li><p>Runnable 是一个接口，该接口中只包含了一个run()方法。它的定义如下：<br>public interface Runnable {<br> public abstract void run();<br>}<br>Runnable的作用，实现多线程。我们可以定义一个类A实现Runnable接口；然后，通过new Thread(new A())等方式新建线程。<br>Thread 是一个类。Thread本身就实现了Runnable接口。它的声明如下：<br>public class Thread implements Runnable {}<br>Thread的作用，实现多线程。</p>
<h3><span id="thread和runnable的异同点">Thread和Runnable的异同点：</span></h3></li>
<li>Thread 和 Runnable 的相同点：<blockquote>
<p>都是“多线程的实现方式”。</p>
</blockquote>
</li>
<li>Thread 和 Runnable 的不同点：<blockquote>
<p>Thread 是类，而Runnable是接口；Thread本身是实现了Runnable接口的类。我们知道“一个类只能有一个父类，但是却能实现多个接口”，因此Runnable具有更好的扩展性。<br>此外，Runnable还可以用于“资源的共享”。即，多个线程都是基于某一个Runnable对象建立的，它们会共享Runnable对象上的资源。<br>通常，建议通过“Runnable”实现多线程！</p>
</blockquote>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java并发锁</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E5%B9%B6%E5%8F%91%E9%94%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="实现方式">实现方式</span></h2><ul>
<li>锁<br>   -[ ] 公平锁<br>   -[ ] 非公平锁<ul>
<li>隐式锁Synchronized</li>
<li>显式锁Lock<ul>
<li>ReentrantLock</li>
<li>ReadWriteLock</li>
<li>ReentrantReadWriteLock</li>
<li>StampedLock </li>
</ul>
</li>
<li></li>
</ul>
</li>
<li>无锁<ul>
<li>atomic</li>
<li>concurrent</li>
<li>blocking</li>
<li>threadLocal</li>
<li>volatile</li>
<li>CAS</li>
</ul>
</li>
</ul>
<h2><span id="锁">锁</span></h2><ul>
<li>Synchronized<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter</span></span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">inc</span><span class="params">()</span></span>&#123;</span><br><span class="line">		<span class="keyword">synchronized</span>(<span class="keyword">this</span>)&#123;</span><br><span class="line">			<span class="keyword">return</span> ++count;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Lock<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter</span></span>&#123;</span><br><span class="line">	<span class="keyword">private</span> Lock lock = <span class="keyword">new</span> Lock();</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">inc</span><span class="params">()</span></span>&#123;</span><br><span class="line">		lock.lock();</span><br><span class="line">		<span class="keyword">int</span> newCount = ++count;</span><br><span class="line">		lock.unlock();</span><br><span class="line">		<span class="keyword">return</span> newCount;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
不可重入自旋锁的简单实现<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Counter</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Lock</span></span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">boolean</span> isLocked = <span class="keyword">false</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span></span><br><span class="line"><span class="function">		<span class="keyword">throws</span> InterruptedException</span>&#123;</span><br><span class="line">		<span class="keyword">while</span>(isLocked)&#123;</span><br><span class="line">			wait();</span><br><span class="line">		&#125;</span><br><span class="line">		isLocked = <span class="keyword">true</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span>&#123;</span><br><span class="line">		isLocked = <span class="keyword">false</span>;</span><br><span class="line">		notify();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2><span id="threadlocal">threadLocal</span></h2><p>   如果想知道为什么使用ThreadLocal，就得先了解局部变量和全局变量对线程安全的影响。<br>   局部变量存储在线程自己的栈中。也就是说，局部变量永远也不会被多个线程共享。所以，基础类型的局部变量是线程安全的。<br>   当多个线程引用同一个对象时，因为对象引用是放在栈上的，但是对象实例存储在堆中，所以不是线程安全的。</p>
<p>   ThreadLocal就是拷贝一份到线程缓存中，Thread正是操作这个对象，就不会出现安全问题。</p>
<ul>
<li><p>InheritableThreadLocal</p>
<p>InheritableThreadLocal类是ThreadLocal的子类。为了解决ThreadLocal实例内部每个线程都只能看到自己的私有值，所以InheritableThreadLocal允许一个线程创建的所有子线程访问其父线程的值。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>深入分析Synchronized</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Synchronized/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="java同步关键字synchronzied">Java同步关键字（synchronzied）</span></h1><blockquote>
<p>所有同步在一个对象上的同步块在同时只能被一个线程进入并执行操作。所有其他等待进入该同步块的线程将被阻塞，直到执行该同步块中的线程退出。</p>
<h2><span id="使用方法">使用方法</span></h2><ul>
<li>实例方法同步<br>作用在实例上 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> value)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.count += value;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li>
<li>静态方法同步<br>作用在对象上 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> value)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.count += value;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li>
<li>实例方法中同步块<br>作用在this这个实例上  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> value)</span></span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(<span class="keyword">this</span>)&#123;</span><br><span class="line">       <span class="keyword">this</span>.count += value;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li>
<li>静态方法中同步块<br>作用在MyClass这个class上  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">log1</span><span class="params">(String msg1, String msg2)</span></span>&#123;</span><br><span class="line">       log.writeln(msg1);</span><br><span class="line">       log.writeln(msg2);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">log2</span><span class="params">(String msg1, String msg2)</span></span>&#123;</span><br><span class="line">       <span class="keyword">synchronized</span>(MyClass.class)&#123;</span><br><span class="line">          log.writeln(msg1);</span><br><span class="line">          log.writeln(msg2);</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<p>[参考]{<a href="http://ifeve.com/synchronized-blocks/}">http://ifeve.com/synchronized-blocks/}</a></p>
<p>[参考2]{<a href="http://cmsblogs.com/?hmsr=toutiao.io&amp;p=2071&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io}">http://cmsblogs.com/?hmsr=toutiao.io&amp;p=2071&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io}</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>负载均衡</title>
    <url>/posts/java/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="什么是负载均衡">什么是负载均衡</span></h2><p>   负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一，它通常是指，将请求/数据【均匀】分摊到多个操作单元上执行，负载均衡的关键在于【均匀】。</p>
<p>   常见互联网分布式架构如上，分为客户端层、反向代理nginx层、站点层、服务层、数据层。可以看到，每一个下游都有多个上游调用，只需要做到，每一个上游都均匀访问每一个下游，就能实现“将请求/数据【均匀】分摊到多个操作单元上执行”。</p>
<ul>
<li>“客户端层-&gt;反向代理层”的负载均衡<br>【客户端层】到【反向代理层】的负载均衡，是通过“DNS轮询”实现的：DNS-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问DNS-server，会轮询返回这些ip，保证每个ip的解析概率是相同的。这些ip就是nginx的外网ip，以做到每台nginx的请求分配也是均衡的。</li>
<li>“反向代理层-&gt;站点层”的负载均衡<br>  【反向代理层】到【站点层】的负载均衡，是通过“nginx”实现的。通过修改nginx.conf，可以实现多种负载均衡策略：<ul>
<li>请求轮询：和DNS轮询类似，请求依次路由到各个web-server</li>
<li>最少连接路由：哪个web-server的连接少，路由到哪个web-server</li>
<li>ip哈希：按照访问用户的ip哈希值来路由web-server，只要用户的ip分布是均匀的，请求理论上也是均匀的，ip哈希均衡方法可以做到，同一个用户的请求固定落到同一台web-server上，此策略适合有状态服务，例如session.</li>
</ul>
</li>
<li>“站点层-&gt;服务层”的负载均衡<br>   【站点层】到【服务层】的负载均衡，是通过“服务连接池”实现的。<br>   上游连接池会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。</li>
<li>“数据层”的负载均衡<br> 在数据量很大的情况下，由于数据层（db，cache）涉及数据的水平切分，所以数据层的负载均衡更为复杂一些，它分为“数据的均衡”，与“请求的均衡”。<ul>
<li>数据的均衡是指：水平切分后的每个服务（db，cache），数据量是差不多的。</li>
<li>请求的均衡是指：水平切分后的每个服务（db，cache），请求量是差不多的。<br>业内常见的水平切分方式有这么几种：<ul>
<li>按照range水平切分        <ul>
<li>好处<ul>
<li>规则简单，service只需判断一下uid范围就能路由到对应的存储服务</li>
<li>数据均衡性较好</li>
<li>比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务</li>
</ul>
</li>
<li>不足是：<ul>
<li>请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大</li>
</ul>
</li>
</ul>
</li>
<li>按照id哈希水平切分<ul>
<li>好处：<ul>
<li>规则简单，service只需对uid进行hash能路由到对应的存储服务</li>
<li>数据均衡性较好</li>
<li>请求均匀性较好</li>
</ul>
</li>
<li>不足：<ul>
<li>不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>代理</title>
    <url>/posts/java/%E4%BB%A3%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="代理分类">代理分类</span></h1><h2><span id="正向代理">正向代理</span></h2><pre><code>&gt;服务器ip地址不变，用户ip地址变。例如用户(1.1.1.1)使用正向代理(2.2.2.2)访问服务器(3.3.3.3),那么服务器收到的消息来自2.2.2.2.服务器不知道用户真正的地址。
</code></pre><h2><span id="反向代理">反向代理</span></h2><pre><code>&gt; 反之，用户不知道服务器的地址。
</code></pre><h3><span id="场景">场景</span></h3><pre><code>对用户屏蔽高可用、屏蔽web-server扩展、内网等一些细节。
由于web-server有多台，需要进行负载均衡。
</code></pre><h1><span id="负载均衡">[负载均衡]{}</span></h1><h2><span id="软件">软件</span></h2><ul>
<li>nginx/apache</li>
<li>F5</li>
<li>lvs</li>
</ul>
<h2><span id="什么是四层转发交换什么是七层转发交换">什么是四层（转发/交换），什么是七层（转发/交换）？</span></h2><p>   <img data-src="img/网络协议7层与5层协议.png" alt="这个是来源于OSI七层模型"><br>   由图可见，4层指传输层，7层指应用层<br>   更具体的，对应到nginx反向代理hash：</p>
<ul>
<li>四层：根据用户ip+port来做hash</li>
<li>七层：根据http协议中的某些属性来做hash</li>
</ul>
<h2><span id="为什么中间少了几层">为什么中间少了几层？</span></h2><pre><code>OSI应用层、表示层、会话层合并到TCP/IP的应用层啦。
</code></pre><h2><span id="上面有四层七层那有没有二层三层呢">上面有四层，七层，那有没有二层，三层呢？</span></h2><ul>
<li>二层：根据数据链路层MAC地址完成数据交换</li>
<li>三层：根据网络层IP地址完成数据交换</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>炸了那个Jvm</title>
    <url>/posts/java/jvm/%E7%82%B8%E4%BA%86%E9%82%A3%E4%B8%AAJvm/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://zhuanlan.51cto.com/art/201709/550451.htm">http://zhuanlan.51cto.com/art/201709/550451.htm</a></p>
<h2><span id="jvm内存模型">JVM内存模型</span></h2><p>   <img data-src="img/JVM内存模型.jpg" alt></p>
<p>   打印出来的信息：</p>
<pre><code>PSYoungGen      total 3072K, used 128K 
    eden space 2560K, 5% used  
    survivor  space 
        from space 512K, 0% used  
         to   space 512K, 0% used  

ParOldGen       total 6656K, used 408K 
    object space 6656K, 6% used   

PSPermGen       total 4096K, used 3039K    
    object space 4096K, 74% used  
</code></pre><h2><span id="gc过程">GC过程</span></h2><ul>
<li>年轻代：<br>  存放对象的特点： 生命周期短，多为临时变量。<blockquote>
<p>新实例化的对象都会在eden中new出来，经过手动System.gc()（本质上也是调用Runtime的gc）、Runtime.getRuntime().gc()（本地方法）或者一段时间后系统自动触发gc，年轻代使用 <em>复制清除</em>算法 ，从Root对象开始标记为存活，存活的对象引用的对象也会标记为存活，扫描整个eden区后，将存活的对象存放到其中一个survivor区，清除eden区和另外一个eden区。下次再产生新的对象仍然是放到eden区内，再gc时将eden区和有对象存储的survivor存活的对象复制到另外一个survivor区内，清除这两个区，反复如此，清除一定次数后（之前看过介绍15次，不太确定）将仍然存活的放到年老代。</p>
</blockquote>
</li>
<li>年老代<br>  存放对象特点： 生命周期长。<blockquote>
<p>年老代使用<em>标记整理</em>算法，还是从Root对象开始搜索，标记所有存活的对象，把所有存活的对象复制到一个区域内，再清除其他区域。</p>
</blockquote>
</li>
</ul>
<h2><span id="示例">示例</span></h2><h3><span id="栈内存溢出javalangstackoverflowerror">栈内存溢出(java.lang.StackOverflowError)</span></h3><pre><code> &gt; -Xmx10m
   -XX:MaxPermSize=5m
   -XX:MaxDirectMemorySize=5m
   -XX:+PrintGCDetails
</code></pre><h3><span id="永久代溢出javalangoutofmemoryerror-gc-overhead-limit-exceeded">永久代溢出(java.lang.OutOfMemoryError: GC overhead limit exceeded)</span></h3>]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>Collections类全解析</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/Collections%E7%B1%BB%E5%85%A8%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql内连接、左外连接、右外连接、全连接</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E5%86%85%E8%BF%9E%E6%8E%A5%E3%80%81%E5%B7%A6%E5%A4%96%E8%BF%9E%E6%8E%A5%E3%80%81%E5%8F%B3%E5%A4%96%E8%BF%9E%E6%8E%A5%E3%80%81%E5%85%A8%E8%BF%9E%E6%8E%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="指定方式">指定方式</span></h2><blockquote>
<p>连接条件可以在FROM或WHERE语句中指定。</p>
</blockquote>
<h2><span id="分类">分类</span></h2><ul>
<li><p>内连接</p>
<blockquote>
<p>典型的连接运算，使用=或者&lt;&gt;之类的比较运算。包括相等连接和自然连接。<br>内连接使用比较运算符根据每个表共有的值匹配两个表中的行。</p>
</blockquote>
</li>
<li><p>外连接</p>
<ul>
<li><p>左外连接</p>
<blockquote>
<p>left join 结果集包括左表中的所有行，如果左表的某行在右表中没有匹配行，结果集中显示为空。</p>
</blockquote>
</li>
<li><p>右外连接</p>
<blockquote>
<p>与左外连接相反。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>全连接</p>
<blockquote>
<p>返回左表和右表中所有的行。</p>
</blockquote>
</li>
</ul>
]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql索引</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E7%B4%A2%E5%BC%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="概念">概念</span></h2><blockquote>
<p>由用户创建的，能够被修改和删除的，实际存储在数据库中的物理存在。它是某一表中一列或者若干列值得集合和相应的指向表中物理标志这些值的数据页的逻辑指针清单</p>
</blockquote>
<h2><span id="优点">优点</span></h2><ul>
<li>通过创建唯一索引，可以保证数据库中每一行数据的唯一性。</li>
<li>大大加快数据的检索速度。</li>
<li>加速表与表之间的联系。</li>
<li>在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。</li>
<li>通过使用索引，可以在查询的过程中使用优化隐藏器，提高系统性能。</li>
</ul>
<h2><span id="缺点">缺点</span></h2><ul>
<li>创建和维护索引需要耗费时间，时间随数据量增加而增加。</li>
<li>索引占据物理空间，如果建立聚簇索引，占用空间更大。</li>
</ul>
<h2><span id="分类">分类</span></h2><ul>
<li>聚集索引，表中数据按照索引的顺序来存储。叶子节点存储了真实的数据行，没有另外单独的数据页。</li>
<li>非聚集索引，表数据存储顺序与索引顺序无关，叶节点包含索引字段值及指向数据页数据行的逻辑指针。</li>
<li>一张表上只能创建一个聚集索引，因为真实数据的物理顺序只能是一种。如果一张表没有聚集索引，它被称为“堆集”，没有特定的顺序，新加的元行被添加到末尾。</li>
</ul>
]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title>ArrayList原理</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/ArrayList%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="实现方式">实现方式</span></h2><p>  存储数据是通过数组： transient Objectp[] elementData<br>  size字段： 存储整个数组的大小，</p>
<pre><code>&gt; 注意的是： size是每次add和remove都会自增和自减的，所以增加null也会size+1.
</code></pre><ul>
<li>是否允许空：<br>允许</li>
<li>是否允许重复数据：<br>允许</li>
<li>是否有序：<br>是</li>
<li>是否线程安全：<br>不是</li>
</ul>
<h2><span id="默认大小-10">默认大小 : 10</span></h2>  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="keyword">this</span>(<span class="number">10</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2><span id="扩容">扩容</span></h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ensureCapacity</span><span class="params">( <span class="keyword">int</span> minCapacity)</span></span>&#123;</span><br><span class="line">  modCount++;</span><br><span class="line">  <span class="keyword">int</span> oldCapacity = elementData.length;</span><br><span class="line">  <span class="keyword">if</span> (minCapacity &gt; oldCapacity) &#123;</span><br><span class="line">      Object oldData[] = elementData;</span><br><span class="line">      <span class="keyword">int</span> newCapacity = (oldCapacity * <span class="number">3</span>)/<span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">          <span class="keyword">if</span> (newCapacity &lt; minCapacity)</span><br><span class="line">      newCapacity = minCapacity;</span><br><span class="line">             <span class="comment">// minCapacity is usually close to size, so this is a win:</span></span><br><span class="line">             elementData = Arrays.copyOf(elementData, newCapacity);</span><br><span class="line">           &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2><span id="删除元素">删除元素</span></h2><ul>
<li>根据下标删除。</li>
<li><p>根据元素删除。</p>
<blockquote>
<p>删除跟元素匹配的 <em>第一个</em> 元素</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> numMoved = size - index - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index,</span><br><span class="line"></span><br><span class="line">         numMoved);</span><br><span class="line"></span><br><span class="line">elementData[--size] = <span class="keyword">null</span>; <span class="comment">// Let gc do its work</span></span><br></pre></td></tr></table></figure>
<ul>
<li>1、把指定元素后面位置的所有元素，利用System.arraycopy方法整体向前移动一个位置</li>
<li>2、最后一个位置的元素指定为null，这样让gc可以去回收它<blockquote>
<p>因为删除的时候，需要将后面所有元素向前移动一个位置，所以删除的时候，很消耗性能。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2><span id="插入元素">插入元素</span></h2><ul>
<li>add(T t)</li>
<li>add(int position,T t)<blockquote>
<p>插入时候会将所有后面的元素向后移动一个位置，很消耗性能。</p>
</blockquote>
</li>
</ul>
<h2><span id="arraylist的优缺点">ArrayList的优缺点</span></h2><ul>
<li>底层以数组方式存储，是一种随机访问方式，并且实现了RandomAccess接口，因此查找十分快速。</li>
<li><p>添加很方便，往数组的最后添加一个就行了。</p>
</li>
<li><p>删除和添加的时候涉及到移动后面所有数据，性能消耗比较大。    </p>
</li>
</ul>
<h2><span id="线程安全">线程安全</span></h2><blockquote>
<p>不是线程安全的，所有方法都没有Synchronized修饰，在并发情况下会出现安全问题。可以使用Collections.synchronizedList方式</p>
</blockquote>
<h2><span id="为什么arraylist的elementdata是用transient修饰的">为什么ArrayList的elementData是用transient修饰的？</span></h2><blockquote>
<p>private transient Object[] elementData;</p>
<p>ArrayList 实现了Serializable接口，所以是可以序列化的。但是elementData不一定是满的，没必要全部序列化。所以ArrayList重写了writeObject方法实现，增快了序列化的速度，见笑了序列化后的大小：<br>   <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeObject</span><span class="params">(java.io.ObjectOutputStream s)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> java.io.IOException</span>&#123;</span><br><span class="line"><span class="comment">// Write out element count, and any hidden stuff</span></span><br><span class="line"><span class="keyword">int</span> expectedModCount = modCount;</span><br><span class="line">s.defaultWriteObject();</span><br><span class="line">        <span class="comment">// Write out array length</span></span><br><span class="line">       s.writeInt(elementData.length);</span><br><span class="line">    <span class="comment">// Write out all elements in the proper order.</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;size; i++)</span><br><span class="line">           s.writeObject(elementData[i]);</span><br><span class="line">    <span class="keyword">if</span> (modCount != expectedModCount) &#123;</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java8新增功能</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java8%E6%96%B0%E5%A2%9E%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>[TOC]</p>
<h1><span id="接口中default关键字修饰方法可以增加默认实现">接口中default关键字修饰方法可以增加默认实现。</span></h1>  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Formula</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">default</span> <span class="keyword">double</span> <span class="title">sqrt</span><span class="params">(<span class="keyword">int</span> a )</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Math.sqrt(a);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1><span id="lambda表达式">Lambda表达式</span></h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Collections.sort(names,(a,b)-&gt;b.compareTo(a));</span><br></pre></td></tr></table></figure>
<h1><span id="函数式接口">函数式接口</span></h1> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@FunctionInterface</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Coverter</span>&lt;<span class="title">F</span>,<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">  <span class="function">T <span class="title">convert</span><span class="params">(F from)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Convert&lt;String,Integer&gt; converter = (from) -&gt; Integer.valueOf(from);</span><br><span class="line">Integer converted = converter.convert(<span class="string">&quot;123&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="方法和构造函数引用">方法和构造函数引用</span></h1><ul>
<li>静态方法引用<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Convert&lt;String,Integer&gt; converter = Integer::valueOf;</span><br><span class="line">Integer converted = converter.convert(<span class="string">&quot;123&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>通过:: 关键字获取方法或者构造函数的引用</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Something</span></span>&#123;</span><br><span class="line">  <span class="function">String <span class="title">startsWith</span><span class="params">(String s)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> String.valueOf(s.charAt(<span class="number">0</span>));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">Something something = <span class="keyword">new</span> Something();</span><br><span class="line">Converter&lt;String,String&gt; converter = something::startsWith;</span><br><span class="line">String converted = converter.convert(<span class="string">&quot;java&quot;</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>引用构造函数<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">  String firstName；</span><br><span class="line">  String lastName；</span><br><span class="line">  Person()&#123;&#125;;</span><br><span class="line">  Person(String firstName,String lastName)&#123;</span><br><span class="line">    <span class="keyword">this</span>.firstName=firstName;</span><br><span class="line">    <span class="keyword">this</span>.lastName=lastName;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//新建工厂类</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">PersonFactory</span>&lt;<span class="title">P</span> <span class="keyword">extends</span> <span class="title">Person</span>&gt;</span>&#123;</span><br><span class="line">  <span class="function">P <span class="title">create</span><span class="params">(String firstName,String lastName)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//通过构造函数引用将所有东西拼到一起，通过手动实现。</span></span><br><span class="line"></span><br><span class="line">PersonFactory&lt;Person&gt; personFactory = Person::<span class="keyword">new</span>;</span><br><span class="line">Person person = personFactory.create(<span class="string">&quot;earyant&quot;</span>,<span class="string">&quot;Lee&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1><span id="类库示例">类库示例</span></h1><h2><span id="predicates断言">Predicates(断言)</span></h2><blockquote>
<p>是一个布尔类型的函数，该函数只有一个输入函数，它实现了多种默认方法，用于处理复杂的逻辑动词。(and ,or,negate(否定))</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Predicate&lt;String&gt; predicate = (s)-&gt;s.length()&gt;<span class="number">0</span>;</span><br><span class="line">predicate.test(<span class="string">&quot;earyant&quot;</span>)  <span class="comment">// true</span></span><br><span class="line">predicate.negate().test(<span class="string">&quot;earyant&quot;</span>); <span class="comment">//false  </span></span><br><span class="line"></span><br><span class="line">Predicate&lt;Boolean&gt; nonNull = Objects::nonNull;</span><br><span class="line">Predicate&lt;Boolean&gt; isNull = Objects::isNull;</span><br><span class="line"></span><br><span class="line">Predicate&lt;String&gt; isEmpty = String::isEmpty;</span><br><span class="line">Predicate&lt;String&gt; isNotEmpty = isEmpty.negate();</span><br></pre></td></tr></table></figure>
<h2><span id="functions">Functions</span></h2><blockquote>
<p>接收一个参数，并返回单一的结果，默认方法可以将多个函数穿在一起(compose，andThen)：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Function&lt;String,Integer&gt; toInteger = Integer:valueOf;</span><br><span class="line">Function&lt;String,String&gt; backToString = toInteger.andThen(String::valueOf);</span><br><span class="line">backToString.apply(<span class="string">&quot;123&quot;</span>);</span><br></pre></td></tr></table></figure>
<h2><span id="suppliers">Suppliers</span></h2><blockquote>
<p>Supplier 接口产生一个给定类型的结果，与Function不同的是，Supplier没有输入参数。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Supplier&lt;Person&gt; personSupplier = Person:<span class="keyword">new</span>;</span><br><span class="line">personSupplier.get();</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring中的事务管理</title>
    <url>/posts/java/Spring%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="基本特征">基本特征</span></h2><ul>
<li>原子性</li>
<li>一致性</li>
<li>隔离性</li>
<li>持久性<h2><span id="事务的分类">事务的分类</span></h2></li>
<li>声明式事务</li>
<li>编程式事务</li>
</ul>
<h2><span id="数据错误类型">数据错误类型</span></h2><ul>
<li><p>脏读(dirty read)</p>
<blockquote>
<p>当前有两个事务A和B，当A事务对数据进行更改，但是还没提交（会有缓存），此时被事务B读取，然后事务A因其他原因导致失败数据回滚，此时的事务A的操作都是失败的，对数据的操作也是失败的，但是B事务已经读取了A没提交的数据，导致B读到了错误的数据。</p>
</blockquote>
</li>
<li><p>不可重复读(no-repeatable-read)</p>
<blockquote>
<p>当前有两个事务A和B，A事务将会对数据进行两次操作，当A事务操作一次成功后，B事务此时对数据操作更改了值并提交，随后A事务再进行读取数据，发现数据已经被更改，造成A事务的数据混乱。</p>
</blockquote>
</li>
<li><p>幻读(phantom read)</p>
<blockquote>
<p>与不可重复读同样都是多次读数据不一致的问题，但是no-repeatable-read强调的是本身需要的数据集改变了， phantom read强调多次查询得出的条件数据集改变了。</p>
</blockquote>
</li>
</ul>
<h2><span id="事务的隔离级别">事务的隔离级别</span></h2><ul>
<li>ISOLATION_DEFAULT 默认级别</li>
<li>ISOLATION_READ_UNCOMMIT   事务最低级别，允许其他事务看到此事务中未提交的数据。   <strong>这种级别会导致脏读、幻读、不可重复读</strong></li>
<li>ISOLATION_READ_COMMIT   保证数据提交后才能被另外一个事务看到。  <strong>这种级别可以防止脏读，但是不能防止不可重复读和幻读</strong></li>
<li>ISOLATION_REPEATABLE_READ       <strong>这种级别可以防止脏读、不可重复读，但是不能防止幻读</strong></li>
<li>ISOLATION_SERALIZABLE     <strong>最强级别，可以防止脏读、不可重复读、幻读</strong></li>
</ul>
<h2><span id="事务的传播行为">事务的传播行为</span></h2><ul>
<li>PROPAGATION_REQUIRED 如果存在一个事务，就是用这个事务，如果没有事务，就开启一个新的事务<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//事务属性 PROPAGATION_REQUIRED</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">methodA</span><span class="params">()</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    methodB();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//事务属性 PROPAGATION_REQUIRED</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">methodB</span><span class="params">()</span></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>PROPAGATION_SUPPORTS 如果存在一个事务，就用这个事务，如果没有事务，就非事务执行，但是对于事务同步管理器，PROPAGATION_SUPPORTS和不使用事务有少许区别。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//事务属性 PROPAGATION_REQUIRED</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">methodA</span><span class="params">()</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    methodB();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//事务属性 PROPAGATION_SUPPORTS</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">methodB</span><span class="params">()</span></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
当通过methodA调用methodB时，methodB就是用methodA的事务，如果单独调用methodB的时候，methodB就非事务执行。</li>
<li>PROPAGATION_MANDATORY 如果存在一个事务，就是用当前事务，如果不存在事务，就抛出一个异常。</li>
<li>PROPAGATION_REQUIRED_NEW 开启一个新的事务，<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//事务属性 PROPAGATION_REQUIRED</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">methodA</span><span class="params">()</span></span>&#123;</span><br><span class="line">  doSomeThingA();</span><br><span class="line">  methodB();</span><br><span class="line">  doSomeThingB();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//事务属性 PROPAGATION_REQUIRES_NEW</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">methodB</span><span class="params">()</span></span>&#123;</span><br><span class="line">……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
相当于：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TransactionManager tm = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="comment">//获得一个JTA事务管理器</span></span><br><span class="line">  tm = getTransactionManager();</span><br><span class="line">  tm.begin();<span class="comment">//开启一个新的事务</span></span><br><span class="line">  Transaction ts1 = tm.getTransaction();</span><br><span class="line">  doSomeThing();</span><br><span class="line">  tm.suspend();<span class="comment">//挂起当前事务</span></span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    tm.begin();<span class="comment">//重新开启第二个事务</span></span><br><span class="line">    Transaction ts2 = tm.getTransaction();</span><br><span class="line">    methodB();</span><br><span class="line">    ts2.commit();<span class="comment">//提交第二个事务</span></span><br><span class="line">  &#125;</span><br><span class="line">  Catch(RunTimeException ex)&#123;</span><br><span class="line">    ts2.rollback();<span class="comment">//回滚第二个事务</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">finally</span>&#123;</span><br><span class="line">   <span class="comment">//释放资源</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//methodB执行完后，复恢第一个事务</span></span><br><span class="line">  tm.resume(ts1);</span><br><span class="line">  doSomeThingB();</span><br><span class="line">  ts1.commit();<span class="comment">//提交第一个事务</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span>(RunTimeException ex)&#123;</span><br><span class="line">  ts1.rollback();<span class="comment">//回滚第一个事务</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">finally</span>&#123;</span><br><span class="line"><span class="comment">//释放资源</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在这里，我把ts1称为外层事务，ts2称为内层事务。从上面的代码可以看出，ts2与ts1是两个独立的事务，互不相干。Ts2是否成功并不依赖于ts1。如果methodA方法在调用methodB方法后的doSomeThingB方法失败了，而methodB方法所做的结果依然被提交。而除了methodB之外的其它代码导致的结果却被回滚了。使用PROPAGATION_REQUIRES_NEW,需要使用JtaTransactionManager作为事务管理器。</p>
</blockquote>
</li>
</ul>
<ul>
<li>PROPAGATION_NOT_SUPPORTED 总是非事务执行，并挂起任何事务，也需要JTATransctionManager作为事务管理器</li>
<li>PROPAGATION_NEVER  总是非事务执行，如果存在一个事务，则抛出异常。</li>
<li>PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中. 如果没有活动事务, 则按TransactionDefinition.PROPAGATION_REQUIRED 属性执行。这是一个嵌套事务,使用JDBC 3.0驱动时,仅仅支持DataSourceTransactionManager作为事务管理器。需要JDBC 驱动的java.sql.Savepoint类。有一些JTA的事务管理器实现可能也提供了同样的功能。使用PROPAGATION_NESTED，还需要把PlatformTransactionManager的nestedTransactionAllowed属性设为true;而nestedTransactionAllowed属性值默认为false;<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//事务属性 PROPAGATION_REQUIRED</span></span><br><span class="line">methodA()&#123;</span><br><span class="line">doSomeThingA();</span><br><span class="line">methodB();</span><br><span class="line">doSomeThingB();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//事务属性 PROPAGATION_NESTED</span></span><br><span class="line">methodB()&#123;</span><br><span class="line">……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果单独调用methodB方法，则按REQUIRED属性执行。如果调用methodA方法，相当于下面的效果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">  Connection con = <span class="keyword">null</span>;</span><br><span class="line">Savepoint savepoint = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line"> con = getConnection();</span><br><span class="line"> con.setAutoCommit(<span class="keyword">false</span>);</span><br><span class="line"> doSomeThingA();</span><br><span class="line"> savepoint = con2.setSavepoint();</span><br><span class="line"> <span class="keyword">try</span>&#123;</span><br><span class="line">     methodB();</span><br><span class="line"> &#125;<span class="keyword">catch</span>(RuntimeException ex)&#123;</span><br><span class="line">    con.rollback(savepoint);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">finally</span>&#123;</span><br><span class="line">   <span class="comment">//释放资源</span></span><br><span class="line">&#125;</span><br><span class="line">  doSomeThingB();</span><br><span class="line">  con.commit();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span>(RuntimeException ex)&#123;</span><br><span class="line">  con.rollback();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">finally</span>&#123;</span><br><span class="line"> <span class="comment">//释放资源</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PROPAGATION_NESTED 与PROPAGATION_REQUIRES_NEW的区别:它们非常类似,都像一个嵌套事务，如果不存在一个活动的事务，都会开启一个新的事务。使用PROPAGATION_REQUIRES_NEW时，内层事务与外层事务就像两个独立的事务一样，一旦内层事务进行了提交后，外层事务不能对其进行回滚。两个事务互不影响。两个事务不是一个真正的嵌套事务。同时它需要JTA事务管理器的支持。<br>  使用PROPAGATION_NESTED时，外层事务的回滚可以引起内层事务的回滚。而内层事务的异常并不会导致外层事务的回滚，它是一个真正的嵌套事务。DataSourceTransactionManager使用savepoint支持PROPAGATION_NESTED时，需要JDBC 3.0以上驱动及1.4以上的JDK版本支持。其它的JTA TrasactionManager实现可能有不同的支持方式。<br>  PROPAGATION_REQUIRES_NEW 启动一个新的, 不依赖于环境的 “内部” 事务. 这个事务将被完全 commited 或 rolled back 而不依赖于外部事务, 它拥有自己的隔离范围, 自己的锁, 等等. 当内部事务开始执行时, 外部事务将被挂起, 内务事务结束时, 外部事务将继续执行。<br>  另一方面, PROPAGATION_NESTED 开始一个 “嵌套的” 事务,  它是已经存在事务的一个真正的子事务. 潜套事务开始执行时,  它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交。<br>  由此可见, PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED 的最大区别在于, PROPAGATION_REQUIRES_NEW 完全是一个新的事务, 而 PROPAGATION_NESTED 则是外部事务的子事务, 如果外部事务 commit, 潜套事务也会被 commit, 这个规则同样适用于 roll back.<br>  PROPAGATION_REQUIRED应该是我们首先的事务传播行为。它能够满足我们大多数的事务需求。</p>
</blockquote>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ结合Aop实现高并发Log记录</title>
    <url>/posts/java/RabbitMQ%E7%BB%93%E5%90%88Aop%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%B9%B6%E5%8F%91Log%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><ul>
<li>[] <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1505634383&amp;ver=397&amp;signature=4eGGO7W4eNN4mhNGRac0hSUTD4tyNwjT0H7tPfYWtEtLPR-TQ0VZAn2dItajttVRP-XgFlJCnrNjkPB95EHmxv-H2k1*uzuHen-VibsJg-464Y8MjAZPKAeuZPBjzBhn&amp;new=1">参考</a></li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>aop原理及实现</title>
    <url>/posts/java/aop%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="静态代理-动态代理">静态代理、动态代理</span></h2><p>1、AspectJ 使用静态代理，生成class文件时，会侵入到代码中。<br>2、Spring AOP 使用动态代理，不会侵入代码，而是在内存中临时为代码生成一个AOP对象，这个AOP对象包含目标对象的全部方法，并且在特定切点进行增强处理，并且调原对象的方法。</p>
<ul>
<li>Jvm动态代理： 通过反射接收代理的类，并要求被代理的类必须实现一个接口。JVM代理的核心是InvocationHandler接口和proxy类。</li>
<li>CGLib(Code Generation Library)： 如果目标没有实现接口，那么Spring会使用CGLib动态代理目标类。它是一个代码生成的类库，可以在运行时动态生成某个类的子类。  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注意： CGLib是通过继承方式实现的，如果某个类被标记为final，是不能通过CGLib实现动态代理的。</span><br></pre></td></tr></table></figure>
<h2><span id="示例使用了cglib">示例(使用了CGLib)：</span></h2>定义Person类，其中sayHello方法是切点，切点被Timer注解修饰。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">  <span class="meta">@Timer</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sayHello</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;sayHello&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
配置切点：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdviceTest</span></span>&#123;</span><br><span class="line">  <span class="meta">@Pointcut(&quot;@annotation(com.earyant.aop.Timer)&quot;)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pointcut</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Before(&quot;pointcut()&quot;)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;before&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
在Mail类中调用。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="keyword">private</span> Person person;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    person.sayHello();</span><br><span class="line">    System.out.println(person.getClass().getName());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
输出结果：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">before</span><br><span class="line">sayHello</span><br><span class="line">com.earyant.aop.Person$$EnhancerBySpringCGLIB$$56b89168</span><br></pre></td></tr></table></figure>
<h2><span id="示例jvm代理">示例(JVM代理)</span></h2>定义一个接口：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Chinese</span></span>&#123;</span><br><span class="line">  sayHello();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
令Person类继承自Chinese类。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">Chinese</span></span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="meta">@Timer</span></span><br><span class="line">  sayHello()&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;sayHello&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
此代码运行的结果是：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">before</span><br><span class="line">sayHello</span><br><span class="line">com.sun.proxy.$Proxy53</span><br></pre></td></tr></table></figure>
证明使用了JVM代理。</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM调优</title>
    <url>/posts/java/jvm/JVM%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>从敲下www.baidu.com到浏览器显示页面，都发生了什么？</title>
    <url>/posts/%E6%9D%82%E7%B1%BB/%E4%BB%8E%E6%95%B2%E4%B8%8Bwww-baidu-com%E5%88%B0%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%BE%E7%A4%BA%E9%A1%B5%E9%9D%A2%EF%BC%8C%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="名词定义">名词定义</span></h1><h2><span id="url">URL</span></h2><pre><code>URL（Uniform Resource Locator），统一资源定位符，实际就是网站网址，又称域名。在茫茫网络世界中，浏览器就是靠URL来查找资源位置。URL包含协议部分，是浏览器和www万维网之间的沟通方式，它会告诉浏览器正确在网路上找到资源位置。常见的协议有http、https、ftp、file、telnet等。其中http是最常见的网络传输协议，而https则是进行加密的网络传输。
</code></pre><h2><span id="ip">IP</span></h2><pre><code>为了便于记忆或辨识，人们使用域名来登录网站，每个域名背后有对应的IP地址。每个网站就是靠IP来定位的。IP是因特网中的每台连接到网络的计算机为实现相互通信而遵循的规则协议。IP分为局域网IP和全网IP。办公中常用的飞秋工具，就是使用办公室局域网IP进行通信的典型表现。每台计算机的本机IP都是127.0.0.1（即localhost）。浏览器并不能识别URL是什么，因此从输入URL开始，浏览器就要做域名解析，也就是IP寻址的工作。
</code></pre><h2><span id="dns">DNS</span></h2><pre><code>DNS（Domain Name System，域名系统）——记录域名和IP地址相互映射的信息，人们可以免于记住IP数串。全国DNS信息可在网上查找到，各省都有对应分配不同的IP网段。大型企业会有自己的DNS服务器，专门存储域名和IP的映射关系，例如为大多数人熟知的谷歌DNS服务器，地址8.8.8.8。
</code></pre><h1><span id="查找">查找</span></h1><h2><span id="域名解析">域名解析</span></h2><p>  当用户在浏览器中输入url后,你使用的电脑会发出一个DNS请求到本地DNS服务器。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动,DNS请求到达本地DNS服务器之后会有以下几个步骤：</p>
<h3><span id="1-浏览器缓存">1. 浏览器缓存</span></h3><p>  浏览器对本地缓存进行查找，查看是否有该域名历史记录，如果有首先直接对缓存地址访问。<br>  Chrome浏览器看本身的DNS缓存时间比较方便，在地址栏输入chrome://net-internals/#dns，就可以看到了</p>
<h3><span id="2-本地hosts文件查找ip地址">2. 本地hosts文件查找ip地址</span></h3><p>  浏览器若无缓存或者缓存地址访问无效，则首先对hosts文件查找对应域名对应ip地址。</p>
<h3><span id="3-查找路由器缓存">3. 查找路由器缓存</span></h3><p>  如果系统缓存中也找不到，那么查询请求就会发向路由器，路由器一般会有自己的DNS缓存。</p>
<h3><span id="4-查找ispinternet-service-provider-dns-缓存">4. 查找ISP(Internet Service Provider) DNS 缓存</span></h3><p>如果路由器缓存中也找不到，那么就查询ISP DNS 缓存服务器了。<br>我们都知道在我们的网络配置中都会有”DNS服务器地址”这一项，操作系统会把这个域名发送给这里设置的DNS，比如114.114.114.114,也就是本地区的域名服务器，通常是提供给你接入互联网的应用提供商。而114.114.114.114是国内移动、电信和联通通用的DNS。</p>
<h3><span id="5-迭代查询">5. 迭代查询</span></h3><p>  如果前面都找不到DNS缓存的话，会有以下几个步骤：</p>
<ol>
<li>本地 DNS服务器将该请求转发到互联网上的根域（根域没有名字，在DNS系统中就用一个空字符串来表示。例如www.baidu.com.现在的DNS系统都不会要求域名以.来结束，即www.baidu.com就可以解析了，但是现在很多DNS解析服务商还是会要求在填写DNS记录的时候以.来结尾域名。）</li>
<li>根域将所要查询域名中的顶级域（比如要查询www.baidu.com，该域名的顶级域就是com）的服务器IP地址返回到本地DNS。</li>
<li>本地DNS根据返回的IP地址，再向顶级域（就是com域）发送请求， com域服务器再将域名中的二级域（即www.baidu.com中的baidu.com）的IP地址返回给本地DNS。</li>
<li>本地DNS再向二级域发送请求进行查询。</li>
<li><p>之后不断重复这样的过程，直到本地DNS服务器得到最终的查询结果，并返回到主机。这时候主机才能通过域名访问该网站。<br>下图能很好的说明这个迭代查询:<br><img data-src="./dns寻址过程.gif" alt><br>当查找到对应的IP地址之后，通过IP地址查找到对应的服务器，浏览器将用户发起的http请求发送给服务器。例如：GET <a href="http://www.baidu.com/">http://www.baidu.com/</a> HTTP/1.1</p>
<h3><span id="6-cdn">6. CDN</span></h3><p>CDN的基本原理是广泛采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区或网络中，在用户访问网站时，利用全局负载技术将用户的访问指向距离最近的工作正常的缓存服务器上，由缓存服务器直接响应用户请求。</p>
<h1><span id="服务器处理用户请求">服务器处理用户请求</span></h1><h2><span id="代理">代理</span></h2><h3><span id="正向代理">正向代理</span></h3><p>正向代理是一种最终用户知道并主动使用的代理方式，比如三台支付服务服务器在微服务SpringCloud中的服务注册中心中注册了三个地址（1.1.1.1,2.2.2.2,3.3.3.3），用户服务服务器访问服务注册中心请求地址正向代理返回某一个地址（1.1.1.1），支付服务缓存到本地，在缓存有效期时间内，直接访问1.1.1.1服务器就可以了。</p>
<h3><span id="反向代理">反向代理</span></h3><p>在计算机世界里，由于单个服务器的处理客户端（用户）请求能力有一个极限，当用户的接入请求蜂拥而入时，会造成服务器忙不过来的局面，可以使用多个服务器来共同分担成千上万的用户请求，这些服务器提供相同的服务，对于用户来说，根本感觉不到任何差别。比如你只需要敲下www.baidu.com这一个域名，其实背后有很多服务器支持着，每个人的请求会被分发到不同的服务器中。</p>
<p>反向代理需要有一个负载均衡设备来分发用户请求，将用户请求分发到空闲的服务器上，负载均衡设备本身也可以有多个。</p>
<p><strong>好处</strong>：<br>用户服务做域名解析时，解析到的ip地址是负载均衡设备的ip地址，不会暴露服务器地址。当需要增加、减少服务器数量时，用户一点都察觉不到。</p>
<h2><span id="负载均衡反向代理的实现">负载均衡（反向代理的实现）</span></h2><h3><span id="硬件负载均衡">硬件负载均衡</span></h3><p>F5</p>
<h3><span id="软件负载均衡">软件负载均衡</span></h3><ul>
<li>LVS(七层协议第四层)<br>LVS是Linux Virtual Server。lvs工作在4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等等。同时，若跟硬件负载均衡相比它的缺点也不容忽视，LVS要求技术水平很高，操作上也比较复杂，配置也很繁琐，没有赖以保障的服务支持，稳定性来说也相对较低（人为和网络环境因素更多一些）。</li>
<li>nginx(七层协议第七层)<br>Nginx是工作在第七层，对于网络的依赖性就小的多。与LVS相比，Nginx的安装和配置也相对简单一些，另外测试方面也更简单，主要还是因为对网络依赖性小的缘故。Nginx有一点不好的就是应用要比LVS少。一般我们做软件负载均衡的时候，通常会先考虑LVS，但是遇到比较复杂的网络环境时，用LVS可能会遇到很多麻烦，不妨就考虑尝试一下Nginx。</li>
</ul>
</li>
</ol>
<h3><span id="容器处理">容器处理</span></h3><ul>
<li><p>常用Java EE容器</p>
<ul>
<li>tomcat</li>
<li>jetty</li>
<li>jBoss<br>tomcat服务器启动main方法，当command命令行是start，就执行start方法。反射调用Catalina类的start()方法。这里面会弄出一个StandardServer对象（内部会使用Digester库去解析server.xml，那个里面的东西），并调用它的start()方法，把那些组件都启动起来。<br>其中在连接器的启动过程中，会弄出一个叫做endpoint的东西去和底层的网络IO打交道，会调用其bind()方法，绑定端口号。<br>connector将请求交给他所在的service里对应的engine，来处理；<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Engine</span> <span class="attr">defaultHost</span>=<span class="string">&quot;localhost&quot;</span> <span class="attr">name</span>=<span class="string">&quot;Catalina&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>
每当HttpConnector的ServerSocket得到客户端的连接时，会创建一个Socket。<br>考虑到客户端同时发来的请求数可能有很多， 所以tomcat 中默认维护着一个连接池<br>NioChannel channel = nioChannels.pop();<br>channel.setIOChannel(socket);<br>channel.reset();<br>getPoller0().register(channel);<br>context随后在自己的mapping table里寻找servlet-mapping拦截路径为*.jsp的servlet，这里找到得是JSPServlet处理<br>找到JSPServlet后，调用JSPServlet的doGet或doPOST方法；<br>context执行完毕后，将HttpServletResponse 返回给Host；<br>host将HttpServletResponse 返回给engine；<br>engine 将HttpServletResponse 返回给 connector；<br>connector 将 HttpServletResponse 返回给用户的browser；</li>
</ul>
<p>tomcat容器在启动后，context对应的项目在初始化的时候，要加载相应的servlet，加载的顺序为：<br>$CATALINA_HOME/conf/web.xml里定义的servlet（对应于上面第5步的JSPServlet）；<br>context对应的项目WEB-INF下的web.xml中定义的servlet；</p>
<h3><span id="应用处理">应用处理</span></h3></li>
</ul>
<ol>
<li>Controller接收到请求，转发给service；</li>
<li>service进行逻辑处理，如果有redis、ehcache等缓存则优先查询缓存；</li>
<li>如果是dubbo或者springcloud分布式，则通过dubbo服务或者restful请求调用其他服务模块请求信息；</li>
<li>调用dao查询数据库；</li>
<li>返回数据给service再给controller，controller再组装数据以及view返回；</li>
<li>view层jsp或者velocity等模板引擎解析数据</li>
</ol>
<h3><span id="mysql架构">Mysql架构</span></h3><ol>
<li>服务器先会检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果。</li>
<li>服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划；</li>
<li>MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询；</li>
<li>将结果返回给客户端。<h4><span id="mysql能够处理的优化类型">MySQL能够处理的优化类型：</span></h4><ol>
<li>重新定义关联表的顺序<br>数据表的关联并不总是按照在查询中指定的顺序进行，决定关联的顺序是优化器很重要的一部分功能。</li>
<li>将外连接转化成内连接<br>并不是所有的outer join语句都必须以外连接的方式执行。诸多因素，例如where条件、库表结构都可能会让外连接等价于一个内连接。MySQL能够识别这点并重写查询，让其可以调整关联顺序。</li>
<li>使用等价变换规则<br>MySQL可以使用一些等价变换来简化并规范表达式。它可以合并和减少一些比较，还可以移除一些恒成立和一些恒不成立的判断。例如：（5=5 and a&gt;5）将被改写为a&gt;5。类似的，如果有（a<b and b="c）and" a="5，则会被改写为">5 and b=c and a=5。</b></li>
<li>优化count()、min()和max()<br>索引和列是否为空通常可以帮助MySQL优化这类表达式。例如，要找到一列的最小值，只需要查询对应B-tree索引最左端的记录，MySQL可以直接获取索引的第一行记录。在优化器生成执行计划的时候就可以利用这一点，在B-tree索引中，优化器会讲这个表达式最为一个常数对待。类似的，如果要查找一个最大值，也只需要读取B-tree索引的最后一个记录。如果MySQL使用了这种类型的优化，那么在explain中就可以看到“select tables optimized away”。从字面意思可以看出，它表示优化器已经从执行计划中移除了该表，并以一个常数取而代之。<br>类似的，没有任何where条件的count(*)查询通常也可以使用存储引擎提供的一些优化，例如，MyISAM维护了一个变量来存放数据表的行数。</li>
<li>预估并转化为常数表达式</li>
<li>覆盖索引扫描<br>当索引中的列包含所有查询中需要使用的列的时候，MySQL就可以使用索引返回需要的数据，而无需查询对应的数据行。</li>
<li>子查询优化<br>MySQL在某些情况下可以将子查询转换成一种效率更高的形式，从而减少多个查询多次对数据进行访问。</li>
<li>提前终止查询<br>在发现已经满足查询需求的时候，MySQL总是能够立即终止查询。一个典型的例子就是当使用了limit子句的时候。除此之外，MySQL还有几种情况也会提前终止查询，例如发现了一个不成立的条件，这时MySQL可以立即返回一个空结果。<br>上面的例子可以看出，查询在优化阶段就已经终止。</li>
<li>等值传播</li>
<li>列表in()的比较<br>在很多数据库系统中，in()完全等同于多个or条件的字句，因为这两者是完全等价的。在MySQL中这点是不成立的，MySQL将in()列表中的数据先进行排序，然后通过二分查找的方式来确定列表中的值是否满足条件，这是一个o(log n)复杂度的操作，等价转换成or的查询的复杂度为o(n)，对于in()列表中有大量取值的时候，MySQL的处理速度会更快。</li>
</ol>
</li>
</ol>
<h1><span id="浏览器渲染">浏览器渲染</span></h1>]]></content>
  </entry>
  <entry>
    <title>SpringMvc工作流程</title>
    <url>/posts/java/SpringMvc%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="springmvc核心流程主要在dodispatch方法中">SpringMVC核心流程,主要在doDispatch方法中</span></h2><ul>
<li>1、用户发送请求，被SpringMvc的DispatcherServlet捕获到</li>
<li>2、DispatcherServlet对获取到的URL进行解析，得到统一定位符URI，然后根据URI调用HandlerMapping获得Handler对象以及跟handler相关的拦截器，最后以HandlerExecutionChain对象形式返回。</li>
<li>3、DispatcherServlet根据返回的Handler选择合适的HandlerAdapter，如果找到了HandlerAdapter,在之前就会执行preHandler方法</li>
<li>4、提取request中的模型数据，填充Handler入参，开始执行Handler<ul>
<li>在填充的过程中，SpringMvc会做一些操作：<ul>
<li>HttpMessageConvert ： 将消息转换成一个对象，将对象转换成指定的响应信息。</li>
<li>数据转换： 比如将String转换成Integer等</li>
<li>数据格式化： 日期格式化等</li>
<li>数据验证： 验证数据的有效性，包括长度、类型等等，验证结果存储到BindingResult或者Error中。</li>
</ul>
</li>
</ul>
</li>
<li>5、Handler执行完成后，像DispatcherServlet返回一个ModelAndView。</li>
<li>6、根据返回的ModelAndView选择一个合适的ViewResolver返回给DispatcherServlet</li>
<li>7、ViewResolveModel和View来渲染视图</li>
<li>8、将渲染结果返回给客户端</li>
</ul>
<h2><span id="处理关键">处理关键</span></h2><ul>
<li>DispatcherServlet的HandlerMapping集合中根据请求的URL匹配每一个handlerMapping对象中的某个handler,匹配成功后将会返回这个handler的处理连接handlerExecutorChain对象，而这个对象中包括多个handlerInterceptor。</li>
<li>HandlerInterceptor中包含三个方法<ul>
<li>preHandler，在Handler执行之前调用。</li>
<li>postHandler，在Handler执行之后调用。</li>
<li>afterComplete，在view渲染完成后，dispatchServlet返回之前调用。</li>
</ul>
</li>
<li>当preHandler返回false时，请求将在执行afterComplete后直接返回，不会执行handler。    </li>
</ul>
<h2><span id="首先有几个类需要声明modelandview-handlerexecutionchain-handlermapping-handlermethod-handleradapter">首先有几个类需要声明,ModelAndView、HandlerExecutionChain、HandlerMapping、HandlerMethod、HandlerAdapter。</span></h2><ul>
<li>1、HandlerMethod(org.springframework.web.method.HandlerMethod)，这个类为中存放了某个bean对象和该bean对象的某个要处理的Method对象。</li>
<li>2、HandlerMapping,作用为通过request对象，获取对应的HandlerMethod对象。</li>
<li>3、HandlerExecutionChain作用为通过加入Interceptor拦截器包装HandlerMapping返回的HandlerMethod对象。让待处理的方法对象与拦截器称为一个整体,即执行链。</li>
<li>4、ModelAndView,顾名思义。Model即MVC的M，View即MVC的V。其对象存放的正是数据与视图信息。</li>
<li>5、HandlerAdapter:作用为具体处理HandlerMethod,即通过它调用某个方法。</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>ArrayList和LinkedList对比</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/ArrayList%E5%92%8CLinkedList%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="接口">接口</span></h2><ul>
<li>ArrayList ： 继承自List接口</li>
<li>LinkedList ： 继承自List和Deque接口</li>
</ul>
<h2><span id="存储结构">存储结构</span></h2><ul>
<li>ArrayList ：底层用数组进行存储</li>
<li>LinkedList ： 底层用双链表进行存储 </li>
</ul>
<h2><span id="优点">优点</span></h2><ul>
<li>ArrayList ： 访问速度快，插入和删除比较慢 ，需要移动元素</li>
<li>LinkedList ： 访问比较慢，插入和删除比较快 ， 需要链式查询</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java集合框架</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="顶级接口">顶级接口：</span></h2><ul>
<li>Collection<br>  <img data-src="img/Collection接口继承关系.jpg" alt></li>
<li>Map<br>  <img data-src="img/Map接口继承关系.jpg" alt></li>
</ul>
<h2><span id="顶级类">顶级类：</span></h2><ul>
<li>Collections</li>
</ul>
<h3><span id="接口描述">接口描述</span></h3><ul>
<li><p>Collection ：  不提供直接子类继承，只提供继承的子接口（List和Set）</p>
<ul>
<li><p>List : 有序的Collection，控制元素的插入位置，和通过索引访问List数据，允许相同的Key。</p>
<ul>
<li>Verctor<ul>
<li>Stack</li>
</ul>
</li>
<li>ArrayList</li>
<li><p>LinkedList( 也继承自 Deque)</p>
</li>
<li><p><a href="https://earyant.github.io/2017/09/10/ArrayList%E5%92%8CLinkedList%E5%AF%B9%E6%AF%94/">ArrayList和LinkedList对比</a></p>
</li>
</ul>
</li>
<li><p>Set ： 不保存重复数据</p>
<ul>
<li>HashSet<ul>
<li>LinkedHashSet</li>
</ul>
</li>
<li>SortedSet<ul>
<li>TreeSet</li>
</ul>
</li>
<li>EnumSet</li>
</ul>
</li>
<li>Queue<ul>
<li>DeQue<ul>
<li>LinkedList</li>
</ul>
</li>
<li>PriorityQueue</li>
</ul>
</li>
</ul>
</li>
<li>Map<ul>
<li>EnumMap</li>
<li>HashMap<ul>
<li>LinkedHashMap</li>
</ul>
</li>
<li>IdentityMap</li>
<li>HashTable<ul>
<li>Properties</li>
</ul>
</li>
<li>SortedMap<ul>
<li>TreeMap</li>
</ul>
</li>
<li>WeakHashMap</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>高可用+高并发+负载均衡架构设计(转发)</title>
    <url>/posts/java/%E9%AB%98%E5%8F%AF%E7%94%A8-%E9%AB%98%E5%B9%B6%E5%8F%91-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-%E8%BD%AC%E5%8F%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><img data-src="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651960393&amp;idx=1&amp;sn=23cf8438b436c531c81b3f09a3d5e8fb&amp;chksm=bd2d01958a5a88838e6ef493ccb1fe0854f7216f3863fbe9798eec5019dc58d73d4e95b3132f&amp;mpshare=1&amp;scene=1&amp;srcid=09082gOCvZ5mjeN9YZ8HSg0o#rd" alt="原地址"></p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title>微信机器人流程</title>
    <url>/posts/java/%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>[TOC]</p>
<h2><span id="获取uuid和二维码">获取uuid和二维码：</span></h2><ul>
<li>在公众号输入8，即可返回二维码图片；<ul>
<li>生成uuid；</li>
<li>生成二维码；</li>
<li>redis中保存要登陆用户的信息；</li>
<li>返回二维码。</li>
</ul>
</li>
</ul>
<h2><span id="后台守护进程">后台守护进程：</span></h2><ul>
<li>开启一个守护线程：<ul>
<li>获取redis中保存的用户信息；</li>
<li>判断如果未登陆则继续执行以下操作，如果已经登陆了，返回，不做任何操作。</li>
<li>loginService.login()<ul>
<li>代码登陆逻辑，如果登陆了，将状态setAlive置为已经登陆，若未登陆，sleep1秒继续。</li>
<li>将联系人信息保存到redis中</li>
</ul>
</li>
<li>webWxInit()<ul>
<li>获取user信息，并保存到数据库。</li>
<li>获取用户的联系人信息，并保存到数据库；</li>
<li>获取SyncKeyBean信息，并保存到数据库；</li>
</ul>
</li>
<li>wxStatusNotify()<ul>
<li>微信通知状态改变，手机端提示网页端登陆成功。</li>
</ul>
</li>
<li>startReceiving()<ul>
<li>开启消息接收。</li>
<li>开启新线程：<ul>
<li>syncCheck() 检查是否有新消息<ul>
<li>状态为0(收到正常报文)：<ul>
<li>webWxSync() 联网获取新消息；<ul>
<li>通过初始化过去的SyncKey参数进行获取，返回成功后，要把新返回的SyncKey保存到数据库中，下次用新SyncKey进行获取新信息。</li>
<li>对获取到的新信息进行操作。 MsgCenter.produceMsg();</li>
<li>保存消息到数据库。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>webWxGetContact() 获取好友列表</li>
<li>WebWxBatchGetContact()</li>
<li>setUserInfo() 缓存本次好友信息。</li>
<li>CheckLoginStatusThread开启登陆状态线程。</li>
</ul>
</li>
</ul>
<h2><span id="20170904">2017.09.04</span></h2><p>  做好微信机器人，在微信公众平台界面发送8将返回一个二维码，扫码登陆后即可开启机器人。<br>  机器人功能： //TODO</p>
<pre><code>* 集成聊天机器人功能。
* 备份聊天记录。
* 爬取所有用户，并分析用户联系人的男女比例，整合头像。
* 爬取公众号文章。
* 撤回消息备份
* 关键词监听
* 消息搜索
* 信息分析
* 查看/删除文件[文件名] e.g. 查看文件[123345234.mp3]
* 撤回附件列表 (查看都有哪些保存在电脑中的已撤回附件)
* 清空附件列表 (清空已经保存在电脑中的附件)
* 添加关键词[关键词] e.g. 设置关键词[在不在]
* 删除关键词[关键词] e.g. 删除关键词[在不在]
* 清空关键词 清空已经设置的所有关键词
* 查看关键词 查看目前设置的关键词
* 添加签到口令#公众号:签到口令# e.g. 添加签到口令#招商银行信用卡:签到#
* 删除签到口令#公众号# e.g. 删除签到口令#招商银行信用卡#
* 查看签到口令 查看已经存在的公众和和对应的签到口令
* 清空签到口令 清空所有签到口令
* 截图 截取当前屏幕发送到文件助手
* 添加自动回复#针对的关键词:回复内容# e.g.添加自动回复#在不在:我现在有事情，待会儿回复你#
* 删除自动回复#针对的关键词# e.g.删除自动回复#在不在#
* 清空自动回复 清空所有的自定义回复规则
* 关闭自动回复
* 打开自动回复
* 退出程序
</code></pre><h2><span id="备份聊天功能">备份聊天功能：</span></h2><pre><code>* 发送 “开启**回复” 即可回复 ** 信息
  后台将配置记录到sql中，并缓存到redis中。
</code></pre>]]></content>
  </entry>
  <entry>
    <title>Mysql引擎myisam和innodb的异同</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E5%BC%95%E6%93%8Emyisam%E5%92%8Cinnodb%E7%9A%84%E5%BC%82%E5%90%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="myisam和innodb不同之处">myisam和innodb不同之处</span></h2><ul>
<li>1事务的支持不同：<ul>
<li>innodb支持事务；</li>
<li>myisam不支持事务；</li>
</ul>
</li>
<li>2锁粒度<ul>
<li>indodb行锁应用</li>
<li>myisam表锁</li>
</ul>
</li>
<li>3存储空间<ul>
<li>innodb既缓存索引文件又缓存数据文件；</li>
<li>myisam只缓存索引文件。</li>
</ul>
</li>
<li>4存储结构<ul>
<li>myisam数据文件的扩展名为.myd myData，索引文件的扩展名是.myi myIndex</li>
<li>innodb所有的表都保存在同一个数据文件里面 即为 .ibd</li>
</ul>
</li>
<li>统计记录行数<ul>
<li>myisam保存表的总行数，select count(*) from table 会直接取出该值</li>
<li>innodb没有保存表的中行书，select count(*) from table 就会遍历整个表，消耗相当大。</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap全解析</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/HashMap%E5%85%A8%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="定义">定义</span></h1><p>HashMap实现了Map接口，继承自AbstactMap。其中Map接口定义了键映射到值的规则。<br>    public class HashMap<k,v><br>    extends AbstractMap<k,v><br>    implements Map<k,v>, Cloneable, Serializable<br>    <img data-src="../img/java.util.map类图.png" alt><br><em>注意</em></k,v></k,v></k,v></p>
<pre><code>* HashMap: 它根据键的hashCode值存储数据，大多数情况下可以直接定位到他的值，因此有很乖的访问速度，但是遍历的顺序是不确定的，HashMap最多只允许一条记录为null，允许多条记录的值为null，HashMap不是线程安全的，即任意时刻有多线程同时写HashMap可能会导致数据不一致问题。
* HashTable: HashTable是遗留类，很多映射的功能和HashMap类似，但是他是继承自Dictionary类，并且是线程安全的，任何时间只有一个线程能写hashTable。
* ConcurrentHashMap：
* LinkedHashMap: 是HashMap的一个自雷，保存了插入顺序，在用iterator遍历LinkedHashMap时，先得到的肯定是新插入的，也可以在构造式带参数，按照访问次数进行排序。
* TreeMap: TreeMap实现了SortMap接口，能够把保存的记录根据键排序，默认是按照键值升序排序，也可以指定排序的比较器，在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出ClassCastExeption。
</code></pre><h1><span id="构造函数">构造函数</span></h1><ul>
<li>HashMap()：默认构造器，构造一个初始容量为10和默认加载银子为0.75的空HashMap</li>
<li>HashMap(int initialCapacity):构造一个指定容量的和默认加载银子为0.75的空HashMap</li>
<li>HashMap(int initialCapacity, float loadFactor)： 构造一个指定初始容量和加载银子的空HashMap；<br><em>其中initialCapacity不能小于0，当它大于1 &lt;&lt; 30的时候，它就等于1 &lt;&lt; 30</em><br>   if (initialCapacity &gt; MAXIMUM_CAPACITY)<pre><code>      initialCapacity = MAXIMUM_CAPACITY;
</code></pre></li>
</ul>
<p>初始容量：代表哈希表中通的数量，<br>加载因子： 代表哈希表在自动增加之前可以达到的尺度。</p>
<h1><span id="数据结构">数据结构</span></h1><p>列表散列：<br><img data-src="http://images.cnitblog.com/blog/381060/201401/152128351581.png" alt><br>数组+链表+红黑树(jdk8中增加红黑树)<br><img data-src="../img/hashMap内存结构.png" alt><br>HashMap的底层实现还是数组，只不过数组的每一项都是一条链，其中initialCapacity参数代表了该数组额长度。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns a power of two size for the given target capacity.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">tableSizeFor</span><span class="params">(<span class="keyword">int</span> cap)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">    <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这一段表示将初始容量变成向下靠近2的幂次方的数。</p>
<h1><span id="node">Node</span></h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;    <span class="comment">//用来定位数组索引位置</span></span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    V value;</span><br><span class="line">    Node&lt;K,V&gt; next;   <span class="comment">//链表的下一个node</span></span><br><span class="line">    Node(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span></span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">setValue</span><span class="params">(V newValue)</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Node是HashMap的一个内部类，实现了Map.Entry接口，本质是一个映射（键值对）。</p>
<p>HashMap就是使用哈希表来存储的，哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，java中HashMap采用了链地址法，简单来说就是数组加链表的结合。在每个数组元素都是一个链表结构，当数据被hash后，得到数组下标，把数据放在对应下标元素的链表上，例如：<br>    <code>map.put(&quot;name&quot;,&quot;earyant&quot;)</code><br>系统将”name”这个key的HashCode()方法得到其hashCode值，然后再通过Hash算法的后两步运算（高位运算和取模运算）来定位该键值对应的存储位置，有时候两个key会定位到相同的位置，表示发生了Hash碰撞，当然hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map存取效率就会更高。<br>如果哈希桶数很大，即使较差的hash算法也会比较分散，如果哈希桶数组很小，就很容易发生碰撞。</p>
<h1><span id="容量">容量</span></h1><p>在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int threshold;             // 所能容纳的key-value对极限</span><br><span class="line">final float loadFactor;    // 负载因子</span><br><span class="line">int modCount;</span><br><span class="line">int size;</span><br></pre></td></tr></table></figure><br>首先，Node[] table的初始化长度length为默认16，loadFactor为负载因子，默认为0.75.threshold是HashMap所能容纳的最大数据量的Node（键值对）个数。threshold=length*loadFactor，也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。</p>
<ul>
<li>size：实际存在的键值对数量</li>
<li>threshold：length*loadFactor</li>
<li>modCount：记录HashMap内部结构发生裱花的次数，主要用于迭代的快速失败，内部结构变化指的是结构发生变化，比如put，但是某个key对应的value值被覆盖部署于结构变化。</li>
</ul>
<p>在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考<a href="http://blog.csdn.net/liuqiyao_01/article/details/14475159，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。">http://blog.csdn.net/liuqiyao_01/article/details/14475159，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。</a></p>
<p>这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考。<br><a href="http://blog.csdn.net/v_july_v/article/details/6105630。">http://blog.csdn.net/v_july_v/article/details/6105630。</a></p>
<h1><span id="方法">方法</span></h1><ul>
<li><p>确定哈希桶数组索引位置。<br>不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">// 方法一：</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;   <span class="comment">//jdk1.8 &amp; jdk1.7</span></span><br><span class="line">     <span class="keyword">int</span> h;</span><br><span class="line">     <span class="comment">// h = key.hashCode() 为第一步 取hashCode值</span></span><br><span class="line">     <span class="comment">// h ^ (h &gt;&gt;&gt; 16)  为第二步 高位参与运算</span></span><br><span class="line">     <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 方法二：</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">indexFor</span><span class="params">(<span class="keyword">int</span> h, <span class="keyword">int</span> length)</span> </span>&#123;  <span class="comment">//jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的</span></span><br><span class="line">     <span class="keyword">return</span> h &amp; (length-<span class="number">1</span>);  <span class="comment">//第三步 取模运算</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。</p>
</li>
</ul>
<p>这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。</p>
<ul>
<li>put方法<br><img data-src="../img/hashMap put方法执行流程图.png" alt></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="number">1</span>   <span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line"> <span class="number">2</span>     <span class="comment">// 对key的hashCode()做hash</span></span><br><span class="line"> <span class="number">3</span>     <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line"> <span class="number">4</span> &#125;</span><br><span class="line"> <span class="number">5</span></span><br><span class="line"> <span class="number">6</span> <span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent,</span></span></span><br><span class="line"><span class="params"><span class="function"> <span class="number">7</span>                <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line"> <span class="number">8</span>     Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, i;</span><br><span class="line"> <span class="number">9</span>     <span class="comment">// 步骤①：tab为空则创建</span></span><br><span class="line"><span class="number">10</span>     <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line"><span class="number">11</span>         n = (tab = resize()).length;</span><br><span class="line"><span class="number">12</span>     <span class="comment">// 步骤②：计算index，并对null做处理</span></span><br><span class="line"><span class="number">13</span>     <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>)</span><br><span class="line"><span class="number">14</span>         tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line"><span class="number">15</span>     <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="number">16</span>         Node&lt;K,V&gt; e; K k;</span><br><span class="line"><span class="number">17</span>         <span class="comment">// 步骤③：节点key存在，直接覆盖value</span></span><br><span class="line"><span class="number">18</span>         <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line"><span class="number">19</span>             ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line"><span class="number">20</span>             e = p;</span><br><span class="line"><span class="number">21</span>         <span class="comment">// 步骤④：判断该链为红黑树</span></span><br><span class="line"><span class="number">22</span>         <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line"><span class="number">23</span>             e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line"><span class="number">24</span>         <span class="comment">// 步骤⑤：该链为链表</span></span><br><span class="line"><span class="number">25</span>         <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="number">26</span>             <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line"><span class="number">27</span>                 <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="number">28</span>                     p.next = newNode(hash, key,value,<span class="keyword">null</span>);</span><br><span class="line">                        <span class="comment">//链表长度大于8转换为红黑树进行处理</span></span><br><span class="line"><span class="number">29</span>                     <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) <span class="comment">// -1 for 1st</span></span><br><span class="line"><span class="number">30</span>                         treeifyBin(tab, hash);</span><br><span class="line"><span class="number">31</span>                     <span class="keyword">break</span>;</span><br><span class="line"><span class="number">32</span>                 &#125;</span><br><span class="line">                    <span class="comment">// key已经存在直接覆盖value</span></span><br><span class="line"><span class="number">33</span>                 <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line"><span class="number">34</span>                     ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))                                            <span class="keyword">break</span>;</span><br><span class="line"><span class="number">36</span>                 p = e;</span><br><span class="line"><span class="number">37</span>             &#125;</span><br><span class="line"><span class="number">38</span>         &#125;</span><br><span class="line"><span class="number">40</span>         <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">// existing mapping for key</span></span><br><span class="line"><span class="number">41</span>             V oldValue = e.value;</span><br><span class="line"><span class="number">42</span>             <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>)</span><br><span class="line"><span class="number">43</span>                 e.value = value;</span><br><span class="line"><span class="number">44</span>             afterNodeAccess(e);</span><br><span class="line"><span class="number">45</span>             <span class="keyword">return</span> oldValue;</span><br><span class="line"><span class="number">46</span>         &#125;</span><br><span class="line"><span class="number">47</span>     &#125;</span><br><span class="line"></span><br><span class="line"><span class="number">48</span>     ++modCount;</span><br><span class="line"><span class="number">49</span>     <span class="comment">// 步骤⑥：超过最大容量 就扩容</span></span><br><span class="line"><span class="number">50</span>     <span class="keyword">if</span> (++size &gt; threshold)</span><br><span class="line"><span class="number">51</span>         resize();</span><br><span class="line"><span class="number">52</span>     afterNodeInsertion(evict);</span><br><span class="line"><span class="number">53</span>     <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"><span class="number">54</span> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="扩容resize">扩容（resize）</span></h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="number">1</span> <span class="function"><span class="keyword">void</span> <span class="title">resize</span><span class="params">(<span class="keyword">int</span> newCapacity)</span> </span>&#123;   <span class="comment">//传入新的容量</span></span><br><span class="line">    <span class="number">2</span>     Entry[] oldTable = table;    <span class="comment">//引用扩容前的Entry数组</span></span><br><span class="line"> <span class="number">3</span>     <span class="keyword">int</span> oldCapacity = oldTable.length;</span><br><span class="line"> <span class="number">4</span>     <span class="keyword">if</span> (oldCapacity == MAXIMUM_CAPACITY) &#123;  <span class="comment">//扩容前的数组大小如果已经达到最大(2^30)了</span></span><br><span class="line"> <span class="number">5</span>         threshold = Integer.MAX_VALUE; <span class="comment">//修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了</span></span><br><span class="line"> <span class="number">6</span>         <span class="keyword">return</span>;</span><br><span class="line"> <span class="number">7</span>     &#125;</span><br><span class="line"> <span class="number">8</span></span><br><span class="line"> <span class="number">9</span>     Entry[] newTable = <span class="keyword">new</span> Entry[newCapacity];  <span class="comment">//初始化一个新的Entry数组</span></span><br><span class="line"><span class="number">10</span>     transfer(newTable);                         <span class="comment">//！！将数据转移到新的Entry数组里</span></span><br><span class="line"><span class="number">11</span>     table = newTable;                           <span class="comment">//HashMap的table属性引用新的Entry数组</span></span><br><span class="line"><span class="number">12</span>     threshold = (<span class="keyword">int</span>)(newCapacity * loadFactor);<span class="comment">//修改阈值</span></span><br><span class="line"><span class="number">13</span> &#125;</span><br></pre></td></tr></table></figure>
<p>这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> <span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Entry[] newTable)</span> </span>&#123;</span><br><span class="line"> <span class="number">2</span>     Entry[] src = table;                   <span class="comment">//src引用了旧的Entry数组</span></span><br><span class="line"> <span class="number">3</span>     <span class="keyword">int</span> newCapacity = newTable.length;</span><br><span class="line"> <span class="number">4</span>     <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; src.length; j++) &#123; <span class="comment">//遍历旧的Entry数组</span></span><br><span class="line"> <span class="number">5</span>         Entry&lt;K,V&gt; e = src[j];             <span class="comment">//取得旧Entry数组的每个元素</span></span><br><span class="line"> <span class="number">6</span>         <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line"> <span class="number">7</span>             src[j] = <span class="keyword">null</span>;<span class="comment">//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）</span></span><br><span class="line"> <span class="number">8</span>             <span class="keyword">do</span> &#123;</span><br><span class="line"> <span class="number">9</span>                 Entry&lt;K,V&gt; next = e.next;</span><br><span class="line"><span class="number">10</span>                 <span class="keyword">int</span> i = indexFor(e.hash, newCapacity); <span class="comment">//！！重新计算每个元素在数组中的位置</span></span><br><span class="line"><span class="number">11</span>                 e.next = newTable[i]; <span class="comment">//标记[1]</span></span><br><span class="line"><span class="number">12</span>                 newTable[i] = e;      <span class="comment">//将元素放在数组上</span></span><br><span class="line"><span class="number">13</span>                 e = next;             <span class="comment">//访问下一个Entry链上的元素</span></span><br><span class="line"><span class="number">14</span>             &#125; <span class="keyword">while</span> (e != <span class="keyword">null</span>);</span><br><span class="line"><span class="number">15</span>         &#125;</span><br><span class="line"><span class="number">16</span>     &#125;</span><br><span class="line"><span class="number">17</span> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2><span id="感谢参考">感谢参考</span></h2><p><a href="http://www.importnew.com/20386.html">参考</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>这可能不只是一篇面经(转发)</title>
    <url>/posts/java/%E8%BF%99%E5%8F%AF%E8%83%BD%E4%B8%8D%E5%8F%AA%E6%98%AF%E4%B8%80%E7%AF%87%E9%9D%A2%E7%BB%8F-%E8%BD%AC%E5%8F%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="https://www.nowcoder.com/discuss/29890?hmsr=toutiao.io&amp;source=rss&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io">原文链接在此</a></p>
<p>mark，有很多地方还是需要学习的。</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud使用docker部署注册eureka找不到地址</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/SpringCloud%E4%BD%BF%E7%94%A8docker%E9%83%A8%E7%BD%B2%E6%B3%A8%E5%86%8Ceureka%E6%89%BE%E4%B8%8D%E5%88%B0%E5%9C%B0%E5%9D%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>跟随大神学习SpringCloud的时候，在使用docker部署时，遇到了提供者注册不到eureka上去，<a href="http://blog.csdn.net/forezp/article/details/70198649#reply">教程地址在此</a></p>
<p>之后我搜了下docker进程间通信找到了一个<strong>解决办法</strong>：</p>
<p>我弄了一整天也是一直注册不进去，后来又搜了搜docker进程间通信，发现一个方法，<br>eureka-server部署的时候给一个名字： docker run —name eureka-server -p 8761:8761<br>server-hi中部署使用link参数 docker run —link eureka-server（server部署时赋予的名字）:eureka-server(配置中写的地址) ……<br>注册不进去的可以试试。</p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库的count的区别</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84count%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>springBot配置大全（转载）</title>
    <url>/posts/java/springBoot%E9%85%8D%E7%BD%AE%E5%A4%A7%E5%85%A8%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>七大查找算法</title>
    <url>/posts/%E7%AE%97%E6%B3%95/%E4%B8%83%E5%A4%A7%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://blog.jobbole.com/111629/">原文链接</a></p>
<h3><span id="查找算法分类">查找算法分类：</span></h3><ul>
<li>1）静态查找和动态查找；<br> 注：静态或者动态都是针对查找表而言的。动态表指查找表中有删除和插入操作的表。</li>
<li>2）无序查找和有序查找。<ul>
<li>无序查找：被查找数列有序无序均可；</li>
<li>有序查找：被查找数列必须为有序数列。</li>
</ul>
</li>
</ul>
<h2><span id="1-顺序查找">1. 顺序查找</span></h2><p>   挨个查找，不用多说，时间复杂度为O(n);</p>
<h2><span id="2-二分查找">2. 二分查找</span></h2><ul>
<li><p>说明元素必须是有序的，如果是无序的则要先进行排序操作。</p>
</li>
<li><p>基本思想：也称为是折半查找，属于有序查找算法。用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。     </p>
</li>
<li>复杂度分析：最坏情况下，关键词比较次数为log2(n+1)，且期望时间复杂度为O(log2n)；<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    //二分查找（折半查找），版本1</span><br><span class="line">int BinarySearch1(int a[], int value, int n)</span><br><span class="line">&#123;</span><br><span class="line"> int low, high, mid;</span><br><span class="line"> low = 0;</span><br><span class="line"> high = n-1;</span><br><span class="line"> while(low&lt;=high)</span><br><span class="line"> &#123;</span><br><span class="line">     mid = (low+high)/2;</span><br><span class="line">     if(a[mid]==value)</span><br><span class="line">     return mid;</span><br><span class="line">     if(a[mid]&gt;value)</span><br><span class="line">     high = mid-1;</span><br><span class="line">     if(a[mid]&lt;value)</span><br><span class="line">     low = mid+1;</span><br><span class="line"> &#125;</span><br><span class="line">     return -1;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">//二分查找，递归版本</span><br><span class="line">int BinarySearch2(int a[], int value, int low, int high)</span><br><span class="line">&#123;</span><br><span class="line">   int mid = low+(high-low)/2;</span><br><span class="line">   if(a[mid]==value)</span><br><span class="line">   return mid;</span><br><span class="line">   if(a[mid]&gt;value)</span><br><span class="line">   return BinarySearch2(a, value, low, mid-1);</span><br><span class="line">   if(a[mid]&lt;value)</span><br><span class="line">   return BinarySearch2(a, value, mid+1, high);</span><br><span class="line">&#125;</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 3. 插值查找</span><br><span class="line"></span><br><span class="line">在介绍插值查找之前，首先考虑一个新问题，为什么上述算法一定要是折半，而不是折四分之一或者折更多呢？</span><br><span class="line"></span><br><span class="line">打个比方，在英文字典里面查“apple”，你下意识翻开字典是翻前面的书页还是后面的书页呢？如果再让你查“zoo”，你又怎么查？很显然，这里你绝对不会是从中间开始查起，而是有一定目的的往前或往后翻。&lt;</span><br><span class="line"></span><br><span class="line">同样的，比如要在取值范围1 ~ 10000 之间 100 个元素从小到大均匀分布的数组中查找5， 我们自然会考虑从数组下标较小的开始查找。</span><br><span class="line"></span><br><span class="line">经过以上分析，折半查找这种查找方式，不是自适应的（也就是说是傻瓜式的）。二分查找中查找点计算如下：</span><br><span class="line"></span><br><span class="line">mid=(low+high)/2, 即mid=low+1/2*(high-low);</span><br><span class="line"></span><br><span class="line">通过类比，我们可以将查找的点改进为如下：</span><br><span class="line"></span><br><span class="line">mid=low+(key-a[low])/(a[high]-a[low])*(high-low)，</span><br><span class="line"></span><br><span class="line">也就是将上述的比例参数1/2改进为自适应的，根据关键字在整个有序表中所处的位置，让mid值的变化更靠近关键字key，这样也就间接地减少了比较次数。</span><br><span class="line"></span><br><span class="line">* 基本思想：基于二分查找算法，将查找点的选择改进为自适应选择，可以提高查找效率。当然，差值查找也属于有序查找。</span><br><span class="line"></span><br><span class="line">* 注：对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。</span><br><span class="line">**如果分布比较均匀，插值查找比二分查找快，如果分布不均匀，二分查找比较快**</span><br><span class="line">* 复杂度分析：查找成功或者失败的时间复杂度均为O(log2(log2n))。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
//插值查找<br>int InsertionSearch(int a[], int value, int low, int high)<br>{<br>int mid = low+(value-a[low])/(a[high]-a[low])*(high-low);<br>if(a[mid]==value)<br>   return mid;<br>if(a[mid]&gt;value)<br>   return InsertionSearch(a, value, low, mid-1);<br>if(a[mid]&lt;value)<br>   return InsertionSearch(a, value, mid+1, high);<br>}<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">## 4. 斐波那契查找</span><br><span class="line"></span><br><span class="line">在介绍斐波那契查找算法之前，我们先介绍一下很它紧密相连并且大家都熟知的一个概念——黄金分割。</span><br><span class="line"></span><br><span class="line">黄金比例又称黄金分割，是指事物各部分间一定的数学比例关系，即将整体一分为二，较大部分与较小部分之比等于整体与较大部分之比，其比值约为1:0.618或1.618:1。</span><br><span class="line"></span><br><span class="line">0.618被公认为最具有审美意义的比例数字，这个数值的作用不仅仅体现在诸如绘画、雕塑、音乐、建筑等艺术领域，而且在管理、工程设计等方面也有着不可忽视的作用。因此被称为黄金分割。</span><br><span class="line"></span><br><span class="line">大家记不记得斐波那契数列：1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89…….（从第三个数开始，后边每一个数都是前两个数的和）。然后我们会发现，随着斐波那契数列的递增，前后两个数的比值会越来越接近0.618，利用这个特性，我们就可以将黄金比例运用到查找技术中。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* 基本思想：也是二分查找的一种提升算法，通过运用黄金比例的概念在数列中选择查找点进行查找，提高查找效率。同样地，斐波那契查找也属于一种有序查找算法。</span><br><span class="line"></span><br><span class="line">相对于折半查找，一般将待比较的key值与第mid=（low+high）/2位置的元素比较，比较结果分三种情况：</span><br><span class="line">   * 1）相等，mid位置的元素即为所求</span><br><span class="line"></span><br><span class="line">   * 2）&gt;，low=mid+1;</span><br><span class="line"></span><br><span class="line">   * 3）&lt;，high=mid-1。</span><br><span class="line"></span><br><span class="line">斐波那契查找与折半查找很相似，他是根据斐波那契序列的特点对有序表进行分割的。他要求开始表中记录的个数为某个斐波那契数小1，及n=F(k)-1;</span><br><span class="line"></span><br><span class="line">开始将k值与第F(k-1)位置的记录进行比较(及mid=low+F(k-1)-1),比较结果也分为三种</span><br><span class="line"></span><br><span class="line">   * 1）相等，mid位置的元素即为所求</span><br><span class="line"></span><br><span class="line">   * 2）&gt;，low=mid+1,k-=2;</span><br><span class="line"></span><br><span class="line">说明：low=mid+1说明待查找的元素在[mid+1,high]范围内，k-=2 说明范围[mid+1,high]内的元素个数为n-(F(k-1))= Fk-1-F(k-1)=Fk-F(k-1)-1=F(k-2)-1个，所以可以递归的应用斐波那契查找。</span><br><span class="line"></span><br><span class="line">   * 3）&lt;，high=mid-1,k-=1。</span><br><span class="line"></span><br><span class="line">说明：low=mid+1说明待查找的元素在[low,mid-1]范围内，k-=1 说明范围[low,mid-1]内的元素个数为F(k-1)-1个，所以可以递归 的应用斐波那契查找。</span><br><span class="line"></span><br><span class="line">复杂度分析：最坏情况下，时间复杂度为O(log2n)，且其期望复杂度也为O(log2n)。</span><br><span class="line"></span><br><span class="line">```const int max_size=20;//斐波那契数组的长度</span><br><span class="line">    </span><br><span class="line">   /*构造一个斐波那契数组*/</span><br><span class="line">   void Fibonacci(int * F)</span><br><span class="line">   &#123;</span><br><span class="line">      F[0]=0;</span><br><span class="line">      F[1]=1;</span><br><span class="line">      for(int i=2;i&lt;max_size;++i)</span><br><span class="line">      F[i]=F[i-1]+F[i-2];</span><br><span class="line">   &#125;</span><br><span class="line">    </span><br><span class="line">   /*定义斐波那契查找法*/</span><br><span class="line">   int FibonacciSearch(int *a, int n, int key) //a为要查找的数组,n为要查找的数组长度,key为要查找的关键字</span><br><span class="line">   &#123;</span><br><span class="line">      int low=0;</span><br><span class="line">      int high=n-1;</span><br><span class="line">    </span><br><span class="line">      int F[max_size];</span><br><span class="line">      Fibonacci(F);//构造一个斐波那契数组F</span><br><span class="line">    </span><br><span class="line">      int k=0;</span><br><span class="line">      while(n&gt;F[k]-1)//计算n位于斐波那契数列的位置</span><br><span class="line">      ++k;</span><br><span class="line">    </span><br><span class="line">      int * temp;//将数组a扩展到F[k]-1的长度</span><br><span class="line">      temp=new int [F[k]-1];</span><br><span class="line">      memcpy(temp,a,n*sizeof(int));</span><br><span class="line">    </span><br><span class="line">      for(int i=n;i&lt;F[k]-1;++i)</span><br><span class="line">      temp[i]=a[n-1];</span><br><span class="line">    </span><br><span class="line">      while(low&lt;=high)</span><br><span class="line">   &#123;</span><br><span class="line">      int mid=low+F[k-1]-1;</span><br><span class="line">      if(key&lt;temp[mid])</span><br><span class="line">   &#123;</span><br><span class="line">      high=mid-1;</span><br><span class="line">      k-=1;</span><br><span class="line">   &#125;</span><br><span class="line">      else if(key&gt;temp[mid])</span><br><span class="line">   &#123;</span><br><span class="line">      low=mid+1;</span><br><span class="line">      k-=2;</span><br><span class="line">   &#125;</span><br><span class="line">      else</span><br><span class="line">   &#123;</span><br><span class="line">      if(mid&lt;n)</span><br><span class="line">      return mid; //若相等则说明mid即为查找到的位置</span><br><span class="line">      else</span><br><span class="line">      return n-1; //若mid&gt;=n则说明是扩展的数值,返回n-1</span><br><span class="line">   &#125;</span><br><span class="line">   &#125;</span><br><span class="line">      delete [] temp;</span><br><span class="line">      return -1;</span><br><span class="line">   &#125;</span><br><span class="line">    </span><br><span class="line">      int main()</span><br><span class="line">   &#123;</span><br><span class="line">      int a[] = &#123;0,16,24,35,47,59,62,73,88,99&#125;;</span><br><span class="line">      int key=100;</span><br><span class="line">      int index=FibonacciSearch(a,sizeof(a)/sizeof(int),key);</span><br><span class="line">      cout&lt;&lt;key&lt;&lt;&quot; is located at:&quot;&lt;&lt;index;</span><br><span class="line">      return 0;</span><br><span class="line">   &#125; </span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2><span id="5-树表查找">5. 树表查找</span></h2><h3><span id="51-最简单的树表查找算法二叉树查找算法">5.1 最简单的树表查找算法——二叉树查找算法。</span></h3><ul>
<li><p>基本思想：二叉查找树是先对待查找的数据进行生成树，确保树的左分支的值小于右分支的值，然后在就行和每个节点的父节点比较大小，查找最适合的范围。 这个算法的查找效率很高，但是如果使用这种查找方法要首先创建树。</p>
<p>二叉查找树（BinarySearch Tree，也叫二叉搜索树，或称二叉排序树Binary Sort Tree）或者是一棵空树，或者是具有下列性质的二叉树：</p>
<p>1）若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；</p>
<p>2）若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；</p>
<p>3）任意节点的左、右子树也分别为二叉查找树。</p>
<p>二叉查找树性质：对二叉查找树进行中序遍历，即可得到有序的数列。</p>
<p>不同形态的二叉查找树如下图所示：</p>
<ul>
<li>复杂度分析：它和二分查找一样，插入和查找的时间复杂度均为O(logn)，但是在最坏的情况下仍然会有O(n)的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡（比如，我们查找上图（b）中的“93”，我们需要进行n次查找操作）。我们追求的是在最坏的情况下仍然有较好的时间复杂度，这就是平衡查找树设计的初衷。</li>
</ul>
</li>
</ul>
<p>基于二叉查找树进行优化，进而可以得到其他的树表查找算法，如平衡树、红黑树等高效算法。</p>
<h3><span id="52-平衡查找树之2-3查找树2-3-tree">5.2 平衡查找树之2-3查找树（2-3 Tree）</span></h3><p>2-3查找树定义：和二叉树不一样，2-3树运行每个节点保存1个或者两个的值。对于普通的2节点(2-node)，他保存1个key和左右两个自己点。对应3节点(3-node)，保存两个Key，2-3查找树的定义如下：</p>
<ul>
<li><p>1）要么为空，要么：</p>
</li>
<li><p>2）对于2节点，该节点保存一个key及对应value，以及两个指向左右节点的节点，左节点也是一个2-3节点，所有的值都比key要小，右节点也是一个2-3节点，所有的值比key要大。</p>
</li>
<li><p>3）对于3节点，该节点保存两个key及对应value，以及三个指向左中右的节点。左节点也是一个2-3节点，所有的值均比两个key中的最小的key还要小；中间节点也是一个2-3节点，中间节点的key值在两个跟节点key值之间；右节点也是一个2-3节点，节点的所有key值比两个key中的最大的key还要大。   </p>
</li>
<li><p>2-3查找树的性质：</p>
<p>1）如果中序遍历2-3查找树，就可以得到排好序的序列；</p>
<p>2）在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。（这也是平衡树中“平衡”一词的概念，根节点到叶节点的最长距离对应于查找算法的最坏情况，而平衡树中根节点到叶节点的距离都一样，最坏情况也具有对数复杂度。）</p>
<ul>
<li>复杂度分析：</li>
</ul>
<p>2-3树的查找效率与树的高度是息息相关的。</p>
<p>在最坏的情况下，也就是所有的节点都是2-node节点，查找效率为lgN<br>在最好的情况下，所有的节点都是3-node节点，查找效率为log3N约等于0.631lgN<br>距离来说，对于1百万个节点的2-3树，树的高度为12-20之间，对于10亿个节点的2-3树，树的高度为18-30之间。</p>
</li>
</ul>
<h3><span id="53-平衡查找树之红黑树red-black-tree">5.3 平衡查找树之红黑树（Red-Black Tree）</span></h3><p>  2-3查找树能保证在插入元素之后能保持树的平衡状态，最坏情况下即所有的子节点都是2-node，树的高度为lgn，从而保证了最坏情况下的时间复杂度。但是2-3树实现起来比较复杂，于是就有了一种简单实现2-3树的数据结构，即红黑树（Red-Black Tree）。</p>
<p>  基本思想：红黑树的思想就是对2-3查找树进行编码，尤其是对2-3查找树中的3-nodes节点添加额外的信息。红黑树中将节点之间的链接分为两种不同类型，红色链接，他用来链接两个2-nodes节点来表示一个3-nodes节点。黑色链接用来链接普通的2-3节点。特别的，使用红色链接的两个2-nodes来表示一个3-nodes节点，并且向左倾斜，即一个2-node是另一个2-node的左子节点。这种做法的好处是查找的时候不用做任何修改，和普通的二叉查找树相同。</p>
]]></content>
  </entry>
  <entry>
    <title>跳跃表</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%B7%B3%E8%B7%83%E8%A1%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://blog.jobbole.com/111731/">看这篇文章</a></p>
<p>和B+树很像，不过B+树插入需要Rebalance进行树重调整。</p>
]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql索引B+树</title>
    <url>/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E7%B4%A2%E5%BC%95B-%E6%A0%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><a href="http://blog.jobbole.com/111757/">看这篇文章讲的很好</a></p>
<h2><span id="b-树balance-tree">B - 树（Balance Tree）</span></h2><pre><code>二叉查找树的时间复杂度是O(log(n)) 已经够快了，但是二叉查找树的查找速度取决于树的高度。
B - 树，每个节点包含最多k个孩子，k被称为阶，k的大小取决于磁盘页的大小。
</code></pre><h3><span id="一个-m-阶的-b-树具有如下几个特征">一个 m 阶的 B 树具有如下几个特征</span></h3><ul>
<li>根节点至少有两个子女。 </li>
<li>每个中间节点包含k-1个元素和k个孩子，其中m/2 &lt;= k &lt;= m</li>
<li>每个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;=m</li>
<li>所有叶子节点都位于同一层</li>
<li>每个节点中的元素从小到大排列，节点当中 k-1 个元素正好是 k 个孩子包含的元素的值域分划。</li>
</ul>
<h2><span id="b树">B+树</span></h2><p>   在b-树基础上进行改造，将索引全部建在叶子节点上，非叶子节点指向叶子节点的大小。</p>
<p>   <a href="http://blog.jobbole.com/105644/">看这篇文章</a></p>
]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>100块钱可以兑换50块、10块、5块、1块的算法</title>
    <url>/posts/%E7%AE%97%E6%B3%95/100%E5%9D%97%E9%92%B1%E5%8F%AF%E4%BB%A5%E5%85%91%E6%8D%A250%E5%9D%97%E3%80%8110%E5%9D%97%E3%80%815%E5%9D%97%E3%80%811%E5%9D%97%E7%9A%84%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3><span id="最先想到的当然是for循环了">最先想到的当然是for循环了：</span></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">   long time1 = System.currentTimeMillis();</span><br><span class="line">           System.out.println(&quot;当前时间为&quot;+time1);</span><br><span class="line">           int n = 0;</span><br><span class="line">           int n1, n5, n10, n50;</span><br><span class="line">           for (n1 = 0; n1 &lt; 100; n1++) &#123;</span><br><span class="line">               for (n5 = 0; n5 &lt; 20; n5++) &#123;</span><br><span class="line">                   for (n10 = 0; n10 &lt; 10; n10++) &#123;</span><br><span class="line">                       for (n50 = 0; n50 &lt; 2; n50++) &#123;</span><br><span class="line">                           if (n1 * 1 + n5 * 5 + n10 * 10 + n50 * 50 == 100) &#123;</span><br><span class="line">                               n++;</span><br><span class="line">                               System.out.println(&quot;1块的：&quot; + n1 + &quot;张 5块的： &quot; + n5 + &quot;张 10块的 ：&quot; + n10 + &quot;张 50块的：&quot; + n50 + &quot;张&quot;);</span><br><span class="line">                           &#125;</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           long time2 = System.currentTimeMillis();</span><br><span class="line">           System.out.println(&quot;结束时间为&quot;+time2);</span><br><span class="line">           long time = time2 - time1;</span><br><span class="line">           System.out.println(n + &quot; 耗费时间为 &quot; + time);</span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<pre><code>很容易得出结果154.但是耗费时间为 1501038954420 - 1501038954413 =7;
虽然时间耗费不是很多，但是通过打印信息可以看出来，50为2的时候只有一种情况，却空跑了很多空循环。
</code></pre>]]></content>
  </entry>
  <entry>
    <title>SpringCloud学习5路由网关(zuul)</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/SpringCloud%E5%AD%A6%E4%B9%A05%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3-zuul/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在微服务架构中，需要几个关键的组件，服务注册与发现、服务消费、负载均衡、断路器、智能路由、配置管理等，由这几个组件可以组建一个简单的微服务架构，如下图：</p>
<p><img data-src="img/路由网关.png" alt="image"></p>
<p>注意：A 服务和 B 服务是可以相互调用的，作图的时候忘记了。并且配置服务也是注册到服务注册中心的。</p>
<p>客户端的请求首先经过负载均衡（zuul、Ngnix），再到达服务网关（zuul 集群），然后再到具体的服务，服务统一注册到高可用的服务注册中心集群，服务的所有的配置文件由配置服务管理（下一篇文章讲述），配置服务的配置文件放在 Git 仓库，方便开发人员随时改配置。</p>
<p>一、Zuul 简介</p>
<p>Zuul 的主要功能是路由和过滤器。路由功能是微服务的一部分，比如／api/user 映射到 user 服务，/api/shop 映射到 shop 服务。zuul 实现了负载均衡。</p>
<p>zuul 有以下功能：</p>
<p>Authentication<br>Insights<br>Stress Testing<br>Canary Testing<br>Dynamic Routing<br>Service Migration<br>Load Shedding<br>Security<br>Static Response handling<br>Active/Active traffic management</p>
<p>二、准备工作</p>
<p>继续使用上一节的工程。在原有的工程上，创建一个新的工程。</p>
<p>三、创建 service-zuul 工程</p>
<pre><code> &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
</code></pre><p>在其入口 applicaton 类加上注解 @EnableZuulProxy，开启 zuul：</p>
<p>filterType：返回一个字符串代表过滤器的类型，在 zuul 中定义了四种不同生命周期的过滤器类型，具体如下：<br>pre：路由之前<br>routing：路由之时<br>post： 路由之后<br>error：发送错误调用<br>filterOrder：过滤的顺序<br>shouldFilter：这里可以写逻辑判断，是否要过滤，本文 true, 永远过滤。<br>run：过滤器的具体逻辑。可用很复杂，包括查 sql，nosql 去判断该请求到底有没有权限访问。</p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud学习4断路器（Hystrix）</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/SpringCloud%E5%AD%A6%E4%B9%A04%E6%96%AD%E8%B7%AF%E5%99%A8%EF%BC%88Hystrix%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在微服务架构中，我们将业务拆分成一个个的服务，服务与服务之间可以相互调用（RPC）。为了保证其高可用，单个服务又必须集群部署。由于网络原因或者自身的原因，服务并不能保证服务的 100% 可用，如果单个服务出现问题，调用这个服务就会出现网络延迟，此时若有大量的网络涌入，会形成任务累计，导致服务瘫痪，甚至导致服务 “雪崩”。<br>为了解决这个问题，就出现断路器模型。</p>
<h3><span id="断路器简介">断路器简介</span></h3><ul>
<li>Netflix 已经创建了一个名为 Hystrix 的库来实现断路器模式。 在微服务架构中，多层服务调用是非常常见的。</li>
<li>较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用达到一个阀值（hystric 是 5 秒 20 次） 断路器将会被打开。</li>
<li>断路打开后，可用避免连锁故障，fallback 方法可以直接返回一个固定值。</li>
</ul>
<h3><span id="在-ribbon-使用断路器">在 ribbon 使用断路器</span></h3><ul>
<li><p>改造 serice-ribbon 工程的代码：</p>
<p>在 pox.xml 文件中加入：</p>
<dependency>
     <groupid>org.springframework.cloud</groupid>
     <artifactid>spring-cloud-starter-hystrix</artifactid>
</dependency> 
</li>
<li><p>在程序的入口类加 @EnableHystrix：   </p>
</li>
<li><p>改造 HelloService 类，加上 @HystrixCommand，并指定 fallbackMethod 方法。</p>
</li>
</ul>
<h3><span id="feign-中使用断路器">Feign 中使用断路器</span></h3><ul>
<li><p>如果你使用了 feign，feign 是自带断路器的，并且是已经打开了。如果使用 feign 不想用断路器的话，可以在配置文件中关闭它，配置如下：</p>
<p>feign.hystrix.enabled=false</p>
</li>
</ul>
<h3><span id="circuit-breaker-hystrix-dashboard-断路器hystrix-仪表盘">Circuit Breaker: Hystrix Dashboard (断路器：hystrix 仪表盘)</span></h3><ul>
<li><p>基于 service-ribbon 改造下：</p>
<p>pom.xml 加入：</p>
<dependency>
            <groupid>org.springframework.boot</groupid>
            <artifactid>spring-boot-starter-actuator</artifactid>
        </dependency>

<pre><code>    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;
    &lt;/dependency&gt;        
</code></pre></li>
</ul>
<h3><span id="在主程序入口中加入-enablehystrixdashboard-注解开启-hystrixdashboard">在主程序入口中加入 @EnableHystrixDashboard 注解，开启 hystrixDashboard：</span></h3><pre><code>  该仪表盘可以查看错误率
</code></pre>]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud学习3服务消费者feign</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/SpringCloud%E5%AD%A6%E4%B9%A03%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85feign/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3><span id="使用feign">使用feign</span></h3><p>spring-cloud-starter-eureka<br>spring-cloud-starter-feign<br>spring-boot-starter-web<br>spring-boot-starter-test</p>
<h3><span id="配置文件">配置文件</span></h3><p>eureka:<br>  client:<br>    serviceUrl:<br>      defaultZone: <a href="http://localhost:8761/eureka/">http://localhost:8761/eureka/</a><br>server:<br>  port: 8765<br>spring:<br>  application:<br>    name: service-feign</p>
<h3><span id="开启feign">开启feign</span></h3><ul>
<li>在程序的入口类，需要通过注解 @EnableFeignClients 来开启 feign:<h3><span id="调用服务">调用服务</span></h3></li>
<li>定义一个 feign 接口类, 通过 @ FeignClient（“服务名”），来指定调用哪个服务：</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud学习2服务消费者</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/SpringCloud%E5%AD%A6%E4%B9%A02%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在上一篇文章，讲了服务的注册和发现。在服务架构中，业务都会被拆分成一个独立的服务，服务与服务的通讯是基于 http restful 的。spring cloud 有两种调用方式，一种是 ribbon+restTemplate，另一种是 feign。在这一篇文章首先讲解下基于 ribbon+rest。</p>
<h2><span id="ribbon">ribbon</span></h2><ul>
<li><p>是一个负载均衡客户端，可以很好的控制 http 和 tcp 的一些行为。Feign 也用到 ribbon，当你使用 @ FeignClient，ribbon 自动被应用。</p>
</li>
<li><p>ribbon 已经默认实现了这些配置 bean：</p>
<ul>
<li><p>IClientConfig ribbonClientConfig: DefaultClientConfigImpl</p>
</li>
<li><p>IRule ribbonRule: ZoneAvoidanceRule</p>
</li>
<li><p>IPing ribbonPing: NoOpPing</p>
</li>
<li><p>ServerList ribbonServerList: ConfigurationBasedServerList</p>
</li>
<li><p>ServerListFilter ribbonServerListFilter: ZonePreferenceServerListFilter</p>
</li>
<li><p>ILoadBalancer ribbonLoadBalancer: ZoneAwareLoadBalancer</p>
</li>
</ul>
</li>
</ul>
<h3><span id="准备工作">准备工作</span></h3><ul>
<li>基于上一节的工程，启动 eureka-server 工程；启动 service-hi 工程，它的端口为 8762；将 service-hi 的配置文件的端口改为 8763, 并启动它，这时你会发现：service-hi 在 eureka-server 注册了 2 个，这就相当于一个小的集群。访问 localhost:8761 如图所示：</li>
</ul>
<h2><span id="新建一个service-ribbon">新建一个service-ribbon</span></h2><ul>
<li>spring-cloud-starter-eureka</li>
<li>spring-cloud-starter-ribbon</li>
<li>spring-boot-starter-web</li>
<li>spring-boot-starter-test</li>
</ul>
<h3><span id="想eureka注册一个客户端">想eureka注册一个客户端</span></h3><pre><code>eureka:
   client:
     serviceUrl:
       defaultZone: http://localhost:8761/eureka/
 server:
   port: 8764
 spring:
   application:
     name: service-ribbon  
</code></pre><h3><span id="启动类">启动类</span></h3><ul>
<li>在工程的启动类中, 通过 @EnableDiscoveryClient 向服务中心注册；   </li>
</ul>
<h3><span id="架构如下">架构如下</span></h3><p>   <img data-src="img/ribbon后的架构.png" alt="image"></p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud学习1EurekaServer</title>
    <url>/posts/%E5%BE%AE%E6%9C%8D%E5%8A%A1/SpringCloud%E5%AD%A6%E4%B9%A01EurekaServer/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2><span id="创建eurekaserver">创建EurekaServer</span></h2><h3><span id="idea初始化项目">Idea初始化项目</span></h3><ul>
<li>选择cloud discovery-&gt;eureka server 。</li>
</ul>
<h3><span id="创建启动类">创建启动类</span></h3><ul>
<li>@EnableEurekaServer</li>
</ul>
<h3><span id="配置参数">配置参数</span></h3><pre><code>server:
  port: 8761

eureka:
  instance:
    hostname: localhost
  client:
    registerWithEureka: false
    fetchRegistry: false
    serviceUrl:
      defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/
</code></pre><h2><span id="创建eurekaclient">创建EurekaClient</span></h2><h3><span id="初始化项目">初始化项目</span></h3><ul>
<li>通server</li>
</ul>
<h3><span id="创阿金启动类">创阿金启动类</span></h3><ul>
<li>@EnableEurekaClient</li>
</ul>
<h3><span id="配置参数">配置参数</span></h3><pre><code> eureka:
   client:
     serviceUrl:
       defaultZone: http://localhost:8761/eureka/
 server:
   port: 8762
 spring:
   application:
     name: service-hi
</code></pre>]]></content>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>微信公众平台Dubbo项目结构</title>
    <url>/posts/java/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%B9%B3%E5%8F%B0Dubbo%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      <tags>
        <tag>java</tag>
        <tag>dubbo</tag>
        <tag>微信公众平台</tag>
      </tags>
  </entry>
  <entry>
    <title>基于微信公众号的微服务架构</title>
    <url>/posts/java/%E5%9F%BA%E4%BA%8E%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><ul>
<li>wechatParent:    <ul>
<li>wechat-base-parent</li>
<li>wechat-business-parent</li>
<li>wechat-core-parent</li>
<li>wechat-web-parent</li>
</ul>
</li>
</ul>
<h3><span id="wechatparent">wechatParent</span></h3><ul>
<li>职责： 一键构建所有需要发布的项目。</li>
<li>特性<ul>
<li>所有项目初始时就带有这些 jar 包的依赖，例如：testng(单元测试相关),h2(单元测试相关),easymock(单元测试相关),lombok（根据注释自动生成 setter 和 getter）</li>
<li>所有项目的额外特性，例如：单元测试插件</li>
<li>项目发布管理，例如：私一的 maven 私服配置</li>
</ul>
</li>
</ul>
<h3><span id="wechat-core-parent">wechat-core-parent</span></h3><ul>
<li>职责：<ul>
<li>该部分与业务没有关联，只提供基础能力。例如：数据库持久能力，缓存能力，http封装能力，通用工具能力。</li>
</ul>
</li>
<li>通用特性：<ul>
<li>javadoc插件，用于生成javadoc</li>
</ul>
</li>
</ul>
<h3><span id="wechat-base-parent">wechat-base-parent</span></h3><ul>
<li>只代表一个真实存在而且能独立存在的业务实体，简称base项目。</li>
</ul>
<h3><span id="we-business-parent">we-business-parent</span></h3><ul>
<li>职责：<ul>
<li>它所聚合的的项目必须是一个提供 “共享” 业务流程，简称：business 项目。在这个流程过程中有可能需要引用 base 服务。它本身没有一个真实存在而且能独立存在的核心实体       </li>
</ul>
</li>
</ul>
<h3><span id="wechat-web-parent">wechat-web-parent</span></h3><ul>
<li>职责：<ul>
<li>它所聚合的的项目可以通过互联网向用户提供服务，在产品规划上它自己独有的不被共享的业务，简称：web 项目。</li>
</ul>
</li>
</ul>
<h3><span id="总体架构图如下">总体架构图如下</span></h3><p>   <img data-src="img/项目架构图.jpg" alt="image">  </p>
<h3><span id="redis">Redis</span></h3><ul>
<li>提到阿里云的这个 Redis，不得不吐槽一句，它竟然是不支持主从的，只能单实例，不过，用它做数据缓存，还真是蛮不错的选择，响应速度非常快。而且，因为是放置在内网的且只能内网访问，所以安全性也很高。<h3><span id="mongodb">MongoDB</span></h3></li>
<li>结构型数据，主要存储档案式的数据，比如每个用户的操作行为，以档案式记录并进行统计分析，方便下一阶段的项目做个性化服务。另外一些关联复杂的数据，也可以用 MongoDb 存储，可以提高访问速度。还有，一些对软件应用版本比较敏感的数据也可以存在 MongoDB 中，比如 a 版本拿到 A 数据，b 版本拿到 B 数据，而这个 AB 数据都是由很多关联关系复杂的数据所组成，如果把这些数据根据版本号存储在不同的 MongoDB 档案中，需要时，直接根据版本号拿就可以了，这样就避免了很多的 mysql 查询。</li>
</ul>
<h3><span id="静态资源">静态资源</span></h3><ul>
<li>OSS + CDN<br>OSS 存储静态资源，CDN(内容分发网络) 可以加速静态资源的下载速度。至于资源链接地址，客户端可以通过接口访问从后端业务数据库中拿到。</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>微信</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>bootstrap日期格式化</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/datetimepicker%20bootstrap%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><ul>
<li>p : 小写上下午 (‘am’ or ‘pm’)  meridian in lower case (‘am’ or ‘pm’) - according to locale file <ul>
<li>P : 大写上下午 (‘AM’ or ‘PM’) meridian in upper case (‘AM’ or ‘PM’) - according to locale file</li>
<li>s : 一位的秒  seconds without leading zeros</li>
<li>ss : 两位的秒  seconds, 2 digits with leading zeros</li>
<li>i : 一位的分钟  minutes without leading zeros</li>
<li>ii : 两位的分钟  minutes, 2 digits with leading zeros</li>
<li>h : 一位的24进制小时  hour without leading zeros - 24-hour format</li>
<li>hh : 两位的24进制小时  hour, 2 digits with leading zeros - 24-hour format</li>
<li>H : 一位的12进制小时 hour without leading zeros - 12-hour format</li>
<li>HH : 两位的24进制小时  hour, 2 digits with leading zeros - 12-hour format</li>
<li>d : 一位的天  day of the month without leading zeros</li>
<li>dd : 两位的天 day of the month, 2 digits with leading zeros</li>
<li>m : 一位的分钟  numeric representation of month without leading zeros</li>
<li>mm : 两位的分钟 numeric representation of the month, 2 digits with leading zeros</li>
<li>M : 缩写月份单词，三位数  short textual representation of a month, three letters</li>
<li>MM : 全拼月份单词 full textual representation of a month, such as January or March</li>
<li>yy : 两位的年  two digit representation of a year</li>
<li>yyyy : 四位的年  full numeric representation of a year, 4 digits</li>
</ul>
</li>
</ul>
<h3><span id="详情请看官网解释">详情请看官网解释</span></h3><p><a href="http://www.bootcss.com/p/bootstrap-datetimepicker/">http://www.bootcss.com/p/bootstrap-datetimepicker/</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>datetimepicker Jquery日期格式化</title>
    <url>/posts/java/java%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/datetimepicker%20Jquery%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3><span id="年">年</span></h3><ul>
<li>y 一位数的年份（2001 显示为 “1”）。</li>
<li>yy 年份的最后两位数（2001 显示为 “01”）。</li>
<li>yyyy 完整的年份（2001 显示为 “2001”）。</li>
</ul>
<h3><span id="月">月</span></h3><ul>
<li>M 一位数或两位数月份值。</li>
<li>MM 两位数月份值。一位数数值前面加一个零。</li>
<li>MMM 三个字符的月份缩写。</li>
<li>MMMM 完整的月份名。</li>
</ul>
<h3><span id="天">天</span></h3><ul>
<li>d 一位数或两位数的天数。</li>
<li>dd 两位数的天数。一位数天数的前面加一个零。</li>
<li>ddd 三个字符的星期几缩写。</li>
<li>dddd 完整的星期几名称。</li>
</ul>
<h3><span id="小时">小时</span></h3><ul>
<li>h12 小时格式的一位数或两位数小时数。<br> hh12 小时格式的两位数小时数。一位数数值前面加一个零。</li>
<li>H24 小时格式的一位数或两位数小时数。</li>
<li>HH24 小时格式的两位数小时数。一位数数值前面加一个零。</li>
</ul>
<h3><span id="分钟">分钟</span></h3><ul>
<li>m 一位数或两位数分钟值。</li>
<li>mm 两位数分钟值。一位数数值前面加一个零。</li>
</ul>
<h3><span id="秒">秒</span></h3><ul>
<li>s 一位数或两位数秒数。</li>
<li>ss 两位数秒数。一位数数值前面加一个零。</li>
</ul>
<h3><span id="上下午">上下午</span></h3><ul>
<li>t 一个字母的 AM/PM 缩写（”AM” 显示为 “A”）。</li>
<li>tt 两个字母的 AM/PM 缩写（”AM” 显示为 “AM”）。</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>完整写一篇博客</title>
    <url>/posts/%E5%B7%A5%E5%85%B7%E7%B1%BB/%E5%AE%8C%E6%95%B4%E5%86%99%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3><span id="1命令行创建一个md文件">1命令行创建一个md文件。</span></h3><ul>
<li>hexo new “title”</li>
<li><p>在 hexo 主目录下 source -&gt; _posts 新建以 .md 为后缀的文件。</p>
<p>这两种方式都可以创建一个，不过命令行形式会在md中创建描述文件：</p>
<pre><code>---
title: 完整写一篇博客
date: 2017-07-18 14:03:42
tags:
---
</code></pre></li>
</ul>
<h3><span id="创建front-matter">创建Front-matter</span></h3><pre><code> 参数    描述    默认值
 layout    布局    post
 title    标题    文件名
 date    建立日期    文件建立日期
 updated    更新日期    文件更新日期
 tags    标签（不适用于分页）
 categories    分类（不适用于分页）
 permalink    覆盖文章网址
 thumbnail    缩略图地址
 toc    显示 TOC 按钮    true
 comment    显示评论    true
 notag    不生成标签按钮    false
 top    置顶    false
 mathJax    启用 Mathjax    false
</code></pre><h3><span id="友情url链接">友情url链接</span></h3><pre><code> pages:
      About:
          link: &quot;#about&quot;
          icon: person
          divider: false
</code></pre><p><a href="https://blog.csdn.net/qq_32767041/category_8927471.html">参考</a></p>
]]></content>
      <categories>
        <category>hexo教程</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建Material主题的Hexo博客</title>
    <url>/posts/%E5%B7%A5%E5%85%B7%E7%B1%BB/%E6%90%AD%E5%BB%BAMaterial%E4%B8%BB%E9%A2%98%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>全篇可以在这搜到：</p>
<p><a href="https://material.viosey.com/services/">戳这里</a></p>
<h2><span id="本地搜索插件">本地搜索插件</span></h2><p>npm install hexo-generator-search —save<br>在主配置文件中添加：<br>search:<br>    path: search.xml<br>    field: all</p>
<h2><span id="rss订阅插件">rss订阅插件</span></h2><p>npm install hexo-generator-feed —save</p>
<p>feed:<br>  type: atom<br>  path: atom.xml<br>  limit: 20<br>  hub:<br>  content:</p>
]]></content>
  </entry>
  <entry>
    <title>node8.0方法弃用解决办法</title>
    <url>/posts/%E5%B7%A5%E5%85%B7%E7%B1%BB/node8-0%E6%96%B9%E6%B3%95%E5%BC%83%E7%94%A8%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3><span id="刚升级node后发现报如下的错">刚升级node后发现报如下的错：</span></h3><ul>
<li><p>(node:34880) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.</p>
<p>  node.js从8.0开始已经弃用了fs.SyncWriteStream方法，hexo中有一个hexo-fs插件，调用了这个方法，所以就会报错。</p>
</li>
</ul>
<h3><span id="解决办法">解决办法：</span></h3><ul>
<li>npm install hexo-fs —save</li>
</ul>
<p>插件就更新了，问题就解决了。</p>
]]></content>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC通俗解释</title>
    <url>/posts/java/RPC%E9%80%9A%E4%BF%97%E8%A7%A3%E9%87%8A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="rpc通俗解释">RPC通俗解释</span></h1><h2><span id="ipc和rpc">IPC和RPC</span></h2><p>早些时间，一个电脑中多个线程互相独立，A线程和B线程都想用发送邮件功能，就需要开发两份代码，所以就有了一个协议是：IPC（Inter-process-communication）进行进程间通信，这样就可以在A中开发一个发送邮件的代码，B进程调用A进程代码就行了。<br>同比，现在的程序员们，为了方便调用其他电脑中的代码，研究出来RPC（Remote Procedure Call Protocol）；</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM介绍</title>
    <url>/posts/java/jvm/JVM%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="jvm介绍">JVM介绍</span></h1><h2><span id="jvm包括">JVM包括：</span></h2><pre><code>* 1、 字节码指令集
* 2、 一组寄存器
* 3、 一个栈
* 4、 一个垃圾回收堆
* 5、 存储方法区
</code></pre><h2><span id="jvm-的生命周期">JVM 的生命周期</span></h2><p>1) JVM 实例对应了一个独立运行的 java 程序它是进程级别<br>    1) 启动。启动一个 Java 程序时，一个 JVM 实例就产生了，任何一个拥有 public static void main(String[] args) 函数的 class 都可以作为 JVM 实例运行的起点<br>    2) 运行。main() 作为该程序初始线程的起点，任何其他线程均由该线程启动。JVM 内部有两种线程：守护线程和非守护线程，main() 属于非守护线程，守护线程通常由 JVM 自己使用，<b> java 程序也可以表明自己创建的线程是守护线程 <b><br>    3) 消亡。当程序中的所有非守护线程都终止时，JVM才退出；若安全管理器允许，程序也可以使用 Runtime 类或者 System.exit() 来退出</b></b></p>
<p>2) JVM 执行引擎实例则对应了属于用户运行程序的线程它是线程级别的</p>
<h2><span id="jvm模型">JVM模型</span></h2><p><img data-src="http://images.cnitblog.com/i/437053/201403/030952082544688.png" alt="image"></p>
<h2><span id="内存空间">内存空间：</span></h2><pre><code>1) 方法区： 指令计数器以及其他隐含寄存器
2) Java堆： 
3) Java栈：
4) 本地方法栈：
</code></pre><h2><span id="共享不共享">共享不共享：</span></h2><pre><code>共享：
    1) 方法区
    2) 栈（Heap）
不共享：
    1)程序计数器
    2)VM stack 虚拟机栈
    3)本地方法栈


1) 程序计数器： 
2) 栈： 线程私有的，每个线程创建的同时都会创建 JVM 栈，JVM栈中存放的为当前线程中局部基本类型的变量（java中定义的八种基本类型：boolean、char、byte、short、int、long、float、double）、部分的返回结果以及 Stack Frame，非基本类型的对象在 JVM 栈上仅存放一个指向堆上的地址。
3) 堆：1）存储 *对象实例以及数组值*
       2）**！Sun Hospot JVM为了提高对象内存分配的效率，对于所创建的线程都会分配一个独立的空间TLAB（Thread Local Allocation Buffer） ，其大小由JVM根据运行的情况计算而得，在TLAB中分配的对象不需要加锁，因此JVM在给线程的对象分配内存时会尽量在TLAB中分配，性能和C性能差不多高效，如果对象过大，仍然直接在堆中分配。 **
       3）TLAB仅作用于新生代的Eden Space，因此多个小对象比一个大对象高效。
       4）新创建的对象总是被放在新生代中，如果在一次或者多次GC后活下来，就会被转移到老年代。
4）方法区：1）在Sun JDK中对应着为永久带、持久带 ！！！
           2）方法区存放了所加载类的信息（名称，修饰符等），类中的静态变量，类中定义为final类型的常量，类中的Field信息，类中的方法信息，当开发人员用Class对象的getname,isInterface等获取信息时，数据都来源于方法区，方法区也是**共享的**，在一定条件下，也会被GC，当方法区使用的内存超过其允许的大小，也会抛OutMemory异常。
</code></pre><h3><span id="原因">原因：</span></h3><pre><code>JVM每遇到一个线程，都会为其分配一个程序计数器，VM stack 和本地方法栈，当线程终止时三者所使用的空间也被回收掉。
</code></pre>]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>如何保证推送消息能够准确推送到客户端</title>
    <url>/posts/java/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%8E%A8%E9%80%81%E6%B6%88%E6%81%AF%E8%83%BD%E5%A4%9F%E5%87%86%E7%A1%AE%E6%8E%A8%E9%80%81%E5%88%B0%E5%AE%A2%E6%88%B7%E7%AB%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1><span id="如何保证推送消息能够准确推送到客户端">如何保证推送消息能够准确推送到客户端。</span></h1><h2><span id="手机端">手机端：</span></h2><ul>
<li>轮询方式获取消息。</li>
<li>短信拦截模式。  发送短信通知消息，应用中的短信拦截模块拦截短信，并解析成数据。成本高。</li>
<li><p>持久连接。</p>
<p>监听电量变化，网络变化，开关屏幕等等时候注册BroadCastReceiver来接收通知，接手后进行消息获取。<br>有些ROM一旦用户kill掉主线程，就不会再投送广播消息给应用，导致应用无法启动，这是可以Fork一个进程,一旦发现主线程被杀，立即调用shell启动该Service（应用保活）</p>
</li>
</ul>
<h2><span id="微服务间如何选择推送和拉取数据">微服务间如何选择推送和拉取数据</span></h2><p>在消息系统中，一般有两种消费模式：生产端推送消息，消费主动拉取消息。</p>
<h4><span id="数据是动态的且实时性较强宜采用生产端推送">数据是动态的，且实时性较强，宜采用生产端推送。</span></h4><p>   例如家长手机控制孩子手机使用，希望设置立即生效，家长端设置后由<strong>立即</strong>由中间系统进行通知。如果让消费端轮询查消息，不仅不能保证消息的实时性和准确性，而且系统也会造成一定的损耗，供应链系统也会被迫处理重复订单问题。<br>    如果把消息设置成实时推送也是不合适的，<strong>推送成不成功不应该作为设置成功的条件</strong>。设置功能和推送功能不应该是强关联的，就像发送验证码，服务器收到了发送验证码的功能请求后，异步交给验证码发送功能，返回给客户200成功，随后验证码发送功能进行异步通知，确保通知成功即可。</p>
<h4><span id="客户端长时间离线状态">客户端长时间离线状态</span></h4><p>   客户端长时间离线状态（断网，没电等等），没办法推送过去，会暂存在一个暂存表中，等待客户端联网等监听广播事件进行主动获取，消息获取成功，就会把离线消息表里的消息转移到已发送的消息表中。（不在本表中将已发送的消息的字段置为已读，会影响查询速度。）</p>
<h4><span id="推送的优点">推送的优点</span></h4><ul>
<li>时效性高。</li>
<li>服务器压力小。 相对比轮询拉取模式，每次推送都会有数据，有效避免了空轮询</li>
<li>交互简单。 只需要提供推送接口就好了，不需要额外开销。</li>
</ul>
<h4><span id="推送的缺点">推送的缺点</span></h4><ul>
<li>不能保证一定能推送成功。</li>
<li>缺乏数据多样性，推送的消息一般都有固定的模板<h4><span id="极光推送">极光推送</span></h4></li>
<li>活跃用户的到达率在90%以上。轮询获取99%以上。</li>
<li>并发情况下第三方服务的实时性不太理想。</li>
</ul>
<h4><span id="自主研发的推送系统">自主研发的推送系统</span></h4><ul>
<li>对客户端的海量长连接的维护管理消耗太大。</li>
<li>App端Service稳定性，保活。</li>
<li>有些厂商不允许有push service存在。</li>
</ul>
<h2><span id="自主研发的推送架构">自主研发的推送架构</span></h2><h3><span id="架构方案类似">架构方案类似：</span></h3><p>   <img data-src="http://upload-images.jianshu.io/upload_images/1760830-e6fbb7ae6613b8ae?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>            （图片来自架构之美公众号，侵删）</p>
<ul>
<li>通过动态组合和扩展方式，结合移动Push推送数据分析，不同的手机使用不同的方案，针对性的优化，android平台中，融合多种不同的第三方推送PUSH平台，提高转化率。</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>推送</tag>
      </tags>
  </entry>
</search>
